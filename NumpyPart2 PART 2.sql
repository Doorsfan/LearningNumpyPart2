# The output shows the total (aggregate) profit fore ach year.
#
# To also determine the total profit summed over all years, you must add up the individual
# values yourself or run an additional query.
#
# Or, you can use ROLLUP - which provides both levels of analysis with a single query.
#
# Adding a WITH ROLLUP modifier to the GROUP BY clause causes the query to produce
# another (super-aggregate) row that shows the grant total over all year values:
#
# 		SELECT year, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+--------+---------------+
# 		| year 	| profit 		 |
# 		+--------+---------------+
# 		| 2000 	| 4525 			 |
# 		| 2001 	| 3010 			 |
# 		| NULL 	| 7535 			 |
# 		+--------+---------------+
#
# The NULL value in the year column identifies the grant total super-aggregate line.
#
# ROLLUP has a more complex effect when there are multiple GROUP by columns.
#
# In this case, each time there is a change in value in any but the last grouping
# column, the query produces an extra super-aggregate summary row.
#
# For example, without ROLLUP, a summary of the sales table based on year, country,
# and product might look like this, where the output indicates summary values only
# at the year/country/product level of analysis:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product;
# 		+------+-----------------+-----------------+-------------+
# 		| year | country 			 | product 			 | profit 		|
# 		+------+-----------------+-----------------+-------------+
# 		| 2000 | Finland 			 | Computer 		 | 1500 			|
# 		| 2000 | Finland 			 | Phone 			 | 100 			|
# 		| 2000 | India 			 | Calculator 		 | 150 		   |
# 		| 2000 | India 			 | Computer 		 | 1200 			|
# 		| 2000 | USA 				 | Calculator 		 | 75 			|
# 		| 2000 | USA 				 | Computer 		 | 1500 			|
# 		| 2001 | Finland 			 | Phone 			 | 10 			|
# 		| 2001 | USA 				 | Calculator 		 | 50 			|
# 		| 2001 | USA 				 | Computer 		 | 2700 			|
# 		| 2001 | USA 				 | TV 				 | 250 			|
# 		+------+-----------------+-----------------+-------------+
#
# With ROLLUP added, the query produces several extra rows:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# 		+------+-----------------+------------+-------------+
# 		| year | country 			 | product 	  | profit 		 |
# 		+------+-----------------+------------+-------------+
# 		| 2000 | Finland 			 | Computer   | 1500 		 |
# 		| 2000 | Finland 			 | Phone 	  | 100 			 |
# 		| 2000 | Finland 			 | NULL 		  | 1600 		 |
# 		| 2000 | India 			 | Calculator | 150 			 |
# 		| 2000 | India 			 | Computer   | 1200 		 |
# 		| 2000 | India 			 | NULL 		  | 1350 		 |
# 		| 2000 | USA 				 | Calculator | 75 			 |
# 		| 2000 | USA 				 | Computer   | 1500 		 |
# 		| 2000 | USA 				 | NULL 		  | 1575 		 |
# 		| 2000 | NULL 				 | NULL 		  | 4525 		 |
# 		| 2001 | Finland 			 | Phone 	  | 10 			 |
# 		| 2001 | Finland 			 | NULL 		  | 10 			 |
# 		| 2001 | USA 				 | Calculator | 50 			 |
# 		| 2001 | USA 				 | Computer   | 2700 		 |
# 		| 2001 | USA 				 | TV 		  | 250 			 |
# 		| 2001 | USA 				 | NULL 		  | 3000 		 |
# 		| 2001 | NULL 				 | NULL 		  | 3010 		 |
# 		| NULL | NULL 				 | NULL 		  | 7535 		 |
# 		+------+-----------------+------------+-------------+
#
# Now the output includes summary information at four levels of analysis, not just one:
#
# 		) Following each set of product rows for a given year and country, an extra super-aggregate summary row
# 			appears showing the total for all products.
#
# 			These rows have the product column set to NULL
#
# 		) Following each set of rows for a given year, an extra super-aggregate summary row appears showing
# 			the total for all countries and products.
#
# 			These rows have the country and products columns set to NULL
#
# 		) Finally, following all other rows, an extra super-aggregate summary row appears showing the grand total
# 			for all years, countries, and products.
#
# 			This row has the year, country and products set to NULL
#
# Previously, MySQL did not allow the use of DISTINCT or ORDER BY in a query having a WITH ROLLUP option.
#
# This restriction is lifted in MySQL 8.0.12, and later.
#
# (Bug #87450, Bug #86311, Bug#26640100, Bug#26073513)
#
# For GROUP BY --- WITH ROLLUP queries, to test whether NULL values in the result represent
# super-aggregate values, the GROUPING() function is available for use in theh select list,
# HAVING clause and (as of MySQL 8.0.12) ORDER BY clause.
#
# For example, GROUPING(year) returns 1 when NULL in the year column occurs in a super-aggregate
# row, and 0 otherwise.
#
# SImilarly, GROUPING(country) and GROUPING(product) return 1 for super-aggregate NULL values
# in the country and product columns, respectively:
#
# 		SELECT
# 			year, country, product, SUM(profit) AS profit,
# 			GROUPING(year) AS grp_year,
# 			GROUPING(country) AS grp_country,
# 			GROUPING(product) AS grp_product
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
# 		| year | country 			  | product 		 | profit 	     | grp_year   	  | grp_country 		| grp_product 	  |
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
# 		| 2000 | Finland 			  | Computer 		 | 1500 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | Finland 			  | Phone 			 | 100 			  | 0 				  | 0 		 			| 0 				  |
# 		| 2000 | Finland 			  | NULL 			 | 1600 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | India 			  | Calculator 	 | 150 			  | 0 				  | 0 				   | 0				  |
# 		| 2000 | India 			  | Computer 		 | 1200 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | India 			  | NULL 			 | 1350 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | USA 				  | Calculator 	 | 75 			  | 0 				  | 0 				   | 0 				  |
# 		| 2000 | USA 				  | Computer 		 | 1500 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | USA 				  | NULL 			 | 1575 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | NULL 				  | NULL 			 | 4525 			  | 0 				  | 1 					| 1 				  |
# 		| 2001 | Finland 			  | Phone 			 | 10 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | Finland 			  | NULL 			 | 10 			  | 0 				  | 0 					| 1 				  |
# 		| 2001 | USA 				  | Calculator 	 | 50 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | Computer 		 | 2700 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | TV 				 | 250 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | NULL 			 | 3000 			  | 0 				  | 0 					| 1 				  |
# 		| 2001 | NULL 				  | NULL 			 | 3010 			  | 0 				  | 1 					| 1 				  |
# 		| NULL | NULL 				  | NULL 			 | 7535 			  | 1 				  | 1 					| 1 				  |
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
#
# Instead of displaying the GROUPING()  result directly, you can use GROUPING() to substitute labels for super-aggregate
# NULL values:
#
# 		SELECT
# 			IF(GROUPING(year), 'All years', year) AS year,
# 			IF(GROUPING(country), 'All countries', country) AS country,
# 			IF(GROUPING(product), 'ALl products', product) AS product,
# 			SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# +------------+---------------------+-------------------+--------------+
# | year 		| country 				 | product 				| profit 		|
# +------------+---------------------+-------------------+--------------+
# | 2000 		| Finland 				 | Computer 			| 1500 			|
# | 2000 		| Finland 				 | Phone 				| 100 			|
# | 2000 		| Finland 				 | All products 		| 1600 			|
# | 2000 		| India 					 | Calculator 			| 150 			|
# | 2000 		| India 					 | Computer 			| 1200 			|
# | 2000 		| India 					 | All products 		| 1350 		   |
# | 2000 		| USA 					 | Calculator 			| 75 				|
# | 2000 		| USA 					 | Computer 			| 1500 		   |
# | 2000 		| USA 					 | All products 		| 1575 			|
# | 2000 		| All countries 		 | All products 		| 4525 			|
# | 2001 		| Finland 				 | Phone 				| 10 				|
# | 2001 		| Finland 				 | All products 		| 10 				|
# | 2001 		| USA 					 | Calculator 			| 50 				|
# | 2001 		| USA 					 | Computer 			| 2700 			|
# | 2001 		| USA 					 | TV 					| 250 			|
# | 2001 		| USA 					 | All Products 		| 3000 			|
# | 2001 		| All countries 		 | ALl products 		| 3010 			|
# | All years  | All countries 		 | All products 		| 7535 			|
# +------------+---------------------+-------------------+--------------+
#
# With multiple expression arguments, GROUPING() returns a result representing a bitmask
# that combines the results for each expression, with the lowest-order bit corresponding
# ot the result for the rightmost expression.
#
# For example, GROUPING(year, country, product) is evaluated like this:
#
# 		result FOR GROUPING(product)
# 	 + result FOR GROUPING(country) << 1
#   + result FOR GROUPING(year) << 2
#
# The result of such a GROUPING() is nonzero if any of the expressions represents a super-aggregate NULL,
# so you can return only the super-aggregate rows and filter out the regular grouped rows like this:
#
# 	SELECT year, country, product, SUM(profit) AS profit
# 	FROM sales
# 	GROUP BY year, country, product WITH ROLLUP
# 	HAVING GROUPING(year, country, product) <> 0;
# +--------+------------+--------+------------+
# | year   | country 	| product| profit 	 |
# +--------+------------+--------+------------+
# | 2000   | Finland 	| NULL 	| 1600 		 |
# | 2000   | India 		| NULL 	| 1350 		 |
# | 2000   | USA 			| NULL   | 1575 		 |
# | 2000   | NULL 		| NULL 	| 4525 		 |
# | 2001   | Finland 	| NULL   | 10 			 |
# | 2001   | USA 			| NULL   | 3000 		 |
# | 2001   | NULL 		| NULL 	| 3010 		 |
# | NULL   | NULL 		| NULL 	| 7535 		 |
# +--------+------------+--------+------------+
#
# The sales table contains no NULL values, so all NULL values in a ROLLUP result represent
# super-aggregate values.
#
# When the data set contains NULL values, ROLLUP summaries may contain NULL values not only
# in super-aggregate rows, but also in regular grouped rows.
#
# GROUPING() enables these to be distinguished.
#
# Suppose that table t1 contains a simple data set with two grouping factors for a
# set of quantity values, where NULL indicates something like "other" or "unknown"
#
# 		SELECT * FROM t1;
# 		+-------+----------+-----------+
# 		| name  | size 	 | quantity  | 
# 		+-------+----------+-----------+
# 		| ball  | small 	 | 10 		 |
# 		| ball  | large 	 | 20 		 |
# 		| ball  | NULL 	 | 5 			 |
# 		| hoop  | small 	 | 15 		 |
# 		| hoop  | large 	 | 5 			 |
# 		| hoop  | NULL 	 | 3 			 |
# 		+-------+----------+-----------+
#
# A simple ROLLUP operation produces these results, in which it is not so easy to distinguish
# NULL values in super-aggregate rows from NULL values in regular grouped rows:
#
# 		SELECT name, size, SUM(quantity) AS quantity
# 		FROM t1
# 		GROUP BY name, size WITH ROLLUP;
# 		+--------+-----------+----------------+
# 		| ball 	| size 		| quantity 		  |
# 		+--------+-----------+----------------+
# 		| ball 	| NULL 		| 	5 				  |
# 		| ball   | large 		|  20 			  |
# 		| ball 	| small 		|  10  			  |
# 		| ball   | NULL 		|  35 			  |
# 		| hoop   | NULL 		|  3 				  |
# 		| hoop   | large 		|  5 				  |
# 		| hoop   | small 		|  15 			  |
# 		| hoop   | NULL 		| 	23 			  |
# 		| NULL 	| NULL 		|  58 			  |
# 		+--------+-----------+----------------+
#
# Using GROUPING() to substitute labels for the super-aggregate NULL values makes the result easier
# to interpret:
#
# 		SELECT
# 			IF(GROUPING(name) = 1, 'All items', name) AS name,
# 			IF(GROUPING(size) = 1, 'All sizes', size) AS size,
# 			SUM(quantity) AS quantity
# 		FROM t1
# 		GROUP BY name, size WITH ROLLUP;
# 	+----------------+----------------+---------------+
# 	| name 			  | size 			 | quantity 	  |
# 	+----------------+----------------+---------------+
# 	| ball 			  | NULL 			 | 	5 			  |
#  | ball 			  | large 			 | 	20 		  |
# 	| ball 			  | small 			 | 	10 		  |
# 	| ball 			  | All sizes 		 | 	35 		  |
# 	| hoop 			  | NULL 			 | 	3 			  |
# 	| hoop 			  | large 			 | 	5 			  |
# 	| hoop 			  | small 			 | 	15 		  |
# 	| hoop 			  | All sizes 		 | 	23 		  |
# 	| All items 	  | All sizes 		 | 	58 		  |
# 	+----------------+----------------+---------------+
#
# OTHER CONSIDERATIONS WHEN USING ROLLUP
#
# The following discussion lists some behaviors specific to the MySQL implementation of ROLLUP.
#
# Prior to 8.0.12, when you use ROLLUP, you cannot also use an ORDER BY clause to sort the results.
# In other words, ROLLUP and ORDER BY were mutually exclusive in MySQL.
#
# However, you still have some control over sort order. To work around the restriction that prevents
# using ROLLUP with ORDER BY and achieve a specific sort order of grouped results, generate the 
# grouped result set as a derived table and apply ORDER BY to it.
#
# For example:
#
# 		SELECT * FROM
# 			(SELECT year, SUM(profit) AS profit
# 			FROM sales GROUP BY year WITH ROLLUP) AS dt
# 		ORDER BY year DESC;
# 		+-------+-----------+
# 		| year  | profit 	  |
# 		+-------+-----------+
# 		| 2001  | 3010 	  |
# 		| 2000  | 4525 	  |
# 		| NULL  | 7535 	  |
# 		+-------+-----------+
#
# As of MySQL 8.0.12, ORDER BY and ROLLUP can be used together, which enables the use
# of ORDER BY and GROUPING() to achieve a specific sort order of grouped results.
#
# For example:
#
# 		SELECT year, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP
# 		ORDER BY GROUPING(year) DESC;
# 		+--------+----------+
# 		| year 	| profit   |
# 		+--------+----------+
# 		| NULL 	| 7535 	  |
# 		| 2000   | 4525 	  |
# 		| 2001 	| 3010 	  |
# 		+--------+----------+
#
# In both cases, the super-aggregate summary rows sort with the rows from which
# they are calculated, and their placement depends on sort order (at the end for
# ascending sort, at the beginning for descending sort)
#
# LIMIT can be used to restrict the number of rows returned to the client.
#
# LIMIT is applied after ROLLUP, so the limit applies against the extra rows
# added by ROLLUP.
#
# For example:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP
# 		LIMIT 5;
# 		+---------+--------------+----------------+-------------+
# 		| year 	 | country 		 | product 			| profit 	  |
# 		+---------+--------------+----------------+-------------+
# 		| 2000    | Finland 		 | Computer 		| 1500 		  |
# 		| 2000 	 | Finland 		 | Phone 			| 100 		  |
# 		| 2000 	 | Finland 		 | NULL 				| 1600 		  |
# 		| 2000 	 | India 		 | Calculator 		| 150 		  |
# 		| 2000    | India 		 | Computer 		| 1200 		  |
# 		+---------+--------------+----------------+-------------+
#
# Using LIMIT with ROLLUP may produce results taht are more difficult to interpret,
# because there is less context for understanding the super-aggregate rows.
#
# The NULL indicators in each super-aggregate row are produced when the row is
# sent to the client.
#
# The server looks at the columns named in the GROUP BY clause following
# the leftmost one that has changed value.
#
# For any column in the result set with a name that matches any of those
# names, its value is set to NULL.
#
# (If you specify grouping columns by column position, the server identifies
# which columns to set to NULL by position)
#
# Because the NULL values in the super-aggregate rows are placed into the result
# set at such a late stage in query processing, you can test them as NULL values
# only in the select list or HAVING clause.
#
# You cannot test them as NULL values in join conditions or the WHERE clause
# to determine which rows to select.
#
# For example, you cannot add WHERE product IS NULL to the query to eliminate
# from the output all but the super-aggregate rows.
#
# The NULL values do appear as NULL on the client side and can be tested as such
# using any MySQL client programming interface.
#
# However, at this point, you cannot distinguish whether a NULL represents
# a regular grouped value or a super-aggregate value.
#
# A MySQL extension permits a column that does not appear in the GROUP BY list 
# to be named in teh select list.
#
# (For information about nonaggregated columns and GROUP BY, see SECTION 12.20.3,
# "MySQL HANDLING OF GROUP BY")
#
# In this case, the server is free to choose any value from this nonaggregated
# column in summary rows, and this includes the extra rows added by WITH ROLLUP.
#
# For example, in the following query, country is a nonaggregated column that does
# not appear in the GROUP BY list and values chosen for this column are nondeterministic:
#
# 		SELECT year, country, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+----------+-------------+-----------+
# 		| year 	  | country 	 | profit 	 |
# 		+----------+-------------+-----------+
# 		| 2000 	  | India 		 | 4525 		 |
# 		| 2001 	  | USA 			 | 3010 		 |
# 		| NULL 	  | USA 			 | 7535 		 |
# 		+----------+-------------+-----------+
#
# This behavior is permitted when the ONLY_FULL_GROUP_BY SQL mode is not enabled.
#
# If that mode is enabled, the server rejects the query as illegal because
# country is not listed in the GROUP BY clause.
#
# With ONLY_FULL_GROUP_BY enabled, you can still execute the query by using the
# ANY_VALUE() function for nondeterministic-value columns:
#
# 		SELECT year, ANY_VALUE(country) AS country, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+-------+--------------+-----------+
# 		| year  | country 	  | profit 	  |
# 		+-------+--------------+-----------+
# 		| 2000  | India 		  | 4525 	  |
# 		| 2001  | USA 			  | 3010 	  |
# 		| NULL  | USA 			  | 7535		  |
# 		+-------+--------------+-----------+
#
# 12.20.3 MYSQL HANDLING OF GROUP BY
#
# SQL92 and earlier does not permit queries for which the select list, HAVING condition,
# or ORDER BY list refer to nonaggregated columns that are not named in the GROUP BY
# clause.
#
# For example, this query is illegal in standard SQL 92 because the nonaggregated name column
# in the select list does not appear in the GROUP BY:
#
# 		SELECT o.custid, c.name, MAX(o.payment)
# 			FROM orders AS o, customers AS c
# 			WHERE o.custid = c.custid
# 			GROUP BY o.custid;
#
# For the query to be legal in SQL92, the name column must be omitted from the select list
# or named in the GROUP BY clause.
#
# SQL99 and later permits such nonaggregates per optional feature T301 if they are functionalily
# dependent on GROUP BY columns:
#
# 		if such a relationship exists between name and custid, th query is legal.
#
# This would be the case, for example, were custid a primary key of customers.
#
# MySQL implements detection of functional dependence.
#
# If the ONLY_FULL_GROUP_BY SQL mode is enabled (which it is by default), MySQL
# rejects queries for which the select list, HAVING CONDITION or ORDER BY list
# refer to nonaggregated columns that are neither named in teh GROUP BY clause
# nor are functionally dependent on them.
#
# If ONLY_FULL_GROUP_BY is disabled, a MySQL extension to the standard SQL use of
# GROUP BY permits the select list, HAVING condition, or ORDER BY list to refer to
# nonaggregated columns even if the columns are not functionally dependent on
# GROUP BY columns.
#
# This causes MySQL to accept the preceding query. In this case, the server is free
# to choose any value from each group, so unless they are the same, the values
# chosen are nondeterministic - which is probably not what you want.
#
# Furthermore, the selection of values from each group cannot be influenced by
# adding an ORDER BY clause.
#
# Result set sorting occurs after values have been chosen, and ORDER BY does not
# affect which value within each group the server chooses.
#
# Disabling ONLY_FULL_GROUP_BY is useful primarily when you know that, due to
# some property of the data, all values in each nonaggregated column not
# named in the GROUP BY are the same for each group.
#
# You can achieve the same effect without disabling ONLY_FULL_GROUP_BY by using
# ANY_VALUE() to refer to the nonaggregated column.
#
# The following discussion demonstrates functional dependence, the error message
# MySQL produces when functional dependence is absent, and ways of causing
# MySQL to accept a query in the absence of functional dependence.
#
# This query might be invalid with ONLY_FULL_GROUP_BY enabled because the nonaggregated
# address column in the select list is not named in the GROUP BY clause:
#
# 		SELECT name, address, MAX(age) FROM t GROUP BY name;
#
# The query is valid if name is a primary key of t or is a unique NOT NULL column.
#
# In such cases, MySQL recognizes that the selected column is functionally
# dependent on a grouping column.
#
# For example, if name is a primary key, its value determines the value of
# address because each group has only one value of the primary key and thus
# only one row.
#
# As a result, there is no randomness in the choice of address value in a group
# and no need to reject the query.
#
# The query is invalid if name is not a primary key of t or a unique NOT NULL column.
# In this case, no functional dependency can be inferred and an error occurs:
#
# 		SELECT name, address, MAX(age) FROM t GROUP BY name;
# 		ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP
# 		BY clause and contains nonaggregated column 'mydb.t.address' which
# 		is not functionally dependent on columns in GROUP BY clause;
# 		this is incompatible with sql_mode=only_full_group_by
#
# If you know that, for a given data set, each name value in fact uniquely
# determines the address value, address is effectively functionally dependent
# on name.
#
# To tell MySQL to accept the query, you can use the ANY_VALUE() function:
#
# 		SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name;
#
# Alternatively, disable ONLY_FULL_GROUP_BY
#
# The preceding example is quite simple, however. In particular, it is unlikely you would
# group on a single primary key because every group would contain only one row.
#
# For additional examples demonstrating functional dependence in more complex queries,
# see SECTION 12.20.4, "DETECTION OF FUNCTIONAL DEPENDENCE"
#
# if a query has aggregate functions and no GROUP BY clause, it cannot have nonaggregated
# columns in the select list, HAVING condition, or ORDER BY list with ONLY_FULL_GROUP_BY enabled:
#
# 		SELECT name, MAX(age) FROM t;
# 		ERROR 1140 (42000): In aggregated query without GROUP BY, expression
# 		#1 of SELECT list contains nonaggregated column 'mydb.t.name'; this
# 		is incompatible with sql_mode=only_full_group_by
#
# Without GROUP BY, there is a single group and it is nondeterministic which name values to choose
# for the group.
#
# Here, too, ANY_VALUE() can be used, if it is immaterial which name value MySQL chooses:
#
# 		SELECT ANY_VALUE(name), MAX(age) FROM t;
#
# ONLY_FULL_GROUP_BY also affects handling of queries that use DISTINCT and ORDER BY.
#
# Consider the case of a table t with three columns c1, c2, and c3 that contains these
# rows:
#
# 		c1 c2 c3
# 		1  2  A
# 		3  4 	B
# 		1  2  C
#
# Suppose that we execute the following query, expecting the results to be ordered
# by c3:
#
# 		SELECT DISTINCT c1, c2 FROM t ORDER BY c3;
#
# To order the result, duplicates must be eliminated first.
#
# But to do so, should we keep the first row or the third?
#
# This arbitrary choice influences the retained value of c3, which in turn
# influences ordering and makes it arbitrary as well.
#
# To prevent this problem, a query that has DISTINCT and ORDER BY is rejected
# as invalid if any ORDER BY expression does not satisfy at least one of these
# conditions:
#
# 		) The expression is equal to one in the select list
#
# 		) All columns referenced by the expression and belonging to the query's selected tables
# 			are elements of the select list.
#
# Another MySQL extension to standard SQL permits references in the HAVING clause to aliased
# expressions in the select list.
#
# For example, the following query returns name values that occur only once in table orders:
#
# 		SELECT name, COUNT(name) FROM orders
# 			GROUP BY name
# 			HAVING COUNT(name) = 1;
#
# The MySQL extension permits the use of an alias in the HAVING clause for the
# aggregated column:
#
# 		SELECT name, COUNT(name) AS c FROM orders
# 			GROUP BY name
# 			HAVING c = 1;
#
# Standard SQL permits only column expressions in GROUP BY clauses, so a statement
# such as this is invalid because FLOOR(value/100) is a noncolumn expression:
#
# 		SELECT id, FLOOR(value/100)
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100);
#
# MySQL extends standard SQL to permit noncolumn expressions in GROUP BY clauses
# and considers the preceding statement valid.
#
# Standard SQL also does not permit alaises in GROUP BY clauses.
#
# MySQL extends standard SQL to permit aliases, so another way to write
# the query is as follows:
#
# 		SELECT id, FLOOR(value/100) AS val
# 			FROM tbl_name
# 			GROUP BY id, val;
#
# The alias val is considered a column expression in the GROUP BY clause.
#
# In the presence of a noncolumn expression in the GROUP BY clause, MySQL recognizes
# equality between that expression and expressions in the select list.
#
# This means that with ONLY_FULL_GROUP_BY SQL mode enabled, tthe query containing 
# GROUP BY id, FLOOR(value/100) is valid because that same FLOOR() expression occurs
# in the select list.
#
# However, MySQL does not try to recognize functional dependence on GROUP BY noncolumn
# expressions, so the following query is invalid with ONLY_FULL_GROUP_BY enabled,
# even though the third selected expression is a simple formula of the id column
# and the FLOOR() expression in the GROUP BY clause:
#
# 		SELECT id, FLOOR(value/100), id+FLOOR(value/100)
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100);
#
# A workaround is to use a derived table:
#
# 		SELECT id, F, id+F
# 		FROM
# 			(SELECT id, FLOOR(value/100) AS F
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100)) AS dt;
#
# 12.20.4 DETECTION OF FUNCTIONAL DEPENDENCE
#
# The following discussion provides several examples of the ways in which MySQL detects
# functional dependencies.
#
# The examples use this notation:
#
# 		{X} -> {Y}
#
# Understand this as "X uniquely determines Y"; which also means that Y is functionally dependent on X.
#
# The examples use the world database, which can be downloaded at <link>.
#
# You can find details on how to install the database on the same page.
#
# 		) FUNCTIONAL DEPENDENCIES DERIVED FROM KEYS
#
# 		) FUNCTIONAL DEPENDENCIES DERIVED FROM MULTIPLE-COLUMN KEYS AND FROM EQUALITIES
#
# 		) FUNCTIONAL DEPENDENCY SPECIAL CASES
#
# 		) FUNCTIONAL DEPENDENCIES AND VIEWS
#
# 		) COMBINATIONS OF FUNCTIONAL DEPENDENCIES
#
# FUNCTIONAL DEPENDENCIES DERIVED FROM KEYS
#
# The following query selects, for each country, a count of spoken languages:
#
# 		SELECT co.Name, COUNT(*)
# 		FROM countrylanguage cl, country co
# 		WHERE cl.CountryCode = co.Code
# 		GROUP BY co.Code;
#
# co.Code is a primary key of co, so all columns of co are functionally dependent on it,
# as expressed using this notation:
#
# 		{co.Code} -> {co.*}
#
# Thus, co.name is functionally dependent on GROUP BY columns and the query is valid.
#
# A UNIQUE index over a NOT NULL column could be used instead of a primary key and the
# same functional dependence would apply.
#
# (This is not true for a UNIQUE index that permits NULL values because it permits multiple
# NULL values and in that case uniqueness is lost)
#
# FUNCTIONAL DEPENDENCIES DERIVED FROM MULTIPLE-COLUMN KEYS AND FROM EQUALITIES
#
# This query selects, for each country, a list of all spoken languages and how many
# people speak them:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population / 100.0 AS SpokenBy
# 		FROM countrylanguage cl, country co
# 		WHERE cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# The pair (cl.CountryCode, cl.Language) is a two-column composite primary key
# of cl, so that column pair uniquely determines all columns of cl:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*)
#
# Moreover, because of the equality in the WHERE clause:
#
# 		{cl.CountryCode} -> {co.Code}
#
# And, because co.Code is primary key of co:
#
# 		{co.Code} -> {co.*}
#
# "Uniquely determines" relationships are transitive, therefore:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# As a result, the query is valid.
#
# AS with the previous example, a UNIQUE key over NOT NULL columns could be used
# instead of a primary key.
#
# An INNER JOIN condition can be used instead of WHERE.
#
# The same functional dependencies apply:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM countrylanguage cl INNER JOIN country co
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# FUNCTIONAL DEPENDENCY SPECIAL CASES
#
# Whereas an equality test in a WHERE condition or INNER JOIN condition is symmetric,
# an equality test in an outer join condition is not, because tables play different roles.
#
# Assume that referential integrity has been accidentally broken and there exists a row
# of countrylanguage without a coresponding row in country.
#
# Consider the same query as in the previous example, but with a LEFT JOIN:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM countrylanguage cl LEFT JOIN country co
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# For a given value of cl.CountryCode, the value of co.Code in the join
# result is either found in a matching row (determined by cl.CountryCode) or is
# NULL-complemented if there is no match (also determined by cl.CountryCode).
#
# In each case, this relationship applies:
#
# 		{cl.CountryCode} -> {co.Code}
#
# cl.CountryCode is itself functionally dependent on {cl.CountryCode, cl.Language} which
# is a primary key.
#
# If in the join result co.Code is NULL-complemented, co.Name is as well.
#
# If co.Code is not NULL-complemented, then because co.Code is a primary key,
# it determines co.Name. Therefore, in all cases:
#
# 		{co.Code} -> {co.Name}
#
# Which yields:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# As a result, the query is valid.
#
# However, suppose that the tables are swapped, as in this query:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM country co LEFT JOIN countrylanguage cl
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# Now this relationship does NOT apply:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# Indeed, all NULL-complemented rows made for cl will be put into
# a single group (they have both GROUP BY columns equal to NULL), and
# inside this group the value of co.Name can vary.
#
# It is invalid, and MySQL rejects it.
#
# Functional dependence in outer joins is thus linked to whether determinant
# columns belong to the left or right side of the LEFT JOIN.
#
# Determination of functional dependence becomes more complex if htere are
# nested outer joins or the join condition does not consist entirely
# of equality comparisons.
#
# FUNCTIONAL DEPENDENCIES AND VIEWS
#
# Suppose that a view on countries produces their code, their name in uppercase,
# and how many different official languages they have:
#
# 		CREATE VIEW Country2 AS
# 		SELECT co.Code, UPPER(co.Name) AS UpperName,
# 		COUNT(cl.Language) AS OfficialLanguages
# 		FROM country AS co JOIN countrylanguage AS cl
# 		ON cl.CountryCode = co.Code
# 		WHERE cl.isOfficial = 'T'
# 		GROUP BY co.Code;
#
# This definition is valid because:
#
# 		{co.Code} -> {co.*}
#
# In the view result, the first selected column is co.Code, which is also
# the group column and thus determines all other selected expressions:
#
# 		{Country2.Code} -> {Country2.*}
#
# MySQL understands this and uses this information, as described following.
#
# This query displays countries, how many different official languages they have,
# and how many cities they have, by joining the view with the city table:
#
# 		SELECT co2.Code, co2.UpperName, co2.OfficialLanguages,
# 		COUNT(*) AS Cities
# 		FROM country2 AS co2 JOIN city ci
# 		ON ci.CountryCode = co2.Code
# 		GROUP BY co2.Code;
#
# This query is valid because, as seen previously:
#
# 		{co2.Code} -> {co2.*}
#
# MySQL is able to discover a functional dependency in the result of a view and use
# that to validate a query which uses the view.
#
# The same would be true if country2 were a derived table (or common table expression),
# as in:
#
# 		SELECT co2.Code, co2.UpperName, co2.OfficialLanguages,
# 		COUNT(*) AS Cities
# 		FROM
# 		( 
# 			SELECT co.Code, UPPER(co.Name) AS UpperName,
# 			COUNT(cl.Language) AS OfficialLanguages
# 			FROM country AS co JOIN countrylanguage AS cl
# 			ON cl.CountryCode=co.Code
# 			WHERE cl.isOfficial='T'
# 			GROUP BY co.Code
#  	) AS co2
# 		JOIN city ci ON ci.CountryCode = co2.Code
# 		GROUP BY co2.Code;
#
# COMBINATIONS OF FUNCTIONAL DEPENDENCIES:
#
# MySQL is able to combine all of hte preceding types
# of functional dependencies (key based, equality based, view based)
# to validate more complex queries.
#
# 12.21 WINDOW FUNCTIONS
#
# 12.21.1 WINDOW FUNCTION DESCRIPTIONS
# 12.21.2 WINDOW FUNCTION CONCEPTS AND SYNTAX
# 12.21.3 WINDOW FUNCTION FRAME SPECIFICATION
# 12.21.4 NAMED WINDOWS
# 12.21.5 WINDOW FUNCTION RESTRICTIONS
#
# MySQL supports window functions that, for each row from a query, perform a calculation
# using rows related to that row.
#
# The following sections discuss how to use window functions, including descriptions
# of the OVER and WINDOW clauses.
#
# The first section provides descriptions of the nonaggregate window functions.
# For descriptions of the aggregate window functions, see 12.20.1, "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# For information about optimization and window functions, see SECTION 8.2.1.19, "WINDOW FUNCTION OPTIMIZATION"
#
# 12.21.1 WINDOW FUNCTION DESCRIPTIONS
#
# This section describes nonaggregate window functions that, for each row from a query,
# perform a calculation using rows related to that row.
#
# Most aggregate functions also can be used as window functions; see SECTION 12.20.1,
# "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# For window function usage information and examples, and definitions of terms such as
# the OVER clause, window, partition, frame and peer, see SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# TABLE 12.27 WINDOW FUNCTIONS
#
# 		Name 							Description
#
# CUME_DIST() 						Cumulative distribution value
#
# DENSE_RANK() 					Rank of current row within its partition, without gaps
#
# FIRST_VALUE() 					Value of argument from first row of window frame
#
# LAG() 								Value of argument from row lagging current row within partition
#
# LAST_VALUE() 					Value of argument from last row of window frame
#
# LEAD() 							Value of argument from row leading current row within partition
#
# NTH_VALUE() 						Value of argument from N-th row of window frame
#
# NTILE() 							Bucket number of current row within its partition
#
# PERCENT_RANK() 					Percentage rank value 
#
# RANK() 							Rank of current row within its partition, with gaps
#
# ROW_NUMBER() 					Number of current row within its partition
#
# In the following function descriptions, over_clause represents the OVER clause, described
# in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# Some window functions permit a null_treatment clause that specifies how to handle
# NULL values when calculating results.
#
# This clause is optional.
#
# It is part of the SQL standard, but the MySQL implementation permits only RESPECT
# NULLS (which is also the default)
#
# This means that NULL values are considered when calculating results.
#
# IGNORE NULLS is parsed, but produces an error.
#
# 		) CUME_DIST() over_clause
#
# 			Returns the cumulative distribution of a value within a group of values,
# 			that is, the percentage of partition values less than or equal to the value in the current row.
#
# 			This represents the number of rows preceding or peer with the current row in the
# 			window ordering of the window partition divided by the total number of rows
# 			in the window partition.
#
# 			Return values range from 0 to 1
#
# 			This function should be used with ORDER BY to sort partition rows into the desired order.
#
# 			Without ORDER BY, all rows are peers and have value N/N = 1, where N is the partition size.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows, for the set of values in the val column, the CUME_DIST()
# 			value for each row, as well as the percentage rank value returned by the similar
# 			PERCENT_RANK() function.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() OVER w AS 'row_number',
# 					CUME_DIST() OVER w AS 'cume_dist',
# 					PERCENT_RANK() OVER w AS 'percent_rank'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+---------+--------------------+----------------------------+-------------------+
# 				| val 	 | row_number 			 | cume_dist 						| percent_rank 	  |
# 				+---------+--------------------+----------------------------+-------------------+
# 				| 1 		 | 1 						 | 0.22 etc. 						| 0 					  |
# 				| 1 		 | 2 						 | 0.22 etc. 						| 0 					  |
# 				| 2 		 | 3 						 | 0.33 etc 						| 0.25 				  |
# 				| 3 		 | 4 						 | 0.66 etc. 						| 0.375 				  |
# 				| 3 		 | 5 						 | 0.66 etc. 						| 0.375 				  |
# 				| 3 		 | 6 						 | 0.66 etc. 						| 0.375 				  |
# 				| 4 		 | 7 						 | 0.88 etc. 						| 0.75 				  |
# 				| 4 		 | 8 						 | 0.88 etc. 						| 0.75 				  |
# 				| 5 		 | 9 						 | 1 									| 1 					  |
# 				+---------+--------------------+----------------------------+-------------------+
#
# 		) DENSE_RANK() over_clause
#
# 			Returns the rank of the current row within its partition, without gaps.
#
# 			Peers are considered ties and receive the same rank. This function assigns
# 			conesecutive ranks to peer groups; the result is that groups of size greater
# 			than one do not produce noncontiguous rank numbers.
#
# 			For an example, see the RANK() function description.
#
# 			This function should be used with ORDER BY to sort partition rows into
# 			the desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) FIRST_VALUE(expr) [null_treatment] over_clause
#
# 			Returns the value of expr from the first row of the window frame.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section introduction.
#
# 			The following query demonstrates FIRST_VALUE(), LAST_VALUE() and two instances
# 			of NTH_VALUE():
#
# 				SELECT
# 					time, subject, val,
# 					FIRST_VALUE(val) OVER w AS 'first',
# 					LAST_VALUE(val) OVER w AS 'last',
# 					NTH_VALUE(val, 2) OVER w AS 'second',
# 					NTH_VALUE(val, 4) OVER w AS 'fourth'
# 				FROM observations
# 				WINDOW w AS (PARTITION BY subject ORDER BY time
# 								ROWS UNBOUNDED PRECEDING);
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
# 			| time 				| subject 		 | val 	 | first  | last 		 | second  | fourth 	 |
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
# 			| 07:00:00 		   | st113 			 | 10 	 | 10 	 | 10 		 | NULL 	  | NULL 	 |
# 			| 07:15:00 		   | st113 			 | 9 		 | 10 	 | 9 			 | 9 		  | NULL 	 |
# 			| 07:30:00 			| st113 			 | 25 	 | 10 	 | 25 		 | 9 		  | NULL 	 |
# 			| 07:45:00 			| st113 			 | 20 	 | 10 	 | 20 		 | 9 		  | 20 		 |
# 			| 07:00:00 			| xh458 			 | 0 		 | 0 		 | 0 			 | NULL 	  | NULL 	 |
# 			| 07:15:00 			| xh458 			 | 10 	 | 0 		 | 10 		 | 10 	  | NULL 	 |
# 			| 07:30:00 			| xh458 			 | 5 		 | 0 		 | 5 			 | 10 	  | NULL 	 |
# 			| 07:45:00 			| xh458 			 | 30 	 | 0 		 | 30 		 | 10 	  | 30 		 |
# 			| 08:00:00 			| xh458 			 | 25 	 | 0 		 | 25 		 | 10 	  | 30 		 |
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
#
# 			Each function uses the rows in the current frame, which, per the window definition shown,
# 			extends from the first partition row to the current row.
#
# 			For the NTH_VALUE() calls, the current frame does not always include the requested row,
# 			in such cases, the return value is NULL
#
# 		) LAG(expr [, N[, default]]) [null_treatment] over_clause
#
# 			Returns the value of expr from the row that lags (precedes) the current row by N rows
# 			within its partition.
#
# 			If there is no such row, the return value is default.
#
# 			For example, if N is 3, the return value is default for the first two rows.
#
# 			If N or default are missing, the defaults are 1 and NULL, respectively.
#
# 			N must be a literal nonnegative integer. If N is 0, expr is evaluated for the current row.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			LAG() (and the similar LEAD() function) are often used to compute differences between rows.
#
# 			The following query shows a set of time-ordered observations and, for each one,
# 			the LAG() and LEAD() values from the adjoining rows, as well as the differences
# 			between the current and adjoining rows:
#
# 				SELECT
# 					t, val,
# 					LAG(val) 			OVER w AS 'lag',
# 					LEAD(val) 			OVER w AS 'lead',
# 					val - LAG(val) 	OVER w AS 'lag diff',
# 					val - LEAD(val) 	OVER w AS 'lead diff'
# 				FROM series
# 				WINDOW w AS (ORDER BY t);
# 				+--------------------+---------+----------+----------+------------------+--------------------+
# 				| t 						| val 	 | lag 		| lead 	  | lag diff 			| lead diff 			|
# 				+--------------------+---------+----------+----------+------------------+--------------------+
# 				| 12:00:00 				| 100 	 | NULL 		| 125 	  | NULL 				| 	-25 					|
# 				| 13:00:00 				| 125 	 | 100 		| 132 	  | 25 					|  -7 					|
# 				| 14:00:00 				| 132 	 | 125 		| 145 	  | 7 					|  -13 					|
# 				| 15:00:00 				| 145 	 | 132 		| 140 	  | 13 					|  5 						|
# 				| 16:00:00 				| 140 	 | 145 		| 150 	  | -5 					|  -10 					|
# 				| 17:00:00 				| 150 	 | 140 		| 200 	  | 10 					|  -50 					|
# 				| 18:00:00 				| 200 	 | 150 		| NULL 	  | 50 					| 	NULL 					|
# 				+--------------------+---------+----------+----------+------------------+--------------------+
#
# 			In the example, the LAG() and LEAD() calls use the default N and default values of 1 and NULL, respectively.
#
# 			The first row shows what happens when there is no previous row for LAG(): The function returns the
# 			default value (in this case, NULL) 
#
# 			The last row shows the same thing when there is no next row for LEAD()
#
# 			LAG() and LEAD() also serve to compute sums rather than differences.
#
# 			Consider this data set, which contains the first few numbers of the Fibonacci series:
#
# 				SELECT n FROM fib ORDER BY n;
# 				+--------+-
# 				| n 	   |
# 				+--------+
# 				| 1 		|
# 				| 1 		|
# 				| 2 		|
# 				| 3 		|
# 				| 5 		|
# 				| 8 		|
# 				+--------+
#
# 			THe following query shows the LAG() and LEAD() values for the rows adjacent
# 			to the current row.
#
# 			It also uses those functions to add to the current row value the values
# 			from the preceding and following rows.
#
# 			The effect is to generate the next number in the Fibonacci series, and the
# 			next number after that:
#
# 				SELECT
# 					n,
# 					LAG(n, 1, 0) 		OVER w AS 'lag',
# 					LEAD(n, 1, 0) 		OVER w AS 'lead',
# 					n + LAG(n, 1, 0) 	OVER w AS 'next_n',
# 					n + LEAD(n, 1, 0) OVER w AS 'next_next_n'
# 				FROM fib
# 				WINDOW w AS (ORDER BY n);
# 				+--------+----------+---------+-----------+-------------------+
# 				| n 		| lag 	  | lead 	| next_n 	| next_next_n 		  |
# 				+--------+----------+---------+-----------+-------------------+
# 				| 1 		| 0 		  | 1 		| 	1 			| 2 					  |
# 				| 1 		| 1 		  | 2 		|  2 			| 3 					  |
# 				| 2 		| 1 		  | 3 		|  3 		   | 5 					  |
# 				| 3 		| 2 		  | 5 		|  5 			| 8 					  |
# 				| 5 		| 3 		  | 8  		|  8 			| 13 					  |
# 				| 8 		| 5 		  | 0 		|  13 		| 8 					  |
# 				+--------+----------+---------+-----------+-------------------+
#
# 			One way to generate the initial set of Fibonacci numbers is to use a recursive
# 			common table expression.
#
# 			For an example, see FIBONACCI SERIES GENERATION
#
# 		) LAST_VALUE(expr) [null_treatment] over_clause
#
# 			Returns the value of expr from the last row of the window frame
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			For an example, see the FIRST_VALUE() function description
#
# 		) LEAD(expr [, N[, default]]) [null_treatment] over_clause
#
# 			Returns the value of expr from the row that leads (follows) the current row
# 			by N rows within its partition.
#
# 			If there is no such row, the return value is default.
#
# 			For example, if N is 3, the return value is default for the last two rows.
#
# 			If N or default are missing, the defaults are 1 and NULL, respectively.
#
# 			N must be a literal nonnegative integer. If N is 0, expr is evaluated for the
# 			current row.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in this section intro
#
# 			For an example, see the LAG() function description
#
# 		) NTH_VALUE(expr, N) [from_first_last] [null_treatment] over_clause
#
# 			Returns the value of expr from the N-th row of the window frame.
# 			If there is no such row, the return value is NULL.
#
# 			N must be a literal positive integer.
#
# 			from_first_last is part of the SQL standard, but the MySQL implementation
# 			permits only FROM FIRST(which is also the default)
#
# 			This means that calculations begin at the first row of the window.
#
# 			FROM LAST is parsed, but produces an error. To obtain the same effect as
# 			FROM LAST (begin calculations at the last row of the window), use 
# 			ORDER BY to sort in reverse order.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			For an example, see the FIRST_VALUE() function description
#
# 		) NTILE(N) over_clause
#
# 			Divides a partition into N groups (buckets), assigns each row in the partition
# 			its bucket number, and returns the bucket number of the current row within its partition.
#
# 			For example, if N is 4, NTILE() divides rows into four buckets.
#
# 			If N is 100, NTILE() divides rows into 100 buckets.
#
# 			N must be a literal positive integer. Bucket number return values range from 1 to N.
#
# 			This function should be used with ORDER BY to sort partition rows into the
# 			desired order.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows, for the set of values in the val column,, the percentile values
# 			resulting from dividing the rows into two or four groups.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() 	OVER w AS 'row_number',
# 					NTILE(2) 		OVER w AS 'ntile2',
# 					NTILE(4) 		OVER w AS 'ntile4'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+---------+---------------+----------------+------------+
# 				| val 	 | row_number 	  | ntile2 			 | ntile4 	  |
# 				+---------+---------------+----------------+------------+
# 				| 1 		 | 1 				  | 1 				 | 1 			  |
# 				| 1 		 | 2 				  | 1 				 | 1 			  |
# 				| 2 		 | 3 				  | 1 				 | 1 			  |
# 				| 3 		 | 4 				  | 1 				 | 2 			  |
# 				| 3 		 | 5 				  | 1 				 | 2 			  |
# 				| 3 		 | 6 				  | 2 				 | 3 			  |
# 				| 4 		 | 7 				  | 2 				 | 3 			  |
# 				| 4 		 | 8 				  | 2 				 | 4 			  |
# 				| 5 		 | 9 				  | 2 				 | 4 			  |
# 				+---------+---------------+-----------------+-----------+
#
# 		) PERCENT_RANK() over_clause
#
# 			Returns the percentage of partition values less than the value in the current row,
# 			excluding the highest value.
#
# 			Return values range from 0 to 1 and represent the row relative rank, calculated
# 			as the result of this formula, where rank is the row rank and rows is the number
# 			of partition rows:
#
# 				(rank - 1) / (rows - 1)
#
# 			This function should be used with ORDER BY to sort partition rows into the desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			For an example, see the CUME_DIST() function description.
#
# 		) RANK() over_clause
#
# 			Returns the rank of the current row within its partition, with gaps.
#
# 			Peers are considered ties and receive the same rank.
#
# 			This function does not assign consecutive ranks to peer groups if groups
# 			of size greater than one exist; the result is noncontiguous rank numbers.
#
# 			This function should be used with ORDER BY to sort partition rows into the
# 			desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows the difference between RANK(), which produces ranks with gaps,
# 			and DENSE_RANK(), which produces ranks without gaps.
#
# 			The query shows rank values for each member of a set of values in the val column,
# 			which contains some duplicates.
#
# 			RANK() assigns peers (the duplicates) the same rank value, and the next greater value
# 			has a rank higher by the number of peers minus one.
#
# 			DENSE_RANK() also assigns peers the same rank value, but the next higher value
# 			has a rank one greater.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() OVER w AS 'row_number',
# 					RANK() 		 OVER w AS 'rank',
# 					DENSE_RANK() OVER w AS 'dense_rank'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+--------+--------------------+----------+---------------+
# 				| val 	| row_number 			| rank 	  | dense_rank 	|
# 				+--------+--------------------+----------+---------------+
# 				| 1 		| 1 						| 1 		  | 1 				|
# 				| 1 		| 2 						| 1 		  | 1 				|
# 				| 2 		| 3 						| 3 		  | 2 				|
# 				| 3 	   | 4 						| 4 		  | 3 				|
# 				| 3 		| 5 						| 4 		  | 3 				|
# 				| 3 		| 6 						| 4 		  | 3 				|
# 				| 4 		| 7 						| 7 		  | 4 				|
# 				| 4 		| 8 					   | 7 		  | 4 				|
# 				| 5 		| 9 						| 9 		  | 5 				|
# 				+--------+--------------------+----------+---------------+
#
# 		) ROW_NUMBER() over_clause
#
# 			Returns the number of the current row within its partition.
#
# 			Rows numbers range from 1 to the number of partition rows.
#
# 			ORDER BY affects the order in which rows are numbered.
#
# 			Without ORDER BY, row numbering is nondeterministic.
#
# 			ROW_NUMBER() assigns peers different row numbers. 
#
# 			To assign peers the same value, use RANK() or DENSE_RANK()
#
# 			For an example, see the RANK() function description
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 12.21.2 WINDOW FUNCTION CONCEPTS AND SYNTAX
#
# This section describes how to use window functions.
#
# Examples use the same sales information data set as found in the discussion
# of the GROUPING() function in SECTION 12.20.2, "GROUP BY MODIFIERS"
#
# 		SELECT * FROM sales ORDER BY country, year, product;
# 		+----------+-------------+-------------------+-----------+
# 		| year 	  | country 	 | product 			   | profit 	|
# 		+----------+-------------+-------------------+-----------+
# 		| 2000 	  | Finland 	 | Computer 			| 1500 		|
# 		| 2000 	  | Finland 	 | Phone 				| 100 		|
# 		| 2001 	  | Finland 	 | Phone 				| 10 			|
# 		| 2000 	  | India 		 | Calculator 			| 75 			|
# 		| 2000 	  | India 		 | Calculator 			| 75 		   |
# 		| 2000 	  | India 		 | Computer 			| 1200 		|
# 		| 2000 	  | USA 			 | Calculator 			| 75 		   |
# 		| 2000 	  | USA 			 | Computer 			| 1500 		|
# 		| 2001 	  | USA 			 | Calculator 			| 50 			|
# 		| 2001 	  | USA 			 | Computer 			| 1500 		|
# 		| 2001 	  | USA 			 | Computer 			| 1200 		|
# 		| 2001 	  | USA 			 | TV 					| 150 		|
# 		| 2001 	  | USA 			 | TV 					| 100 		|
# 		+----------+-------------+-------------------+-----------+
#
# A window function performs an aggregate-like operation on a set of query rows.
#
# However, whereas an aggregate operation groups query rows into a single
# result row, a window function produces a result for each query row:
#
# 		) The row for which function evaluation occurs is called the current row
#
# 		) The query rows related to the current row over which function evaluation occurs
# 			comprise the window for the current row.
#
# For example, using the sales information table, these two queries perform aggregate
# operations that produce a single global sum for all rows taken as a group, and sums
# grouped per country:
#
# 		SELECT SUM(profit) AS total_profit
# 		FROM sales;
# 		+---------------------------+
# 		| total_profit 				 |
# 		+---------------------------+
# 		| 	7535 							 |
# 		+---------------------------+
#
# 		SELECT country, SUM(profit) AS country_profit
# 		FROM sales
# 		GROUP BY country
# 		ORDER BY country;
# 		+------------+----------------+
# 		| country 	 | country_profit |
# 		+------------+----------------+
# 		| Finland 	 | 		1610 	   |
# 		| India 		 | 		1350 	   |
# 		| USA 		 | 		4575 		|
# 		+------------+----------------+
#
# By contrast, window operations do not collapse groups of query rows to a single
# output row.
#
# Instead, they produce a result for each row.
#
# Like the preceding queries, the following query uses SUM(), but this time
# as a window function:
#
# 		SELECT
# 			year, country, product, profit,
# 			SUM(profit) OVER() AS total_profit,
# 			SUM(profit) OVER(PARTITION BY country) AS country_profit
# 		FROM sales
# 		ORDER BY country, year, product, profit;
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
# 		| year 	  | country 		| product 			 | profit 	 | total_profit 		  | country_profit 	 |
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
# 		| 2000 	  | Finland 		| Computer 			 | 1500 		 | 7535 					  | 	1610 				 |
# 		| 2000 	  | Finland 		| Phone 				 | 100 		 | 7535 					  | 	1610 				 |
# 		| 2001 	  | Finland 		| Phone 				 | 10 		 | 7535 					  | 	1610 				 |
# 		| 2000 	  | India 			| Calculator 		 | 75 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | India 			| Calculator 		 | 75 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | India 			| Computer 			 | 1200 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | USA 				| Calculator 		 | 75 		 | 7535 					  | 	4575 				 |
# 		| 2000 	  | USA 				| Computer 			 | 1500 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| Calculator 		 | 50 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 			   | Computer 			 | 1200 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| Computer 			 | 1500 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| TV 					 | 100 		 | 7535 					  | 	4575 				 |
#		| 2001 	  | USA 				| TV 					 | 150 		 | 7535 					  | 	4575 				 |
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
#
# Each window operation in the query is signified by inclusion of an OVER clause that specifies
# how to partition query rows into groups for processing by the window function:
#
# 		) The first OVER clause is empty, which treats the entire set of query rows as a single partition.
#
# 			The window function thus produces a global sum, but does so for each row
#
# 		) The second OVER clause partitions rows by country, producing a sum per partition (per country)
#
# 			The function produces this sum for each partition row.
#
# Window functions are permitted only in the select list and ORDER BY clause.
#
# Query result rows are determined from the FROM clause, after WHERE, GROUP BY, and 
# HAVING processing, and windowing execution occurs before ORDER BY, LIMIT and SELECT DISTINCT.
#
# The OVER clause is permitted for many aggregate functions, which therefore can be used
# as window or nonwindow functions, depending on whether the OVER clause is present or absent:
#
# 		AVG()
# 		BIT_AND()
# 		BIT_OR()
#
# 		BIT_XOR()
# 		COUNT()
# 		JSON_ARRAYAGG()
# 			
#		JSON_OBJECTAGG()
# 		MAX()
# 		MIN()
#
# 		STDDEV_POP(), STDDEV(), STD()
# 		STDDEV_SAMP()
# 		SUM()
#
# 		VAR_POP(), VARIANCE()
# 		VAR_SAMP()
#
# For details about each aggregate function, see SECTION 12.20.1, "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# MySQL also supports nonaggregate functions that are used only as window functions.
#
# For these, the OVER clause is mandatory:
#
# 		CUME_DIST()
#
# 		DENSE_RANK()
#
# 		FIRST_VALUE()
#
# 		LAG()
#
# 		LAST_VALUE()
#
# 		LEAD()
#
# 		NTH_VALUE()
#
# 		NTILE()
#
# 		PERCENT_RANK()
#
# 		RANK()
#
# 		ROW_NUMBER()
#
# For details about each nonaggregate function, see SECTION 12.21.1, "WINDOW FUNCTION DESCRIPTIONS"
#
# As an example of one of those nonaggregate window functions, this query uses ROW_NUMBER(),
# which produces the row number of each row within its partition.
#
# In this case, rows are numbered per country.
#
# By default, partition rows are unordered and row numbering is nondeterministic.
#
# To sort partition rows, include an ORDER BY clause within the window definition.
#
# The query uses unordered and ordered partitions (the row_num1 and row_num2 columns)
# to illustrate the difference between omitting and including ORDER BY:
#
# 		SELECT
# 			year, country, product, profit,
# 			ROW_NUMBER() OVER(PARTITION BY country) AS row_num1,
# 			ROW_NUMBER() OVER(PARTITION BY country ORDER BY year, product) AS row_num2
# 		FROM sales;
#
# +--------+------------------+------------------+---------------+----------------+--------------+
# | year   | country 			| product 			 | profit 		  | row_num1 		 | row_num2 	 |
# +--------+------------------+------------------+---------------+----------------+--------------+
# | 2000   | Finland 			| Computer 			 | 1500 			  | 2 				 | 	1 			 |
# | 2000   | Finland 			| Phone 				 | 100 			  | 1 				 | 	2 			 |
# | 2001   | Finland 			| Phone 				 | 10 			  | 3 				 | 	3 			 |
# | 2000   | India 				| Calculator 		 | 75 			  | 2 				 | 	1 			 |
# | 2000   | India 				| Calculator 		 | 75 			  | 3 				 | 	2 			 |
# | 2000   | India 				| Computer 			 | 1200 			  | 1 				 | 	3 			 |
# | 2000   | USA 					| Calculator 		 | 75 			  | 5 				 | 	1 		    |
# | 2000   | USA 					| Computer 			 | 1500 			  | 4 				 | 	2 			 |
# | 2001   | USA 					| Calculator 		 | 50 			  | 2 				 | 	3 			 |
# | 2001   | USA 					| Computer 			 | 1500 			  | 3 				 | 	4 			 |
# | 2001   | USA 					| Computer 			 | 1200 			  | 7 				 | 	5 			 |
# | 2001   | USA 					| TV 					 | 150 			  | 1 				 | 	6 			 |
# | 2001   | USA 					| TV 					 | 100 			  | 6 				 | 	7 			 |
# +--------+------------------+------------------+---------------+----------------+--------------+
#
# As mentioned previously, to use a window function (or treat an aggregate function as a window function),
# include an OVER clause following the function call.
#
# The OVER clause has two forms:
#
# 		over_clause:
# 			{OVER (window_spec) | OVER window_name}
#
# Both forms define how the window functions should process query rows.
#
# They differ in whether the window is defined directly in the OVER clause, or
# supplied by a reference to a named window defined elsewhere in the query:
#
# 		) In the first case, the window specification appears directly in the OVER clause, between the parentheses
#
# 		) In the second case, window_name is the name for a window specification defined by a WINDOW clause elsewhere
# 			in the query.
#
# 			For details, see SECTION 12.21.4, "NAMED WINDOWS"
#
# For OVER (window_spec) syntax, the window specification has several parts, all optional:
#
# 		window_spec:
# 			[window_name] [partition_clause] [order_clause] [frame_clause]
#
# If OVER() is empty, the window consists of all query rows and the window function computes
# a result using all rows.
#
# Otherwise, the clauses present within the parentheses determine which query rows are used
# to compute the function result and how they are partitioned and ordered:
#
# 		) window_name: The name of a window defined by a WINDOW clause elsewhere in the query.
#
# 			If window_name appears by itself within the OVER clause, it completely defines
# 			the window.
#
# 			If partitioning, ordering, or framing clauses are also given, they modify interpretation
# 			of the named window.
#
# 			For details, SEE SECTION 12.21.4, "NAMED WINDOWS"
#
# 		) partition_clause: A PARTITION BY clause indicates how to divide the query rows into groups.
#
# 			The window function result for a given row is based on the rows of the partition
# 			that contains the row.
#
# 			If PARTITION BY is omitted, there is a single partition consisting of all query rows.
#
# 			NOTE:
#
# 				Partitioning for window functions differs from table partitioning. For more information about
# 				table partitioning, see CHAPTER 23, PARTITIONING
#
# 			partition_clause has this syntax:
#
# 				partition_clause:
# 					PARTITION BY expr [, expr] ---
#
# 			Standard SQL requires PARTITION BY to be followed by column names only.
#
# 			A MySQL extension is to permit expressions, not just column names.
#
# 			For example, if a table contains a TIMESTAMP column named ts, standard SQL
# 			permits PARTITION BY ts but not PARTITION BY HOUR(ts), whereas MySQL permits both.
#
# 		) order_clause: An ORDER BY clause indicates how to sort rows in each partition.
#
# 			Partition rows that are equal according to the ORDER BY clause are considered peers.
#
# 			If ORDER BY is omitted, partition rows are unordered, with no procesing order implied,
# 			and all partition rows are peers.
#
# 			order_clause has this syntax:
#
# 				order_clause:
# 					ORDER BY expr [ASC|DESC] [, expr [ASC|DESC]] ---
#
# 			Each ORDER BY expression optionally can be followed by ASC or DESC to indicate sort direction.
#
# 			The default is ASC if no direction is specified, NULL values sort first for
# 			ascending sorts, last for descending sorts.
#
# 			An ORDER BY in a window definition applies within individual partitions.
#
# 			To sort the result set as a whole, include an ORDER BY at the query top level.
#
# 		) frame_clause: A frame is a subset of the current partition and the frame clause specifies
# 			how to define the subset.
#
# 			The frame clause has many subclasses of its own.
#
# 			For details, see SECTION 12.21.3, "WINDOW FUNCTION FRAME SPECIFICATION"
#
# 12.21.3 WINDOW FUNCTION FRAME SPECIFICATION
#
# The definition of a window used with a window function can include a frame clause.
#
# A frame is a subset of the current partition and the frame clause specifies
# how to define the subset.
#
# Frames are determined with respect to the current row, which enables a frame to
# move within a partition depending on the location of the current row within its
# partition.
#
# Examples:
#
# 		) By defining a frame to be all rows from the partition start to the current row,
# 			you can compute running totals for each row
#
# 		) By defining a frame as extending N rows on either side of the current row,
# 			you can compute rolling averages.
#
# The following query demonstrates the use of moving frames to compute running totals
# within each group of time-ordered level values, as well as rolling averages computed
# from the current row and the rows that immediately precede and follow it:
#
# 		SELECT
# 			time, subject, val,
# 			SUM(val) OVER (PARTITION BY subject ORDER BY time
# 								ROWS UNBOUNDED PRECEDING)
# 			AS running_total,
# 			AVG(val) OVER (PARTITION BY subject ORDER BY time
# 								ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)
# 				AS running_average
# 			FROM observations;
# 		+------------------+---------------+-------------+-------------------+-------------------+
# 		| time 				 | subject 		  | val 			 | running_total 		| running_average   |
# 		+------------------+---------------+-------------+-------------------+-------------------+
# 		| 07:00:00 			 | st113 		  | 10 			 | 		10 			| 9.5000 			  |
# 		| 07:15:00 			 | st113 		  | 9 			 | 		19 			| 14.6667 			  |
# 		| 07:30:00 			 | st113 		  | 25 			 | 		44 		   | 18.0000 			  |
# 		| 07:45:00 			 | st113 		  | 20 			 | 		64 			| 22.5000 			  |
# 		| 07:00:00 			 | xh458 		  | 0 			 | 		0 				| 5.0000 			  |
# 		| 07:15:00 			 | xh458 		  | 10 			 | 		10 			| 5.0000 			  |
# 		| 07:30:00 			 | xh458 		  | 5 			 | 		15 			| 15.0000 			  |
# 		| 07:45:00 			 | xh458 		  | 30 			 | 		45 			| 20.0000 			  |
# 		| 08:00:00 			 | xh458 		  | 25 			 | 		70 			| 27.5000 			  |
# 		+------------------+---------------+-------------+-------------------+-------------------+
#
# For the running_average column, there is no frame row preceding the first one or following the last.
#
# In these cases, AVG() computes the average of the rows that are available.
#
# Aggregate functions used as window functions operate on rows in the current row frame,
# as do these nonaggregate window functions:
#
# 		FIRST_VALUE()
# 		LAST_VALUE()
# 		NTH_VALUE()
#
# Standard SQL specifies that window functions that operate on the entire partition should
# have no frame clause.
#
# MySQL permits a frame clause for such functions but ignores it.
#
# These functions use the entire partition even if a frame is specified:
#
# 		CUME_DIST()
# 
# 		DENSE_RANK()
#
# 		LAG()
#
# 		LEAD()
#
# 		NTILE()
#
# 		PERCENT_RANK()
#
# 		RANK()
#
# 		ROW_NUMBER()
#
# The frame clause,, if given, has this syntax:
#
# 		frame_clause:
# 			frame_units frame_extent
#
# 		frame_units:
# 			{ROWS | RANGE}
#
# In the absence of a frame clause, the default frame depends on whether
# an ORDER BY clause is present, as described later in this section.
#
# The frame_units value indicates the type of relationship between the
# current row and frame rows:
#
# 		) ROWS: The frame is defined by beginning and ending row positions.
#
# 			Offsets are differences in row numbers from the current row number.
#
# 		) RANGE: The frame is defined by rows within a value range.
#
# 			Offsets are differences in row values from the current row value.
#
# The frame_extent value indicates the start and end points of the frame.
#
# You can specify just the start of hte frame (in which case the current row is implicitly the end)
# or use BETWEEN to specify both frame endpoints:
#
# 		frame_extent:
# 			{frame_start | frame_between}
#
# 		frame_between:
# 			BETWEEN frame_start AND frame_end
#
# 		frame_start, frame_end: {
# 			CURRENT ROW
# 		 | UNBOUNDED PRECEDING
# 		 | UNBOUNDED FOLLOWING
# 		 | expr PRECEDING
# 		 | expr FOLLOWING
# 		}
#
# With BETWEEN syntax, frame_start must not occur later than frame_end
#
# The permitted frame_start and frame_end values have these meanings:
#
# 		) CURRENT ROW: For ROWS, the bound is the current row. For RANGE, the bounds is the peers of the current row.
#
# 		) UNBOUNDED PRECEDING: The bound is the first partition row
#
# 		) UNBOUNDED FOLLOWING: The bound is the last partition row
#
# 		) expr PRECEDING: For ROWS, the bound is expr rows before the current row.
#
# 			For RANGE, the bound is the rows with values equal to the current row value
# 			minus expr; if the current row value is NULL, the bound is the peers of the row.
#
# 			For expr PRECEDING (and expr FOLLOWING) expr can be a ? parameter marker
# 			(for use in a prepared statement), a nonnegative numeric literal, or a temporal
# 			interval of the form INTERVAL val unit.
#
# 			For INTERVAL expressions, val specifies nonnegative interval value,
# 			and unit is a keyword indicating the units in which the value should be interpreted.
#
# 			(For details about the permitted units specifiers, see the description of the DATE_ADD()
# 			function in SECTION 12.7, "DATE AND TIME FUNCTIONS")
#
# 			RANGE on a numeric or temporal expr requires ORDER BY on a numeric or temporal expression,
# 			respectively.
#
# 			Examples of valid expr PRECEDING and expr FOLLOWING indicators:
#
# 				10 PRECEDING
# 				INTERVAL 5 DAY PRECEDING
# 				5 FOLLOWING
# 				INTERVAL '2:30' MINUTE_SECOND FOLLOWING
#
# 		) expr FOLLOWING: For ROWS, the bound is expr rows after the current row.
#
# 			For RANGE, the bound is the rows with values equal to the current row
# 			value plus expr; if the current row value is NULL, the bound is the
# 			peers of hte row.
#
# 			For permitted values of expr, see the description of expr PRECEDING
#
# The following query demonstrates FIRST_VALUE(), LAST_VALUE() and two instaces of NTH_VALUE():
#
# 		SELECT
# 			time, subject, val,
# 			FIRST_VALUE(val) 		OVER w AS 'first',
# 			LAST_VALUE(val) 		OVER w AS 'last',
# 			NTH_VALUE(val, 2) 	OVER w AS 'second',
# 			NTH_VALUE(val, 4) 	OVER w AS 'fourth'
# 		FROM observations
# 		WINDOW w AS (PARTITION BY subject ORDER BY time
# 						ROWS UNBOUNDED PRECEDING);
#
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
# 		| time 			| subject 	 | val 	  | first 	 | last 	    | second 		| fourth |
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
# 		| 07:00:00 		| st113 		 | 10 	  | 10 		 | 10 		 | NULL 		   | NULL 	|
# 		| 07:15:00     | st113 		 | 9 		  | 10 		 | 9 			 | 9 				| NULL   |
# 		| 07:30:00     | st113 		 | 25 	  | 10 		 | 25 		 | 9 				| NULL   |
# 		| 07:45:00 		| st113 		 | 20 	  | 10 		 | 20 		 | 9 				| 20 		|
# 		| 07:00:00  	| xh458 		 | 0 		  | 0 		 | 0 			 | NULL 		   | NULL 	|
# 		| 07:15:00     | xh458 		 | 10 	  | 0 		 | 10 		 | 10 			| NULL 	|
# 		| 07:30:00 		| xh458 		 | 5 		  | 0 		 | 5 			 | 10 			| NULL 	|
# 		| 07:45:00 	   | xh458 		 | 30 	  | 0 		 | 30 		 | 10 			| 30 		|
# 		| 08:00:00 		| xh458 		 | 25 	  | 0 		 | 25 		 | 10 			| 30 	   |
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
#
# Each function uses the rows in the current frame, which, per the window definition shown,
# extends from the first partition row to the current row.
#
# For the NTH_VALUE() calls, the current frame does not always include the requested row;
# in such cases, the return value is NULL
#
# In the absence of a frame clause, the default frame depends on whether an ORDER BY clause
# is present:
#
# 		) With ORDER BY: 
#
# 			The default frame includes rows from the partition start through
# 			the current row, including all peers of the current row (rows equal to the current
# 			row according to the ORDER BY clause)
#			
# 			The default is equivalent to this frame specification:
#
# 				RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
#
# 		) Without ORDER BY:
#
# 			The default frame includes all partition rows (because, without ORDER BY, all partition
# 			rows are peers)
#
# 			The default is equivalent to this frame specification:
#
# 				RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
#
# Because the default frame differs depending on presence or absence of ORDER BY,
# adding ORDER BY to a query to get deterministic results may change the results.
#
# (For example, the values produced by SUM() might change)
#
# TO obtain the same results but ordered per ORDER BY, provide an explicit
# frame specification to be used regardless of whether ORDER BY is present.
#
# The meaning of a frame specification can be nonobvious when the current
# row value is NULL.
#
# Assuming that to be the case, these examples illustrate how various frame
# specifications apply:
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 FOLLOWING AND 15 FOLLOWING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 FOLLOWING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at the end of the partition.
#
# 			Because an ASC sort puts NULL values first, the frame is the entire partition.
#
# 		) ORDER BY X DESC RANGE BETWEEN 10 FOLLOWING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at the end of the partition.
#
# 			Because a DESC sort puts NULL values last, the frame is only the NULL values.
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at teh end of the partition.
#
# 			Because an ASC sort puts NULL values first, the frame is the entire partition.
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND 10 FOLLOWING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND 1 PRECEDING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN UNBOUNDED PRECEDING AND 10 FOLLOWING
#
# 			The frame starts at the beginning of the partition and stops at rows with value NULL.
#
# 			Because n ASC sort puts NULL values first, the frame is only the NULL values
#
# 12.21.4 NAMED WINDOWS
#
# Windows can be defined and given names by which to refer to them in OVER clauses.
#
# To do this, use a WINDOW clause.
#
# If present in a query, the WINDOW clause falls between the positions of the
# HAVING and ORDER BY clauses, and has this syntax:
#
# 		WINDOW window_name AS (window_spec)
# 			[, window_name AS (window_spec)] ---
#
# For each window definition, window_name is the window name, and window_spec is the
# same type of window specification as given between the parentheses of an OVER
# clause, as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		window_spec:
# 			[window_name] [partition_clause] [order_clause] [frame_clause]
#
# A WINDOW clause is useful for queries in which multiple OVER clauses would otherwise
# define the same window.
#
# Instead, you can define the window once, give it a name, and refer to the name
# in teh OVER clauses.
#
# Consider this query, which defines the same window multiple times:
#
# 		SELECT
# 			val,
# 			ROW_NUMBER() OVER (ORDER BY val) AS 'row_number',
# 			RANK() 		 OVER (ORDER BY val) AS 'rank',
# 			DENSE_RANK() OVER (ORDER BY val) AS 'dense_rank'
# 		FROM numbers;
#
# The query can be written more simply by using WINDOW to define the window once and referring
# to the window by name in the OVER clauses:
#
# 		SELECT
# 			val,
# 			ROW_NUMBER() OVER w AS 'row_number',
# 			RANK() 		 OVER w AS 'rank',
# 			DENSE_RANK() OVER w AS 'dense_rank'
# 		FROM numbers
# 		WINDOW w AS (ORDER BY val);
#
# A named window also makes it easier to experiment with the window definition
# to see the effect on query results.
#
# YOu need only modify the window definition in the WINDOW clause, rather than
# multiple OVER clause definitions.
#
# If an OVER clause uses OVER (window_name ---) rather than OVER window_name,
# the named window can be modified by the addition of other clauses.
#
# For example, this query defines a window that includes partitioning, and uses
# ORDER BY in the OVER clauses to modify the window in different ways:
#
# 		SELECT
# 			DISTINCT year, country,
# 			FIRST_VALUE(year) OVER (w ORDER BY year ASC) AS first,
# 			FIRST_VALUE(year) OVER (w ORDER BY year DESC) AS last
# 		FROM sales
# 		WINDOW w AS (PARTITION BY country);
#
# An OVER clause cna only add properties to a named window, not modify them.
#
# If the named window definition includes a partitioning, ordering or framing
# property, the OVER clause that refers to the window name cannot also include
# the same kind of property or an error occurs:
#
# 		) This construct is permitted because the window definition and the referring
# 			OVER clause do not contain the same kind of properties:
#
# 			OVER (w ORDER BY country)
# 			--- WINDOW w AS (PARTITION BY country)
#
# 		) This construct is not permitted because the OVER clause specifies PARTITION BY 
# 			for a named window that already has PARTITION BY:
#
# 			OVER (w PARTITION BY year)
# 			--- WINDOW w AS (PARTITION BY country)
#
# The definition of a named window can itself begin with a window_name.
#
# In such cases, forward and backward references are permitted, but not cycles:
#
# 		) This is permitted; it contains forward and backward references but no cycles:
#
# 			WINDOW w1 AS (w2), w2 AS (), w3 AS (w1)
#
# 		) This is not permitted because it contains a cycle:
#
# 			WINDOW w1 AS (w2), w2 AS (w3), w3 AS (w1)
#
# 12.21.5 WINDOW FUNCTION RESTRICTIONS
#
# The SQL standard imposes a constraint on window functions that they cannot
# be used in UPDATE or DELETE statements to update rows.
#
# Using such functions in a subquery of these statements (to select rows)
# is permitted.
#
# MySQL does not support these window function features:
#
# 		) DISTINCT syntax for aggregate window functions
#
# 		) Nested window functions
#
# 		) Dynamic frame endpoints that depend on the value of the current row
#
# THe parser recognizes these window constructs which nevertheless are not
# supported:
#
# 		) The GROUPS frame units specifier is parsed, but produces an error.
#
# 			Only ROWS and RANGE are supported.
#
# 		) The EXCLUDE clause for frame specification is parsed, but produces an error.
#
# 		) IGNORE NULLS is parsed, but produces an error. Only RESPECT NULLS
# 			is supported.
#
# 		) FROM LAST is parsed, but produces an error. Only FROM FIRST is supported.
#
# 12.22 INTERNAL FUNCTIONS
#
# TABLE 12.28 INTERNAL FUNCTIONS
#
# NAME 								Desc
#
# CAN_ACCESS_COLUMN() 			Internal use only
#
# CAN_ACCESS_DATABASE() 		Internal
#
# CAN_ACCESS_TABLE() 			Internal
#
# CAN_ACCESS_VIEW() 				Internal
#
# GET_DD_COLUMN_PRIVILEGES() 	Internal
#
# GET_DD_CREATE_OPTIONS() 		Internal
#
# GET_DD_INDEX_SUB_PART_LENGTH() Internal
#
# INTERNAL_AUTO_INCREMENT() 	Internal
#
# INTERNAL_AVG_ROW_LENGTH() 	Internal
#
# INTERNAL_CHECK_TIME() 		Internal
#
# INTERNAL_CHECKSUM() 			Internal
#
# INTERNAL_DATA_FREE() 			Internal
#
# INTERNAL_DATA_LENGTH() 		Internal
#
# INTERNAL_DD_CHAR_LENGTH() 	Internal
#
# INTERNAL_GET_COMMENT_OR_ERROR() Internal
#
# INTERNAL_GET_VIEW_WARNING_OR_ERROR() Internal
#
# INTERNAL_INDEX_COLUMN_CARDINALITY() Internal
#
# INTERNAL_INDEX_LENGTH() 		Internal
#
# INTERNAL_KEYS_DISABLED() 	INternal
#
# INTERNAL_MAX_DATA_LENGTH() 	Internal
#
# INTERNAL_TABLE_ROWS() 		internal
#
# INTERNAL_UPDATE_TIME() 		internal
#
# The functions listed in this section are intended only for internal use by teh server.
#
# Attempts by users to invoke them, results in an error.
#
# 		) CAN_ACCESS_COLUMN(ARGS)
#
# 		) CAN_ACCESS_DATABASE(ARGS)
#
# 		) CAN_ACCESS_TABLE(ARGS)
#
# 		) CAN_ACCESS_VIEW(ARGS)
#
# 		) GET_DD_COLUMN_PRIVILEGES(ARGS)
#
# 		) GET_DD_CREATE_OPTIONS(ARGS)
#
# 		) GET_DD_INDEX_SUB_PART_LENGTH(ARGS)
#
# 		) INTERNAL_AUTO_INCREMENT(ARGS)
#
# 		) INTERNAL_AVG_ROW_LENGTH(ARGS)
#
# 		) INTERNAL_CHECK_TIME(ARGS)
#
# 		) INTERNAL_CHECKSUM(ARGS)
#
# 		) INTERNAL_DATA_FREE(ARGS)
#
# 		) INTERNAL_DATA_LENGTH(ARGS)
#
# 		) INTERNAL_DD_CHAR_LENGTH(ARGS)
#
# 		) INTERNAL_GET_COMMENT_OR_ERROR(ARGS)
#
# 		) INTERNAL_GET_VIEW_WARNING_OR_ERROR(ARGS)
#
# 		) INTERNAL_INDEX_COLUMN_CARDINALITY(ARGS)
#
# 		) INTERNAL_INDEX_LENGTH(ARGS)
#
# 		) INTERNAL_KEYS_DISABLED(ARGS)
#
# 		) INTERNAL_MAX_DATA_LENGTH(ARGS)
#
# 		) INTERNAL_TABLE_ROWS(ARGS)
#
# 		) INTERNAL_UPDATE_TIME(ARGS)
#
# 		) IS_VISIBLE_DD_OBJECT(ARGS)
#
# 12.23 MISCELLANEOUS FUNCTIONS
#
# TABLE 12.29 MISCELLANEOUS FUNCTIONS
#
# 		NAME 									DESCRIPTION
# ANY_VALUE() 			Suppress ONLY_FULL_GROUP_BY value rejection
#
# BIN_TO_UUID() 		Convert binary UUID to string
#
# DEFAULT() 			Return the default value for a table column
#
# GROUPING() 			Distinguish super-aggregate ROLLUP rows from regular rows
#
# INET_ATON() 			Return the numeric value of an IP address
#
# INET_NTOA() 			Return the IP address from a numeric value
#
# INET6_ATON() 		Return the numeric value of an IPv6 address
#
# INET6_NTOA() 		Return the IPv6 address from a numeric value
#
# IS_IPV4() 			Whether argument is an IPv4 address
#
# IS_IPV4_COMPAT() 	Whether argument is an IPv4-compatible address
#
# IS_IPV4_MAPPED() 	Whether argument is an IPV4-mapped address
#
# IS_IPV6() 			Whether argument is an IPv6 address
#
# IS_UUID() 			Whether argument is a valid UUID
#
# MASTER_POS_WAIT() 	Block until the slave has read and applied all updates up to teh specific position
#
# NAME_CONST() 		Cause the column to have the given name
#
# RAND() 				Return a random floating-point value
#
# SLEEP() 				Sleep for a number of seconds
#
# UUID() 				Returns a Universal Unique Identifier (UUID)
#
# UUID_SHORT() 		Return an integer-valued universal identifier
#
# UUID_TO_BIN() 		Convert string UUID to binary
#
# VALUES() 				Defines the values to be used during an INSERT
#
# 		) ANY_VALUE(arg)
#
# 			THis function is useful for GROUP BY queries when the ONLY_FULL_GROUP_BY SQL mode is enabled,
# 			for cases when MySQL rejects a query that you know is valid for reasons that MySQL
# 			cannot determine.
#
# 			The function return value  and type are the same as the return value and type of its argument,
# 			but the function result is not checked for the ONLY_FULL_GROUP_BY SQL mode.
#
# 			For example, if name is a nonindexed column, the following query fails with
# 			ONLY_FULL_GROUP_BY enabled:
#
# 				SELECT name, address, MAX(age) FROM t GROUP BY name;
# 				ERROR 1055 (42000): Expression #2 of SELECT list is not
# 				in GROUP BY clause and contains nonaggregated column
# 				'mydb.t.address' which is not functionally dependent
# 				on columns in GROUP BY clause; this is incompatible
# 				with sql_mode=only_full_group_by
#
# 			THe failure occurs because address is a nonaggregated column that is
# 			neither named among GROUP BY columns nor functionally dependent on them.
#
# 			As a result, the address value for rows within each name group is nondeterminsitic.
#
# 			There are multiple ways to cause MySQL to accept the query:
#
# 				) Alter the table to make name a primary key or a unique NOT NULL column.
#
# 					This enables MySQL to determine that address is functionally dependent
# 					on name;
#
# 					That is, address is uniquely determined by name. (This technique is inapplicable if NULL
# 					must be permitted as a valid name value)
#
# 				) Use ANY_VALUE() to refer to address:
#
# 					SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name;
#
# 					In this case, MySQL ignores teh nondeterminism of address values within
# 					each name group and accepts the query.
#
# 					This may be useful if you simply do not care which value of a nonaggregated
# 					column is chosen for each group.
#
# 					ANY_VALUE() is not an aggregate function, unlike functions such as SUM()
# 					or COUNT()
#
# 					It simply acts to suppress the test for nondeterminism
#
# 				) Disable ONLY_FULL_GROUP_BY.
#
# 					This is equivalent to using ANY_VALUE() with ONLY_FULL_GROUP_BY enabled,
# 					as described in previous time.
#
# 			ANY_VALUE() is also useful if funcitonal dependence exists between columns but
# 			MySQL cannot determine it.
#
# 			The following query is valid because age is functionally dependent
# 			on the grouping column age-1, but MySQL cannot tell that and rejects
# 			the query with ONLY_FULL_GROUP_BY enabled:
#
# 				SELECT age FROM t GROUP BY age-1;
#
# 			To cause MySQL to accept the query, use ANY_VALUE():
#
# 				SELECT ANY_VALUE(age) FROM t GROUP BY age-1;
#
# 			ANY_VALUE() can be used for queries that refer to aggregate functions
# 			in the absence of a GROUP BY clause:
#
# 				SELECT name, MAX(age) FROM t;
# 				ERROR 1140 (42000): In aggregated query without GROUP BY, expression
# 				#1 of SELECT list contains nonaggregated column 'mydb.t.name'; this
# 				is incompatible with sql_mode=only_full_group_by
#
# 			Without GROUP BY, there is a single group and it is nondeterminsitic which name value
# 			to choose for the group.
#
# 			ANY_VALUE() tells MySQL to accept the query:
#
# 				SELECT ANY_VALUE(name), MAX(age) FROM t;
#
# 			It may be that, due to some property of a given data set, you know that a selected
# 			nonaggregated column is effectively functionally dependent on a GROUP BY column.
#
# 			For example, an application may enforce uniqueness of one column with respect
# 			to another.
#
# 			In this case, using ANY_VALUE() for hte effectively functioanlly dependent
# 			column may make sense.
#
# 			For additional discussion, see SECTION 12.20.3, "MySQL HANDLING OF GROUP BY"
#
# 		) BIN_TO_UUID(binary uuid), BIN_TO_UUID(binary uuid, swap flag)
#
# 			BIN_TO_UUID() is the inverse of UUID_TO_BIN()
#
# 			It converts a binary UUID to a string UUID and returns the result.
#
# 			The binary value should be a UUID as a VARBINARY(16) value
#
# 			The return value is a utf8 string of five hexadecimal numbers separated
# 			by dashes.
#
# 			(For details about this format, see the UUID() function description)
#
# 			If the UUID argument is NULL, the return value is NULL.
#
# 			If any argument is invalid, an error occurs.
#
# 			BIN_TO_UUID() takes one orw two arguments:
#
# 				) The one-argument form takes a binary UUID value.
#
# 					the UUID value is assumed not to have its time-low and time-high
# 					parts swapped.
#
# 					The string result is in the same order as the binary argument.
#
# 				) The two argument form takes a binary UUID value and a swap-flag value:
#
# 					) If swap_flag is 0, the two-argument form is equivalent to the one-argument form.
#
# 						The string result is in the same order as the binary argument.
#
# 					) If swap_flag is 1, the UUID value is assumed to have its time-low and time-high parts
# 						swapped.
#
# 						These parts are swapped back to their original position in the result value.
#
# 				For usage examples and information about time-part swapping, see the UUID_TO_BIN() function description.
#
# 		) DEFAULT(col name)
#
# 			Returns the default value for a table column. An error results if the column has no default value.
#
# 			The use of DEFAULT(col name) to specify the default value for a named column is permitted
# 			only for columns that have a literal default value, not for columns that have an expression
# 			default value.
#
# 				UPDATE t SET i = DEFAULT(i)+1 WHERE id < 100;
#
# 		) FORMAT(X,D)
#
# 			Formats the number X to a format like '#,###,###.##', rounded to D decimal places,
# 			and returns the result as a string.
#
# 			For details, see SECTION 12.5, "STRING FUNCTIONS"
#
# 		) GROUPING(expr [, expr] ---)
#
# 			For GROUP BY queries that include a WITH ROLLUP modifier, the ROLLUP operation
# 			produces super-aggregate output rows where NULL represents the set of all values.
#
# 			The GROUPING() function enables you to distinguish NULL values for super-aggregate rows
# 			from NULL values in regular grouped rows.
#
# 			GROUPING() is permitted only in the select list or HAVING clause.
#
# 			Each argument to GROUPING() must be an expression that exactly matches an expression
# 			in the GROUP BY clause.
#
# 			The expression cannot be a positional specifier.
#
# 			For each expression, GROUPING() produces 1 if the expression value in the
# 			current row is a NULL representing a super-aggregate value.
#
# 			Otherwise, GROUPING() produces 0, indicating that the expression value
# 			is a NULL for a regular result row or is not NULL.
#
# 			Suppose that table t1 contains these rows, where NULL indicates something
# 			like "other" or "unknown"
#
# 				SELECT * FROM t1;
# 				+--------+------------+-----------------+
# 				| name   | size 		 | quantity 		 |
# 				+--------+------------+-----------------+
# 				| ball   | small 		 | 10 				 |
# 				| ball   | large 		 | 20 				 |
# 				| ball   | NULL 		 | 5 					 |
# 				| hoop   | small 		 | 15 				 |
# 				| hoop   | large 		 | 5 					 |
# 				| hoop   | NULL 		 | 3 					 |
# 				+--------+------------+-----------------+
#
# 			A summary of the table without WITH ROLLUP looks like this:
#
# 				SELECT name, size, SUM(quantity) AS quantity
# 				FROM t1
# 				GROUP BY name, size;
# 				+--------+---------+-----------+
# 				| name   | size 	 | quantity  |
# 				+--------+---------+-----------+
# 				| ball   | small   | 10 		 |
# 				| ball   | large   | 20 		 |
# 				| ball   | NULL    | 5 			 |
# 				| hoop   | small   | 15 		 |
# 				| hoop   | large   | 5 			 |
# 				| hoop   | NULL 	 | 3 			 |
# 				+--------+---------+-----------+
#
# 			The result contains NULL values, but those do not represent super-aggregate rows because the
# 			query does not include WITH ROLLUP.
#
# 			adding WITH ROLLUP produces super-aggregate summary rows containing additional NULL values.
#
# 			However, without comparing this result to the previous one, it is not easy to see
# 			which NULL values occur in super-aggregate rows and which occur in regular grouped rows:
#
# 				SELECT name, size, SUM(quantity) AS quantity
# 				FROM t1
# 				GROUP BY name, size WITH ROLLUP;
# 				+--------+--------+----------------+
# 				| name   | size 	| quantity 		  |
# 				+--------+--------+----------------+
# 				| ball   | NULL   | 	5 				  |
# 				| ball   | large  |  20 			  |
# 				| ball   | small  |  10 			  |
# 				| ball   | NULL   | 	35 			  |
# 				| hoop   | NULL 	| 	3 				  |
# 				| hoop   | large  |  5 				  |
# 				| hoop   | small  |  15 			  |
# 				| hoop   | NULL   | 	23 			  |
# 				| NULL   | NULL   | 	58 			  |
# 				+--------+--------+----------------+
#
# 			To distinguish NULL values in super-aggregate rows from those in regular grouped rows,
# 			use GROUPING(), which returns 1 only for super-aggregate NULL values:
#
# 				SELECT
# 					name, size, SUM(quantity) AS quantity,
# 					GROUPING(name) AS grp_name,
# 					GROUPING(size) AS grp_size
# 				FROM t1
# 				GROUP BY name, size WITH ROLLUP;
# 				+-------+--------+------------------+-----------------+--------------------+
# 				| name  | size   | quantity 			| grp_name 			| grp_size 				|
# 				+-------+--------+------------------+-----------------+--------------------+
# 				| ball  | NULL   | 		5 				| 			0 			| 		0 					|
# 				| ball  | large  | 		20 			| 			0 			| 		0 					|
# 				| ball  | small  | 		10 			| 			0 			| 		0 					|
# 				| ball  | NULL   | 		35 			| 			0 			| 		1 					|
# 				| hoop  | NULL   | 		3 				| 			0 			| 		0 					|
# 				| hoop  | large  | 		5 				| 			0 			| 		0 					|
# 				| hoop  | small  | 		15 			| 			0 			| 		0 					|
# 				| hoop  | NULL   | 		23 			| 			0 			| 		1 					|
# 				| NULL  | NULL   | 		58 			| 			1 			| 		1 					|
# 				+-------+--------+------------------+-----------------+--------------------+
#
# 			Common uses for GROUPING():
#
# 				) Substitute a label for super-aggregate NULL values:
#
# 					SELECT
# 						IF(GROUPING(name) = 1, 'All items', name) AS name,
# 						IF(GROUPING(size) = 1, 'All sizes', size) AS size,
# 						SUM(quantity) AS quantity
# 					FROM t1
# 					GROUP BY name, size WITH ROLLUP;
# 					+-----------------+-------------------+---------------+
# 					| name 				| size 				  | quantity 		|
# 					+-----------------+-------------------+---------------+
# 					| ball 				| NULL 				  | 5 				|
# 					| ball 				| large 				  | 20 				|
# 					| ball 				| small 				  | 10 			   |
# 					| ball 				| All sizes 		  | 35 				|
# 					| hoop 				| NULL 				  | 3 				|
# 					| hoop 				| large 				  | 5 				|
# 					| hoop 				| small 				  | 15 			 	|
# 					| hoop 				| All sizes 		  | 23 				|
# 					| All items 		| All sizes 		  | 58 				|
# 					+-----------------+-------------------+---------------+
#
# 				) Return only super-aggregate lines by filtering out the regular grouped lines:
#
# 					SELECT name, size, SUM(quantity) AS quantity
# 					FROM t1
# 					GROUP BY name, size WITH ROLLUP
# 					HAVING GROUPING(name) = 1 OR GROUPING(size) = 1;
# 					+-----------+-----------+-----------------+
# 					| name 		| size 		| quantity 			|
# 					+-----------+-----------+-----------------+
# 					| ball 		| NULL 		| 35 					|
# 					| hoop      | NULL 		| 23 					|
# 					| NULL 		| NULL 		| 58 					|
# 					+-----------+-----------+-----------------+
#
# 			GROUPING() permits multiple expression arguments. In this case, the GROUPING()
# 			return value represents a bitmask combined from the results for each expression,
# 			where the lowest-order bit corresponds to the result for the rightmost expression.
#
# 			For example, with three expression arguments, GROUPING(expr1, expr2, expr3) is evaluated
# 			like this:
#
# 				result for GROUPING(expr3)
# 			 + result for GROUPING(expr2) << 1
# 			 + result for GROUPING(expr1) << 2
#
# 			The following query shows how GROUPING() results for single arguments combine for 
# 			a multiple-argument call to produce a bitmask value:
#
# 				SELECT 
# 					name, size, SUM(quantity) AS quantity,
# 					GROUPING(name) AS grp_name,
# 					GROUPING(size) AS grp_size,
# 				GROUPING(name, size) AS grp_all
# 				FROM t1
# 				GROUP BY name, size WITH ROLLUP;
# 				+--------+------------+------------------+-------------+----------+--------------+
# 				| name   | size 		 | quantity 		  | grp_name    | grp_size | grp_all 		|
# 				+--------+------------+------------------+-------------+----------+--------------+
# 				| ball   | NULL 		 | 5 					  | 0 			 | 	0 		| 	0 			   |
# 				| ball   | large 		 | 20 				  | 0 			 | 	0 		|  0 				|
# 				| ball   | small 		 | 10 				  | 0 			 | 	0 		|  0 			   |
# 				| ball   | NULL 		 | 35 				  | 0 			 | 	1 		| 	1 				|
# 				| hoop   | NULL 		 | 3 					  | 0 			 | 	0 		|  0 				|
# 				| hoop   | large 		 | 5 					  | 0 			 | 	0 		| 	0 				|
# 				| hoop 	| small 		 | 15 				  | 0 			 | 	0 		|  0 				|
# 				| hoop   | NULL 		 | 23 				  | 0 			 | 	1 		| 	1 				|
# 				| NULL 	| NULL 		 | 58 				  | 1 			 | 	1 		|  3 				|
# 				+--------+------------+------------------+-------------+----------+--------------+
#
# 			With multiple expression arguments, the GROUPING() return value is nonzero if any expression
# 			represents a super-aggregate value.
#
# 			Multiple-argument GROUPING() syntax thus provides a simpler way to write the earlier query
# 			that returned only super-aggregate rows, by using a single multiple-argument GROUPING()
# 			call rather than multiple single-argument calls:
#
# 				SELECT name, size, SUM(quantity) AS quantity
# 				FROM t1
# 				GROUP BY name, size WITH ROLLUP
# 				HAVING GROUPING(name, size) <> 0;
# 				+--------+--------+--------------+
# 				| name   | size   | quantity 		|
# 				+--------+--------+--------------+
# 				| ball   | NULL   | 35 				|
# 				| hoop   | NULL   | 23 				|
# 				| NULL   | NULL   | 58 				|
# 				+--------+--------+--------------+
#
# 			Use of GROUPING() is subject to these limitations:
#
# 				) Do not use subquery GROUP BY expressions as GROUPING() arguments because
# 					matching might fail.
#
# 					For example, matching fails for this query:
#
# 						SELECT GROUPING((SELECT MAX(name) FROM t1))
# 						FROM t1
# 						GROUP BY (SELECT MAX(name) FROM t1) WITH ROLLUP;
# 						ERROR 3580 (HY000): Argument #1 of GROUPING function is not in GROUP BY
#
# 				) GROUP BY literal expressions should not be used within a HAVING clause as
# 					GROUPING() arguments.
#
# 					Due to differences between when the optimizer evaluates GROUP BY and HAVING,
# 					matching may succeed but GROUPING() evaluation does not produce the expected
# 					result.
#
# 					Consider this query:
#
# 						SELECT a AS f1, 'w' AS f2
# 						FROM t
# 						GROUP BY f1, f2 WITH ROLLUP
# 						HAVING GROUPING(f2) = 1;
#
# 					GROUPING() is evaluated earlier for the literal constant expression than for the
# 					HAVING clause as a whole and returns 0.
#
# 					To check whether a query such as this is affected, use EXPLAIN and look for
# 					Impossible having in the Extra column.
#
# 					For more information about WITH ROLLUP and GROUPING(), see SECTION 12.20.2, "GROUP BY MODIFIERS"
#
# 		) INET_ATON(expr)
#
# 			Given the dotted-quad representation of an IPv4 network address as a string, returns an integer that
# 			represents the numeric value of the address in network byte order (big endian) 
#
# 			INET_ATON() returns NULL if it does not understand its argument.
#
# 				SELECT INET_ATON('10.0.5.9');
# 					-> 167773449
#
# 			For this example, the return value is calculated as 10x256^3 + 0x256^2+5x256+9
#
# 			INET_ATON() may or may not return a non-NULL result for short-form IP addresses (such as '127.1'
# 			as a representation of '127.0.0.1')
#
# 			Because of this, INET_ATON() a should not be used for such addresses.
#
# 				NOTE:
#
# 					To store values generated by INET_ATON(), use an INT UNSIGNED column rather than
# 					INT, which is signed.
#
# 					If you use a signed column, values corresponding to IP addresses for which the
# 					first octet is greater than 127 cannot be stored correctly.
#
# 					See SECTION 11.2.6, "OUT-OF-RANGE AND OVERFLOW HANDLING"
#
# 		) INET_NTOA(expr)
#
# 			Given a numeric IPv4 network address in network byte order, returns the dotted-quad string
# 			representation of the address as a string in the connection character set.
#
# 			INET_NTOA() returns NULL if it does not understand its argument.
#
# 				SELECT INET_NTOA(16777349);
# 					-> '10.0.5.9'
#
# 		) INET6_ATON(expr)
#
# 			Given an IPv6 or IPv4 network address as a string, returns a binary string
# 			that represents the numeric value of the address in network byte order
# 			(big endian)
#
# 			Because numeric-format IPv6 addresses require more bytes than the largest
# 			integer type, the representation returned by this function has the VARBINARY
# 			data type:
#
# 				VARBINARY(16) for IPv6 addresses and VARBINARY(4) for IPv4 addresses.
#
# 			If the argument is not a valid address, INET6_ATON() returns NULL
#
# 			The following examples use HEX() to display the INET6_ATON() result in
# 			printable form:
#
# 				SELECT HEX(INET6_ATON('fde::5a55:caff:fefa:9089'));
# 					-> 'FDFE000000000000005A55CAFFFEFA9089'
# 				SELECT HEX(INET6_ATON('10.0.5.9'));
# 					-> '0A000509'
#
# 			INET6_ATON() observes several constraints on valid arguments.
#
# 			These are given in the following list along with examples.
#
# 				) A trailing zone ID is not permitted, as in fe80::3%1 or fe80::3%eth0
#
# 				) A trailing network mask is not permitted, as in 2001:45f:3:ba::/64 or 198.51.100.0/24
#
# 				) For values representing IPv4 addresses, only classless addresses are supported.
#
# 					Classful addresses such as 198.51.1 are rejected
#
# 					A trailing port number is not permitted, as in 198.51.100.2:8080
#
# 					Hexadecimal numbers in address components are not permitted, as in 198.0xa0.1.2
#
# 					Octal numbers are not supported:
#
# 						198.51.010.1 is treated as 198.51.10.1, not 198.51.8.1
#
# 					These IPv4 constraints also apply to IPv6 addresses that have IPv4 address
# 					parts, such as IPv4-compatible or IPv4-mapped addresses.
#
# 			To convert an IPv4 address expr represented in numeric form as an INT value to an
# 			IPv6 address represented in numeric form as a VARBINARY value, use this expression:
#
# 				INET6_ATON(INET_NTOA(expr))
#
# 			For example:
#
# 				SELECT HEX(INET6_ATON(INET_NTOA(167773449)));
# 					-> '0A000509'
#
# 		) INET6_NTOA(expr)
#
# 			Given an IPv6 or IPv4 network address represented in numeric form as a binary string,
# 			returns the string representation of the address as a string in the connection char set.
#
# 			If the argument is not a valid address, INET6_NTOA() returns NULL
#
# 			INET6_NTOA() has these properties:
#
# 				) It does not use operating system functions to perform conversions, thus the output string is platform independent.
#
# 				) The return string has a maximum length of 39(4x8 + 7)
#
# 					Given this statement:
#
# 						CREATE TABLE t AS SELECT INET6_NTOA(expr) AS c1;
#
# 					The resulting table would have this definition:
#
# 						CREATE TABLE t (c1 VARCHAR(39) CHARACTER SET utf8 DEFAULT NULL);
#
# 				) The return string uses lowercase letters for IPv6 addresses.
#
# 					SELECT INET6_NTOA(INET6_ATON('fdfe::5a55:caff:fefa:9089'));
# 						-> 'fdfe::5a55:caff:fefa:9089'
#
# 					SELECT INET6_NTOA(INET6_ATON('10.0.5.9'));
# 						-> '10.0.5.9'
#
# 					SELECT INET6_NTOA(UNHEX('FDFE0000000000000000000005A55CAFFFEFA9089'));
# 						-> 'fdfe::5a55:caff:fefa:9089'
#
# 					SELECT INET6_NTOA(UNHEX('0A000509'));
# 						-> '10.0.5.9'
#
# 			) IS_IPV4(expr)
#
# 				Returns 1 if the argument is a valid IPv4 address specified as a string. Otherwise 0
#
# 					SELECT IS_IPV4('10.0.5.9'), IS_IPV4('10.0.5.256');
# 						-> 1, 0
#
# 				For a given argument, if IS_IPV4() returns 1, INET_ATON() (and INET6_ATON()) will return
# 				non-NULL
#
# 				THe converse statement is not true: In some cases, INET_ATON() returns non-NULL
# 				when IS_IPV4() returns 0
#
# 				As implied by the preceding remarks, IS_IPV4() is more strict than INET_ATON() about what
# 				constitutes a valid IPV4 address, so it may be useful for applications that need to
# 				perform strong checks against invalid values.
#
# 				Alternatively, use INET6_ATON() to convert IPv4 addresses to internal form and check for
# 				a NULL result (which indicates an invalid address)
#
# 				INET6_ATON() is equally strong as IS_IPV4() about checking IPv4 addresses.
#
# 			) IS_IPV4_COMPAT(expr)
#
# 				This function takes an IPv6 address represented in numeric form as a binary string,
# 				as returned by INET6_ATON()
#
# 				It returns 1 if the argument is a valid IPv4-compatible IPv6 address, 0 otherwise.
#
# 				IPv4-compatible addresses have the form ::ipv4_address
#
# 					SELECT IS_IPV4_COMPAT(INET6_ATON('::10.0.5.9'));
# 						-> 1
# 					SELECT IS_IPV4_COMPAT(INET6_ATON('::ffff:10.0.5.9'));
# 						-> 0
#
# 				The IPv4 part of an IPv4-compatible address can also be represented using hexadecimal notation.
#
# 				For example, 198.51.100.1, has this raw hexadecimal value:
#
# 					SELECT HEX(INET6_ATON('198.51.100.1'));
# 						-> 'C6336401'
#
# 				Expressed in IPv4-compatible form, ::198.51.100.1 is equivalent to
# 				::c0a8:0001 or (without leading zeros) ::c0a8:1
#
# 					SELECT
# 						IS_IPV4_COMPAT(INET6_ATON('::198.51.100.1')),
# 						IS_IPV4_COMPAT(INET6_ATON('::c0a8:0001')),
# 						IS_IPV4_COMPAT(INET6_ATON('::c0a8:1'));
# 							-> 1, 1, 1
#
# 			) IS_IPV4_MAPPED(expr)
#
# 				This function takes an IPv6 address represented in numeric form as a binary string,
# 				as returned by INET6_ATON()
#
# 				It returns 1 if the argument is a valid IPV4-mapped IPV6 address, 0 otherwise.
#
# 				IPv4-mapped addresses have the form ::ffff:ipv4_address
#
# 					SELECT IS_IPV4_MAPPED(INET6_ATON('::10.0.5.9'));
# 						-> 0
# 					SELECT IS_IPV4_MAPPED(INET6_ATON('::ffff:10.0.5.9'));
# 						-> 1
#
# 				As with IS_IPV4_COMPAT() the IPv4 part of an IPv4-mapped address can
# 				also be represented using hexadecimal notation:
#
# 					SELECT
# 						IS_IPV4_MAPPED(INET6_ATON('::ffff:198.51.100.1')),
# 						IS_IPV4_MAPPED(INET6_ATON('::ffff:c0a8:0001')),
# 						IS_IPV4_MAPPED(INET6_ATON('::ffff:c0a8:1'));
# 							-> 1, 1, 1
#
# 			) IS_IPV6(expr)
#
# 				Returns 1 if the argument is a valid IPv6 address specified as a string, 0 otherwise.
#
# 				This function does not consider IPv4 addresses to be valid IPv6 addresses.
#
# 					SELECT IS_IPV6('10.0.5.9'), IS_IPV6('::1');
# 						-> 0, 1
#
# 				For a given argument, if IS_IPV6() returns 1, INET6_ATON() will return non-NULL
#
# 			) IS_UUID(string uuid)
#
# 				Returns 1 if the argument is a valid string-format UUID, 0 if the argument is not a valid
# 				UUID, and NULL if the argument is NULL
#
# 				"Valid" means that the value is in a format that can be parsed.
#
# 				That is, has the correct length and contains only the permitted characters
# 				(hexadecimal digits in any lettercase and optionally, dashes and curly braces)
#
# 				This format is most common:
#
# 					aaaaaaaaaa-bbbb-cccc-dddd-eeeeeeeeee
#
# 				These other formats are also permitted:
#
# 					aaaaaaaabbbbccccddddeeeeeeeeee
# 					{aaaaaaaaaa-bbbb-cccc-dddd-eeeeeeeeee}
#
# 				For the meanings of fields within the value, see the UUID() function description.
#
# 					SELECT IS_UUID('6ccd780c-baba-1026-9564-5b8c656024db');
# 					+-------------------------------------------------------+
# 					| IS_UUID('6ccd780c-baba-1026-9564-5b8c656024db') 		  |
# 					+-------------------------------------------------------+
# 					| 									1 									  |
# 					+-------------------------------------------------------+
#
# 					SELECT IS_UUID('6CCD780C-BABA-1026-9564-5B8C656024DB');
# 					+-------------------------------------------------------+
# 					| IS_UUID('6ccd780cbaba102695645b8c656024db') 			  |
# 					+-------------------------------------------------------+
# 					| 									1 									  |
# 					+-------------------------------------------------------+
#
# 					SELECT IS_UUID('6ccd780cbaba102695645b8c656024db');
# 					+-------------------------------------------------------+
# 					| IS_UUID('6ccd780cbaba102695645b8c656024db') 			  |
# 					+-------------------------------------------------------+
# 					| 									1 									  |
# 					+-------------------------------------------------------+
#
# 					SELECT IS_UUID('{6ccd780c-baba-1026-9564-5b8c656024db}');
# 					+----------------------------------------------------+
# 					| IS_UUID('{6ccd780c-baba-1026-9564-5b8c656024db}')  |
# 					+----------------------------------------------------+
# 					| 							1 										  |
# 					+----------------------------------------------------+
#
# 					SELECT IS_UUID('6ccd780c-baba-1026-9564-5b8c6560');
# 					+------------------------------------------------+
# 					| IS_UUID('6ccd780c-baba-1026-9564-5b8c6560') 	 |
# 					+------------------------------------------------+
# 					| 							0 									 |
# 					+------------------------------------------------+
#
# 					SELECT IS_UUID(RAND());
# 					+----------------------+
# 					| IS_UUID(RAND()) 	  |
# 					+----------------------+
# 					| 				0 			  |
# 					+----------------------+
#
# 		) MASTER_POS_WAIT(log name, log pos [, timeout][, channel])
#
# 			This function is useful for control of master/slave synchronization.
#
# 			It blocks until the slave has read and applied all updates up to the specified
# 			position in the master log.
#
# 			The return value is the number of log events the slave had to wait for advance
# 			to the specified position.
#
# 			The function returns NULL if the slave SQL thread is not started, the slave's
# 			master information is not initialized, the arguments are incorrect, or an error
# 			occurs.
#
# 			It returns -1 if the timeout has been exceeded.
#
# 			If the slave SQL thread stops while MASTER_POS_WAIT() is waiting, the function
# 			returns NULL.
#
# 			If the slave is past the specified position, the function returns immediately.
#
# 			On a multithreaded slave, the function waits until expiry of the limit set by the
# 			slave_checkpoint_group or slave_checkpoint_period system variable, when the checkpoint
# 			operation is called to update the status of the slave.
#
# 			Depending on the setting for the system variables, the function might therefore
# 			return some time after the specified position was reached.
#
# 			If a timeout value is specified, MASTER_POS_WAIT() stops waiting when timeout
# 			seconds have elapsed.
#
# 			timeout must be greater than 0; a zero or negative timeout means no timeout.
#
# 			The optional channel value enables you to name which replication channel the function
# 			applies to.
#
# 			See SECTION 17.2.3, "REPLICATION CHANNELS" for more information.
#
# 			This function is unsafe for statement-based replication. A warning is logged if you
# 			use this function when binlog_format is set to STATEMENT.
#
# 		) NAME_CONST(name, value)
#
# 			Returns the given value. When used to produce a result set column, NAME_CONST() causes
# 			the column to have the given name.
#
# 			The arguments should be constants.
#
# 				SELECT NAME_CONST('myname', 14);
# 				+----------+
# 				| myname   |
# 				+----------+
# 				| 14 		  |
# 				+----------+
#
# 			This function is for internal use only.
#
# 			THe server uses it when writing statements from stored programs that contain
# 			references to local program variables, as described in SECTION 24.7, "BINARY LOGGING OF STORED PROGRAMS"
#
# 			You might see this function in the output from mysqlbinlog
#
# 			For your applications, you can obtain exactly the same result as in the example just shown
# 			by using simple aliasing, like this:
#
# 				SELECT 14 AS myname;
# 				+-------------------+
# 				| myname 			  |
# 				+-------------------+
# 				| 		14 			  |
# 				+-------------------+
# 				1 row in set (0.00 sec)
#
# 			See SECTION 13.2.10, "SELECT SYNTAX" for more information about column aliases.
#
# 		) SLEEP(duration)
#
# 			SLeeps (pauses) for the number of seconds given by the duration argument, then returns 0.
#
# 			The duration may have a fractional part.
#
# 			If the argument is NULL or negative, SLEEP() produces a warning, or an error
# 			in strict SQL mode.
#
# 			When sleep returns normally (without interupption), it returns 0:
#
# 				SELECT SLEEP(1000);
# 				+-----------------------+
# 				| SLEEP(1000) 				|
# 				+-----------------------+
# 				| 			0 					|
# 				+-----------------------+
#
# 			When SLEEP() is the only thing invoked by a query that is interuppted, it returns
# 			1 and the query itself returns no error.
#
# 			This is true whether the query is killed or times out:
#
# 				) This statement is interrupted using KILL_QUERY from another session:
#
# 					SELECT SLEEP(1000);
# 					+------------------+
# 					| SLEEP(1000) 		 |
# 					+------------------+
# 					| 			1 			 |
# 					+------------------+
#
# 				) This statement is interrupted by timing out:
#
# 					SELECT /*+ MAX_EXECUTION_TIME(1) */ SLEEP(1000);
# 					+-------------------+
# 					| SLEEP(1000) 		  |
# 					+-------------------+
# 					| 			1 			  |
# 					+-------------------+
#
# 			When SLEEP() is only part of a query that is interrupted, the query returns an error:
#
# 				) This statement is interrupted using KILL_QUERY from another session:
#
# 					SELECT 1 FROM t1 WHERE SLEEP(1000);
# 					ERROR 1317 (70100): Query execution was interrupted
#
# 				) This statement is interrupted by timing out:
#
# 					SELECT /*+ MAX_EXECUTION_TIME(1000) */ 1 FROM t1 WHERE SLEEP(1000);
# 					ERROR 3024 (HY000): Query execution was interrupted, maximum statement
# 					execution time exceeded
#
# 			This function is unsafe for statement-based replication.
#
# 			A warning is logged if you use this function when binlog_format is set
# 			to STATEMENT.
#
# 		) UUID()
#
# 			Returns a Universal Unique Identifier (UUID) generated according to RFC 4122,
# 			"A Universally Unique Identifier (UUID) URN Namespace" (<link>)
#
# 			A UUID is designed as a number that is globally unique in space and time.
#
# 			Two calls to UUID() are expected to generate two different values, even if these
# 			calls are performed on two separate devices not connected to each other.
#
# 				WARNING
#
# 					Although UUID() values are intended to be unique, they are not necessarily unguessable
# 					or unpredictable.
#
# 					If unpreidctability is required, UUID() values should be generated some other way.
#
# 			UUID() returns a value that conforms to UUID version 1 as described in RFC 4122.
#
# 			The value is a 128-bit number represented as a utf8 string of five hexadecimal numbers in
# 			aaaaaaaa-bbbb-cccc-dddd-eeeeeeee format:
#
# 				) The first three numbers are generated from the low, middle and high parts of a timestamp.
#
# 					The high part also includes the UUID version number.
#
# 				) The fourth number preserves temporal uniqueness in case the timestamp value loses monotonicity
# 					(for example, due to daylight saving time)
#
# 				) The fifth number is an IEEE 802 node number that provides spatial uniqueness.
#
# 				A random number is substituted if the latter is not available (for example, because the host device
# 				has no Ethernet card, or it is unknown how to find the hardware address of an interface on the host
# 				operating system)
#
# 				In this case, spatial uniqueness cannot be guaranteed.
#
# 				Nevertheless, a collision should have very low probability.
#
# 				The MAC address of an interface is taken into account only on FreeBSD and Linux
#
# 				On other operating systems, MySQL uses a randomly generated 48-bit number.
#
# 					SELECT UUID();
# 						-> '6ccd780c-baba-1026-9564-5b8c656024db'
#
# 			To convert between string and binary UUID values, use the UUID_TO_BIN() and
# 			BIN_TO_UUID() functions.
#
# 			TO check whether a string is a valid UUID value, use the IS_UUID() function.
#
# 			NOTE:
#
# 				UUID() does not work with statement-based replication
#
# 		) UUID_SHORT()
#
# 			Returns a "short" universal identifier as a 64-bit unsigned integer.
#
# 			Values returned by UUID_SHORT() differ from the string-format 128-bit
# 			identifiers returned by the UUID() function and have different uniqueness
# 			properties.
#
# 			The value of UUID_SHORT() is guaranteed to be unique if the following conditions hold:
#
# 				) The server_id value of the current server is between 0 and 255 and is unique among your
# 					set of master and slave servers
#
# 				) You do not set back the system time for your server host between mysqld restarts
#
# 				) You invoke UUID_SHORT() on average fewer than 16 million times per second between mysqld restarts
#
# 			The UUID_SHORT() return value is constructed this way:
#
# 				(server_id & 255) << 56
# 			 + (server_startup_time_in_seconds << 24)
# 			 + incremented_variable++;
#
# 				SELECT UUID_SHORT();
# 					-> 92395783831158784
#
# 			NOTE:
#
# 				UUID_SHORT() does not work with statement-based replication
#
# 		) UUID_TO_BIN(string uuid), UUID_TO_BIN(string uuid, swap flag)
#
# 			Converts a string UUID to a binary UUID and returns the result.
#
# 			(The IS_UUID() function description lists the permitted string UUID formats)
#
# 			THe return binary UUID is a VARBINARY(16) value
#
# 			If the UUID argument is NULL, the return value is NULL.
#
# 			If any argument is invalid, an error occurs.
#
# 			UUID_TO_BIN() takes one or two arguments:
#
# 				) The one-argument form takes a string UUID value. The binary result is in the same
# 					order as the string argument.
#
# 				) The two-argument form takes a string UUID value and a flag value:
#
# 					) If swap_flag is 0, the two-argument form is equivalent to the one-argument form.
#
# 						The binary result is in the same order as the string argument.
#
# 					) If swap_flag is 1, the format of the return value differs:
#
# 						The time-low and time-high parts (the first and third groups of hexadecimal digits,
# 						respectively) are swapped.
#
# 						This moves the more rapidly varying part to the right and can improve indexing efficiency
# 						if the result is stored in an indexed column.
#
# 			Time-part swapping assumes the use of UUID version 1 values, such as are generated by the UUID()
# 			function.
#
# 			For UUID values produced by other means that do not follow version 1 format, time-part swapping
# 			provides no benefit.
#
# 			For details about version 1 format, see the UUID() function description.
#
# 			Suppose that you have the following string UUID value:
#
# 				SET @uuid = '6ccd780c-baba-1026-9564-5b8c656024db';
#
# 			To convert the string UUID to binary with or without time-part swapping,
# 			use UUID_TO_BIN():
#
# 				SELECT HEX(UUID_TO_BIN(@uuid));
# 				+-------------------------------------+
# 				| HEX(UUID_TO_BIN(@uuid)) 				  |
# 				+-------------------------------------+
# 				| 6CCD780CBABA102695645B8C656024DB 	  |
# 				+-------------------------------------+
#
# 				SELECT HEX(UUID_TO_BIN(@uuid, 0));
# 				+-------------------------------------+
# 				| HEX(UUID_TO_BIN(@uuid, 0)) 			  |
# 				+-------------------------------------+
# 				| 6CCD780CBABA102695-> ETC 			  |
# 				+-------------------------------------+
#
# 				SELECT HEX(UUID_TO_BIN(@uuid, 1));
# 				+-------------------------------------+
# 				| HEX(UUID_TO_BIN(@uuid, 1)) 			  |
# 				+-------------------------------------+
# 				| 1026BABA6CCD780C95645B8C656024DB 	  |
# 				+-------------------------------------+
#
# 			To convert a binary UUID returned by UUID_TO_BIN() to a string UUID,
# 			use BIN_TO_UUID() 
#
# 			If you produce a binary UUID by calling UUID_TO_BIN() with a second
# 			argument of 1 to swap time parts, you should also pass a second argument
# 			of 1 to BIN_TO_UUID() to unswap the time parts when converting the binary
# 			UUID back to a string UUID:
#
# 				SELECT BIN_TO_UUID(UUID_TO_BIN(@uuid));
# 				+---------------------------------------+
# 				| BIN_TO_UUID(UUID_TO_BIN(@uuid)) 		 |
# 				+---------------------------------------+
# 				| 6ccd780c-baba-1026-9564-5b8c656024db  |
# 				+---------------------------------------+
#
# 				SELECT BIN_TO_UUID(UUID_TO_BIN(@uuid,0),0);
# 				+---------------------------------------+
# 				| BIN_TO_UUID(UUID_TO_BIN(@uuid,0),0) 	 |
# 				+---------------------------------------+
# 				| 6ccd780c-baba-1026-9564-5b8c656024db  |
# 				+---------------------------------------+
#
# 				SELECT BIN_TO_UUID(UUID_TO_BIN(@uuid,1),1);
# 				+---------------------------------------+
# 				| BIN_TO_UUID(UUID_TO_BIN(@uuid,1),1) 	 |
# 				+---------------------------------------+
# 				| 6ccd780c-baba-1026-9564-5b8c656024db  |
# 				+---------------------------------------+
#
# 			If the use of time-part swapping is not the same for the conversion
# 			in both directions, the original UUID will not be recovered properly:
#
# 				SELECT BIN_TO_UUID(UUID_TO_BIN(@uuid,0),1);
# 				+---------------------------------------+
# 				| BIN_TO_UUID(UUID_TO_BIN(@uuid,0),1)   |
# 				+---------------------------------------+
# 				| baba1026-780c-6ccd-9564-5b8c656024db  |
# 				+---------------------------------------+
#
# 				SELECT BIN_TO_UUID(UUID_TO_BIN(@uuid,1),0);
# 				+---------------------------------------+
# 				| BIN_TO_UUID(UUID_TO_BIN(@uuid,1),0)   |
# 				+---------------------------------------+
# 				| 1026baba-6ccd-780c-9564-5b8c656024db  |
# 				+---------------------------------------+
#
# 		) VALUES(col name)
#
# 			In an INSERT_---_ON_DUPLICATE_KEY_UPDATE statement, you can use the VALUES(col_name)
# 			function in the UPDATE clause to refer to column values from the INSERT portion of the
# 			statement.
#
# 			In other words, VALUES(col_name) in the UPDATE clause refers to the value of col_name
# 			that would be inserted, had no duplicate-key conflict occurred.
#
# 			This function is especially useful in multiple-row inserts
#
# 			The VALUES() function is meaningful only in the ON DUPLICATE KEY UPDATE clause of
# 			INSERT statements and returns NULL otherwise.
#
# 			See SECTION 13.2.6.2, "INSERT --- ON DUPLICATE KEY UPDATE SYNTAX"
#
# 				INSERT INTO table (a,b,c) VALUES (1,2,3),(4,5,6)
# 					-> ON DUPLICATE KEY UPDATE c=VALUES(a)+VALUES(b);
#
# 12.24 PRECISION MATH
#
# 12.24.1 TYPES OF NUMERIC VALUES
# 12.24.2 DECIMAL DATA TYPE CHARACTERISTICS
# 12.24.3 EXPRESSION HANDLING
# 12.24.4 ROUNDING BEHAVIOR
# 12.24.5 PRECISION MATH EXAMPLES
#
# MySQL provides support for precision math: numeric value handling that results in extremely
# accurate results and a high degree control over invalid values.
#
# Precision math is based on these two features:
#
# 		) SQL modes that control how strict the server is about accepting or rejecting invalid data.
#
# 		) The MySQL library for fixed-point arithmetic
#
# These features have several implications for numeric operations and provide a high degree of
# compliance with standard SQL:
#
# 		) Precise calculations: For exact-value numbers, calculations do not introduce floating-point errors.
#
# 			Instead, exact precision is used.
#
# 			For example, MySQL treats a number such as .0001 as an exact value rather than as an approximation,
# 			and summing it 10,000 times produces a result of exactly 1, not a value that is merely "close" to 1.
#
# 		) Well-defined rounding behavior. For exact-value numbers, the result of ROUND() depends on its argument,
# 			not on environmental factors such as how the underlying C library works.
#
# 		) Platform independence: Operations on exact numeric values are the same across different platforms such as Windows and Unix.
#
# 		) Control over handling of invalid values: Overflow and division by zero are detectable and can be treated as errors.
#
# 			For example, you can treat a value that is too large for a column as an error rather than having the value
# 			truncated to lie within the range of the columns data type.
#
# 			SImilarly, you can treat division by zero as an error rather than as an operation that produces a result
# 			of NULL.
#
# 			The choice of which approach to take is determined by the setting of the server SQL mode.
#
# The following discussion covers several aspects of how precision math works, including possible incomatibilities
# with older applications.
#
# At the end, some examples are given that demonstrate how MySQL handles numeric operations precisely.
#
# For information about controlling the SQL mode, see SECTION 5.1.11, "SERVER SQL MODES"
#
# 12.24.1 TYPES OF NUMERIC VALUES
#
# The scope of precision math for exact-value operations includes the exact-value data types
# (integer and DECIMAL types) and exact-value numeric literals.
#
# Approximate-value data types and numeric literals are handled as floating-point numbers.
#
# Exact-value numeric literals have an integer part or fractional part, or both.
#
# They may be signed. Examples: 1, .2, 3.4, -5, -6.78, +9.10
#
# Approximate-value numeric literals are represented in scientific notation with a mantissa
# and exponent.
#
# Either or both parts may be signed. Examples: 1.2E3, 1.2E-3, -1.2E3, -1.2E-3
#
# Two numbers that look similar may be treated differently.
#
# For example, 2.34 is an exact-value (fixed-point) number, whereas 2.34E0 is an
# approximate value (floating-point) number
#
# The DECIMAL data type is a fixed-point type and calculations are exact.
#
# In MySQL, the DECIMAL type has several synonyms: NUMERIC, DEC, FIXED.
#
# The integer types also are exact-value types.
#
# The FLOAT and DOUBLE data types are floating-point types and calculations
# are approximate.
#
# In MySQL, types that are synonymous with FLOAT or DOUBLE are DOUBLE_PRECISION
# and REAL.
#
# 12.24.2 DECIMAL DATA TYPE CHARACTERISTICS
#
# This section discusses the characteristics of the DECIMAL data type (and its synonyms),
# with particular regard to the following topics:
#
# 		) Maximum number of digits
#
# 		) Storage format
#
# 		) Storage requirements
#
# 		) The nonstandard MySQL extension to the upper range of DECIMAL columns
#
# The declaration syntax for a DECIMAL column is DECIMAL(M,D)
#
# The ranges of values for the arguments are as follows:
#
# 		) M is the maximum number of digits (the precision). Has a range of 1 to 65
#
# 		) D is the number of digits to the right of the decimal point (the scale). Range of 0 to 30, must be no larger than M.
#
# If D is omitted, the default is 0. If M is omitted, the default is 10.
#
# The maximum value of 65 for M means that calculations on DECIMAL values are accurate up to
# 65 digits.
#
# This limit of 65 digits of precision also applies to exact-value numeric literals,
# so the maximum range of such literals differs from before.
#
# Values for DECIMAL columns are stored using a binary format that packs nine decimal
# digits into 4 bytes.
#
# The storage requirements for the integer and fractional parts of each value are determined
# separately.
#
# Each multiple of nine digits requires 4 bytes, and any remaining digits left over require some
# fraction of 4 bytes.
#
# The storage required for remaining digits is given by the following table.
#
# LEFTOVER DIGITS 				NUMBER OF BYTES
#
# 0 									0
#
# 1-2 								1
#
# 3-4 								2
#
# 5-6 								3
#
# 7-9 								4
#
# For example, a DECIMAL (18,9) column has nine digits on either side of the decimal point,
# so the integer part and the fractional part each require 4 bytes.
#
# A DECIMAL(20,6) column has fourteen integer digits and six fractional digits.
#
# The integer digits require four bytes for nine of the digits and 3 bytes for the remaining
# five digits.
#
# THe six fractional digits require 3 bytes.
#
# DECIMAL columns do not store a leading + character or - character or leading 0 digits.
#
# If you insert +0003.1 into a DECIMAL(5,1) column, it is stored as 3.1
#
# For negative numbers, a literal - character is not stored.
#
# DECIMAL columns do not permit values larger than the range implied by the column definition.
#
# For example, a DECIMAL(3,0) column supports a range of -999 to 999
#
# A DECIMAL(M,D) column permits up to M - D digits to the left of the decimal point.
#
# The SQL standard requires that the precision of NUMERIC(M,D) be exactly M digits.
#
# For DECIMAL(M,D), the standard requires a precision of at least M digits but permits
# more.
#
# In MySQL, DECIMAL(M,D) and NUMERIC(M,D) are the same, and both have a precision
# of exactly M digits.
#
# For a full explanation of the internal format of DECIMAL values, see the file
# strings/decimal.c in a MySQL source distrib.
#
# The format is explained (with an example) in the decimal2bin() function.
#
# 12.24.3 EXPRESSION HANDLING
#
# With precision math, exact-value numbers are used as given whenever possible.
#
# For example, numbers in comparisons are used exactly as given without a change in
# value.
#
# In strict SQL mode, for INSERT into a column with an exact data type (DECIMAL or integer),
# a number is inserted with its exact value if it is within the column range.
#
# When retrieved, the value should be the same as what was inserted.
#
# (If strict SQL mode is not enabled, truncation for INSERT is permissible)
#
# Handling of a numeric expression depends on what kind of values the expression contains:
#
# 		) If any approximate values are present, the expression is approximate and is evaluated using floating-point arithmetic
#
# 		) If no approximate value are present, the expression contains only exact values.
#
# 			If any exact value contains a fractional part (a value following the decimal point),
# 			the expression is evaluated using DECIMAL exact arithmetic and has a precision of 65 digits.
#
# 			The term "exact" is subject to the limits of what can be represented in binary.
#
# 			For example, 1.0/3.0 can be approximated in decimal notation as .333---, but not written
# 			as an exact number, so (1.0/3.0)*3.0 does not evaluate to exactly 1.0
#
# 		) Otherwise, the expression contains only integer values.
#
# 			The expression is exact and is evaluated using integer arithmetic and has a precision
# 			the same as BIGINT(64 bits)
#
# If a numeric expression contains any strings, they are converted to double-precision floating-point
# values and the expression is approximate.
#
# Inserts into numeric columns are affected by the SQL mode, which is controlled by the sql_mode system
# variable.
#
# (See SECTION 5.1.11, "SERVER SQL MODES")
#
# The following discussion mentions strict mode (selected by the STRICT_ALL_TABLES or STRICT_TRANS_TABLES
# mode values) and ERROR_FOR_DIVISION_BY_ZERO
#
# To turn on all restrictions, you can simply use TRADITIONAL mode, which includes both strict mode values
# and ERROR_FOR_DIVISION_BY_ZERO:
#
# 		SET sql_mode='TRADITIONAL';
#
# If a number is inserted inot an exact type column (DECIMAL or integer), it is inserted with its exact
# value if it is within the column range and precision.
#
# If the value has too many digits in the fractional part, rounding occurs and a note is generated.
#
# Rounding is done as described in SECTION 12.24.4, "ROUNDING BEHAVIOR"
#
# Truncation due to rounding of the fractional part is not an error, even in strict mode.
#
# If te value has too many digits in the integer part, it is too large (out of range) and is
# handled as follows:
#
# 		) If strict mode is not enabled, the value is truncated to the nearest legal value and a warning is generated.
#
# 		) If strict mode is enabled, an overflow error occurs.
#
# Underflow is not detected, so underflow handling is undefined.
#
# For inserts of strings into numeric columns, conversion from string to number is handled as follows
# if the string has nonnumeric contents:
#
# 		) A string that does not begin with a number cannot be used as a number and pproduces an error in strict mode,
# 			or a warning otherwise.
#
# 			This includes the empty string.
#
# 		) A string that begins with a number can be converted, but the trailing nonnumeric portion is truncated.
#
# 		If the truncated portion contains anything other than spaces, this produces an error in strict mode,
# 		or a warning otherwise.
#
# By default, division by zero produces a result of NULL and no warning.
#
# By setting the SQL mode appropriately, division by zero can be restricted.
#
# With the ERROR_FOR_DIVISION_BY_ZERO SQL mode enabled, MySQL handles division by zero differently:
#
# 		) if strict mode is not enabled, a warning occurs
#
# 		) If strict mode is enabled, inserts and updates involving division by zero are prohibited, and an error occurs.
#
# In other words, inserts and updates involving expressions that perform division by zero can be treated as errors,
# but this requires ERROR_FOR_DIVISION_BY_ZERO in addition to strict mode.
#
# Suppose that we have this statement:
#
# 		INSERT INTO t SET i = 1/0;
#
# This is what happens for combinations of strict and ERROR_FOR_DIVISION_BY_ZERO modes.
#
# 		sql_mode VALUE 				RESULT
#
# ''(Default) 							No warning, no error; i is set to NULL
#
# strict 								No warning, no error; i is set to NULL
#
# ERROR_FOR_DIVISION_BY_ZERO 		Warning, no error; i is set to NULL
#
# strict, ERROR_FOR_DIVISION_BY_ZERO Error condition; no row is inserted.
#
# 12.24.4 ROUNDING BEHAVIOR
#
# This section discusses precision math rounding for the ROUND() function and for
# inserts into columns with exact-value types (DECIMAL and integer)
#
# The ROUND() function rounds differently depending on whether its argument is exact
# or approximate:
#
# 		) For exact-value numbers, ROUND() uses the "round half up" rule:
#
# 			A value with a fractional part of .5 or greater is rounded up to the next
# 			integer if positive or down to the next integer if negative.
#
# 			(IN other words, it is rounded away from zero)
#
# 			A value with a fractional part less than .5 is rounded down to the next
# 			integer if positive or up to the next integer if negative.
#
# 			(In other words, it is rounded toward zero)
#
# 		) For approximate-value numbers, the result depends on the C library.
#
# 			On many systems, this means that ROUND() uses the "round to nearest even" rule:
#
# 				A value with a fractional part exactly half way between two integers is rounded
# 				to the nearest even integer.
#
# The following example shows how rounding differs for exact and approximate values:
#
# 		SELECT ROUND(2.5), ROUND(25E-1);
# 		+------------+------------------+
# 		| ROUND(2.5) | ROUND(25E-1) 	  |
# 		+------------+------------------+
# 		| 3 			 | 	2 				  |
# 		+------------+------------------+
#
# For inserts into a DECIMAL or integer column, the target is an exact data type, so rounding
# uses "round half away from zero", regardless of whether the value to be inserted is exact
# or approximate:
#
# 		CREATE TABLE t (d DECIMAL(10,0));
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO t VALUES(2.5),(2.5E0);
# 		Query OK, 2 rows affected, 2 warnings (0.00 sec)
# 		Records: 2 Duplicates: 0 Warnings: 2
#
# 		SHOW WARNINGS;
# 		+---------+----------+------------------------------------------------+
# 		| Level   | Code     | Message 													 |
# 		+---------+----------+------------------------------------------------+
# 		| Note 	 | 1265 		| Data truncated for column 'd' at row 1 			 |
# 		| Note 	 | 1265 		| Data truncated for column 'd' at row 2 			 |
# 		+---------+----------+------------------------------------------------+
# 		2 rows in set (0.00 sec)
#
# 		SELECT d FROM t;
# 		+-----------+
# 		| d 			|
# 		+-----------+
# 		| 3 			|
# 		| 3 			|
# 		+-----------+
# 		2 rows in set (0.00 sec)
#
# The SHOW_WARNINGS statement displays the notes that are generated by truncation due to rounding
# of the fractional part.
#
# Such truncation is not an error, even in strict SQL mode (see SECTION 12.24.3, "EXPRESSION HANDLING")
#
# 12.24.5 PRECISION MATH EXAMPLES
#
# This section provides some examples that show precision math query results in MySQL.
#
# These examples demonstrates the principles described in SECTION 12.24.3, "EXPRESSION HANDLING",
# and SECTION 12.24.4, "ROUNDING BEHAVIOR"
#
# EXAMPLE 1.
#
# Numbers are used with their exact values as given when possible:
#
# 		SELECT (.1 + .2) = 3;
# 		+---------------------+
# 		| (.1 + .2) = .3      |
# 		+---------------------+
# 		| 				1 			 |
# 		+---------------------+
#
# For floating-point values, results are inexact:
#
# 		SELECT (.1E0 + .2E0) = .3E0;
# 		+-----------------------------+
# 		| (.1E0 + .2E0) = .3E0 			|
# 		+-----------------------------+
# 		| 					0 					|
# 		+-----------------------------+
#
# ANother way to see the difference in exact and approximate value handling is to add
# a small number to a sum many times.
#
# Consider the following stored procedure, which adds .0001 to a variable 1.000 times
#
# CREATE PROCEDURE p ()
# BEGIN
# 		DECLARE i INT DEFAULT 0;
# 		DECLARE d DECIMAL(10,4) DEFAULT 0;
# 		DECLARE f FLOAT DEFAULT 0;
# 		WHILE i < 10000 DO
# 			SET d = d + .0001;
# 			SET f = f + .0001E0;
# 			SET i = i + 1;
# 		END WHILE;
# 		SELECT d, f;
# END;
#
# The sum for both d and f logically should be 1, but that is true only for decimal calculation.
#
# The floating-point calculation introduces small errors:
#
# 		+-------------+-------------------------------+
# 		| d 			  | 	f 									 |
# 		+-------------+-------------------------------+
# 		| 1.0000      | 0.99999999999991 				 |
# 		+-------------+-------------------------------+
#
# Example 2
#
# Multiplication is performed with the scale required by standard SQL.
#
# That is, for two numbers X1 and X2 that have scale S1 and S2, the scale
# of the result is S1 + S2:
#
# 		SELECT .01 * .01;
# 		+---------------+
# 		| .01 * .01 	 |
# 		+---------------+
# 		| 0.0001 		 |
# 		+---------------+
#
# Example 3
#
# Rounding behavior for exact-value numbers is well-defined:
#
# 		Rounding behavior (for example, with the ROUND() function) is independent of the implementation
# 		of the underlying C library, which means that results are consistent from platform to platform.
#
# 			) Rounding for exact-value columns (DECIMAL and integer) and exact-valued numbers uses the "round half away from zero" rule.
#
# 				A value with a fractional part of .5 or greater is rounded away from zero to the nearest
# 				integer, as shown here:
#
# 					SELECT ROUND(2.5), ROUND(-2.5);
# 					+---------------+------------------+
# 					| ROUND(2.5)    | ROUND(-2.5) 	  |
# 					+---------------+------------------+
# 					| 3 				 | -3 				  |
# 					+---------------+------------------+
#
# 			) Rounding for floating-point values uses the C library, which on many systems uses the
# 				"round to nearest even" rule.
#
# 				A value with a fractional part exactly half way between two integers is rounded to
# 				the nearest even integer:
#
# 					SELECT ROUND(2.5E0), ROUND(-2.5E0);
# 					+-------------+-------------------+
# 					| ROUND(2.5E0)| ROUND(-2.5E0) 	 |
# 					+-------------+-------------------+
# 					| 		2 		  | 		-2 			 |
# 					+-------------+-------------------+
#
# Example 4
#
# In strict mode, inserting a value that is out of range for a column causes an error,
# rather than truncation to a legal value.
#
# When MySQL is not running in strict mode, truncation to a legal value occurs:
#
# 		SET sql_mode='';
# 		Query OK,, 0 rows affected (0.00 sec)
#
# 		CREATE TABLE t (i TINYINT);
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		INSERT INTO t SET i = 128;
# 		Query OK, 1 row affected, 1 warning (0.00 sec)
#
# 		SELECT i FROM t;
# 		+----------+
# 		| 	i 		  |
# 		+----------+
# 		| 127 	  |
# 		+----------+
#
# However, an error occurs if strict mode is in effect:
#
# 		SET sql_mode='STRICT_ALL_TABLES';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CREATE TABLE t (i TINYINT);
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO t SET i = 128;
# 		ERROR 1264 (22003): Out of range value adjusted for column 'i' at row 1
#
# 		SELECT i FROM t;
# 		Empty set (0.00 sec)
#
# Example 5
#
# In strict mode and with ERROR_FOR_DIVISION_BY_ZERO set, division by zero causes
# an error, not a result of NULL.
#
# In nonstrict mode, division by zero has a result of NULL:
#
# 		SET sql_mode='';
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		CREATE TABLE t (i TINYINT);
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO t SET i = 1 / 0;
# 		Query OK, 1 row affected (0.00 sec)
#
# 		SELECT i FROM t;
# 		+-----------+
# 		| i 			|
# 		+-----------+
# 		| NULL 		|
# 		+-----------+
# 		1 row in set (0.03 sec)
#
# However, division by zero is an error if the proper SQL modes are in effect:
#
# 		SET sql_mode='STRICT_ALL_TABLES, ERROR_FOR_DIVISION_BY_ZERO';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CREATE TABLE t (i TINYINT);
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO t SET = 1 / 0;
# 		ERROR 1365 (22012): Division by 0
#
# 		SELECT i FROM t;
# 		Empty set (0.01 sec)
#
# Example 6
#
# Exact-value literals are evaluted as exact values.
#
# Approximate-value literals are evaluated using floating-point, but exact-value
# literals are handled as DECIMAL:
#
# 		CREATE TABLE t SELECT 2.5 AS a, 25E-1 AS b;
# 		Query OK, 1 row affected (0.01 sec)
# 		Records: 1 Duplicates: 0 Warnings: 0
#
# 		DESCRIBE t;
# 		+---------+--------------------------------------+----------+----------+-----------------------+-----------+
# 		| Field 	 | Type 											 | Null 		| Key 	  | Default 				  | Extra 	  |
# 		+---------+--------------------------------------+----------+----------+-----------------------+-----------+
# 		| a 		 | decimal(2,1) unsigned 					 | NO       | 			  | 0.0 						  | 			  |
# 		| b 		 | double 										 | NO 		| 			  | 0 						  | 			  |
# 		+---------+--------------------------------------+----------+----------+-----------------------+-----------+
#
# Example 7
#
# If the argument to an aggregate function is an exact numeric type, the result is also an exact numeric type,
# with a scale at least that of the argument.
#
# Consider these statements:
#
# 		CREATE TABLE t (i INT, d DECIMAL, f FLOAT);
# 		INSERT INTO t VALUES(1,1,1);
# 		CREATE TABLE y SELECT AVG(i), AVG(d), AVG(f) FROM t;
#
# THe result is a double only for the floating-point argument.
#
# For exact type arguments, the result is also an exact type:
#
# 		DESCRIBE y;
# 		+----------+---------------------------+-------+---------+---------------+--------------+
# 		| Field 	  | Type 							| Null  | Key 	   | Default 		 | Extra 		 |
# 		+----------+---------------------------+-------+---------+---------------+--------------+
# 		| AVG(i)   | decimal(14,4) 				| YES   | 			| NULL 			 | 				 |
# 		| AVG(d)   | decimal(14,4) 				| YES   | 		   | NULL 			 | 				 |
# 		| AVG(f)   | double 							| YES   | 			| NULL 			 | 				 |
# 		+----------+---------------------------+-------+---------+---------------+--------------+
#
# The result is a double only for the floating-point argument.
#
# for exact type arguments, the result is also an exact type.
#
# CHAPTER 13 SQL STATEMENT SYNTAX
#
# TABLE OF CONTENTS
#
# 13.1 DATA DEFINITION STATEMENTS
# 13.2 DATA MANIPULATION STATEMENTS
# 13.3 TRANSACTIONAL AND LOCKING STATEMENTS
# 13.4 REPLICATION STATEMENTS
# 13.5 PREPARED SQL STATEMENT SYNTAX
# 13.6 COMPOUND-STATEMENT SYNTAX
# 13.7 DATABASE ADMINISTRATION STATEMENTS
# 13.8 UTILITY STATEMENTS
#
# This chapter describes the syntax for the SQL statements supported by MySQL.
#
# 13.1 DATA DEFINITION STATEMENTS
#
# 13.1.1 ATOMIC DATA DEFINITION STATEMENT SUPPORT
# 13.1.2 ALTER DATABASE SYNTAX
# 13.1.3 ALTER EVENT SYNTAX
# 13.1.4 ALTER FUNCTION SYNTAX
# 
# 13.1.5 ALTER INSTANCE SYNTAX
# 13.1.6 ALTER LOGFILE GROUP SYNTAX
# 13.1.7 ALTER PROCEDURE SYNTAX
# 13.1.8 ALTER SERVER SYNTAX
#
# 13.1.9 ALTER TABLE SYNTAX
# 13.1.10 ALTER TABLESPACE SYNTAX
# 13.1.11 ALTER VIEW SYNTAX
# 13.1.12 CREATE DATABASE SYNTAX
#
# 13.1.13 CREATE EVENT SYNTAX
# 13.1.14 CREATE FUNCTION SYNTAX
# 13.1.15 CREATE INDEX SYNTAX
# 13.1.16 CREATE LOGFILE GROUP SYNTAX
#
# 13.1.17 CREATE PROCEDURE AND CREATE FUNCTION SYNTAX
# 13.1.18 CREATE SERVER SYNTAX
# 13.1.19 CREATE SPATIAL REFERENCE SYSTEM SYNTAX
# 13.1.20 CREATE TABLE SYNTAX
#
# 13.1.21 CREATE TABLESPACE SYNTAX
# 13.1.22 CREATE TRIGGER SYNTAX
# 13.1.23 CREATE VIEW SYNTAX
# 13.1.24 DROP DATABASE SYNTAX
#
# 13.1.25 DROP EVENT SYNTAX
# 13.1.26 DROP FUNCTION SYNTAX
# 13.1.27 DROP INDEX SYNTAX
# 13.1.28 DROP LOGFILE GROUP SYNTAX
#
# 13.1.29 DROP PROCEDURE AND DROP FUNCTION SYNTAX
# 13.1.30 DROP SERVER SYNTAX
# 13.1.31 DROP SPATIAL REFERENCE SYSTEM SYNTAX
# 13.1.32 DROP TABLE SYNTAX
#
# 13.1.33 DROP TABLESPACE SYNTAX
# 13.1.34 DROP TRIGGER SYNTAX
# 13.1.35 DROP VIEW SYNTAX
# 13.1.36 RENAME TABLE SYNTAX
#
# 13.1.37 TRUNCATE TABLE SYNTAX
#
# 13.1.1 ATOMIC DATA DEFINITION STATEMENT SUPPORT
#
# MySQL 8.0 supports atomic Data Definition Language (DDL) statements.
#
# This feature is referred to as atomic DDL.
#
# AN atomic DDL statement combines the data dictionary updates, storage engine operations,
# and binary log writes associated with a DDL operation into a single, atomic transaction.
#
# The transaction is either committed, with applicable changes persisted to the data dictionary,
# storage engine and binary log, or is rolled back, even if the server halts during the operation.
#
# Atomic DDL is made possible by the introduction of the MySQL data dictionary in MySQL 8.0
#
# In earlier MySQL versions, metadata was stored in metadata files, nontransactional tables
# and storage engine-specific dictionaries, which necessitated intermediate commits.
#
# Centralized, transactional metadata storage provided by the MySQL data dictionary
# removed this barrier, making it possible to restructure DDL statement operations into
# atomic transactions.
#
# The atomic DDL feature is described under the following topics in this section:
#
# 		) Supported DDL statements
#
# 		) Atomic DDL characteristics
#
# 		) Changes in DDL Statement Behavior
#
# 		) Storage Engine Support
#
# 		) Viewing DDL Logs
#
# SUPPORTED DDL STATEMENTS
#
# The atomic DDL feature supports both table and non-table DDL statements.
#
# Table-related DDL operations require storage engine support, whereas non-table
# DDL operations do not.
#
# Currently, only the InnoDB storage engine supports atomic DDL.
#
# 		) Supported table DDL statements include CREATE ALTER, and DROP statements for databases,
# 			tablespaces, tables and indexes, and the TRUNCATE_TABLE statement.
#
# 		) Supported non-table DDL statements include:
#
# 			) CREATE and DROP statements, and, if applicable, ALTER statements for stored programs,
# 				triggers, views and user-defined functions (UDFs)
#
# 			) Account management statements: CREATE, ALTER, DROP and if applicable, RENAME
# 				statements for users and roles, as well as GRANT and REVOKE statements.
#
# The following statements are not supported by the atomic DDL feature:
#
# 		) Table-related DDL statements that involve a storage engine other than InnoDB
#
# 		) INSTALL_PLUGIN and UNINSTALL_PLUGIN statements
#
# 		) INSTALL_COMPONENT and UNINSTALL_COMPONENT statements
#
# 		) CREATE_SERVER, ALTER_SERVER and DROP_SERVER statements
#
# ATOMIC DDL CHARACTERISTICS
#
# The characteristics of atomic DDL statements include the following:
#
# 		) Metadata updates, binary log writes, and storage engine operations, where applicable, are combined into a single transaction.
#
# 		) There are no intermediate commits at the SQL layer during the DDL operation
#
# 		) Where applicable:
#
# 			) The state of data dictionary, routine, event and UDF caches is consistent with the status
# 				of the DDL operation, meaning that caches are updated to reflect whether or not the
# 				DDL operation was completed successfully or rolled back.
#
# 			) The storage engine method involved in a DDL operation do not perform intermediate commits,
# 				and the storage engine registers itself as part of the DDL transaction.
#
# 			) The storage engine supports redo and rollback of DDL operations, which is performed in the
# 				Post-DDL phase of the DDL operation.
#
# 		) The visible behavior of DDL operations is atomic, which changes the behavior of some DDL statements.
#
# 			See CHANGES IN DDL STATEMENT BEHAVIOR
#
# NOTE:
#
# 		DDL statements, atomic or otherwise, implicitly end any transaction that is active in the current session,
# 		as if you had done a COMMIT before executing the statement.
#
# 		This means that DDL statements cannot be performed within another transaction, within transaction control
# 		statements such as START TRANSACTION --- COMMIT, or combined with other statements within the same transaction.
#
# CHANGES IN DDL STATEMENT BEHAVIOR
#
# This section describes changes in DDL statement behavior due to the introduction of atomic DDL support.
#
# 		) DROP TABLE operations are fully atomic if all named tables use an atomic DDL-supported storage engine.
#
# 			The statement either drops all tables successfully or is rolled back.
#
# 			DROP TABLE fails with an error if a named table does not exist, and no changes are made, regardless
# 			of the storage engine.
#
# 			This change in behavior is demonstrated in the following example, where the DROP TABLE statement
# 			fails because a named table does not exist:
#
# 				CREATE TABLE t1 (c1 INT);
# 				DROP TABLE t1, t2;
# 				ERROR 1051 (42S02): Unknown table 'test.2'
# 				SHOW TABLES;
# 				+--------------------+
# 				| Tables_in_test 		|
# 				+--------------------+
# 				| t1 					   |
# 				+--------------------+
#
# 			Prior to the introduction of atomic DDL, DROP TABLE reports an error for the named table
# 			that does not exist but succeeds for the named table that does exist:
#
# 				CREATE TABLE t1 (c1 INT);
# 				DROP TABLE t1, t2;
# 				ERROR 1051 (42S02): Unknown table 'test.t2'
# 				SHOW TABLES;
# 				Empty set (0.00 sec)
#
# 			NOTE:
#
# 				Due to this change in behavior, a partially completed DROP TABLE statement on a MySQL 5.7
# 				master fails when replicated on a MySQL 8.0 slave
#
# 				To avoid this failure scenario, use IF EXISTS syntax in DROP TABLE statements to prevent errors
# 				from occurring for tables that do not exist.
#
# 		) DROP_DATABASE is atomic if all tables use an atomic DDL-supported storage engine.
#
# 			The statement either drops all objects successfully or is rolled back.
#
# 			However, removal of the database directory from the file system occurs last
# 			and is not part of the atomic transaction.
#
# 			If removal of the database directory fails due to a file system error
# 			or server halt, the DROP DATABASE transaction is not rolled back.
#
# 		) For tables that do not use an atomic DDL-supported storage engine, table deletion
# 			occur outside of the atomic DROP_TABLE or DROP_DATABASE transaction.
#
# 			Such table deletions are written to the binary log individually, which limits the
# 			discrepancy between the storage engine, data dictionary, and binary log to one table
# 			at most in the case of an interrupted DROP_TABLE or DROP_DATABASE operation.
#
# 			For operations that drop multiple tables, the tables that do not use an atomic
# 			DDL-supported storage engine are dropped before tables that do.
#
# 		) CREATE_TABLE, ALTER_TABLE, RENAME_TABLE, TRUNCATE_TABLE, CREATE_TABLESPACE,
# 			and DROP_TABLESPACE operations for tables that use an atomic DDL-supported
# 			storage engine are either fully committed or rolled back if the server halts
# 			during their operation.
#
# 			In earlier MySQL releases, interruption of these operations could cause discrepancies
# 			between the storage engine, data dictionary and binary log, or leave behind
# 			orphan files.
#
# 			RENAME_TABLE operations are only atomic if all named tables use an atomic
# 			DDL-supported storage engine.
#
# 		) DROP_VIEW fails if a named view does not exist, and no changes are made.
#
# 			The change in behavior is demonstrated in this example, where the
# 			DROP_VIEW statement fails because a named view does not exist:
#
# 				CREATE VIEW test.viewA AS SELECT * FROM t;
# 				DROP VIEW test.viewA, test.viewB;
# 				ERROR 1051 (42S02): Unknown table 'test.viewB'
# 				SHOW FULL TABLES IN test WHERE TABLE_TYPE LIKE 'VIEW';
# 				+-----------------+-------------------+
# 				| Tables_in_test  | Table_type 		  |
# 				+-----------------+-------------------+
# 				| viewA 				| VIEW 				  |
# 				+-----------------+-------------------+
#
# 			Prior to the introduction of atomic DDL, DROP_VIEW returns an error for
# 			the named view that does not exist but succeeds for the named view that
# 			does exist:
#
# 				CREATE VIEW test.viewA AS SELECT * FROM t;
# 				DROP VIEW test.viewA, test.viewB;
# 				ERROR 1051 (42S02): Unknown table 'test.viewB'
# 				SHOW FULL TABLES IN test WHERE TABLE_TYPE LIKE 'VIEW';
# 				Empty set (0.00 sec)
#
# 			NOTE:
#
# 				Due to this change in behavior, a partially completed DROP_VIEW
# 				on a MySQL 5.7 master fails when replicated on a MySQL 8.0 slave.
#
# 				To avoid this failure scenario, use IF EXISTS syntax in DROP_VIEW
# 				statements to prevent an error from occurring for views that do not
# 				exist.
#
# 		) Partial execution of account management statements is no longer permitted.
#
# 			Account management statements either succeed for all named users or roll back
# 			and have no effect if an error occurs.
#
# 			In earlier MySQL versions, account management statements that name multiple
# 			users could succeed for some users and fail for others.
#
# 			The change in behavior is demonstrated in this example, where the second
# 			CREATE_USER statement returns an error but fails because it cannot succeed
# 			for all named users:
#
# 				CREATE USER userA;
# 				CREATE USER userA, userB;
# 				ERROR 1396 (HY000): Operation CREATE USER failed for 'userA'@'%'
# 				SELECT User FROM mysql.user WHERE User LIKE 'user%';
# 				+-------------+
# 				| User 		  |
# 				+-------------+
# 				| userA 		  |
# 				+-------------+
#
# 			Prior to the introduction of atomic DDL, the second CREATE USER statement
# 			returns an error for the named user that does not exist but succeeds
# 			for the named user that does exist:
#
# 				CREATE USER userA;
# 				CREATE USER userA, userB;
# 				ERROR 1396 (HY000): Operation CREATE USER failed for 'userA'@'%'
# 				SELECT User FROM mysql.user WHERE User LIKE 'user%';
# 				+----------+
# 				| User 	  |
# 				+----------+
# 				| userA 	  |
# 				| userB    |
# 				+----------+
#
# 			NOTE:
#
# 				Due to this change in behavior, partially completed account management
# 				statements on a MySQL 5.7 master fail when replicated on a MySQL 8.0 Slave.
#
# 				To avoid this failure scenario, use IF EXISTS or IF NOT EXISTS syntax,
# 				as appropriate, in account management statements to prevent errors related
# 				to named users.
#
# STORAGE ENGINE SUPPORT
#
# Currently, only the InnoDB storage engine supports atomic DDL.
#
# Storage engines that do not support atomic DDL are exempted from DDL
# atomicity.
#
# DDL operations involving exempted storage engines remain capable
# of introducing inconsistencies that can occur when operations are interuppted
# or only partially completed.
#
# To support redo and rollback of DDL operations, InnoDB writes DDL logs to
# the mysql.innodb_ddl_log table, which is a hidden data dictionary table that
# resides in the mysql.ibd data dictionary tablespace.
#
# To view DDL logs that are written to the mysql.innodb_ddl_log table during
# a DDL operation, enable the innodb_print_ddl_logs configuration option.
#
# For more information, see VIEWING DDL LOGS.
#
# NOTE:
#
# 		THe redo logs for changes to the mysql.innodb_ddl_log table are flushes to disk
# 		immediately regardless of the innodb_flush_log_at_trx_commit setting.
#
# 		Flushing the redo logs immediately avoids situations where data files are modified
# 		by DDL operations but the redo logs for changes to the mysql.innodb_ddl_log
# 		table resulting from those operations are not persisted to disk.
#
# 		SUch a situation could cause errors during rollback or recovery.
#
# The InnoDB storage engine executes DDL operations in phases.
#
# DDL operations such as ALTER_TABLE may perform the Prepare and Perform
# phases multiple times prior to the Commit phase.
#
# 		1. Prepare: Create hte required objects and write the DDL logs to the
# 			mysql.innodb_ddl_log table
#
# 			The DDL logs define how to roll forward and roll back the DDL
# 			operation
#
# 		2. Perform: Perform the DDL operation. For example, perform a create routine for a CREATE TABLE operation.
#
# 		3. Commit: Update the data dictionary and commit the data dictionary transaction
#
# 		4. Post-DDL: Replay and remove DDL logs from the mysql.innodb_ddl_log table.
#
# 			To ensure that rollback can be performed safely without introducing inconsistencies,
# 			file operations such as renaming or removing data files are performed in
# 			this final phase.
#
# 			This phase also removes dynamic metadata from the mysql.innodb_dynamic_metadata
# 			data dictionary table for DROP_TABLE, TRUNCATE_TABLE and other DDL operations
# 			that rebuild the table.
#
# DDL logs are replayed and removed from the mysql.innodb_ddl_log table during the
# Post-DDL phase, regardless of whether the transaction is committed or rolled back.
#
# DDL logs should only remain in the mysql.innodb_ddl_log table if the server is halted
# during a DDL operation.
#
# In this case, the DDL logs are replayed and removed after recovery.
#
# In a recovery situation, a DDL transaction may be committed or rolled back when
# the server is restarted.
#
# If the data dictionary transaction that was performed during the Commit phase of a
# DDL operation is present in the redo log and binary log, the operation is considered
# successful and is rolled forward.
#
# Otherwise, the incomplete data dictionary transaction is rolled back when InnoDB
# replays data dictionary redo logs, and the DDL transaction is rolled back.
#
# VIEWING DDL LOGS
#
# To view DDL logs that are written to the mysql.innodb_ddl_log data dictionary
# table during atomic DDL operations that involve the InnoDB storage engine, enable
# innodb_print_ddl_logs to have MySQL write the DDL logs to stderr.
#
# Depending on the host operating system and MySQL configuration, stderr may be the
# error log, terminal or console window.
#
# See SECTION 5.4.2.2, "DEFAULT ERROR LOG DESTINATION CONFIGURATION"
#
# InnoDB writes DDL logs to the mysql.innodb_ddl_log table to support redo and
# rollback of DDL operations.
#
# The mysql.innodb_ddl_log table is a hidden data dictionary table that resides
# in the mysql.ibd data dictionary tablespace.
#
# Like other hidden data dictionary tables, the mysql.innodb_ddl_log table cannot
# be accessed directly in non-debug versions of MySQL.
#
# (See SECTION 14.1, "DATA DICTIONARY SCHEMA")
#
# The structure of the mysql.innodb_ddl_log table corresponds to this definition:
#
# 		CREATE TABLE mysql.innodb_ddl_log (
# 			id BIGINT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 			thread_id BIGINT UNSIGNED NOT NULL,
# 			type INT UNSIGNED NOT NULL,
# 			space_id INT UNSIGNED,
# 			page_no INT UNSIGNED,
# 			index_id BIGINT UNSIGNED,
# 			table_id BIGINT UNSIGNED,
# 			old_file_path VARCHAR(512) COLLATE UTF8_BIN,
# 			new_file_path VARCHAR(512) COLLATE UTF8_BIN,
# 			KEY(thread_id)
# 		);
#
# 		) id: A unique identifier for a DDL log record
#
# 		) thread_id: Each DDL log record is assigned a thread_id which is used to replay and remove
# 			DDL logs that belong to a particular DDL transaction.
#
# 			DDL transactions that involve multiple data file operations generate multiple DDL log records.
#
# 		) type: The DDL operation type. Types include FREE (drop an index tree), DELETE (delete a file),
# 			RENAME (rename a file), or DROP (drop metadata from the mysql.innodb_dynamic_metadata data dictionary
# 			table)
#
# 		) space_id: The tablespace ID
#
# 		) page_no: A page that contains allocation information; an index tree root page, for example.
#
# 		) index_id: The index ID
#
# 		) table_id: The table ID
#
# 		) old_file_path: The old tablespace file path. Used by DDL operations that create or drop tablespace
# 			files; also used by DDL operations that rename a tablespace.
#
# 		) new_file_path: The new tablespace file path. Used by DDL operations that rename tablespace files.
#
# THis example demonstrates enabling innodb_print_ddl_logs to view DDL logs written to stderr for
# a CREATE TABLE operation.
#
# 		SET GLOBAL innodb_print_ddl_logs=1;
# 		CREATE TABLE t1 (c1 INT) ENGINE = InnoDB;
#
# 		[Note] [000000] InnoDB: DDL log insert : [DDL record: DELETE SPACE, id=18, thread_id=7,
# 		space_id=5, old_file_path=./test/t1.ibd]
# 		[Note] [000000] InnoDB: DDL log delete : by id 18
#
# 		[Note] [000000] InnoDB: DDL log insert : [DDL record: REMOVE CACHE, id=19, thread_id=7,
# 		table_id=1058, new_file_path=test/t1]
# 		[Note] [000000] InnoDB: DDL log delete : by id 19
#
# 		[Note] [000000] InnoDB: DDL log insert : [DDL record: FREE, id=20, thread_id=7,
# 		space_id=5, index_id=132, page_no=4]
# 		[Note] [000000] InnoDB: DDL log delete : by id 20
#
# 		[Note] [000000] InnoDB: DDL log post ddl : begin for thread id : 7
# 		[Note] [000000] InnoDB: DDL log post ddl : end for thread id : 7
#
# 13.1.2 ALTER DATABASE SYNTAX
#
# ALTER {DATABASE | SCHEMA} [db_name]
# 		alter_specification ---
#
# alter_specification:
# 		[DEFAULT] CHARACTER SET [=] charset_name
# 	 | [DEFAULT] COLLATE [=] collation_name
#
# ALTER_DATABASE enables you to change the overall characteristics of a database.
#
# These characteristics are stored in the data dictionary.
#
# To use ALTER_DATABASE, you need the ALTER privilege on the database.
#
# ALTER_SCHEMA is a synonym for ALTER_DATABASE
#
# The database name can be omitted from the first syntax, in which case the statement
# applies to the default database.
#
# NATIONAL LANGUAGE CHARACTERISTICS
#
# The CHARACTER SET clause changes the default database character set.
#
# The COLLATE clause changes the default database collation. CHAPTER 10, CHARACTER SETS,
# COLLATIONS,, UNICODE discusses char sets and collation names.
#
# You can see what character sets and collations are available using, respectively,
# the SHOW_CHARACTER_SET and SHOW_COLLATION statements.
#
# See SECTION 13.7.6.3, "SHOW CHARACTER SET SYNTAX", and SECTION 13.7.6.4, "SHOW COLLATION SYNTAX"
# for more information
#
# If you change the default character set or collation for a database, stored routines that use the
# database defaults must be dropped and recreated so that they use the new defaults.
#
# (in a stored routine, variables with character data types use the database defaults if
# the character set or collation are not specified explicitly.
#
# See SECTION 13.1.17, "CREATE PROCEDURE AND CREATE FUNCTION SYNTAX")
#
# 13.1.3 ALTER EVENT SYNTAX
#
# ALTER
# 		[DEFINER = { user | CURRENT_USER }]
# 		EVENT event_name
# 		[ON SCHEDULE schedule]
# 		[ON COMPLETION [NOT] PRESERVE]
# 		[RENAME TO new_event_name]
# 		[ENABLE | DISABLE | DISABLE ON SLAVE]
# 		[COMMENT 'string']
# 		[DO event_body]
#
# The ALTER_EVENT statement changes one or more of the characteristics of an existing event
# without the need to drop and recreate it.
#
# THe syntax for each of the DEFINER, ON SCHEDULE, ON COMPLETION, ENABLE / DISABLE and DO clauses
# is exactly the same as when used with CREATE_EVENT
#
# (See SECTION 13.1.13, "CREATE EVENT SYNTAX")
#
# Any user can alter an event defined on a database for which that user has the EVENT privilege.
#
# When a user executes a successful ALTER_EVENT statement, that user becomes the definer
# for the affected event.
#
# ALTER_EVENT works only with an existing event:
#
# 		ALTER EVENT no_such_event
# 			ON SCHEDULE
# 				EVERY '2:3' DAY_HOUR;
# 		ERROR 1517 (HY000): Unknown event 'no_such_event'
#
# In each of the following examples, assume that hte event named myevent is defined
# as shown here:
#
# 		CREATE EVENT myevent
# 			ON SCHEDULE
# 				EVERY 6 HOUR
# 			COMMENT 'A sample comment.'
# 			DO
# 				UPDATE myschema.mytable SET mycol = mycol + 1;
#
# The following statement changes the schedule for myevent from once every six hours
# starting immediately to once every twelve hours, starting four hours from the time
# the statement is run:
#
# 		ALTER EVENT myevent
# 			ON SCHEDULE
# 				EVERY 12 HOUR
# 			STARTS CURRENT_TIMESTAMP + INTERVAL 4 HOUR;
#
# It is possible to change multiple characteristics of an event in a single statement.
#
# This example changes the SQL statement executed by myevent to one that deletes all
# records from mytable;
#
# It also changes the schedule for the event such that it executes once, one day
# after this ALTER_EVENT statement is run.
#
# 		ALTER EVENT myevent
# 			ON SCHEDULE
# 				AT CURRENT_TIMESTAMP + INTERVAL 1 DAY
# 			DO
# 				TRUNCATE TABLE myschema.mytable;
#
# Specify the options in an ALTER_EVENT statement only for those characteristics
# that you want to change;
#
# Omitted options keep their existing values.
#
# This includes any default values for CREATE_EVENT such as ENABLE.
#
# To disable myevent, use this ALTER_EVENT statement:
#
# 		ALTER EVENT myevent
# 			DISABLE;
#
# The ON SCHEDULE clause may use expressions involving built-in MySQL functions and user variables
# to obtain any of the timestamp or interval values which it contains.
#
# You cannot use stored routines or user-defined functions in such expressions, and you cannot
# use any table references;
#
# However, you can use SELECT FROM DUAL. This is true for both ALTER_EVENT and CREATE_EVENT
# statements.
#
# References to stored routines, user-defined functions, and tables in such cases are specifically
# not permitted, and fail with an error (see Bug #22830)
#
# Although an ALTER_EVENT statement that contains another ALTER_EVENT statement in its DO clause
# appears to succeed, when the server attempts to execute the resulting scheduled event, the execution
# fails with an error.
#
# To rename an event, use the ALTER_EVENT statement's RENAME TO clause.
#
# This statement renames the event myevent to yourevent:
#
# 		ALTER EVENT myevent
# 			RENAME TO yourevent;
#
# You can also move an event to a different database using ALTER EVENT --- RENAME TO ---
# and db_name.event_name notation, as shown here:
#
# 		ALTER EVENT olddb.myevent
# 			RENAME TO newdb.myevent;
#
# To execute the previous statement, the user executing it must have the EVENT privilege
# on both the olddb and newdb databases.
#
# NOTE:
#
# 		There is no RENAME EVENT statement
#
# The value DISABLE ON SLAVE is used on a replication slave instead of ENABLE or DISABLE
# to indicate an event that was created on the master and replicated to the slave, but that
# is not executed on the slave.
#
# Normally, DISABLE ON SLAVE is set automatically as required; however, there are some circumstances
# under which you may want or need to change it manually.
#
# See SECTION 17.4.1.16, "REPLICATION OF INVOKED FEATURES", for more information.
#
# 13.1.4 ALTER FUNCTION SYNTAX
#
# ALTER FUNCTION func_name [characteristic ...]
#
# characteristic:
# 		COMMENT 'string'
# 	 | LANGUAGE SQL
# 	 | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }
# 	 | SQL SECURITY { DEFINER | INVOKER }
#
# This statement can be used to change the characteristics of a stored function.
#
# More than one change may be specified in an ALTER_FUNCTION statement.
#
# However, you cannot change the parameters or body of a stored function
# using this statement; to make such changes, you must drop and re-create
# the function using DROP_FUNCTION and CREATE_FUNCTION
#
# You must have the ALTER_ROUTINE privilege for the function.
#
# (That privilege is granted automatically to the function creator)
#
# If binary logging is enabled, the ALTER_FUNCTION statement might also require
# the SUPER privilege, as described in SECTION 24.7, "BINARY LOGGING OF STORED PROGRAMS"
#
# 13.1.5 ALTER INSTANCE SYNTAX
#
# ALTER INSTANCE ROTATE INNODB MASTER KEY
#
# ALTER INSTANCE defines actions applicable to a MySQL server instance.
#
# The ALTER INSTANCE ROTATE INNODB MASTER KEY statement is used to rotate the master encryption
# key used for InnoDB tablespace encryption.
#
# A keyring plugin must be installed and configured to use this statement.
#
# By default, the MySQL server loads the keyring_file plugin.
#
# Key rotation requires the ENCRYPTION_KEY_ADMIN or SUPER privilege
#
# ALTER INSTANCE ROTATE INNODB MASTER KEY supports concurrent DML.
#
# However, it cannot be run concurrently with CREATE_TABLE_---_ENCRYPTION
# or ALTER_TABLE_---_ENCRYPTION operations, and locks are taken to prevent
# conflicts that could arise from concurrent execution of these statements.
#
# If one of the conflicting statements is running, it must complete before 
# another can proceed.
#
# ALTER INSTANCE actions are written to the binary log so that they can be 
# executed on replicated servers.
#
# For additional ALTER INSTANCE ROTATE INNODB MASTER KEY usage information,
# see SECTION 15.6.3.9, "TABLESPACE ENCRYPTION"
#
# For information about the keyring_file plugin, see SECTION 6.5.4, "THE MYSQL KEYRING"
#
# 13.1.6 ALTER LOGFILE GROUP SYNTAX
#
# ALTER LOGFILE GROUP logfile_group
# 		ADD UNDOFILE 'file_name'
# 		[INITIAL_SIZE [=] size]
# 		[WAIT]
# 		ENGINE [=] engine_name
#
# This statement adds an UNDO file named 'file_name' to an existing log file group
# logfile_group.
#
# An ALTER_LOGFILE_GROUP statement has one and only one ADD UNDOFILE clause.
#
# No DROP UNDOFILE clause is currently supported.
#
# NOTE:
#
# 		All NDB Cluster Disk Data objects share the same namespace.
#
# 		This means that each Disk Data object must be uniquely named
# 		(and not merely each Disk Data object of a given type)
#
# 		For example, you cannot have a tablespace and an undo log file
# 		with the same name, or an undo log file and a data file with the
# 		same name.
#
# The optional INITIAL_SIZE parameter sets the UNDO file's initial size in bytes;
# if not specified, the initial size defaults to 134217728 (128 MB)
#
# You may optionally follow size with a one-letter abbreviation for an order
# of magnitude, similar to those used in my.cnf 
#
# Generally, this is one of the letters M (megabytes) or G (gigabytes)
#
# (Bug #13116514, Bug #16104705, Bug #62858)
#
# On 32-bit systems, the maximum supported value for INITIAL_SIZE is
# 4294967296 (4 GB) (Bug #29186)
#
# The minimum allowed value for INITIAL_SIZE is 1048576 (1 MB) (Bug #29574)
#
# NOTE:
#
# 		WAIT is parsed but otherwise ignored. 
# 		This keyword currently has no effect, and is intended for future expansion.
#
# The ENGINE parameter (required) determines the storage engine which is used by this
# log file group, with engine_name being the name of the storage engine.
#
# Currently, the only accepted values for engine_name are "NDBCLUSTER" and "NDB"
#
# The two values are equivalent
#
# Here is an example, which assumes that the log file group lg_3 has already been
# created using CREATE_LOGFILE_GROUP (see SECTION 13.1.16, "CREATE LOGFILE GROUP SYNTAX"):
#
# 		ALTER LOGFILE GROUP lg_3
# 			ADD UNDOFILE 'undo_10.dat'
# 			INITIAL_SIZE=32M
# 			ENGINE=NDBCLUSTER;
#
# When ALTER_LOGFILE_GROUP is used with ENGINE = NDBCLUSTER (alternatively, ENGINE = NDB), an UNDO log file
# is created on each NDB Cluster data node.
#
# You can verify that the UNDO files were created and obtain information about them by querying
# the INFORMATION_SCHEMA.FILES table.
#
# For example:
#
# 		SELECT FILE_NAME, LOGFILE_GROUP_NUMBER, EXTRA
# 		FROM INFORMATION_SCHEMA.FILES
# 		WHERE LOGFILE_GROUP_NAME = 'lg_3';
# 		+-------------+------------------------------+-------------------+
# 		| FILE_NAME   | LOGFILE_GROUP_NUMBER 			| EXTRA 				  |
# 		+-------------+------------------------------+-------------------+
# 		| newdata.dat | 	0 									| CLUSTER_NODE=3    |
# 		| newdata.dat | 	0 									| CLUSTER_NODE=4 	  |
# 		| undo_10.dat | 	11 								| CLUSTER_NODE=3    |
# 		| undo_10.dat | 	11 								| CLUSTER_NODE=4	  |
# 		+-------------+------------------------------+-------------------+
#
# (See SECTION 25.10, "THE INFORMATION_SCHEMA FILES TABLE")
#
# Memory used for UNDO_BUFFER_SIZE comes from the global pool whose size is determined
# by the value of the SharedGlobalMemory data node configuration parameter.
#
# This includes any default value implied for this option by the setting of the
# InitialLogFileGroup data node configuration parameter.
#
# ALTER_LOGFILE_GROUP is useful only with Disk Data storage for NDB Cluster.
# For more information, see SECTION 22.5.13, "NDB CLUSTER DISK DATA TABLES"
#
# 13.1.7 ALTER PROCEDURE SYNTAX
#
# ALTER PROCEDURE proc_name [characteristic ---]
#
# characteristic:
# 		COMMENT 'string'
# 	 | LANGUAGE SQL
# 	 | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }
# 	 | SQL SECURITY { DEFINER | INVOKER }
#
# This statement can be used to change the characteristics of a stored procedure.
#
# More than one change may be specified in an ALTER_PROCEDURE statement.
#
# However, you cannot change the parameters or body of a stored procedure
# using this statement; to make such changes, you must drop and re-create
# the procedure using DROP_PROCEDURE and CREATE_PROCEDURE.
#
# You must have the ALTER_ROUTINE privilege for the procedure.
#
# By default, that privilege is granted automatically to the procedure creator.
#
# This behavior can be changed by disabling the automatic_sp_privileges system 
# variable.				
#
# See SECTION 24.2.2, "STORED ROUTINES AND MYSQL PRIVILEGES"
#
# 13.1.8 ALTER SERVER SYNTAX
#
# ALTER SERVER server_name
# 		OPTIONS (option [, option] ---)
#
# Alters the server information for server_name, adjusting any of the options
# permitted in the CREATE_SERVER statement.
#
# The corresponding fields in the mysql.servers table are updated accordingly.
#
# This statement requires the SUPER privilege.
#
# For example, to update the USER option:
#
# 		ALTER SERVER s OPTIONS (USER 'sally');
#
# ALTER SERVER causes an implicit commit. See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# ALTER SERVER is not written to the binary log, regardless of the logging format that
# is in use.
#
# 13.1.9 ALTER TABLE SYNTAX
#
# 13.1.9.1 ALTER TABLE PARTITION OPERATIONS
# 13.1.9.2 ALTER TABLE AND GENERATED COLUMNS
# 13.1.9.3 ALTER TABLE EXAMPLES
#
# 		ALTER TABLE tbl_name
# 			[alter_specification [, alter_specification] ---]
# 			[partition_options]
#
# 		alter_specification:
# 			table_options
# 		 | ADD [COLUMN] col_name column_definition
# 				 [FIRST | AFTER col_name]
# 		 | ADD [COLUMN] (col_name column_definition ---)
# 		 | ADD {INDEX|KEY} [index_name]
# 				 [index_type] (key_part, ---) [index_option] ---
# 		 | ADD [CONSTRAINT [symbol]] PRIMARY KEY
# 				 [index_type] (key_part, ---) [index_option] ---
# 		 | ADD [CONSTRAINT [symbol]]
# 				 UNIQUE [INDEX|KEY] [index_name]
# 				 [index_type] (key_part, ---) [index_option] ---
# 		 | ADD FULLTEXT [INDEX|KEY] [index_name]
# 				(key_part,---) [index_option] ---
# 		 | ADD SPATIAL [INDEX|KEY] [index_name]
# 				(key_part,---) [index_option] ---
# 		 | ADD [CONSTRAINT [symbol]]
# 				FOREIGN KEY [index_name] (col_name, ---)
# 				reference_definition
# 		 | ALGORITHM [=] {DEFAULT|INSTANT|INPLACE|COPY}
# 		 | ALTER [COLUMN] col_name {SET DEFAULT literal | DROP DEFAULT}
# 		 | ALTER INDEX index_name {VISIBLE | INVISIBLE}
# 		 | CHANGE [COLUMN] old_col_name new_col_name column_definition
# 				[FIRST|AFTER col_name]
# 		 | [DEFAULT] CHARACTER SET [=] charset_name [COLLATE [=] collation_name]
# 		 | CONVERT TO CHARACTER SET charset_name [COLLATE collation_name]
# 		 | {DISABLE|ENABLE} KEYS
# 		 | {DISCARD|IMPORT} TABLESPACE
# 		 | DROP [COLUMN] col_name
# 		 | DROP {INDEX|KEY} index_name
# 		 | DROP PRIMARY KEY
# 		 | DROP FOREIGN KEY fk_symbol
# 		 | FORCE
# 		 | LOCK [=] {DEFAULT|NONE|SHARED|EXCLUSIVE}
# 		 | MODIFY [COLUMN] col_name column_definition
# 				[FIRST | AFTER col_name]
# 		 | ORDER BY col_name [, col_name] ---
# 		 | RENAME COLUMN old_col_name TO new_col_name
# 		 | RENAME {INDEX|KEY} old_index_name TO new_index_name
# 		 | RENAME [TO|AS] new_tbl_name
# 		 | {WITHOUT|WITH} VALIDATION
# 		 | ADD PARTITION (partition_definition)
# 		 | DROP PARTITION partition_names
# 		 | DISCARD PARTITION {partition_names | ALL} TABLESPACE
# 		 | IMPORT PARTITION {partition_names | ALL} TABLESPACE
# 		 | TRUNCATE PARTITION {partition_names | ALL}
# 		 | COALESCE PARTITION number
# 		 | REORGANIZE PARTITION partition_names INTO (partition_definitions)
# 		 | EXCHANGE PARTITION partition_name WITH TABLE tbl_name [{WITH|WITHOUT} VALIDATION]
# 		 | ANALYZE PARTITION {partition_names | ALL}
# 		 | CHECK PARTITION {partition_names | ALL}
# 		 | OPTIMIZE PARTITION {partition_names | ALL}
# 		 | REBUILD PARTITION {partition_names | ALL}
# 		 | REPAIR PARTITION {partition_names | ALL}
# 		 | REMOVE PARTITIONING
# 		 | UPGRADE PARTITIONING
#
# 		key_part: {col_name [(length)] | (expr)} [ASC | DESC]
#
# 		index_type:
# 			USING {BTREE | HASH}
#
# 		index_option:
# 			KEY_BLOCK_SIZE [=] value
# 		 | index_type
# 		 | WITH PARSER parser_name
# 		 | COMMENT 'string'
# 		 | {VISIBILE | INVISIBLE}
#
# 		table_options:
# 			table_option [[,] table_option] ---
#
# 		table_option:
# 			AUTO_INCREMENT [=] value
# 		 | AVG_ROW_LENGTH [=] value
# 		 | [DEFAULT] CHARACTER SET [=] charset_name
# 		 | CHECKSUM [=] {0 | 1}
# 		 | [DEFAULT] COLLATE [=] collation_name
# 		 | COMMENT [=] 'string'
# 		 | COMPRESSION [=] {'ZLIB'|'LZ4'|'NONE'}
# 		 | CONNECTION [=] 'connect_string'
# 		 | {DATA|INDEX} DIRECTORY [=] 'absolute path to directory'
# 		 | DELAY_KEY_WRITE [=] {0 | 1}
# 		 | ENCRYPTION [=] {'Y' | 'N'}
# 		 | ENGINE [=] engine_name
# 		 | INSERT_METHOD [=] { NO | FIRST | LAST }
# 		 | KEY_BLOCK_SIZE [=] value
# 		 | MAX_ROWS [=] value
# 		 | MIN_ROWS [=] value
# 		 | PACK_KEYS [=] {0 | 1 | DEFAULT}
# 		 | PASSWORD [=] 'string'
# 		 | ROW_FORMAT [=] {DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT|COMPACT}
# 		 | STATS_AUTO_RECALC [=] {DEFAULT|0|1}
# 		 | STATS_PERSISTENT [=] {DEFAULT|0|1}
# 		 | STATS_SAMPLE_PAGES [=] value
# 		 | TABLESPACE tablespace_name [STORAGE {DISK|MEMORY|DEFAULT}]
# 		 | UNION [=] (tbl_name[,tbl_name] ---)
#
# 		partition_options:
# 			(see CREATE TABLE options)
#
# ALTER_TABLE changes the structure of a table. For example, you can add or delete columns,
# create or destroy indexes, change the type of existing columns, or rename columns
# or the table itself.
#
# You can also change characteristics such as the storage engine used for the table or the
# table comment.
#
# 		) To use ALTER_TABLE, you need ALTER, CREATE and INSERT privileges for the table.
#
# 			Renaming a table requires ALTER and DROP on the old table, ALTER, CREATE, and
# 			INSERT on the new table.
#
# 		) Following the table name, specify the alterations to be made. If none are given, ALTER_TABLE does nothing.
#
# 		) The syntax for many of the permissible alterations is similar to clauses of the CREATE_TABLE statement.
#
# 			column_definition clauses use the same syntax for ADD and CHANGE as for CREATE_TABLE 
#
# 			For more information, see SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# 		) The word COLUMN is optional and can be omitted, except for RENAME COLUMN (to distinguish a column-renaming
# 			operation from the RENAME table-renaming operation)
#
# 		) Multiple ADD, ALTER, DROP, and CHANGE clauses are permitted in a single ALTER_TABLE statement,
# 			separated by commas.
#
# 			This is a MySQL extension to standard SQL, which permits only one of each clause per ALTER_TABLE
# 			statement.
#
# 			For example, to drop multiple columns in a single statement, do this:
#
# 				ALTER TABLE t2 DROP COLUMN c, DROP COLUMN d;
#
# 		) If a storage engine does not support an attempted ALTER_TABLE operation, a warning may result.
#
# 		Such warnings can be displayed with SHOW_WARNINGS.
#
# 		See SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# 		For information on troubleshooting ALTER_TABLE, see SECTION B.6.6.1, "PROBLEMS WITH ALTER TABLE"
#
# 		) For information about generated columns, see SECTION 13.1.9.2, "ALTER TABLE AND GENERATED COLUMNS"
#
# 		) For usage examples, see SECTION 13.1.9.3, "ALTER TABLE EXAMPLES"
#
# 		) With the mysql_info() C API function, you can find out how many rows were copied by ALTER_TABLE.
#
# 			See SECTION 28.7.7.36, "MYSQL_INFO()"
#
# There are several additional aspects to the ALTER TABLE statement, described under the following
# topics in this section:
#
# 		) TABLE OPTIONS
#
# 		) PERFORMANCE AND SPACE REQUIREMENTS
#
# 		) CONCURRENCY CONTROL
#
# 		) ADDING AND DROPPING COLUMNS
#
# 		) RENAMING, REDEFINING, AND REORDERING COLUMNS
#
# 		) PRIMARY KEYS AND INDEXES
#
# 		) FOREIGN KEYS
#
# 		) CHANGING THE CHARACTER SET
#
# 		) DISCARDING AND IMPORTING INNODB TABLESPACES
#
# 		) ROW ORDER FOR MYISAM TABLES
#
# 		) PARTITIONING OPTIONS
#
# TABLE OPTIONS
#
# table_options signifies table options of the kind that can be used in the CREATE_TABLE
# statement, such as ENGINE, AUTO_INCREMENT, AVG_ROW_LENGTH, MAX_ROWS, ROW_FORMAT or TABLESPACE.
#
# For descriptions of all table options, see SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# However, ALTER_TABLE ignores DATA DIRECTORY and INDEX DIRECTORY when given as table options.
#
# ALTER_TABLE permits them only as partitioning options, and requires that you have the FILE privilege.
#
# Use of table options with ALTER_TABLE provides a convenient way of altering single table characteristics.
#
# For example:
#
# 		) If t1 is currently not an InnoDB table, this statement changes its storage engine to InnoDB:
#
# 			ALTER TABLE t1 ENGINE = InnoDB;
#
# 			) See SECTION 15.6.1.3, "CONVERTING TABLES FROM MYISAM TO INNODB" for considerations when switching
# 				tables to the InnoDB storage engine.
#
# 			) When you specify an ENGINE clause, ALTER_TABLE rebuilds the table.
#
# 				This is true even if the table already has the specified storage engine.
#
# 			) Running ALTER_TABLE_tbl_name_ENGINE=INNODB on an existing InnoDB table performs
# 				a "null" ALTER_TABLE operation, which can be used to defragment an InnoDB table,
# 				as described in SECTION 15.11.4, "DEFRAGMENTING A TABLE"
#
# 				Running ALTER_TABLE_tbl_name_FORCE on an InnoDB table performs the same function
#
# 			) ALTER_TABLE_tbl_name_ENGINE=INNODB and ALTER_TABLE_tbl_name_FORCE use online DDL.
#
# 				For more information, see SECTION 15.12, "INNODB AND ONLINE DDL"
#
# 			) The outcome of attempting to change the storage engine of a table is affected
# 				by whether the desired storage engine is available and the setting of the
# 				NO_ENGINE_SUBSTITUTION SQL mode, as described in SECTION 5.1.11, "SERVER SQL MODES"
#
# 			) To prevent inadvertent loss of data, ALTER_TABLE cannot be used to change the storage
# 				engine of a table to MERGE or BLACKHOLE
#
# 		) To change the InnoDB table to use compressed row-storage format:
#
# 			ALTER TABLE t1 ROW_FORMAT = COMPRESSED;
#
# 		) To enable or disable encryption for an InnoDB table in a file-per-table tablespace:
#
# 			ALTER TABLE t1 ENCRYPTION='Y';
# 			ALTER TABLE t1 ENCRYPTION='N';
#
# 			A keyring plugin must be installed and configured to use the ENCRYPTION option.
#
# 			For more information, see SECTION 15.6.3.9, "TABLESPACE ENCRYPTION"
#
# 		) To reset the current auto-increment value:
#
# 			ALTER TABLE t1 AUTO_INCREMENT = 13;
#
# 			You cannot reset the counter to a value less than or equal to the value that is
# 			currently in use.
#
# 			For both InnoDB and MyISAM, if the value is less than or equal to the maximum value
# 			currently in the AUTO_INCREMENT column, the value is reset to the current maximum
# 			AUTO_INCREMENT column value plus one.
#
# 		) To change the default table character set:
#
# 			ALTER TABLE t1 CHARACTER SET = utf8;
#
# 			See also CHANGING THE CHARACTER SET
#
# 		) To add(or change) a table comment:
#
# 			ALTER TABLE t1 COMMENT = 'New table comment';
#
# 		) Use ALTER TABLE with the TABLESPACE option to move InnoDB tables between existing
# 			general tablespaces, file-per-table tablespaces, and the system tablespace.
#
# 			See MOVING TABLES BETWEEN TABLESPACES USING ALTER TABLE
#
# 			) ALTER TABLE --- TABLESPACE operations always cause a full table rebuild, even if
# 				the TABLESPACE attribute has not changed from its previous value.
#
# 			) ALTER TABLE --- TABLESPACE syntax does not support moving a table from a temporary
# 				tablespace to a persistent tablespace.
#
# 			) The DATA DIRECTORY clause, which is supported with CREATE_TABLE_---_TABLESPACE,
# 				is not supported with ALTER TABLE --- TABLESPACE, and is ignored if specified.
#
# 			) For more information about the capabilities and limitations of the TABLESPACE option, see CREATE_TABLE
#
# 		) MySQL NDB Cluster 8.0 supports setting NDB_TABLE options for controlling a table's partition balance
# 			(fragment count type), read-from-any-replica capability, full replication, or any combination of these,
# 			as part of the table comment for an ALTER TABLE statement in the same manner as for CREATE_TABLE,
# 			as shown in this example:
#
# 				ALTER TABLE t1 COMMENT = "NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RA_BY_NODE";
#
# 			Bear in mind that ALTER TABLE --- COMMENT --- discards any existing comment for the table.
#
# 			See SETTING NDB_TABLE OPTIONS, for additional information and examples.
#
# To verify that the table options were changed as intended, use SHOW_CREATE_TABLE,
# or query the INFORMATION_SCHEMA.TABLES table.
#
# PERFORMANCE AND SPACE REQUIREMENTS
#
# ALTER_TABLE operations are processed using one of the following algorithms:
#
# 		) COPY: Operations are performed on a copy of the original table, and table data is copied
# 			from the original table to the new table row by row.
#
# 			Concurrent DML is not permitted.
#
# 		) INPLACE: Operations avoid copying table data but may rebuild the table in place.
#
# 			An exclusive metadata lock on the table may be taken briefly during preparation and
# 			execution phases of the operation.
#
# 			Typically, concurrent DML is supported.
#
# 		) INSTANT: Operations only modify metadata in the data dictionary.
#
# 			No exclusive metadata locks are taken on the table during preparation and execution,
# 			and table data is unaffected, making operations instantaneous.
#
# 			Concurrent DML is permitted. (Introduced in MySQL 8.0.12)
#
# The ALGORITHM clause is optional. If the ALGORITHM clause is omitted, MySQL uses ALGORITHM=INSTANT
# for storage engines and ALTER_TABLE clauses that support it.
#
# Otherwise, ALGORITHM=INPLACE is used. If ALGORITHM=INPLACE is not supported,
# ALGORITHM=COPY is used.
#
# Specifying an ALGORITHM clause requires the operation to use the specified algorithm for clauses
# and storage engines that support it, or fail with an error otherwise.
#
# Specifying ALGORITHM=DEFAULT is the same as omitting the ALGORITHM clause.
#
# ALTER_TABLE operations that use the COPY algorithm wait for other operations that
# are modifying the table to complete.
#
# After alterations are applied to the table copy, data is copied over, the original
# table is deleted, and the table copy is renamed to the name of the original table.
#
# While the ALTER_TABLE operation executes, the original table is readable by other
# sessions (with the exception noted shortly)
#
# Updates and writes to the table started after the ALTER_TABLE operation begins are
# stalled until the new table is ready, then are automatically redirected to the new table.
#
# The temporary copy of the table is created in the database directory of the original
# table unless it is a RENAME TO operation that moves the table to a database that 
# resides in a different directory.
#
# The exception referred to earlier is that ALTER_TABLE blocks reads (not just writes)
# at the point where it is ready to clear outdated table structures from the table and
# table definition caches.
#
# At this point, it must acquire an exclusive lock.
#
# To do so, it waits for the current readers to finish, and blocks new reads and writes.
#
# An ALTER_TABLE operation that uses the COPY algorithm prevents concurrent DML operations.
#
# Concurrent queries are still allowed. That is, a table-copying operationg always includes
# at least the concurrency restrictions of LOCK=SHARED (allow queries but not DML)
#
# You can further restrict concurrency for operations that support the LOCK clause
# by specifying LOCK=EXCLUSIVE, which prevents DML and queries.
#
# For more information, see CONCURRENCY CONTROL
#
# To force use of the COPY algorithm for an ALTER_TABLE operation that would otherwise
# not use it, specify ALGORITHM=COPY or enable the old_alter_table system variable.
#
# If there is a conflict between the old_alter_table setting and an ALGORITHM
# clause with a value other than DEFAULT, the ALGORITHM clause takes precedence.
#
# For InnnoDB tables, an ALTER_TABLE operation that uses the COPY algorithm on a table
# that resides in a shared tablespace can increase the amount of space used by the tablespace.
#
# Such operations require as much additional space as the data in the table plus indexes.
#
# For a table residing in a shared tablespace, the additional space used during the operation
# is not released back to the operating system as it is for a table that resides in a file-per-table
# tablespace.
#
# For information about space requirements for online DDL operations, see SECTION 15.12.3, "ONLINE DDL SPACE REQUIREMENTS"
#
# ALTER_TABLE operations that support the INPLACE algorithm include:
#
# 		) ALTER TABLE operations supported by the InnoDB online DDL feature. See SECTION 15.12.1, "ONLINE DDL OPERATIONS"
#
# 		) Renaming a table. MySQL renames files that correspond to the table tbl_name without making a copy.
#
# 			(You can also use the RENAME_TABLE statement to rename tables. See SECTION 13.1.36, "RENAME TABLE SYNTAX")
#
# 			Privileges granted specifically for the renamed table are not migrated to the new name.
#
# 			They must be changed manually.
#
# 		) Operations that only modify table metadata. These operations are immediate because the server does
# 			not touch table contents.
#
# 			Metadata-only operations include:
#
# 			) Renaming a column
#
# 			) Changing the default value of a column (except for NDB tables)
#
# 			) Modifying the definition of an ENUM or SET column by adding new enumeration or set members
# 				to the end of the list of valid member values, as long as the storage size of the data
# 				type does not change.
#
# 				For example, adding a member to a SET column that has 8 members changes the required
# 				storage per value from 1 byte to 2 bytes; this requires a table copy.
#
# 				Adding members in the middle of the list causes renumbering of existing members,
# 				which requires a table copy.
#
# 			) Changing the definition of a spatial column to remove the SRID attribute.
#
# 				(Adding or changing an SRID attribute does require a rebuild and cannot be done
# 				in place because the server must verify that all values have the specified SRID value)
#
# 			) As of MySQL 8.0.14, changing a column character set, when these conditions apply:
#
# 				) The column data type is CHAR, VARCHAR, a TEXT type or ENUM
#
# 				) The character set change is from utf8mb3 to utf8mb4, or any character set to binary.
#
# 				) There is no index on the column.
#
# 			) As of MySQL 8.0.14, changing a generated column, when these conditions apply:
#
# 				) For InnoDB tables, statements that modify generated stored columns but do not change
# 					their type, expression, or nullability.
#
# 				) For non-InnoDB tables, statements that modify generated stored or virtual columns but do not
# 					change their type, expression or nullability.
#
# 				An example of such a change is a change to the column comment.
#	
# 			) Renaming an index
#
# 			) Adding or dropping a secondary index, for InnoDB and NDB tables. See SECTION 15.12.1, "ONLINE DDL OPERATIONS"
#
# 			) For NDB tables, operations that add and drop indexes on variable-width columns.
#
# 				These operations occur online, without table copying and without blocking concurrent
# 				DML actions for most of their duration.
#
# 				See SECTION 22.5.14, "ONLINE OPERATIONS WITH ALTER TABLE IN NDB CLUSTER"
#
# 			) Modifying index visibility with an ALTER INDEX operation
#
# 			) Column modifications of tables containing generated columns that depend on columns with a DEFAULT
# 				value if the modified columns are not involved in the generated column expressions.
#
# 				For example, changing the NULL property of a separate column can be done in place without a table rebuild.
#
# 		ALTER TABLE operations that support the INSTANT algorithm include:
#
# 			) Adding a column. This feature is referred to as "INSTANT ADD COLUMN"
#
# 				Limitations apply. See SECTION 15.12.1, "ONLINE DDL OPERATIONS"
#
# 			) Adding or dropping a virtual column
#
# 			) Adding or dropping a column default value
#
# 			) Modifying the definition of an ENUM or SET column. 
#
# 				The same restrictions apply as described above for ALGORITHM=INSTANT
#
# 			) Changing the index type
#
# 			) Renaming a table. The same restrictions apply as described above for ALGORITHM=INSTANT
#
# For more information about operations that support ALGORITHM=INSTANT, see SECTION 15.12.1, "ONLINE DDL OPERATIONS"
#
# ALTER_TABLE upgrades MySQL 5.5 temporal columns to 5.6 format for ADD COLUMN, CHANGE COLUMN, MODIFY COLUMN,
# ADD INDEX and FORCE operations.
#
# This conversion cannot be done using the INPLACE algorithm because the table must be rebuilt,
# so specifying ALGORITHM=INPLACE in these cases results in an error.
#
# Specify ALGORITHM=COPY if necessary.
#
# If an ALTER TABLE operation on a multicolumn index used to partition a table by KEY changes
# the order of the columns, it can only be performed using ALGORITHM=COPY
#
# The WITHOUT VALIDATION and WITH VALIDATION clauses affect whether ALTER_TABLE performs an
# in-place operation for virtual generated column modifications.
#
# See SECTION 13.1.9.2, "ALTER TABLE AND GENERATED COLUMNS"
#
# NDB Cluster 8.0 supports online operations using the same ALGORITHM=INPLACE syntax used with
# the standard MySQL server.
#
# See SECTION 22.5.14, "ONLINE OPERATIONS WITH ALTER TABLE IN NDB CLUSTER", for more information.
#
# ALTER TABLE with DISCARD --- PARTITION --- TABLESPACE or IMPORT --- PARTITION --- TABLESPACE
# does not create any temporary tables or temporary partition files.
#
# ALTER TABLE with ADD PARTITION, DROP PARTITION, COALESCE PARTITION, REBUILD PARTITION,
# or REORGANIZE PARTITION does not create temporary tables (except when used with NDB tables);
#
# However, these operations can and do create temporary partition files.
#
# ADD or DROP operations for RANGE or LIST partitions are immediate operations or nearly so.
#
# ADD or COALESCE operations for HASH or KEY partitions copy data between all partitions;
# unless LINEAR HASH or LINEAR KEY was used; this is effectively the same as creating
# a new table, although the ADD or COALESCE operation is performed partition by partition.
#
# REORGANIZE operations copy only changed partitions and do not touch unchanged ones.
#
# For MyISAM tables, you can speed up index re-creation (the slowest part of the alteration
# process) by setting the myisam_sort_buffer_size system variable to a high value.
#
# CONCURRENCY CONTROL
#
# For ALTER_TABLE operations that support it, you can use the LOCK clause to control
# the level of concurrent reads and writes on a table while it is being altered.
#
# Specifying a non-default value for this clause enables you to require a certain amount
# of concurrent access or exclusivity during the alter operation, and halts the operation
# if the requested degree of locking is not available.
#
# Only LOCK = DEFAULT is permitted for operations that use ALGORITHM=INSTANT
#
# The other LOCK clause parameters are not applicable.
#
# The parameters for the LOCK clause are:
#
# 		) LOCK = DEFAULT
#
# 			Maximum level of concurrency for the given ALGORITHM clause (if any) and ALTER TABLE
# 			operation:
#
# 				Permit concurrent reads and writes if supported.
#
# 			If not, permit concurrent reads if supported.
#
# 			If not, enforce exclusive access.
#
# 		) LOCK = NONE
#
# 			If supported, permit concurrent reads and writes.
#
# 			Otherwise, an error occurs.
#
# 		) LOCK = SHARED
#
# 			If supported, permit concurrent reads but block writes.
#
# 			Writes are blocked even if concurrent writes are supported by the storage engine
# 			for the given ALGORITHM clause (if any) and ALTER TABLE operation.
#
# 			If concurrent reads are not supported, an error occurs.
#
# 		) LOCK = EXCLUSIVE
#
# 			Enforce exclusive access.
#
# 			This is done even if concurrent reads/writes are supported by the storage engine
# 			for the given ALGORITHM clause (if any) and ALTER TABLE operation.
#
# ADDING AND DROPPING COLUMNS
#
# Use ADD to add new columns to a table, and DROP to remove existing columns.
#
# DROP col_name is a MySQL extension to standard SQL.
#
# To add a column at a specific position within a table row, use FIRST or AFTER
# col_name.
#
# The default is to add the column last.
#
# If a table contains only one column, that column cannot be dropped.
#
# If what you intend is to remove the table, use the DROP_TABLE statement instead.
#
# If columns are dropped from a table, the columns are also removed from any index of
# which they are a part.
#
# If all columns that make up an index are dropped, the index is dropped as well.
#
# If you use CHANGE or MODIFY to shorten a column for which an index exists on the
# column, and the resulting column length is less than the index length, MySQL shortens
# the index automatically.
#
# For ALTER TABLE --- ADD, if the column has an expression default value that uses a 
# nondeterministic function, the statement may produce a warning or error.
#
# For details, see SECTION 17.1.3.6, "RESTRICTIONS ON REPLICATION WITH GTIDS"
#
# RENAMING, REDEFINING, AND REORDERING COLUMNS
#
# The CHANGE, MODIFY, RENAME COLUMN and ALTER clauses enable the names and definitions of
# existing columns to be altered.
#
# They have these comparative characteristics:
#
# 		) CHANGE:
#
# 			) Can rename a column and change its definition, or both
#
# 			) Has more capability than MODIFY or RENAME COLUMN, but at the expense of
# 				convenience for some operations.
#
# 				CHANGE requires naming the column twice if not renaming it, and requires
# 				respecifying the column definition if only renaming it.
#
# 			) With FIRST or AFTER, can reorder columns
#
# 		) MODIFY:
#
# 			) Can change a column definition but not its name.
#
# 			) More convenient than CHANGE to change a column definition without renaming it
#
# 			) With FIRST or AFTER, can reorder columns
#
# 		) RENAME COLUMN:
#
# 			) Can change a column name but not its definition
#
# 			) More convenient than CHANGE to rename a column without changing its definition
#
# 		) ALTER: Used only to change a column default value
#
# CHANGE is a MySQL extension to standard SQL. MODIFY and RENAME COLUMN are MySQL
# extensions for Oracle compatibility.
#
# To alter a column to change both its name and definition, use CHANGE, specifying
# the old and new names and the new definition.
#
# For example, to rename an INT NOT NULL column from a to b and change its definition
# to use the BIGINT data type while retaining the NOT NULL attribute, do this:
#
# 		ALTER TABLE t1 CHANGE a b BIGINT NOT NULL;
#
# To change a column definition but not its name, use CHANGE or MODIFY.
#
# With CHANGE, the syntax requires two column names, so you must specify
# the same name twice to leave the name unchanged.
#
# For example, to change the definition of column b, do this:
#
# 		ALTER TABLE t1 CHANGE b b INT NOT NULL;
#
# MODIFY is more convenient to change the definition without changing the name
# because it requires the column name only once:
#
# 		ALTER TABLE t1 MODIFY b INT NOT NULL;
#
# To change a column name but not its definition, use CHANGE or RENAME COLUMN.
#
# With CHANGE, the syntax requires a column definition, so to leave the definition
# unchanged, you must respecify the definition the column currently has.
#
# For example, to rename an INT NOT NULL column from b to a, do this:
#
# 		ALTER TABLE t1 CHANGE b a INT NOT NULL;
#
# RENAME COLUMN is more convenient to change the name without changing the definition
# because it requires only the old and new names:
#
# 		ALTER TABLE t1 RENAME COLUMN b TO a;
#
# In general, you cannot rename a column to a name that already exists in the table.
#
# However, this is sometimes not the case, such as when you swap names or move them
# through a cycle.
#
# If a table has columns named a,b and c, these are valid operations:
#
# 		-- swap a and b
# 		ALTER TABLE t1 RENAME COLUMN a TO b,
# 						   RENAME COLUMN b TO a;
# 		-- "rotate" a, b, c through a cycle
# 		ALTER TABLE t1 RENAME COLUMN a TO b,
# 							RENAME COLUMN b TO c,
# 							RENAME COLUMN c TO a;
#
# For column definition changes using CHANGE or MODIFY, the definition must include
# the data type and all attributes that should apply to the new column, other than
# index attributes such as PRIMARY KEY or UNIQUE.
#
# Attributes present in the original definition but not specified for the new definition
# are not carried forward.
#
# Suppose that a column col1 is defined as INT UNSIGNED DEFAULT 1 COMMENT 'my column'
# and you modify the column as follows, intending to change only INT to BIGINT:
#
# 		ALTER TABLE t1 MODIFY col1 BIGINT;
#
# That statement changes the data type from INT to BIGINT, but it also drops the UNSIGNED,
# DEFAULT and COMMENT attributes.
#
# To retain them, the statement must include them explicitly:
#
# 		ALTER TABLE t1 MODIFY col1 BIGINT UNSIGNED DEFAULT 1 COMMENT 'my column';
#
# For data type changes using CHANGE or MODIFY, MySQL tries to convert existing columns
# values to the new type as well as possible.
#
# WARNING:
#
# 		This conversion may result in alteration of data.
#
# 		For example, if you shorten a string column, values may be truncated.
#
# 		To prevent the operation from succeeding if conversions to the new data type
# 		would result in loss of data, enable strict SQL mode before using ALTER_TABLE
#
# 		(see SECTION 5.1.11, "SERVER SQL MODES")
#
# If you use CHANGE or MODIFY to shorten a column for which an index exists on the
# column, and the resulting column length is less than the index length, MySQL shortens
# the index automatically.
#
# For columns renamed by CHANGE or RENAME COLUMN, MySQL automatically renames these
# references to the renamed column:
#
# 		) Indexes that refer to the old column, including invisible indexes and disabled by MyISAM indexes.
#
# 		) Foreign keys that refer to the old column
#
# For columns renamed by CHANGE or RENAME COLUMN, MySQL does not automatically rename these references
# to the renamed column:
#
# 		) Generated column and partition expressions that refer to the renamed column.
#
# 			You must use CHANGE to redefine such expressions in the same ALTER_TABLE statement
# 			as the one that renames the column.
#
# 		) Views and stored programs that refer to the renamed column. 
#
# 			You must manually alter the definition of these objects to refer to the 
# 			new column name.
#
# To reorder columns within a table, use FIRST and AFTER in CHANGE or MODIFY operations.
#
# ALTER --- SET DEFAULT or ALTER --- DROP DEFAULT specify a new default value for a column
# or remove the old default value, respectively.
#
# If the old default is removed and the column can be NULL, the new default is NULL.
#
# If the column cannot be NULL, MySQL assigns a default value as described in SECTION 11.7,
# "DATA TYPE DEFAULT VALUES"
#
# PRIMARY KEYS AND INDEXES
#
# DROP PRIMARY KEY drops the primary key.
#
# If there is no primary key, an error occurs.
#
# For information about the performance characteristics of primary keys, especially
# for InnoDB tables, see SECTION 8.3.2, "PRIMARY KEY OPTIMIZATION"
#
# If you add a UNIQUE INDEX or PRIMARY KEY to a table, MySQL stores it before any
# nonunique index to permit detection of duplicate keys as early as possible.
#
# DROP_INDEX removes an index. This is a MySQL extension to standard SQL.
#
# See SECTION 13.1.27, "DROP INDEX SYNTAX"
#
# To determine index names, use SHOW INDEX FROM tbl_name
#
# Some storage engines permit you to specify an index type when creating an index.
#
# The syntax for the index_type specifier is USING type_name.
#
# For details about USING, see SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# The preferred position is after the column list. Support for use of the
# option before the column list will be removed in a future MySQL release.
#
# index_option values specify additional options for an index. USING is one such option.
#
# For details about permissible index_option values, see SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# RENAME INDEX old_index_name TO new_index_name renames an index.
#
# This is a MySQL extension to standard SQL. The content of the table remains unchanged.
#
# old_index_name must be the name of an existing index in the table that is not dropped
# by the same ALTER_TABLE statement.
#
# new_index_name is the new index name, which cannot duplicate the name of an index
# in the resulting table after changes have been applied.
#
# Neither index name can be PRIMARY.
#
# If you use ALTER_TABLE on a MyISAM table, all nonunique indexes are created in a 
# separate batch (as for REPAIR_TABLE)
#
# This should make ALTER_TABLE much faster when you have many indexes.
#
# For MyISAM tables, key updating can be controlled explicitly. Use ALTER TABLE --- DISABLE KEYS
# to tell MySQL to stop updating nonunique indexes.
#
# Then use ALTER TABLE --- ENABLE KEYS to re-create missing indexes.
#
# MyISAM does this with a special algorithm that is much faster than inserting keys
# one by one, so disabling keys before performing bulk insert operations should give a 
# considerable speedup.
#
# Using ALTER TABLE --- DISABLE KEYS requires the INDEX privilege in addition to the
# privileges mentioned earlier.
#
# While the nonunique indexes are disabled, they are ignored for statements such as
# SELECT and EXPLAIN that otherwise would use them.
#
# After an ALTER_TABLE statement, it may be necessary to run ANALYZE_TABLE to update
# index cardinality information.
#
# See SECTION 13.7.6.22, "SHOW INDEX SYNTAX"
#
# The ALTER INDEX operation permits an index to be made visible or invisible.
#
# An invisible index is not used by the optimizer.
#
# Modification of index visibility applies to indexes other than primary keys
# (either explicit or implicit)
#
# This feature is storage engine neutral (supported for any engine)
#
# FOr more information, see SECTION 8.3.12, "INVISIBLE INDEXES"
#
# FOREIGN KEYS
#
# The FOREIGN KEY and REFERENCES clauses are suppported by the InnoDB and NDB
# storage engines, which implement ADD [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (---) REFERENCES --- (---)
#
# See SECTION 15.6.1.5, "InnoDB AND FOREIGN KEY CONSTRAINTS"
#
# For other storage engines, the clauses are parsed but ignored.
#
# The CHECK clause is parsed but ignored by all storage engines.
#
# See SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# The reason for accepting but ignoring syntax clauses is for compatibility,
# to make it easier to port code from other SQL servers, and to run applications
# that create tables with references.
#
# See SECTION 1.8.2, "MYSQL DIFFERENCES FROM STANDARD SQL"
#
# For ALTER_TABLE, unlike CREATE_TABLE, ADD FOREIGN KEY ignores index_name if given
# and uses an automatically generated foreign key name.
#
# As a workaround, include the CONSTRAINT clause to specify the foreign key name:
#
# 		ADD CONSTRAINT name FOREIGN KEY (---) ---
#
# IMPORTANT:
#
# 		MySQL silently ignores inline REFERENCES specifications, where the references
# 		are defined as part of the column specification.
#
# 		MySQL accepts only REFERENCES clauses defined as part of a separate FOREIGN KEY specification.
#
# NOTE:
#
# 		Partitioned InnoDB tables do not support foreign keys.
#
# 		This restriction does not apply to NDB tables, including those explicitly partitioned
# 		by [LINEAR] KEY
#
# 		For more information, see SECTION 23.6.2, "PARTITIONING LIMITATIONS RELATING TO STORAGE ENGINES"
#
# MySQL Server and NDB Cluster both support the use of ALTER_TABLE to drop foreign keys:
#
# 		ALTER TABLE tbl_name DROP FOREIGN KEY fk_symbol;
#
# Adding and dropping a foreign key in the same ALTER_TABLE statement is supported for ALTER_TABLE_---_ALGORITHM=INPLACE
# but not for ALTER_TABLE_---_ALGORITHM=COPY
#
# The server prohibits changes to foreign key columns that have the potential to cause loss of referential
# integrity.
#
# It also prohibits changes to the data type of such columns that may be unsafe.
#
# For example, changing VARCHAR(20) to VARCHAR(30) is permitted, but changing it to
# VARCHAR(1024) is not - because that alters hte number of length bytes required to store
# individual values.
#
# A workaround is to use ALTER_TABLE_---_DROP_FOREIGN_KEY before changing the column
# definition and ALTER_TABLE_---_ADD_FOREIGN_KEY afterward.
#
# ALTER TABLE tbl_name RENAME new_tbl_name changes internally generated foreign key
# constraint names and user-defined foreign key constraint names that contain the string
# "tbl_name_ibfk_" to reflect the new table name.
#
# InnoDB interprets foreign key constraint names that contain the string "tbl_name_ibfk_"
# as internally generated names.
#
# CHANGING THE CHARACTER SET
#
# To change the table default character set and all character columns (CHAR, VARCHAR, TEXT)
# to a new character set, use a statement like this:
#
# 		ALTER TABLE tbl_name CONVERT TO CHARACTER SET charset_name;
#
# The statement also changes the collation of all character columns.
#
# If you specify no COLLATE clause to indicate which collation to use, the statement
# uses default collation for the character set.
#
# If this collation is inappropriate for the intended table use (for example, if it would
# change from a case-sensitive collation to a case-insensitive collation), specify
# a collation explicitly.
#
# For a column that has a data type of VARCHAR or one of the TEXT types, CONVERT TO CHARACTER SET
# changes the data type as necessary to ensure that the new column is long
# enough to store as many chars as the original column.
#
# For example, a TEXT column has two length bytes, which stores the byte-length of values in the
# column, up to a maximum of 65,535
#
# For a latin1 TEXT column, each character requires a single byte, so the column can store up to
# 65,535 characters
#
# If the column is converted to utf8, each char might require up to three bytes, for a maximum
# possible length of 3 x 65,535 = 196,605 bytes.
#
# That length does not fit in a TEXT column's length bytes, so MySQL converts
# the data type to MEDIUMTEXT, which is the smallest string type for which the length
# bytes can record a value of 196,605.
#
# Similarly, a VARCHAR column might be converted to MEDIUMTEXT
#
# To avoid data type changes of the type just described, do not use CONVERT TO CHARACTER SET
# 
# Instead, use MODIFY to change individual columns. for example:
#
# 		ALTER TABLE t MODIFY latin1_text_col TEXT CHARACTER SET utf8;
# 		ALTER TABLE t MODIFY latin1_varchar_col VARCHAR(M) CHARACTER SET utf8;
#
# If you specify CONVERT TO CHARACTER SET binary, the CHAR, VARCHAR and TEXT columns are converted
# to their corresponding binary string types (BINARY, VARBINARY, BLOB)
#
# This means that the columns no longer will have a character set and a subsequent CONVERT TO
# operation will not apply to them.
#
# If charset_name is DEFAULT in a CONVERT TO CHARACTER SET operation, the character set named
# by the character_set_database system variable is used.
#
# WARNING:
#
# 		The CONVERT TO operation converts column values between the original and named character sets.
#
# 		This is not what  you want, if you have a column in one character set (like latin1) but the
# 		stored values actually use some other, incompatible character set (like utf8).
#
# 		In this case, you have to do the following for each such column:
#
# 			ALTER TABLE t1 CHANGE c1 c1 BLOB;
# 			ALTER TABLE t1 CHANGE c1 c1 TEXT CHARACTER SET utf8;
#
# 		The reason this works, is that there is no conversion when you convert to or from BLOB columns.
#
# To change only the default character set for a table, use this statement:
#
# 		ALTER TABLE tbl_name DEFAULT CHARACTER SET charset_name;
#
# THe word DEFAULT is optional. The default character set is the character set that is
# used if you do not specify the char set for columns that you add to a table later 
# (for example, with ALTER TABLE --- ADD column)
#
# When the foreign_key_checks system variable is enabled, which is the default string, character set
# conversion is not permitted on tables that include a character string column used in a
# foreign key constraint.
#
# The workaround is to disable foreign_key_checks before performing the character set conversion.
#
# You must perform the conversion on both tables involved in the foreign key constraint
# before re-enabling foreign_key_checks
#
# If you re-enable foreign_key_checks after converting only one of the tables, an ON DELETE
# CASCADE or ON UPDATE CASCADE operation could corrupt data in the referencing table due to
# implicit conversion that occurs during these operations.
#
# (Bug #45290, Bug #74816)
#
# DISCARDING AND IMPORTING INNODB TABLESPACES
#
# An InnoDB table created in its own file-per-table tablespace can be discarded and imported
# using the DISCARD TABLESPACE and IMPORT TABLESPACE options
#
# These options can be used to import a file-per-table tablespace from a backup or to copy
# a file-per-table tablespace from one database server to another.
#
# See SECTION 15.6.3.7, "COPYING TABLESPACES TO ANOTHER INSTANCE"
#
# ROW ORDER FOR MYISAM TABLES
#
# ORDER BY enables you to create the new table with the rows in a specific order.
#
# This option is useful primarily when you know that you query the rows in a certain
# order most of the time.
#
# By using this option after major changes to the table, you might be able to get higher
# performance.
#
# In some cases, it might make sorting easier for MySQL if the table is in order by the
# column that you want to order it by later.
#
# NOTE:
#
# 		The table does not remain in the specified order after inserts and deletes
#
# ORDER BY syntax permits one or more column names to be specified for sorting, each of which
# optionally can be followed by ASC or DESC to indicate ascending or descending sort order,
# respectively.
#
# The default is ascending order. 
#
# Only column names are permitted as sort criteria; 
# arbitrary expressions are not permitted.
#
# This clause should be given last after any other clauses.
#
# ORDER BY does not make sense for InnoDB tables because InnoDB always
# orders table rows according to the clustered index.
#
# When used on a partitioned table, ALTER TABLE --- ORDER BY orders
# rows within each partition only.
#
# PARTITIONING OPTIONS
#
# partition_options signifies options that can be used with partitioned tables 
# for reparatitioning, to add, drop, discard, import, merge, and split partitions,
# and to perform partitioning maintenance.
#
# It is possible for an ALTER_TABLE statement to contain a PARTITION BY or 
# REMOVE PARTITIONING clause in an addition to other alter specifications,
# but the PARTITION BY or REMOVE PARTITIONING clause must be specified last
# after any other specifications.
#
# The ADD PARTITION, DROP PARTITION, DISCARD PARTITION, IMPORT PARTITION,
# COALESCE PARTITION, REORGANIZE PARTITION, EXCHANGE PARTITION, ANALYZE PARTITION,
# CHECK PARTITION and REPAIR PARTITION options cannot be combined with other
# alter specifications in a single ALTER TABLE, since the options just listed
# act on individual partitions.
#
# For more information about partition options, see SECTION 13.1.20, "CREATE TABLE SYNTAX"
# and SECTION 13.1.9.1, "ALTER TABLE PARTITION OPERATIONS"
#
# For information about and examples of ALTER TABLE --- EXCHANGE PARTITION statements,
# see SECTION 23.3.3, "EXCHANGING PARTITIONS AND SUBPARTITIONS WITH TABLES"
#
# 13.1.9.1 ALTER TABLE PARTITION OPERATIONS
#
# Partitioning-related clauses for ALTER_TABLE can be used with partitioned tables for
# reparationing, to add, drop, discard, import, merge, and split partitions,
# and to perform partitioning maintenance.
#
# 		) Simply using a partition_options clause with ALTER_TABLE on a partitioned table
# 			repartitions the table according to the partitioning scheme defined by the
# 			partition_options.
#
# 			This clause always begins with PARTITION BY, and follows the same syntax and other
# 			rules as apply to the partition_options clause for CREATE_TABLE (for more detailed information,
# 			see SECTION 13.1.20, "CREATE TABLE SYNTAX"), and can also be used to partition
# 			an existing table that is not already partitioned.
#
# 			For example, consider a (nonpartitioned) table defined as shown here:
#
# 				CREATE TABLE t1 (
# 					id INT,
# 					year_col INT
# 				);
#
# 			This table can be partitioned by HASH, using the id column as the partitioning key,
# 			into 8 partitions by means of this statement:
#
# 				ALTER TABLE t1
# 					PARTITION BY HASH(id)
# 					PARTITIONS 8;
#
# 			MySQL supports an ALGORITHM option with [SUB]PARTITION BY [LINEAR] KEY.ALGORITHM=1 causes
# 			the server to use the same key-hashing functions as MySQL 5.1 when comptuing
# 			the placement of rows in partitions;
#
# 			ALGORITHM=2 means that the server employs the key-hashing functions implemented
# 			and used by default for new KEY partitioned tables in MySQL 5.5 and later.
#
# 			(Partitioned tables created with the key-hashing functions employed in MySQL 5.5
# 			and later cannot be used by a MySQL 5.1 server)
#
# 			Not specifying the option has the same effect as using ALGORITHM=2
#
# 			This option is intended for use chiefly when upgrading or downgrading [LINEAR]
# 			KEY partitioned tables between 5.1 and later MySQL versions, or for creating
# 			tables partitioned by KEY or LINEAR KEY on a MySQL 5.5 or later server which
# 			can be used on a MySQL 5.1 server
#
# 			The table that results from using an ALTER TABLE --- PARTITION BY statement must
# 			follow the same rules as one created using CREATE TABLE --- PARTITION BY
#
# 			This includes the rules governing the relationship between any unique keys
# 			(including any primary key) that the table might have, and the column
# 			or columns used in the partitioning expression, as discussed in SECTION 23.6.1,
# 			"PARTITIONING KEYS, PRIMARY KEYS, AND UNIQUE KEYS"
#
# 			The CREATE TABLE --- PARTITION BY rules for specifying the number of partitions
# 			also apply to ALTER TABLE --- PARTITION BY
#
# 			The partition_definition clause for ALTER TABLE ADD PARTITION supports
# 			the same options as the clause of the same name for the CREATE_TABLE
# 			statement.
#
# 			(See SECTION 13.1.20, "CREATE TABLE SYNTAX", for the syntax and descriptions)
#
# 			Suppose that you have the partitioned table created as shown here:
#
# 				CREATE TABLE t1 (
# 					id INT,
# 					year_col INT
# 				)
# 				PARTITION BY RANGE (year_col) (
# 					PARTITION p0 VALUES LESS THAN (1991),
# 					PARTITION p1 VALUES LESS THAN (1995),
# 					PARTITION p2 VALUES LESS THAN (1999)
# 				);
#
# 			You can add a new partition p3 to this table for storing values
# 			less than 2002 as follows:
#
# 				ALTER TABLE t1 ADD PARTITION (PARTITION p3 VALUES LESS THAN (2002));
#
# 			DROP PARTITION can be used to drop one or more RANGE or LIST partitions.
#
# 			This statement cannot be used with HASH or KEY partitions; instead, use
# 			COALESCE PARTITION (see later in this section)
#
# 			Any data that was stored in the dropped partitions named in the
# 			partition_names list is discarded.
#
# 			For example, given the table t1 defined previously, you can drop
# 			the partitions named p0 and p1 as shown here:
#
# 				ALTER TABLE t1 DROP PARTITION p0, p1;
#
# 			NOTE:
#
#   			DROP PARTITION does not work with tables that use the NDB storage engine.
#
# 				See SECTION 23.3.1, "MANAGEMENT OF RANGE AND LIST PARTITIONS", and
# 				SECTION 22.1.7, "KNOWN LIMITATIONS OF NDB CLUSTER"
#
# 			ADD PARTITION and DROP PARTITION do not currently support IF [NOT] EXISTS
#
# 			The DISCARD_PARTITION_---_TABLESPACE and IMPORT_PARTITION_---_TABLESPACE options
# 			extend the Transportable Tablespace feature to individual InnoDB table partitions.
#
# 			Each InnoDB table partition has its own tablespace file (.idb file)
#
# 			The Transportable Tablespace feature makes it easy to copy the tablespaces
# 			from a running MySQL server instance to another running instance, or to
# 			perform a restore on the same instance.
#
# 			Both options take a comma-separated list of one or more partition names.
#
# 			For example:
#
# 				ALTER TABLE t1 DISCARD PARTITION p2, p3 TABLESPACE;
#
# 				ALTER TABLE t1 IMPORT PARTITION p2, p3 TABLESPACE;
#
# 			When running DISCARD_PARTITION_---_TABLESPACE and IMPORT_PARTITION_---_TABLESPACE
# 			on subpartitioned tables, both partition and subpartition names are
# 			allowed.
#
# 			When a partition name is specified, subpartitions of that partition are included.
#
# 			The Transportable Tablespace feature also supports copying or restoring partitioned
# 			InnoDB tables (all partitions at once)
#
# 			For additional information, see SECTION 15.6.3.7, "COPYING TABLESPACE TO ANOTHER INSTANCE",
# 			as well as, SECTION 15.6.3.7.1, "TRANSPORTABLE TABLESPACE EXAMPLES"
#
# 			Renames of partitioned tables are supported.
#
# 			You can rename individual partitions indirectly using ALTER TABLE --- REORGANIZE PARTITION;
# 			however, this operation copies the partition's data
#
# 			To delete rows from selected partitions, use the TRUNCATE PARTITION option.
#
# 			This option takes a list of one or more comma-separated partition names.
#
# 			Consider the table t1 created by this statement:
#
# 				CREATE TABLE t1 (
# 					id INT,
# 					year_col INT
# 				)
# 				PARTITION BY RANGE (year_col) (
# 					PARTITION p0 VALUES LESS THAN (1991),
# 					PARTITION p1 VALUES LESS THAN (1995),
# 					PARTITION p2 VALUES LESS THAN (1999),
# 					PARTITION p3 VALUES LESS THAN (2003),
# 					PARTITION p4 VALUES LESS THAN (2007)
# 				);
#
# 			To delete all rows from partition p0, use the following statement:
#
# 				ALTER TABLE t1 TRUNCATE PARTITION p0;
#
# 			The statement just shown has the same effect as the following DELETE statement:
#
# 				DELETE FROM t1 WHERE year_col < 1991;
#
# 			When truncating multiple partitions, the partitions do not have to be contiguous:
#
# 				This can greatly simplify delete operations on partitioned tables that would
# 				otherwise require very complex WHERE Conditions if done with DELETE statements.
#
# 				For example, this statement deletes all rows from partitions p1 and p3:
#
# 					ALTER TABLE t1 TRUNCATE PARTITION p1, p3;
#
# 				An equivalent DELETE statement is shown here:
#
# 					DELETE FROM t1 WHERE
# 						(year_col >= 1991 AND year_col < 1995)
# 						OR
# 						(year_col >= 2003 AND year_col < 2007);
#
# 				If you use the ALL keyword in place of the list of partition names,
# 				the statement acts on all table partitions.
#
# 				TRUNCATE PARTITION merely deletes rows; it does not alter the definition
# 				of the table itself, or of any of its partitions.
#
# 				To verify that the rows were dropped, check the INFORMATION_SCHEMA.PARTITIONS
# 				table, using a query such as this one:
#
# 					SELECT PARTITION_NAME, TABLE_ROWS
# 						FROM INFORMATION_SCHEMA.PARTITIONS
# 						WHERE TABLE_NAME = 't1';
#
# 				COALESCE PARTITION can be used with a table that is partitioned by HASH or KEY
# 				to reduce the number of partitions by number.
#
# 				Suppose that you have created table t2 as follows:
#
# 					CREATE TABLE t2 (
# 						name VARCHAR(30),
# 						started DATE
# 					)
# 					PARTITION BY HASH( YEAR(started) )
# 					PARTITIONS 6;
#
# 				To reduce the number of partitions used by t2 from 6 to 4, use hte following statement:
#
# 					ALTER TABLE t2 COALESCE PARTITION 2;
#
# 				The data contained in the last number partitions will be merged into the remaining partitions.
#
# 				In this case, partitions 4 and 5 will be merged into the first 4 partitions (0, 1, 2, 3)
#
# 				To change some but not all the partitions used by a partitioned table, you can use
# 				REORGANIZE PARTITIOn.
#
# 				This statement can be used in severel ways:
#
# 					) TO merge a set of partitions into a single partition.
#
# 						This is done by naming several partitions in the partition_names list
# 						and supplying a single definition for partition_definition
#
# 					) To split an existing partition into several partitions.
#
# 						Accomplish this by naming a single partition for partition_names
# 						and providing multiple partition_definitions.
#
# 					) To change the ranges for a subset of partitions defined using VALUES LESS THAN
# 						or the values lists for a subset of partitions defined using VALUES IN.
#
# 						NOTE:
#
# 							For partitions that have not been explicitly named, MySQL automatically provides
# 							the default names p0, p1, p2 and so on.
#
# 							The same is true in regards to subpartitions
#
# 						For more detailed information about and examples of ALTER TABLE --- REORGANIZE PARTITION statements,
# 						see SECTION 23.3.1, "MANAGEMENT OF RANGE AND LIST PARTITIONS"
#
# 					) To exchange a table partition or subpartition with a table, use the ALTER_TABLE_---_EXCHANGE_PARTITION
# 						statement - that is, to move any existing rows in the partition or subpartition to the nonpartitioned
# 						table, and any existing rows in the nonpartitioned table to the table partition or subpartition.
#
# 						For usage information and examples, see SECTION 23.3.3, "EXCHANGING PARTITIONS AND SUBPARTITIONS WITH TABLES"
#
# 					) Several options provide partition maintenance and repair functionality analogous to that implemented for
# 						nonpartitioned tables by statements such as CHECK_TABLE and REPAIR_TABLE
#
# 						(which are also supported for partitioned tables; for more information, see
# 						see SECTION 13.7.3, "TABLE MAINTENANCE STATEMENTS")
#
# 						These include ANALYZE PARTITION, CHECK PARTITION, OPTIMIZE PARTITION, REBUILD PARTITION
# 						and REPAIR PARTITION.
#
# 						Each of these options takes a partition_names clause consisting of one or more
# 						names of partitions, separated by commas.
#
# 						The partitions must already exist in the target table.
#
# 						You can also use the ALL keyword in place of partition_names, in which case
# 						the statement acts on all table partitions.
#
# 						For more information and examples, see SECTION 23.3.4, "MAINTENANCE OF PARTITIONS"
#
# 						InnoDB does not currently support per-partition optimization; ALTER TABLE --- OPTIMIZE PARTITION
# 						causes the entire table to rebuilt and analyzed, and an appropriate warning to be issued.
#
# 						(BUG #11751825, BUG #42822)
#
# 						To work around this problem, use ALTER TABLE --- REBUILD PARTITION and ALTER TABLE --- ANALYZE PARTITION instead
#
# 						The ANALYZE PARTITION, CHECK PARTITION, OPTIMIZE PARTITION and REPAIR PARTITION options are not
# 						supported for tables which are not partitioned.
#
# 					) REMOVE PARTITIONING enables you to remove a table's partitioning without otherwise affecting the table or its data.
#
# 						This option can be combined with other ALTER_TABLE options such as those used to add, drop or rename columns or indexes.
#
# 					) Using the ENGINE option with ALTER_TABLE changes the storage engine used by the table without affecting
# 						the partitioning.
#
# 						The target storage engine must provide its own partitioning handler.
#
# 						Only the InnoDB and NDB storage engines have native partitioning handlers;
#
# 						NDB is currently not currently supported in MySQL 8.0
#
# It is possible for an ALTER_TABLE statement to contain a PARTITION BY or REMOVE PARTITIONING
# clause in an addition to other alter specifications, but the PARTITION BY or REMOVE PARTITIONING
# clause must be specified last after any other specifications.
#
# The ADD PARTITION, DROP PARTITION, COALESCE PARTITION, REORGANIZE PARTITION, ANALYZE PARTITION,
# CHECK PARTITION and REPAIR PARTITION options cannot be combined with other alter specifications
# in a single ALTER TABLE, since the options just listed act on individual partitions.
#
# For more information, see SECTION 13.1.9.1, "ALTER TABLE PARTITION OPERATIONS"
#
# Only a single instance of any one of the following options can be used in a given ALTER_TABLE
# statement:
#
# 		PARTITION BY, ADD PARTITION, DROP PARTITION, TRUNCATE PARTITION, EXCHANGE PARTITION,
# 		REORGANIZE PARTITION, or 
#
# 		COALESCE PARTITION, ANALYZE PARTITION, CHECK PARTITION, OPTIMIZE PARTITION,
# 		REBUILD PARTITION, REMOVE PARTITIONING
#
# 		For example, the following two statements are invalid:
#
# 			ALTER TABLE t1 ANALYZE PARTITION p1, ANALYZE PARTITION p2;
#
# 			ALTER TABLE t1 ANALYZE PARTITION p1, CHECK PARTITION p2;
#
# 		In the first case, you can analyze partitions p1 and p2 of table t1 concurrently
# 		using a single statement with a single ANALYZE PARTITION option that lists both
# 		of the partitions to be analyzed, like this:
#
# 			ALTER TABLE t1 ANALYZE PARTITION p1, p2;
#
# 		In the second case, it is not possible to perform ANALYZE and CHECK operations
# 		on different partitions of the same table concurrently.
#
# 		Instead, you must issue two seperate statements, like this:
#
# 			ALTER TABLE t1 ANALYZE PARTITION p1;
# 			ALTER TABLE t1 CHECK PARTITION p2;
#
# 		REBUILD operations are currently unsupported for subpartitions.
#
# 		The REBUILD keyword is expressly disallowed with subpartitions, and causes
# 		ALTER TABLE to fail with an error if so used.
#
# 		CHECK PARTITION and REPAIR PARTITION operations fail when the partition to be checked or repaired
# 		contains any duplicate key errors.
#
# 		For more information, see SECTION 23.3.4, "MAINTENANCE OF PARTITIONS"
#
# 13.1.9.2 ALTER TABLE AND GENERATED COLUMNS
#
# ALTER TABLE operations permitted for generated columns are ADD, MODIFY and CHANGE.
#
# 		) Generated columns can be added.
#
# 			CREATE TABLE t1 (c1 INT);
# 			ALTER TABLE t1 ADD COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;
#
# 		) The data type and expression of generated columns can be modified.
#
# 			CREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYSA AS (c1 + 1) STORED);
# 			ALTER TABLE t1 MODIFY COLUMN c2 TINYINT GENERATED ALWAYS AS (c1 + 5) STORED;
#
# 		) Generated columns can be renamed or dropped, if no other column refers to them.
#
# 			CREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) STORED);
# 			ALTER TABLE t1 CHANGE c2 c3 INT GENERATED ALWAYS AS (c1 + 1) STORED;
# 			ALTER TABLE t1 DROP COLUMN c3;
#
# 		) Virtual generated columns cannot be altered to store generated columns, or vice versa.
#
# 			To work around this, drop the column, then add it with the new definition.
#
# 				CREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) VIRTUAL);
# 				ALTER TABLE t1 DROP COLUMN c2;
# 				ALTER TABLE t1 ADD COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;
#
# 		) Nongenerated columns can be altered to store but not virtual generated columns:
#
# 			CREATE TABLE t1 (c1 INT, c2 INT);
# 			ALTER TABLE t1 MODIFY COLUMN c2 INT GENERATED ALWAYS AS (c1 + 1) STORED;
#
# 		) Stored but not virtual generated columns can be altered to nongenerated columns.
#
# 			The stored generated values become the values of the nongenerated column.
#
# 				CREATE TABLE t1 (c1 INT, c2 INT GENERATED ALWAYS AS (c1 + 1) STORED);
# 				ALTER TABLE t1 MODIFY COLUMN c2 INT;
#
# 		) ADD COLUMN is not an in-place operation for stored columns (done without using a temp table)
# 			because the expression must be evaluated by the server.
#
# 			For stored columns, indexing changes are done in place, and expression changes
# 			are not done in place.
#
# 			Changes to column comments are done in place.
#
# 		) For non-partitioned tables, ADD COLUMN and DROP COLUMN are in-place operations
# 			for virtual columns.
#
# 			However, adding or dropping a virtual column cannot be performed in place in combination
# 			with other ALTER_TABLE operations.
#
# 			For partitioned tables, ADD COLUMN and DROP COLUMN are not in-place operations
# 			for virtual columns.
#
# 		) InnoDB supports secondary indexes on virtual generated columns.
#
# 			Adding or dropping a secondary index on a virtual generated column
# 			is an in-place operation.
#
# 			For more information, see SECTION 13.1.20.9, "SECONDARY INDEXES AND GENERATED COLUMNS"
#
# 		) When a VIRTUAL generated column is added to a table or modified, it is not ensured that
# 			data being calculated by the generated column expression will not be out of range for the column.
#
# 			This can lead to inconsistent data being returned and unexpectedly failed statements.
#
# 			To permit control over whether validation occurs for such columns, ALTER TABLE
# 			supports WITHOUT VALIDATION and WITH VALIDATION clauses:
#
# 				) With WITHOUT VALIDATION (the default if neither clause is specified), an in-place operation
# 					is performed (if possible), data integrity is not checked, and the statement finishes more quickly.
#
# 					However, later reads from the table might report warnings or errors for the column if values are out of range.
#
# 				) With WITH VALIDATION, ALTER TABLE copies the table.
#
# 					If an out-of-range or any other error occurs, the statement fails.
#
# 					Because a table copy is performed, the statement takes longer.
#
# 			WITHOUT VALIDATION and WITH VALIDATION are permitted only with ADD COLUMN,
# 			CHANGE COLUMN, and MODIFY COLUMN operations.
#
# 			Otherwise, an ER_WRONG_USAGE error occurs.
#
# 		) If expression evaluation causes truncation or provides incorrect input to a function,
# 			the ALTER_TABLE statement terminates with an error and the DDL operation is rejected.
#
# 		) An ALTER_TABLE statement that changes the default value of a column col_name may also
# 			change the value of a generated column expression that refers to the column using
# 			col_name, which may change the value of a generated column expression that refers
# 			to the column using DEFAULT(col name)
#
# 			For htis reason, ALTER_TABLE operations that change the definition of a column
# 			cause a table rebuild if any generated column expression uses DEFAULT()
#
# 13.1.9.3 ALTER TABLE EXAMPLES
#
# Begin with a table t1 created as shown here:
#
# 		CREATE TABLE t1 (a INTEGER, b CHAR(10));
#
# To rename teh table from t1 to t2:
#
# 		ALTER TABLE t1 RENAME t2;
#
# To change column a from INTEGER to TINYINT NOT NULL (leaving the name the same),
# and to change column b from CHAR(10) to CHAR(20) as well as renaming it from b
# to c:
#
# 		ALTER TABLE t2 MODIFY a TINYINT NOT NULL, CHANGE b c CHAR(20);
#
# To add a new TIMESTAMP column named d:
#
# 		ALTER  TABLE t2 ADD d TIMESTAMP;
#
# To add an index on column d and a UNIQUE index on column a:
#
# 		ALTER TABLE t2 ADD INDEX (d), ADD UNIQUE (a);
#
# To remove column c:
#
# 		ALTER TABLE t2 DROP COLUMN c;
#
# To add a new AUTO_INCREMENT integer column named c:
#
# 		ALTER TABLE t2 ADD c INT UNSIGNED NOT NULL AUTO_INCREMENT,
# 			ADD PRIMARY KEY (c);
#
# We indexed (c) as a PRIMARY KEY, because AUTO_INCREMENT columns must be
# indexed, and we declare c as NOT NULL because primary key columns cannot be NULL.
#
# For NDB tables, it is also possible to change the storage type used for a 
# table or column.
#
# For example, consider an NDB table created as shown here:
#
# 		CREATE TABLE t1 (c1 INT) TABLESPACE ts_1 ENGINE NDB;
# 		Query OK, 0 rows affected (1.27 sec)
#
# To convert this table to disk-based storage, you can use the following
# ALTER_TABLE statement:
#
# 		ALTER TABLE t1 TABLESPACE ts_1 STORAGE DISK;
# 		Query OK, 0 rows affected (2.99 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
# 		SHOW CREATE TABLE t1\G
# 		******************************* 1. row *********************************
# 						Table: t1
# 			  Create Table: CREATE TABLE `t1` (
# 					`c1` int(11) DEFAULT NULL
# 			  ) /*!50100 TABLESPACE ts_1 STORAGE DISK */
# 			  ENGINE=ndbcluster DEFAULT CHARSET=latin1
# 			  1 row in set (0.01 sec)
#
# It is not necessary that the tablespace was referenced when the table was originally
# created;
#
# However, the tablespace must be referenced by the ALTER_TABLE:
#
# 		CREATE TABLE t2 (c1 INT) ts_1 ENGINE NDB;
# 		Query OK, 0 rows affected (1.00 sec)
#
# 		ALTER TABLE t2 STORAGE DISK;
# 		ERROR 1005 (HY000): Can't create table 'c.#sql-1750_3' (errno: 140)
# 		ALTER TABLE t2 TABLESPACE ts_1 STORAGE DISK;
# 		Query OK, 0 rows affected (3.42 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
#  	SHOW CREATE TABLE t2\G
# 		*********************** 1. row *******************************
#  				Table: t1
# 			Create Table: CREATE TABLE `t2` (
# 				`c1` int(11) DEFAULT NULL
# 			) /*!50100 TABLESPACE ts_1 STORAGE DISK */
# 			ENGINE=ndbcluster DEFAULT CHARSET=latin1
# 			1 row in set (0.01 sec)
#
# To change the storage type of an individual column, you can use ALTER TABLE --- MODIFY [COLUMN]
#
# For example, suppose you create an NDB Cluster Disk Data table with two columns,
# using this CREATE_TABLE statement:
#
# 		CREATE TABLE t3 (c1 INT, c2 INT)
# 			TABLESPACE ts_1 STORAGE DISK ENGINE NDB;
# 		Query OK, 0 rows affected (1.34 sec)
#
# To change column c2 from disk-based to in-memory storage, include a STORAGE MEMORY
# clause in the column definition used by the ALTER TABLE statement, as shown
# here:
#
# 		ALTER TABLE t3 MODIFY c2 INT STORAGE MEMORY;
# 		Query OK, 0 rows affected (3.14 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
# You can make in-memory columns into a disk-based column by using STORAGE DISK
# in a similar fashion.
#
# Column c1 uses disk-based storage, since this is hte default for the table
# (determined by the table-level STORAGE DISK clause in the CREATE_TABLE statement)
#
# However, column c2 uses in-memory storage, as can be seen here in the output
# of SHOW CREATE_TABLE:
#
# 		SHOW CREATE TABLE t3\G
# 		******************** 1. row ************************************
# 				Table: t3
# 		Create Table: CREATE TABLE `t3` (
# 			`c1` int(11) DEFAULT NULL,
# 			`c2` int(11) /*!50120 STORAGE MEMORY */ DEFAULT NULL
# 		) /*!50100 TABLESPACE ts_1 STORAGE DISK */ ENGINE=ndbcluster
# 		DEFAULT CHARSET=latin1
# 		1 row in set (0.02 sec)
#
# When you add an AUTO_INCREMENT column, column values are filled in with sequence
# numbers automatically.
#
# For MyISAM tables, you can set the first sequence number by executing SET INSERT_ID=value
# before ALTER_TABLE or by using the AUTO_INCREMENT=value table option.
#
# With MyISAM tables, if you do not change the AUTO_INCREMENT column, the sequence number
# is not affected.
#
# If you drop an AUTO_INCREMENT column and then add another AUTO_INCREMENT column
# , the numbers are resequenced beginning with 1
#
# When replication is used, adding an AUTO_INCREMENT column to a table might not produce
# the same ordering of the rows on the slave and the master.
#
# This occurs because the orders in which the rows are numbered depends on the specific
# storage engine used for the table and the order in which the rows were inserted.
#
# It is important to have the same order on the master and slave, the rows must be
# ordered before assigning an AUTO_INCREMENT number
#
# Assuming that you want to add an AUTO_INCREMENT column to the table t1, the following
# statements produce a new table t2 identical to t1 but with an AUTO_INCREMENT column:
#
# 		CREATE TABLE t2 (id INT AUTO_INCREMENT PRIMARY KEY)
# 		SELECT * FROM t1 ORDER BY col1, col2;
#
# This assumes that the table t1 has columns col1 and col2
#
# This set of statements will also produce a new table t2 identical to t1,
# with the addition of an AUTO_INCREMENT column:
#
# 		CREATE TABLE t2 LIKE t1;
# 		ALTER TABLE t2 ADD id INT AUTO_INCREMENT PRIMARY KEY;
# 		INSERT INTO t2 SELECT * FROM t1 ORDER BY col1, col2;
#
# IMPORTANT:
#
# 		To guarantee the same ordering on both master and slave, all columns
# 		of t1 must be referenced in the ORDER BY clause
#
# Regardless of the method used to create and populate the copy having the
# AUTO_INCREMENT column , the final step is to drop the original table
# and then rename the copy:
#
# 		DROP TABLE t1;
# 		ALTER TABLE t2 RENAME t1;
#
# 13.1.10 ALTER TABLESPACE SYNTAX
#
# ALTER [UNDO] TABLESPACE tablespace_name
# 		NDB only:
# 			{ADD|DROP} DATAFILE 'file_name'
# 			[INTIIAL_SIZE [=] size]
# 			[WAIT]
# 		InnoDB and NDB:
# 			[RENAME TO tablespace_name]
# 		InnoDB only:
# 			[SET {ACTIVE|INACTIVE}]
# 			[ENCRYPTION [=] {'Y' | 'N'}]
# 		InnoDB and NDB:
# 			[ENGINE [=] engine_name]
#
# This statement is used with NDB and InnoDB tablespaces.
#
# It can be used to add a new data file to, or to drop a data file from
# an NDB tablespace.
#
# It can also be used to rename an NDB Cluster Disk Data tablespace,
# rename an InnoDB general tablespace, encrypt an InnoDB general tablespace,
# or mark an InnoDB undo tablespace as active or inactive.
#
# The UNDO keyword, introduced in MySQL 8.0.14, is used with the SET {ACTIVE|INACTIVE}
# clause to mark an InnoDB undo tablespace as active or inactive.
#
# For more information, See SECTION 15.6.3.4, "UNDO TABLESPACES"
#
# The ADD DATAFILE variant enables you to specify an initial size for an NDB Disk Data
# tablespace using an INITIAL_SIZE clause, where size is measured in bytes; the default
# value is 134217728 (128 mb)
#
# You may optionally follow size with a one-letter abbreviation for an order of
# magnitude, similar to those used in my.cnf
#
# Generally, this is one of the letters M (megabytes) or G (gigabytes)
#
# On 32-bit systems, the maximum supported value for INTIIAL_SIZE is 4 GB. (Bug #29186)
#
# INITIAL_SIZE is rounded, explicitly, as for CREATE_TABLESPACE
#
# Once a data file has been created, its size cannot be changed; however, you can
# add more data files to an NDB tablespace using additional ALTER TABLESPACE --- ADD DATAFILE
# statements.
#
# When ALTER TABLESPACE --- ADD DATAFILE is used with ENGINE = NDB, a data file is created
# on each Cluster data node, but only one row is generated in the INFORMATION_SCHEMA.FILES
# table.
#
# See the description of this table, as well as SECTION 22.5.13.1, "NDB CLUSTER DISK DATA OBJECTS",
# for more information.
#
# ADD DATAFILE is not supported with InnoDB tablespaces.
#
# Using DROP DATAFILE with ALTER_TABLESPACE drops the data file 'file_name' from an NDB tablespace.
#
# You cannot drop a data file from a tablespace which is in use by any table; in other words,
# the data file must be empty (no extents used)
#
# See SECTION 22.5.13.1, "NDB CLUSTER DISK DATA OBJECTS"
#
# In addition, any data file to be dropped must previously have been added to the tablespace
# with CREATE_TABLESPACE or ALTER_TABLESPACE
#
# DROP DATAFILE is not supported with InnoDB tablespaces.
#
# WAIT is parsed but otherwise ignored. It is intended for future expansion.
#
# The ENGINE clause, which specifies the storage engine used by the tablespace, is deprecated
# and will be removed.
#
# The tablespace storage engine is known by the data dictionary, making the ENGINE
# clause obsolete.
#
# If the storage engine is specified, it must match the tablespace storage engine
# defined in the data dictionary.
#
# The only values for engine_name compatible with NDB tablespaces are NDB and NDBCLUSTER.
#
# RENAME TO operations are implicitly performed in autocommit mode, regardless of the autocommit setting.
#
# A RENAME TO operation cannot be performed while LOCK_TABLES or FLUSH_TABLES_WITH_READ_LOCK is in effect
# for tables that reside in the tablespace.
#
# Exclusive metadata locks are taken on tables that reside in a general tablespace while the tablespace
# is renamed, which prevents concurrent DDL.
#
# Concurrent DML is supported.
#
# The CREATE_TABLESPACE privilege is required to rename an InnoDB general tablespace.
#
# The ENCRYPTION option is used to enable or disable page-level data encryption for an
# InnoDB general tablespace.
#
# Option values are not case-sensitive.
#
# Encryption support for general tablespaces was introduced in MySQL 8.0.13.
#
# A keyring plugin must be installed and configured to encrypt a tablespace using
# the ENCRYPTION option.
#
# When a general tablespace is encrypted, all tables residing in the tablespace are encrypted.
# Likewise, a table created in an encrypted general tablespace is encrypted.
#
# The INPLACE algorithm is used when altering the ENCRYPTION attribute of a general
# tablespace.
#
# The INPLACE algorithm permits concurrent DML on tables that reside in the general
# tablespace.
#
# Concurrent DDL is blocked.
#
# For more information, see SECTION 15.6.3.9, "TABLESPACE ENCRYPTION"
#
# 13.1.11 ALTER VIEW SYNTAX
#
# ALTER
# 		[ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]
# 		[DEFINER = { user | CURRENT_USER }]
# 		[SQL SECURITY { DEFINER | INVOKER }]
# 		VIEW view_name [(column_list)]
# 		AS select_statement
# 		[WITH [CASCADED | LOCAL] CHECK OPTION]
#
# This statement changes the definition of a view, which must exist.
#
# The syntax is similar to that for CREATE_VIEW (see SECTION 13.1.23, "CREATE VIEW SYNTAX")
#
# This statement requires the CREATE_VIEW and DROP privileges for the view, and some
# privilege for each column referred to in the SELECT statement.
#
# ALTER_VIEW is permitted only to the definer or users with the SET_USER_ID or SUPER privilege.
#
# 13.1.12 CREATE DATABASE SYNTAX
#
# CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name
# 		[create_specification] ---
#
# create_specification:
# 		[DEFAULT] CHARACTER SET [=] charset_name
# 	 | [DEFAULT] COLLATE [=] collation_name
#
# CREATE_DATABASE creates a database with the given name. 
#
# To use this statement, you need the CREATE privilege for the database.
#
# CREATE_SCHEMA is a synonym for CREATE_DATABASE
#
# An error occurs if the database exists and you did not specify IF NOT EXISTS
#
# CREATE_DATABASE is not permitted within a session that has an active LOCK_TABLES statement
#
# create_specification options specify database characteristics. Database characteristics
# are stored in the data dictionary.
#
# The CHARACTER SET clause specifies the default database character set. The COLLATE
# clause specifies the default database collation.
#
# CHAPTER 10, CHARACTER SETS, COLLATIONS, UNICODE, discusses character set and collation
# names.
#
# A database in MySQL is implemented as a directory containing files that correspond to tables
# in the database.
#
# Because there are no tables in a database when it is initially created, the CREATE_DATABASE
# statement creates only a directory under the MySQL data directory.
#
# Rules for permissible database names are given in SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# If a database name contains special characters, the name for the database directory
# contains encoded versions of those characters as described in SECTION 9.2.3, "MAPPING OF IDENTIFIERS TO FILE NAMES"
#
# Creating a database directory by manually creating a directory under the data directory
# (for example, with mkdir) is temporarily unsupported in MySQL 8.0.0
#
# You can also use the mysqladmin program to create databases.
#
# See SECTION 4.5.2, "MYSQLADMIN -- CLIENT FOR ADMINISTERING A MYSQL SERVER"
#
# 13.1.13 CREATE EVENT SYNTAX
#
# CREATE
# 		[DEFINER = { user | CURRENT_USER }]
# 		EVENT
# 		[IF NOT EXISTS]
# 		event_name
# 		ON SCHEDULE schedule
# 		[ON COMPLETION [NOT] PRESERVE]
# 		[ENABLE | DISABLE | DISABLE ON SLAVE]
# 		[COMMENT 'string']
# 		DO event_body;
#
# schedule:
# 		AT timestamp [+ INTERVAL interval] ---
#   | EVERY interval
# 		[STARTS timestamp [+ INTERVAL interval] ---]
# 		[ENDS timestamp [+ INTERVAL interval] ---]
#
# interval:
# 		quantity {YEAR | QUARTER | MONTH | DAY | HOUR | MINUTE |
# 					 WEEK | SECOND  | YEAR_MONTH | DAY_HOUR | DAY_MINUTE |
# 					 DAY_SECOND | HOUR_MINUTE | HOUR_SECOND | MINUTE_SECOND}
#
# This statement creates and schedules a new event.
#
# The event will not run unless the Event Scheduler is enabled.
#
# For information about checking Event Scheduler status and enabling it if
# necessary, see SECTION 24.4.2, "EVENT SCHEDULER CONFIGURATION"
#
# CREATE_EVENT requires the EVENT privilege for the schema in which the event
# is to be created.
#
# It might also require the SET_USER_ID or SUPER privilege, depending on the
# DEFINER value, as described later in this section.
#
# The minimum requirements for a valid CREATE_EVENT statement are as follows:
#
# 		) The keywords CREATE_EVENT plus an event name, which uniquely identifies the event in a database schema.
#
# 		) An ON SCHEDULE clause, which determines when and how often the event executes
#
# 		) A DO clause, which contains the SQL statement to be executed by an event
#
# This is an example of a minimal CREATE_EVENT statement:
#
# 		CREATE EVENT myevent
# 			ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR
# 			DO
# 				UPDATE myschema.mytable SET mycol = mycol + 1;
#
# The previous statement creates an event named myevent.
#
# This event executes once - one hour following its creation - by running an 
# SQL statement that increments the value of the myschema.mytable table's
# mycol column by 1.
#
# The event_name must be a valid MySQL identifier with a maximum length of 64 characters.
#
# Event names are not case-sensitive, so you cannot have two events named myevent
# and MyEvent in the same schema.
#
# In general, the rules governing event names are the same as those for names
# of stored routines.
#
# See SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# An event is associated with a schema. If no schema is indicated as part of event_name,
# the default (current) schema is assumed.
#
# To create an event in a specific schema, qualify the event name with a schema using
# schema_name.event_name syntax
#
# The DEFINER clause specifies the MySQL account to be used when checking access privileges
# at event execution time.
#
# If a user value is given, it should be a MySQL account specified as 'user_name'@'host_name',
# CURRENT_USER or CURRENT_USER()
#
# The default DEFINER value is the user who executes the CREATE_EVENT statement.
#
# This is the same as specifying DEFINER = CURRENT_USER explicitly
#
# If you specify the DEFINER clause, these rules determine the valid DEFINER user values:
#
# 		) If you do not have the SET_USER_ID or SUPER privilege, the only permitted user value is
# 			your own account, either specified literally or by using CURRENT_USER
#
# 			You cannot set the definer to some other account
#
# 		) If you have the SET_USER_ID or SUPER privilege, you can specify any syntactically valid account name.
#
# 			If the account does not exist, a warning is generated.
#
# 		) Although it is possible to create an event with a nonexistent DEFINER account, an error occurs
# 			at event execution time if the account does not exist.
#
# For more information about event security, see SECTION 24.6, "ACCESS CONTROL FOR STORED PROGRAMS AND VIEWS"
#
# Within an event, the CURRENT_USER() function returns the account used to check privileges at event
# execution time, which is the DEFINER user.
#
# For information about user auditing within events, see SECTION 6.3.13, "SQL-BASED MYSQL ACCOUNT ACTIVITY AUDITING"
#
# IF NOT EXISTS has the same meaning for CREATE_EVENT as for CREATE_TABLE:
#
# 		If an event named event_name already exists in the same schema, no action is taken,
# 		and no error results.
#
# 		(However, a warning is generated in such cases)
#
# The ON SCHEDULE clause determines when, how often, and for how long the event_body
# defined for the event repeats.
#
# This clause takes one of two forms:
#
# 		) AT timestamp is used for a one-time event.
#
# 		It specifies that the event executes one time only at the date and time given by
# 		timestamp, which must include both the date and time, or must be an expression that
# 		resolves to a datetime value.
#
# 		You may use a value of either the DATETIME or TIMESTAMP type for this purpose.
#
# 		If the date is in the past, a warning occurs, as shown here:
#
# 			SELECT NOW();
# 			+--------------------------------+
# 			| NOW() 								   |
# 			+--------------------------------+
# 			| 2006-02-10 23:59:01 			   |
# 			+--------------------------------+
# 			1 row in set (0.04 sec) 	
#
# 			CREATE EVENT e_totals
# 				ON SCHEDULE AT '2006-02-10 23:59:00'
# 				DO INSERT INTO test.totals VALUES (NOW());
# 			Query OK, 0 rows affected, 1 warning (0.00 sec)
#
# 			SHOW WARNINGS\G
# 			********************** 1. row *******************************
# 				Level: Note
# 				 Code: 1588
# 			 Message: Event execution time is in the past and ON COMPLETION NOT
# 						 PRESERVE is set.
#
# 						 The event was dropped immediately after creation.
#
# CREATE_EVENT statements which are themselves invalid - for whatever reason - fail with an error.
#
# You may use CURRENT_TIMESTAMP to specify the current date and time. 
#
# In such a case, the event acts as soon as it is created.
#
# To create an event which occurs at some point in the future relative to the current date
# and time - such as the expressed by the phrase "three weeks from now" - you can use
# the optional clause + INTERVAL interval.
#
# The interval portion consists of two parts, a quantity and a unit of time, and follows
# the syntax rules described in Temporal Intervals, except that you cannot use any units
# keywords that involve microseconds when defining an event.
#
# With some interval types, complex time units may be used.
#
# For example, "two minutes and ten seconds" can be expressed as + INTERVAL '2:10' MINUTE_SECOND
#
# You can also combine intervals.
#
# For example, AT CURRENT_TIMESTAMP + INTERVAL 3 WEEK + INTERVAL 2 DAY is equivalent
# to "three weeks and two days from now"
#
# Each portion of such a clause must begin with + INTERVAL.
#
# ) 	To repeat actions at a regular interval, use an EVERY clause.
#
	# 	The EVERY keyword is followed by an interval as described in the previous discussion
	# of the AT keyword.
	# (+ INTERVAL is not used with EVERY)
	#
	# For example, EVERY 6 WEEK means "every six weeks"
	#
	# Although + INTERVAL clauses are not permitted in an EVERY clause, you can use
	# the same complex time units permitted in a + INTERVAL
	#
	# An EVERY clause may contain an optional STARTS clause.
	#
	# STARTS is followed by a timestamp value that indicates when the action should
	# begin repeating, and may also use + INTERVAL interval to specify an amount of time
	# "from now"
	#
	# For example, EVERY 3 MONTH STARTS CURRENT_TIMESTAMP + INTERVAL 1 WEEK means
	# "every three months, beginning one week from now"
	#
	# Similarly, you can express "every two weeks, beginning six hours and fiften
	# minutes from now" as EVERY 2 WEEK STARTS CURRENT_TIMESTAMP + INTERVAL '6:15' HOUR_MINUTE
	#
	# Not specifying STARTS is the same as using STARTS CURRENT_TIMESTAMP - that is, the action
	# specified for the event begins repeating immediately upon creation of the event.
	#
	# An EVERY clause may contain an optional ENDS clause.
	#
	# The ENDS keyword is followed by a timestamp value that tells MySQL when the event
	# should stop repeating.
	#
	# You may also use + INTERVAL interval with ENDS; for instance, EVERY 12 HOUR
	# STARTS CURRENT_TIMESTAMP + INTERVAL 30 MINUTE ENDS CURRENT_TIMESTAMP + INTERVAL 4 WEEK
	# is equivalent to "every twelve hours, beginning thirty minutes from now, and ending
	# four weeks from now".
	#
	# Not using ENDS means that the event continues executing indefinitly.
	#
	# ENDS supports the same syntax for complex time units as STARTS does.
	#
	# You may use STARTS, ENDS, both or neither in an EVERY clause.
	#
	# If a repeating event does not terminate within its scheduling interval,
	# the result may be multiple instances of the event executing simultaneously.
	#
	# If this is undesirable, you should institute a mechanism to prevent simultaneous
	# instances.
	#
	# For example, you could use the GET_LOCK() function, or row or table locking.
#
# The ON SCHEDULE clause may use expressions involving built-in MySQL functions
# and user variables to obtain any of the timestamp or interval values which it contains.
#
# You may not use stored functions or user-defined functions in such expressions, nor
# may you use any table references; however, you may use SELECT FROM DUAL.
#
# This is true for both CREATE_EVENT and ALTER_EVENT statements.
#
# References to stored functions, user-defined functions, and tables in such cases
# are specifically not permitted, and fail with an error (see Bug #22830)
#
# Times in the ON SCHEDULE clause are interpreted using the current session time_zone
# value.
#
# This becomes the event time zone; that is, the time zone that is used for event scheduling
# and is in effect within the event as it executes.
#
# These times are converted to UTC and stored along with the event time zone in the
# mysql.event table.
#
# This enables event execution to proceed as defined regardless of any subsequent
# changes to the server time zone or daylight saving time effects.
#
# For additional information about representation of event times, see SECTION 24.4.4, "EVENT METADATA"
#
# See also SECTION 13.7.6.18, "SHOW EVENTS SYNTAX", and SECTION 25.9, "THE INFORMATION_SCHEMA EVENTS TABLE"
#
# Normally, once an event has expired, it is immediately dropped.
#
# You can override this behavior by specifying ON COMPLETION PRESERVE.
#
# Using ON COMPLETION NOT PRESERVE merely makes the default nonpersistent behavior explicit.
#
# You can create an event but prevent it from being active using the DISABLE keyword.
#
# Alternatively, you can use ENABLE to make explicit the default status, which is active.
#
# This is most useful in conjunction with ALTER_EVENT (see SECTION 13.1.3, "ALTER EVENT SYNTAX")
#
# A third value may also appear in place of ENABLE or DISABLE; DISABLE ON SLAVE is set for
# the status of an event on a replication slave to indicate that the event was created on
# the master and replicated to the slave, but is not executed on the slave.
#
# See SECTION 17.4.1.16, "REPLICATION OF INVOKED FEATURES"
#
# You may supply a comment for an event using a COMMENT clause. Comment may be any string
# of up to 64 chars that you wish to use for describing the event.
#
# The comment text, being a string literal, must be surrounded by quotation marks.
#
# The DO clause specifies an action carried by the event, and consists of an SQL
# statement.
#
# Nearly any valid MySQL statement that can be used in a stored routine can also
# be used as the action statement for a scheduled event.
#
# (See SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS")
#
# For example, the following event e_hourly deletes all rows from the
# sessions table once per hour, where this table is part of the site_activity schema:
#
# 		CREATE EVENT e_hourly
# 			ON SCHEDULE
# 				EVERY 1 HOUR
# 			COMMENT 'Clears out sessions table each hour.'
# 			DO
# 				DELETE FROM site_activity.sessions;
#
# MySQL stores the sql_mode system variable setting in effect when an event is created
# or altered, and always executes the event with this setting in force, regardless of the
# current server SQL mode when the event begins executing.
#
# A CREATE_EVENT statement that contains an ALTER_EVENT statement in its DO clause appears
# to succeed; however, when the server attempts to execute the resulting scheduled event,
# the execution fails with an error.
#
# 		NOTE:
#
# 			Statements such as SELECT or SHOW that merely return a result set have no effect
# 			when used in an event; the output from these is not sent to the MySQL Monitor,
# 			nor is it stored anywhere.
#
# 			However, you can use statements such as SELECT_---_INTO and INSERT_INTO_---_SELECT
# 			that store a result.
#
# 			(See the next example in this section for an instance of the latter)
#
# The schema to which an event belongs is the default schema for table references in the DO clause.
#
# Any references to tables in other schemas must be qualified with the proper schema name.
#
# As with stored routines, you can use compound-statement syntax in the DO clause by using the
# BEGIN and END keywords, as shown here:
#
# 		delimiter |
#
# 		CREATE EVENT e_daily
# 			ON SCHEDULE
# 				EVERY 1 DAY
# 			COMMENT 'Saves total number of sessions then clears the table each day'
# 			DO
# 				BEGIN
# 					INSERT INTO site_activity.totals (time, total)
# 						SELECT CURRENT_TIMESTAMP, COUNT(*)
# 							FROM site_activity.sessions;
# 					DELETE FROM site_activity.sessions;
# 				END |
#
# 		delimiter ;
#
# This example uses the delimiter command to change the statement delimiter.
#
# See SECTION 24.1, "DEFINING STORED PROGRAMS"
#
# More complex compound statements, such as those used in stored routines, are possible
# in an event.
#
# This example uses local variables, an error handler, and a flow control construct:
#
# 		delimiter |
#
# 		CREATE EVENT e
# 			ON SCHEDULE
# 				EVERY 5 SECOND
# 			DO
# 				BEGIN
# 					DECLARE v INTEGER;
# 					DECLARE CONTINUE HANDLER FOR SQLEXCEPTION BEGIN END;
#
# 					SET v = 0;
#
# 					WHILE v < 5 DO
# 						INSERT INTO t1 VALUES (0);
# 						UPDATE t2 SET s1 = s1 + 1;
# 						SET v = v + 1;
# 					END WHILE;
# 			END |
#
# 		delimiter ;
#
# There is no way to pass parameters directly to or from events; however, it is
# possible to invoke a stored routine with parameters within an event:
#
# 		CREATE EVENT e_call_myproc
# 			ON SCHEDULE
# 				AT CURRENT_TIMESTAMP + INTERVAL 1 DAY
# 			DO CALL myproc(5, 27);
#
# If an event's definer has privileges sufficient to set global system variables
# (see SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"), the event can read and write
# global variables.
#
# As granting such privileges entails a potential for abuse, extreme care must be
# taken in doing so.
#
# Generally, any statements that are valid in stored routines may be used for action
# statements executed by events.
#
# For more information about statements permissible within stored routines, see 
# SECTION 24.2.1, "STORED ROUTINE SYNTAX"
#
# You can create an event as part of a stored routine, but an event cannot be 
# created by another event.
#
# 13.1.14 CREATE FUNCTION SYNTAX
#
# The CREATE_FUNCTION statement is used to create stored functions and user-defined
# functions (UDFs):
#
# 		) For information about creating stored functions, see SECTION 13.1.17, "CREATE PROCEDURE AND CREATE FUNCTION SYNTAX"
#
# 		) For information about creating user-defined functions, see SECTION 13.7.4.1, "CREATE FUNCTION SYNTAX FOR USER-DEFINED FUNCTIONS"
#
# 13.1.15 CREATE INDEX SYNTAX
#
# CREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX index_name
# 		[index_type]
# 		ON tbl_name (key_part, ---)
# 		[index_option]
# 		[algorithm_option | lock_option] ---
#
# key_part: {col_name [(length)] | (expr)} [ASC | DESC]
#
# index_option:
# 		KEY_BLOCK_SIZE [=] value
# 	 | index_type
# 	 | WITH PARSER parser_name
#   | COMMENT 'string'
#   | {VISIBILE | INVISIBILE}
#
# index_type:
# 		USING {BTREE | HASH}
#
# algorithm_option:
# 		ALGORITHM [=] {DEFAULT | INPLACE | COPY}
#
# lock_option:
# 		LOCK [=] {DEFAULT | NONE | SHARED | EXCLUSIVE}
#
# Normally, you create all indexes on a table at the time the table itself is created
# with CREATE_TABLE.
#
# See SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# This guideline is especially important for InnoDB tables, where the primary key
# determines the physical layout of rows in the data file.
#
# CREATE_INDEX enables you to add indexes to existing tables.
#
# CREATE_INDEX is mapped to an ALTER_TABLE statement to create indexes.
#
# See SECTION 13.1.9, "ALTER TABLE SYNTAX". CREATE_INDEX cannot be used to
# create a PRIMARY KEY; use ALTER_TABLE instead.
#
# For more information about indexes, see SECTION 8.3.1, "HOW MYSQL USES INDEXES"
#
# InnoDB supports secondary indexes on virtual columns. For more information,
# see SECTION 13.1.20.9, "SECONDARY INDEXES AND GENERATED COLUMNS"
#
# When the innodb_stats_persistent setting is enabled, run the ANALYZE_TABLE
# statement for an InnoDB table after creating an index on that table.
#
# An index specification of the form (key_part1, key_part2, ---) creates an index
# with multiple key parts.
#
# Index key values are formed by concatenating the values of the
# given key parts.
#
# For example (col1, col2, col3) specifies a multiple-column index with index
# keys consisting of values from col1, col2 and col3.
#
# A key_part specificaiton can end with ASC or DESC to specify whether index values 
# are stored in ascending or descending order.
#
# The default is ascending if no order specifier is given.
#
# ASC and DESC are not permitted for HASH indexes.
#
# As of MySQL 8.0.12, ASC and DESC are not permitted for SPATIAL indexes.
#
# The following sections describe different aspects of the CREATE_INDEX statement:
#
# 		) Column Prefix Key Parts
#
# 		) Functional Key parts
#
# 		) Unique Indexes
#
# 		) Full-Text Indexes
#
# 		) Spatial indexes
#
# 		) Index Options
#
# 		) Table Copying and Locking Options
#
# COLUMN PREFIX KEY PARTS
#
# For string columns, indexes can be created that use only the leading part of column values,
# using col_name(length) syntax to specify an index prefix length:
#
# 		) Prefixes can be specified for CHAR, VARCHAR, BINARY, and VARBINARY key parts
#
# 		) Prefixes must be specified for BLOB and TEXT key parts. Additionally, BLOB and TEXT columns
# 			can be indexed only for InnoDB, MyISAM, and BLACKHOLE tables.
#
# 		) Prefix limits are measured in bytes. However, prefix lengths for index specifications
# 			in CREATE_TABLE, ALTER_TABLE and CREATE_INDEX statements are interpreted as number
# 			of characters for nonbinary string types (CHAR, VARCHAR, TEXT) and number of bytes
# 			for binary string types (BINARY, VARBINARY, BLOB)
#
# 			Take this into account when specifying a prefix length for a nonbinary string column
# 			that uses a multibyte character set.
#
# 			Prefix support and lengths of prefixes (where supported) are storage engine dependent.
#
# 			For example, a prefix can be up to 767 bytes long for InnoDB tables that use the
# 			REDUNDANT or COMPACT row format.
#
# 			The prefix length limit is 3072 bytes for InnoDB tables that use the DYNAMIC
# 			or COMPRESSED row format.
#
# 			For MyISAM tables, the prefix length is 1000 bytes.
#
# 			The NDB storage engine does not support prefixes (see SECTION 22.1.7.6, "UNSUPPORTED OR MISSING FEATURES IN NDB CLUSTER")
#
# If a specified index prefix exceeds the maximum column data type size, CREATE_INDEX handles
# the index as follows:
#
# 		) For a nonunique index, either an error occurs (if strict SQL mode is enabled), or the index length is
# 			reduced to lie within the maximum column data type size and a warning is produced
# 			(if strict SQL mode is not enabled)
#
# 		) For a unique index, an error occurs regardless of SQL mode because reducing the index length
# 			might enable insertion of nonunique entries that do not meet the specified uniqueness requirement.
#
# The statement shown here creates an index using the first 10 characters of the name column
# (assuming that name has a nonbinary string type):
#
# 		CREATE INDEX part_of_name ON customer (name(10));
#
# If names in the column usually differ in the first 10 characters, lookups performed using
# this index should not be much slower than using an index created from the entire
# name column.
#
# Also, using column prefixes for indexes can make the index file much smaller, which could
# save a lot of disk space and might also speed up INSERT operations.
#
# FUNCTIONAL KEY PARTS
#
# A "normal" index indexes column values or prefixes of column values.
#
# For example, in teh following table, the index entry for a given t1 row includes
# the full col1 value and a prefix of the col2 value consisting of its first 10 bytes:
#
# 		CREATE TABLE t1 (
# 			col1 VARCHAR(10),
# 			col2 VARCHAR(20),
# 			INDEX (col1, col2(10))
# 		);
#
# MySQL 8.0.13 and higher supports functional key parts that index expression
# values rather than column or column prefix values.
#
# Use of functional key parts enables indexing of values not stored directly
# in the table. 
#
# Examples:
#
# 		CREATE TABLE t1 (col1 INT, col2 INT, INDEX func_index ((ABS(col1))));
# 		CREATE INDEX idx1 ON t1 ((col1 + col2));
# 		CREATE INDEX idx2 ON t1 ((col1 + col2), (col1 - col2), col1);
# 		ALTER TABLE t1 ADD INDEX ((col1 * 40) DESC);
#
# An index with multiple key parts can mix nonfunctional and functional key parts.
#
# ASC and DESC are supported for functional key parts.
#
# Functional key parts must adhere to the following rules. An error occurs if a key
# part definition contains disallowed constructs.
#
# 		) In index definitions, enclose expressions within parentheses to distinguish them from 
# 			columns or column prefixes.
#
# 			For example, this is permitted; the expressions are enclosed within parentheses:
#
# 				INDEX ((col1 + col2), (col3 - col4))
#
# 			This produces an error, the expressions are not enclosed within parentheses:
#
# 				INDEX (col1 + col2, col3 - col4)
#
# 		) A functional key part cannot consist solely of a column name. 
#
# 			For example, this is not permitted:
#
# 				INDEX ((col1), (col2))
#
# 			Instead, write the key parts as nonfunctional key parts, without parentheses:
#
# 				INDEX (col1, col2)
#
# 		) A functional key part expression cannot refer to column prefixes.
#
# 			For a workaround, see the discussion of SUBSTRING() and CAST() later in this section.
#
# 		) Functional key parts are not permitted in foreign key specifications.
#
# For CREATE_TABLE_---_LIKE, the destination table preserves functional key parts from the 
# original table.
#
# Functional indexes are implemented as hidden virtual generated columns, which has these implications:
#
# 		) Each functional key part counts against the limit on total number of table columns; See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# 		) Functional key parts inherit all restrictions that apply to generated columns. Examples:
#
# 			) Only functions permitted for generated columns are permitted for functional key parts
#
# 			) Subqueries, parameters, variables, stored functions, and user-defined functions are not permitted.
#
# 			For more information about applicable restrictions, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
# 			and SECTION 13.1.9.2, "ALTER TABLE AND GENERATED COLUMNS"
#
# 		) The virtual generated column itself requires no storage.
#
# 			The index itself takes up storage space as any other index.
#
# UNIQUE is supported for indexes that include functional key parts. However, primary keys cannot
# include functional key parts.
#
# A primary key requires the generated column to be stored, but functional key parts are implemented
# as virtual generated columns, not stored generated columns.
#
# SPATIAL and FULLTEXT indexes cannot have functional key parts.
#
# If a table contains no primary key, InnoDB automatically promotes the first UNIQUE NOT FULL
# index to the primary key.
#
# This is not supported for UNIQUE NOT NULL indexes that have functional key parts.
#
# Nonfunctional indexes raise a warning if there are duplicate indexes.
#
# Indexes that contain functional key parts do not have this feature.
#
# To remove a column that is referenced by a functional key part, the index
# must be removed first.
#
# Otherwise, an error occurs.
#
# Although nonfunctional key parts support a prefix length specification, this
# is not possible for functional key parts.
#
# The solution is to use SUBSTRING() (or CAST(), as described later in this section)
#
# For a functional key part containing the SUBSTRING() function to be used in a query,
# the WHERE clause must contain SUBSTRING() with the same arguments.
#
# In the following example, only the second SELECT is able to use the index because
# that is the only query in which the arguments to SUBSTRING() match the index
# specification:
#
# 		CREATE TABLE tbl (
# 			col1 LONGTEXT,
# 			INDEX idx1 ((SUBSTRING(col1, 1, 10)))
# 		);
# 		SELECT * FROM tbl WHERE SUBSTRING(col1, 1, 9) = '123456789';
# 		SELECT * FROM tbl WHERE SUBSTRING(col1, 1, 10) = '1234567890';
#
# Functional key parts enable indexing of values that cannot be indexed otherwise,
# such as JSON values.
#
# However, this must be done correctly to achieve the desired effect.
#
# For example, this syntax does not work:
#
# 		CREATE TABLE employees (
# 			data JSON,
# 			INDEX ((data->>'$.name'))
# 		);
#
# This syntax fails because:
#
# 		) The ->> operator translates into JSON_UNQUOTE(JSON_EXTRACT(---))
#
# 		) JSON_UNQUOTE() returns a value with a data type of LONGTEXT, and the hidden generated
# 			column thus is assigned the same data type.
#
# 		) MySQL cannot index LONGTEXT columns specified without a prefix length on the key part,
# 			and prefix lengths are not permitted in functional key parts.
#
# To index the JSON column, you could try using the CAST() function as follows:
#
# 		CREATE TABLE employees (
# 			data JSON,
# 			INDEX ((CAST(data->>'$.name' AS CHAR(30))))
# 		);
#
# The hidden generated column is assigned the VARCHAR(30) data type, which can be indexed.
#
# But this approach produces a new issue when trying to use theh index:
#
# 		) CAST() returns a string with the collation utf8mb4_0900_ai_ci (the server default collation)
#
# 		) JSON_UNQUOTE() returns a string with the collation utf8mb4_bin (hard coded)
#
# As a result, there is a collation mismatch between the indexed expression in the preceding
# table definition and the WHERE clause expression in the following query:
#
# 		SELECT * FROM employees WHERE data->>'$.name' = 'James';
#
# The index is not used because the expression in the query and the index differ.
#
# To support this kind of scenario for functional key parts, the optimizer automatically
# strips CAST() when looking for an index to use, but only if the collation of the indexed
# expression matches that of the query expression.
#
# For an index with a functional key part to be used, either of the following two solutions
# work (although they differ somewhat in effect):
#
# 		) Solution 1.  Assign the indexed expression the same collation as JSON_UNQUOTE():
#
	# 			CREATE TABLE employees (
	# 				data JSON,
	# 				INDEX idx ((CAST(data->>"$.name" AS CHAR(30)) COLLATE utf8mb4_bin))
	# 			);
	# 			INSERT INTO employees VALUES
	# 				('{ "name": "james", "salary": 9000 }'),
	# 				('{ "name": "James", "salary": 10000 }'),
	# 				('{ "name": "Mary", "salary": 12000 }'),
	# 				('{ "name": "Peter", "salary": 8000 }');
	# 			SELECT * FROM employees WHERE data->>'$.name' = 'James';
#
# 			The ->> operator is the same as JSON_UNQUOTE(JSON_EXTRACT(---)), and JSON_UNQUOTE()
# 			returns a string with collation utf8mb4_bin
#
# 			The comparison is thus case sensitive, and only one row matches:
#
# 				+--------------------------------------------+
# 				| data 													|
# 				+--------------------------------------------+
# 				| {"name": "James", "salary": 10000} 		   |
# 				+--------------------------------------------+
#
# 		) Solution 2. Specify the full expression in the query:
#
	# 			CREATE TABLE employees (
	# 				data JSON,
	# 				INDEX idx ((CAST(data->>"$.name" AS CHAR(30))))
	# 			);
	# 			INSERT INTO employees VALUES
	# 				('{ "name": "james", "salary": 9000 }'),
	# 				('{ "name": "James", "salary": 10000 }'),
	# 				('{ "name": "Mary", "salary": 12000 }'),
	# 				('{ "name": "Peter", "salary": 8000 }');
	# 			SELECT * FROM employees WHERE CAST(data->>'$.name' AS CHAR(30)) = 'James';
#
# 		
# 			CAST() returns a string with collation utf8mb4_0900_ai_ci, so the comparison case
# 			insensitive and two rows match:
#
# 				+----------------------------------------------+
# 				| data 													  |
# 				+----------------------------------------------+
# 				| {"name": "james", "salary": 9000} 			  |
# 				| {"name": "James", "salary": 10000} 			  |
# 				+----------------------------------------------+
#
# 			Be aware that although the optimizer supports automatically stripping CAST() with indexed
# 			generated columns, the following approach does not work because it produces a different
# 			result with and without an index (Bug#27337092):
#
# 				CREATE TABLE employees (
# 					data JSON,
# 					generated_col VARCHAR(30) AS (CAST(data->>'$.name' AS CHAR(30)))
# 				);
# 				Query OK, 0 rows affected, 1 warning (0.03 sec)
#
# 				INSERT INTO employees (data)
# 				VALUES ('{"name": "james"}'), ('{"name": "James"}');
# 				Query OK, 2 rows affected, 1 warning (0.01 sec)
# 				Records: 2 Duplicates: 0 Warnings: 1
#
# 				SELECT * FROM employees WHERE data->>'$.name' = 'James';
# 				+------------------------------+----------------------+
# 				| data 								 | generated_col 			|
# 				+------------------------------+----------------------+
# 				| {"name": "James"} 				 | James 					|
# 				+------------------------------+----------------------+
# 				1 row in set (0.00 sec)
#
# 				ALTER TABLE employees ADD INDEX idx (generated_col);
# 				Query OK, 0 rows affected, 1 warning (0.03 sec)
# 				Records: 0 Duplicates: 0 Warnings: 1
#
# 				SELECT * FROM employees WHERE data->>'$.name' = 'James';
# 				+------------------------------+----------------------+
# 				| data 								 | generated_col 		   |
# 				+------------------------------+----------------------+
# 				| {"name": "james"} 				 | james 					|
# 				| {"name": "James"} 				 | James 					|
# 				+------------------------------+----------------------+
# 				2 rows in set (0.01 sec)
#
# UNIQUE INDEXES
#
# A UNIQUE index creates a constraint such that all values in the index must be
# distinct.
#
# An error occurs if you try to add a new row with a key value that matches an
# existing row.
#
# If you specify a prefix value for a column in a UNIQUE index, the column values
# must be unique within the prefix length.
#
# A UNIQUE index permits multiple NULL values for columns that can contain NULL
#
# If a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists of a single
# column that has an integer type, you can use _rowid to refer to the indexed
# column in SELECT statements, as follows:
#
# 		) _rowid refers to the PRIMARY KEY column if there is a PRIMARY KEY consisting
# 			of a single integer column.
#
# 			If there is a PRIMARY KEY but it does not consist of a single integer column,
# 			_rowid cannot be used.
#
# 		) Otherwise, _rowid refers to the column in the first UNIQUE NOT NULL index if that
# 			index consists of a single integer column.
#
# 			If the first UNIQUE NOT NULL index does not consist of a single integer column,
# 			_rowid cannot be used.
#
# FULL-TEXT INDEXES
#
# FULLTEXT indexes are supported only for InnoDB and MyISAM tables and can include only
# CHAR, VARCHAR and TEXT columns.
#
# Indexing always happens over the entire column; column prefix indexing is not
# supported and any prefix length is ignored if specified.
#
# See SECTION 12.9, "FULL-TEXT SEARCH FUNCTIONS", for details of operation.
#
# SPATIAL INDEXES
#
# The MyISAM, InnoDB, NDB and ARCHIVE storage engines support spatial columns such as
# POINT and GEOMETRY.
#
# (SECTION 11.5, "SPATIAL DATA TYPES", describes the spatial data types)
#
# However, support for spatial column indexing varies among engines.
#
# Spatial and nonspatial indexes on spatial columns are available according to
# the following rules.
#
# Spatial indexes on spatial columns have these characteristics:
#
# 		) Available only for InnoDB and MyISAM tables. Specifying SPATIAL INDEX for other storage engines results in an error.
#
# 		) As of MySQL 8.0.12, an index on a spatial column MUST be a SPATIAL index.
#
# 			The SPATIAL keyword is thus optional but implicit for creating an index on a spatial column.
#
# 		) Available for single spatial columns only. A spatial index cannot be created over multiple spatial columns.
#
# 		) Indexed columns must be NOT NULL
#
# 		) Column prefix lengths are prohibited. The full width of each column is indexed.
#
# 		) Not permitted for a primary key or unique index
#
# Nonspatial indexes on spatial columns (created with INDEX, UNIQUE, or PRIMARY KEY) have these
# characteristics:
#
# 		) Permitted for any storage engine that supports spatial columns except ARCHIVE
#
# 		) Columns can be NULL unless the index is a primary key
#
# 		) The index type for a non-SPATIAL index depends on the storage engine. Currently, B-tree is used.
#
# 		) Permitted for a column that can have NULL values only for InnoDB, MyISAM, and MEMORY tables
#
# INDEX OPTIONS
#
# Following the key part list, index options can be given.
#
# An index_option value can be any of the following:
#
# 		) KEY_BLOCK_SIZE [=] value
#
# 			For MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use
# 			for index key blocks.
#
# 			The value is treated as a hint; a different size could be used if necessary.
#
# 			A KEY_BLOCK_SIZE value specified for an individual index definition overrides
# 			a table-level KEY_BLOCK_SIZE value.
#
# 			KEY_BLOCK_SIZE is not supported at the index level for InnoDB tables.
#
# 			See SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# 		) index_type
#
# 			Some storage engines permit you to specify an index type when creating an index.
#
# 			For example:
#
# 				CREATE TABLE lookup (id INT) ENGINE = MEMORY;
# 				CREATE INDEX id_index ON lookup (id) USING BTREE;
#
# 			TABLE 13.1, "INDEX TYPES PER STORAGE ENGINE" shows the permissible index type values
# 			supported by different storage engines.
#
# 			Where multiple index types are listed, the first one is the default when no
# 			index type specifier is given.
#
# 			Storage engines not listed in the table do not support an index_type clause
# 			in index definitions.
#
	# 			TABLE 13.1 INDEX TYPES PER STORAGE ENGINE
	#
	# 			STORAGE ENGINE 			PERMISSIBILE INDEX TYPES
	#
	# 			InnoDB 						BTREE
	#
	# 			MyISAM 						BTREE
	#
	# 			MEMORY/HEAP 				HASH, BTREE
	#
	# 			NDB 							HASH, BTREE (see note in text)
#
# 			The index_type clause cannot be used for FULLTEXT INDEX or (prior to MySQL 8.0.12)
# 			SPATIAL INDEX specifications.
#
# 			Full-text index implementation is storage engine dependent.
#
# 			Spatial indexes are implemented as R-tree indexes.
#
# 			If you specify an index type that is not valid for a given storage engine,
# 			but another index type is available that the engine can use without affecting
# 			query results, the engine uses the available type.
#
# 			The parser recognizes RTREE as a type name. AS of MySQL 8.0.12, this is permitted
# 			only for SPATIAL indexes.
#
# 			Prior to 8.0.12, RTREE cannot be specified for any storage engine.
#
# 			BTREE indexes are implemented by the NDB storage engine as T-tree indexes.
#
# 				NOTE:
#
# 					For indexes on NDB table columns, the USING option can be specified only
# 					for a unique index or primary key.
#
# 					USING HASH prevents the creation of an ordered index; otherwise,
# 					creating a unique index or primary key on an NDB table automatically
# 					results in the creation of both an ordered index and a hash index,
# 					each of which indexes the same set of columns.
#
# 					For unique indexes that include one or more NULL columns of an NDB
# 					table, the hash index can be used only to look up literal values,
# 					which means that IS [NOT] NULL conditions require a full scan of the table.
#
# 					One workaround is to make sure that a unique index using one or more NULL
# 					columns on such a table is always created in such a way that it includes
# 					the ordered index; that is, avoid employing USING HASH when creating the
# 					index.
#
# 			If you specify an index type that is not valid for a given storage engine, but another
# 			index type is available that the engine can use without affecting query results,
# 			the engine uses the available type.
#
# 			The parser recognizes RTREE as a type name, but currently this cannot be specified
# 			for any storage engine.
#
# 				NOTE:
#
# 					Use of the index_type option before the ON tbl_name clause is deprecated;
# 					support for use of the option in this position will be removed in a 
# 					future MySQL release.
#
# 					If an index_type option is given in both the earlier and later positions,
# 					the final option applies.
#
# 			TYPE type_name is recognized as a synonym for USING type_name.
#
# 			However, USING is the preferred form.
#
# 			The following tables show index characteristics for the storage engines that
# 			support the index_type option.
#
# 				TABLE 13.2 InnoDB STORAGE ENGINE INDEX CHARACTERISTICS
#
# 					INDEX CLASS 		INDEX TYPE 		STORES NULL VALUES 		PERMITS MULTIPLE NULL VALUES 	IS NULL SCAN TYPE 		IS NOT NULL SCAN TYPE
#
# 					Primary key 		BTREE 			No 							No 									N/A 							N/A
# 					Unique 				BTREE 			Yes 							Yes 									Index 						Index
# 					Key 					BTREE 			Yes 							Yes 									Index 						Index
# 					FULLTEXT 			N/A 				Yes 							Yes 									Table 						Table
# 					SPATIAL 				N/A 				No 							No 									N/A 							N/A
#
# 				Table 13.3 MyISAM Storage Engine Index Characteristics
#
# 					INDEX CLASS 		INDEX TYPE 		STORES NULL VALUES 		PERMITS MULTIPLE NULL VALUES 	IS NULL SCAN TYPE 		IS NOT NULL SCAN TYPE
#
# 					Primary key 		BTREE 			No 							No 									N/A 							N/A
# 					Unique 				BTREE 			Yes 							Yes 									Index 						Index
# 					Key 					BTREE 			Yes 							Yes 									Index 						Index
# 					FULLTEXT 			N/A 				Yes 							Yes 									Table 						Table
# 					SPATIAL 				N/A 				No 							No 									N/A 							N/A
#
# 				Table 13.4 MEMORY Storage Engine Index Characteristics
#
# 					INDEX CLASS 		INDEX TYPE 		STORES NULL VALUES 		PERMITS MULTIPLE NULL VALUES 	IS NULL SCAN TYPE 		IS NOT NULL SCAN TYPE
#
# 					Primary key 		BTREE 			No 							No 									N/A 							N/A
# 					Unique 				BTREE 			Yes 							Yes 									Index 						Index
# 					Key 					BTREE 			Yes 							Yes 									Index 						Index
# 					Primary key 		HASH 				No 							No 									N/A 							N/A
# 					Unique 				HASH 				Yes 							Yes 									Index 						Index
# 					Key 					HASH 				Yes 							Yes 									Index 						Index
#
# 				Table 13.5 NDB Storage Engine Index Characteristics
#
# 					INDEX CLASS 		INDEX TYPE 		STORES NULL VALUES 		PERMITS MULTIPLE NULL VALUES 	IS NULL SCAN TYPE 		IS NOT NULL SCAN TYPE
#
# 					Primary key 		BTREE 			No 							No 									Index 						Index
# 					Unique 				BTREE 			Yes 							Yes 									Index 						Index
# 					Key 					BTREE 			Yes 							Yes 									Index 						Index
# 					Primary key 		HASH 				No 							No 									Table (see note 1) 		Table (see note 1)
# 					Unique 				HASH 				Yes 							Yes 									Table (see note 1) 		Table (see note 1)
# 					Key 					HASH 				Yes 							Yes 									Table (see note 1) 		Table (see note 1)
#
# 			Table note:
#
# 				1. USING HASH prevents creation of an implicit ordered index
#
# 		) WITH PARSER parser_name
#
# 			This option can be used only with FULLTEXT indexes.
#
# 			It associates a parser plugin with the index if full-text indexing and searching
# 			operations need special handling.
#
# 			InnoDB and MyISAM support full-text parser plugins
#
# 			See FULL-TEXT PARSER PLUGINS and SECTION 29.2.4.4, "WRITING FULL-TEXT PARSER PLUGINS"
# 			for more information.
#
# 		) COMMENT 'string'
#
# 			Index definitions can include an optional comment of up to 1024 characters
#
# 			The MERGE_THRESHOLD for index pages can be configured for individual indexes using the
# 			index_option COMMENT clause of the CREATE_INDEX statement.
#
# 			For example:
#
# 				CREATE TABLE t1 (id INT);
# 				CREATE INDEX id_index ON t1 (id) COMMENT 'MERGE_THRESHOLD=40';
#
# 			If the page-full percentage for an index page falls below the MERGE_THRESOLD value
# 			when a row is deleted or when a row is shortened by an update operation, InnoDB
# 			attempts to merge the index page with a neighboring index page.
#
# 			The default MERGE_THRESHOLD value is 50, which is the previously hardcoded value.
#
# 			MERGE_THRESHOLD can also be defined at the index level using CREATE_TABLE and ALTER_TABLE statements.
#
# 			For more information, see SECTION 15.8.11, "CONFIGURING THE MERGE THRESHOLD FOR INDEX PAGES"
#
# 		) VISIBLE, INVISIBLE
#
# 			Specify index visibility.
#
# 			Indexes are visible by default. An invisible index is not used by the optimizer.
#
# 			Specification of index visibility applies to indexes other than primary keys
# 			(either explicit or implicit)
#
# 			For more information, see SECTION 8.3.12, "INVISIBLE INDEXES"
#
# TABLE COPYING AND LOCKING OPTIONS
#
# ALGORITHM and LOCK clauses may be given to influence the table copying method and
# level of concurrency for reading and writing the table while its indexes are being modified.
#
# They have the same meanings as for the ALTER_TABLE statement.
#
# For more information, see SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# NDB Cluster supports online operations using the same ALGORITHM=INPLACE syntax used
# with the standard MySQL server.
#
# See SECTION 22.5.14, "ONLINE OPERATIONS WITH ALTER TABLE IN NDB CLUSTER", for more information.
#
# 13.1.16 CREATE LOGFILE GROUP SYNTAX
#
# CREATE LOGFILE GROUP logfile_group
# 		ADD UNDOFILE 'undo_file'
# 		[INITIAL_SIZE [=] initial_size]
# 		[UNDO_BUFFER_SIZE [=] undo_buffer_size]
# 		[REDO_BUFFER_SIZE [=] redo_buffer_size]
# 		[NODEGROUP [=] nodegroup_id]
# 		[WAIT]
# 		[COMMENT [=] 'string']
# 		ENGINE [=] engine_name
#
# This statement creates a new log file group named logfile_group having a single
# UNDO file named 'undo_file'
#
# A CREATE_LOGFILE_GROUP statement has one and only one ADD UNDOFILE clause
#
# For rules covering the naming of log file groups, see SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# NOTE:
#
# 		All NDB Cluster Disk Data objects share the same namespace.
#
# 		This means that each Disk Data Object must be uniquely named
# 		(and not merely each Disk Data object of a given type)
#
# 		For example, you cannot have a tablespace and a log file group
# 		with the same name, or a tablespace and a data file with the same name.
#
# There can be only one log file group per NDB Cluster instance at any given time.
#
# The optional INITIAL_SIZE parameter sets the UNDO file's initial size; if not specified,
# it defaults to 128M (128 megabytes)
#
# The optional UNDO_BUFFER_SIZE parameter sets the size used by the UNDO buffer
# for the log file group; The default value for UNDO_BUFFER_SIZE is 8M (eight MB);
# This value cannot exceed the amount of system memory available.
#
# Both of these parameters are specified in bytes.
#
# You may optionally follow either or both of these with a one-letter
# abbreviation for an order of magnitude, similar to those used in my.cnf
#
# Generally, this is one of the letters M (for megabytes) or G (for gigabytes)
#
# Memory used for UNDO_BUFFER_SIZE comes from the global pool whose size is
# determined by the value of the SharedGlobalMemory data node configuration
# parameter.
#
# This includes any default value implied for this option by the setting
# of the InitialLogFileGroup data node configuration parameter.
#
# The maximum permitted for UNDO_BUFFER_SIZE is 629145600 (600 MB)
#
# On 32-bit systems, the maximum supported value for INITIAL_SIZE 
# is 4294967296 (4 GB) (Bug #29186)
#
# The minimum allowed value for INITIAL_SIZE is 1048576 (1 MB)
#
# The ENGINE option determines the storage engine to be used by this log file group,
# with engine_name being the name of the storage engine.
#
# In MySQL 8.0, this must be NDB (or NDBCLUSTER)
#
# If ENGINE is not set, MySQL tries to use the engine specified by the default_storage_engine
# server system variable (formerly storage engine)
#
# In any case, if the engine is not specified as NDB or NDBCLUSTER, the CREATE LOGFILE GROUP
# statement appears to succeed but actually fails to create the log file group, as shown
# here:
#
# 		CREATE LOGFILE GROUP lg1
# 			ADD UNDOFILE 'undo.dat' INITIAL_SIZE = 10M;
# 		Query OK, 0 rows affected, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS;
# 		+-----------+-----------+------------------------------------------------------------------------------------------------+
# 		| Level 		| Code 		| Message 																								 					 |
# 		+-----------+-----------+------------------------------------------------------------------------------------------------+
# 		| Error 		| 1478 	   | Table storage engine 'InnoDB' does not support the create option 'TABLESPACE or LOGFILE GROUP' |
# 		+-----------+-----------+------------------------------------------------------------------------------------------------+
# 		1 row in set (0.00 sec)
#
# 		DROP LOGFILE GROUP lg1 ENGINE = NDB;
# 		ERROR 1529 (HY000): Failed to drop LOGFILE GROUP
#
# 		CREATE LOGFILE GROUP lg1
# 			ADD UNDOFILE 'undo.dat' INITIAL_SIZE = 10M
# 			ENGINE = NDB;
# 		Query OK, 0 rows affected (2.97 sec)
#
# The fact that the CREATE LOGFILE GROUP statement does not actually return an error when a non-NDB storage
# engine is named, but rather appears to succeed, is a known issue which we hope to address in a future
# release of NDB Cluster.
#
# REDO_BUFFER_SIZE, NODEGROUP, WAIT and COMMENT are parsed but ignored, and so have no effect in MySQL 8.0
#
# These options are intended for future expansion
#
# When used with ENGINE [=] NDB, a log file group and associated UNDO log file are created on each Cluster
# data node.
#
# You can verify that the UNDO files were created and obtain information about them by querying the
# INFORMATION_SCHEMA.FILES table.
#
# For example:
#
# 		SELECT LOGFILE_GROUP_NAME, LOGFILE_GROUP_NUMBER, EXTRA
# 			FROM INFORMATION_SCHEMA.FILES
# 			WHERE FILE_NAME = 'undo_10.dat';
# 		+-------------------------+------------------------------+--------------------+
# 		| LOGFILE_GROUP_NAME 	  | LOGFILE_GROUP_NUMBER 		   | EXTRA 					|
# 		+-------------------------+------------------------------+--------------------+
# 		| lg_3 						  | 11 								   | CLUSTER_NODE=3 	   |
# 		| lg_3 						  | 11 									| CLUSTER_NODE=4 		|
# 		+-------------------------+------------------------------+--------------------+
#
# CREATE_LOGFILE_GROUP is useful only with Disk Data storage for NDB Cluster.
#
# See SECTION 22.5.13, "NDB CLUSTER DISK DATA TABLES"
#
# 13.1.17 CREATE PROCEDURE AND CREATE FUNCTION SYNTAX
#
# 		CREATE
# 			[DEFINER = { user | CURRENT_USER }]
# 			PROCEDURE sp_name ([proc_parameter[,---]])
# 			[characteristic ---] routine_body
#
# 		CREATE
# 			[DEFINER = { user | CURRENT_USER }]
# 			FUNCTION sp_name ([func_parameter[,---]])
# 			RETURNS type
# 			[characteristic ---] routine_body
#
# 		proc_parameter:
# 			[ IN | OUT | INOUT ] param_name type
#
# 		func_parameter:
# 			param_name type
#
# 		type:
# 			Any valid MySQL data type
#
# 		characteristic:
# 			COMMENT 'string'
# 		 | LANGUAGE SQL
# 		 | [NOT] DETERMINISTIC
# 		 | { CONTAINS SQL | NO SQL | READS SQL DATA | MODIFIES SQL DATA }
# 		 | SQL SECURITY { DEFINER | INVOKER }
#
# 		routine_body:
# 			Valid SQL routine statement
#
# These statements create stored routines.
#
# By default, a routine is associated with the default database.
#
# To associate the routine explicitly with a given database, specify the
# name as db_name.sp_name when you create it.
#
# The CREATE_FUNCTION statement is also used in MySQL to support UDFs (user-defined functions)
#
# See SECTION 29.4, "ADDING NEW FUNCTIONS TO MYSQL"
#
# A UDF can be regarded as an external stored function. Stored functions share their namespace with
# UDFs.
#
# See SECTION 9.2.4, "FUNCTION NAME PARSING AND RESOLUTION", for the rules describing how the server
# interprets references to different kinds of functions.
#
# To invoke a stored procedure, use the CALL statement (see SECTION 13.2.1, "CALL SYNTAX")
#
# To invoke a stored function, refer to it in an expression. The function returns a
# value during expression evaluation.
#
# CREATE_PROCEDURE and CREATE_FUNCTION require the CREATE_ROUTINE privilege.
#
# They might also require the SET_USER_ID or SUPER privilege, depending on the
# DEFINER value, as described later in this section.
#
# If binary logging is enabled, CREATE_FUNCTION might require the SUPER privilege,
# as described in SECTION 24.7, "BINARY LOGGING OF STORED PROGRAMS"
#
# By default, MySQL automatically grants the ALTER_ROUTINE and EXECUTE privileges
# to the routine creator.
#
# This behavior can be changed by disabling the automatic_sp_privileges system variable.
#
# See SECTION 24.2.2, "STORED ROUTINES AND MYSQL PRIVILEGES"
#
# The DEFINER and SQL SECURITY clauses specify the security context to be used when
# checking access privileges at routine execution time, as described later in this section.
#
# If the routine name is the same as the name of a built-in SQL function, a syntax error occurs
# unless you use a space between the name and the following parenthesis when defining
# the routine or invoking it later.
#
# For this reason, avoid using the names of existing SQL functions for your own stored routines.
#
# The IGNORE_SPACE SQL mode applies to built in functions, not to stored routines.
#
# IT is always permissibile to have spaces after a stored routine name, regardless
# of whether IGNORE_SPACE is enabled.
#
# The parameter list enclosed within parentheses must always be present.
#
# If there are no parameters, an empty parameter list of () should be used.
#
# Parameter names are not case sensitive.
#
# Each parameter is an IN parameter by default. To specify otherwise for a parameter,
# use the keyword OUT or INOUT before the parameter name.
#
# NOTE:
#
# 		Specifying a parameter as IN, OUT, or INOUT is valid only for a PROCEDURE.
#
# 		For a FUNCTION, parameters are always regarded as IN parameters.
#
# An IN parameter passes a value into a procedure.
#
# The procedure might modify the value, but the modification is not visible
# to the caller when the procedure returns.
#
# An OUT parameter passes a value from the procedure back to the caller.
#
# Its initial value is NULL within the procedure, and its value is visible
# to the caller when the procedure returns.
#
# An INOUT parameter is initialized by the caller, can be modified by the
# procedure, and any change made by the procedure is visible to the caller
# when the procedure returns.
#
# For each OUT or INOUT parameter, pass a user-defined variable in the CALL
# statement that invokes the procedure so that you can obtain its value
# when the procedure returns.
#
# If you are calling the procedure from within another stored procedure or
# function, you can also pass a routine parameter or local routine variable
# as an OUT or INOUT parameter.
#
# If you are calling the procedure from within a trigger, you can also pass
# NEW.col_name as an OUT or INOUT parameter.
#
# For information about the effect of unhandled conditions on procedure params,
# see SECTION 13.6.7.8, "CONDITION HANDLING AND OUT OR INOUT PARAMETERS"
#
# Routine parameters cannot be referenced in statements prepared within the
# routine; see SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# The following example shows a simple stored procedure that uses an OUT parameter:
#
# 		delimiter //
#
# 		CREATE PROCEDURE simpleproc (OUT param1 INT)
# 		BEGIN
# 			SELECT COUNT(*) INTO param1 FROM t;
# 		END//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		delimiter ;
#
# 		CALL simpleproc(@a);
# 		Query OK, 0 rows affected (0.00 sec)
# 
# 		SELECT @a;
# 		+---------+
# 		| @a 		 |
# 		+---------+
# 		| 3 		 |
# 		+---------+
# 		1 row in set (0.00 sec)
#
# The example uses the mysql client delimiter command to change the statement
# delimiter from ; to // while the procedure is being defined.
#
# This enables the ; delimiter used in the procedure body to be passed through
# to the server rather than being interpreted by mysql itself.
#
# See SECTION 24.1, "DEFINING STORED PROGRAMS"
#
# The RETURNS clause may be specified only for a FUNCTION, for which it is mandatory.
#
# It indicates the return type of the function, and the function body must contain
# a RETURN value statement.
#
# If the RETURN statement returns a value of a different type, the value is coerced
# to the proper type.
#
# For example, if a function specifies an ENUM or SET value in the RETURNS clause,
# but the RETURN statement returns an integer, the value returned from the function
# is the string for the corresponding ENUM member of set of SET members.
#
# The following example function takes a parameter, performs an operation using an
# SQL function, and returns the result.
#
# In this case, it is unnecessary to use delimiter because the function definition
# contains no internal ; statement delimiters:
#
# 			CREATE FUNCTION hello (s CHAR(20))
# 			RETURNS CHAR(50) DETERMINISTIC
# 			RETURN CONCAT('Hello, ',s,'!');
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT hello('world');
# 		+--------------------+
# 		| hello('world') 		|
# 		+--------------------+
# 		| Hello, world! 		|
# 		+--------------------+
# 		1 row in set (0.00 sec)
#
# Parameter types and function return types can be declared to use any valid data type.
#
# The COLLATE attribute can be used if preceded by a CHARACTER SET specification.
#
# The routine_body consists of a valid SQL routine statement.
#
# This can be a simple statement such as SELECT or INSERT, or a compound statement
# written using BEGIN and END.
#
# Compound statements can contain declarations, loops, and other control structure
# statements.
#
# The syntax for these statements is described in SECTION 13.6, "COMPOUND-STATEMENT SYNTAX"
#
# MySQL permits routines to contain DDL statements, such as CREATE and DROP.
#
# MySQL also permits stored procedures (but not stored functions) to contain
# SQL transaction statements such as COMMIT.
#
# Stored functions may not contain statements that perform explicit or implicit
# commit or rollback.
#
# Support for these statements is not required by the SQL standard, which states
# that  each DBMS vendor may decide whether to permit them.
#
# Statements that return a result can be used within a stored procedure but not
# within a stored function.
#
# This prohibition includes SELECT statements that do not have an INTO var_list clause
# and other statements such as SHOW, EXPLAIN and CHECK_TABLE
#
# FOr statements that cna be determined at function definition time to return a result
# set, a Not allowed to return a result set from a function error occurs (ER_SP_NO_RETSET)
#
# For statements that can be determined only at runtime to return a result set, a 
# PROCEDURE %s can't return a result set in the given context error occurs (ER_SP_BADSELECT)
#
# USE statements within stored routines are not permitted.
#
# When a routine is invoked, an implicit USE db_name is performed (and undone when the
# routine terminates)
#
# The causes the routine to have the given default database while it executes.
#
# References to objects in databases other than the routine default database
# should be qualified with the appropriate database name.
#
# For additional information about statements that are not permitted in stored routines,
# see SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# For information about invoking stored procedures from within programs written in a language
# that has a MySQL interface, see SECTION 13.2.1, "CALL SYNTAX"
#
# MySQL stores the sql_mode system variable setting in effect when a routine is created or
# altered, and always executes the routine with this setting in force, regardless of the
# current server SQL mode when the routine begins executing.
#
# The switch from the SQL mode of the invoker to that of the routine occurs after evaluation
# of arguments and assignment of the resulting values to routine parameters.
#
# If you define a routine in strict SQL mode but invoke it in nonstrict mode, assignment
# of arguments to routine parameters does not take place in strict mode.
#
# If you require that expressions passed to a routine be assigned in strict SQL mode, you
# should invoke the routine with strict mode in effect.
#
# The COMMENT characteristic is a MySQL extension, and may be used to describe the stored
# routine.
#
# This information is displayed by the SHOW_CREATE_PROCEDURE and SHOW_CREATE_FUNCTION statements.
#
# The LANGUAGE characteristic indicates the language in which the routine is written.
#
# The server ignores the characteristic; only SQL routines are supported.
#
# A routine is considered "determinsitic" if it always produces the same result for the
# same input params, and "not deterministic" otherwise.
#
# If neither DETERMINISTIC nor NOT DETERMINISTIC is given in the routine definition, the default
# is NOT DETERMINSITIC.
#
# To declare that a function is deterministic, you must specify DETERMINISTIC explicitly.
#
# ASsessment of the nature of a routine is based on the "honesty" of the creator:
#
# MySQL does not  check that a routien declared DETERMINSITIC is free of statements that produce
# RNG results.
#
# However, misdeclaring a routine might affect results or affect performance.
#
# Declaring a nondeterministic routine as DETERMINISTIC might lead to unexpected
# results by causing the optimizer to make incorrect execution plan choices.
#
# Declaring a deterministic routine as NONDETERMINISTIC might diminish performance
# by causing available optimizations not ot be used.
#
# If binary logging is enabled, the DETERMINISTIC characteristic affects which routine
# definitions MySQL accepts.
#
# See SECTION 24.7, "BINARY LOGGING OF STORED PROGRAMS"
#
# A routine that contains the NOW() function (or its synonyms) or RAND()
# is RNG, but it might still be replication-safe.
#
# For NOW(), the binary log includes the timestamp and replicates correctly.
#
# RAND() also replicates correctly as long as it is called only a single
# time during the execution of a routine.
#
# (You can consider the routine execution timestamp and random number seed as implicit
# inputs that are identical on the master and slave)
#
# Several characteristics provide information about the nature of data use by the routine.
#
# In MySQL, these characteristics are advisory only.
#
# THe server does not use them to constrain what kinds of statements a routine will be
# permitted to execute.
#
# 		) CONTAINS SQL indicates that the routine does not contain statements that read or write data.
#
# 			This is the default if none of these characteristics is given explicitly.
#
# 			Examples of such statements are SET @x = 1 or DO RELEASE_LOCK('abc'), which execute
# 			but neither read nor write data.
#
# 		) NO SQL indicates that the routine contains no SQL statements.
#
# 		) READS SQL DATA indicates that the routine contains statements that read data (for example, SELECT),
# 			but not statements that write data.
#
# 		) MODIFIES SQL DATA indicates that the routine contains statements that may write data (for example, INSERT or DELETE)
#
# The SQL SECURITY characteristic can be DEFINER or INVOKER to specify the security context; that is, whether the
# routine executes using the privileges of the account named in the routine DEFINER clause or the user who
# invokes it.
#
# This account must have permission to access the database with which the routine is associated.
#
# The default value is DEFINER.
#
# The user who invokes the routine must have the EXECUTE privilege for it, as must the DEFINER account
# if the routine executes in definer security context.
#
# The DEFINER clause specifies the MySQL account to be used when checking access privileges at routine
# execution time for routines that have the SQL SECURITY DEFINER characteristic.
#
# If a user value is given for the DEFINER clause, it should be a MySQL account specified as 
# 'user_name'@'host_name', CURRENT_USER or CURRENT_USER()
#
# THe default DEFINER value is the user who executes the CREATE_PROCEDURE or CREATE_FUNCTION
# statement.
#
# This is the same as specifying DEFINER = CURRENT_USER explicitly.
#
# If you specify the DEFINER clause, these rules determine the valid DEFINER user values:
#
# 		) If you do not have the SET_USER_ID or SUPER privilege, the only permitted user value is
# 			your own account, either specified literally or by using CURRENT_USER.
#
# 			You cannot set the definer to some other account.
#
# 		) If you have the SET_USER_ID or SUPER privilege, you can specify any syntactically
# 		valid account name.
#
# 		If the account does not exist, a warning is generated.
#
# 		) ALthough it is possible to create a routine with a nonexistent DEFINER account,
# 			an error occurs at routine execution time if the SQL SECURITY value is DEFINER
# 			but the definer account does not exist.
#
# For more information about stored routine security, see SECTION 24.6, "ACCESS CONTROL FOR STORED PROGRAMS AND VIEWS"
#
# Within a stored routine that is defined with the SQL SECURITY DEFINER characteristic, CURRENT_USER
# returns the routine's DEFINER value.
#
# For information about user auditing within stored routines, see SECTION 6.3.13, "SQL-BASED MYSQL ACCOUNT ACTIVITY AUDITING"
#
# Consider the following procedure, which displays a count of the number of MySQL accounts listed in
# the mysql.user system table:
#
# 		CREATE DEFINER = 'admin'@'localhost' PROCEDURE account_count()
# 		BEGIN
# 			SELECT 'Number of accounts:', COUNT(*) FROM mysql.user;
# 		END;
#
# The procedure is assigned a DEFINER account of 'admin'@'localhost' no matter which user defines it.
#
# It executes with the privileges of that account no matter which user invokes it
# (because the default security characteristic is DEFINER)
#
# THe procedure succeeds or fails depending on whether invoker has the EXECUTE
# privilege for it and 'admin'@'localhost' has the SELECT privilege for the mysql.user table
#
# Now suppose that the procedure is defined with the SQL SECURITY INVOKER characteristic:
#
# 		CREATE DEFINER = 'admin'@'localhost' PROCEDURE account_count()
# 		SQL SECURITY INVOKER
# 		BEGIN
# 			SELECT 'Number of accounts:', COUNT(*) FROM mysql.user;
# 		END;
#
# The procedure still has a DEFINER of 'admin'@'localhost', but in this case, it executes
# with the privileges of the invoking user.
#
# Thus, the procedure succeeds or fails depending on whether the invoker has the EXECUTE
# privilege for it and the SELECT privilege for the mysql.user table
#
# THe server handles the data type of a routine parameter, local routine variable created
# with DECLARE, or function return value as follows:
#
# 		) Assignments are checked for data type mismatches and overflow.
#
# 			Conversion and overflow problems result in warnings, or errors in strict SQL mode.
#
# 		) Only scalar values can be assigned. For example, a statement such as SET x = (SELECT 1, 2) is invalid
#
# 		) For character data types, if CHARACTER SET is included in the declaration, the specified character set
# 			and its default collation is used.
#
# 			IF the COLLATE attribute is also present, that collation is used rather than the default collation.
#
# 			If CHARACTER SET and COLLATE are not present, the database character set and collation in effect
# 			at routine creation time are used.
#
# 			To avoid having the server use the database character set and collation, provide an explicit
# 			CHARACTER SET and a COLLATE attribute for character data parameters.
#
# 			If you change the database default character set or collation, stored routines that use
# 			the database defaults must be dropped and recreated so that they use the new defaults.
#
# 			The database character set and collation are given by the value of the character_set_database
# 			and collation_database system variables.
#
# 			For more information, see SECTION 10.3.3, "DATABASE CHARACTER SET AND COLLATION"
#
# 13.1.18 CREATE SERVER SYNTAX
#
# CREATE SERVER server_name
# 		FOREIGN DATA WRAPPER wrapper_name
# 		OPTIONS (option [, option] ---)
#
# option:
# 		{ HOST character-literal
# 		| DATABASE character-literal
#		| USER character-literal
# 		| PASSWORD character-literal
# 		| SOCKET character-literal
# 		| OWNER character-literal
# 		| PORT numeric-literal }
#
# This statement creates the definition of a server for use with the FEDERATED storage engine.
#
# The CREATE SERVER statement creates a new row in the servers table in the mysql database.
#
# This statement requires the SUPER privilege.
#
# The server_name should be a unique reference to the server. Server definitions are global
# within the scope of the server, it is not possible to qualify the server definition to
# a specific database.
#
# server_name has a maximum length of 64 characters (names longer than 64 chars are silently
# truncated), and is case insensitive.
#
# You may specify the name as a quoted string.
#
# The wrapper_name is an identifier and may be quoted with single quotation marks.
#
# For each option you must specify either a character literal or numeric literal
#
# Character literals are UTF-8, support a max length of 64 chars and default to a
# blank (empty) string.
#
# String literals are silently truncated to 64 chars.
#
# Numeric literals must be a number between 0 and 9999, default value is 0.
#
# NOTE:
#
# 		The OWNER option is currently not applied, and has no effect on the ownership or operation
# 		of the server connection that is created.
#
# The CREATE SERVER statement creates an entry in the mysql.servers table that can later
# be used with the CREATE_TABLE statement when creating a FEDERATED table.
#
# The options that you specify will be used to populate the columns in the mysql.servers table.
#
# The table columns are Server_name, Host, Db, Username, Password, Port and Socket.
#
# For example:
#
# 		CREATE SERVER s
# 		FOREIGN DATA WRAPPER mysql
# 		OPTIONS (USER 'Remote', HOST '198.51.100.106', DATABASE 'test');
#
# Be sure to specify all options necessary to establish a connection to the server.
#
# The user name, host name, and DB name are mandatory.
#
# oTher options might be required as well, such as Password.
#
# The data stored in teh table can be used when creating a connection to a FEDERATED table:
#
# 		CREATE TABLE t (s1 INT) ENGINE=FEDERATED CONNECTION='s';
#
# For more information, see SECTION 16.8, "THE FEDERATED STORAGE ENGINE"
#
# CREATE SERVER causes an implicit commit. See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# CREATE SERVER is not written to the binary log, regardless of the logging format that is in use.
#
# 13.1.19 CREATE SPATIAL REFERENCE SYSTEM SYNTAX
#
# CREATE OR REPLACE SPATIAL REFERENCE SYSTEM
# 		srid srs_attribute
#
# CREATE SPATIAL REFERENCE SYSTEM
# 		[IF NOT EXISTS]
# 		srid srs_attribute ---
#
# srs_attribute: {
# 		NAME 'srs_name'
# 	 | DEFINITION 'definition'
# 	 | ORGANIZATION 'org_name' IDENTIFIED BY org_id
# 	 | DESCRIPTION 'description'
# }
#
# srid, org_id: 32-bit unsigned integer
#
# This statement creates a spatial reference system (SRS) definition and stores it in the data dictionary.
#
# THe definition can be inspected using the INFORMATION_SCHEMA ST_SPATIAL_REFERENCE_SYSTEMS table.
#
# This statement requires the SUPER privilege.
#
# If neither OR REPLACE nor IF NOT EXISTS is specified, an error occurs if an SRS definition with the 
# SRID value already exists.
#
# With CREATE OR REPLACE syntax, any existing SRS Definition with the same SRID value is replaced,
# unless the SRID value is used by some column in an existing table.
#
# In taht case, an error occurs.
#
# For example:
#
# 		CREATE OR REPLACE SPATIAL REFERENCE SYSTEM 4326 ---;
# 		ERROR 3716 (SR005): Can't modify SRID 4326.
#
# 		There is at least one column depending on it.
#
# To identify which column or columns use the SRID, use this query:
#
# 		SELECT * FROM INFORMATION_SCHEMA.ST_GEOMETRY_COLUMNS WHERE SRS_ID=4326;
#
# With CREATE_---_IF NOT EXISTS syntax, any existing SRS definition with the same SRID value
# causes the new definition to be ignored and a warning occurs.
#
# SRID values must be in the range of 32-bit unsigned integers, with these restrictions:
#
# 		) SRID 0 is a valid SRID but cannot be used with CREATE_SPATIAL_REFERENCE_SYSTEM
#
# 		) If the value is in a reserved SRID range, a warning occurs.
#
# 			Reserved ranges are [0, 32767] (reserved by EPSG), [60,000,000,69,999,999,999] (reserved by EPSG),
# 			and [2,000,000,000, 2,147,483,647] (reserved by MySQL)
#
# 		) Uses should not create SRSs with SRIDs in the reserved ranges.
#
# 			Doing so runs the risk that the SRIDs will conflict with future SRS
# 			definitions distributed with MySQL, with the reuslt that hte new system-provided
# 			SRS are not installed for MySQL upgrades or that hte user-defined SRSs are overwritten.
#
# Attributes for the statement must satisfy these conditions:
#
# 		) Attributes can be given in any order, but not attribute can be given more than once
#
# 		) The NAME and DEFINITION attributes are mandatory
#
# 		) The NAME srs_name attribute value must be unique. The combination of the ORGANIZATION
# 			org_name and org_id attribute values must be unique.
#
# 		) The NAME srs_name attribute value and ORGANIZATION org_name attribute value cannot be
# 			empty or begin or end with whitespace.
#
# 		) String values in attribute specifications cannot contain control chars, including newline
#
# 		) The following table shows hte max lengths for string attrib values
#
# 			TABLE 13.6 CREATE SPATIAL REFERENCE SYSTEM ATTRIBUTE LENGTHS
#
# 			Attribute 			Max length (chars)
#
# 			NAME 					80
#
# 			DEFINITION 			4096
#
# 			ORGANIZATION 		256
#
# 			DESCRIPTION 		2048
#
# Here is an example CREATE_SPATIAL_REFERENCE_SYSTEM statement.
#
# The DEFINITION value is reformatted across multiple lines for readability.
#
# (For the statement to be legal, the value actually must be given on a single line)
#
# 		CREATE SPATIAL REFERENCE SYSTEM 4120
# 		NAME 'Greek'
# 		ORGANIZATION 'EPSG' IDENTIFIED BY 4120
# 		DEFINITION
# 			'GEOGCS["Greek",DATUM["Greek",SPHEROID["Bessel 1841",
# 			<numbers>, etc.';
#
# The grammar for SRS definition is based on teh grammar defined in OpenGIS Implementation Spec: Coordinate tarnsformation services.
#
# Revision 1.00, OGC 01-009, January 12, 2001, Section 7.2
#
# This specification exists at <link>
#
# MySQL incorporates these changes to the spec:
#
# 		) Only the <horz cs> production rule is implemented (that is, geographic and projected SRSs)
#
# 		) There is an optional, nonstandard <authority> clause for <parameter>
#
# 			This makes it possible to recognize projection parameters by authority instead of name
#
# 		) SRS definitions may not contain newlines
#
# 13.1.20 CREATE TABLE SYNTAX
#
# 13.1.20.1 CREATE TABLE STATEMENT RETENTION
# 13.1.20.2 FILES CREATED BY CREATE TABLE
# 13.1.20.3 CREATE TEMPORARY TABLE SYNTAX
# 13.1.20.4 CREATE TABLE --- LIKE SYNTAX
# 13.1.20.5 CREATE TABLE --- SELECT SYNTAX
#
# 13.1.20.6 USING FOREIGN KEY CONSTRAINTS
# 13.1.20.7 SILENT COLUMN SPECIFICATION CHANGES
# 13.1.20.8 CREATE TABLE AND GENERATED COLUMNS
# 13.1.20.9 SECONDARY INDEXES AND GENERATED COLUMNS
# 
# 13.1.20.10 SETTING NDB_TABLE OPTIONS
#
# CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name
# 		(create_definition, ---)
# 		[table_options]
# 		[partition_options]
#
# CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name
# 		[(create_definition,---)]
# 		[table_options]
# 		[partition_options]
# 		[IGNORE | REPLACE]
# 		[AS] query_expression
#
# CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name
# 		{ LIKE old_tbl_name | (LIKE old_tbl_name) }
#
# create_definition:
# 		col_name column_definition
# 	 | [CONSTRAINT [symbol]] PRIMARY KEY [index_type] (key_part,---)
# 		[index_option] ---
# 	 | {INDEX|KEY} [index_name] [index_type] (key_part,---)
# 		[index_option] ---
#
# 	 | [CONSTRAINT [symbol]] UNIQUE [INDEX|KEY]
# 			[index_name] [index_type] (key_part,---)
# 			[index_option] ---
# 	 | {FULLTEXT|SPATIAL} [INDEX|KEY] [index_name] (key_part,---)
# 			[index_option] ---
# 	 | [CONSTRAINT [symbol]] FOREIGN KEY
# 			[index_name] (col_name, ---) reference_definition
#   | CHECK (expr)
#
# column_definition:
# 		data_type [NOT NULL | NULL] [DEFAULT {literal | (expr)} ]
# 			[AUTO_INCREMENT] [UNIQUE [KEY]] [[PRIMARY] KEY]
# 			[COMMENT 'string']
# 			[COLLATE collation_name]
# 			[COLUMN_FORMAT {FIXED|DYNAMIC|DEFAULT}]
# 			[STORAGE {DISK|MEMORY|DEFAULT}]
# 			[reference_definition]
# 		| data_type
# 			[GENERATED ALWAYS] AS (expression)
# 			[VIRTUAL | STORED] [NOT NULL | NULL]
# 			[UNIQUE [KEY]] [[PRIMARY] KEY]
# 			[COMMENT 'string']
#
# data_Type:
# 		(see Chapter 11, Data types)
#
# key_part: {col_name [(length)] | (expr)} [ASC | DESC]
#
# index_type:
# 		USING {BTREE | HASH}
#
# index_option:
# 		KEY_BLOCK_SIZE [=] value
# 	 | index_type
# 	 | WITH PARSER parser_name
#   | COMMENT 'string'
# 	 | {VISIBLE | INVISIBLE}
#
# reference_definition:
# 		REFERENCES tbl_name (key_part, ---)
# 			[MATCH FULL | MATCH PARTIAL | MATCH SIMPLE]
# 			[ON DELETE reference_option]
# 			[ON UPDATE reference_option]
#
# reference_option:
# 		RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT
#
# table_options:
# 		table_option [[,] table_option] ---
#
# table_option:
# 		AUTO_INCREMENT [=] value
# 	 | AVG_ROW_LENGTH [=] value
#   | [DEFAULT] CHARACTER SET [=] charset_name
# 	 | CHECKSUM [=] {0 | 1}
#   | [DEFAULT] COLLATE [=] collation_name
# 	 | COMMENT [=] 'string'
# 	 | COMPRESSION [=] {'ZLIB'|'LZ4'|'NONE'}
# 	 | CONNECTION [=] 'connect_string'
#   | {DATA|INDEX} DIRECTORY [=] 'absolute path to directory'
# 	 | DELAY_KEY_WRITE [=] {0 | 1}
# 	 | ENCRYPTION [=] {'Y' | 'N'}
# 	 | ENGINE [=] engine_name
#   | INSERT_METHOD [=] { NO | FIRST | LAST }
#   | KEY_BLOCK_SIZE [=] value
#   | MAX_ROWS [=] value
#   | MIN_ROWS [=] value
#   | PACK_KEYS [=] {0 | 1 | DEFAULT}
#   | PASSWORD [=] 'string'
#   | ROW_FORMAT [=] {DEFAULT|DYNAMIC|FIXED|COMPRESSED|REDUNDANT|COMPACT}
#   | STATS_AUTO_RECALC [=] {DEFAULT|0|1}
#   | STATS_PERSISTENT [=] {DEFAULT|0|1}
#   | STATS_SAMPLE_PAGES [=] value
#   | TABLESPACE tablespace_name [STORAGE {DISK|MEMORY|DEFAULT}]
#   | UNION [=] (tbl_name[,tbl_name]---)
#
# partition_options:
# 		PARTITION BY
# 			{ [LINEAR] HASH(expr)
# 			| [LINEAR] KEY [ALGORITHM={1|2}] (column_list)
# 			| RANGE{(expr) | COLUMNS(column_list)}
# 			| LIST{(expr) | COLUMNS(column_list)} }
# 		[PARTITIONS num]
# 		[SUBPARTITION BY
# 			{ [LINEAR] HASH(expr)
# 			| [LINEAR] KEY [ALGORITHM={1|2}] (column_list) }
# 		 [SUBPARTITIONS num]
# 		]
# 		[(partition_definition [, partition_definition] ---)]
#
# partition_definition:
# 		PARTITION partition_name
# 			[VALUES
# 				{LESS THAN {(expr | value_list) | MAXVALUE}
# 				|
# 				IN (value_list)}]
# 			[[STORAGE] ENGINE [=] engine_name]
# 			[COMMENT [=] 'string' ]
# 			[DATA DIRECTORY [=] 'data_dir']
# 			[INDEX DIRECTORY [=] 'index_dir']
# 			[MAX_ROWS [=] max_number_of_rows]
# 			[MIN_ROWS [=] min_number_of_rows]
# 			[TABLESPACE [=] tablespace_name]
# 			[(subpartition_definition [, subpartition_definition] ---)]
#
# subpartition_definition:
# 		SUBPARTITION logical_name
# 			[[STORAGE] ENGINE [=] engine_name]
# 			[COMMENT [=] 'string' ]
# 			[DATA DIRECTORY [=] 'data_dir']
# 			[INDEX DIRECTORY [=] 'index_dir']
# 			[MAX_ROWS [=] max_number_of_rows]
# 			[MIN_ROWS [=] min_number_of_rows]
# 			[TABLESPACE [=] tablespace_name]
#
# query_expression:
# 		SELECT --- (Some valid select or union statement)
#
# CREATE_TABLE creates a table with the given name. You must have the CREATE privilege for the table.
#
# By default, tables are created in the default database, using the InnoDB storage engine.
#
# An error occurs if the table exists, if there is no default database, or if the database
# does not exist.
#
# For information about the physical representation of a table, see SECTION 13.1.20.2, "FILES CREATED BY CREATE TABLE"
#
# The original CREATE_TABLE statement, including all specifications and table options are stored
# by MySQL when the table is created.
#
# For more information, see SECTION 13.1.20.1, "CREATE TABLE STATEMENT RETENTION"
#
# There are several aspects to the CREATE_TABLE statement, described under the following topics
# in this section:
#
# 		) TABLE NAME
#
# 		) TEMPORARY TABLES
#
# 		) CLONING OR COPYING A TABLE
#
# 		) COLUMN DATA TYPE AND ATTRIBUTES
#
# 		) INDEXES AND FOREIGN KEYS
#
# 		) TABLE OPTIONS
#
# 		) CREATING PARTITIONED TABLES
#
# TABLE NAME
#
# 		) tbl_name
#
# 			The table name can be specified as db_name.tbl_name to create the table in a specific database.
#
# 			This works regardless of whether there is a default database, assuming that the database exists.
#
# 			If you use quoted identifiers, quote the database and table names separately.
#
# 			For example, write `mydb`.`mytbl`, not `mydb.mytbl`
#
# 			Rules for permissible table names are given in SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# 		) IF NOT EXISTS
#
# 			Prevents an error from occurring if the table exists.
#
# 			However, there is no verification that the existing table has a structure identical
# 			to that indicated by the CREATE_TABLE statement.
#
# TEMPORARY TABLES
#
# You can use the TEMPORARY keyword when creating a table.
#
# A TEMPORARY table is visible only within the current session, and is dropped automatically
# when the session is closed.
#
# For more information, see SECTION 13.1.20.3, "CREATE TEMPORARY TABLE SYNTAX"
#
# CLONING OR COPYING A TABLE
#
# 		) LIKE
#
# 			Use CREATE TABLE --- LIKE to create an empty table based on the defininition of another
# 			table, including any column attributes and indexes defined in the original table:
#
# 				CREATE TABLE new_tbl LIKE orig_tbl;
#
# 			For more information, see SECTION 13.1.20.4, "CREATE TABLE --- LIKE SYNTAX"
#
# 		) [AS] query_expression
#
# 			To create one table from another, add a SELECT statement at the end of the
# 			CREATE TABLE statement:
#
# 				CREATE TABLE new_tbl AS SELECT * FROM orig_tbl;
#
# 			For more information, see SECTION 13.1.20.5, "CREATE TABLE --- SELECT SYNTAX"
#
# 		) IGNORE|REPLACE
#
# 			The IGNORE and REPLACE options indicate how to handle rows that duplicate unique key
# 			values when copying a table using a SELECT statement.
#
# 			For more information, see SECTION 13.1.20.5, "CREATE TABLE --- SELECT SYNTAX"
#
# COLUMN DATA TYPES AND ATTRIBUTES
#
# There is a hard limit of 4096 columns per table, but the effective maximum may be less
# for a given table and depends on the factors discussed in SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# 		) data_type
#
# 			data_type represents the data type in a column definition.
#
# 			For a full description of the syntax available for specifying column data types,
# 			as well as information about the properties of each type, see CHAPTER 11, DATA TYPES
#
# 				) Some attributes do not apply to all data types.
#
# 					AUTO_INCREMENT applies only to integer and floating-point types.
#
# 					Prior to MySQL 8.0.13, DEFAULT does not apply to the BLOB, TEXT, GEOMETRY
# 					and JSON types.
#
# 				) Character data types (CHAR, VARCHAR, the TEXT types, ENUM, SET and any synonyms) synonyms) can include
# 					CHARACTER SET to specify the character set for the column.
#
# 					CHARSET is a synonym for CHARACTER SET.
#
# 					A collation for the character set can be specified with the COLLATE attribute,
# 					along with any other attributes.
#
# 					For details, see CHAPTER 10, CHARACTER SETS, COLLATIONS, UNICODE. Example:
#
# 						CREATE TABLE t (c CHAR(20) CHARACTER SET utf8 COLLATE utf8_bin);
#
# 					MySQL 8.0 interprets length specifications in character column definitions in characters.
#
# 					Lengths for BINARY and VARBINARY are in bytes.
#
# 				) For CHAR, VARCHAR, BINARY and VARBINARY columns, indexes can be created that use only
# 					the leading part of column values, using col_name(length) syntax to specify an index
# 					prefix length.
#
# 					BLOB and TEXT columns also can be indexed, but a prefix length must be given.
#
# 					Prefix lengths are given in characters for nonbinary string types and in bytes
# 					for binary string types.
#
# 					That is, index entries consist of the first length characters of each column value
# 					for CHAR, VARCHAR, and TEXT columns, and the first length bytes of each column value
# 					for BINARY, VARBINARY, and BLOB columns.
#
# 					Indexing only a prefix of column values like this can make the index file much smaller.
#
# 					For additional information about index prefixes, see SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# 					Only the InnoDB and MyISAM storage engines support indexing on BLOB and TEXT columns.
#
# 					For example:
#
# 						CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10)));
#
# 					If a specified index prefix exceeds the maximum column data type size, CREATE_TABLE
# 					handles the index as follows:
#
# 						) For a nonunique index, either an error occurs (if strict SQL mode is enabled),
# 							or the index length is reduced to lie within the maximum column data type size
# 							and a warning is produed (if strict SQL mode is not enabled)
#
# 						) For a unique index, an error occurs regardless of SQL mode because reducing the index
# 							length might enable insertion of nonunique entries that do not meet the specified
# 							uniqueness requirement.
#
# 			) JSON columns cannot be indexed.
#
# 				You can work around this restriction by creating an index on a generated column
# 				that extracts a scalar value from the JSON column.
#
# 				See INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX, for a detailed example.
#
# 		) NOT NULL | NULL
#
# 			If neither NULL nor NOT NULL is specified, the column is treated as though NULL had been specified.
#
# 			In MySQL 8.0, only the InnoDB, MyISAM, and MEMORY storage engines support indexes on columns
# 			that can have NULL values.
#
# 			In other cases, you must declare indexed columns as NOT NULL or an error results
#
# 		) DEFAULT
#
# 			Specifies a default value for a column.
#
# 			For more information about default value handling, including the case that
# 			a column definition includes no explicit DEFAULT value, see SECTION 11.7, "DATA TYPE DEFAULT VALUES"
#
# 			If the NO_ZERO_DATE or NO_ZERO_IN_DATE SQL mode is enabled and a date-valued default is not correct
# 			according to that mode, CREATE_TABLE produces a warning if strict SQL mode is not enabled and an
# 			error if strict mode is enabled.
#
# 			For example, with NO_ZERO_IN_DATE enabled, c1 DATE DEFAULT '2010-00-00' produces a warning.
#
# 		) AUTO_INCREMENT
#
# 			An integer or floating-point column can have the additional attribute AUTO_INCREMENT.
#
# 			When you insert a value of NULL (recommended) or 0 into an indexed AUTO_INCREMENT column,
# 			the column is set to the next sequence value.
#
# 			Typically this is value+1, where value is the largest value for the column currently
# 			in the table.
#
# 			AUTO_INCREMENT sequences begin with 1.
#
# 			To retrieve an AUTO_INCREMENT value after inserting a row, use the LAST_INSERT_ID()
# 			SQL function or the mysql_insert_id() C API function
#
# 			See SECTION 12.15, "INFORMATION FUNCTIONS" and SECTION 28.7.7.38, "mysql_insert_id()"
#
# 			If the NO_AUTO_VALUES_ON_ZERO SQL mode is enabled, you can store 0 in AUTO_INCREMENT
# 			columns as 0 without generating a new sequence value.
#
# 			See SECTION 5.1.11, "SERVER SQL MODES"
#
# 			There can be only one AUTO_INCREMENT column per table, it must be indexed, and it cannot
# 			have a DEFAULT value.
#
# 			An AUTO_INCREMENT column works properly only if it contains only positive values.
#
# 			Inserting a negative number is regarded as inserting a very large positive number.
#
# 			This is done to avoid precision problems when numbers "wrap" over from positive to
# 			negative and also to ensure that you do not accidentally get an AUTO_INCREMENT
# 			column that contains 0.
#
# 			For MyISAM tables, you can specify an AUTO_INCREMENT secondary column in a multiple-column
# 			key.
#
# 			See SECTION 3.6.9, "USING AUTO_INCREMENT"
#
# 			To make MySQL compatible with some ODBC applications, you can find the AUTO_INCREMENT
# 			value for the last inserted row with the following query:
#
# 				SELECT * FROM tbl_name WHERE auto_col IS NULL
#
# 			This method requires that sql_auto_is_null variable is not set to 0.
#
# 			See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 			For information about InnoDB and AUTO_INCREMENT, see SECTION 15.6.1.4,
# 			"AUTO_INCREMENT HANDLING IN INNODB"
#
# 			For information about AUTO_INCREMENT and MySQL Replication, see 
# 			SECTION 17.4.1.1, "REPLICATION AND AUTO_INCREMENT"
#
# 		) COMMENT
#
# 			A comment for a column can be specified with the COMMENT option, up to
# 			1024 characters long.
#
# 			The comment is displayed by the SHOW_CREATE_TABLE and SHOW_FULL_COLUMNS
# 			statements.
#
# 		) COLUMN_FORMAT
#
# 			In NDB Cluster, it is also possible to specify a data storage format for
# 			individual columns of NDB tables using COLUMN_FORMAT.
#
# 			Permissible column formats are FIXED, DYNAMIC and DEFAULT.
#
# 			FIXED is used to specify fixed-width storage, DYNAMIC permits the column
# 			to be variable-width, and DEFAULT causes the column to use fixed-width
# 			or variable-width storage as determined by the column's data type
# 			(possibly overridden by a ROW_FORMAT specifier)
#
# 			For NDB tables, the default value for COLUMN_FORMAT is FIXED.
#
# 			COLUMN_FORMAT currently has no effect on columns of tables using storage engines
# 			other than NDB.
#
# 			MySQL 8.0 silently ignores COLUMN_FORMAT
#
# 		) STORAGE
#
# 			For NDB tables, it is possible to specify whether the column is stored on disk or
# 			in memory by using a STORAGE clause.
#
# 			STORAGE DISK causes the column to be stored on disk, and STORAGE MEMORY causes
# 			in-memory storage to be used.
#
# 			The CREATE_TABLE statement used must still include a TABLESPACE clause:
#
# 				CREATE TABLE t1 (
# 					c1 INT STORAGE DISK,
# 					c2 INT STORAGE MEMORY
# 				) ENGINE NDB;
# 				ERROR 1005 (HY000): Can't create table 'c.t1' (errno: 140)
#
# 				CREATE TABLE t1 (
# 					c1 INT STORAGE DISK,
# 					c2 INT STORAGE MEMORY
# 				) TABLESPACE ts_1 ENGINE NDB;
# 				Query OK, 0 rows affected (1.06 sec)
#
# 			For NDB tables, STORAGE DEFAULT is equivalent to STORAGE MEMORY.
#
# 			The STORAGE clause has no effect on tables using storage engines other than
# 			NDB.
#
# 			The STORAGE keyword is supported only in the build of mysqld that is supplied
# 			with NDB Cluster; it is not recognized in any other version of MySQL, where
# 			any attempt to use the STORAGE keyword cause a syntax error.
#
# 		) GENERATED ALWAYS
#
# 			Used to specify a generated column expression.
#
# 			For information about generated columns, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
#
# 			Stored generated columns can be indexed.
#
# 			InnoDB supports secondary indexes on virtual generated columns.
# 			See SECTION 13.1.20.9, "SECONDARY INDEXES AND GENERATED COLUMNS"
#
# INDEXES AND FOREIGN KEYS
#
# Several keywords apply to creation of indexes and foreign keys.
#
# For general background in addition to the following descriptions, see
# SECTION 13.1.15, "CREATE INDEX SYNTAX" and SECTION 13.1.20.6, "USING FOREIGN KEY CONSTRAINTS"
#
# 		) CONSTRAINT <SYMBOL>
#
# 			If the CONSTRAINT symbol clause is given, the symbol value, if used, must be unique
# 			in the database.
#
# 			A duplicate symbol results in an error.
#
# 			If the clause is not given, or a symbol is not included following the CONSTRAINT keyword,
# 			a name for the constraint is created automatically.
#
# 		) PRIMARY KEY
#
# 			A unique index where all key columns must be defined as NOT NULL.
#
# 			If they are not explicitly declared as NOT NULL, MySQL declares them so
# 			implicitly (and silently)
#
# 			A table can have only one PRIMARY KEY. 
#
# 			The name of a PRIMARY KEY is always PRIMARY, which thus cannot be used
# 			as the name for any other kind of index.
#
# 			If you do not have a PRIMARY KEY and an application asks for the PRIMARY KEY
# 			in your tables, MySQL returns the first UNIQUE index that has no NULL
# 			columns as the PRIMARY KEY.
#
# 			In InnoDB tables, keep the PRIMARY KEY short to minimize storage overhead
# 			for secondary indexes.
#
# 			Each secondary index entry contains a copy of the primary key columns
# 			for the corresponding row. (See SECTION 15.6.2.1, "CLUSTERED AND SECONDARY INDEXES")
#
# 			In the created table, a PRIMARY KEY is placed first, followed by all UNIQUE indexes,
# 			and then the nonunique indexes.
#
# 			This helps the MySQL optimizer to prioritize which index to use and also
# 			more quickly to detect duplicated UNIQUE keys.
#
# 			A PRIMARY KEY can be a multiple-column index.
#
# 			However, you cannot create a multiple-column index using the PRIMARY KEY
# 			attribute in a column specification.
#
# 			Doing so only marks that single column as primary.
#
# 			You must use a separate PRIMARY KEY(key_part, ---) clause
#
# 			If a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists
# 			of a single column that has an integer type, you can use _rowid
# 			to refer to the indexed column in SELECT statements, as described
# 			in Unique Indexes.
#
# 			In MySQL, the name of a PRIMARY KEY is PRIMARY.
#
# 			Foro ther indexes, if you do not assign a name, the index is assigned
# 			the same name as the first indexed column, with an optional suffix
# 			(_2,_3,---) to make it unique.
#
# 			You can see index names for a table using SHOW INDEX FROM tbl_name.
#
# 			See SECTION 13.7.6.22, "SHOW INDEX SYNTAX"
#
# 		) KEY | INDEX
#
# 			KEY is normally a synonym for INDEX.
#
# 			The key attribute PRIMARY KEY can also be specified as just KEY when given
# 			in a column definition.
#
# 			This was implemented for compatibility with other database systems.
#
# 		) UNIQUE
#
# 			A UNIQUE index creates a constraint such that all values in the index must be distinct.
#
# 			An error occurs if you try to add a new row with a key value that matches an
# 			existing row.
#
# 			For all engines, a UNIQUE index permits multiple NULL values for columns that
# 			can contain NULL.
#
# 			If you specify a prefix value for a column in a UNIQUE index, the column values
# 			must be unique within the prefix length.
#
# 			If a table has a PRIMARY KEY or UNIQUE NOT NULL index that consists of a single
# 			column that has an integer type, you can use _rowid to refer to the indexed
# 			column in SELECT statements, as described in UNIQUE INDEXES.
#
# 		) FULLTEXT
#
# 			A FULLTEXT index is a special type of index used for full-text searches.
#
# 			Only the InnoDB and MyISAM storage engines support FULLTEXT indexes.
#
# 			They can be created only from CHAR, VARCHAR, and TEXT columns.
#
# 			Indexing always happens over the entire column; column prefix indexing
# 			is not supported and any prefix length is ignored if specified.
#
# 			See SECTION 12.9, "FULL-TEXT SEARCH FUNCTIONS", for details of operation.
#
# 			A WITH PARSER clause can be specified as an index_option value to associate
# 			a parser plugin with the index if full-text indexing and searching operations
# 			need special handling.
#
# 			This clause is valid only for FULLTEXT indexes.
#
# 			InnoDB and MyISAM support full-text parser plugins.
#
# 			See FULL-TEXT PARSER PLUGINS and SECTION 29.2.4.4, "WRITING FULL-TEXT PARSER PLUGINS"
# 			for more information.
#
# 		) SPATIAL
#
# 			You can create SPATIAL indexes on spatial data types.
#
# 			Spatial types are supported only for InnoDB and MyISAM tables, and indexed
# 			columns must be declared as NOT NULL.
#
# 			See SECTION 11.5, "SPATIAL DATA TYPES"
#
# 		) FOREIGN KEY
#
# 			MySQL supports foreign keys, which let you cross-reference related data
# 			across tables, and foreign key constraints, which help keep this spread-out
# 			data consistent.
#
# 			For definition and option information, see REFERENCE_DEFINITION and REFERENCE_OPTION
#
# 			Partitioned tables employing the InnoDB storage engine do not support foreign keys.
#
# 			See SECTION 23.6, "RESTRICTIONS AND LIMITATIONS ON PARTITIONING", for more information.
#
# 		) CHECK
#
# 			The CHECK clause is parsed but ignored by all storage engines.
#
# 			See SECTION 1.8.2.3, "FOREIGN KEY DIFFERENCES"
#
# 		) key_part
#
# 			) A key_part specification can end with ASC or DESC to specify whether index values
# 				are stored in ascending or descending order.
#
# 				The default is ascending if no order specifier is given.
#
# 			) Prefixes, defined by the length attribute, can be up to 767 bytes long for InnoDB tables
# 				that use the REDUNDANT or COMPACT row format.
#
# 				The prefix length limit is 3072 bytes for InnoDB tables that use the DYNAMIC
# 				or COMPRESSED row format.
#
# 				For MyISAM tables, the prefix length limit is 1000 bytes.
#
# 				Prefix limits are measured in bytes.
#
# 				However, prefix lengths for index specifications in CREATE_TABLE,
# 				ALTER_TABLE and CREATE_INDEX statements are interpreted as number of
# 				characters for nonbinary string types (CHAR, VARCHAR, TEXT) and number of
# 				bytes for binary string types (BINARY, VARBINARY, BLOB)
#
# 				Take this into account when specifying a prefix length for a nonbinary
# 				string column that uses a multibyte character set.
#
# 		) index_type
#
# 			Some storage engine permit you to specify an index type when creating an index.
#
# 			The syntax for the index_type specifier is USING type_name
#
# 			Example:
#
# 				CREATE TABLE lookup
# 					(id INT, INDEX USING BTREE (id))
# 					ENGINE = MEMORY;
#
# 			The preferred position for USING is after the index column list.
#
# 			It can be given before the column list, but support for use of the option
# 			in that position is deprecated and will be removed in a future release.
#
# 		) index_option
#
# 			index_option values specify additional options for an index
#
# 				) KEY_BLOCK_SIZE
#
# 					For MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use
# 					for index key blocks.
#
# 					The value is treated as a hint; a different size could be used if necessary.
#
# 					A KEY_BLOCK_SIZE value specified for an individual index definition overrides
# 					the table-level KEY_BLOCK_SIZE value.
#
# 					For information about the table-level KEY_BLOCK_SIZE attribute, see TABLE OPTIONS
#
# 				) WITH PARSER
#
# 					The WITH PARSER option can only be used with FULLTEXT indexes.
#
# 					It associates a parser plugin with the index if full-text indexing
# 					and searching operations need special handling.
#
# 					InnoDB and MyISAM support full-text parser plugins.
#
# 					If you have a MyISAM table with an associated full-text parser
# 					plugin, you can convert the table to InnoDB using ALTER TABLE.
#
# 				) COMMENT
#
# 					In MySQL 8.0, index definitions can include an optional comment
# 					of up to 1024 characters.
#
# 					You can set the InnoDB MERGE_THRESHOLD value for an individual index using
# 					the index_option COMMENT clause.
#
# 					See SECTION 15.8.11, "CONFIGURING THE MERGE THRESHOLD FOR INDEX PAGES"
#
# 			For more information about permissible index_option values, see SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# 			For more information about indexes, see SECTION 8.3.1, "HOW MYSQL USES INDEXES"
#
# 		) reference_definition
#
# 			For reference_definition syntax details and examples, see SECTION 13.1.20.6,
# 			"USING FOREIGN KEY CONSTRAINTS"
#
# 			For information specific to foreign keys in InnoDB, see SECTION 15.6.1.5, "InnoDB AND FOREIGN KEY CONSTRAINTS"
#
# 			InnoDB and NDB tables support checking of foreign key constraints.
#
# 			The  columns of the referenced table must always be explicitly named.
#
# 			Both ON DELETE and ON UPDATE actions on foreign keys are supported.
#
# 			For more detailed information and examples, see SECTION 13.1.20.6,
# 			"USING FOREIGN KEY CONSTRAINTS"
#
# 			For information specific to foreign keys in InnoDB, see SECTION 15.6.1.5,
# 			"InnoDB AND FOREIGN KEY CONSTRAINTS"
#
# 			For other storage engines, MySQL Server parses and ignores the FOREIGN KEY
# 			and REFERENCES syntax in CREATE_TABLE statements.
#
# 			See SECTION 1.8.2.3, "FOREIGN KEY DIFFERENCES"
#
# 				IMPORTANT:
#
# 					For users familiar with the ANSI/ISO SQL Standard, please note that no storage engine,
# 					includin InnoDB, recognizes or enforces the MATCH clause used in referential integrity
# 					constraint definitions.
#
# 					Use of an explicit MATCH clause will not have the specified effect, and also causes
# 					ON DELETE and ON UPDATE clauses to be ignored. For these reasons, specifying
# 					MATCH should be avoided.
#
# 					The MATCH clause in SQL standard controls how NULL values in a composite (multiple-column)
# 					foreign key are handled when comparing to a primary key.
#
# 					InnoDB essentially implements the semantics defined by MATCH SIMPLE, which permit a foreign
# 					key to be all or partially NULL.
#
# 					In that case, the (child table) row containing such a foreign key is permitted to be inserted,
# 					and does not match any row in the referenced (parent) table.
#
# 					It is possible to implement other semantics using triggers.
#
# 					Additionally, MySQL requires that the referenced columns be indexed for performance.
#
# 					However, InnoDB does not enforce any requirement that the referenced columns be declared
# 					UNIQUE or NOT NULL.
#
# 					The handling of foreign key references to nonunique keys or keys that contain NULL values
# 					is not well defined for operations such as UPDATE or DELETE CASCADE.
#
# 					You are advised to use foreign keys that reference only keys that are both UNIQUE 
# 					(or PRIMARY) and NOT NULL.
#
# 					MySQL parses but ignores "inline REFERENCES specifications" (as defined in the SQL standard)
# 					where the references are defined as part of the column specification.
#
# 					MySQL accepts REFERENCES clauses only when specified as part of a separate FOREIGN KEY 
# 					specification.
#
# 		) reference_option
#
# 			For information about the RESTRICT, CASCADE, SET NULL, NO ACTION and SET DEFAULT options, see
# 			SECTION 13.1.20.6, "USING FOREIGN KEY CONSTRAINTS"
#
# TABLE OPPTIONS
#
# Table options are used to optimize the behavior of the table.
#
# In most cases, you do not have to specify any of them. These options apply to all storage engines
# unless otherwise indicated.
#
# Options that do not apply to a given storage engine may be accepted and remembered as part of the
# table definition.
#
# Such options then apply if you later use ALTER_TABLE to convert the table to use a different storage engine.
#
# 		) ENGINE
#
# 			Specifies the storage engine for the table, using one of the names shown in the following table.
#
# 			The engine name can be unquoted or quoted. The quoted name 'DEFAULT' is recognized but ignored.
#
# 			STORAGE ENGINE 			DESC
#
# 			InnoDB 					Transaction-safe tables with row locking and foreign keys.
#
# 										The default storage engine for new tables. 
#
# 										See CHAPTER 15, The InnoDB Storage Engine, and in particular Section 15.1,
# 										"Introduction to InnoDB" if you have MySQL experience but are new to InnoDB.
#  		
# 			MyISAM 					The binary portable storage engine that is primarily used for read-only or read-mostly
# 										workloads.
#
# 										See SECTION 16.2, "THE MYISAM STORAGE ENGINE"
#
# 			MEMORY 					The data for this storage engine is stored only in memory. See SECTION 16.3, "THE MEMORY STORAGE ENGINE"
#
# 			CSV 						Tables that store rows in comma-separated values format. See SECTION 16.4, "THE CSV STORAGE ENGINE"
#
# 			ARCHIVE 					The archiving storage engine. See SECTION 16.5, "THE ARCHIVE STORAGE ENGINE"
#
# 			EXAMPLE 					An example engine. See SECTION 16.9, "THE EXAMPLE STORAGE ENGINE"
#
# 			FEDERATED 				Storage engine that accesses remote tables. See SECTION 16.8, "THE FEDERATED STORAGE ENGINE"
#
# 			HEAP 						This is a synonym for MEMORY
#
# 			MERGE 					A collection of MyISAM tables used as one table.
#
# 										Also known as MRG_MyISAM. See SECTION 16.7, "THE MERGE STORAGE ENGINE"
#
# 			NDB 						Clustered, fault-tolerant, memory-based tables, supporting transactions and foreign
# 										keys.
#
# 										Also known as NDBCLUSTER.
#
# 										See CHAPTER 22, MySQL NDB CLUSTER 8.0
#
# 			By default, if a storage engine is specified that is N/A, the statement fails with an error.
#
# 			You can override this behavior by removing NO_ENGINE_SUBSTITUTION from the server SQL mode
# 			(see SECTION 5.1.11, "SERVER SQL MODES") so that MySQL allows substitution of the specified
# 			engine with the default storage engine instead.
#
# 			Normally, in such cases, this is InnoDB, which is the default value for the default_storage_engine
# 			system variable.
#
# 			When NO_ENGINE_SUBSTIUTTION is disabled, a warning occurs if the storage engine specification is not honored.
#
# 		) AUTO_INCREMENT
#
# 			The initial AUTO_INCREMENT value for the table.
#
# 			In MySQL 8.0, this works for MyISAM, MEMORY, InnoDB and ARCHIVE tables.
#
# 			To set the first auto-increment value for engines that do not support the
# 			AUTO_INCREMENT table option, insert a "dummy" row with a value one less than the
# 			desired value after creating the table, and then delete the dummy row.
#
# 			For engines that support the AUTO_INCREMENT table option in CREATE_TABLE statements,
# 			you can also use ALTER TABLE tbl_name AUTO_INCREMENT = N to reset the AUTO_INCREMENT value.
#
# 			The value cannot be set lower than the maximum value currently in the column.
#
# 		) AVG_ROW_LENGTH
#
# 			An approximation of the average row length for your table. You need to set this only for large
# 			tables with variable-size rows.
#
# 			When you create a MyISAM table, MySQL uses the product of the MAX_ROWS and AVG_ROW_LENGTH options
# 			to decide how big the resulting table is.
#
# 			If you do not specify either option, the max size for MyISAM data and index file is 256TB by default.
#
# 			(If your OS does not support files that large, table sizes are constrained by the file size limit)
#
# 			If you want to keep down the pointer size to make the index smaller and faster and you do not really
# 			need big files, you can decrease the default pointer size by setting the myisam_data_pointer_size
# 			system variable.
#
# 			(See SECTION 5.1.8, "SERVER SYSTEM VARIABLES")
#
# 			If you want all your tables to be able to grow above the default limit and are willing to have your
# 			tables slightly slower and larger than necessary, you can increase the default point size by setting
# 			this variable.
#
# 			Setting this value to 7 permits table sizes up to 65,536TB
#
# 		) [DEFAULT] CHARACTER SET
#
# 			Specifies a default character set for the table.
#
# 			CHARSET is a synonym for CHARACTER SET.
#
# 			If the character set name is DEFAULT, the database character set is used.
#
# 		) CHECKSUM
#
# 			Set this to 1 if you want MySQL to maintain live checksum for all rows (that is,
# 			a checksum that MySQL updates automatically as the table changes)
#
# 			This makes the table a little slower to update, but also makes it easier
# 			to find corrupted tables.
#
# 			The CHECKSUM_TABLE statement reports the checksum. (MyISAM only)
#
# 		) [DEFAULT] COLLATE
#
# 			Specifies a default collation for the table.
#
# 		) COMMENT
#
# 			A comment for the table, up to 2048 characters long.
#
# 			You can set the InnoDB MERGE_THRESHOLD value for a table using the 
# 			table_option COMMENT clause.
#
# 			See SECTION 15.8.11, "CONFIGURING THE MERGE THRESHOLD FOR INDEX PAGES"
#
# 			SETTING NDB_TABLE OPTIONS.
#
# 			The table comment in a CREATE TABLE that creates an NDB table or an
# 			ALTER_TABLE statement which alters one can also be used to specify one
# 			to four of the NDB_TABLE options:
#
# 				NOLOGGING
#
# 				READ_BACKUP
#
# 				PARTITION_BALANCE
#
# 				FULLY_REPLICATED
#
# 			as a set of name-value pairs, separated by commas if need be, immediately
# 			following the string NDB_TABLE= that begins the quoted comment text.
#
# 			An example statement using this syntax is shown here (emphasized text):
#
# 				CREATE TABLE t1 (
# 					c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 					c2 VARCHAR(100),
# 					c3 VARCHAR(100) )
# 				ENGINE=NDB
# 				COMMENT="NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE";
#
# 			Spaces are not permitted within the quoted string.
#
# 			The string is case-insensitive.
#
# 			The comment is displayed as part of the output of SHOW_CREATE_TABLE
#
# 			The text of the comment is also available as the TABLE_COMMENT column of the
# 			MySQL Information Schema TABLES table.
#
# 			This comment syntax is also supported with ALTER_TABLE statements for NDB tables.
#
# 			Keep in mind that a table comment used with ALTER TABLE replaces any existing
# 			comment which the table might have had previously.
#
# 			Setting the MERGE_THRESHOLD option in table comments is not supported for NDB tables
# 			(it is ignored)
#
# 			For complete syntax information and examples, see SECTION 13.1.20.10, "SETTING NDB_TABLE OPTIONS"
#
# 		) COMPRESSION
#
# 			The compression algorithm used for page level compression for InnoDB tables.
#
# 			Supported values include Zlib, LZ4, and None.
#
# 			The COMPRESSION attribute was introduced with the transparent page compression
# 			feature.
#
# 			Page compression is only supported with InnoDB tables that reside in file-per-table
# 			tablespaces, and is only available on Linux and Windows platforms that support
# 			sparse files and hole punching.
#
# 			For more information, see SECTION 15.9.2, "InnoDB PAGE COMPRESSION"
#
# 		) CONNECTION
#
# 			The connection string for a FEDERATED table
#
# 			NOTE:
#
# 				Older versions of MySQL used a COMMENT option for the connection string
#
# 		) DATA DIRECTORY, INDEX DIRECTORY
#
# 			For InnoDB, the DATA_DIRECTORY='directory' clause permits creating a file-per-table
# 			tablespace outside of the data directory.
#
# 			The tablespace data file is created in the specified directory, inside a subdirectory
# 			with the same name as the schema.
#
# 			The innodb_file_per_table variable must be enabled to use the DATA DIRECTORY
# 			clause.
#
# 			The full directory path must be specified.
#
# 			For more information, see SECTION 15.6.3.6, "CREATING A TABLESPACE OUTSIDE OF THE DATA DIRECTORY"
#
# 			When creating MyISAM tables, you can use the DATA DIRECTORY='directory' clause, the INDEX DIRECTORY='directory'
# 			clause, or both.
#
# 			They specify where to put a MyISAM table's data file and index file, respectively.
#
# 			Unlike InnoDB tables, MySQL does not create subdirectories that correspond to the 
# 			database name when creating a MyISAM table with a DATA DIRECTORY or INDEX DIRECTORY option.
#
# 			Files are created in the directory that is specified.
#
# 			You must have the FILE privilege to use the DATA DIRECTORY or INDEX DIRECTORY table option.
#
# 			IMPORTANT:
#
# 				Table-level DATA DIRECTORY and INDEX DIRECTORY options are ignored for partitioned tables.
# 				(Bug #32091)
#
# 			These options work only when you are not using the --skip-symbolic-links option.
#
# 			Your OS must also have a working, thread-safe realpath() call
#
# 			See SECTION 8.12.2.2, "USING SYMBOLIC LINKS FOR MYISAM TABLES ON UNIX", for more
# 			complete information.
#
# 			If a MyISAM table is created with no DATA DIRECTORY option, the .MYD file is created
# 			in the database directory.
#
# 			By default, if MyISAM finds an existing .MYD file in this case, it overwrites it.
#
# 			The same applies to .MYI files for tables created with no INDEX DIRECTORY option.
#
# 			To suppress this behavior, start the server with the --keep_files_on_create option,
# 			in which case MyISAM will not overwrite existing files and returns an error instead.
#
# 			If a MyISAM table is created with a DATA DIRECTORY or INDEX DIRECTORY option and
# 			an existing .MYD or .MYI file is found, MyISAM always returns an error.
#
# 			It will not overwrite a file in the specified directory.
#
# 				IMPORATNT:
#
# 					You cannot use path names that contain the MySQL data directory with
# 					DATA DIRECTORY or INDEX DIRECTORY.
#
# 					THis includes partitioned tables and individual table partitions.
# 					(See Bug #32167)
#
# 		) DELAY_KEY_WRITE
#
# 			Set this to 1 if you want to delay key updates for the table until the table is closed.
#
# 			See the description of the delay_key_write system variable in SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
# 			(MyISAM only)
#
# 		) ENCRYPTION
#
# 			Set the ENCRYPTION option to 'Y' to enable page-level data encryption for an InnoDB
# 			table created in a file-per-table tablespace.
#
# 			Option values are not case-sensitive.
#
# 			The ENCRYPTION option was introduced with the InnoDB tablespace encryption feature;
# 			see SECTION 15.6.3.9, "TABLESPACE ENCRYPTION"
#
# 			A keyring plugin must be installed and configured to use the ENCRYPTION option.
#
# 		) INSERT_METHOD
#
# 			If you want to insert data into a MERGE table; you must specify with INSERT_METHOD
# 			the table into which the row should be inserted.
#
# 			INSERT_METHOD is an option useful for MERGE tables only.
#
# 			Use a value of FIRST or LAST to have inserts go to the first or last table,
# 			or a value of NO to prevent inserts.
#
# 			See SECTION 16.7, "THE MERGE STORAGE ENGINE"
#
# 		) KEY_BLOCK_SIZE
#
# 			For MyISAM tables, KEY_BLOCK_SIZE optionally specifies the size in bytes to use
# 			for index key blocks.
#
# 			The value is treated as a hint; a different size could be used if necessary.
#
# 			A KEY_BLOCK_SIZE value specified for an individual index definition overrides
# 			the table-level KEY_BLOCK_SIZE value.
#
# 			For InnoDB tables, KEY_BLOCK_SIZE specifies the page size in kilobytes to use
# 			for compressed InnoDB tables.
#
# 			The KEY_BLOCK_SIZE value is treated as a hint; a different size could be used
# 			by InnoDB if necessary.
#
# 			KEY_BLOCK_SIZE can only be less than or equal to the innodb_page_size value.
#
# 			A value of 0 represents the default compressed page size, which is half of the
# 			innodb_page_size value.
#
# 			Depending on innodb_page_size, possible KEY_BLOCK_SIZE values include
# 			0, 1, 2, 4, 8 and 16.
#
# 			See SECTION 15.9.1, "InnoDB TABLE COMPRESSION" for more information
#
# 			Oracle recommends enabling innodb_strict_mode when specifying KEY_BLOCK_SIZE
# 			for InnoDB tables.
#
# 			When innodb_strict_mode is enabled, specifying an invalid KEY_BLOCK_SIZE value
# 			returns an error.
#
# 			If innodb_strict_mode is disabled, an invalid KEY_BLOCK_SIZE value results
# 			in a warning, and the KEY_BLOCK_SIZE option is ignored.
#
# 			The Create_options column in response to SHOW_TABLE_STATUS reports the
# 			actual KEY_BLOCK_SIZE used by the table, as does SHOW_CREATE_TABLE
#
# 			InnoDB only supports KEY_BLOCK_SIZE at the table level
#
# 			KEY_BLOCK_SIZE is not supported with 32KB and 64KB innodb_page_size values.
#
# 			InnoDB table compression does not support these page sizes.
#
# 			InnoDB does not support the KEY_BLOCK_SIZE option when creating temporary tables.
#
# 		) MAX_ROWS
#
# 			The maximum number of rows you plan to store in the table.
#
# 			This is not a hard limit, but rather a hint to the storage engine that
# 			the table must be able to store at least this many rows.
#
# 				IMPORTANT:
#
# 					The use of MAX_ROWS with NDB tables to control the number of table
# 					partitions is deprecated.
#
# 					It remains supported in later versions for backward compatibility,
# 					but is subject to removal in a future release.
#
# 					Use PARTITION_BALANCE instead; see SETTING NDB_TABLE OPTIONS
#
# 			The NDB storage engine treats this value as a maximum.
#
# 			If you plan to create very large NDB Cluster tables (containing millions of rows),
# 			you should use this option to insure that NDB allocates sufficient number of index slots
# 			in the hash table used for storing hashes of the table's primary keys by setting
# 			MAX_ROWS = 2 * rows, where rows is the number of rows that you expect to insert
# 			into the table.
#
# 			The maximum MAX_ROWS value is 4294967295; larger values are truncated to this limit.
#
# 		) MIN_ROWS
#
# 			The minimum number of rows you plan to store in the table.
#
# 			The MEMORY storage engine uses this option as a hint about memory use.
#
# 		) PACK_KEYS
#
# 			Takes effect only with MyISAM tables.
#
# 			Set this option to 1 if you want to have smaller indexes.
#
# 			This usually makes updates slower and reads faster. 
# 			Setting this option to 0 disables all packing of keys.
#
# 			Setting it to DEFAULT tells the storage engine to pack only long
# 			CHAR, VARCHAR, BINARY or VARBINARY columns.
#
# 			If you do not use PACK_KEYS, the default is to pack strings, but not 
# 			numbers.
#
# 			If you use PACK_KEYS=1, numbers are packed as well.
#
# 			When packing binary number keys, MySQL uses prefix compression:
#
# 				) Every key needs one extra byte to indicate how many bytes of the previous key are the same 
# 					for the next key.
#
# 				) The pointer to the row is stored in high-byte-first order directly after the key, to improve compression.
#
# 			This means that if you have many equal keys on two consecutive rows, all following "same" keys
# 			usually only take two bytes (including the pointer ot the row)
#
# 			Compare this to the ordinary case where the following keys takes storage_size_for_key +
# 			pointer_size (where the pointer size is usually 4)
#
# 			Conversely, you get a significant benefit from prefix compression only if you have
# 			many numbers that are the same.
#
# 			If all keys are totally different, you use one byte more per key, if the key is not a key
# 			that can have NULL values.
#
# 			(In this case, the packed key length is stored in the same byte that is used to mark if a key is NULL)
#
# 		) PASSWORD
#
# 			This option is unused
#
# 		) ROW_FORMAT
#
# 			Defines the physical format in which the rows are stored.
#
# 			When executing a CREATE_TABLE statement with strict mode disabled, if you specify
# 			a row format that is not supported by the storage engine that is used
# 			for the table, the table is created using that storage engine's default row format.
#
# 			The actual row format of the table is reported in the Row_format and Create_options
# 			columns in response to SHOW_TABLE_STATUS.
#
# 			SHOW_CREATE_TABLE also reports the actual row format of the table.
#
# 			Row format choices differ depending on the storage engine used for the table.
#
# 			For InnoDB tables:
#
# 				) The default row format is defined by innodb_default_row_format, which has
# 					a default setting of DYNAMIC.
#
# 					The default row format is used when the ROW_FORMAT option is not defined
# 					or when ROW_FORMAT=DEFAULT is used.
#
# 					If the ROW_FORMAT option is not defined, or if ROW_FORMAT=DEFAULT is used,
# 					operations that rebuild a table also silently change the row format
# 					of the table to the default defined by innodb_default_row_format.
#
# 					For more information, see DEFINING THE ROW FORMAT OF A TABLE
#
# 				) For more efficient InnoDB storage of data types, especially BLOB types,
# 					use the DYNAMIC.
#
# 					See DYNAMIC ROW FORMAT for requirements associated with the DYNAMIC
# 					row format.
#
# 				) To enable compression for InnoDB tables, specify ROW_FORMAT=COMPRESSED
#
# 					The ROW_FORMAT=COMPRESSED option is not supported when creating temporary
# 					tables.
#
# 					See SECTION 15.9, "InnoDB TABLE AND PAGE COMPRESSION" for requirements
# 					associated with the COMPRESSED row format.
#
# 				) The row format used in older versions of MySQL can still be requested by specifying the REDUNDANT row format.
#
# 				) When you specify a non-default ROW_FORMAT clause, consider also enabling the innodb_strict_mode configuration option
#
# 				) ROW_FORMAT=FIXED is not supported.
#
# 					If ROW_FORMAT=FIXED is specified while innodb_strict_mode is disabled, InnoDB issues a warning
# 					and assumes ROW_FORMAT=DYNAMIC.
#
# 					If ROW_FORMAT=FIXED is specified while innodb_strict_mode is enabled,
# 					which is the default, InnoDB returns an error.
#
# 				) For additional information about InnoDB row formats, see SECTION 15.10, "InnoDB ROW FORMATS"
#
# 			For MyISAM tables, the option value can be FIXED or DYNAMIC for static or variable-length
# 			row format.
#
# 			myisampack sets the type to COMPRESSED. See SECTION 16.2.3, "MyISAM TABLE STORAGE FORMATS"
#
# 			For NDB tables, the default ROW_FORMAT is DYNAMIC
#
# 		) STATS_AUTO_RECALC
#
# 			Specifies whether to automatically recalculate persistent statistics for an InnoDB table.
#
# 			The value DEFAULT causes the persistent statistics setting for the table to be
# 			determined by the innodb_stats_auto_recalc configuration option.
#
# 			The value 1 causes statistics to be recalculated when 10% of the data in teh table
# 			has changed.
#
# 			The value 0 prevents automatic recalculation for this table; with this setting,
# 			issue an ANALYZE_TABLE statement to recalculate the statistics after making
# 			substansial changes to the table.
#
# 			For more information about the persistent statistics feature, see SECTION 15.8.10.1,
# 			"CONFIGURING PERSISTENT OPTIMIZER STATISTICS PARAMETERS"
#
# 		) STATS_PERSISTENT
#
# 			Specifies whether to enable persistent statistics for an InnoDB table.
#
# 			The value DEFAULT causes the persistent statistics setting for the table to
# 			be determined by the innodb_stats_persistent configuration option.
#
# 			The value 1 enables persistent statistics for the table, while the value 
# 			0 turns off this feature.
#
# 			After enabling persistent statistics through a CREATE TABLE or ALTER TABLE
# 			statement, issue an ANALYZE_TABLE statement to calculate the statistics,
# 			after loading representative data into the table.
#
# 			For more information about the persistent statistics feature,
# 			see SECTION 15.8.10.1, "CONFIGURING PERSISTENT OPTIMIZER STATISTICS PARAMETERS"
#
# 		) STATS_SAMPLE_PAGES
#
# 			The number of index pages to sample when estimating cardinality and other
# 			statistics for an indexed column, such as those calculated by ANALYZE_TABLE.
#
# 			For more information, see SECTION 15.8.10.1, "CONFIGURING PERSISTENT OPTIMIZER STATISTICS PARAMETERS"
#
# 		) TABLESPACE
#
# 			The TABLESPACE clause can be used to create a table in an existing general tablespace,
# 			a file-per-table tablespace, or the system tablespace.
#
# 				CREATE TABLE tbl_name --- TABLESPACE [=] tablespace_name
#
# 			The general tablespace that you specify must exist prior to using the
# 			TABLESPACE clause.
#
# 			For information about general tablespaces, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# 			The tablespace_name is a case-sensitive identifier.
#
# 			It may be quoted or unquoted. The forward slash character ("/") is not permitted.
#
# 			Names beginning with "innodb_" are reserved for special use.
#
# 			To create a table in the system tablespace, specify innodb_system as the tablespace name.
#
# 				CREATE TABLE tbl_name --- TABLESPACE [=] innodb_system
#
# 			Using TABLESPACE [=] innodb_system you can place a table of any uncompressed row
# 			format in the system tablespace regardless of the innodb_file_per_table setting.
#
# 			For example, you can add a table with ROW_FORMAT=DYNAMIC to the system tablespace
# 			using TABLESPACE [=] innodb_system
#
# 			To create a table in a file-per-table tablespace, specify innodb_file_per_table as
# 			the tablespace name.
#
# 				CREATE TABLE tbl_name --- TABLESPACE [=] innodb_file_per_table
#
# 			NOTE:
#
# 				If innodb_file_per_table is enabled, you need not specify TABLESPACE=innodb_file_per_table
# 				to create an InnoDB file-per-table tablespace.
#
# 				InnoDB tables are created in file-per-table tablespaces by default when innodb_file_per_table 
# 				is enabled.
#
# 			The DATA DIRECTORY clause is permitted with CREATE TABLE --- TABLESPACE=innodb_file_per_table but
# 			is otherwise not supported for use in combination with the TABLESPACE clause.
#
# 			NOTE:
#
# 				Support for TABLESPACE = innodb_file_per_table and TABLESPACE = innodb_temporary clauses
# 				with CREATE_TEMPORARY_TABLE is deprecated as of MySQL 8.0.13, and will be removed
# 				in a future version of MySQL.
#
# 		) UNION
#
# 			Used to access a collection of identical MyISAM tables as one.
#
# 			This works only with MERGE tables. See SECTION 16.7, "THE MERGE STORAGE ENGINE"
#
# 			You must have SELECT, UPDATE and DELETE privileges for the tables you map to a MERGE table
#
# 			NOTE:
#
# 				Formerly, all tables used had to be in the same database as the MERGE table itself.
#
# 				This restriction no longer applies.
#
# CREATING PARTITIONED TABLES
#
# partition_options can be used to control partitioning of the table created with CREATE_TABLE
#
# Not all options shown in the syntax for partition_options at the beginning of this section are
# available for all partitioning types.
#
# Please see the listings for the following individual types for information specific to each
# type,  and see CHAPTER 23, PARTITIONING, for more complete information about the workings
# of and uses for partitioning in MySQL, as well as additional examples of table creation
# and other statements relating to MySQL partitioning.
#
# Partitions can be modified, merged, added to tables, and dropped from tables.
#
# For basic information about the MySQL statements to accomplish these tasks, see
# SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# For more detailed descriptions and examples, see SECTION 23.3, "PARTITION MANAGEMENT"
#
# 		) PARTITION BY
#
# 			If used, a partition_options clause begins with PARTITION BY.
#
# 			This clause contains the function that is used to determine the partition;
# 			the function returns an integer value ranging from 1 to num, where num is
# 			the number of partitions.
#
# 			(The maximum number of user-defined partitions which a table may contain is 
# 			1024; the number of subpartitions - discussed later in this section - 
# 			is included in this maximum)
#
# 			NOTE:
#
# 				The expression (expr) used in a PARTITION BY clause cannot refer to any
# 				columns not in the table being created;
#
# 				Such references are specifically not permitted and cause the statement to fail
# 				with an error (Bug #29444)
#
# 		) HASH(expr)
#
# 			Hashes one or more columns to create a key for placing and locating rows.
#
# 			expr is an expression using one or more table columns.
#
# 			This can be any valid MySQL expression (including MySQL functions) that
# 			yields a single integer value.
#
# 			For example, these are both valid CREATE_TABLE statements using PARTITION BY HASH:
#
# 				CREATE TABLE t1 (col1 INT, col2 CHAR(5))
# 					PARTITION BY HASH(col1);
#
# 				CREATE TABLE t1 (col1 INT, col2 CHAR(5), col3 DATETIME)
# 					PARTITION BY HASH ( YEAR(col3) );
#
# 			You may not use either VALUES LESS THAN or VALUES IN clauses with PARTITION BY HASH
#
# 			PARTITION BY HASH uses the remainder of expr divided by the number of partitions (that is, modulus)
#
# 			For examples and additional information, see SECTION 23.2.4, "HASH PARTITIONING"
#
# 			The LINEAR keyword entails a somewhat different algorithm.
#
# 			In this case, the number of the partition in which a row is stored is calculated
# 			as the result of one or more logical AND operations.
#
# 			For discussion and examples of linear hashing, see SECTION 23.2.4.1, "LINEAR HASH PARTITIONING"
#
# 		) KEY(column_list)
#
# 			This is similar to HASH, except that MySQL supplies the hashing function so as to
# 			guarantee an even data distribution.
#
# 			The column_list argument is simply a list of 1 or more table columns (max: 16)
#
# 			This example shows a simple table partitioned by key, with 4 partitions:
#
# 				CREATE TABLE tk (col1 INT, col2 CHAR(5), col3 DATE)
# 					PARTITION BY KEY(col3)
# 					PARTITIONS 4;
#
# 			For tables that are partitioned by key, you can employ linear partitioning by using
# 			the LINEAR keyword.
#
# 			THis has the same effect as with tables that are partitioned by HASH.
#
# 			That is, the partition number is found using the & operator rather than
# 			the modulus (see SECTION 23.2.4.1, "LINEAR HASH PARTITIONING", and SECTION 23.2.5, "KEY PARTITIONING", for details)
#
# 			This example uses linear partitioning by key to distribute data between 5 partitions:
#
# 				CREATE TABLE tk (col1 INT, col2 CHAR(5), col3 DATE)
# 					PARTITION BY LINEAR KEY(col3)
# 					PARTITIONS 5;
#
# 			The ALGORITHM={1|2} option is supported with [SUB]PARTITION BY [LINEAR] KEY ALGORITHM=1 causes
# 			the server to use the same key-hashing functions as MySQL 5.1
#
# 			ALGORITHM=2 means that hte server employs the key-hashing functions implemented and used
# 			by default for new KEY partitioned tables in MySQL 5.5 and later.
#
# 			(Partitioned tables created with the key-hashing functions employed in MySQL 5.5 and later
# 			cannot be used by a MySQL 5.1 server)
#
# 			Not specifying the option has the same effect as using ALGORITHM=2
#
# 			This option is intended for use chiefly when upgrading or downgrading [LINEAR]
# 			KEY partitioned tables between MySQL 5.1 and later MySQL versions, or for creating
# 			tables partitioned by KEY or LINEAR KEY on a MySQL 5.5 or later server which can be used
# 			on a MySQL 5.1 server
#
# 			For more information, see SECTION 13.1.9.1, "ALTER TABLE PARTITION OPERATIONS"
#
# 			mysqldump in MySQL 5.7 (and later) writes this option encased in versioned comments like this:
#
# 				CREATE TABLE t1 (a INT)
# 				/*!50100 PARTITION BY KEY */ /*!50611 ALGORITHM = 1 */ /*!50100 ()
# 						PARTITIONS 3 */
#
# 			This causes MySQL 5.6.10 and earlier servers to ignore the option, which would otherwise
# 			cause a syntax error in those versions.
#
# 			If you plan to load a dump made on a MySQL 5.7 server where you use tables that are
# 			partitioned or subpartitioned by KEY into a MySQL 5.6 server previous to 5.6.11,
# 			be sure to consult changes in MySQL 5.6
#
# 			(The information found there also applies if you are loading a dump containing KEY
# 			partitioned or subpartitioned tables made from a MySQL 5.7 - actually, 5.6.11
# 			or later - server into a MySQL 5.5.30 or earlier server)
#
# 			Also in MySQL 5.6.11, and later, ALGORITHM=1 is shown when necessary in the output
# 			of SHOW_CREATE_TABLE using versioned comments in teh same manner as mysqldump.
#
# 			ALGORITHM=2 is always omitted from SHOW CREATE TABLE output, even if this option
# 			was speified when creating the original table.
#
# 			You may not use either VALUES LESS THAN or VALUES IN clauses with PARTITION BY KEY
#
# 		) RANGE(expr)
#
# 			In this case, expr shows a range of values using a set of VALUES LESS THAN operators.
#
# 			When using range partitioning, you must define at least one partition using
# 			VALUE LESS THAN
#
# 			You cannot use VALUES IN with range partitioning
#
# 			NOTE:
#
# 				For tables partitioned by RANGE, VALUES LESS THAN must be used with either
# 				an integer literal value or an expression that evaluates to a single integer
# 				value.
#
# 				In MySQL 8.0, you can overcome this limitation in a table that is defined
# 				using PARTITION BY RANGE COLUMNS, as described later in this section.
#
# 			Suppose that you have a table that you wish to partition on a column containing
# 			year values, according to the following scheme.
#
	# 			PARTITION NUMBER: 			YEARS RANGE:
	#
	# 			0 									1990 and earlier
	#
	# 			1 									1991 to 1994
	#
	# 			2 									1995 to 1998
	#
	# 			3 									1999 to 2002
	#
	# 			4 									2003 to 2005
	#
	# 			5 									2006 and later
#
# 			A table implementing such a partitioning scheme can be realized by the 
# 			CREATE_TABLE statement shown here:
#
# 				CREATE TABLE t1 (
# 					year_col INT,
# 					some_data INT
# 				)
# 				PARTITION BY RANGE (year_col) (
# 					PARTITION p0 VALUES LESS THAN (1991),
# 					PARTITION p1 VALUES LESS THAN (1995),
# 					PARTITION p2 VALUES LESS THAN (1999),
# 					PARTITION p3 VALUES LESS THAN (2002),
# 					PARTITION p4 VALUES LESS THAN (2006),
# 					PARTITION p5 VALUES LESS THAN MAXVALUE
# 				);
#
# 			PARTITION --- VALUES LESS THAN --- statements work in a consecutive fashion.
#
# 			VALUES LESS THAN MAXVALUE works to specify "leftover" values that are greater
# 			than the maximum value otherwise specified.
#
# 			VALUES LESS THAN clauses work sequentially in a manner similar to that of hte case
# 			portions of a switch --- case block (as found in many languages)
#
# 			THat is, the clauses must be arranged in such a way that hte upper limit specified
# 			in each successive VALUES LESS THAN is greater than that of the previous one,
# 			with the one referencing MAXVALUE coming last of all in the list.
#
# 		) RANGE COLUMNS (column_list)
#
# 			This variant of RANGE facilitates partition pruning for queries using range conditions
# 			on multiple columns (that is, having conditions such as WHERE a = 1 AND b < 10 or
# 			WHERE a = 1 AND b = 10 AND c < 10)
#
# 			It enables you to specify value ranges in multiple columns by using a list of columns
# 			in the COLUMNS clause and a set of column values in each PARTITION --- VALUES LESS THAN (value_list)
# 			partition definition clause.
#
# 			(In the simplest case, this set consists of a single column)
#
# 			The maximum number of columns that can be referenced in the column_list and
# 			value_list is 16.
#
# 			The column_list used in the COLUMNS clause may contain only names of columns;
# 			each column in the list must be one of the following MySQL data types:
#
# 				The integer types
#
# 				The string types
#
# 				´Time or date column types
#
# 			Columns using BLOB, TEXT, SET, ENUM, BIT or spatial data types
# 			are not permitted;
#
# 			Columns that use floating-point number types are also not permitted.
#
# 			You also may not use functions or arithmetic expressions in the COLUMNS clause.
#
# 			The VALUES LESS THAN clause used in a partition definition must specify a literal value
# 			for each column that appears in the COLUMNS() clause
#
# 			That is, the list of values used for each VALUES LESS THAN clause must contain the 
# 			same number of values as there are columns listed in the COLUMNS clause.
#
# 			AN attempt to use more or fewer values in a VALUES LESS THAN clause than there are
# 			in the COLUMNS clause causes the statements to fail with the:
#
# 			 error Inconsistency in usage of column lists for partitionining 	error
#
# 			You cannot use NULL for any value appearing in VALUES LESS THAN
#
# 			It is possible to use MAXVALUE more than once for a given column
# 			other than the first, as shown in this example:
#
# 				CREATE TABLE rc (
# 					a INT NOT NULL,
# 					b INT NOT NULL
# 				)
# 				PARTITION BY RANGE COLUMNS(a,b) (
# 					PARTITION p0 VALUES LESS THAN (10,5),
# 					PARTITION p1 VALUES LESS THAN (20,10),
# 					PARTITION p2 VALUES LESS THAN (50,MAXVALUE),
# 					PARTITION p3 VALUES LESS THAN (65,MAXVALUE),
# 					PARTITION p4 VALUES LESS THAN (MAXVALUE,MAVALUE)
# 				);
#
# 			Each value in a VALUES LESS THAN value list must match the type of the corresponding
# 			column exactly; no conversion is made.
#
# 			For example, you cannot use the string '1' for a value that matches a column that uses
# 			an integer type (you must use the numeral 1 instead), nor can you use hte numeral 1
# 			for a value that matches a column that uses a string type (in such a case, you must use a quoted string '1')
#
# 			For more information, see SECTION 23.2.1, "RANGE PARTITIONING" and SECTION 23.4, "PARTITION PRUNING"
#
# 		) LIST(expr)
#
# 			THis is useful when assigning partitions based on a table column with a restricted set of possible values,
# 			such as a state or country code.
#
# 			In such a case, all rows pertaining to a certain state or country can be assigned
# 			to a single partition, or a partition can be reserved for a certain set of states
# 			or countries.
#
# 			It is similar to RANGE, except that only VALUES IN may be used to specify permissible
# 			values for each partition.
#
# 			VALUES IN is used with a list of values to be matched.
#
# 			For instance, you could create a partitioning scheme such as
# 			the following:
#
# 				CREATE TABLE client_firms (
# 					id INT,
# 					name VARCHAR(35)
# 				)
# 				PARTITION BY LIST (id) (
# 					PARTITION r0 VALUES IN (1, 5, 9, 13, 17, 21),
# 					PARTITION r1 VALUES IN (2, 6, 10, 14, 18, 22),
# 					PARTITION r2 VALUES IN (3, 7, 11, 15, 19, 23),
# 					PARTITION r3 VALUES IN (4, 8, 12, 16, 20, 24)
# 				);
#
# 			When using list partitioning, you must define at least one partition using VALUES IN.
#
# 			You cannot use VALUES LESS THAN with PARTITION BY LIST.
#
# 			NOTE:
#
# 				For tables partitioned by LIST, the value list used with VALUES IN must consist
# 				of integer values only.
#
# 				In MySQL 8.0, you can overcome this limitation using partitioning by LIST COLUMNS,
# 				which is described later in this section.
#
# 		) LIST COLUMNS(column_list)
#
# 			This variant on LIST facilitates partition pruning for queries using comparison conditions
# 			on multiple columns (that is, having conditions such as WHERE a = 5 AND b = 5 or WHERE a = 1 AND b = 10 AND c = 5)
#
# 			It enables you to specify values in multiple columns by using a list of columns in the
# 			COLUMNS clause and a set of column values in each PARTITION --- VALUES IN (value_list)
# 			partition definition clause.
#
# 			The rules governing regarding data types for the column list used in LIST COLUMNS (column_list)
# 			and the value listed used in VALUES IN (value_list) are the same as those for the column
# 			list used in RANGE COLUMNS (column_list) and the value list used in VALUES LESS THAN (value_list),
# 			respectively, except that in the VALUES IN clause, MAXVALUE is not permitted, and you may use NULL.
#
# 			There is one important difference between the list of values used for VALUES IN with PARTITION BY LIST COLUMNS
# 			as opposed to when it is used with PARTITION BY LIST.
#
# 			When used with PARTITION BY LIST COLUMNS, each element in the VALUES IN clause must be a set of column values;
# 			the number of values in each set must be the same as the number of columns used in the COLUMNS clause, and the
# 			data types of these values must match those of the columns (and occur in the same order)
#
# 			In the simplest case, the set consists of a single column.
#
# 			The maximum number of columns that can be used in the column_list and in the elements
# 			making up the value_list is 16.
#
# 			The table defined by the following CREATE TABLE statement provides an example of a table
# 			using LIST COLUMNS partitioning:
#
# 				CREATE TABLE lc (
# 					a INT NULL,
# 					b INT NULL
# 				)
# 				PARTITION BY LIST COLUMNS(a,b) (
# 					PARTITION p0 VALUES IN( (0,0), (NULL,NULL) ),
# 					PARTITION p1 VALUES IN( (0,1), (0,2), (0,3), (1,1), (1,2) ),
# 					PARTITION p2 VALUES IN( (1,0), (2,0), (2,1), (3,0), (3,1) ),
# 					PARTITION p3 VALUES IN( (1,3), (2,2), (2,3), (3,2), (3,3) )
# 				);
#
# 		) PARTITIONS num
#
# 			The number of partitions may optionally be specified with a PARTITIONS num clause,
# 			where num is the number of partitions.
#
# 			If both this clause and any PARTITION clause are used, num must be equal to the
# 			total number of any partitions that are declared using PARTITION clauses.
#
# 			NOTE:
#
# 				Whether or not you use a PARTITIONS clause in creating a table that is partitioned
# 				by RANGE or LIST, you must still include at least one PARTITION VALUES clause in
# 				the table definition (see below)
#
# 		) SUBPARTITION BY
#
# 			A partition may optionally be divided into a number of subpartitions.
#
# 			This can be indicated by using the optional SUBPARTITION BY clause.
#
# 			Subpartitioning may be done by HASH or KEY.
#
# 			Either of these may be LINEAR. These work in the same way as previously described
# 			for the equivalent partitioning types.
#
# 			(It is not possible to subpartition by LIST or RANGE)
#
# 			The number of subpartitions can be indicated using the SUBPARTITIONS keyword
# 			followed by an integer value.
#
# 		) Rigorous checking of the value used in PARTITIONS or SUBPARTITIONS clauses is applied
# 			and this value must adhere to the following rules:
#
# 				) THe value must be a positive, nonzero integer
#
# 				) No leading zeros are permitted
#
# 				) The value must be an integer literal, and cannot not be an expression.
#
# 					For example, PARTITIONS 0.2E+01 is not permitted, even though 0.2E+01 evaluates
# 					to 2. (Bug #15890)
#
# 		) partition_definition
#
# 			Each partition may be individually defined using a partition_definition clause.
#
# 			The individual parts making up this clause are as follows:
#
# 				) PARTITION partition_name
#
# 					Specifies a logical name for the partition
#
# 				) VALUES
#
# 					For range partitioning, each partition must include a VALUES LESS THAN clause;
# 					for list partitioning, you must specify a VALUES IN clause for each partition.
#
# 					This is used to determine which rows are to be stored in this partition.
#
# 					See the discussion of partitioning types in CHAPTER 23, PARTITIONING, for syntax examples.
#
# 				) [STORAGE] ENGINE
#
# 					MySQL accepts a [STORAGE] ENGINE option for both PARTITION and SUBPARTITION.
#
# 					Currently, the only way in which this option can be used is to set all partitions
# 					or all subpartitions to the same storage engine, and an attempt to set different storage
# 					engines for partitions or subpartitions in the same table will give rise to the error:
#
# 						ERROR 1469 (HY000): The mix of handlers in the partitions is not permitted in this version of MySQL
#
# 				) COMMENT
#
# 					An optional COMMENT clause may be used to specify a string that describes the partition.
#
# 					Example:
#
# 						COMMENT = 'Data for the years previous to 1999'
#
# 					The maximum length for a partition comment is 1024 chars.
#
# 				) DATA DIRECTORY and INDEX DIRECTORY
#
# 					DATA DIRECTORY and INDEX DIRECTORY may be used to indicate the directory where,
# 					respectively, the data and indexes for this partition are to be stored.
#
# 					Both the data_dir and the index_dir must be absolute system path names.
#
# 					You must have the FILE privilege to use the DATA DIRECTORY or INDEX DIRECTORY partition option.
#
# 					Example:
#
# 						CREATE TABLE th (id INT, name VARCHAR(30), adate DATE)
# 						PARTITION BY LIST(YEAR(adate))
# 						(
# 							PARTITION p1999 VALUES IN (1995, 1999, 2003)
# 								DATA DIRECTORY = '/var/appdata/95/data'
# 								INDEX DIRECTORY = '/var/appdata/95/idx',
# 							PARTITION p2000 VALUES IN (1996, 2000, 2004)
# 								DATA DIRECTORY = '/var/appdata/96/data'
# 								INDEX DIRECTORY = '/var/appdata/96/idx',
# 							PARTITION p2001 VALUES IN (1997, 2001, 2005)
# 								DATA DIRECTORY = '/var/appdata/97/data'
# 								INDEX DIRECTORY = '/var/appdata/97/idx',
# 							PARTITION p2002 VALUES IN (1998, 2002, 2006)
# 								DATA DIRECTORY = '/var/appdata/98/data'
# 								INDEX DIRECTORY = '/var/appdata/98/idx'
# 						);
#
# 					DATA DIRECTORY and INDEX DIRECTORY behave in the same way as in the CREATE TABLE statements
# 					table_option clause as used for MyISAM tables.
#
# 					One data directory and one index directory may be specified per partition.
#
# 					If left unspecified, the data and the indexes are stored by default in teh table's database
# 					directory.
#
# 					The DATA DIRECTORY and INDEX DIRECTORY options are ignored for creating partitioned tables if
# 					NO_DIR_IN_CREATE is in effect.
# 				
# 				) MAX_ROWS and MIN_ROWS
#
# 					May be used to specify, respectively, the maximum and the minimum number of rows to be stored
# 					in the partition.
#
# 					The values for max_number_of_rows and min_number_of_rows must be positive integers.
#
# 					As with the table-level options with the same names, these act only as "suggestions"
# 					to the server and are not hard limits.
#
# 				) TABLESPACE
#
# 					May be used to designate an InnoDB file-per-table tablespace for the partition by specifying
# 					TABLESPACE `innodb_file_per_table
#
# 					All partitions must belong to the same storage engine
#
# 					Placing InnoDB table partitions in shared InnoDB tablespaces is not supported.
#
# 					Shared tablespaces include the InnoDB system tablesapce and general tablespaces.
#
# 		) subpartition_definition
#
# 			The partition definition may optionally contain one or more subpartition_definition clauses.
#
# 			Each of these consists at a minimum of the SUBPARTITION name, where name is an identifier
# 			for the subpartition.
#
# 			Except for the replacement of the PARTITION keyword with SUBPARTITION, the syntax for a 
# 			subpartition definintion is identical to that for a partition definition.
#
# 			Subpartitioning must be done by HASH or KEY, and can be done only on RANGE or LIST partitions.
#
# 			See SECTION 23.2.6, "SUBPARTITIONING"
#
# PARTITIONING BY GENERATED COLUMNS
#
# Partitioning by generated columns is permitted.
#
# For example:
#
# 		CREATE TABLE t1 (
# 			s1 INT,
# 			s2 INT AS (EXP(s1)) STORED
# 		)
# 		PARTITION BY LIST (s2) (
# 			PARTITION p1 VALUES IN (1)
# 		);
#
# Partitioning sees a generated column as a regular column, which enables workarounds for limitations
# on functions that are not permitted for partitioning (see SECTION 23.6.3, "PARTITIONING LIMITATIONS RELATING TO FUNCTIONS")
#
# THe preceding example demonstrates this technique:
#
# 		EXP() cannot be used directly in teh PARTITION BY clause, but a generated
# 		column defined using EXP() is permitted.
#
# 13.1.20.1 CREATE TABLE STATEMENT RETENTION
#
# The original CREATE_TABLE statement, including all specifications and table options are stored by
# MySQL when the table is created.
#
# The information is retained so that if you change storage engines, collations or other settings
# using an ALTER_TABLE statement, the original table options specified are retained.
#
# This enables you to change between InnoDB and MyISAM table types even though the row formats
# supported by the two engines are different.
#
# Because the text of the original statement is retained, but due to the way that certain values
# and options may be silently reconfigured, the active table definition (accessible through 
# DESCRIBE or with SHOW_TABLE_STATUS) and the table creation string (accessible through
# SHOW_CREATE_TABLE) may report different values.
#
# For InnoDB tables, SHOW_CREATE_TABLE and the Create_options column reported by SHOW_TABLE_STATUS
# show the actual ROW_FORMAT and KEY_BLOCK_SIZE attributes used by the table.
#
# In previous MySQL releases, the originally specified values for these attributes were reported.
#
# 13.1.20.2 FILES CREATED BY CREATE TABLE
#
# For an InnoDB table created in a file-per-table tablespace or general tablespace, table data
# and associated indexes are stored in an ibd file in the database directory.
#
# When an InnoDB table is created in the system tablespace, table data and indexes are stored
# in the ibdata* files that represent the system tablespace.
#
# The innodb_file_per_table option controls whether tables are created in file-per-table
# tablespaces or the system tablespace, by default.
#
# The TABLESPACE option can be used to place a table in a file-per-table tablespace,
# general tablespace, or the  system tablespace, regardless of the innodb_file_per_table
# setting.
#
# For MyISAM tables, the storage engine creates data and index files.
#
# Thus, for each MyISAM table tbl_name, there are two disk files.
#
# FILE 			PURPOSE
#
# tbl_name.MYD Data file
# tbl_name.MYI Index file
#
# Chapter 16, ALTERNATIVE STORAGE ENGINES describes what files each storage engine
# creates to represent tables.
#
# If a table name contains special characters, the names for the table files 
# contain encoded versions of those characters as described in SECTION 9.2.3, "MAPPING OF IDENTIFIERS TO FILE NAMES"
#
# 13.1.20.3 CREATE TEMPORARY TABLE SYNTAX
#
# You can use the TEMPORARY keyword when creating a table.
#
# A TEMPORARY table is visible only within the current session, and is dropped automatically when
# the session is closed.
#
# THis means that two different sessions can use the same temporary table name without conflicting
# with each other or with an existing non-TEMPORARY table of the same name.
#
# (The existing table is hidden until the temporary table is dropped)
#
# InnoDB does not support compressed temporary tables.
#
# When innodb_strict_mode is enabled (the default), CREATE_TEMPORARY_TABLE returns an error
# if ROW_FORMAT=COMPRESSED or KEY_BLOCK_SIZE is specified.
#
# If innodb_strict_mode is disabled, warnings are issued and the temporary table is created
# using a non-compressed row format.
#
# The innodb_file_per-table option does not affect the creation of InnoDB temporary tables.
#
# CREATE_TABLE causes an implicit commit, except when used with the TEMPORARY keyword.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# TEMPORARY tables have a very loose relationship with databases (schemas)
#
# Dropping a database does not automatically drop any TEMPORARY tables created
# within that database.
#
# ALso, you can create a TEMPORARY table in a nonexistent database if you qualify the
# table name with the database name in the CREATE TABLE statement.
#
# In this case, all subsequent references to the table must be qualified with the database name.
#
# To create a temporary table, you must have the CREATE_TEMPORARY_TABLES privilege.
#
# After a session has created a temporary table, the server performs no further
# privilege checks on the table.
#
# The creating session can perform any operation on the table, such as DROP_TABLE,
# INSERT, UPDATE or SELECT.
#
# One implication of this behavior is that a session can manipulate its temporary table
# even if the current user has no privilege to create them.
#
# Suppose that hte current user does not have the CREATE_TEMPORARY_TABLES privilege
# but is able to execute a definer-context stored procedure that executes with the
# privileges of a user who does have CREATE_TEMPORARY_TABLES and that creates a 
# temporary table.
#
# While the procedure executes, the session uses the privileges of the defining user.
#
# After hte procedure returns, the effective privileges revert to those of the current
# user, which can still see the temporary table and perform any operation on it.
#
# YOu cannot use CREATE TEMPORARY TABLE --- LIKE to create an empty table based on the
# definition of a table that resides in teh mysql tablespace, InnoDB system tablespace
# (innodb_system), or a general tablespace.
#
# The tablespace definition for such a table includes a TABLESPACE attribute that defines
# the tablespace where the table resides, and the aformentioned tablespaces do not support
# temporary tables.
#
# To create a temporary table based on the definition of such a table, use this syntax instead:
#
# 		CREATE TEMPORARY TABLE new_tbl SELECT * FROM orig_tbl LIMIT 0;
#
# NOTE:
#
# 		Support for TABLESPACE = innodb_file_per_table and TABLESPACE = innodb_temporary clauses
# 		with CREATE_TEMPORARY_TABLE is deprecated as of MysQL 8.0.13.
#
# 13.1.20.4 CREATE TABLE --- LIKE SYNTAX
#
# Use CREATE TABLE --- LIKE to create an empty table based on the definition
# of another table, including any column attributes and indexes defined in the
# original table:
#
# 		CREATE TABLE new_tbl LIKE orig_tbl;
#
# The copy is created using the same version of the table storage format as the 
# original table.
#
# The SELECT privilege is required on the original table
#
# LIKE works only for base tables, not for views.
#
# IMPORTANT:
#
# 		You cannot execute CREATE TABLE or CREATE TABLE --- LIKE while a LOCK_TABLES statement is in effect.
#
# 		CREATE_TABLE_---_LIKE makes the same checks as CREATE_TABLE
#
# 		This means that if the current SQL mode is different from the mode in effect when
# 		the original table was created, the table definition might be considered invalid for
# 		the new mode and the statement will fail.
#
# For CREATE TABLE --- LIKE, the destination table preserves generated column information
# from the original table.
#
# For CREATE TABLE --- LIKE, the destination table expression default values from the original table
#
# CREATE TABLE --- LIKE does not preserve any DATA DIRECTORY or INDEX DIRECTORY table options
# that were specified for the original table, or any foreign key defintiions.
#
# If hte original table is a TEMPORARY table, CREATE TABLE --- LIKE does not preserve TEMPORARY
#
# To create a TEMPORARY destination table, use CREATE TEMPORARY TABLE --- LIKE
#
# Tables created in the mysql tablespace, the InnoDB system tablespace (innodb_system),
# or general tablespaces include a TABLESPACE attribute in the table definition, which
# defines the tablespace where the table resides.
#
# Due to a temporary regression, CREATE TABLE --- LIKE preserves the TABLESPACE attribute
# and creates the table in the defined tablespace regardless of the innodb_file_per_table
# setting.
#
# To avoid the TABLESPACE attribute when creating an empty table based on the definition
# of such a table, use this syntax instead:
#
# 		CREATE TABLE new_tbl SELECT * FROM orig_tbl LIMIT 0;
#
# 13.1.20.5 CREATE TABLE --- SELECT SYNTAX
#
# You can create one table from another by adding a SELECT statement at the end
# of the CREATE_TABLE statement:
#
# 		CREATE TABLE new_tbl [AS] SELECT * FROM orig_tbl;
#
# MySQL creates new columns for all elements in the SELECT. For example:
#
# 		CREATE TABLE test (a INT NOT NULL AUTO_INCREMENT,
# 					PRIMARY KEY (a), KEY(b))
# 					ENGINE=MyISAM SELECT b,c FROM test2;
#
# This creates a MyISAM table with three columns, a,b and c.
#
# The ENGINE option is part of the CREATE_TABLE statement, and should
# not be used following the SELECT; This would result in syntax error.
#
# THe same is true for other CREATE_TABLE options such as CHARSET.
#
# Notice that the columns from the SELECT statements are appended to the right
# side of the table, not overlapped onto it.
#
# Take the following example:
#
# 		SELECT * FROM foo;
# 		+----+
# 		| n  |
# 		+----+
# 		| 1  |
# 		+----+
#
# 		CREATE TABLE bar (m INT) SELECT n FROM foo;
# 		Query OK, 1 row affected (0.02 sec)
# 		Records: 1 Duplicates: 0 Warnings: 0
#
# 		SELECT * FROM bar;
# 		+--------+-------+
# 		| m 		| n 	  |
# 		+--------+-------+
# 		| NULL   | 1 	  |
# 		+--------+-------+
# 		1 row in set (0.00 sec)
#
# For each row in table foo, a row is inserted in bar with the value from foo
# and default values for the new columns.
#
# In a table resulting from CREATE_TABLE_---_SELECT, columns named only in the
# CREATE_TABLE part come first.
#
# Columns named in both parts or only in the SELECT part come after that.
#
# The data type of SELECT columns can be overridden by also specifying
# the column in the CREATE_TABLE part
#
# If any errors occur while copying the data to the table, it is automatically
# dropped and not created.
#
# You can precede the SELECT by IGNORE or REPLACE to indicate how to handle rows
# that duplicate unique key values.
#
# With IGNORE, rows that duplicate an existing row on a unqiue key value are discarded.
#
# With REPLACE, new rows replace rows that have the same unique key value.
#
# If neither IGNORE nor REPLACE is specified, duplicate unique key values result
# in an error.
#
# For more information, see COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE.
#
# Because the ordering of the rows in the underlying SELECT statements cannot always
# be determined, CREATE TABLE --- IGNORE SELECT and CREATE TABLE --- REPLACE SELECT
# statements are flagged as unsafe for statement-based replication.
#
# Such statements produce a warning in the error log when using statement-based mode
# and are written to the binary log using the row-based format when using MIXED mode.
#
# See also SECTION 17.2.1.1, "ADVANTAGES AND DISADAVANTAGES OF STATEMENT-BASED AND ROW-BASED REPLICATION"
#
# CREATE_TABLE_---_SELECT does not automatically create any indexes for you.
#
# This is done intentionally to make the statement as flexible as possible.
#
# If you want to have indexes in the created table, you should specify these before
# the SELECT statement:
#
# 		CREATE TABLE bar (UNIQUE (n)) SELECT n FROM foo;
#
# For CREATE TABLE --- SELECT, the destination table does not preserve information about
# whether columns in the selected-from table are generated columns.
#
# The SELECT part of the statement cannot assign values to generated columns in the destination table.
#
# For CREATE TABLE --- SELECT, the destination table does preserve expression default values
# from the original table.
#
# Some conversion of data types might occur. For example, the AUTO_INCREMENT attribute is not
# preserved, and VARCHAR columns can become CHAR columns.
#
# Retrained attributes are NULL (or NOT NULL) and, for those columns that have them,
# CHARACTER SET, COLLATION, COMMENT, and the DEFAULT clause.
#
# When creating a table with CREATE_TABLE_---_SELECT, make sure to alias any function
# calls or expressions in the query.
#
# If you do not, the CREATE statement might fail or result in undesirable column names.
#
# CREATE TABLE artists_and_works
# 		SELECT artist.name, COUNT(work.artist_id) AS number_of_works
# 		FROM artist LEFT JOIN work ON artist.id = work.artist_id
# 		GROUP BY artist.id;
#
# You can also explicitly specify the data type for a column in the created table:
#
# 		CREATE TABLE foo (a TINYINT NOT NULL) SELECT b+1 AS a FROM bar;
#
# For CREATE_TABLE_---_SELECT, if IF NOT EXISTS is given and the target table exists,
# nothing is inserted into the destination table, and the statement is not logged.
#
# To ensure that the binary log can be used to re-create the original tables, MySQL
# does not permit concurrent inserts during CREATE_TABLE_---_SELECT
#
# You cannot use FOR UPDATE as part of the SELECT in a statement such as 
# CREATE_TABLE_new_table_SELECT_---_FROM_old_table_---
#
# Attempting to do so, causes the statement to fail.
#
# 13.1.20.6 USING FOREIGN KEY CONSTRAINTS
#
# MySQL supports foreign keys, which let you cross-reference related data across
# tables, and foreign key constraints, which help keep this spread-out data consistent.
#
# The essential syntax for a foreign key constraint definition in a CREATE_TABLE or
# ALTER_TABLE statement looks like this:
#
# 		[CONSTRAINT [symbol]] FOREIGN KEY
# 			[index_name] (col_name, ---)
# 			REFERENCES tbl_name (col_name, ---)
# 			[ON DELETE reference_option]
# 			[ON UPDATE reference_option]
# 		
# 		reference_option:
# 			RESTRICT | CASCADE | SET NULL | NO ACTION | SET DEFAULT
#
# index_name represents a foreign key ID.
#
# The index_name value is ignored if there is already an explicitly defined index
# on the child table that  can support the foreign key.
#
# Otherwise, MySQL implicitly creates a foreign key index that is named according
# to the following rules:
#
# 		) If defined, the CONSTRAINT symbol value is used. Otherwise, the FOREIGN KEY index_name value is used
#
# 		) If neither a CONSTRAINT symbol or FOREIGN KEY index_name is defined, the foreign key index name is generated
# 			using the name of the referencing foreign key column.
#
# The FOREIGN KEY index_name value must be unique in the database.
#
# Foreign keys definitions are subject to the following conditions:
#
# 		) Foreign key relationships involve a parent table that holds the central data values,
# 			and a child table with identical values pointing back to its parent.
#
# 			The FOREIGN KEY clause is specified in the child table.
#
# 			The parent and child tables must use the same storage engine.
#
# 			They must not be TEMPORARY tables.
#
# 			In MySQL 8.0, creation of a foreign key constraint requires the REFERENCES privilege
# 			for the parent table
#
# 		) Corresponding columns in the foreign key and the referenced key must have similar data types.
#
# 			The size and sign of integer types must be the same. The length of string types need
# 			not be the same.
#
# 			For nonbinary (character) string columns, the character set and collation must be the same.
#
# 		) When foreign_key_checks is enabled, which is the default setting, character set conversion is not
# 			permitted on tables that include a character string column used in a foreign key constraint.
#
# 			The workaround is described in SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# 		) MySQL requires indexes on foreign keys and referenced keys so that foreign key checks can be fast
#  		and not require a table scan.
#
# 			In the referencing table, there must be an index where the foreign key columns are listed as
# 			the first columns in the same order.
#
# 			Such an index is created on the referencing table automatically if it does not exist.
#
# 			This index might be silently dropped later, if you create another index that can be used to enforce
# 			the foreign key constraint.
#
# 			index_name, if given, is used as described previously.
#
# 		) InnoDB permits a foreign key to reference any column or group of columns.
#
# 			However, in the reference table, there must be an index where the referenced
# 			columns are listed as the first columns in the same order.
#
# 			NDB requires an explicit unique key (or primary key) on any column referenced as a foreign key.
#
# 		) Index prefixes on foreign key columns are not supported.
#
# 			One consequence of this is that BLOB and TEXT columns cannot be included in a foreign key because
# 			indexes on those columns must always include a prefix length.
#
# 		) If the CONSTRAINT symbol clause is given, the symbol value, if used, must be unique in the database.
#
# 			A duplicate symbol will result in an error similar to: 
#
# 				ERROR 1022 (2300): Can't write; duplicate key in table '#sql- 464_1'
#
# 			If the clause is not given, or a symbol is not included following the CONSTRAINT keyword,
# 			a name for the constraint is created automatically.
#
# 		) InnoDB does not currently support foreign keys for tables with user-defined partitioning.
#
# 			This includes both parent and child tables.
#
# 			This restriction does not apply for NDB tables that are partitioned by KEY or LINEAR KEY
# 			(the only user partitioning types supported by the NDB storage engine);
#
# 			these may have foreign key references or be the targets of such references.
#
# 		) For NDB tables, ON UPDATE CASCADE is not supported where the reference is to be the parent
# 			table's primary key.
#
# Additional aspects of FOREIGN KEY constraint usage are described under the following topics in this section:
#
# 		) REFERENTIAL ACTIONS
#
# 		) EXAMPLES OF FOREIGN KEY CLAUSES
#
# 		) ADDING FOREIGN KEYS
#
# 		) DROPPING FOREIGN KEYS
#
# 		) FOREIGN KEYS AND OTHER MYSQL STATEMENTS
#
# 		) FOREIGN KEYS AND THE ANSI/ISO SQL STANDARD
#
# 		) FOREIGN KEY METADATA 
#
# 		) FOREIGN KEY ERRORS
#
# REFERENTIAL ACTIONS
#
# This section describes how foreign keys help guarantee referential integrity.
#
# For storage engines supporting foreign keys, MySQL rejects any INSERT or UPDATE operation that
# attempts to create a foreign key value in a child  table if there is not a matching candidate
# key value in the parent table.
#
# When an UPDATE or DELETE operation affects a key value in the parent table that has matching
# rows in the child table, the result depends on the referential action specified using
# ON UPDATE and ON DELETE subclauses of the FOREIGN KEY clause.
#
# MySQL supports five options regarding the action to be taken, listed here:
#
# 		) CASCADE: Delete or update the row from the parent table, and automatically delete or update
# 			the matching rows in the child table.
#
# 			Both ON DELETE CASCADE and ON UPDATE CASCADE are supported.
#
# 			Between two tables, do not define several ON UPDATE CASCADE clauses that act
# 			on the same column in the parent table or in the child table.
#
# 			If a FOREIGN KEY clause is defined on both tables in a foreign key relationship,
# 			making both tables a parent and child, an ON UPDATE CASCADE or ON DELETE CASCADE
# 			subclause defined for one FOREIGN KEY clause must be defined for the other in order
# 			for cascading operations to succeed.
#
# 			If an ON UPDATE CASCADE or ON DELETE CASCADE subclause is only defined for one 
# 			FOREIGN KEY clause, cascading operations fail with an error.
#
# 			NOTE:
#
# 				Cascaded foreign key actions do not active triggers
#
# 		) SET NULL:
#
# 			Delete or update the row from the parent table, and set the foreign key column
# 			or columns in the child table to NULL.
#
# 			Both ON DELETE SET NULL and ON UPDATE SET NULL clauses are supported.
#
# 			If you specify a SET NULL action, make sure that you have not declared the columns
# 			in the child table as NOT NULL
#
# 		) RESTRICT:
#
# 			Rejects the delete or update operation for the parent table.
#
# 			Specifying RESTRICT (or NO ACTION) is the same as omitting the ON DELETE
# 			or ON UPDATE clause.
#
# 		) NO ACTION:
#
# 			A keyword from standard SQL. In MySQL, equivalent to RESTRICT.
#
# 			The MySQL Server rejects the delete or update operation for the
# 			parent table if there is a related foreign key value in the referenced table.
#
# 			Some database systems have deferred checks, and NO ACTION is a deferred check.
#
# 			In MySQL, foreign key constraints are checked immediately, so NO ACTION is the same
# 			as RESTRICT.
#
# 		) SET DEFAULT:
#
# 			This action is recognized by the MySQL parser, but both InnoDB and NDB reject table
# 			defintions containing ON DELETE SET DEFAULT or ON UPDATE SET DEFAULT clauses.
#
# For an ON DELETE or ON UPDATE that is not specified, the default action is always RESTRICT.
#
# MySQL supports foreign key references between one column and another within a table.
#
# (A column cannot have a foreign key reference to itself)
#
# In these cases, "child table records" really refers to dependent records within the
# same table.
#
# A foreign key constraint on a stored generated column cannot use ON UPDATE CASCADE,
# ON DELETE SET NULL, ON UPDATE SET NULL, ON DELETE SET DEFAULT or ON UPDATE SET DEFAULT.
#
# A foreign key constraint cannot reference a virtual generated column.
#
# For InnoDB restrictions related to foreign keys and generated columns, see
# SECTION 15.6.1.5, "InnoDB AND FOREIGN KEY CONSTRAINTS"
#
# EXAMPLES OF FOREIGN KEY CLAUSES
#
# Here is a simple example that relates parent and child tables through a single-column
# foreign key:
#
# 		CREATE TABLE parent (
# 			id INT NOT NULL,
# 			PRIMARY KEY (id)
# 		) ENGINE=INNODB;
#
# 		CREATE TABLE child (
# 			id INT,
# 			parent_id INT,
# 			INDEX par_ind (parent_id),
# 			FOREIGN KEY (parent_id)
# 				REFERENCES parent(id)
# 				ON DELETE CASCADE
# 		) ENGINE=INNODB;
#
# A more complex example in which a product_order table has foreign keys for two other tables.
#
# One foreign key references a two-column index in the product table.
#
# The other references a single-column index in the customer table:
#
# 		CREATE TABLE product (
# 			category INT NOT NULL, id INT NOT NULL,
# 			price DECIMAL,
# 			PRIMARY KEY(category, id)
# 		) ENGINE=INNODB;
#
# 		CREATE TABLE customer (
# 			id INT NOT NULL,
# 			PRIMARY KEY (id)
# 		) ENGINE=INNODB;
#
# 		CREATE TABLE product_order (
# 			no INT NOT NULL AUTO_INCREMENT,
# 			product_category INT NOT NULL,
# 			product_id INT NOT NULL,
# 			customer_id INT NOT NULL,
#
# 			PRIMARY KEY(no),
# 			INDEX (product_category, product_id),
# 			INDEX (customer_id),
#
# 			FOREIGN KEY (product_category, product_id)
# 				REFERENCES product(category, id)
# 				ON UPDATE CASCADE ON DELETE RESTRICT,
#
# 			FOREIGN KEY (customer_id)
# 				REFERENCES customer(id)
# 		) 	ENGINE=INNODB;
#
# ADDING FOREIGN KEYS
#
# You can add a new foreign key constraint to an existing table by using
# ALTER_TABLE
#
# The syntax relating to foreign keys for this statement is shown here:
#
# 		ALTER TABLE tbl_name
# 			ADD [CONSTRAINT [symbol]] FOREIGN KEY
# 			[index_name] (col_name, ---)
# 			REFERENCES tbl_name (col_name,---)
# 			[ON DELETE reference_option]
# 			[ON UPDATE reference_option]
#
# The foreign key can be self referential (referring to the same table)
#
# When you add a foreign key constraint to a table using ALTER_TABLE,
# remember to create the required indexes first.
#
# DROPPING FOREIGN KEYS
#
# You can also use ALTER_TABLE to drop foreign keys, using the syntax shown here:
#
# 		ALTER TABLE tbl_name DROP FOREIGN KEY fk_symbol;
#
# If the FOREIGN KEY clause included a CONSTRAINT name when you created the foreign key,
# you can refer to that name to drop the foreign key.
#
# Otherwise, the fk_symbol value is generated internally when the foreign key is created.
#
# To find out the symbol value when you want to drop a foreign key, use a SHOW_CREATE_TABLE
# statement, as shown here:
#
# 		SHOW CREATE TABLE ibtest11c\G
# 		************************** 1. row ******************************
# 						Table: ibtest11c
# 			Create Table  : CREATE TABLE `ibtest11c` (
# 				`A` int(11) NOT NULL auto_increment,
# 				`D` int(11) NOT NULL default '0',
# 				`B` varchar(200) NOT NULL default '',
# 				`C` varchar(175) default NULL,
# 				PRIMARY KEY (`A`, `D`, `B`),
# 				KEY `B` (`B`,`C`),
# 				KEY `C` (`C`),
# 				CONSTRAINT `0_38775` FOREIGN KEY (`A`, `D`)
# 			REFERENCES `ibtest11a` (`A`, `D`)
# 			ON DELETE CASCADE ON UPDATE CASCADE,
# 				CONSTRAINT `0_38776` FOREIGN KEY (`B`, `C`)
# 			REFERENCES `ibtest11a` (`B`, `C`)
# 			ON DELETE CASCADE ON UPDATE CASCADE
# 			) ENGINE=INNODB CHARSET=utf8mb4
# 			1 row in set (0.01 sec)
#
# 			ALTER TABLE ibtest11c DROP FOREIGN KEY `0_38775`;
#
# Adding and dropping a foreign key in the same ALTER_TABLE statement is supported for
# ALTER_TABLE_---_ALGORITHM=INPLACE but is unsupported for ALTER_TABLE_---_ALGORITHM=COPY
#
# In MySQL 8.0, the server prohibits changes to foreign key columns with the potential
# to cause loss of referential integrity.
#
# A workaround is to use ALTER_TABLE_---_DROP_FOREIGN_KEY before changing the column
# defintion and ALTER_TABLE_---_ADD_FOREIGN_KEY afteward
#
# FOREIGN KEYS AND OTHER MYSQL STATEMENTS
#
# Table and column identifiers in a FOREIGN KEY --- REFERENCES --- clause can be quoted
# within backticks (`)
#
# Alternatively, double quotation marks (") can be used if the ANSI_QUOTES SQL mode is enabled.
#
# The setting of the lower_case_table_names system variable is also taken into account.
#
# You can view a child table's foreign key definitions as part of the output of the
# SHOW_CREATE_TABLE statement:
#
# 		SHOW CREATE TABLE tbl_name;
#
# You can also obtain information about foreign keys by querying the INFORMATION_SCHEMA.KEY_COLUMN_USAGE table
#
# You can find information about foreign keys used by InnoDB tables in the INNODB_FOREIGN and
# INNODB_FOREIGN_COLS tables, also in the INFORMATION_SCHEMA database.
#
# mysqldump produces correct defintiions of tables in the dump file, including the foreign keys for child tables.
#
# TO make it easier to reload dump files that have foreign key relationships, mysqldump automatically
# includes a statement in the dump output to set foreign_key_checks to 0
#
# This avoids problems with tables having to be reloaded in a particular order when the dump is
# reloaded.
#
# It is also possible to set this variable manually:
#
# 		SET foreign_key_checks = 0;
# 		SOURCE dump_file_name;
# 		SET foreign_key_checks = 1;
#
# This enables you to import the tables in any order if the dump file contains tables
# that are not correctly ordered for foreign keys.
#
# It also speeds up the import operation.
#
# Setting foreign_key_checks to 0 can also be useful for ignoring foreign key constraints
# during LOAD_DATA and ALTER_TABLE operations.
#
# However, even if foreign_key_checks = 0, MySQL does not permit the creation of a foreign key
# constraint where a column references a nonmatching column type.
#
# ALso, if a table has foreign key constraints, ALTER_TABLE cannot be used to alter the table
# to use another storage engine.
#
# To change the storage engine, you must drop any foreign key constarints first.
#
# You cannot issue DROP_TABLE for a table that is referenced by a FOREIGN KEY constraint,
# unless you do SET foreign_key_checks = 0
#
# When you drop a table, any constraints that were defined in the statement used to create
# that table are also dropped.
#
# If you re-create a table that was dropped, it must have a definition that conforms to
# the foreign key constraints referencing it.
#
# It must have the correct column names and types, and it must have indexes on the referenced
# keys, as stated earlier.
#
# If these are not satisfied, MySQL returns Error 1005 and refers to Error 150 in the error message,
# which means that a foreign key constraint was not correctly formed.
#
# SImilarly, if an ALTER_TABLE fails due to Error 150, this means that a foreign key definition
# would be incorrectly formed for the altered table
#
# For InnoDB tables, you can obtain a detailed explanation of the most recent InnoDB foreign key
# error in the MySQL Server, by checking the output of SHOW_ENGINE_INNODB_STATUS
#
# MySQL extends metadata locks, as necessary, to tables that are related by a foreign key constraint.
#
# Extending metadata locks prevents conflicting DML and DDL operations from executing concurrently
# on related tables.
#
# This feature also enables updates to foreign key metadata when a parent table is modified.
#
# In earlier MysQl releases, foreign key metadata, which is owned by the child table, could not
# be updated safely.
#
# If a table is locked explicitly with LOCK_TABLES, any tables related by a foreign key constraint
# are opened and locked implicitly.
#
# For foreign key checks, a shared read-only lock (LOCK_TABLES_READ) is taken on related tables.
#
# For cascading updates, a shared-nothing write lock (LOCK_TABLES_WRITE) is taken on related
# tables that are involved in the operation
#
# FOREIGN KEYS AND THE ANSI/ISO SQL STANDARD
#
# For users familiar with the ANSI/ISO SQL Standard, please note htat no storage engine, including
# innoDB, recognizes or enforces the MATCH clause used in referential-integrity constraint defintiions.
#
# Use of an explicit MATCH clause will not have the specified effect, and also causes ON DELETE
# and ON UPDATE clauses to be ignored.
#
# For these reasons, specifying MATCH should be avoided
#
# The MATCH clause in the SQL standard controls how NULL values in a composite (multiple-column)
# foreign key are handled when comparing to a primary key
#
# MySQL essentialy implements the semantics defined by MATCH SIMPLE, which permit a foreign key
# to be all or partially NULL
#
# In that case, the (child table) row containing such a foreign key is permitted to be inserted,
# and does not match any row in the referenced (parent) table
#
# It is possible to implement other semantics using triggers.
#
# Additionally, MySQL requires that the referenced columns be indexed for performance reasons.
#
# However, the system does not enforce a requirement that the referenced columns be UNIQUE
# or be declared NOT NULL
#
# The handling of foreign key references to nonunique keys or keys that contain NULL values
# is not well defined for operations such as UPDATE or DELETE CASCADE
#
# You are advised to use foreign keys that reference only UNIQUE (including PRIMARY)
# and NOT NULL keys.
#
# Furthermore, MySQL parses but ignores "inline REFERENCES specifications" (as defined in the
# SQL standard) where the references are defined as part of the column specification.
#
# MySQL accepts REFERENCES clauses only when specified as part of a separate FOREIGN KEY
# specification.
#
# For storage engines that do not support foreign keys (such as MyISAM), MySQL Server
# parses and ignores foreign key specifications.
#
# FOREIGN KEY METADATA
#
# The INFORMATION_SCHEMA.KEY_COLUMN_USAGE table identifies the key columns that have constraints.
#
# Metadata specific to InnoDB foreign keys is found in the INNODB_SYS_FOREIGN and INNODB_SYS_FOREIGN_COLS
# tables
#
# FOREIGN KEY ERRORS
#
# In the event of a foreign key error involving InnoDB tables (usually Error 150 in the MySQL Server),
# information about the most recent InnoDB foreign key error can be obtained by checking
# SHOW_ENGINE_INNODB_STATUS output.
#
# 	WARNING:
#
# 		If a user has table-level privileges for all parent tables, ER_NO_REFERENCED_ROW_2 and
# 		ER_ROW_IS_REFERENCED_2 error messages for foreign key operations expose information
# 		about parent tables.
#
# 		If a user does not have table-level privileges for all parent tables, more generic
# 		eror messages are displayed instead (ER_NO_REFERENCED_ROW and ER_ROW_IS_REFERENCED)
#
# 		An exception is that, for stored programs defiend to execute with DEFINER privileges,
# 		the user against which privileges are assessed is the user in the program DEFINER clause,
# 		not the invoking user.
#
# 		If that user has table-level parent table privileges, parent table informaiton is
# 		still displayed.
#
# 		In this case, it is the responsibility of the stored program creator to hide
# 		information by including appropriate condition handlers.
#
# 13.1.20.7 SILENT COLUMN SPECIFICATION CHANGES
#
# In some cases, MySQL silently changes column specifications from those given in a 
# CREATE_TABLE or ALTER_TABLE statement.
#
# These might be changes to a data type, to attributes associated with a data type,
# or to an index specification.
#
# ALl changes are subject to the internal row-size limit of 65,535 bytes, which may
# cause some attempts at data type changes to fail.
#
# See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# 		) Columns that are part of a PRIMARY KEY are made NOT NULL even if not declared that way
#
# 		) Trailing spaces are automatically deleted from ENUM and SET member values when the table is created.
#
# 		) MySQL maps certain data types used by other SQL database vendors to MySQL types.
#
# 			See SECTION 11.10, "USING DATA TYPES FROM OTHER DATABASE ENGINES"
#
# 		) If you include a USING clause to specify an index type that is not permitted for a given storage
# 			engine, but there is another index type available that the engine can use without affecting
# 			query results, the engine uses the available type.
#
# 		) If strict SQL mode is not enabled, a VARCHAR column with a length specification greater than
# 			65535 is converted to TEXT, and a VARBINARY column with a length specification greater than
# 			65535 is converted to BLOB.
#
# 			Otherwise, an error occurs in either of these cases
#
# 		) Specifying the CHARACTER SET binary attribute for a character data type causes the column to be
# 			created as the corresponding binary data type:
#
# 				CHAR becomes BINARY, VARCHAR becomes VARBINARY, and TEXT becomes BLOB
#
# 			For the ENUM and SET data types, this does not occur; they are created as declared.
#
# 			Suppose that you specify a table using this definition:
#
# 				CREATE TABLE t
# 				(
# 					c1 VARCHAR(10) CHARACTER SET binary,
# 					c2 TEXT CHARACTER SET binary,
# 					c3 ENUM('a', 'b', 'c') CHARACTER SET binary
# 				);
#
# 			The resulting table has this definition:
#
# 				CREATE TABLE t
# 				(
# 					c1 VARBINARY(10),
# 					c2 BLOB,
# 					c3 ENUM('a', 'b', 'c') CHARACTER SET binary
# 				);
#
# 			To see whether MySQL uses a data type other than the one you specified, issue a DESCRIBE
# 			or SHOW_CREATE_TABLE statement after creating or altering the table.
#
# 			Certain other data type changes can occur if you compress a table using myisampack.
#
# 			See SECTION 16.2.3.3, "COMPRESSED TABLE CHARACTERISTICS"
#
# 13.1.20.8 CREATE TABLE AND GENERATED COLUMNS
#
# CREATE_TABLE supports the specification of generated columns.
#
# Values of a generated column are computed from an expression included in the column definition.
#
# Generated columns are also supported by the NDB storage engine.
#
# The following simple example shows a table that stores the lengths of the sides of right triangles
# in the sidea and sideb columns, and computes hte length of the hypotenuse in sidec
# (the square root of the sums of the squares of the other sides):
#
# 		CREATE TABLE triangle (
# 			sidea DOUBLE,
# 			sideb DOUBLE,
# 			sidec DOUBLE AS (SQRT(sidea * sidea + sideb * sideb))
# 		);
# 		INSERT INTO triangle (sidea, sideb) VALUES(1,1), (3,4), (6,8);
#
# Selecting from the table yields this result:
#
# 		SELECT * FROM triangle;
# 		+-----------+-------------+-----------------------------+
# 		| sidea     | sideb 		  | sidec 							  |
# 		+-----------+-------------+-----------------------------+
# 		| 1 			| 1 			  | 1.4142135623730951 			  |
# 		| 3 		  	| 4 			  | 5 								  |
# 		| 6 			| 8 			  | 10 								  |
# 		+-----------+-------------+-----------------------------+
#
# ANy application that uses the triangle table has access to the hypotenuse values without
# having to specify the expression that calculates them.
#
# Generated column definitions have this syntax:
#
# 		col_name data_type [GENERATED ALWAYS] AS (expression)
# 			[VIRTUAL | STORED] [NOT NULL | NULL]
# 			[UNIQUE [KEY]] [[PRIMARY] KEY]
# 			[COMMENT 'string']
#
# AS (expression) indicates that the column is genrated and defines the expression
# used to compute column values.
#
# AS may be preceded by GENERATED ALWAYS to make the generated nature of the column
# more explicit.
#
# Constructs that are permitted or prohibited in the expression are discussed later.
#
# The VIRTUAL or STORED keyword indicates how column values are stored, which has implications
# for column use:
#
# 		) VIRTUAL: Column values are not stored, but are evaluated when rows are read, immediately
# 			after any BEFORE triggers.
#
# 			A virtual column takes no storage
#
# 			InnoDB supports secondary indexes on virtual columns.
#
# 			See SECTION 13.1.20.9, "SECONDARY INDEXES AND GENERATED COLUMNS"
#
# 		) STORED: Column values are evaluated and stored when rows are inserted or updated.
#
# 			A stored column does require storage space and can be indexed.
#
# The default is VIRTUAL if neither keyword is specified.
#
# It is permitted to mix VIRTUAL and STORED columns within a table.
#
# Other attributes may be given to indicate whether the column is indexed or can be
# NULL or provide a comment.
#
# Genrated column expressions must adhere to hte following rules.
#
# An error occurs if an expression contains disallowed constructs.
#
# 		) Literals, determinsitic built-in functions, and operators are permitted.
#
# 			A function is determinsitic, if given the same data in tables, multiple
# 			invocations produce the same result, independently of the connected user.
#
# 			Examples of functions that fail this definition:
#
# 				CONNECTION_ID(), CURRENT_USER(), NOW()
#
# 		) Subqueries, parameters, variables, stored functions, and user-defined functions are not permitted.
#
# 		) A generated column definition can refer to other generated columns, but only those occurring
# 			earlier in the table definition.
#
# 			A generated column definition can refer to any base (nongenerated) column in the table
# 			whether its definition occurs earlier or later.
#
# 		) The AUTO_INCREMENT attribute cannot be used in a generated column definition
#
# 		) An AUTO_INCREMENT column cannot be used as a base column in a generated column definition
#
# 		) If expression evaluation causes truncation or provides incorrect input to a function,
# 			the CREATE_TABLE statement terminates with an error and the DDL operation is rejected.
#
# If the expression evaluates to a data type that differs from the declared column type,
# Implicit coercion to the declared type occurs according to the usual MySQL type-conversion
# rules.
#
# See SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION"
#
# NOTE:
#
# 		If any component of the expression depends on the SQL mode, different results may
# 		occur for different uses of the table unless the SQL mode is the same during
# 		all uses.
#
# For CREATE_TABLE_---_LIKE, the destination table preserves generated column information from the original table
#
# For CREATE_TABLE_---_SELECT, the destination table does not preserve information about whether columns
# in the selected-from table are generated columns.
#
# The SELECT part of the statement cannot assign values to generated columns in teh destination table
#
# Partitioning by generated columns is permitted. See CREATING PARTITIONED TABLES
#
# A foreign key constraint on a stored generated column cannot use:
#
# 		) ON UPDATE CASCADE
#
# 		) ON DELETE SET NULL
#
# 		) ON UPDATE SET NULL
#
# 		) ON DELETE SET DEFAULT
#
# 		) ON UPDATE SET DEFAULT
#
# A foreign key constraint cannot reference a virtual generated column
#
# For InnoDB restrictions related to foreign keys and generated columns, see SECTION 15.6.1.5, "InnoDB AND FOREIGN KEY CONSTRAINTS"
#
# Triggers cannot use NEW.col_name or use OLD.col_name to refer to generated columns
#
# For INSERT, REPLACE, and UPDATE,, if a generated column is inserted into, replaced, or updated explicitly,
# the only permitted value is DEFAULT
#
# A generated column in a view is considered updatable because it is possible to assign to it
#
# However, if such a column is updated explicitly, the only permitted value is DEFAULT
#
# Generated columns have several use cases, such as these:
#
# 		) Virtual generated columns can be used as a way to simplify and unify queries.
#
# 			A complicated condition can be defined as a generated column and referred 
# 			to from multiple queries on the table to ensure that all of them use exactly
# 			the same condition.
#
# 		) Stored generated columns can be used as a materialized cache for complicated conditions that
# 			are costly to calculate on the fly.
#
# 		) Generated columns can simulate functional indexes; Use a generated column to define a functional
# 			expression and index it.
#
# 			This can be useful for working with columns of types that cannot be indexed directly,
# 			such as JSON columns;
#
# 			See INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX, for a detailed example 
# 
# 			For stored generated columns, the disadvantage of htis approach is that values are stored twice,
# 			once as the value of the generated column and once in the index.
#
# 		) If a generated column is indexed, the optimizer recognizes query expressions that match the column
# 			definition and uses indexes from the column as appropriate during query execution, even if a query
# 			does not refer to the column directly by  name.
#
# 			For details, see SECTION 8.3.11, "OPTIMIZER USE OF GENERATED COLUMN INDEXES"
#
# Example:
#
# 		Suppose that a table t1 contains first_name and last_name columns and that applications
# 		frequently construct the full name using an expression like this:
#
# 			SELECT CONCAT(first_name, ' ',last_name) AS full_name FROM t1;
#
# 		One way to avoid writing out the expression is to create a view v1 on t1, which simplifies
# 		applications by enabling them to select full_name directly without using an expression:
#
# 			CREATE VIEW v1 AS
# 			SELECT *, CONCAT(first_name,' ',last_name) AS full_name FROM t1;
#
# 			SELECT full_name FROM v1;
#
# 		A generated column also enables applications to select full_name directly
# 		without the need to define a view:
#
# 			CREATE TABLE t1 (
# 				first_name VARCHAR(10),
# 				last_name VARCHAR(10),
# 				full_name VARCHAR(255) AS (CONCAT(first_name,' ',last_name))
# 			);
#
# 			SELECT full_name FROM t1;
#
# 13.1.20.9 SECONDARY INDEXES AND GENERATED COLUMNS
#
# InnoDB supports secondary indexes on virtual generated columns.
#
# Other index types are not supported. A secondary index defined on a virtual column
# is sometimes referred to as a "virtual index"
#
# A secondary index may be created on one or more virtual columns or on a combination
# of virtual columns and regular columns or stored generated columns.
#
# Secondary indexes that include virtual columns may be defined as UNIQUE
#
# When a secondary index is created on a virtual generated column, generated column values
# are materialized in the records of the index.
#
# If the index is a covering index (one that includes all the columns retrieved by a query),
# generated column values are retrieved from materialized values in the index structure
# instead of computed "on the fly"
#
# There are additional write costs to consider when using a secondary index on a virtual column
# due to computation performed when materializing virtual column values in secondary
# secondary index records during INSERT and UPDATE operations.
#
# Even with additional write costs, secondary indexes on virtual columns may be preferable
# to generated stored columns, which are materialized in the clustered index, resulting
# in larger tables that require more disk space and memory.
#
# If a secondary index is not defined on a virtual column, there are additional costs for
# reads, as virtual column values must be computed each time the column's row is examined.
#
# Values of an indexed virtual column are MVCC-logged to avoid unnecessary recomputation of
# generated column values during rollback or during a purge operation.
#
# The data length of logged values is limited by the index key limit of 767 bytes for
# COMPACT and REDUNDANT row formats, and 3072 bytes for DYNAMIC and COMPRESSED row formats.
#
# Adding or dropping a secondary index on a virtual column is an in-place operation
#
# INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX
#
# As noted elsewhere, JSON columns cannot be indexed directly
#
# To create an index that references such a column directly, you can define a generated
# column that extracts the information that hsould be indexed, then create an index
# on the generated column, as shown in this example:
#
# 		CREATE TABLE jemp (
# 			c JSON,
# 			g INT GENERATED ALWAYS AS (c->"$.id")),
# 			INDEX i (g)
# 		);
# 		Query OK, 0 rows affected (0.28 sec)
#
# 		INSERT INTO jemp (c) VALUES
# 			('{"id": "1", "name": "Fred"}'), ('{"id": "2", "name": "Wilma"}'),
# 			('{"id": "3", "name": "Barney"}'), ('{"id": "4", "name": "Betty"}');
# 		Query OK, 4 rows affected (0.04 sec)
# 		Records: 4 Duplicates: 0 Warnings: 0
#
# 		SELECT c->>"$.name" AS name
# 			FROM jemp WHERE g > 2;
# 		+-----------+
# 		| name 		|
# 		+-----------+
# 		| Barney 	|
# 		| Betty 	   |
# 		+-----------+
# 		2 rows in set (0.00 sec)
#
# 		EXPLAIN SELECT c->>"$.name" AS name
# 			FROM jemp WHERE g > 2\G
# 		************************ 1. row *******************************
# 						id: 1
# 				select_type: SIMPLE
# 				table  : jemp
# 			partitions: NULL
# 				type   : range
# 		possible_keys: i
# 				key    : i
# 			key_len   : 5
#
# 				ref    : NULL
# 				rows   : 2
# 			filtered  : 100.00
# 			Extra     : Using where
# 	1 row in set, 1 warning (0.00 sec)
#
# SHOW WARNINGS\G
# ************************ 1. row *******************************
# 		Level: Note
# 	Code    : 1003
#  Message : /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`, '$.name'))
# 	AS `name` from `test`.`jemp` where (`test`.`jemp`.`g` > 2)
#  1 row in set (0.00 sec)
#
# (We have wrapped the output from the last statement in this example to fit the viewing area)
#
# When you use EXPLAIN on a SELECT or other SQL statement containing one or more expressions that use
# the -> or ->> operator, these expressions are translated into their equivalents using JSON_EXTRACT()
# and (if needed) JSON_UNQUOTE() instead, as shown here in the output from SHOW_WARNINGS immediately
# following this EXPLAIN statement:
#
# 		EXPLAIN SELECT c->>"$.name"
# 		FROM jemp WHERE g > 2 ORDER BY c->"$.name"\G
# 		*************************** 1. row ***************************
# 					id: 1
# 		select_type: SIMPLE
# 		table      : jemp
# 		partitions : NULL
# 		type       : range
# 		possible_keys: i
# 		key 		  : i
#
# 		key_len    : 5
# 		ref        : NULL
# 		rows       : 2
# 		filtered   : 100.00
# 		Extra      : Using where; Using filesort
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		************************* 1. row *******************************
# 		Level: Note
# 		Code : 1003
# 	  Message: /* select#1 */ select json_unquote(json_extract(`test`.`jemp`.`c`, '$.name'))
# 		AS `c->>"$.name"` from `test`.`jemp` where (`test`.`jemp`.`g` > 2) order by 
# 		json_extract(`test`.`jemp`.`c`,'$.name')
# 		1 row in set (0.00 sec)
#
# See the descriptions of the -> and ->> operators, as well as those of the JSON_EXTRACT() and
# JSON_UNQUOTE() functions, for additional information and examples.
#
# This technique also can be used to provide indexes that indirectly reference columns of other
# types that cannot be indexed directly, such as GEOMETRY columns.
#
# JSON COLUMNS AND INDIRECT INDEXING IN NDB CLUSTER
#
# It is also possible to use indirect indexing of JSON columns in MySQL NDB cluster, subject to the
# following conditions:
#
# 		1. NDB handles a JSON column value internally as a BLOB.
#
# 			This means that any NDB table having one or more JSON columns must have a primary key,
# 			else it cannot be recorded in the binary log.
#
# 		2. The NDB storage engine does not support indexing of virtual columns.
#
# 			Since the default for generated columns is VIRTUAL, you must specify explicitly
# 			the generated column to which to apply the indirect index as STORED.
#
# The CREATE TABLE statement used to create the table jempn shown here is a version of the
# jemp table shown previously, with modifications making it compatible with NDB:
#
# 		CREATE TABLE jempn (
# 			a BIGINT(20) NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 			c JSON DEFAULT NULL,
# 			g INT GENERATED ALWAYS AS (c->"$.name") STORED,
# 			INDEX i (g)
# 		) ENGINE=NDB;
#
# We can populate this table using the following INSERT statement:
#
# 		INSERT INTO jempn (a, c) VALUES
# 			(NULL, '{"id": "1", "name": "Fred"}'),
# 			(NULL, '{"id": "2", "name": "Wilma"}'),
# 			(NULL, '{"id": "3", "name": "Barney"}'),
# 			(NULL, '{"id": "4", "name": "Betty"}');
#
# Now NDB can use index i, as shown here:
#
# 		EXPLAIN SELECT c->>"$.name" AS name
# 			FROM jempn WHERE g > 2\G
# 		******************** 1. row *********************************
# 						id: 1
# 				select_type: SIMPLE
# 					table: jempn
# 			partitions : p0,p1
# 					type : range
# 		possible_keys : i
# 					key  : i
# 				key_len : 5
# 					ref  : NULL
# 				   rows : 3
# 			filtered   : 100.00
# 				Extra   : Using where with pushed condition (`test`.`jempn`.`g` > 2)
# 			1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		*********************** 1. row ****************************
# 		 	Level: Note
# 			Code : 1003
# 		Message : /* select#1 */ select
# 		json_unquote(json_extract(`test`.`jempn`.`c`,'$.name')) AS `name` from
# 		`test`.`jempn` where (`test`.`jempn`.`g` > 2)
# 		1 row in set (0.00 sec)
#
# You should keep in mind that a stored generated column uses DataMemory,
# and that an index on such a column uses IndexMemory
#
# 13.1.20.10 SETTING NDB_TABLE OPTIONS
#
# In MySQL NDB Cluster, the table comment in a CREATE TABLE or ALTER_TABLE statement
# can also be used to specify an NDB_TABLE option, which consists of one or more name-value
# pairs, separated by commas if need be, following the string NDB_TABLE= 
#
# Complete syntax for names and values syntax is shown here:
#
# 		COMMENT="NDB_TABLE=ndb_table_option[,ndb_table_option[,---]]"
#
# 		ndb_table_option:
# 			NOLOGGING={1|0}
# 		 | READ_BACKUP={1|0}
# 		 | PARTITION_BALANCE={FOR_RP_BY_NODE|FOR_RA_BY_NODE|FOR_RP_BY_LDM
# 									|FOR_RA_BY_LDM|FOR_RA_BY_LDM_X_2
# 									|FOR_RA_BY_LDM_X_3|FOR_RA_BY_LDM_X_4}
# 		 | FULLY_REPLICATED={1|0}
#
# Spaces are not permitted within the quoted string. The string is case-insensitive.
#
# The four NDB table options that can be set as part of a comment in this way are described
# in more detail in the next few paragraphs.
#
# NOLOGGING: Using 1 corresponds to having ndb_table_no_logging enabled, but has no actual effect.
#
# Provided as a placeholder, mostly for completeness of ALTER_TABLE statements
#
# READ_BACKUP: Setting this option to 1 has the same effect as though ndb_read_backup were enabled;
# enables reading from any replica.
#
# You can set READ_BACKUP for an existing table online, using an ALTER TABLE statement similar to
# one of those shown here:
#
# 		ALTER TABLE --- ALGORITHM=INPLACE, COMMENT="NDB_TABLE=READ_BACKUP=1";
#
# 		ALTER TABLE --- ALGORITHM=INPLACE, COMMENT="NDB_TABLE=READ_BACKUP=0";
#
# For more information about the ALGORITHM option for ALTER TABLE, see
# SECTION 22.5.14, "ONLINE OPERATIONS WITH ALTER TABLE IN NDB CLUSTER"
#
# PARTITION_BALANCE: Provides additional control over assignment and placement of partitions.
#
# The following four schemes are supported:
#
# 		1. FOR_RP_BY_NODE: One partition per node
#
# 			Only one LDM on each node stores a primary partition. Each partition is stored
# 			in the same LDM (same ID) on all nodes
#
# 		2. FOR_RA_BY_NODE: One partition per node group
#
# 			Each node stores a single partition, which can be either a primary replica
# 			or a backup replica.
#
# 			Each partition is stored in the same LDM on all nodes.
#
# 		3. FOR_RP_BY_LDM: One partition for each LDM on each node; the default
#
# 			This is the same behavior as prior to MySQL NDB Cluster 7.5.2, except for a slightly
# 			different mapping of partitions to LDMs, starting with LDM 0 and placing one
# 			partition per node group, then moving on to the next LDM.
#
# 			This is the setting used if READ_BACKUP is set to 1
#
# 		4. FOR_RA_BY_LDM: One partition per LDM in each node group
#
# 			These partitions can be primary or backup partitions
#
# 		5. FOR_RA_BY_LDM_X_2: Two partitions per LDM in each node group.
#
# 			These partitions can be primary or backup partitions.
#
# 		6. FOR_RA_BY_LDM_X_3: Three partitions per LDM in each node group.
#
# 			These partitions can be primary or backup partitions
#
# 		7. FOR_RA_BY_LDM_X_4: Four partitions per LDM in each node group.
#
# 			These partitions can be primary or backup partitions
#
# PARTITION_BALANCE is the preferred interface for setting the number of partitions per table.
#
# Using MAX_ROWS to force the number of partitions is deprecated but continues to be supported
# for backwards compatibility; it is subject to removal in a future release of MySQL NDB Cluster.
# (Bug #81759, Bug #23544301)
#
# FULLY_REPLICATED controls whether the table is fully replicated, that is, whether each data node
# has a complete code of the table.
#
# To enable full replication of the table, use FULLY_REPLICATED=1
#
# This setting can also be controlled using the ndb_fully_replicated system variable.
#
# Setting it to ON enables the option by default for all new NDB tables;
# the default is OFF.
#
# The ndb_data_node_neighbour system variable is also used for fully replicated tables,
# to ensure that when a fully replicated table is accessed, we access the data node
# which is local to this MySQL server.
#
# An example of a CREATE TABLE statement using such a comment when creating an NDB table
# is shown here:
#
# 		CREATE TABLE t1 (
# 			c1 INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 			c2 VARCHAR(100),
# 			c3 VARCHAR(100) )
# 		ENGINE=NDB
#
# 		COMMENT="NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE";
#
# The comment is displayed as part of the output of SHOW_CREATE_TABLE 
#
# The text of the comment is also available from querying the MySQL Information Schema
# TABLES table, as in this example:
#
# 		SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT
# 		FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME="t1";
# 		+--------------+------------------+-----------------------------------------------------------+
# 		| TABLE_NAME   | TABLE_SCHEMA     | TABLE_COMMENT 															 |
# 		+--------------+------------------+-----------------------------------------------------------+
# 		| t1 			   | c 					 | NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE  |
# 		| t1 			   | d 					 | 																			 |
# 		+--------------+------------------+-----------------------------------------------------------+
# 		2 rows in set (0.00 sec)
#
# This comment syntax is also supported with ALTER_TABLE statements for NDB tables.
#
# Keep in mind that a table comment used with ALTER TABLE replaces any existing comment which
# the table might have.
#
# 		ALTER TABLE t1 COMMENT="NDB_TABLE=PARTTION_BALANCE=FOR_RA_BY_NODE";
# 		Query OK, 0 rows affected (0.40 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
# 		SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT
# 		FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME="t1";
# 		+--------------+-------------------------+------------------------------------------------------+
# 		| TABLE_NAME   | TABLE_SCHEMA 			  | TABLE_COMMENT 													|
# 		+--------------+-------------------------+------------------------------------------------------+
# 		| t1 				| c 							  | NDB_TABLE=PARTITION_BALANCE=FOR_RA_BY_NODE 			   |
# 		| t1 				| d 							  | 																		|
# 		+--------------+-------------------------+------------------------------------------------------+
# 		2 rows in set (0.01 sec)
#
# You can also see the value of the PARTITION_BALANCE option in the output of ndb_desc.ndb_desc also
# shows whether the READ_BACKUP and FULLY_REPLICATED options are set for the table.
#
# See the description of this program for more information.
#
# Because the READ_BACKUP value was not carried over to the new comment set by the ALTER TABLE statement,
# there is no longer a way using SQL to retrieve the value previously set for it.
#
# To keep this from happening, it is suggested that you preserve any such values from the existing comment
# string, like this:
#
# 		SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT
# 		FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME="t1";
# 		+---------------+-----------------------+----------------------------------------------------------+
# 		| TABLE_NAME 	 | TABLE_SCHEMA 			 | TABLE_COMMENT 														   |
# 		+---------------+-----------------------+----------------------------------------------------------+
# 		| t1 				 | c 							 | NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RP_BY_NODE |
# 		| t1 				 | d 							 | 																			|
# 		+---------------+-----------------------+----------------------------------------------------------+
# 		2 rows in set (0.00 sec)
#
# 		ALTER TABLE t1 COMMENT="NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RA_BY_NODE";
# 		Query OK, 0 rows affected (1.56 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
# 		SELECT TABLE_NAME, TABLE_SCHEMA, TABLE_COMMENT
# 		FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_NAME="t1";
# 		+----------------+---------------------------+----------------------------------------------------------+
# 		| TABLE_NAME 	  | TABLE_SCHEMA 					| TABLE_COMMENT 														  |
# 		+----------------+---------------------------+----------------------------------------------------------+
# 		| t1 				  | c 								| NDB_TABLE=READ_BACKUP=0,PARTITION_BALANCE=FOR_RA_BY_NODE |
# 		| t1 				  | d 								| 																			  |
# 		+----------------+---------------------------+----------------------------------------------------------+
# 		2 rows in set (0.01 sec)
#
# 13.1.21 CREATE TABLESPACE SYNTAX
#
# 		CREATE [UNDO] TABLESPACE tablespace_name
#
# 		InnoDB and NDB:
# 			[ADD DATAFILE 'file_name']
#
# 		InnoDB only:
# 			[FILE_BLOCK_SIZE = value]
# 			[ENCRYPTION [=] {'Y' | 'N'}]
#
# 		NDB only:
# 			USE LOGFILE GROUP logfile_group
# 			[EXTENT_SIZE [=] extent_size]
# 			[INITIAL_SIZE [=] initial_size]
# 			[AUTOEXTEND_SIZE [=] autoextend_size]
# 			[MAX_SIZE [=] max_size]
# 			[NODEGROUP [=] nodegroup_id]
# 			[WAIT]
# 			[COMMENT [=] 'string']
#
# 		InnoDB and NDB:
# 			[ENGINE [=] engine_name]
#
# This statement is used to create a tablespace.
#
# The precise syntax and semantics depend on the storage engine used.
#
# In standard MySQL releases, this is always an InnoDB tablespace.
#
# MySQL NDB Cluster also supports tablespaces using the NDB storage engine.
#
# 		) Considerations for InnoDB
#
# 		) Considerations for NDB Cluster
#
# 		) Options
#
# 		) Notes
#
# 		) InnoDB Examples
#
# 		) NDB Example
#
# CONSIDERATIONS FOR INNODB
#
# CREATE_TABLESPACE syntax is used to create general tablespaces or undo tablespaces.
#
# The UNDO keyword, introduced in MySQL 8.0.14, must be specified to create an undo tablespace.
#
# A general tablespace is a shared tablespace.
#
# It can hold multiple tables, and supports all table row formats.
#
# General tablespaces can be created in a location relative to or independent
# of the data directory.
#
# After creating an InnoDB general tablespace, use CREATE_TABLE_tbl_name_---_TABLESPACE_[=]_tablespace_name
# or ALTER_TABLE_tbl_name_TABLESPACE_[=]_tablespace_name to add tables to the tablespace.
#
# For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# Undo tablespaces contain undo logs.
#
# Undo tablespaces can be created in a chosen location by specifying a fully qualified data file path.
#
# For more information, see SECTION 15.6.3.4, "UNDO TABLESPACES"
#
# CONSIDERATIONS FOR NDB CLUSTER
#
# This statement is used to create a tablespace, which can contain one or more data files, providing
# storage space for NDB Cluster Disk Data tables (see SECTION 22.5.13, "NDB CLUSTER DISK TABLES")
#
# One data file is created and added to the tablespace using this statement.
#
# Additional data files may be added to the tablespace by using the ALTER_TABLESPACE statement
# (see SECTION 13.1.10, "ALTER TABLESPACE SYNTAX")
#
# NOTE:
#
# 		All NDB Cluster Disk Data objects share the same namespace.
#
# 		This means that each Disk Data object must be uniquely named (and not merely each
# 		Disk Data object of a given type)
#
# 		For example, you cannot have a tablespace and a log file group with the same name,
# 		or a tablespace and a data file with the same name.
#
# A log file group of one or more UNDO log files must be assigned to the tablespace to be created
# with the USE LOGFILE GROUP clause.
#
# logfile_group must be an existing log file group created with CREATE_LOGFILE_GROUP
# (see SECTION 13.1.16, "CREATE LOGFILE GROUP SYNTAX")
#
# Multiple tablespaces may use the same log file group for UNDO logging.
#
# When setting EXTENT_SIZE or INITIAL_SIZE, you may optionally follow the number with a 
# one-letter abbreviation for an order of magnitude, similar to those used in my.cnf
#
# Generally, this is one of the letters M (for megabytes) or G (for gigabytes)
#
# INITIAL_SIZE and EXTENT_SIZE qre subject to rounding as follows:
#
# 		) EXTENT_SIZE is rounded up to the nearest whole multiple of 32K
#
# 		) INITIAL_SIZE is rounded down to the nearest whole multiple of 32K; this result is rounded up
# 			to the nearest whole multiple of EXTENT_SIZE (after any rounding)
#
# The rounding just described is done explicitly, and a warning is issued by the MySQL Server
# when any such rounding is performed.
#
# The rounded values are also used by the NDB kernel for calculating INFORMATION_SCHEMA.FILES
# column values and other purposes.
#
# However, to avoid an unexpected result, we suggest that you always use whole multiples of
# 32K in specifying these options.
#
# When CREATE_TABLESPACE is used with ENGINE [=] NDB, a tablespace and associated data file
# are created on each Cluster data node.
#
# You can verify the data files were created and obtain information about them by querying
# the INFORMATION_SCHEMA.FILES table
#
# (See the example later in this section)
#
# (See SECTION 25.10, "THE INFORMATION_SCHEMA FILES TABLE")
#
# OPTIONS
#
# 		) ADD DATAFILE:
#
# 			Defines the name of a tablespace data file.
#
# 			The ADD DATAFILE clause is required when creating undo tablespaces.
# 			Otherwise, it is optional as of MySQL 8.0.14
#
# 			An InnoDB tablespace supports only a single data file, whose name must include
# 			a .ibd extension
#
# 			An NDB Cluster tablespace supports multiple data files which can have any
# 			legal file names; More data files can be added to an NDB Cluster tablespace
# 			following its creation by using an ALTER_TABLESPACE statement.
#
# 			To place a general tablespace data file in a location outside of the data directory,
# 			include a fully qualified path or a path relative to the data directory.
#
# 			Only a fully qualified path is permitted for undo tablespaces.
#
# 			If you do not specify a path, a general tablespace is created in the
# 			data directory.
#
# 			An undo tablespace created without specifying a path is created in the directory
# 			defined by the innodb_undo_directory variable.
#
# 			If the innodb_undo_directory variable is undefined, undo tablespaces are created
# 			in the data directory.
#
# 			Creating a general tablespace in a subdirectory under the data directory is not supported
# 			to avoid conflict with implicitly created file-per-table tablespaces.
#
# 			When creating a general tablespace or undo tablespace outside of the data directory,
# 			the directory must exist and must be known to InnoDB prior to creating the tablespace.
#
# 			To make a directory known to InnoDB, add it to the innodb_directories value or to one
# 			of the variables whose values are appended to the innodb_directories value.
#
# 			innodb_directories is a read-only variable. Configuring it requires restarting the server.
#
# 			The file_name, including any specified path, must be quoted with single or double quotation marks.
#
# 			File names (not counting the file extensions) and directory names must be at least one byte
# 			in length.
#
# 			Zero length file names and dir names are not supported.
#
# 			If the ADD DATAFILE clause is not specified when creating a tablespace, a tablespace data file
# 			with a unique file name is created implicitly.
#
# 			The unique file name is a 128 bit UUID formatted into five groups of hexadecimal numbers
# 			separated by dashes (aaaaaaaa-bbbb-cccc-dddd-eeeeeeee)
#
# 			A file extension is added if required by the storage engine.
#
# 			An .ibd file extension is added for InnoDB general tablespace data files.
#
# 			In a replication environment, the data file name created on the master is not the same
# 			as the data file name created on the slave.
#
# 		) FILE_BLOCK_SIZE:
#
# 			This option - which is specific to InnoDB general tablespaces, and is ignored by NDB -
# 			defines the block size for the tablespace data file.
#
# 			Values can be specified in bytes or kilobytes.
#
# 			For example, an 8 kilobyte file block size can be specified as 8192 or 8K
#
# 			If you do not specify this option, FILE_BLOCK_SIZE defaults to the innodb_page_Size
# 			value.
#
# 			FILE_BLOCK_SIZE is required when you intend to use the tablespace for storing
# 			compressed InnoDB tables (ROW_FORMAT=COMPRESSED)
#
# 			In this case, you must define the tablespace FILE_BLOCK_SIZE when creating the tablespace.
#
#			If FILE_BLOCK_SIZE is equal to the innodb_page_size value, the tablespace can contain only
# 			tables having an uncompressed row format (COMPACT, REDUNDANT and DYNAMIC)
#
# 			Tables with a COMPRESSED row format have a different physical page size than uncompressed tables.
#
# 			Therefore, compressed tables cannot coexist in the same tablespace as uncompressed tables.
#
# 			For a general tablespace to contain compressed tables, FILE_BLOCK_SIZE must be specified,
# 			and the FILE_BLOCK_SIZE value must be a valid compressed page size in relation to the
# 			innodb_page_size value.
#
# 			Also, the physical page size of the compressed table (KEY_BLOCK_SIZE) must be equal
# 			to FILE_BLOCK_SIZE/1024
#
# 			For example, if innodb_page_size=16K, and FILE_BLOCK_SIZE=8K, the KEY_BLOCK_SIZE
# 			of the table must be 8.
#
# 			For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# 		) USE LOGFILE GROUP:
#
# 			Required for NDB, this is the name of a log file group previously created using
# 			CREATE_LOGFILE_GROUP
#
# 			Not supported for InnoDB, where it fails with an error.
#
# 		) EXTENT_SIZE:
#
# 			This option is specific to NDB, and is not supported by InnoDB, where it fails
# 			with an error.
#
# 			EXTENT_SIZE sets the size, in bytes, of the extents used by any files belonging
# 			to the tablespace.
#
# 			The default value is 1M. The minimum size is 32K, and theoretical maximum is
# 			2G, although the practical maximum size depends on a number of factors.
#
# 			In most cases, changing the extent size does not have any measurable effect
# 			on performance, and the default value is recommended for all but the most unusual situations.
#
# 			An extent is a unit of disk space allocation.
#
# 			One extent is filled with as much data as that extent can contain before another extent is used.
#
# 			In theory, up to 65,535 (64K) extents may be used per data file; however, the recommended
# 			maximum is 32,768 (32K)
#
# 			The recommended maximum size for a single data file is 32G - that is, 32K
# 			extents x 1 MB per extent.
#
# 			In addition, once an extent is allocated to a given partition, it cannot be used to store
# 			data from a different partition; an extent cannot store data from more than one partition.
#
# 			This means, for example that a tablespace having a single datafile whose INITIAL_SIZE
# 			(described in the following item) is 256 MB and whose EXTENT_SIZE is 128M has just two extents,
# 			and so can be used to store data from at most two different disk data table partitions.
#
# 			You can see how many extents remain free in a given data file by querying the INFORMATION_SCHEMA.FILES
# 			table, and so derive an estimate for how much space remains free in the file.
#
# 			For further discussion and examples, see SECTION 25.10, "THE INFORMATION_SCHEMA FILES TABLE"
#
# 		) INITIAL_SIZE:
#
# 			This option is specific to NDB, and is not supported by InnoDB, where it fails with an error.
#
# 			The INITIAL_SIZE parameter sets the total size in bytes of the data file that was specific
# 			using ADD DATAFILE.
#
# 			Once this file has been created, its size cannot be changed;
#
# 			However, you can add more data files to the tablespace using ALTER_TABLESPACE_---_ADD_DATAFILE
#
# 			INITIAL_SIZE is optional; its default value is 128MB (134217728)
#
# 			On 32-bit systems, the maximum supported value for INITIAL_SIZE is 4GB (4294967296)
#
# 		) AUTOEXTEND_SIZE:
#
# 			Currently ignored by MySQL; reserved for possible future use.
#
# 			Has no effect in any release of MySQL 8.0 or MySQL NDB Cluster 8.0, regardless
# 			of the storage engine used.
#
# 		) MAX_SIZE:
#
# 			Currently ignored by MySQL;
#
# 			reserved for possible future use. Has no effect in any release of MySQL 8.0 or
# 			MySQL NDB Cluster 8.0, regardless of the storage engine used.
#
# 		) NODEGROUP:
#
# 			Currently ignored by MySQL
#
# 			reserved for possible future use. has no effect in any release of MysQL 8.0 or
# 			MySQL NDB CLuster 8.0, regardless of the storage engine used
#
# 		) WAIT:
#
# 			Currently ignored by MySQL;
#
# 			reserved for possible future use. Has no effect in any release of MySQL 8.0 or
# 			MySQL NDB Cluster 8.0, regardless of the storage engine used.
#
# 		) COMMENT:
#
# 			Currently ignored by MySQL;
#
# 			reserved for possible future use.
#
# 			Has no effect in any release of MySQL 8.0 or MySQL NDB Cluster 8.0, regardless
# 			of the storage engine used.
#
# 		) The ENCRYPTION option is used to enable or disable page-level data encryption for an
# 			InnoDB general tablespace.
#
# 			Option values are not case-sensitive.
#
# 			Encryption support for general tablespaces was introduced in MySQL 8.0.13
#
# 			A keyring plugin must be installed and configured to use the ENCRYPTION option.
#
# 			When a general tablespace is encrypted, all tables residing in the tablespace is
# 			encrypted.
#
# 			For more information, see SECTION 15.6.3.9, "TABLESPACE ENCRYPTION"
#
# 		) ENGINE:
#
# 			Defines the storage engine which uses the tablespace, where engine_name
# 			is the name of the storage engine.
#
# 			Currently, only the InnoDB storage engine is supported by standard MySQL
# 			8.0 releases
#
# 			MySQL NDB Cluster supports both NDB and InnoDB tablespaces.
#
# 			The value of the default_storage_engine system variable is used
# 			for ENGINE if the option is not specified.
#
# NOTES
#
# 		) For the rules covering the naming of MySQL tablespaces, see SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# 		In addition to these rules, the slash character ("/") is not permitted, nor can
# 		you use names beginning with innodb_, as this prefix is reserved for system use.
#
# 		) Creation of temporary general tablespace is not supported
#
# 		) General tablespaces do not support temporary tables
#
# 		) The TABLESPACE option may be used with CREATE_TABLE or ALTER_TABLE to assign
# 			an InnoDB table partition or subpartition to a file-per-table tablespace.
#
# 			All partitions must belong to the same storage engine.
#
# 			Assigning table partitions to shared InnoDB tablespaces is not supported.
#
# 			Shared tablespaces include the InnoDB system tablesapce and general tablespaces.
#
# 		) General tablespaces support the addition of tables of any row format using CREATE_TABLE_---_TABLESPACE,
# 			innodb_file_per_table does not need to be enabled.
#
# 		) innodb_strict_mode is not applicable to general tablespaces.
#
# 			Tablespace management rules are strictly enforced indepdently of
# 			innodb_strict_mode
#
# 			If CREATE TABLESPACE parameters are incorrect or incompatible,
# 			the operation fails regardless of the innodb_strict_mode setting.
#
# 			When a table is added to a general tablespace using CREATE_TABLE_---_TABLESPACE
# 			or ALTER_TABLE_---_TABLESPACE then innodb_strict_mode is ignored but the
# 			statement is evaluated as if innodb_strict_mode is enabled.
#
# 		) Use DROP TABLESPACE to remove a tablespace.
#
# 			ALl tables must be dropped from a tablespace using DROP_TABLE prior to
# 			dropping the tablespace.
#
# 			Before dropping an NDB Cluster tablespace you must also remove all
# 			its data files using one or more ALTER_TABLESPACE_---_DROP_DATAFILE
# 			statements.
#
# 			See SECTION 22.5.13.1, "NDB CLUSTER DISK DATA OBJECTS"
#
# 		) ALl parts of an InnoDB table added to an InnoDB general tablespace reside
# 			in the general tablespace, including indexes and BLOB pages.
#
# 			For an NDB table assigned to a tablespace, only those columns which are not indexed
# 			are stored on disk, and actually use the tablespace data files.
#
# 			Indexes and indexed columns for all NDB tables are always kept in memory.
#
# 		) Similar to the system tablespace, truncating or dropping tables stored in a general
# 			tablespace creates free space internally in the general tablespace
# 			.ibd data file which can only be used for new InnoDB data.
#
# 			Space is not released back to the operating system as it is for
# 			file-per-table tablespaces.
#
# 		) A general tablespace is not associated with any database or schema.
#
# 		) ALTER_TABLE_---_DISCARD_TABLESPACE and ALTER_TABLE_---_IMPORT_TABLESPACE
# 			are not supported for tables that belong to a general tablespace.
#
# 		) The several uses tablespace-level metadata locking for DDL that references
# 			general tablespaces.
#
# 			By comparison, the server uses table-level metadata locking for DDL
# 			that references file-per-table tablespaces.
#
# 		) A generated or existing tablespace cannot be changed to a general tablespace
#
# 		) There is no conflict between general tablespace names and file-per-table tablespace
# 			names.
#
# 			The "/" character, which is present in file-per-table tablespace names,
# 			is not permitted in general tablespace names.
#
# 		) mysqldump and mysqlpump do not dump InnoDB CREATE_TABLESPACE statements
#
# INNODB EXAMPLES
#
# This example demonstrates creating a general tablespace and adding three uncompressed
# tables of different row formats.
#
# 		CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' ENGINE=INNODB;
#
# 		CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=REDUNDANT;
#
# 		CREATE TABLE t2 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=COMAPCT;
#
# 		CREATE TABLE t3 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=DYNAMIC;
#
# This example demonstrates creating a general tablespace and adding a compressed table.
#
# The example assumes a default innodb_page_size value of 16K
#
# The FILE_BLOCK_SIZE of 8192 requires that the compressed table have a KEY_BLOCK_SIZE
# of 8.
#
# 		CREATE TABLESPACE `ts2` ADD DATAFILE 'ts2.ibd' FILE_BLOCK_SIZE = 8192 Engine=InnoDB;
#
# 		CREATE TABLE t4 (c1 INT PRIMARY KEY) TABLESPACE ts2 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;
#
# This example demonstrates creating a general tablespace without specifying the ADD DATAFILE
# clause, which is optional as of MySQL 8.0.14
#
# 		CREATE TABLESPACE `ts3` ENGINE=INNODB;
#
# This example demonstrates creating an undo tablespace.
#
# 		CREATE UNDO TABLESPACE undo_003 ADD DATAFILE 'undo_003.ibu';
#
# NDB EXAMPLE
#
# Suppose that you wish to create an NDB Cluster Disk Data tablespace named
# myts using a datafile named mydata-1.dat 
#
# An NDB tablespace always requires the use of a log file group consisting
# of one or more undo log files.
#
# For htis example, we first create a log file group named mylg that contains
# one undo long file named myundo-1.dat, using the CREATE_LOGFILE_GROUP statement
# shown here:
#
# 		CREATE LOGFILE GROUP myg1
# 			ADD UNDOFILE 'myundo-1.dat'
# 			ENGINE=NDB;
# 		Query OK, 0 rows affected (3.29 sec)
#
# Now you can create the tablespace previously described using the following statement:
#
# 		CREATE TABLESPACE myts
# 			ADD DATAFILE 'mydata-1.dat'
# 			USE LOGFILE GROUP mylg
# 			ENGINE=NDB;
# 		Query OK, 0 rows affected (2.98 sec)
#
# You can now create a Disk Data table using a CREATE_TABLE statement with the
# TABLESPACE and STORAGE DISK options, similar to what is shown here:
#
# 		CREATE TABLE mytable (
# 			id INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 			lname VARCHAR(50) NOT NULL,
# 			fname VARCHAR(50) NOT NULL,
# 			dob DATE NOT NULL,
# 			joined DATE NOT NULL,
# 			INDEX(last_name, first_name)
# 		)
# 			TABLESPACE myts STORAGE DISK
# 			ENGINE=NDB;
# 		Query OK, 0 rows affected (1.41 sec)
#
# It is important to note that only the dob and joined columns from mytable are actually
# stored on disk, due to the fact that the id, lname, and fname columns are all indexed.
#
# As mentioned previously, when CREATE TABLESPACE is used with ENGINE [=] NDB, a tablespace
# and associated data file are created on each NDB Cluster data node.
#
# You can verify that the data files were created and obtain all information about them
# by querying the INFORMATION_SCHEMA.FILES table, as shown here:
#
# 		SELECT FILE_NAME, FILE_TYPE, LOGFILE_GROUP_NAME, STATUS, EXTRA
# 			FROM INFORMATION_SCHEMA.FILES
# 			WHERE TABLESPACE_NAME = 'myts';
#  	
# 		+----------------------+-----------------+---------------------------------+--------------+--------------------+
# 		| file_name 			  | file_type 		  | logfile_group_name 					| status 		| extra 					|
# 		+----------------------+-----------------+---------------------------------+--------------+--------------------+
# 		| mydata-1.dat 		  | DATAFILE 		  | mylg 									| NORMAL 		| CLUSTER_NODE=5 	   |
# 		| mydata-1.dat 		  | DATAFILE 		  | mylg 									| NORMAL 		| CLUSTER_NODE=6 	   |
# 		| NULL 					  | TABLESPACE 	  | mylg  									| NORMAL 		| NULL 					|
# 		+----------------------+-----------------+---------------------------------+--------------+--------------------+
# 		3 rows in set (0.01 sec)
#
# For additional information and examples, see SECTION 22.5.13.1, "NDB CLUSTER DISK DATA OBJECTS"
#
# 13.1.22 CREATE TRIGGER SYNTAX
#
# 		CREATE
# 			[DEFINER = { user | CURRENT_USER }]
# 			TRIGGER trigger_name
# 			trigger_name trigger_event
# 			ON tbl_name FOR EACH ROW
# 			[trigger_order]
# 			trigger_body
#
# 		trigger_time: { BEFORE | AFTER }
#
# 		trigger_event: { INSERT | UPDATE | DELETE }
#
# 		trigger_order: { FOLLOWS | PRECEDES } other_trigger_name
#
# This statement creates a new trigger.
#
# A trigger is a named database object that is associated with a table, and that activates
# when a particular event occurs for the table.
#
# The trigger becomes associated with the table named tbl_name, which must refer to a permanent
# table.
#
# You cannot associate a trigger with a TEMPORARY table or a view.
#
# Trigger names exist in the schema namespace, meaning that all triggers must have unique names
# within a schema.
#
# Triggers in different schemas can have the same name.
#
# This section describes CREATE_TRIGGER syntax. For additional discussion, see SECTION 24.3.1, "TRIGGER SYNTAX AND EXAMPLES"
#
# CREATE_TRIGGER requires the TRIGGER privilege for the table associated with the trigger.
#
# The statement might also require the SET_USER_ID or SUPER privilege, depending on
# the DEFINER value, as described later in this section.
#
# If binary logging is enabled, CREATE_TRIGGER might require the SUPER privilege,
# as described in SECTION 24.7, "BINARY LOGGING OF STORED PROGRAMS"
#
# The DEFINER clause determines the security context to be used when checking access
# privileges at trigger activation time, as described later in this section.
#
# trigger_time is the trigger action time.
#
# It can be BEFORE or AFTER to indicate that the trigger activates before or after
# each row to be modified.
#
# Basic column value checks occur prior to trigger activation, so you cannot use BEFORE
# triggers to convert values inappropriate for the column type to valid values.
#
# trigger_event indicates the kind of operation that activates the trigger.
#
# These trigger_event values are permitted:
#
# 		) INSERT: The trigger activates whenever a new row is inserted into the table;
# 			for example, through INSERT, LOAD_DATA and REPLACE statements.
#
# 		) UPDATE: The trigger activates whenever a row is modified; for example, through UPDATE statements.
#
# 		) DELETE: The trigger activates whenever a row is deleted from the table;
#
# 		For example, through DELETE and REPLACE statements. DROP_TABLE and TRUNCATE_TABLE
# 		statements on the table do not activate this trigger, because they do not use DELETE.
#
# 		Dropping a partition does not activate DELETE triggers, either.
#
# The trigger_event does not represent a literal type of SQL statement that activates the trigger so much
# as it represents a type of table operation.
#
# For example, an INSERT trigger activates not only for INSERT statements but also LOAD_DATA statements
# because both statements insert rows into a table.
#
# A potentially confusing example of this is the INSERT INTO --- ON DUPLICATE KEY UPDATE --- syntax:
#
# 		a BEFORE INSERT trigger activates for every row, followed by either an
# 		AFTER INSERT trigger or both the BEFORE UPDATE and AFTER UPDATE triggers,
# 		depending on whether there was a duplicate key for the row.
#
# NOTE:
#
# 		Cascaded foreign key actions do not activate triggers
#
# It is possible to define multiple triggers for a given table that have the same trigger
# event and action time.
#
# For example, you can have two BEFORE UPDATE triggers for a table.
#
# By default, triggers that have the same trigger event and action name activate
# in the order htey were created.
#
# To affect trigger order, specify a trigger_order clause that indicates FOLLOWS
# or PRECEDES and the name of an existing trigger that also has the same trigger
# event and action time.
#
# With FOLLOWS, the new trigger activates after the existing trigger.
#
# With PRECEDES, the new trigger activates before the existing trigger.
#
# trigger_body is the statement to execute when the trigger activates.
#
# To execute multiple statements, use the BEGIN_---_END compound statement
# construct.
#
# This also enables you to use the same statements that are permitted within stored
# routines.
#
# See SECTION 13.6.1, "BEGIN_---_END COMPOUND-STATEMENT SYNTAX"
#
# Some statements are not permitted in triggers, see SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# Within the trigger body, you can refer to columns in the subject table (the table associated
# with the trigger) by using the aliases OLD and NEW.
#
# OLD.col_name refers to a column of an existing row before it updated or deleted
#
# NEW.col_name refers to teh column of a new row to be inserted or an existing row after
# it is updated.
#
# Triggers cannot use NEW.col_name or use OLD.col_name to refer to generated columns.
#
# FOr information about generated columns, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
#
# MySQL stores the sql_mode system variable setting in effect ´when a trigger is created, and always
# executes the trigger body with this setting in force, regardless of the current server SQL
# mode when the trigger begins executing.
#
# The DEFINER clause specifies the MySQL account to be used when checking access privileges
# at trigger activation time.
#
# If a user value is given, it should be a MySQL account specified as 'user_name'@'host_name',
# CURRENT_USER or CURRENT_USER()
#
# The default DEFINER value is the user who executes the CREATE_TRIGGER statement.
#
# THis is the same as specifying DEFINER = CURRENT_USER explicitly.
#
# If you specify the DEFINER clause, these rules determine the valid DEFINER user values:
#
# 		) If you do not have the SET_USER_ID or SUPER privilege, the only permitted user value
# 			is your own account, either specified literally or by using CURRENT_USER 
#
# 		You cannot set the definer to some other account
#
# 		) If you have the SET_USER_ID or SUPER privilege, you can specify any syntactically
# 			valid account name.
#
# 			If the account does not exist, a warning is generated.
#
# 		) Although it is possible to create a trigger with a nonexistent DEFINER account,
# 			it is not a good idea for such triggers to be activated until the account
# 			actually does exist.
#
# 			Otherwise, the behavior with respect to privilege checking is undefined.
#
# MySQL takes the DEFINER user into account when checking trigger privileges as follows:
#
# 		) At CREATE_TRIGGER time, the user who issues the statement must have the TRIGGER privilege
#
# 		) At trigger activation time, privileges are checked against the DEFINER user.
#
# 			This user must have these privileges:
#
# 				) The TRIGGER privilege for the subject table
#
# 				) The SELECT privilege for the subject table if references to table columns occur
# 				using OLD.col_name or NEW.col_name in the trigger body.
#	
# 				) The UPDATE privilege for the subject table if table columns are targets of
# 				SET NEW.col_name = value assignments in the trigger body.
#
# 				) Whatever other privileges normally are required for the statements executed by the trigger.
#
# For more information about trigger security, see SECTION 24.6, "ACCESS CONTROL FOR STORED PROGRAMS AND VIEWS"
#
# Within a trigger body, the CURRENT_USER() function returns the account used to check privileges
# at trigger activation time.
#
# This is the DEFINER user, not the user whose actions caused the trigger to be activated.
#
# For information about user auditing within triggers, see SECTION 6.3.13,
# "SQL-BASED MYSQL ACCOUNT ACTIVITY AUDITING"
#
# If you use LOCK_TABLES to lock a table that has triggers, the tables used within the trigger
# are also locked, as described in LOCK TABLES AND TRIGGERS
#
# For additional discussions of trigger use, see SECTION 24.3.1, "TRIGGER SYNTAX AND EXAMPLES"
#
# 13.1.23 CREATE VIEW SYNTAX
#
# CREATE
# 		[OR REPLACE]
# 		[ALGORITHM = {UNDEFINED | MERGE | TEMPTABLE}]
# 		[DEFINER = { user | CURRENT_USER }]
# 		[SQL SECURITY { DEFINER | INVOKER }]
# 		VIEW view_name [(column_list)]
# 		AS select_statement
# 		[WITH [CASCADED | LOCAL] CHECK OPTION]
#
# The CREATE_VIEW statement creates a new view, or replaces an existing view if hte
# OR REPLACE clause is given.
#
# If the view does not exist, CREATE_OR_REPLACE_VIEW is the same as CREATE_VIEW
# 
# If the view does exist, CREATE_OR_REPLACE_VIEW replaces it
#
# For information about restrictions on view use, see SECTION C.5, "RESTRICTIONS ON VIEWS"
#
# The select_statement is a SELECT statement that provides the definition of the view.
#
# (Selecting from the view selects, in effect, using the SELECT statement)
#
# The select_statement can select from base tables or other views.
#
# The view definition is "frozen" at creation time and is not affected by subsequent changes
# to the definitions of the underlying tables.
#
# For example, if a view is defined as SELECT * on a table, new columns added to the table
# later do not become part of the view, and columns dropped from the table will result in
# an error when selecting from teh view.
#
# the ALGORITHM clause affects how MySQL processes the view.
#
# The DEFINER and SQL SECURITY clauses specify the security context to be used when
# checking access privileges at view invocation time.
#
# The WITH CHECK OPTION clause can be given to constrain inserts or updates to rows
# in tables referenced by the view.
#
# These clauses are described later in this section.
#
# The CREATE_VIEW statement requires the CREATE_VIEW privilege for the view, and some
# privilege for each column selected by the SELECT statement.
#
# For columns used elsewhere in the SELECT statement, you must have the SELECT privilege.
#
# If the OR REPLACE clause is present, you must also have the DROP privilege for the view.
#
# CREATE VIEW might also require the SET_USER_ID or SUPER privilege, depending on the DEFINER
# value, as described later in this section.
#
# WHen a view is referenced, privilege checking occurs as described later in this section
#
# A view belongs to a database.
#
# By default, a new view is created in the default database. To create the view explicitly
# in a given database, use db_name.view_name syntax to qualify the view name with the
# database name:
#
# 		CREATE VIEW test.v AS SELECT * FROM t;
#
# Unqualified table or view names in the SELECT statement are also interpreted with respect
# to the default database.
#
# A view can refer to tables or views in other databases by qualifying the table or view
# name with the appropriate database name.
#
# Within a database, base tables and views share the same namespace, so a base table and
# a view cannot have the same name.
#
# Columns retrieved by the SELECT statement can be simple references to table columns,
# or expressions that use functions, constant values, operators, and so forth.
#
# A view must have unique columns names with no duplicates, just like a base table.
#
# By default, the names of the columns retrieved by the SELECT statement are used for
# the view column names.
#
# To define explicit names for the view columns, specify the optional column_list
# clause as a list of comma-separated identifiers.
#
# The number of names in column_list must be the same as the number of columns
# retrieved by the SELECT statement.
#
# A view can be created from many kinds of SELECT statements.
#
# It can refer to base tables or other views. It can use joins, UNION and subqueries.
#
# The SELECT need not even refer to any tables:
#
# 		CREATE VIEW v_today (today) AS SELECT CURRENT_DATE;
#
# The following example defines a view that selects two columns from another table as well
# as an expression calculated from those columns:
#
# 		CREATE TABLE t (qty INT, price INT);
# 		INSERT INTO t VALUES(3, 50);
# 		CREATE VIEW v AS SELECT qty, price, qty*price AS value FROM t;
# 		SELECT * FROM v;
# 		+-------+----------+----------+
# 		| qty   | price 	 | value 	|
# 		+-------+----------+----------+
# 		| 3 	  | 50 		 | 150 		|
# 		+-------+----------+----------+
#
# A view definition is subject to the following restrictions:
#
# 		) The SELECT statement cannot refer to system variables or user-defined variables
#
# 		) Within a stored program, the SELECT statement cannot refer to program parameters
# 			or local variables.
#
# 		) The SELECT statement cannot refer to prepared statemnt parameters.
#
# 		) Any table or view referred to in the definition must exist.
#
# 			If, after the view has been created, a table or view that the definition
# 			refers to is dropped, use of the view results in an error.
#
# 			To check a view definition for problems of this kind, use the CHECK_TABLE statement.
#
# 		) The definition cannot refer to a TEMPORARY table, and you cannot create a TEMPORARY view.
#
# 		) You cannot associate a trigger with a view
#
# 		) Aliases for column names in the SELECT statement are checked against the maximum column
# 			length of 64 characters (not the maximum alias length of 256 characters)
#
# ORDER BY is permitted in a view definition, but it is ignored if you select from a view using
# a statement that has its own ORDER BY.
#
# For other options or clauses in the definition, they are added to the options or clauses
# of the statement that references the view, but the effect is undefined.
#
# For example, if a view definition includes a LIMIT clause, and you select from the view
# using a statement that has its own LIMIT clause, it is undefined which limit applies.
#
# This same principle applies to options such as ALL, DISTINCT, or SQL_SMALL_RESULT that follow
# the SELECT keyword, and to clauses such as INTO, FOR UPDATE, FOR SHARE, LOCK IN SHARE MODE,
# and PROCEDURE.
#
# The results obtained from a view may be affected if you change the query processing
# environment by changing system variables:
#
# 		CREATE VIEW v (mycol) AS SELECT 'abc';
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		SET sql_mode = '';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT "mycol" FROM v;
# 		+----------+
# 		| mycol    |
# 		+----------+
# 		| mycol    |
# 		+----------+
# 		1 row in set (0.01 sec)
#
# 		SET sql_mode = 'ANSI_QUOTES';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT "mycol" FROM v;
# 		+----------+
# 		| mycol    |
# 		+----------+
# 		| abc 	  |
# 		+----------+
# 		1 row in set (0.00 sec)
#
# The DEFINER and SQL SECURITY clauses determine which MySQL account to use when
# checking access privileges for the view when a statement is executed that 
# references the view.
#
# The valid SQL SECURITY characteristic values are DEFINER (the default) and INVOKER.
#
# These indicate that the required privileges must be held by the user who defined
# or invoked the view, respectively.
#
# If a user value is given for the DEFINER claus, it should be a MySQL account specified
# as 'user_name'@'host_name', CURRENT_USER or CURRENT_USER() 
#
# The default DEFINER value is the user who executes the CREATE_VIEW statement.
#
# This is the same as specifying DEFINER = CURRENT_USER explicitly.
#
# If the DEFINER clause is present, these rules determine the valid DEFINER user values:
#
# 		) If you do not have the SET_USER_ID or SUPER privilege, the only valid user value is
# 			your own account, either specified literally or by using CURRENT_USER
#
# 			You cannot set the definer to some other account
#
# 		) If you have the SET_USER_ID or SUPER privilege, you can specify any syntactically
# 			valid account name.
#
# 			If the account does not exist, a warning is generated.
#
# 		) Although it is possible to create a view with a nonexistent DEFINER account,
# 			an error occurs when the view is referenced if the SQL SECURITY value is
# 			DEFINER but the definer account does not exist.
#
# For more information about view security, see SECTION 24.6, "ACCESS CONTROL FOR STORED PROGRAMS AND VIEWS"
#
# Within a view definition, CURRENT_USER returns the view's DEFINER value by default.
#
# For views defined with the SQL SECURITY INVOKER characteristic, CURRENT_USER returns
# the account for the view's invoker.
#
# For information about user auditing within views, see SECTION 6.3.13, "SQL-BASED MYSQL
# ACCOUNT ACTIVITY AUDITING"
#
# Within a stored routine that is defined with the SQL SECURITY DEFINER characteristic,
# CURRENT_USER returns the routine's DEFINER value.
#
# THis also affects a view defined within such a routine, if hte view definition 
# contains a DEFINER value of CURRENT_USER
#
# MySQL checks view privileges like this:
#
# 		) At view definition time, the view creator must have the privileges needed to use the
# 			top-level objects accessed by the view.
#
# 			For example, if the view definitions refers to table columns, the creator must have
# 			some privilege for each column in the select list of the definition, and the SELECT
# 			privilege for each column used elsewhere in the definition.
#
# 			If the definition refers to a stored function, only the privileges needed to invoke
# 			the function can be checked.
#
# 			The privileges required at function invocation time  can be checked only as it executes:
#
# 				For different invocations, different execution paths within the function might be taken.
#
# 		) The user who references a view must have appropriate privileges to access it (SELECT to select from it,
# 			INSERT to insert into it and so forth.)
#
# 		) When a view has been referenced, privileges for objects acessed by the view are checked against the
# 			privileges held by the view DEFINER account or invoker, depending on whether the SQL SECURITY
# 			characteristic is DEFINER or INVOKER, respectively.
#
# 		) If reference to a view causes execution of a stored function, privilege checking for statements executed
# 		within the function depend on whether the function SQL SECURITY characteristic is DEFINER or INVOKER.
#
# 		If the security characteristic is DEFINER, the function runs with the privileges of the DEFINER account.
#
# 		If the characteristic is INVOKER, the function runs with the privileges determined by the view's SQL SECURITY
# 		characteristic.
#
# Example: A view might depend on a stored function, and that function might invoke other stored routines.
#
# For example, the following view invokes a stored function f():
#
# 		CREATE VIEW v AS SELECT * FROM t WHERE t.id = f(t.name);
#
# Suppose that f() contains a statement such as this:
#
# 		IF name IS NULL then
# 			CALL p1();
# 		ELSE
# 			CALL p2();
# 		END IF;
#
# The privileges required for executing statements within f() need to be checked when
# f() executes.
#
# This might mean that privileges are needed for p1() or p2(), depending on the execution
# path within f()
#
# Those privileges must be checked at runtime, and the user who must possess the privileges
# is determined by the SQL SECURITY values of the view v and the function f()
#
# The DEFINER and SQL SECURITY clauses for views are extensions to standard SQL.
#
# In standard SQL, views are handled using the rules for SQL SECURITY DEFINER
#
# The standard says that the definer of the view, which is the same as the owner
# of the view's schema, gets applicable privileges on the view (for example, SELECT)
# and may grant them.
#
# MySQL has no concept of a schema "owner", so MySQL adds a clause to identify the definer.
#
# The DEFINER clause is an extension where the intent is to have what the standard
# has; that is, a permanent record of who defined the view.
#
# This is why the default DEFINER value is the account of the view creator.
#
# The optional ALGORITHM clause is a MySQL extension to standard SQL.
#
# It affects how MySQL processes the view. ALGORITHM takes three values:
#
# 		MERGE
#
# 		TEMPTABLE
#
# 		UNDEFINED
#
# For more information, see SECTION 24.5.2, "VIEW PROCESSING ALGORITHMS", as well as
# SECTION 8.2.2.4, "OPTIMIZING DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS
# WITH MERGING OR MATERIALIZATION"
#
# Some views are updatable.
#
# That is, you can use them in statements such as UPDATE, DELETE or INSERT to update
# the contents of the underlying table.
#
# For a view to be updatable, there must be a one-to-one relationship between the rows
# in the view and the rows in the underlying table.
#
# There are also certain other constructs that make a view nonupdatable.
#
# A generated column in a view is considered updatable because it is possible to assign to it.
#
# However, if such a column is updated explicitly, the only permitted value is
# DEFAULT.
#
# For information about generated columns, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
#
# The WITH CHECK OPTION clause can be given for an updatable view to prevent inserts or updates
# to rows except those for which the WHERE clause in the select_statement is true.
#
# In a WITH CHECK OPTION clause for an updatable view, the LOCAL and CASCADED keywords determine
# the scope of check testing when the view is defined in terms of another view.
#
# The LOCAL keyword restricts the CHECK OPTION only to the view being defined.
#
# CASCADED causes the checks for underlying views to be evaluated as well.
#
# When neither keyword is given, the default is CASCADED.
#
# For more information about updatable views and the WITH CHECK OPTION clause, see
# SECTION 24.5.3, "UPDATABLE AND INSERTABLE VIEWS", and SECTION 24.5.4, "THE VIEW WITH CHECK OPTION CLAUSE"
#
# 13.1.24 DROP DATABASE SYNTAX
#
# 		DROP {DATABASE | SCHEMA} [IF EXISTS] db_name
#
# DROP_DATABASE drops all tables in the database and deletes teh database.
#
# Be very careful with this statement. To use DROP_DATABASE, you need the DROP privilege
# on the database.
#
# DROP_SCHEMA is a synonym for DROP_DATABASE
#
# IMPORTANT:
#
# 		When a database is dropped, privileges granted specifically for the database are not automatically dropped.
#
# 		They must be dropped manually. See SECTION 13.7.1.6, "GRANT SYNTAX"
#
# IF EXISTS is used to prevent an error from occurring if the database does not exist.
#
# If the default database is dropped, the default database is unset (the DATABASE() function returns NULL)
#
# If you use DROP_DATABASE on a symbolically linked database, both the link and the original database are deleted.
#
# DROP_DATABASE returns the number of tables that were removed.
#
# The DROP_DATABASE statement removes from the given database directory those files and directories
# that MySQL itself may create during normal operation.
#
# This includes all files with the extensions shown in the following list:
#
# 		) .BAK
#
# 		) .DAT
#
# 		) .HSH
#
# 		) .MRG
#
# 		) .MYD
#
# 		) .MYI
#
# 		) .cfg
#
# 		) .db
#
# 		) .ibd
#
# 		) .ndb
#
# If other files or directories remain in the database directory after MySQL removes those just listed,
# the database directory cannot be removed.
#
# In this case, you must remove any remaining files or directories manually and issue the
# DROP_DATABASE statement again.
#
# Dropping a database does not remove any TEMPORARY tables that were created in that database.
#
# TEMPORARY tables are automatically removed when the session that created them ends.
# See SECTION 13.1.20.3, "CREATE TEMPORARY TABLE SYNTAX"
#
# You can also drop databases with mysqladmin.
#
# See SECTION 4.5.2, "MYSQLADMIN - CLIENT FOR ADMINSTERING A MYSQL SERVER"
#
# 13.1.25 DROP EVENT SYNTAX
#
# DROP EVENT [IF EXISTS] event_name
#
# This statement drops the event named event_name.
#
# The event immediately ceases being active, and is deleted completely from the server
#
# If the event does not exist, the error ERROR 1517 (HY000): Unknown event 'event_name' results.
#
# You can override this and cause the statement to generate a warning for nonexistent
# events instead using IF EXISTS
#
# This statement requires the EVENT privilege for the schema to which the event
# to be dropped belongs.
#
# 13.1.26 DROP FUNCTION SYNTAX
#
# The DROP_FUNCTION statement is used to drop stored functions and user-defined functions
# (UDFs):
#
# 		) For information about dropping stored functions, see SECTION 13.1.29, "DROP PROCEDURE AND DROP FUNCTION SYNTAX"
#
# 		) For information about dropping user-defined functions, see SECTION 13.7.4.2, "DROP FUNCTION SYNTAX"
#
# 13.1.27 DROP INDEX SYNTAX
#
# DROP INDEX index_name ON tbl_name
# 		[algorithm_option | lock_option] ---
#
# algorithm_option:
# 		ALGORITHM [=] {DEFAULT|INPLACE|COPY}
#
# lock_option:
# 		LOCK [=] {DEFAULT|NONE|SHARED|EXCLUSIVE}
#
# DROP_INDEX drops the index named index_name from the table tbl_name
#
# This statement is mapped to an ALTER_TABLE statement to drop the index.
#
# See SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# To drop a primary key, the index name is always PRIMARY, which must be specified
# as a quoted identifier because PRIMARY is a reserved word:
#
# 		DROP INDEX `PRIMARY` ON t;
#
# Indexes on variable-width columns of NDB tables are dropped online; that is, without
# any table copying.
#
# The table is not locked against access from other NDB Cluster API nodes, although
# it is locked against other operations on the same API node for the duration of the
# operation.
#
# This is done automatically by the server whenever it determines that it is possible
# to do so;
#
# you do not have to use any special SQL syntax or server options to cause it to happen.
#
# ALGORITHM and LOCK clauses may be given to influence the table copying method and level
# of concurrency for reading and writing the table while its indexes are being
# modified.
#
# They have the same meaning as for the ALTER_TABLE statement.
#
# For more information, see SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# MySQL NDB Cluster supports online operations using the same ALGORITHM=INPLACE
# syntax supported in the standard MySQL server.
#
# See SECTION 22.5.14, "ONLINE OPERATIONS WITH ALTER TABLE IN NDB CLUSTER", for more information.
#
# 13.1.28 DROP LOGFILE GROUP SYNTAX
#
# DROP LOGFILE GROUP logfile_group
# 		ENGINE [=] engine_name
#
# This statement drops the log file group named logfile_group.
#
# The log file group must already exist or an error results.
#
# (For information on creating log file groups, see SECTION 13.1.16, "CREATE LOGFILE GROUP SYNTAX")
#
# IMPORTANT:
#
# 		Before dropping a log file group, you must drop all tablespaces that use that log file
# 		group for UNDO logging.
#
# The required ENGINE clauses provides the name of the storage engine used by the log file group
# to be dropped.
#
# Currently, the only permitted values for engine_name are NDB and NDBCLUSTER
#
# DROP_LOGFILE_GROUP is useful only with Disk Data storage for NDB Cluster.
#
# See SECTION 22.5.13, "NDB CLUSTER DISK DATA TABLES"
#
# 13.1.29 DROP PROCEDURE AND DROP FUNCTION SYNTAX
#
# 	DROP {PROCEDURE | FUNCTION} [IF EXISTS] sp_name
#
# This statement is used to drop a stored procedure or function.
#
# That is, the specified routine is removed from the server. You must have the ALTER_ROUTINE
# privilege for the routine.
#
# (If the automatic_sp_privileges system variable is enabled, that privilege and EXECUTE are granted
# automatically to the routine creator when the routine is created and dropped from the creator
# when the routine is dropped.
#
# See SECTION 24.2.2, "STORED ROUTINES AND MYSQL PRIVILEGES")
#
# The IF EXISTS clause is a MySQL extension.
#
# It prevents an error from occurring if the procedure or function does not exist.
#
# A warning is produced that can be viewed with SHOW_WARNINGS.
#
# DROP_FUNCTION is also used to drop user-defined functions (see SECTION 13.7.4.2, "DROP FUNCTION SYNTAX")
#
# 13.1.30 DROP SERVER SYNTAX
#
# DROP SERVER [ IF EXISTS ] server_name
#
# Drops the server definition for the server named server_name.
#
# The corresponding row in the mysql.servers table is deleted.
#
# This statement requires the SUPER privilege.
#
# Dropping a server for table does not affect any FEDERATED tables that used
# this connection information when they were created.
#
# See SECTION 13.1.18, "CREATE SERVER SYNTAX"
#
# DROP SERVER causes an implicit commit. See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# DROP SERVER is not written to the binary log, regardless of the logging format that is in use.
#
# 13.1.31 DROP SPATIAL REFERENCE SYSTEM SYNTAX
#
# 		DROP SPATIAL REFERENCE SYSTEM
# 			[IF EXISTS]
# 			srid
#
# 		srid: 32-bit unsigned integer
#
# This statement removes a spatial reference system (SRS) definition from the data
# dictionary.
#
# It requires the SUPER privilege.
#
# Example:
#
# 		DROP SPATIAL REFERENCE SYSTEM 4120;
#
# If no SRS definition with the SRID value exists, an error occurs unless IF EXISTS
# is specified.
#
# In that case, a warning occurs rather than an error.
#
# If the SRID value is used by some column in an existing table, an error occurs.
# For example:
#
# 		DROP SPATIAL REFERENCE SYSTEM 4326;
# 		ERROR 3716 (SR005): Can't modify SRID 4326. There is at
# 		least one column depending on it.
#
# To identify which column or columns use the SRID, use this query:
#
# 		SELECT * FROM INFORMATION_SCHEMA.ST_GEOMETRY_COLUMNS WHERE SRS_ID=4326;
#
# SRID values must be in the range of 32-bit unsigned integers, with these restrictions:
#
# 		) SRID 0 is a valid SRID but cannot be used with DROP_SPATIAL_REFERENCE_SYSTEM
#
# 		) If the value is in a reserved SRID range, a warning occurs.
#
# 			Reserved ranges are [0, 32767] (reserved by EPSG), [60,000,000,000,69,999,999] (reserved by EPSG),
# 			and [2,000,000,000,2,147,483,647] (reserved by MySQL)
#
# 			EPSG stands for the European Petroleum Survey Group
#
# 		) Users should not drop SRSs with SRIDs in the reserved ranges.
#
# 			If system-installed SRSs are dropped, the SRS definitions may be recreated
# 			for MySQL upgrades.
#
# 13.1.32 DROP TABLE SYNTAX
#
# 		DROP [TEMPORARY] TABLE [IF EXISTS]
# 			tbl_name [, tbl_name] ---
# 			[RESTRICT | CASCADE]
#
# DROP_TABLE removes one or more tables. You must have the DROP privilege
# for each table.
#
# Be careful with this statement.
#
# It removes the table definition and all table data.
#
# For a partitioned table, it permanently removes the table definition,
# all its partitions and all data stored in those partitions.
#
# It also removes partition definitions associated with the dropped table.
#
# DROP_TABLE causes an implicit commit, except when used with the TEMPORARY
# keyword.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# IMPORTANT:
#
# 		When a table is dropped, privileges granted specifically for the table are NOT
# 		automatically dropped.
#
# 		They must be dropped manually.
#
# 		See SECTION 13.7.1.6, "GRANT SYNTAX"
#
# If any tables named in the argument list do not exist, the statement fails with an
# error indicating by name which nonexisting tables it was unable to drop, and no
# changes are made.
#
# Use IF EXISTS to prevent an error from occurring for tables that do not exist.
#
# Instead of an error, a NOTE is generated for each nonexistent table; these notes
# can be displayed with SHOW_WARNINGS. See SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# IF EXISTS can also be useful for dropping tables in unusual circumstances under which
# there is an entry in the data dictionary but no table managed by the storage engine.
#
# (For example, if an abnormal server exit occurs after removal of the table from the
# storage engine but before removal of the data dictionary entry)
#
# The TEMPORARY keyword has the following effects:
#
# 		) The statement drops only TEMPORARY tables
#
# 		) The statement does not cause an implicit commit
#
# 		) No access rights are checked. A TEMPORARY table is visible only with the session
# 			that created it, so no check is necessary.
#
# Using TEMPORARY is a good way to ensure that you do not accidentally drop a 
# non-TEMPORARY table
#
# The RESTRICT and CASCADE keywords do nothing. They are permitted to make porting easier
# from other database systems.
#
# DROP_TABLE is not supported with all innodb_force_recovery settings.
#
# See SECTION 15.20.2, "FORCING INNODB RECOVERY"
#
# 13.1.33 DROP TABLESPACE SYNTAX
#
# 		DROP [UNDO] TABLESPACE tablespace_name
# 			[ENGINE [=] engine_name]
#
# This statement drops a tablespace that was previously created using CREATE_TABLESPACE.
#
# It is supported by the NDB and InnoDB storage engines.
#
# The UNDO keyword, introduced in MySQL 8.0.14, must be specified to drop an undo tablespace.
#
# Only undo tablespaces created using CREATE_UNDO_TABLESPACE syntax can be dropped.
#
# An undo tablespace must be in an empty state before it can be dropped.
# For more information, see SECTION 15.6.3.4, "UNDO TABLESPACES"
#
# ENGINE sets the storage engine that uses the tablespace, where engine_name is the name
# of the storage engine.
#
# Currently, the values InnoDB and NDB are supported.
#
# If not set, the value of default_storage_engine is used
#
# If it is not the same as the storage engine used to create the tablespace,
# the DROP TABLESPACE statement fails.
#
# tablespace_name is a case-sensitive identifier in MySQL.
#
# For an InnoDB general tablespace, all tables must be dropped from the tablespace
# prior to a DROP TABLESPACE operation.
#
# If the tablespace is not empty, DROP TABLESPACE returns an error.
#
# An NDB tablespace to be dropped must not contain any data files; in other words,
# before you can drop an NDB tablespace, you must first drop each of its data
# files using ALTER_TABLESPACE_---_DROP_DATAFILE
#
# NOTES
#
# 		) A general InnoDB tablespace is not deleted automatically when the last table in the
# 			tablespace is dropped.
#
# 			The tablespace must be dropped explicitly using DROP TABLESPACE tablespace_name
#
# 		) A DROP_DATABASE operation can drop tables that belong to a general tablespace but it cannot
# 			drop the tablespace, even if the operation drops all tables that belong to the tablespace.
#
# 			The tablespace must be dropped explicitly using DROP TABLESPACE tablespace_name
#
# 		) Similar to the system tablespace, truncating or dropping tables stored in a general tablespace
# 			creates free space internally in the general tablespace .ibd data file which can only
# 			be used for new InnoDB data.
#
# 			Space is not released back to the operating system as it is for file-per-table tablespaces
#
# InnoDB EXAMPLES
#
# This example demonstrates how to drop an InnoDB general tablespace.
#
# The general tablespace ts1 is created with a single table. 
# Before dropping the tablespace, the table must be dropped.
#
# 		CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' Engine=InnoDB;
#
# 		CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts10 Engine=InnoDB;
#
# 		DROP TABLE t1;
#
# 		DROP TABLESPACE ts1;
#
# This example demonstrates dropping an undo tablespace.
#
# An undo tablespace must be in an empty state before it can be dropped.
#
# For more information, see SECTION 15.6.3.4, "UNDO TABLESPACES"
#
# 		DROP UNDO TABLESPACE undo_003;
#
# NDB EXAMPLE
#
# This example shows how to drop an NDB tablespace myts having a data file named mydata-1.dat
# after first creating the tablespace, and assumes the existence of a log file group named
# mylg (see SECTION 13.1.16, "CREATE LOGFILE GROUP SYNTAX")
#
# 		CREATE TABLESPACE myts
# 			ADD DATAFILE 'mydata-1.dat'
# 			USE LOGFILE GROUP mylg
# 			ENGINE=NDB;
#
# You must remove all data files from the tablespace using ALTER_TABLESPACE, as shown here
# , before it can be dropped:
#
# 		ALTER TABLESPACE 
# 			DROP DATAFILE 'mydata-1.dat'
# 			ENGINE=NDB;
#
# 		DROP TABLESPACE myts;
#
# 13.1.34 DROP TRIGGER SYNTAX
#
# 		DROP TRIGGER [IF EXISTS] [schema_name.]trigger_name
#
# This statement drops a trigger. The schema (database) name is optional.
#
# If the schema is omitted, the trigger is dropped from the default schema.
#
# DROP_TRIGGER requires the TRIGGER privilege for the table associated with the trigger.
#
# Use IF EXISTS to prevent an error from occurring for a trigger that does not exist.
#
# A NOTE is generated for a nonexistent trigger when using IF EXISTS.
#
# See SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# Triggers for a table are also dropped if you drop the table.
#
# 13.1.35 DROP VIEW SYNTAX
#
# 		DROP VIEW [IF EXISTS]
# 			view_name [, view_name] ---
# 			[RESTRICT | CASCADE]
#
# DROP_VIEW removes one or more views.
#
# You must have the  DROP privilege for each view.
#
# If any views named in the argument list do not exist, the statement fails
# with an error indicating by name which nonexisting views it was unable to
# drop, and no changes are made.
#
# 		NOTE:
#
# 			In MySQL 5.7 and earlier, DROP_VIEW returns an error if any views named in the argument
# 			list do not exist, but also drops all views in the list that do exist.
#
# 			Due to the change in behavior in MySQL 8.0, a partially completed DROP_VIEW operaiton
# 			on a MySQL 5.7 master fails when replicated on a MySQL 8.0 slave
#
# 			To avoid this failure scenario, use IF EXISTS syntax in DROP_VIEW statements to prevent
# 			an error from occurring for views that do not exist.
#
# 			For more information, see SECTION 13.1.1, "ATOMIC DATA DEFINITION STATEMENT SUPPORT"
#
# The IF EXISTS clause prevents an error from occurring for views taht do not exist.
#
# When this clause is given, a NOTE is generated for each nonexistent view.
#
# See SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# RESTRICT and CASCADE, if given, are parsed and ignored.
#
# 13.1.36 RENAME TABLE SYNTAX
#
# RENAME TABLE
# 		tbl_name TO new_tbl_name
# 		[, tbl_name2 TO new_tbl_name2] ---
#
# RENAME_TABLE renames one or more tables. You must have ALTER and DROP privileges
# for the original table, and CREATE and INSERT privileges for the new table.
#
# For example, to rename a table named old_table to new_table, use this statement:
#
# 		RENAME TABLE old_table TO new_table;
#
# That statement is equivalent to the following ALTER_TABLE statement:
#
# 		ALTER TABLE old_table RENAME new_table;
#
# RENAME TABLE, unlike ALTER_TABLE, can rename multiple tables within a single statement:
#
# 		RENAME TABLE old_table1 TO new_table1,
# 						 old_table2 TO new_table2,
# 						 old_table3 TO new_table3;
#
# Renaming operations are performed left to right.
#
# Thus, to swap two table names, do this (assuming that a table with the intermediary
# name tmp_table does not already exist):
#
# 		RENAME TABLE old_table TO tmp_table,
# 						 new_table TO old_table,
# 						 tmp_table TO new_table;
#
# Metadata locks on tables are acquired in name order, which in some cases can make a difference
# in operation outcome when multiple transactions execute concurrently.
#
# See SECTION 8.11.4, "METADATA LOCKING"
#
# As of MySQL 8.0.13, you can rename tables locked with a LOCK_TABLES statement, provided
# that they are locked with a WRITE lock or are the product of renaming WRITE-locked
# tables from earlier steps in a multiple-table rename operation.
#
# For example, this is permitted:
#
# 		LOCK TABLE old_table1 WRITE;
# 		RENAME TABLE old_table1 TO new_table1,
# 						 new_table1 TO new_table2;
#
# This is not permitted:
#
# 		LOCK TABLE old_table1 READ;
# 		RENAME TABLE old_table1 TO new_table1,
# 						 new_table1 TO new_table2;
#
# Prior to MySQL 8.0.13, to execute RENAME TABLE, there must be no tables locked with LOCK TABLES.
#
# With the transaction table locking conditions satisfied, the rename operation is done atomically;
# no other session can access any of the tables while the rename is in progress.
#
# If any error occurs during a RENAME TABLE, the statement fails and no changes are made.
#
# You can use RENAME TABLE to move a table from one database to another:
#
# 		RENAME TABLE current_db.tbl_name TO other_db.tbl_name;
#
# Using this method to move all tables from one database to a different one in effect
# renames the database (an operation for which MySQL has no single statement), except
# that the original database continue to exist, albeit with no tables.
#
# Like RENAME TABLE, ALTER TABLE --- RENAME can also be used to move a table to a different
# database.
#
# Regardless of the statement used, if the rename operation would move the table to a database
# located on a different file system, the success of the outcome is platform specific and
# depends on the underlying OS calls used to move table files.
#
# If a table has triggers, attempts to rename the table into a different database fail with a
# Trigger in wrong schema (ER_TRG_IN_WRONG_SCHEMA) error
#
# To rename TEMPORARY tables, RENAME TABLE does not work.
#
# Use ALTER_TABLE instead.
#
# RENAME TABLE works for views, except that views cannot be renamed into a different database.
#
# Any privileges granted specifically for a renamed table or view are not migrated to the new name.
#
# They must be changed manually.
#
# RENAME TABLE changes interally generated foreign key constraint names and user-defined foreign
# key constraint names that contain the string "tbl_name_ibfk_" to reflect the new table name.
#
# InnoDB interprets foreign key constraint names that contain the string "tbl_name_ibfk_"
# as internally generated names.
#
# Foreign key constraint names that point to the renamed table are automatically updated unless
# there is a conflict, in which case the statement fails with an error.
#
# A conflict occurs if the renamed constraint name already exists.
#
# In such cases, you must drop and re-create the foreign keys for them to function properly.
#
# 13.1.37 TRUNCATE TABLE SYNTAX
#
# TRUNCATE [TABLE] tbl_name
#
# TRUNCATE_TABLE empties a table completely. It requires the DROP privilege.
#
# Logically, TRUNCATE_TABLE is similar to DELETE statement that deletes all rows,
# or a sequence of DROP_TABLE and CREATE_TABLE statements.
#
# To achieve a high performance, TRUNCATE_TABLE bypasses the DML method of deleting data.
#
# Thus, it does not cause ON DELETE triggers to fire, it cannot be performed for 
# InnoDB tables with parent-child foreign key relationships, and it cannot be rolled
# back like a DML operation.
#
# However, TRUNCATE TABLE operations on tables that use an atomic DDL-supported storage
# engine are either fully committed or rolled back if the server halts during their operation.
#
# For more information, see SECTION 13.1.1, "ATOMIC DATA DEFINITION STATEMENT SUPPORT"
#
# Although TRUNCATE_TABLE is similar to DELETE, it is classified as a DDL statement rather than
# a DML statement.
#
# It differs from DELETE in the following ways:
#
# 		) Truncate operations drop and re-create the table, which is much faster than deleting rows
# 			one by one, particularly for large tables.
#
# 		) Truncate operations cause an implicit commit, and so cannot be rolled back.
#
# 			See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# 		) Truncation operations cannot be performed if the session holds an active table lock
#
# 		) TRUNCATE_TABLE fails for an InnoDB table or NDB table if there are any FOREIGN KEY constraints
# 			from other tables that reference the table.
#
# 			Foreign key constraints between columns of the same table are permitted.
#
# 		) Truncation operations do not return a meaningful value for the number of deleted rows.
#
# 			The usual result is "0 rows affected", which should be interpreted as "no information"
#
# 		) As long as the table definition is valid, the table can be re-created as an empty table with TRUNCATE_TABLE,
# 			even if the data or index files have become corrupted.
#
# 		) Any AUTO_INCREMENT value is reset to its start value. This is true even for MyISAM and InnoDB, which normally
# 			do not reuse sequence values.
#
# 		) When used with partitioned tables, TRUNCATE_TABLE preserves the partitioning; that is, the data and index
# 			files are dropped and re-created, while the partition definitions are unaffected.
#
# 		) The TRUNCATE_TABLE statement does not invoke ON DELETE triggers
#
# 		) Truncating a corrupted InnoDB table is supported.
#
# TRUNCATE_TABLE for a table closes all handlers for the table that were opened with HANDLER_OPEN
#
# TRUNCATE_TABLE is treated for purposes of binary logging and replication as DROP_TABLE followed by CREATE_TABLE -
# that is, as DDL rather than DML.
#
# This is due to the fact that, when using InnoDB and other transactional storage engines where the transaction
# isolation level does not permit statement-based logging (READ COMMITTED or READ UNCOMMITTED), the statement
# was not logged and replicated when using STATEMENT or MIXED logging mode.
#
# (Bug #36763)
#
# However, it is still applied on replication slaves using InnoDB in the manner described previously.
#
# In MySQL 5.7 and earlier, on a system with a large buffer pool and innodb_adaptive_hash_index
# enabled, a TRUNCATE TABLE operation could cause a temporary drop in system performance due to
# an LRU scan that occurred when removing the table's adaptive hash index entries (Bug #68184)
#
# The remapping of TRUNCATE_TABLE to DROP_TABLE and CREATE_TABLE in MySQL 8.0 avoids the problematic
# LRU scan.
#
# TRUNCATE_TABLE can be used with Performance Schema summary tables, but the effect is to reset the
# summary columns to 0 or NULL, not to remove rows.
#
# See SECTION 26.12.16, "PERFORMANCE SCHEMA SUMMARY TABLES"
#
# 13.2 DATA MANIPULATION STATEMENTS
#
# 13.2.1 CALL SYNTAX
# 13.2.2 DELETE SYNTAX
# 13.2.3 DO SYNTAX
#
# 13.2.4 HANDLER SYNTAX
# 13.2.5 IMPORT TABLE SYNTAX
# 13.2.6 INSERT SYNTAX
#
# 13.2.7 LOAD DATA INFILE SYNTAX
# 13.2.8 LOAD XML SYNTAX
# 13.2.9 REPLACE SYNTAX
# 
# 13.2.10 SELECT SYNTAX
# 13.2.11 SUBQUERY SYNTAX
# 13.2.12 UPDATE SYNTAX
#
# 13.2.13 WITH SYNTAX (COMMON TABLE EXPRESSIONS)
#
# 13.2.1 CALL SYNTAX
#
# CALL sp_name([parameter[,---]])
# CALL sp_name[()]
#
# The CALL statement invokes a stored procedure that was defined previously with CREATE_PROCEDURE
#
# Stored procedures that take no arguments can be invoked without parentheses.
#
# That is, CALL p() and CALL p are equivalent.
#
# CALL can pass back values to its caller using parameters that are declared as OUT or
# INOUT parameters.
#
# When the procedure returns, a client program can also obtain the number of rows
# affected for the final statement executed within the routine:
#
# 		At the SQL level, call the ROW_COUNT() function
#
# 		From the C API, call the mysqL_affected_rows() function
#
# For information about the effect of unhandled conditions on procedure parameters,
# see SECTION 13.6.7.8, "CONDITION HANDLING AND OUT OR INOUT PARAMETERS"
#
# To get back a value from a procedure using an OUT or INOUT parameter, pass the parameter
# by means of a user variable, and then check the value of the variable after the
# procedure returns.
#
# (If you are calling the procedure from within another stored procedure or function,
# you can also pass a routine parameter or local routine variable as an IN or INOUT parameter)
#
# For an INOUT parameter, initialize its value before passing it to the procedure.
#
# The following procedure has an OUT parameter that the procedure sets to
# the current server version, and an INOUT value that the procedure increments by one
# from its current value:
#
# 		CREATE PROCEDURE p (OUT ver_param VARCHAR(25), INOUT incr_param INT)
# 		BEGIN
# 			# Set value of OUT parameter
# 			SELECT VERSION() INTO ver_param;
# 			# Increment value of INOUT parameter
# 			SET incr_param = incr_param + 1;
# 		END;
#
# Before calling the procedure, initialize the variable to be passed as the INOUT parameter.
#
# After calling the procedure, the values of the two variables will have been set or modified:
#
# 		SET @increment = 10;
# 		CALL p(@version, @increment);
# 		SELECT @version, @increment;
# 		+-----------------------------+-------------+
# 		| @version 							| @increment  |
# 		+-----------------------------+-------------+
# 		| 8.0.3-rc-debug-log 			| 11 			  |
# 		+-----------------------------+-------------+
#
# IN prepared CALL statements used with PREPARE and EXECUTE, placeholders
# can be used for IN parameters, OUT, and INOUT parameters.
#
# These types of parameters can be used as follows:
#
# 		SET @increment = 10;
# 		PREPARE s FROM 'CALL p(?, ?)';
# 		EXECUTE s USING @version, @increment;
# 		SELECT @version, @increment;
# 		+----------------------+---------------+
# 		| @version 				  | @increment 	|
# 		+----------------------+---------------+
# 		| 8.0.3-rc-debug-log   | 11 			   |
# 		+----------------------+---------------+
#
# To write C programs that use the CALL SQL statements to execute stored procedures
# that produce result sets, the CLIENT_MULTI_RESULTS flag must be enabled.
#
# THis is because each CALL returns a result to indicate the call status, in addition
# to any result sets that might be returned by statements executed within the procedure.
#
# CLIENT_MULTI_RESULTS must also be enabled if CALL is used to execute any stored procedure
# that contains prepared statements.
#
# It cannot be determined when such a procedure is loaded whether those statements will produce
# result sets, so it is necessary to assume that they will.
#
# CLIENT_MULTI_RESULTS can be enabled when you call mysql_real_connect(), either explicitly
# by passing the CLIENT_MULTI_RESULTS flag itself, or implicitly by passing CLIENT_MULTI_STATEMENTS
# (which also enables CLIENT_MULTI_RESULTS) 
#
# CLIENT_MULTI_RESULTS is enabled by default
#
# To process the result of a CALL statement executed using mysql_query() or mysql_real_query(),
# use a loop that calls mysql_next_result() to determine whether there are more results.
#
# For an example, see SECTION 28.7.19, "C API MULTIPLE STATEMENT EXECUTION SUPPORT"
#
# C programs can use hte prepared-statement interface to execute CALL statements and access
# OUT and INOUT parameters.
#
# This is done by processing the result of a CALL statement using a loop that calls
# mysql_stmt_next_result() to determine whether there are more results.
#
# For an example, see SECTION 28.7.21, "C API PREPARED CALL STATEMENT SUPPORT"
#
# Languages that provide a MySQL interface can use prepared CALL statements to directly
# retrieve OUT and INOUT procedure statements.
#
# Metadata changes to objects referred to by stored programs are detected and cause 
# automatic reparsing of the affected statements when the program is next executed.
#
# For more information, see SECTION 8.10.3, "CACHING OF PREPARED STATEMENTS AND STORED PROGRAMS"
#
# 13.2.2 DELETE SYNTAX
#
# DELETE is a DML statement that removes rows from a table
#
# A DELETE statement can start with a WITH clause to define common table expressions accessible
# within the DELETE.
#
# See SECTION 13.2.13, "WITH SYNTAX (COMMON TABLE EXPRESSIONS)"
#
# SINGLE-TABLE SYNTAX
#
# 		DELETE [LOW_PRIORITY] [QUICK] [IGNORE] FROM tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			[WHERE where_condition]
# 			[ORDER BY ---]
# 			[LIMIT row_count]
#
# The DELETE statement deletes rows from tbl_name and returns the number of deleted rows.
#
# To check the number of deleted rows, call the ROW_COUNT() function described in
# SECTION 12.15, "INFORMATION FUNCTIONS"
#
# MAIN CLAUSES
#
# The conditions in the optional WHERE clause identify which rows to delete.
#
# With no WHERE clause, all rows are deleted.
#
# where_condition is an expression that evaluates to true for each row to be deleted.
# It is specified as described in SECTION 13.2.10, "SELECT SYNTAX"
#
# If the ORDER BY clause is specified, the rows are deleted in the order that is specified.
#
# The LIMIT clause places a limit on the number of rows that can be deleted.
#
# These clauses apply to single-table deletes, but not multi-table deletes
#
# MULTIPLE-TABLE SYNTAX
#
# 		DELETE [LOW_PRIORITY] [QUICK] [IGNORE]
# 			tbl_name[.*] [, tbl_name[.*]] ---
# 			FROM table_references
# 			[WHERE where_condition]
#
# 		DELETE [LOW_PRIORITY] [QUICK] [IGNORE]
# 			FROM tbl_name[.*] [, tbl_name[.*]] ---
# 			USING table_references
# 			[WHERE where_condition]
#
# PRIVILEGES
#
# You need the DELETE privilege on a table to delete rows from it.
#
# You need only the SELECT privilege for any columns that are only read,
# such as those named in the WHERE clause.
#
# PERFORMANCE
#
# When you do not need to know the number of deleted rows, the TRUNCATE_TABLE
# statement is a faster way to empty a table than a DELETE statement with no WHERE clause.
#
# Unlike DELETE, TRUNCATE_TABLE cannot be used within a transaction or if you have a lock
# on the table.
#
# See SECTION 13.1.37, "TRUNCATE TABLE SYNTAX" and SECTION 13.3.6, "LOCK TABLES AND UNLOCK TABLES SYNTAX"
#
# The speed of delete operations may also be affected by factors discussed in SECTION 8.2.5.3,
# "OPTIMIZING DELETE STATEMENTS"
#
# To ensure that a given DELETE statement does not take too much time, the MySQL-specific LIMIT
# row_count clause for DELETE specifies the maximum number of rows to be deleted.
#
# If the number of rows to delete is larger than the limit, repeat the DELETE statement
# until the number of affected rows is less than the LIMIT value.
#
# SUBQUERIES
#
# You cannot delete from a table and select from the same table in a subquery
#
# PARTITIONED TABLE SUPPORT
#
# DELETE supports explicit partition selection using the PARTITION option, which takes a list of the
# comma-separated names of one or more partitions or subpartitions (or both) from which to select
# rows to be dropped.
#
# Partitions not included in the list are ignored.
#
# Given a partitioned table t with a partition named p0, executing the statement
# DELETE FROM t PARTITION (p0) has the same effect on the table as executing ALTER_TABLE_t_TRUNCATE_PARTITION_(p0);
# in both cases, all rows in partition p0 are dropped.
#
# PARTITION can be used along with a WHERE condition, in which case the condition is tested
# only on rows in the listed partitions.
#
# For example, 
#
# 		DELETE FROM t PARTITION (p0) WHERE c < 5 
# 
# deletes rows only from partition p0 for which the condition c < 5 is true;
# rows in any other partitions are not checked and thus not affected by the DELETE
#
# The PARTITION option can also be used in multiple-table DELETE statements.
#  
# You can use up to one such option per table named in the FROM option
#
# For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# AUTO-INCREMENT COLUMNS
#
# If you delete the row containing the maximum value for an AUTO_INCREMENT column,
# the value is not reused for a MyISAM or InnoDB table.
#
# if you delete all rows in the table with DELETE FROM tbl_name (without a WHERE clause)
# in autocommit mode, the sequence starts over for all storage engines except InnoDB
# and MyISAM.
#
# There are some exceptions to this behavior for InnoDB tables, as discussed
# in SECTION 15.6.1.14, "AUTO_INCREMENT HANDLING IN INNODB"
#
# For MyISAM tables, you can specify an AUTO_INCREMENT secondary column in a multiple-column
# key.
#
# In this case, reuse of values deleted from the top of the sequence occurs even for
# MyISAM tables. See SECTION 3.6.9, "USING AUTO_INCREMENT"
#
# MODIFIERS
#
# The DELETE statement supports the following modifiers:
#
# 		) If you specify LOW_PRIORITY, the server delays execution of the DELETE until no other
# 			clients are reading from the table.
#
# 			This affects only storage engines that use only table-level locking
# 			(such as MyISAM, MEMORY and MERGE)
#
# 		) For MyISAM tables, if you use the QUICK modifier, the storage engine does not merge
# 			index leaves during delete, which may speed up some kinds of delete operations.
#
# 		) The IGNORE modifier causes MySQL to ignore errors during the process of deleting rows.
#
# 			(Errors encountered during the parsing stage are processed in the usual manner)
#
# 			Errors that are ignored due to the use of IGNORE are returend as warnings.
#
# 			For more information, see COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE
#
# ORDER OF DELETION
#
# If the DELETE statement includes an ORDER BY clause, rows are deleted in the order specified
# by the clause.
#
# This is useful primarily in conjunction with LIMIT.
#
# For example, the following statement finds rows matching the WHERE clause, sorts them
# by timestamp_column, and deletes the first (oldest) one:
#
# 		DELETE FROM somelog WHERE user = 'jcole'
# 		ORDER BY timestamp_column LIMIT 1;
#
# ORDER BY also helps to delete rows in an order required to avoid referential
# integrity violations.
#
# INNODB TABLES
#
# If you are deleting many rows from a large table, you may exceed the lock table
# size for an InnoDB table.
#
# To avoid this problem, or simply to minimize the time that the table remains locked,
# the following strategy (which does not use DELETE at all) might be helpful:
#
# 		1. Select the rows NOT to be deleted into an empty table that has the same structure as the original table:
#
# 			INSERT INTO t_copy SELECT * FROM t WHERE --- ;
#
# 		2. Use RENAME_TABLE to atomically move the original table out of the way and rename the copy to the original name:
#
# 			RENAME TABLE t TO t_old, t_copy TO t;
#
# 		3. Drop the original table:
#
# 			DROP TABLE t_old;
#
# No other sessions can access the tables involved while RENAME_TABLE executes, so the rename operation
# is not subject to concurrency problems.
#
# See SECTION 13.1.36, "RENAME TABLE SYNTAX"
#
# MYISAM TABLES
#
# In MyISAM tables, deleted rows are maintained in a linked list and subsequent INSERT operations
# reuse old row positions.
#
# To reclaim unused space and reduce file size, use the OPTIMIZE TABLE statement or the
# myisamchk utility to reorganize tables.
#
# OPTIMIZE_TABLE is easier to use, but myisamchk is faster.
#
# See SECTION 13.7.3.4, "OPTIMIZE TABLE SYNTAX", and SECTION 4.6.4, "MYISAMCHK -- MyISAM TABLE-MAINTENANCE UTILITY"
#
# The QUICK modifier affects whether index leaves are merged for delete operations.
#
# DELETE QUICK is most useful for applications where index values for deleted rows are replaced by similar
# index values from rows inserted later.
#
# In this case, the holes left by deleted values are reused.
#
# DELETE QUICK is not useful when deleted values lead to underfilled blocks spanning
# a range of index values for which new inserts occur again.
#
# In this case, use of QUICK can lead to wasted space in the index that remains unreclaimed.
#
# Here is an example of such a scenario:
#
# 		1. Create a table that contains an indexed AUTO_INCREMENT column
#
# 		2. Insert many rows into the table. Each insert results in an index value that is added
# 			to the high end of the index.
#
# 		3. Delete a block of rows at the low end of the column range using DELETE QUICK
#
# In this scenario, the index blocks associated with the deleted index values become underfilled
# but are not merged with other index blocks due to the use of QUICK.
#
# They remain underfilled when new inserts occur, because new rows do not have index values
# in the deleted range.
#
# Furthermore, they remain underfilled even if you later use DELETE without QUICK, unless some
# of the deleted index values happen to lie in index blocks within or adjacent to the
# underfilled blocks.
#
# To reclaimed unused index space under these circumstances, use OPTIMIZE_TABLE
#
# If you are going to delete many rows from a table, it might be faster to use DELETE QUICK
# followed by OPTIMIZE TABLE.
#
# This rebuilds the index rather than performing many index block merge operations.
#
# MULTI-TABLE DELETES
#
# You can specify multiple tables in a DELETE statement to delete rows from one or more
# tables depending on teh condition in teh WHERE clause.
#
# You cannot use ORDER BY or LIMIT in a multiple-table DELETE
#
# The table_references clause lists the tables involved in the join,
# as described in SECTION 13.2.10.2, "JOIN SYNTAX"
#
# For the first multiple-table syntax, only matching rows from tables listed before
# the FROM clause are deleted.
#
# For the second multiple-table syntax, only matching rows from the tables listed
# in the FROM clause (before the USING clause) are deleted.
#
# The effect is that you can delete rows from many tables at the same time and have
# additional tables that are used only for searching:
#
# 		DELETE t1, t2 FROM t1 INNER JOIN t2 INNER JOIN t3
# 		WHERE t1.id=t2.id AND t2.id=t3.id;
#
# OR
#
# 		DELETE FROM t1, t2 USING t1 INNER JOIN t2 INNER JOIN t3
# 		WHERE t1.id=t2.id AND t2.id=t3.id;
#
# These statements use all three tables when searching for rows to delete, but delete
# matching rows only from tables t1 and t2.
#
# The preceding examples use INNER JOIN, but multiple-table DELETE statements cna use
# other types of join permitted in SELECT statements, such as LEFT JOIN
#
# For example, to delete rows that exist in t1 that have no match in t2, use a LEFT JOIN:
#
# 		DELETE t1 FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL;
#
# The syntax permits .* after each tbl_name for compatibility with Access.
#
# If you use a multiple-table DELETE statement involving InnoDB tables for which
# there are foreign key constraints, the MySQL optimizer might process tables in
# an order that differs from that of their parent/child relationship.
#
# In this case, the statement fails and rolls back.
#
# Instead, you should delete from a single table and rely on the ON DELETE 
# capabilities that INnoDB provides to cause the other tables ot be modified accordingly.
#
# NOTE:
#
# 		if you declare an alias for a table, you must use the alias when referring to teh table:
#
# 			DELETE t1 FROM test AS t1, test2 WHERE ---
#
# Table aliases in a multiple-table DELETE should be declared only in the table_references
# part of the statement.
#
# Elsewhere, alias references are permitted but not alias declarations.
#
# CORRECT:
#
# 		DELETE a1, a2 FROM t1 AS a1 INNER JOIN t2 AS a2
# 		WHERE a1.id=a2.id;
#
# 		DELETE FROM a1, a2 USING t1 AS a1 INNER JOIN t2 AS a2
# 		WHERE a1.id=a2.id;
#
# INCORRECT:
#
# 		DELETE t1 AS a1, t2 AS a2 FROM t1 INNER JOIN t2
# 		WHERE a1.id=a2.id;
#
# 		DELETE FROM t1 AS a1, t2 AS a2 USING t1 INNER JOIN t2
# 		WHERE a1.id=a2.id;
#
# 13.2.3 DO SYNTAX
#
# 		DO expr [, expr] ---
#
# DO executes the expressions but does not return any results.
#
# In most respects, DO is shorthand for SELECT expr, ---, but has the advantage
# that it is slightly faster when you do not care about the result.
#
# DO is useful primarily with functions that have side effects, such as
# RELEASE_LOCCK()
#
# Example: This SELECT statement pauses, but also produces a result set:
#
# 		SELECT SLEEP(5);
# 		+-------------+
# 		| SLEEP(5) 	  |
# 		+-------------+
# 		| 		0 		  |
# 		+-------------+
# 		1 row in set (5.02 sec)
#
# DO, on the other hand, pauses without producing a result set:
#
# 		DO SLEEP(5);
# 		Query OK, 0 rows affected (4.99 sec)
#
# This could be useful, for example in a stored function or trigger, which prohibit
# statements that produce result sets.
#
# DO only executes expressions.
#
# It cannot be used in all cases where SELECT can be used.
#
# For example, DO id FROM t1 is invalid ebcause it references a table.
#
# 13.2.4 HANDLER SYNTAX
#
# 		HANDLER tbl_name OPEN [ [AS] alias]
#
# 		HANDLER tbl_name READ index_name { = | <= | >= | < | > } (value1, value2, ---)
# 			[ WHERE where_condition ] [LIMIT --- ]
# 		HANDLER tbl_name READ index_name { FIRST | NEXT | PREV | LAST }
# 			[ WHERE where_condition ] [LIMIT --- ]
#
# 		HANDLER tbl_name READ { FIRST | NEXT }
# 			[ WHERE where_condition ] [LIMIT --- ]
# 
# 		HANDLER tbl_name CLOSE
#
# The HANDLER statement provides direct access to table storage engine interfaces.
#
# It is available for InnoDB and MyISAM tables.
#
# The HANDLER --- OPEN statement opens a table, making it accessible using subsequent
# HANDLER --- READ statements.
#
# This table object is not shared by other sessions and is not closed until the
# session calls HANDLER --- CLOSE or the session terminates.
#
# If you open the table using an alias, further references to the open table with
# other HANDLER statements must use the alias rather than the table name.
#
# If you do not use an alias, but open the table using a table name qualified
# by the database name, further references must use the unqualified table name.
#
# For example, for a table opened using mydb.mytable - further references must use mytable
#
# The first HANDLER --- READ syntax fetches a row where the index specified statisfies
# the given values and the WHERE condition is met.
#
# If you have a multiple-column index, specify the index column values as a comma-separated
# list.
#
# Either specify values for all the columns in the index, or specify values for a leftmost
# prefix of the index columns.
#
# Suppose that an index my_idc includes three columns named col_a, col_b and col_c, in taht order.
#
# The HANDLER statement can specify values for all three columns in the index,
# or for the columns in a leftmost prefix. For example:
#
# 		HANDLER --- READ my_idx = (col_a_val, col_b_val, col_c_val) ---
# 		HANDLER --- READ my_idx = (col_a_val, col_b_val) ---
# 		HANDLER --- READ my_idx = (col_a_val) ---
#
# To employ the HANDLER interface to refer to a table's PRIMARY KEY, use the quoted
# identifier `PRIMARY`:
#
# 		HANDLER tbl_name READ `PRIMARY` ---
#
# The second HANDLER --- READ syntax fetches a row from the table in index order that
# matches the WHERE condition.
#
# The third HANDLER --- READ syntax fetches a row from the table in natural row order
# that matches the WHERE condition.
#
# It is faster than HANDLER tbl_name READ index_name when a full table scan is desired.
#
# Natural row order is the order in which rows are stored in a MyISAM table data file.
#
# This statement works for INnoDB tables as well, but there is no such concept because
# there is no separate data file.
#
# Without a LIMIT clause, all forms of HANDLER --- READ fetch a single row if one is 
# available.
#
# To return a specific number of rows, include a LIMIT clause.
#
# It has the same syntax as for the SELECT statement. See SECTION 13.2.10, "SELECT SYNTAX"
#
# HANDLER -- CLOSE closes a table that was opened with HANDLER --- OPEN
#
# There are several reasons to use the HANDLER interface instead of normal
# SELECT statements:
#
# 		) HANDLER is faster than SELECT
#
# 			) A desiganted storage engine handler object is allocated for the HANDLER --- OPEN.
#
# 				THe object is reused for subsequent HANDLER statements for that table;
# 				it need not be reinitialized for each one.
#
# 			) There is less parsing involved
#
# 			) There is no optimizer or query-checking overhead
#
# 			) The handler interface does not have to provide a consistent look of the data (for example,
# 				dirty reads are permitted), so the storage engine can use optimizations that SELECT
# 				does not normally permit.
#
# 		) HANDLER makes it easier to port to MySQL applications that use a low-level ISAM-like interface.
#
# 			(See SECTION 15.19, "INNODB MEMCACHED PLUGIN" for an alternative way to adapt applications
# 			that use the key-value store paradigm)
#
# 		) HANDLER enables you to traverse a database in a manner that is difficult (or even impossible)
# 			to accomplish with SELECT.
#
# 			The HANDLER interface is a more natural way to look at data when working with applications
# 			that provide an interactive user interface to the database.
#
# HANDLER is a somewhat low-level statement.
#
# For example, it does not provide consistency.
#
# That is, HANDLER --- OPEN does NOT take a snapshot of the table, and does NOT 
# lock the table.
#
# THis means that after a HANDLER --- OPEN statement is issued, table data can be modified 
# (by the current session or other sessions) and these modifications might be only
# partially visible to HANDLER --- NEXT or HANDLER --- PREV scans.
#
# An open handler can be closed and marked for reopen, in which case the handler loses
# its position in the table.
#
# This occurs when both of the following circumstances are true:
#
# 		) Any session executes FLUSH_TABLES or DDL statements on the handler's table
#
# 		) The session in which the handler is open executes non-HANDLER statements that use tables
#
# TRUNCATE_TABLE for a table closes all handlers for the table that were opened with HANDLER_OPEN
#
# If a table is flushed with FLUSH_TABLES_tbl_name_WITH_READ_LOCK was opened with HANDLER,
# the handler is implicitly flushed and loses its position.
#
# 13.2.5 IMPORT TABLE SYNTAX
#
# 		IMPORT TABLE FROM sdi_file [, sdi_file] ---
#
# The IMPORT_TABLE statement imports MyISAM tables based on information contained in .sdi
# (Serialized Dictionary Information) metadata files.
#
# IMPORT TABLE requires the FILE privilege to read the .sdi and table content files,
# and the CREATE privilege for the table to be created.
#
# Tables can be exported from one server using mysqldump to write a file of SQL statements
# and imported into another server using mysql to process the dump file.
#
# IMPORT TABLE provides a faster alternative using the "raw" table files
#
# Prior to import, the files that provide the table content must be placed in the 
# appropriate schema directory for the import server, and the .sdi file must be
# located in a directory accessible to the server.
#
# For example, the .sdi file can be placed in the directory named by the secure_file_priv
# system variable, or (if secure_file_priv is empty) in a directory under the server
# data directory.
#
# The following example describes how to export MyISAM tables named employees and
# managers from the hr schema of one server and import them into the hr schema of
# another server.
#
# The examples uses these assumptions (to perform a similar operaiton on your own system,
# modify the path names as called for):
#
# 		) For the export server, export_basedir represents its base directory, and its data directory
# 			is export_basedir/data
#
# 		) For the import server, import_basedir represents its base directory, and its data directory
# 			is import_basedir/data
#
# 		) Table files are exported from the export server into the /tmp/export directory and
# 			this directory is secure (not accessible to other users)
#
# 		) The import server uses /tmp/mysql-files as the directory named by its secure_file_priv
# 			system variable
#
# To export tables from the export server, use this procedure:
#
# 		1. Ensure a consistent snapshot by executing this statement to lock the tables so that they cannot
# 			be modified during export:
#
# 				FLUSH TABLES hr.employees, hr.managers WITH READ LOCK;
#
# 			While the lock is in effect, the tables can still be used, but only for read access.
#
# 		2. At the file system level, copy the .sdi and table content files from the hr schema directory
# 			to the secure export directory:
#
# 				) The .sdi file is located in the hr schema directory, but might not have exactly
# 					the same basename as the table name.
#
# 					For example, the .sdi files for the employees and managers tables might be named
# 					employees_125.sdi and managers_238.sdi
#
# 				) For a MyISAM table, the content files are its .MYD data file and .MYI index file
#
# 			Given those file names, the copy commands are:
#
# 				cd export_basedir/data/hr
# 				cp employees_125.sdi /tmp/export
# 				cp managers_238.sdi /tmp/export
# 				cp employees.{MYD,MYI} /tmp/export
# 				cp managers.{MYD,MYI} /tmp/export
#
# 		3. Unlock the tables:
#
# 			UNLOCK TABLES;
#
# To import tables into hte import server, use this procedure:
#
# 		1. The import schema must exist.
#
# 			If necessary, execute this statement to create it:
#
# 				CREATE SCHEMA hr;
#
# 		2. At the file system level, copy the .sdi files to the import server
# 			secure_file_priv directory, /tmp/mysql-files
#
# 			Also, copy the table content files to the hr schema directory:
#
# 				cd /tmp/export
# 				cp employees_125.sdi /tmp/mysql-files
# 				cp managers_238.sdi /tmp/mysql-files
# 				cp employees.{MYD,MYI} import_basedir/data/hr
# 				cp managers.{MYD,MYI} import_basedir/data/hr
#
# 		3. Import the tables by executing an IMPORT_TABLE statement that names the .sdi files:
#
# 			IMPORT TABLE FROM
# 				'/tmp/mysql-files/employees.sdi',
# 				'/tmp/mysql-files/managers.sdi';
#
# The .sdi file need not be placed in the import server directory named by the secure_file_priv
# system variable if that variable is empty; it can be in any directory accessible to the server,
# including the schema directory for the imported table.
#
# If the .sdi file is placed in that directory, however, it may be rewritten; the import
# operation creates a new .sdi file for hte table, which will overwrite the old .sdi file
# if hte operation uses the same file name for the new file.
#
# Each sdi_file value must be a string literal that names the .sdi file for a table
# or is a pattern that matches .sdi files.
#
# If the string is a pattern, any leading directory path and the .sdi file name
# suffix must be given literally.
#
# Pattern characters are permitted only in the base name part of the file name:
#
# 		) ? matches any single character
#
# 		) * matches any sequence of characters, including no characters
#
# Using a pattern, the previous IMPORT_TABLE statement could have been written like
# this (assuming that the /tmp/mysql-files directory contains no other .sdi files matching
# the pattern):
#
# 		IMPORT TABLE FROM '/tmp/mysql-files/*.sdi';
#
# To interpret the location of .sdi file path names, the server uses the same rules for
# IMPORT_TABLE as the server-side rules for LOAD_DATA (that is, the non-LOCAL rules)
#
# See SECTION 13.2.7, "LOAD DATA INFILE SYNTAX", paying particular attention to the
# rules used to interpret relative path names.
#
# IMPORT_TABLE fails if the .sdi or table files cannot be located.
#
# After importing a table, the server attempts to open it and reports
# as warnings any problems detected.
#
# To attempt a repair to correct any reported issues, use REPAIR_TABLE
#
# IMPORT_TABLE is not written to the binary log
#
# RESTRICTIONS AND LIMITATIONS
#
# IMPORT_TABLE applies only to non-TEMPORARY MyISAM tables.
#
# It does not apply to tables created with a transactional storage engine,
# tables created with CREATE_TEMPORARY_TABLE or views.
#
# The table data and index files must be placed in the schema directory for the
# import server prior to the import operation, unless the table as defined on the
# export server uses the DATA DIRECTORY or INDEX DIRECTORY table options.
#
# In that case, modify the import procedure using one of these alternatives
# before executing the IMPORT_TABLE statement:
#
# 		) Put the data and index files into the same directory on the import server
# 			host as on the export server host, and create symlinks in the import server
# 			schema directory to those files.
#
# 		) Put the data and index files into an import server host directory from that on the export
# 			server host, and create symlinks in the import server schema directory to those files.
#
# 			In addition, modify the .sdi file to reflect the different file locations
#
# 		) Put the data and index files into the schema directory on the import server host,
# 			and modify the .sdi file to remove the data and index directory table options.
#
# Any collation IDs stored in the .sdi file must refer to the same collations on the export
# and import servers.
#
# Trigger information for a table is not serialized into the table .sdi file, so triggers
# are not restored by the import operaiton
#
# Some edits to an .sdi file are permissible prior to executing the IMPORT_TABLE statement,
# whereas others are problematic or may even cause the import operation to fail:
#
# 		) Changing the data directory and index directory table options is required if the locations
# 			of the data and index files differ between the export and import servers.
#
# 		) Changing the schema name is required to import the table into a different schema on the import server
# 			tahn on the export server
#
# 		) Changing schema and table names may be required to accomodate differences between
# 			file system case-sensitivity semantics on the export and import servers or differences
# 			in lower_case_table_names settings.
#
# 			Changing the table names in the .sdi file may require renaming the tbale files as well
#
# 		) In some cases, changes to column definitions are permitted.
#
# 			Changing data types is likely to cause problems.
#
# 13.2.6 INSERT SYNTAX
#
# 13.2.6.1 INSERT --- SELECT SYNTAX
# 13.2.6.2 INSERT --- ON DUPLICATE KEY UPDATE SYNTAX
# 13.2.6.3 INSERT DELAYED SYNTAX
#
# 		INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]
# 			[INTO] tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			[(col_name [, col_name] ---)]
# 			{VALUES | VALUE} (value_list) [, (value_list)] ---
# 			[ON DUPLICATE KEY UPDATE assignment_list]
#
# 		INSERT [LOW_PRIORITY | DELAYED | HIGH_PRIORITY] [IGNORE]
# 			[INTO] tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			SET assignment_list
# 			[ON DUPLICATE KEY UPDATE assignment_list]
#
# 		INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]
# 			[INTO] tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			[(col_name [, col_name] ---)]
# 			SELECT ---
# 			[ON DUPLICATE KEY UPDATE assignment_list]
#
# 		value:
# 			{expr | DEFAULT}
#
# 		value_list:
# 			value [, value] ---
#
# 		assignment:
# 			col_name = value
#
# 		assignment_list:
# 			assignment [, assignment] ---
#
# INSERT inserts new rows into an existing table.
#
# The INSERT --- VALUES and INSERT --- SET forms of the statement insert rows based
# on explicitly specified values.
#
# The INSERT --- SELECT form inserts rows selected from another table or tables.
#
# INSERT with an ON DUPLICATE KEY UPDATE clause enables existing rows to be updated if
# a row to be inserted would cause a duplicate value in a UNIQUE index or PRIMARY KEY.
#
# For additional information about INSERT_---_SELECT and INSERT_---_ON_DUPLICATE_KEY_UPDATE,
# see SECTION 13.2.6.1, "INSERT --- SELECT SYNTAX", and SECTION 13.2.6.2, "INSERT --- ON DUPLICATE KEY UPDATE SYNTAX"
#
# In MySQL 8.0, the DELAYED keyword is accepted but ignored by the server.
#
# For the reasons for this, see SECTION 13.2.6.3, "INSERT DELAYED SYNTAX"
#
# Inserting into a table requires the INSERT privilege for the table. 
#
# If the ON DUPLICATE KEY UPDATE clause is used and a duplicate key causes an UPDATE to be performed instead, the statement
# requires the UPDATE privilege for the columns to be updated.
#
# For columns that are read but not modified you need only the SELECT privilege (such as for a column referenced only
# on the right hand side of an col_name=expr assignment in an ON DUPLICATE KEY UPDATE clause)
#
# When inserting into a partitioned table, you can control which partitions and subpartitions accept new rows.
#
# The PARTITION option takes a list of the comma-separated names of one or more partitions or subpartitions
# (or both) of the table.
#
# if any of hte rows to be inserted by a given INSERT statement do not match one of the partitions
# listed, the INSERT statement fails with the error:
#
# 		Found a row not matching the given partition set
#
# for more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# You can use REPLACE instead of INSERT to overwrite old rows.
#
# REPLACE is the counterpart to INSERT_IGNORE in teh treatment of new rows that
# contain unique key values that duplicate old rows:
#
# 		The new rows replace the old rows rather than being discarded.
#
# 		see SECTION 13.2.9, "REPLACE SYNTAX"
#
# tbl_name is the table into which rows should be inserted.
#
# Specify the columns for which the statement provides values as follows:
#
# 		) Provide a parenthesized list of comma-separated column names following
# 			the table name.
#
# 			In this case, a value for each named column must be provided by the 
# 			VALUES list or the SELECT statement.
#
# 		) If you do not specify a list of column names for INSERT_---_VALUES or
# 			INSERT_---_SELECT, values for every column in the table must be provided
# 			by the VALUES list or the SELECT statement.
#
# 			If you do not know the order of hte columns in the table, use DESCRIBE
# 			tbl_name to find out.
#
# 		) A SET clause indicates columns explicitly by name, together with the value
# 			to assign each one.
#
# Column values can be given in several ways:
#
# 		) If strict SQL mode is not enabled, any column not explicitly given a value is set
# 			to its default (explicit or implicit) value.
#
# 			For example, if you specify a column list that does not name all the columns
# 			in the table, unnamed columns are set to their default values.
#
# 			Default value assignment is described in SECTION 11.7, "DATA TYPE DEFAULT 
# 			VALUES"
#
# 			See also SECTION 1.8.3.3, "CONSTRAINTS ON INVALID DATA"
#
# 			If strict SQL mode is enabled, an INSERT statement generates an error
# 			if it does not specify an explicit value for every column that has no default
# 			value.
#
# 			See SECTION 5.1.11, "SERVER SQL MODES"
#
# 		) If both the column list and the VALUES list are empty, INSERT creates a row
# 			with each column set to its default value:
#
# 				INSERT INTO tbl_name () VALUES();
#
# 			If strict mode is not enabled, MySQL uses the implicit default value for any
# 			column that has no explicitly defined default.
#
# 			If strict mode is enabled, an error occurs if any column has no default value.
#
# 		) Use the keyword DEFAULT to set a column explicitly to its default value.
#
# 			This makes it easier to write INSERT statements that assign values to all
# 			but a few columns, because it enables you to avoid writing an incomplete VALUES
# 			list taht does not include a value for each column in the table.
#
# 			Otherwise, you must provide the list of column names corresponding to each
# 			value in the VALUES list.
#
# 		) If a generated column is inserted into explicitly, the only permitted value is DEFAULT.
#
# 			For information about generated columns, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
#
# 		) In expressions, you can use DEFAULT(col_name) to produce the default value for column col_name.
#
# 		) Type conversions of an expression expr that provides a column value might occur if the 
# 			expression data type does not match the column data type.
#
# 			Conversion of a given value can result in different inserted values depending on the column
# 			type.
#
# 			For example, inserting the string '1999.0e-2' into an INT, FLOAT, DECIMAL(10,6) or
# 			YEAR column inserts the value 1999, 19.9921, 19.992100, or 1999, respectively.
#
# 			The value stored in the INT and YEAR columns is 1999 because the string-to-number
# 			conversion looks only at as much of the initial part of the string as may be 
# 			considered a valid integer or year.
#
# 			For the FLOAT and DECIMAL columns, the string-to-number conversion considers the
# 			entire string a valid numeric value.
#
# 		) An expression expr can refer to any column that was set earlier in a value list.
#
# 			For example, you can do this because the value for col2 refers to col1, which has
# 			previously been assigned:
#
# 				INSERT INTO tbl_name (col1,col2) VALUES(15,col1*2);
#
# 			But the following is not legal, because the value for col1 refers to col2,
# 			which is assigned after col1:
#
# 				INSERT INTO tbl_name (col1, col2) VALUES(col2*2,15);
#
# 			An exception occurs for columns that contain AUTO_INCREMENT values.
#
# 			Because AUTO_INCREMENT values are generated after other value assignments,
# 			any reference to an AUTO_INCREMENT column in the assignment returns a 0.
#
# INSERT statements that use VALUES syntax can insert multiple rows.
#
# To do this, include multiple lists of comma-separated column values, with lists
# enclosed within parentheses and separated by commas.
#
# Example:
#
# 		INSERT INTO tbl_name (a,b,c) VALUES(1,2,3),(4,5,6),(7,8,9);
#
# Each value list must contain exactly as many values as are to be inserted per row.
#
# The following statement is invalid because it contains one list of nine values,
# rather than three lists of three values each:
#
# 		INSERT INTO tbl_name (a,b,c) VALUES(1,2,3,4,5,6,7,8,9);
#
# VALUE is a synonym for VALUES in this context.
#
# Neither implies anything about hte number of values lists, nor about the number of
# values per list.
#
# Either may be used whether there is a single values list or multiple lists, and
# regardless of the number of values per list.
#
# The affected-rows value for an INSERT can be obtained using the ROW_COUNT() SQL
# function or the mysql_affected_rows() C API function.
#
# See SECTION 12.15, "INFORMATION FUNCTIONS" and SECTION 28.7.7.1, "MYSQL_AFFECTED_ROWS()"
#
# If you use an INSERT_---_VALUES statement with multiple value lists or INSERT_---_SELECT,
# the statement returns an information string in this format:
#
# 		Records: N1 Duplicates: N2 Warnings: N3
#
# If you are using the C API, the information string can be obtained by invoking the
# mysql_info() function.
#
# See SECTION 28.7.7.36, "MYSQL_INFO()"
#
# Records indicate the number of rows processed by the statement.
#
# (This is not necessarily the number of rows actually inserted because 
# Duplicates can be nonzero)
#
# Duplicates indicates the number of rows that could not be inserted because they would
# duplicate some existing unique index value.
#
# Warnings indicate the number of attempts to insert column values that were problematic
# in some way.
#
# Warnings can occur under any of the following conditions:
#
# 		) Inserting NULL into a column that has been declared NOT NULL.
#
# 			For multiple-row INSERT statements or INSERT_INTO_---_SELECT statements,
# 			the column is set to the implicit default value for the column data type.
#
# 			This is 0 for numeric types, the empty string ('') for string types, and the
# 			"zero" value for date and time types.
#
# 			INSERT INTO --- SELECT statements are handled the same way as multiple-row inserts
# 			because the server does not examine the result set from the SELECT to see whether it
# 			returns a single row.
#
# 			(For a single-row INSERT, no warning occurs when NULL is inserted into a NOT NULL column.
#
# 			Instead, the statement fails with an error)
#
# 		) Setting a numeric column to a value that lies outside the column's range.
#
# 			The value is clipped to the closest endpoint of the range.
#
# 		) Assigning a value such as '10.34 a' to a numeric column.
#
# 			The trailing nonnumeric text is stripped off and the remaining numeric part
# 			is inserted.
#
# 			If the string value has no leading numeric part, the column is set to 0.
#
# 		) Inserting a string into a string column (CHAR, VARCHAR, TEXT or BLOB) that exceeds
# 			the column's maximum length.
#
# 			The value is truncated to the column's maximum length
#
# 		) Inserting a value into a date or time column that is illegal for the data type.
#
# 			The column is set to the appropriate zero value for the type.
#
# 		) For INSERT examples involving AUTO_INCREMENT column values, see SECTION 3.6.9, "USING AUTO_INCREMENT"
#
# 			If INSERT inserts a row into a table that has an AUTO_INCREMENT column, you can find
# 			the value used for that column by using the LAST_INSERT_ID() SQL function or the
# 			mysql_insert_id() C API function.
#
# 				NOTE:
#
# 					These two functions do not always behave identically.
#
# 					The behavior of INSERT statements with respect to AUTO_INCREMENT columns is discussed
# 					further in SECTION 12.15, "INFORMATION FUNCTIONS", and SECTION 28.7.7.38, "MYSQL_INSERT_ID()"
#
# The INSERT statement supports the following modifiers:
#
# 		) if you use the LOW_PRIORITY modifier, execution of the INSERT is delayed until no other
# 			clients are reading from the table.
#
# 			This includes other clients that began reading while existing clients are reading;
# 			and while the INSERT LOW_PRIORITY statement is waiting.
#
# 			It is possible, therefore, for a client that issues an INSERT LOW_PRIORITY
# 			statement to wait or a very long time.
#
# 			LOW_PRIORITY affects only storage engines that use only table-level locking 
# 			(such as MyISAM, MEMORY, and MERGE)
#
# 			NOTE:
#
# 				LOW_PRIORITY should normally not be used with MyISAM tables because doing so
# 				disables concurrent inserts.
#
# 				See SECTION 8.11.3, "CONCURRENT INSERTS"
#
# 		) If  you specify HIGH_PRIORITY, it overrides the effect of the --low-priority-updates option if
# 			the server was started with that option.
#
# 			It also causes concurrent inserts not to be used.
#
# 			See SECTION 8.11.3, "CONCURRENT INSERTS"
#
# 			HIGH_PRIORITY affects only storage engines that use only table-level locking
# 			(such as MyISAM, MEMORY, and MERGE)
#
# 		) If you use the IGNORE modifier, errors that occur while executing the INSERT statement
# 			are ignored.
#
# 			For example, without IGNORE, a row that duplicates an existing UNIQUE index or PRIMARY KEY
# 			value in the table causes a duplicate-key error and the statement is aborted.
#
# 			With IGNORE, the row is discarded and no error occurs.
#
# 			Ignored errors generate warnings instead.
#
# 			IGNORE has a similar effect on inserts into partitioned tables where no partition matching
# 			a given value is found.
#
# 			Without IGNORE, such INSERT statements are aborted with an error.
#
# 			When INSERT_IGNORE is used, the insert operation fails silently for rows containing
# 			the unmatched value, but inserts rows that are matched.
#
# 			For an example, see SECTION 23.2.2, "LIST PARTITIONING"
#
# 			Data conversions that would trigger errors abort the statement if IGNORE is not specified.
#
# 			With IGNORE, invalid values are adjusted to the closest values and inserted;
# 			warnings are produced but the statement does not abort.
#
# 			You can determine with the mysql_info() C API function how many rows were actually
# 			inserted into the table.
#
# 			For more information, see COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE
#
# 		) If you specify ON DUPLICATE KEY UPDATE, and a row is inserted that would cause a duplicate value
# 			in a UNIQUE index or PRIMARY KEY, an UPDATE of the old row occurs.
#
# 			The affected-rows value per row is 1 if the row is inserted as a new row, 2 if an existing
# 			row is updated, and 0 if an existing row is set to its current values.
#
# 			If you specify the CLIENT_FOUND_ROWS flag to the mysql_real_connect() C API function
# 			when connecting to mysqld, the affected-rows value is 1 (not 0) if an existing row
# 			is set to its current values.
#
# 			See SECTION 13.2.6.2, "INSERT --- ON DUPLICATE KEY UPDATE SYNTAX"
#
# 		) INSERT_DELAYED was deprecated in MySQL 5.6, and is scheduled for eventual removal.
#
# 			In MySQL 8.0, the DELAYED modifier is accepted but ignored.
#
# 			Use INSERT (without DELAYED) instead. See SECTION 13.2.6.3, "INSERT DELAYED SYNTAX"
#
# An INSERT statement affecting a partitioned table using a storage engine such as MyISAM that
# employs table-level locks locks only those partitions into which rows are actually inserted.
#
# (For storage engines such as InnoDB that employ row-level locking, no locking of partitions takes place)
#
# For more information, see PARTITIONING AND LOCKING.
#
# 13.2.6.1 INSERT --- SELECT SYNTAX
#
# 		INSERT [LOW_PRIORITY | HIGH_PRIORITY] [IGNORE]
# 			[INTO] tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			[(col_name [, col_name] ---)]
# 			SELECT
# 			[ON DUPLICATE KEY UPDATE assignment_list]
#
# 		value:
# 			{expr | DEFAULT}
#
# 		assignment:
# 			col_name = value
#
# 		assignment_list:
# 			assignment [, assignment]
#
# With INSERT_---_SELECT, you can quickly insert many rows into a table from the result
# of a SELECT statement, which can select from one or many tables.
#
# For example:
#
# 		INSERT INTO tbl_temp2 (fld_id)
# 			SELECT tbl_temp1.fld_order_id
# 			FROM tbl_temp1 WHERE tbl_temp1.fld_order_id > 100;
#
# The following conditions hold for INSERT_---_SELECT statements:
#
# 		) Specify IGNORE to ignore rows that would cause duplicate-key violations
#
# 		) The target table of the INSERT statement may appear in the FROM clause of the
# 			SELECT part of the query.
#
# 			However, you cannot insert into a table and select from the same table in a
# 			subquery.
#
# 			When selecting from and inserting into the same table, MySQL creates an internal
# 			temporary table to hold the rows from the SELECT and then inserts those rows
# 			into the target table.
#
# 			However, you cannot use INSERT INTO t --- SELECT --- FROM t when t is a TEMPORARY
# 			table, because TEMPORARY tables cannot be referred to twice in the same statement.
#
# 			See SECTION 8.4.4, "INTERNAL TEMPORARY TABLE USE IN MYSQL", and SECTION B.6.6.2,
# 			"TEMPORARY TABLE PROBLEMS"
#
# 		) AUTO_INCREMENT columns work as usual
#
# 		) To ensure that the binary log can be used to re-create the original tables,
# 			MySQL does not permit concurrent inserts for INSERT_---_SELECT statements
# 			(see SECTION 8.11.3, "CONCURRENT INSERTS")
#
# 		) To avoid ambiguous column reference problems when the SELECT and the INSERT
# 			refer to the same table, provide a unique alias for each table used in the 
# 			SELECT part, and qualify column names in that part with the appropriate alias.
#
# You can explicitly select which partitions or subpartitions (or both) of the source or target
# table (or both) are to be used with a PARTITION option following the name of the table.
#
# When PARTITION is used with the name of the source table in the SELECT portion of the statement,
# rows are selected only from the partitions or subpartitions named in its partition list.
#
# When PARTITION is used with the name of the target table for the INSERT portion of the statement,
# it must be possible to insert all rows selected into the partitions or subpartitions named in the
# partition list following the option.
#
# Otherwise, the INSERT --- SELECT statement fails.
#
# For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# For INSERT_---_SELECT statements, see SECTION 13.2.6.2, "INSERT --- ON DUPLICATE KEY UPDATE SYNTAX"
# for conditions under which the SELECT columns can be referred to in an ON DUPLICATE KEY UPDATE clause.
#
# The order in which a SELECT statement with no ORDER BY clause returns rows is nondeterminsitic.
#
# This means that, when using replication, there is no guarantee that such a SELECT returns rows
# in the same order on the master and the slave, which can lead to inconsistencies between them.
#
# To prevent this from occurring, always write INSERT --- SELECT statements that are to be replicated
# using an ORDER BY clause that produces the same row order on the master and the slave.
#
# See also SECTION 17.4.1.18, "REPLICATION AND LIMIT"
#
# Due to this issue, INSERT_---_SELECT_ON_DUPLICATE_KEY_UPDATE and INSERT_IGNORE_---_SELECT
# statements are flagged as unsafe for statement-based replication.
#
# Such statements produce a warning in the error log when using statement-based mode
# and are written to the binary log using the row-based formats when using MIXED
# mode. (Bug #11758262, Bug #50439)
#
# See also SECTION 17.2.1.1, "ADVANTAGES AND DISADVANTAGES OF STATEMENT-BASED AND ROW-BASED REPLICATION"
#
# An INSERT_---_SELECT statement affecting partitioned tables using a storage engine such as
# MyISAM that employs table-level locks locks all partitions of the target table;
# However, only those partitions that are actually read from the source table are locked.
#
# (This does not occur with tables using storage engines such as InnoDB that employ
# row-level locking)
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.6.2 INSERT --- ON DUPLICATE KEY UPDATE SYNTAX
#
# If you specify an ON DUPLICATE KEY UPDATE clause and a row to be inserted would cause a 
# duplicate value in a UNIQUE index or PRIMARY KEY, an UPDATE of the old row occurs.
#
# For example, if column a is declared as UNIQUE and contains the value 1, the following
# two statements have similar effect:
#
# 		INSERT INTO t1 (a,b,c) VALUES (1,2,3)
# 			ON DUPLICATE KEY UPDATE c=c+1;
#
# 		UPDATE t1 SET c=c+1 WHERE a=1;
#
# (The effects are not identical for an InnoDB table where a is an auto-increment column.
#
# With an auto-increment column, an INSERT statement increases the auto-increment
# value but UPDATE does not)
#
# If column b is also unique, the INSERT is equivalent to this UPDATE statement instead:
#
# 		UPDATE t1 SET c=c+1 WHERE a=1 OR b=2 LIMIT 1;
#
# If a=1 OR b=2 matches several rows, only one row is updated.
#
# In general, you should try to avoid using an ON DUPLICATE KEY UPDATE clause
# on tables with multiple unique indexes.
#
# With ON DUPLICATE KEY UPDATE, the affected-rows value per row is 1 if the row
# is inserted as a new row, 2 if an existing row is updated, and 0 if an existing
# row is set to its current values.
#
# If you specify the CLIENT_FOUND_ROWS flag to the mysql_real_connect() C API function
# when connecting to mysqld, the affected-rows value is 1 (not 0) if an existing
# row is set to its current values.
#
# If a table contains an AUTO_INCREMENT column and INSERT_---_ON_DUPLICATE_KEY_UPDATE inserts
# or updates a row, the LAST_INSERT_ID() function returns the AUTO_INCREMENT value.
#
# The ON DUPLICATE KEY UPDATE clause can contain multiple column assignments,
# separated by commas.
#
# In assignment value expressions in the ON DUPLICATE KEY UPDATE clause, you can use
# the VALUES(col name) function to refer to column values from the INSERT portion
# of the INSERT_---_ON_DUPLICATE_KEY_UPDATE statement.
#
# In other words, VALUES(col_name) in the ON DUPLICATE KEY UPDATE clause refers
# to the value of col_name that would be inserted, had no duplicate-key conflict
# occurred.
#
# This function is especially useful in multiple-row inserts.
#
# The VALUES() function is meaningful only in the ON DUPLICATE KEY UPDATE clause
# or INSERT statements and returns NULL otherwise. Example:
#
# 		INSERT INTO t1 (a,b,c) VALUES (1,2,3),(4,5,6)
# 			ON DUPLICATE KEY UPDATE c=VALUES(a)+VALUES(b);
#
# That statement is identical to the following two statements:
#
# 		INSERT INTO t1 (a,b,c) VALUES (1,2,3)
# 			ON DUPLICATE KEY UPDATE c=3;
#
# 		INSERT INTO t1 (a,b,c) VALUES (4,5,6)
# 			ON DUPLICATE KEY UPDATE c=9;
#
# For INSERT_---_SELECT statements, these rules apply regarding acceptable forms
# of SELECT query expressions that you can refer to in an ON DUPLICATE KEY UPDATE
# clause:
#
# 		) References to columns from queries on a single table, which may be a derived table
#
# 		) References to columns from queries on a join over multiple tables
#
# 		) References to columns from DISTINCT queries
#
# 		) References to columns in other tables, as long as the SELECT does not use GROUP BY.
#
# 			One side effect is that you must qualify references to nonunique column names.
#
# References to columns from a UNION are not supported.
#
# To work around this restriction, rewrite the UNION as a derived table so that its rows
# can be treated as a single-table result set.
#
# For example, this statement produces an error:
#
# 		INSERT INTO t1 (a, b)
# 			SELECT c, d FROM t2
# 			UNION
# 			SELECT e, f FROM t3
# 		ON DUPLICATE KEY UPDATE b = b + c;
#
# Instead, use an equivalent statement that rewrites the UNION as a derived table:
#
# 		INSERT INTO t1 (a, b)
# 		SELECT * FROM
# 			(SELECT c, d FROM t2
# 			UNION
# 			SELECT e, f FROM t3) AS dt
# 		ON DUPLICATE KEY UPDATE b = b + c;
#
# The technique of rewriting a query as a derived table also enables references
# to columns from GROUP BY queries.
#
# Because the results of INSERT_---_SELECT statements depend on the ordering of rows
# from the SELECT and this order cannot always be guaranteed, it is possible when
# logging INSERT_---_SELECT_ON_DUPLICATE_KEY_UPDATE statements for the master
# and the slave to diverge.
#
# Thus, INSERT_---_SELECT_ON_DUPLICATE_KEY_UPDATE statements are flagged as unsafe
# for statement-based replication.
#
# Such statements produce a warning in the error log when using statement-based mode
# and are written to the binary log using the row-based format when using MIXED mode.
#
# An INSERT_---_ON_DUPLICATE_KEY_UPDATE statement against a table having more than
# one unique or primary key is also marked as unsafe. (Bug #117655650, Bug #58637)
#
# See also SECTION 17.2.1.1, "ADAVANTAGES AND DISADVANTAGES OF STATEMENT-BASED AND 
# ROW-BASED REPLICATION"
#
# An INSERT --- ON DUPLICATE KEY UPDATE on a partitioned table using a storage engine
# such as MyISAM that employs table-level locks locks any partitions of the table
# in which a partitioning key column is updated.
#
# (This does not occur with tables using storage engines such as InnoDB that employ
# row-level locking)
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.6.3 INSERT DELAYED SYNTAX
#
# INSERT DELAYED ---
#
# The DELAYED option for the INSERT statement is a MySQL extension to standard SQL
#
# In previous versions of MySQL, it can be used for certain kinds of tables (such as
# MyISAM), such that when a client uses INSERT_DELAYED, it gets an okay from the server
# at once, and the row is queued to be inserted when the table is not in use by any
# other thread.
#
# DELAYED inserts and replaces were deprecated in MySQL 5.6
#
# In MySQL 8.0, DELAYED is not supported.
#
# The server recognizes but ignores the DELAYED keyword, handles the insert
# as a nondelayed insert, and generates an ER_WARN_LEGACY_SYNTAX_CONVERTED
# warning ("INSERT DELAYED is no longer supported. The statement was converted to INSERT")
#
# The DELAYED keyword is scheduled for removal in a future release.
#
# 13.2.7 LOAD DATA INFILE SYNTAX
#
# 		LOAD DATA [LOW_PRIORITY | CONCURRENT] [LOCAL] INFILE 'file_name'
# 			[REPLACE | IGNORE]
# 			INTO TABLE tbl_name
# 			[PARTITION (partition_name [, partition_name] ---)]
# 			[CHARACTER SET charset_name]
# 			[{FIELDS | COLUMNS}
# 				[TERMINATED BY 'string']
# 				[[OPTIONALLY] ENCLOSED BY 'char']
# 				[ESCAPED BY 'char']
# 			]
# 			[LINES
# 				[STARTING BY 'string']
# 				[TERMINATED BY 'string']
# 			]
# 			[IGNORE number {LINES | ROWS}]
# 			[(col_name_or_user_var
# 				[,col_name_or_user_var] ---)]
# 			[SET col_name={expr | DEFAULT},
# 				[, col_name={expr | DEFAULT}] ---]
#
# The LOAD_DATA_INFILE statement reads rows from a text file into a table at 
# a very high speed.
#
# LOAD_DATA_INFILE is the complement of SELECT_---_INTO_OUTFILE 
#
# (See SECTION 13.2.10.1, "SELECT --- INTO SYNTAX")
#
# To write data from a table to a file, use SELECT_---_INTO_OUTFILE
#
# To read the file back into a table, use LOAD_DATA_INFILE 
#
# The syntax of the FIELDS and LINES clauses is the same for both statements
#
# You can also load data files by using the mysqlimport utility;
#
# See SECTION 4.5.5, "MYSQLIMPORT -- A DATA IMPORT PROGRAM"
#
# mysqlimport operates by sending a LOAD_DATA_INFILE statement to the server.
#
# The --local option causes mysqlimport to read data files from the client host.
#
# You can specify the --compress option to get better performance over slow
# networks if the client and server support the compressed protocol.
#
# For more information about the efficiency of INSERT versus LOAD_DATA_INFILE and
# speeding up LOAD_DATA_INFILE, see SECTION 8.2.5.1, "OPTIMIZING INSERT STATEMENTS"
#
# 		) PARTITIONED TABLE SUPPORT
#
# 		) INPUT FILE NAME, LOCATION, AND CONTENT INTERPRETATION
#
# 		) CONCURRENCY CONSIDERATIONS
#
# 		) DUPLICATE-KEY HANDLING
#
# 		) INDEX HANDLING
#
# 		) FIELD AND LINE HANDLING
#
# 		) COLUMN LIST SPECIFICATION
#
# 		) INPUT PREPROCESSING
#
# 		) STATEMENT RESULT INFORMATION
#
# 		) MISCELLANEOUS TOPICS
#
# PARTITIONED TABLE SUPPORT
#
# LOAD DATA supports explicit partition selection using the PARTITION option with
# a list of one or more comma-separated names of partitions, subpartitions, or both.
#
# When this option is used, if any rows from the file cannot be inserted into any of
# the partitions or subpartitions named in the list, the statement fails with the
# error:
#
# 		Found a row not matching the given partition set
#
# For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# For partitioned tables using storage engines taht employ table locks, such as
# MyISAM, LOAD DATA cannot prune any partition locks.
#
# This does not apply to tables using storage engines which employ row-level
# locking, such as InnoDB.
#
# For more information, see PARTITIONING AND LOCKING.
#
# INPUT FILE NAME, LOCATION AND CONTENT INTERPRETATION
#
# The file name must be given as a literal string.
#
# On Windows, specify backslashes in path names as forward slashes or doubled
# backslashes.
#
# The character_set_filesystem system variable controls the interpretation of
# the file name character set.
#
# The server uses the character set indicated by the character_set_database system
# variable to interpret the information in the file.
#
# SET_NAMES and the setting of character_set_client do not affect interpretation of
# input.
#
# If the contents of the input file use a character set that differs from teh default,
# it is usually preferable to specify the character set of the files by using the
# CHARACTER SET clause.
#
# A character set of binary specifies "no conversion"
#
# LOAD_DATA_INFILE interprets all fields in the file as having the same character set,
# regardless of hte data types of the columns into which field values are loaded.
#
# For proper interpretation of file contents, you must ensure that it was written
# with the correct character set.
#
# For example, if you write a data file with mysqldump -T or by issuing
# a SELECT_---_INTO_OUTFILE statement in Mysql, be sure to use a --default-character-set
# option so that output is written in the character set to be used when the file
# is loaded with LOAD_DATA_INFILE.
#
# 	NOTE:
#
# 		It is not possible to load data files that use the ucs2, utf16, utf16le, or utf32 character set.
#
# CONCURRENCY CONSIDERATIONS
#
# If you use LOW_PRIORITY, execution of the LOAD_DATA statement is delayed until no other clients
# are reading from the table.
#
# This affects only storage engines that use only table-level locking (such as MyISAM, MEMORY and MERGE)
#
# If you specify CONCURRENT with a MyISAM table that satisfies the condition for the concurrent
# inserts (that is, it contains no free blocks in the middle), other threads can retrieve
# data from the table while LOAD_DATA is executing.
#
# This option affects the performance of LOAD_DATA a bit, even if no other thread
# is using the table at the same time.
#
# With row-based replication, CONCURRENT is replicated regardless of MySQL version.
#
# With statement-based replication CONCURRENT is not replicated prior to MySQL 5.5.1
# (see Bug #34628)
#
# For more information, see SECTION 17.4.1.19,, "REPLICATION AND LOAD DATA INFILE"
#
# The LOCAL keyword affects expected location of the file and error handling, as described
# later.
#
# LOCAL works only if your server and your client both have been configured to permit it.
#
# For example, if mysqld was started with the local_infile system variable disabled,
# LOCAL does not work.
#
# See SECTION 6.1.6, "SECURITY ISSUES WITH LOAD DATA LOCAL"
#
# The LOCAL keyword affects where the file is expected to be found:
#
# 		) If LOCAL is specified, the file is read by the client program on the client
# 			host and sent to the server.
#
# 			The file can be given as a full path name to specify its exact location.
#
# 			If given as a relative path name, the name is interpreted relative to the
# 			directory in which the client program was started.
#
# 			When using LOCAL with LOAD_DATA, a copy of the file is created in the directory
# 			where the MySQL server stores temporary files.
#
# 			See SECTION B.6.3.5, "WHERE MySQL STORES TEMPORARY FILES"
#
# 			Lack of sufficient space for the copy in this directory can cause the LOAD_DATA_LOCAL
# 			statement to fail.
#
# 		) If LOCAL is not specified, the file must be located on the server host and is read directly
# 			by the server.
#
# 			The server uses the following rules to locate the file:
#
# 				) If the file name is an absolute path name, the server uses it as given
#
# 				) If the file name is a relative path name with one or more leading components,
# 					the server searches for the file relative to the server's data directory.
#
# 				) If a file name with no leading components is given, the server looks for the file
# 					in the database directory of the default database.
#
# In the non-LOCAL case, these rules mean that a file named as ./myfile.txt is read from the
# server's data directory, whereas the file named as myfile.txt is read from the database
# directory of the default database.
#
# For example, if db1 is the default database, the following LOAD_DATA statement reads the
# file data.txt from the database directory for db1, even though the statement explicitly
# loads the file into a table in the db2 database:
#
# 		LOAD DATA INFILE 'data.txt' INTO TABLE db2.my_table;
#
# NOTE:
#
# 		The server also uses the non-LOCAL rules to locate .sdi files for the IMPORT_TABLE statement
#
# Non-LOCAL load operations read text files located on the server.
#
# For security reasons, such operations require that you have the FILE privilege.
#
# See SECTION 6.2.1, "PRIVILEGES PROVIDED BY MYSQL"
#
# Also, non-LOCAL load operations are subject to the secure_file_priv system variable
# setting.
#
# If the variable value is a nonempty directory name, the file to be loaded must be located
# in that directory.
#
# If the variable value is empty (which is insecure), the file need only be readable by the server.
#
# Using LOCAL is a bit slower than letting the server access the files directly, because the contents
# of the file must be sent over the connection by the client to the server.
#
# On the other hand, you do not need the FILE privilege to load local files.
#
# LOCAL also affects error handling:
#
# 		) With LOAD_DATA_INFILE, data-interpretation and duplicate-key errors terminate the operation
#
# 		) With LOAD_DATA_LOCAL_INFILE, data-interpretation and duplicate-key errors become warnings and 
# 			the operation continues because the server has no way to stop transmission of the file
# 			in the middle of the operation.
#
# 			For duplicate-key errors, this is the same as if IGNORE is specified.
#
# 			IGNORE is explained further later in this section.
#
# DUPLICATE-KEY HANDLING
#
# The REPLACE and IGNORE keywords control handling of input rows that duplicate existing rows
# on unique key values:
#
# 		) If you specify REPLACE, input rows replace existing rows.
#
# 			In other words, rows that have the same value for a primary key or unique index
# 			as an existing row.
#
# 			See SECTION 13.2.9, "REPLACE SYNTAX"
#
# 		) If you specify IGNORE, rows that duplicate an existing row on a unique key value
# 			are discarded.
#
# 			For more information, see COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE
#
# 		) If you do not specify either option, the behavior depends on whether the LOCAL keyword
# 			is specified.
#
# 			Without LOCAL, an error occurs when a duplicate key value is found, and the rest of
# 			the text file is ignored.
#
# 			With LOCAL, the default behavior is the same as if IGNORE is specified;
#
# 			This is because the server has no way to stop transmission of the file in the
# 			middle of the operation.
#
# INDEX HANDLING
#
# To ignore foreign key constraints during the load operation, issue a SET foreign_key_checks = 0
# statement before executing LOAD_DATA
#
# If you use LOAD_DATA_INFILE on an empty MyISAM table, all nonunique indexes are created
# in a separate batch (as for REPAIR TABLE)
#
# Normally, this makes LOAD_DATA INFILE much faster when you have many indexes.
#
# In some extreme cases, you can create the indexes even faster by turning them
# off with ALTER TABLE --- DISABLE KEYS before loading the file into the table
# and using ALTER TABLE --- ENABLE KEYS to re-create the indexes after loading
# the file.
#
# See SECTION 8.2.5.1, "OPTIMIZING INSERT STATEMENTS"
#
# FILE AND LINE HANDLING
#
# For both the LOAD_DATA_INFILE and SELECT_---_INTO_OUTFILE statements, the syntax
# of the FIELDS and LINES clauses is the same.
#
# Both clauses are optional, but FIELDS must precede LINES if both are specified.
#
# If you specify a FIELDS clause, each of its subclauses (TERMINATED BY, [OPTIONALLY]
# ENCLOSED BY, and ESCAPED BY) is also optional, except that you must specify
# at least one of them. 
# 
# Arguments to these clauses are permitted to contain only ASCII characters.
#
# If you specify no FIELDS or LINES clause, the defaults are the same as if you had
# written this:
#
# 		FIELDS TERMINATED BY '\t' ENCLOSED BY '' ESCAPED BY '\\'
# 		LINES TERMINATED BY '\n' STARTING BY ''
#
# (Backslash is the MySQL escape character within strings in SQL statements, so to specify
# a literal backslash, you must specify two backslashes for the value to be interpreted
# as a single backslash.
#
# The escape sequences '\t' and '\n' specify tab and newline characters, respectively.)
#
# In other words, the default cause LOAD_DATA_INFILE to act as follows when reading input:
#
# 		) Look for line boundaries at newlines
#
# 		) Do not skip over any line prefix
#
# 		) Break lines into fields at tabs
#
# 		) Do not expect fields to be enclosed within any quoting characters
#
# 		) Interpret characters preceded by the escape character \ as escape sequences.
#
# 			For example, \t, \n, and \\ signify tab, newline, and backslash, respectively.
#
# 			See the discussion of FIELDS ESCAPED BY later for the full list of escape sequences.
#
# Conversely, the defaults cause SELECT_---_INTO_OUTFILE to act as follows when writing output:
#
# 		) Write tabs between fields
#
# 		) Do not enclose fields within any quoting characters
#
# 		) Use \ to escape instances of tab, newline, or \ that occur within field values.
#
# 		) Write newlines at the ends of lines.
#
# NOTE:
#
# 		If you have generated the text file on a Windows system, you might have to use LINES TERMINATED
# 		BY '\r\n' to read the file properly because Windows programs typically use two characters
# 		as a line terminator.
#
# 		Some programs, such as WordPad, might use \r as a line terminator when writing files
#
# 		To read such files, use LINES TERMINATED BY '\r'
#
# If all the lines you want to read in have a common prefix that you want to ignore, you can use
# LINES STARTING BY 'prefix_string' to skip over the prefix, and anything before it.
#
# If a line does not include the prefix, the entire line is skipped.
#
# Suppose that you issue the following statement:
#
# 		LOAD DATA INFILE '/tmp/test.txt' INTO TABLE test
# 			FIELDS TERMINATED BY ',' LINES STARTING BY 'xxx';
#
# If the data file looks like this:
#
# 		xxx"abc",1
# 		something xxx"def",2
# 		"ghi",3
#
# The resulting rows will be ("abc",1) and ("def",2)
#
# The third row in the file is skipped because it does not contain the prefix.
#
# The IGNORE number LINES option can be used to ignore lines at the start of the file.
#
# For example, you can use IGNORE 1 LINES to skip over an initial header line containing
# column names:
#
# 		LOAD DATA INFILE '/tmp/test.txt' INTO TABLE test IGNORE 1 LINES;
#
# When you use SELECT_---_INTO_OUTFILE in tandem with LOAD_DATA_INFILE to write data
# from a database into a file and then read the file back into the database later,
# the field- and line-handling options for both statements must match.
#
# Otherwise, LOAD_DATA_INFILE will not interpret the contents of the file properly.
#
# Suppose that you use SELECT_---_INTO_OUTFILE to write a file with fields delimited
# by commas:
#
# 		SELECT * INTO OUTFILE 'data.txt'
# 			FIELDS TERMINATED BY ','
# 			FROM table2;
#
# To read the comma-delimited file back in, the correct statement would be:
#
# 		LOAD DATA INFILE 'data.txt' INTO TABLE table2
# 			FIELDS TERMINATED BY ',';
#
# If instead you tried to read in the file with the statement shown following,
# it would not work because it instructs LOAD_DATA_INFILE to look for tabs
# between fields:
#
# 		LOAD DATA INFILE 'data.txt' INTO TABLE table2
# 			FIELDS TERMINATED BY '\t';
#
# The likely result is that each input line would be interpreted as a single field.
#
# LOAD_DATA_INFILE can be used to read files obtained from external sources.
#
# For example, many programs can export data in comma-separated values (CSV) format,
# such that lines have fields separated by commas and enclosed within double quotation
# marks, with an initial line of column names.
#
# If the lines in such a file are terminated by carriage return/newline pairs,
# the statement shown here illustrates the field- and line-handling options
# you would use to load the file:
#
# 		LOAD DATA INFILE 'data.txt' INTO TABLE tbl_name
# 			FIELDS TERMINATED BY ',' ENCLOSED BY '"'
# 			LINES TERMINATED BY '\r\n'
# 			IGNORE 1 LINES;
#
# If the input values are not necessarily enclosed within quotation marks,
# use OPTIONALLY before the ENCLOSED BY keywords.
#
# Any of the field- or line-handling options can specify an empty string
# ('')
#
# If not empty, the FIELDS [OPTIONALLY] ENCLOSED BY and FIELDS ESCAPED BY
# values must be a single character.
#
# The FIELDS TERMINATED BY, LINES STARTING BY, and LINES TERMINATED BY values
# can be more than one character.
#
# For example, to write lines that are terminated by carriage return/linefeed
# pairs, or to read a file containing such lines, specify a LINES TERMINATED BY '\r\n'
# clause.
#
# To read a file containing jokes that are separated by lines consisting of 
# %%, you can do this:
#
# 		CREATE TABLE jokes
# 			(a INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 			joke TEXT NOT NULL);
# 		LOAD DATA INFILE '/tmp/jokes.txt' INTO TABLE jokes
# 			FIELDS TERMINATED BY ''
# 			LINES TERMINATED BY '\n%%\n' (joke);
#
# FIELDS [OPTIONALLY] ENCLOSED BY controls quoting of fields.
#
# For output (SELECT --- INTO OUTFILE), if you omit the word OPTIONALLY,
# all fields are enclosed by the ENCLOSED BY character.
#
# An example of such output (using a comma as the field delimiter)
# is shown here:
#
# 		"1","a string","100.20"
# 		"2","a string containing a , comma","102.20"
# 		"3","a string containing a \" quote","102.20"
# 		"4","a string containing a \", quote and comma","102.20"
#
# If you specify OPTIONALLY, the ENCLOSED BY character is used only to enclose values
# from columns that have a string data type (such as CHAR, BINARY, TEXT or ENUM):
#
# 		1,"a string",100.20
# 		2,"a string containing a , comma",102.20
# 		3,"a string containing a \" quote",102.20
# 		4,"a string containing a \", quote and comma",102.20
#
# Occurrences of the ENCLOSED BY character within a field value are escaped by
# prefixing them with the ESCAPED BY character.
#
# Also, if you specify an empty ESCAPED BY value, it is possible to inadvertedly
# generate output that cannot be read properly by LOAD_DATA_INFILE
#
# For example, the preceding output just shown would appear as follows
# if the escape character is empty.
#
# Observe that the second field in the fourth line contains a comma following
# the quote, which (errorneously) appears to terminate the field:
#
# 		1,"a string",100.20
# 		2,"a string containing a , comma",102.20
# 		3,"a string containing a " quote",102.20
# 		4,"a string containing a ", quote and comma",102.20
#
# For input, the ENCLOSED BY character, if present, is stripped from the ends of field values.
#
# (This is true regardless of whether OPTIONALLY is specified; OPTIONALLY has no effect on
# input interpretation)
#
# Occurrences of the ENCLOSED BY character preceded by the ESCAPED BY character
# are interpreted as part of the current field value.
#
# If the field begins with the ENCLOSED BY character, instances of that character
# are recognized as terminating a field value only if followed by the field or
# line TERMINATED BY sequence.
#
# To avoid ambiguity, occurrences of the ENCLOSED BY character within a field value
# can be doubled and are interpreted as a single instance of the character.
#
# For example, if ENCLOSED BY '"' is specified, quotation marks are handled as shown here:
#
# 		"The ""BIG"" boss" 	-> The "BIG" boss
# 		
# 		The "BIG" boss 		-> The "BIG" boss
#
# 		The ""BIG"" boss 		-> The ""BIG"" boss
#
# FIELDS ESCAPED BY controls how to read or write special characters:
#
# 		) For input, if the FIELDS ESCAPED BY character is not empty, occurences
# 			of that character are stripped and the following character is taken
# 			literally as part of a field value.
#
# 			Some two-character sequences that are exceptions, where the first character
# 			is the escape character.
#
# 			These sequences are shown in the following table (using \ for the escape character)
#
# 			The rules for NULL handling are described later in this section.
#
# 				CHARACTER 	ESCAPE SEQUENCE
# 
#  			\0 			An ASCII NUL (X'00') character
#
# 				\b 			a backspace character
#
# 				\n 			A newline (linefeed) character
#
# 				\r 			A carriage return character
#
# 				\t 			A tab character
#
# 				\Z 			ASCII 26 (control+Z)
#
# 				\N 			NULL
#
# 			For more information about \-escape syntax, see SECTION 9.1.1, "STRING LITERALS"
#
# 			If the FIELDS ESCAPED BY character is empty, escape-sequence interpretation does not occur.
#
# 		) For output, if the FIELDS ESCAPED BY character is not empty, it is used to prefix the following
# 			characters on output:
#
# 			) The FIELDS ESCAPED BY character
#
# 			) The FIELDS [OPTIONALLY] ENCLOSED BY character
#
# 			) The first character of the FIELDS TERMINATED BY and LINES TERMINATED BY values,
# 				if the ENCLOSED BY character is empty or unspecified.
#
# 			) ASCII 0 (what is actually written following the escape character is ASCII 0, not a zero-valued byte)
#
# 			If the FIELDS ESCAPED BY character is empty, no characters are escaped and NULL is output as NULL,
# 			not \N
#
# 			It is probably not a good idea to specify an empty escape character, particularly if field values
# 			in your data contain any of the characters in the list just given.
#
# In certain cases, field- and line-handling options interact:
#
# 		) If LINES TERMINATED BY is an empty string and FIELDS TERMINATED BY is nonempty, lines are also
# 			terminated with FIELDS TERMINATED BY
#
# 		) If the FIELDS TERMINATED BY and FIELDS ENCLOSED BY values are both empty (''), a fixed-row
# 			(nondelimited) format is used.
#
# 			With fixed-row format, no delimiters are used between fields (but you can still have a line terminator)
#
# 			Instead, column values are read and written using a field width wide enough to hold all values
# 			in the field.
#
# 			For TINYINT, SMALLINT, MEDIUMINT, INT, and BIGINT, the field widths are 4, 6, 8, 11 and 20, respectively,
# 			no matter what the declared display width is.
#
# 			LINES TERMINATED BY is still used to separate lines.
#
# 			If a line does not contain all fields, the rest of the columns are set to their
# 			default values.
#
# 			If you do not have a line terminator, you should set this to ''
#
# 			In this case, the text file must contain all fields for each row.
#
# 			Fixed row format also affects handling of NULL values, as described later.
#
# 			NOTE:
#
# 				Fixed-size format does not work if you are using a multibyte character set
#
# Handling of NULL values varies according to the FIELDS and LINES options in use:
#
# 		) For the default FIELDS and LINES values, NULL is written as a field value of 
# 			\N for output, and a field value of \N is read as NULL for input
#
# 			(Assuming that the ESCAPED BY character is \)
#
# 		) If FIELDS ENCLOSED BY is not empty, a field containing the literal word NULL
# 			as its value is read as a NULL value.
#
# 			This differs from the word NULL enclosed within FIELDS ENCLOSED BY characters,
# 			which is read as the string 'NULL'
#
# 		) If FIELDS ESCAPED BY is empty, NULL is written as the word NULL
#
# 		) With fixed-row format (which is used when FIELDS TERMINATED BY and FIELDS ENCLOSED BY
# 			are both empty), NULL is written as a empty string.
#
# 			This causes both NULL values and empty strings in the table to be indistinguishable when
# 			written to the file because both are written as empty strings.
#
# 			If you need to be able to tell the two apart when reading the file back in,
# 			you should not use fixed-row format.
#
# An attempt to load NULL into a NOT NULL column causes assignment of the implicit default value
# for the column's data type and a warning, or an error in strict SQL mode.
#
# Implicit default values are discussed in SECTION 11.7, "DATA TYPE DEFAULT VALUES"
#
# Some cases are not supported by LOAD_DATA_INFILE:
#
# 		) Fixed-size rows (FIELDS TERMINATED BY and FIELDS ENCLOSED BY both empty) and BLOB or TEXT columns.
#
# 		) If you specify one separator that is the same as or a prefix of another, LOAD_DATA_INFILE cannot
# 			interpret the input properly.
#
# 			For example, the following FIELDS clause would cause problems:
#
# 				FIELDS TERMINATED BY '"' ENCLOSED BY '"'
#
# 		) If FIELDS ESCAPED BY is empty, a field value that contains an occurrence of FIELDS
# 			ENCLOSED BY or LINES TERMINATED BY followed by the FIELDS TERMINATED BY value
# 			causes LOAD_DATA_INFILE to stop reading a field or line too early.
#
# 			This happens because LOAD_DATA_INFILE cannot properly determine whether the field
# 			or line value ends.
#
# COLUMN LIST SPECIFICATION
#
# The following example loads all columns of the persondata table:
#
# 		LOAD DATA INFILE 'persondata.txt' INTO TABLE persondata;
#
# By default, when no column list is provided at the end of the LOAD_DATA_INFILE
# statement, input lines are expected to contain a field for each table column.
#
# If you want to load only some of a table's columns, specify a column list:
#
# 		LOAD DATA INFILE 'persondata.txt' INTO TABLE persondata
# 		(col_name_or_user_var [, col_name_or_user_var] ---);
#
# You must also specify a column list if the order of the fields in the input file
# differs from the order of the columns in the table.
#
# Otherwise, MySQL cannot tell how to match input fields with table columns.
#
# INPUT PREPROCESSING
#
# Each col_name_or_user_var value is either a column or a user variable.
#
# With user variables, the SET clause enables you to perform preprocessing
# transformations on their values before assigning the result to columns.
#
# User variables in the SET clause can be used in several ways.
#
# The following example uses the first input column directly for the value
# of t1.column1, and assigns the second input column to a user variable
# that is subjected to a division operation beore being used for the
# value of t1.column2:
#
# 		LOAD DATA INFILE 'file.txt'
# 			INTO TABLE t1
# 			(column1, @var1)
# 			SET column2 = @var1/100;
#
# The SET clause can be used to supply values not derived from the input file.
#
# The following statement sets column3 to the current date and time:
#
# 		LOAD DATA INFILE 'file.txt'
# 			INTO TABLE t1
# 			(column1, column2)
# 			SET column3 = CURRENT_TIMESTAMP;
#
# You can also discard an input value by assigning it to a user variable
# and not assigning the variable to a table column:
#
# 		LOAD DATA INFILE 'file.txt'
# 			INTO TABLE t1
# 			(column1, @dummy, column2, @dummy, column3);
#
# Use of the column/variable list and SET clause is subject to the following restrictions:
#
# 		) Assignments in the SET clause should have only column names on the left hand side of assignment operators
#
# 		) You can use subqueries in the right hand side of SET assignments.
#
# 			A subquery that returns a value to be assigned to a column may be a scalar subquery only.
#
# 			ALso, you cannot use a subquery to select from the table that is being loaded.
#
# 		) Lines ignored by an IGNORE clause are not processed for the column/variable list or SET clause
#
# 		) User variables cannot be used when loading data with fixed-row format because user variables do
# 			not have a display width
#
# When processing an input line, LOAD_DATA splits it into fields and uses the values according to
# the column/variable list and the SET clause, if they are present.
#
# Then the resulting row is inserted into the table. If there are BEFORE INSERT or AFTER INSERT
# triggers for the table, they are activated before or after inserting the row, respectively.
#
# If an input line has too many fields, the extra fields are ignored and the number of warnings
# is incremented.
#
# If an input line has too few fields, the table columns for which input fields are missing are set
# to their default values.
#
# Default value assignment is described in SECTION 11.7, "DATA TYPE DEFAULT VALUES"
#
# An empty field value is interpreted different from a missing field:
#
# 		) For string types, the column is set to the empty string
#
# 		) For numeric types, the column is set to 0
#
# 		) For date and time types, the column is set to the appropriate "zero" value for the type.
#
# 			See SECTION 11.3, "DATE AND TIME TYPES"
#
# These are the same values that result if you assign an empty string explicitly to a string,
# numeric, or date or time type explicitly in an INSERT or UPDATE statement.
#
# Treatment of empty or incorrect field values differs from that just described if the SQL
# mode is set to a restrictive value.
#
# For example, if sql_mode is set to TRADITIONAL, conversion of an empty value or a value
# such as 'x' for a numeric column results in an error, not conversion to 0.
#
# (With LOCAL or IGNORE, warnings occur rather than errors, even with a restrictive sql_mode value,
# and the row is inserted using the same closest-value behavior used for nonrestrictive
# SQL modes.
#
# This occurs because the server has no way to stop transmission of the file in the middle of the operation)
#
# TIMESTAMP columns are set to the current date and time only if there is a NULL value for the
# column (that is, \N) and the column is not declared to permit NULL values, or if the TIMESTAMP
# column's default value is the current timestamp and it is omitted from the field list when a 
# field list is specified.
#
# LOAD_DATA_INFILE regards all input as strings, so you cannot use numeric values for ENUM or
# SET columns the way you can with INSERT statements.
#
# All ENUM and SET values must be specified as strings.
#
# BIT values cannot be loaded directly using binary notation (for example, b'011010')
#
# To work around this, use the SET clause to strip off the leading b' and trailing '
# and perform a base-2 to base-10 conversion so that MySQL loads the values into the
# BIT column properly:
#
# 		cat /tmp/bit_test.txt
# 		b'10
# 		b'1111111'
# 		mysql test
# 		LOAD DATA INFILE '/tmp/bit_test.txt'
# 		INTO TABLE bit_test (@var1)
# 		SET b = CAST(CONV(MID(@var1, 3, LENGTH(@var1)-3), 2, 10) AS UNSIGNED);
# 		Query OK, 2 rows affected (0.00 sec)
# 		Records: 2 Deleted: 0 Skipped: 0 Warnings: 0
#
# 		SELECT BIN(b+0) FROM bit_test;
# 		+------------+
# 		| BIN(b+0)   |
# 		+------------+
# 		| 10 		    |
# 		| 1111111    |
# 		+------------+
# 		2 rows in set (0.00 sec)
#
# For BIT values in 0b binary notation (for example, 0b011010), use this SET
# clause instead to strip off the leading 0b:
#
# 		SET b = CAST(CONV(MID(@var1, 3, LENGTH(@var1)-2), 2, 10) AS UNSIGNED)
#
# STATEMENT RESULT INFORMATION
#
# When the LOAD_DATA_INFILE statement finishes, it returns an information string in the
# following format:
#
# 		Records: 1 Deleted: 0 Skipped: 0 Warnings: 0
#
# Warnings occur under the same circumstances as when values are inserted using the INSERT
# statement (see SECTION 13.2.6, "INSERT SYNTAX"), except that LOAD_DATA_INFILE also generates
# warnings when there are too few or too many fields in the input row.
#
# You can use SHOW_WARNINGS to get a list of the first max_error_count warnings as information
# about what went wrong.
#
# See SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# If you are using the C API, you can get information about the statement by calling the
# mysql_info() function.
#
# See SECTION 28.7.7.36, "MYSQL_INFO()"
#
# MISCELLANEOUS TOPICS
#
# On Unix, if you need LOAD_DATA to read from a pipe, you can use the following technique 
# (the example loads a listing of the / directory into the table db1.t1):
#
# 		mkfifo /mysql/data/db1/ls.dat
# 		chmod 666 /mysql/data/db1/ls.dat
# 		find / -ls > /mysql/data/db1/ls.dat &
# 		mysql -e "LOAD DATA INFILE 'ls.dat' INTO TABLE t1" db1
#
# Here you must run the command that generates the data to be loaded and the mysql commands
# either on separate terminals, or run the data generation process in the background
# (as shown in the preceding example)
#
# If you do not do this, the pipe will block until data is read by the mysql process
#
# 13.2.8 LOAD XML SYNTAX
#
# 		LOAD XML [LOW_PRIORITY | CONCURRENT] [LOCAL] INFILE 'file_name'
# 			[REPLACE | IGNORE]
# 			INTO TABLE [db_name.]tbl_name
# 			[CHARACTER SET charset_name]
# 			[ROWS IDENTIFIED BY '<tagname>']
# 			[IGNORE number {LINES | ROWS}]
# 			[(field_name_or_user_var
# 				[, field_name_or_user_var] ---)]
# 			[SET col_name={expr | DEFAULT},
# 				[, col_name={expr | DEFAULT}] ---]
#
# The LOAD_XML statement reads data from an XML file into a table.
#
# The file_name must be given as a literal string. The tagname in the optional ROWS IDENTIFIED BY 
# clause must also be given as a literal string, and must be surrounded by angle brackets (< and >)
#
# LOAD_XML acts as the complement of running the mysql client in XML output mode (that is, starting
# the client with the --xml option)
#
# To write data from a table to an XML file, you can invoke the mysql client with the --xml
# and -e options from the system shell, as shown here:
#
# 		mysql --xml -e 'SELECT * FROM mydb.mytable' > file.xml
#
# To read the file back into a table, use LOAD_XML_INFILE
#
# By default, the <row> element is considered to be the equivalent of a database
# table row; this can be changed using the ROWS IDENTIFIED BY clause.
#
# This statement supports three different XML formats:
#
# 		) Column names as attributes and column values as attribute values:
#
# 			<row column1="value1" column2="value2" ---/>
#
# 		) Column names as tags and column values as the content of these tags:
#
# 			<row>
# 				<column1>value1</column1>
# 				<column2>value2</column2>
# 			</row>
#
# 		) Column names are the name attributes of <field> tags, and values are the contents of these tags:
#
# 			<row>
# 				<field name='column1'>value1</field>
# 				<field name='column2'>value2</field>
# 			</row>
#
# 			This is the format used by other MySQL tools, such as mysqldump
#
# All three formats can be used in the same XML file; the import routine automatically
# detects the format for each row and interprets it correctly.
#
# Tags are matched based on the tag or attribute name and the column name.
#
# The following clauses work essentially the same way for LOAD_XML as they do for LOAD_DATA:
#
# 		) LOW_PRIORITY or CONCURRENT
#
# 		) LOCAL
#
# 		) REPLACE or IGNORE
#
# 		) CHARACTER SET
#
# 		) SET
#
# See SECTION 13.2.7, "LOAD DATA INFILE SYNTAX", for more information about these clauses.
#
# (field_name_or_user_var, ---) is a list of one or more comma-separated XML fields or user variables.
#
# The name of a user variable used for this purpose must match the name of a field from the XML file,
# prefixed with @.
#
# You can use field names to select only desired fields.
#
# User variables can be employed to store the corresponding field values for subsequent re-use.
#
# The IGNORE number LINES or IGNORE number ROWS clause causes the first number rows in the
# XML file to be skipped.
#
# It is analogous to the LOAD_DATA statement's IGNORE --- LINES clause.
#
# Suppose that we have a table named person, created as shown here:
#
# 		USE test;
#
# 		CREATE TABLE person (
# 			person_id INT NOT NULL PRIMARY KEY,
# 			fname VARCHAR(40) NULL,
# 			lname VARCHAR(40) NULL,
# 			created TIMESTAMP
# 		);
#
# Suppose further that this table is initially empty.
#
# Now suppose that we have a simple XML file person.xml, whose contents
# are as shown here:
#
# 		<list>
# 			<person person_id="1" fname="Kapek" lname="Sainnouine"/>
# 			<person person_id="2" fname="Sajon" lname="Rondela"/>
# 			<person person_id="3"><fname>Likame</fname><lname>Örrtmons</lname></person>
# 			<person person_id="4"><fname>Slar</fname><lname>Manlanth</lname></person>
# 			<person><field name="person_id">5</field><field name="fname">Stoma</field>
# 				<field name="lname">Milu</field></person>
# 			<person><field name="person_id">6</field><field name="fname">Nirtam</field>
# 				<field name="lname">Sklöd</field></person>
# 			<person person_id="7"><fname>Sungam</fname><lname>Dulbåd</lname></person>
# 			<person person_id="8" fname="Srafef" lname="Encmelt"/>
# 		</list>
#
# Each of the permissible XML formats discussed previously is represented in this example file.
#
# To import the data in person.xml into the person table, you can use this statement:
#
# 		LOAD XML LOCAL INFILE 'person.xml'
# 			INTO TABLE person
# 			ROWS IDENTIFIED BY '<person>';
# 		Query OK, 8 rows affected (0.00 sec)
# 		Records: 8 Deleted: 0 Skipped: 0 Warnings: 0
#
# Here, we assume that person.xml is located in the MySQL data directory.
#
# If the file cannot be found, the following error results:
#
# 		ERROR 2 (HY000): File '/person.xml' not found (Errcode: 2)
#
# The ROWS IDENTIFIED BY '<person>' clause means that each <person> element in the XML
# file is considered equivalent to a row in the table into which the data is to be
# imported.
#
# In this case, this is the person table in the test database.
#
# As can be seen by the response from the server, 8 rows were imported into the test.person
# table.
#
# This can be verified by a simple SELECT statement:
#
# 		SELECT * FROM person;
# 		+-----------------+---------------+----------------+----------------------+
# 		| person_id 		| fname 			 | lname 			| created 				  |
# 		+-----------------+---------------+----------------+----------------------+
# 		| 1 				   | Kapek 			 | Sainnouine 	   | 2007-07-13 16:18:47  |
# 		| 2 					| Sajon 			 | Rondela 			| 2007-07-13 16:18:47  |
# 		| 3 					| Likame 		 | Örrtmons 		| 2007-07-13 16:18:47  |
# 		| 4 					| etc.
# 		etc.
#
# This shows, as stated earlier in this section, that any or all of hte 3 permitted XML
# formats may appear in a single file and be read in using LOAD_XML
#
# The inverse of the import operation just shown - that is, dumping MySQL table data
# into an XML file - can be accomplished using the mysql client from the system shell,
# as shown here:
#
# 		mysql --xml -e "SELECT * FROM test.person" > person-dump.xml
# 		cat person-dump.xml
# 		<?xml version="1.0"?>
#
# 		<resultset statement="SELECT * FROM test.person" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
# 			<row>
# 				<field name="person_id">1</field>
# 				<field name="fname">Kapek</field>
# 				<field name="lname">Sainnouine</field>
# 			</row>
#
# 			<row>
# 				<field name="person_id">2</field>
# 				etc.
# 			etc.
# 		</resultset>
#
# NOTE:
#
# 		The --xml option causes the mysql client to use XML formatting for its output;
#
# 		The -e option causes the client to execute the SQL statement immediately following
# 		the option. See SECTION 4.5.1, "MYSQL -- THE MYSQL COMMAND-LINE CLIENT"
#
# YOu can verify that hte dump is valid by creating a copy of the person table
# and importing the dump file into the new table, like this:
#
# 		USE test;
# 		CREATE TABLE person2 LIKE person;
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		LOAD XML LOCAL INFILE 'person-dump.xml'
# 			INTO TABLE person2;
# 		Query OK, 8 rows affected (0.01 sec)
# 		Records: 8 Deleted: 0 Skipped: 0 Warnings: 0
#
# 		SELECT * FROM person2;
# 		+---------------------+---------------+-----------------------+---------------------+
# 		| person_id 			 | fname 		  | lname 					  | created 				|
# 		+---------------------+---------------+-----------------------+---------------------+
# 		| etc.
# 		8 rows in set (0.00 sec)
#
# There is no requirement that every field in the XML file be matched with a column in the 
# corresponding table.
#
# Fields which have no corresponding columns are skipped.
#
# You can see this by first emptying the person2 table and dropping the created column,
# then using the same LOAD XML statement we just employed previously, like this:
#
# 		TRUNCATE person2;
# 		Query OK, 8 rows affected (0.26 sec)
#
# 		ALTER TABLE person2 DROP COLUMN created;
# 		Query OK, 0 rows affected (0.52 sec)
# 		Records: 0 Duplicates: 0 Warnings: 0
#
# 		SHOW CREATE TABLE person2\G
# 		************************** 1. row *********************************
# 				Table: person2
# 		Create table: CREATE TABLE `person2` (
# 			`person_id` int(11) NOT NULL,
# 			`fname` varchar(40) DEFAULT NULL,
# 			`lname` varchar(40) DEFAULT NULL,
# 			PRIMARY KEY (`person_id`)
# 		) ENGINE=InnoDB DEFAULT CHARSET=utf8
# 		1 row in set (0.00 sec)
#
# 		LOAD XML LOCAL INFILE 'person-dump.xml'
# 			INTO TABLE person2;
# 		Query OK, 8 rows affected (0.01 sec)
# 		Records: 8 Deleted: 0 Skipped: 0 Warnings: 0
#
# 		SELECT * FROM person2;
# 		+--------------+--------------+--------------+
# 		| person_id    | fname 		   | lname 			|
# 		+--------------+--------------+--------------+
# 		| 		etc.
# 		8 rows in set (0.00 sec)
#
# The order in which the fields are given within each row of the XML file does not
# affect the operation of LOAD XML; the field order can vary from row to row,
# and is not required to be in the same order as the corresponding columns in the table.
#
# As mentioned previously, you can use a (field_name_or_user_var, ---) list of one or more
# XML fields (to select desired fields only) or user variables (to store the corresponding
# field values for later use)
#
# User variables can be especially useful when you want to insert data from an XML file
# into table columns whose names do not match those of the XML fields.
#
# To see how this works, we first create a table named individual whose structure
# matches that of the person table, but whose columns are named differently:
#
# 		CREATE TABLE individual (
# 			individual_id INT NOT NULL PRIMARY KEY,
# 			name1 VARCHAR(40) NULL,
# 			name2 VARCHAR(40) NULL,
# 			made TIMESTAMP
# 		);
# 		Query OK, 0 rows affected (0.42 sec)
#
# In this case, you cannot simply load the XML file directly into the table,
# because the field and column names do not match:
#
# 		LOAD XML INFILE '../bin/person-dump.xml' INTO TABLE test.individual;
# 		ERROR 1263 (22004): Column set to default value; NULL supplied to NOT NULL column
# 		'individual_id' at row 1
#
# This happens because the MySQL server looks for field names matching the column names
# of hte target table.
#
# You can work around this problem by selecting the field values into user variables,
# then setting the target table's columns equal to the values of those variables
# using SET.
#
# You can perform both of these operations in a single statement, as shown here:
#
# 		LOAD XML INFILE '../bin/person-dump.xml'
# 				INTO TABLE test.individual (@person_id, @fname, @lname, @created)
# 				SET individual_id=@person_id, name1=@fname, name2=@lname, made=@created;
# 		Query OK, 8 rows affected (0.05 sec)
# 		Records: 8 Deleted: 0 Skipped: 0 Warnings: 0
#
# 		SELECT * FROM individual;;
# 		+-----------------+--------------+-------------------+------------------------+
# 		| individual_id 	| name1 			| name2 				  | made 					   |
# 		+-----------------+--------------+-------------------+------------------------+
# 		| etc.
#
# 		8 rows in set (0.00 sec)
#
# The names of the user variables must match those of the corresponding fields from the
# XML file, with the addition of hte required @ prefix to indicate that they are variables.
#
# THe user variables need not be listed or assigned in the same order as the corresponding fields.
#
# Using a ROWS IDENTIFIED BY '<tagname>' clause, it is possible to import data from the same XML
# file into database tables with different definitions.
#
# For this example, suppose that you have a file named address.xml which contains the following XML:
#
# 		<?xml version="1.0"?>
#
# 		<list>
# 			<person person_id="1">
# 				<fname>Robert</fname>
# 				<lname>Jones</lname>
# 				<address address_id="1" street="Mill Creek Road" zip="45365" city="Sidney"/>
#  			<address address_id="2" street="Main Street" zip="28681" city="Taylorsville"/>
# 			</person>
#
# 			etc.
#
# 		</list>
#
# You can again use the test.person table as defined previously in this section,
# after clearing all the existing records from the table and then showing its
# structure as shown here:
#
# 		mysql< TRUNCATE person;
# 		Query OK, 0 rows affected (0.04 sec)
#
# 		mysql< SHOW CREATE TABLE person\G
# 		******************* 1. row *************************
# 				Table: person
# 		Create Table: CREATE TABLE `person` (
# 			`person_id` int(11) NOT NULL,
# 			`fname` varchar(40) DEFAULT NULL,
# 			`lname` varchar(40) DEFAULT NULL,
# 			`created` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
# 		  PRIMARY KEY (`person_id`)
# 		) ENGINE=MyISAM DEFAULT CHARSET=utf8mb4
# 		1 row in set (0.00 sec)
#
# Now create an address table in the test database using the following CREATE_TABLE statement:
#
# 		CREATE TABLE address (
# 			address_id INT NOT NULL PRIMARY KEY,
# 			person_id INT NULL,
# 			street VARCHAR(40) NULL,
# 			zip INT NULL,
# 			city VARCHAR(40) NULL,
# 			created TIMESTAMP
# 		);
#
# To import the data from the XML file into the person table, execute the following
# LOAD_XML statement, which specifies that rows are to be specified by the
# <person> element, as shown here:
#
# 		LOAD XML LOCAL INFILE 'address.xml'
# 			INTO TABLE person
# 			ROWS IDENTIFIED BY '<person>';
# 		Query OK, 2 rows affected (0.00 sec)
# 		Records: 2 Deleted: 0 Skipped: 0 Warnings: 0
#
# You can verify that hte records were imported using a SELECT statement:
#
# 		SELECT * FROM person;
# 		+------------------+------------------+-----------+----------------------+
# 		| person_id 		 | fname 			  | lname 	  | created 			    |
# 		+------------------+------------------+-----------+----------------------+
# 		| 1 					 | Robert 			  | Jones 	  | 2007-07-24 17:37:06  |
# 		| 2 					 | Mary 				  | Smith 	  | 2007-07-24 17:37:06  |
# 		+------------------+------------------+-----------+----------------------+
# 		2 rows in set (0.00 sec)
#
# Since the <address> elements in the XML file have no corresponding columns in the
# person table, they are skipped.
#
# To import the data from the <address> elements into the address table, using the
# LOAD_XML statement shown here:
#
# 		LOAD XML LOCAL INFILE 'address.xml'
# 			INTO TABLE address
# 			ROWS IDENTIFIED BY '<address>';
# 		Query OK, 3 rows affected (0.00 sec)
# 		Records: 3 Deleted: 0 Skipped: 0 Warnings: 0
#
# You can see that the data was imported using a SELECT statement such as this one:
#
# 		SELECT * FROM address;
# 		+-------------+---------------+--------------------+---------+---------------+---------------------+
# 		| address_id  | person_id 		| street 				| zip     | city 			  | created 		      |
# 		+-------------+---------------+--------------------+---------+---------------+---------------------+
# 		| 1 			  | 1 				| Mill Creek Road 	| 45365   | Sidney 		  | 2007-07-24 17:37:37 |
# 		 etc.
# 		
# 		3 rows in set (0.00 sec)
#
# The data from the <address> element that is enclosed in XML comments is not imported.
#
# However, since there is a person_id column in the address table, the value of the 
# person_id attribute from the parent <person> element for each <address> is imported
# into the address table.
#
# SECURITY CONSIDERATIONS
#
# AS with the LOAD_DATA statement, the transfer of the XML file from the client
# host to the server host is initiated by the MySQL server.
#
# In theory, a patched server could be built that would tell the client program to
# transfer a file of the server's choosing rather than the file named by the client
# in the LOAD_XML statement.
#
# Such a server could access any file on the client host to which the client
# user has read access.
#
# In a Web environment, clients usually connect to MySQL from a Web server.
#
# A user that can run any command against the MySQL server can use LOAD_XML_LOCAL
# to read any files ot which the Web server process has read access.
#
# In this environment, the client with respect tot the MySQL server is actually
# the Web server, not the remote program being run by the user who connects
# to the Web server.
#
# You can disable loading of XML files from clients by starting the server with
# --local-infile=0 or --local-infile=OFF
#
# This option can also be used when starting the mysql client to disable
# LOAD_XML for the duration of the client session.
#
# To prevent a client from loading XML files from the server, do not grant
# the FILE privilege to the corresponding MySQL user account, to revoke
# this privilege if the client user account already has it.
#
# IMPORTANT:
#
# 		Revoking the FILE privilege (or not granting it in the first place) keeps
# 		hte user only from executing the LOAD_XML_INFILE statement
#
# 		(as well as the LOAD_FILE() function; it does not prevent the user
# 		from executing LOAD_XML_LOCAL_INFILE 
#
# 		To disallow this statement, you must start the server or the client
# 		with --local-infile=OFF
#
# 		In other words, the FILE privilege affects only whether the client
# 		can read files on the server;
#
# 		it has no bearing on whether the client can read files on the local file system.
#
# For partitioned tables using storage engines that employ table locks, such as MyISAM;
# any locks caused by LOAD XML performs locks on all partitions of the table.
#
# This does not apply to tables using storage engines which employ row-level locking,
# such as InnoDB.
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.9 REPLACE SYNTAX
#
# 	REPLACE [LOW_PRIORITY | DELAYED]
# 		[INTO] tbl_name
# 		[PARTITION (partition_name [, partition_name] ---)]
# 		[(col_name [, col_name] ---)]
# 		{VALUES | VALUE} (value_list) [, (value_list)] ---
#
# 	REPLACE [LOW_PRIORITY | DELAYED]
# 		[INTO] tbl_name
# 		[PARTITION (partition_name [, partition_name] ---)]
# 		SET assignment_list
#
# 	REPLACE [LOW_PRIORITY | DELAYED]
# 		[INTO] tbl_name
# 		[PARTITION (partition_name [, partition_name] ---)]
# 		[(col_name [, col_name] ---)]
# 		SELECT ---
#
# 	value:
# 		{expr | DEFAULT}
#
# 	value_list:
# 		value [, value] ---
#
# 	assignment:
# 		col_name = value
#
# 	assignment_list:
# 		assignment [, assignment] ---
#
# REPLACE works exactly like INSERT, except that if an old row in the table has the same value as a new row
# for a PRIMARY KEY or a UNIQUE index, the old row is deleted before hte new row is isnerted.
#
# See SECTION 13.2.6, "INSERT SYNTAX"
#
# REPLACE is a MySQL extension to the SQL standard.
#
# It either inserts, or deletes and inserts.
#
# For another MySQL extension to standard SQL - that either inserts
# or updates - see SECTION 13.2.6.2, "INSERT --- ON DUPLICATE KEY UPDATE SYNTAX"
#
# DELAYED inserts and replaces were deprecated in MySQL 5.6
#
# In MySQL 8.0, DELAYED is not supported. THe server recognizes but ignores the DELAYED
# keyword, handles the replace as a nondelayed replace, and generates an ER_WARN_LEGACY_SYNTAX_CONVERTED
# warning.
#
# ("REPLACE DELAYED is no longer supported. The statement was converted to REPLACE")
#
# The DELAYED keyword will be removed in a future release.
#
# NOTE:
#
# 		REPLACE makes sense only if a table has a PRIMARY KEY or UNIQUE index.
#
# 		Otherwise, it becomes equivalent to INSERT, because there is no index to be
# 		used to determine whether a new row duplicates another.
#
# Values for all columns are taken from the values specified in the REPLACE statement.
#
# Any missing columns are set to their default values, just as happens for INSERT.
#
# You cannot refer to values from the current row and use them in the new row.
#
# If you use an assignment such as SET col_name = col_name + 1, the reference
# to the column name on the right hand side is treated as DEFAULT(col_name),
# so the assignment is equivalent to SET col_name = DEFAULT(col_name) + 1
#
# To use REPLACE, you must have both the INSERT and DELETE privileges for the table.
#
# If a generated column is replaced explicitly, the only permitted value is DEFAULT.
#
# For information about generated columns, see SECTION 13.1.20.8,, "CREATE TABLE AND GENERATED COLUMNS"
#
# REPLACE supports explicit partition selection using the PARTITION keyword with a list
# of comma-separated names of partitions, subpartitions, or both.
#
# As with INSERT, if it is not possible to insert the new row into any of these
# partitions or subpartitions, the REPLACE statement fails with the error:
#
# 		Found a row not matching the given partition set
#
# For more information, and examples - see SECTION 23.5, "PARTITION SELECTION"
#
# The REPLACE statement returns a count to indicate the number of rows affected.
#
# This is the sum of hte rows deleted and inserted. If the count is 1 for a single-row
# REPLACE, a row was inserted and no rows were deleted.
#
# If the count is greater than 1, one or more old rows were deleted before the new row
# was inserted.
#
# It is possible for a single row to replace more than one old row if the table contains
# multiple unique indexes and the new row duplicates values for different old rows
# in different unique indexes.
#
# THe affected-rows count makes it easy to determine whether REPLACE only added a row
# or whether it also replaced any rows:
#
# 		Check whether the count is 1 (added) or greater (replaced)
#
# If you are using the C API, the affected-rows count cna be obtained using the
# mysql_affected_rows() function.
#
# You cannot replace into a table and select from the same table in a subquery.
#
# MySQL uses the following algorithm for REPLACE (and LOAD DATA --- REPLACE):
#
# 		1. Try to insert the new row into the table
#
# 		2. While the insertion fails because a duplicate-key error occurs for a primary key or unique index:
#
# 			a. Delete from the table the conflicting row that has the duplicate key value
#
# 			b. Try again to insert the new row into the table
#
# It is possible that in the case of a duplicate-key error, a storage engine may perform
# the REPLACE as an update rather than a delete plus insert, but the semantics are the
# same.
#
# There are no user-visible effects other than a possible difference in how the storage
# engine increments Handler_xxx status variables.
#
# Because the results of REPLACE --- SELECT statements depend on the ordering of rows
# from the SELECT and this order cannot always be guaranteed, it is possible when
# logging these statements for the master and the slave to diverge.
#
# For this reason, REPLACE --- SELECT statements are flagged as unsafe for statement-based
# replication.
#
# Such statements produce a warning in the error log when using statement-based mode and are
# written to the binary log using the row-based format when using MIXED mode.
#
# See also SECTION 17.2.1.1, "ADVANTAGES AND DISADVANTAGES OF STATEMENT-BASED AND ROW-BASED REPLICATION"
#
# When modifying an existing table that is not partitioned to accomodate partitioning, or, when modifying
# the partitioning of an already partitioned table, you may consider altering the table's primary key
# (see SECTION 23.6.1, "PARTITIONING KEYS, PRIMARY KEYS, AND UNIQUE KEYS")
#
# You should be aware that, if you do this, the results of REPLACE statements may be affected,
# just as they would be if you modified the primary key of a nonpartitioned table.
#
# Consider the table created by the following CREATE_TABLE statement:
#
# 		CREATE TABLE test (
# 			id INT UNSIGNED NOT NULL AUTO_INCREMENT,
# 			data VARCHAR(64) DEFAULT NULL,
# 			ts TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
# 			PRIMARY KEY (id)
# 		);
#
# When we create this table and run the statements shown in the mysql client, the result
# is as follows:
#
# 		REPLACE INTO test VALUES (1, 'Old', '2014-08-20 18:47:00');
# 		Query OK, 1 row affected (0.04 sec)
#
# 		REPLACE INTO test VALUES (1, 'New', '2014-08-20 18:47:42');
# 		Query OK, 2 rows affected (0.04 sec)
#
# 		SELECT * FROM test;
# 		+----+---------+-----------------------+
# 		| id | data    | ts 							|
# 		+----+---------+-----------------------+
# 		| 1  | New 		| 2014-08-20 18:47:42   |
# 		+----+---------+-----------------------+
# 		1 row in set (0.00 sec)
#
# Now we create a second table almost identical to the first, except that hte primary key
# now covers 2 columns, as shown here (emphasized text):
#
# 		CREATE TABLE test2 (
# 			id INT UNSIGNED NOT NULL AUTO_INCREMENT,
# 			data VARCHAR(64) DEFAULT NULL,
# 			ts TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
# 			PRIMARY KEY (id, ts)
# 		);
#
# When we run on test2 the same two REPLACE statements, as we did on the original test table,
# we obtain a different result:
#
# 		REPLACE INTO test2 VALUES (1, 'Old', '2014-08-20 18:47:00');
# 		Query OK, 1 row affected (0.05 sec)
#
# 		REPLACE INTO test2 VALUES (1, 'New', '2014-08-20 18:47:42');
# 		Query OK, 1 row affected (0.06 sec)
#
# 		SELECT * FROM test2;
# 		+----+----------+--------------------+
# 		| id | data     | ts 					 |
# 		+----+----------+--------------------+
# 		| 1  | Old 		 | 2014-08-20 18:47:00|
# 		| 1  | New 		 | 2014-08-20 18:47:42|
# 		+----+----------+--------------------+
# 		2 rows in set (0.00 sec)
#
# This is due to the fact that, when run on test2, both the id and ts column values must match
# those of an existing row for hte row to be replaced; otehrwise, a row is inserted.
#
# A REPLACE statement affecting a partitioned table using a storage engine such as MyISAM that
# employs table-level locks locks only those partitions containing rows that match the
# REPLACE statement WHERE clause, as long as none of the table partitioning columns are updated;
# otherwise the entire table is locked.
#
# (For storage engines such as InnoDB that employ row-level locking, no locking of partitions
# takes place)
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.10 SELECT SYNTAX
#
# 13.2.10 SELECT --- INTO SYNTAX
# 13.2.10.2 JOIN SYNTAX
# 13.2.10.3 UNION SYNTAX
#
# 		SELECT
# 			[ALL | DISTINCT | DISTINCTROW ]
# 				[HIGH_PRIORITY]
# 				[STRAIGHT_JOIN]
# 				[SQL_SMALL_RESULT] [SQL_BIG_RESULT] [SQL_BUFFER_RESULT]
# 				SQL_NO_CACHE [SQL_CALC_FOUND_ROWS]
# 			select_expr [, select_expr ---]
# 			[FROM table_references
# 				[PARTITION partition_list]
# 			[WHERE where_condition]
# 			[GROUP BY {col_name | expr | position}, --- [WITH ROLLUP]]
# 			[HAVING where_condition]
# 			[WINDOW window_name AS (window_spec)
# 				[, window_name AS (window_spec)] ---]
# 			[ORDER BY {col_name | expr | position}
# 				[ASC | DESC], --- [WITH ROLLUP]]
# 			[LIMIT {[offset,] row_count | row_count OFFSET offset}]
# 			[INTO OUTFILE 'file_name'
# 				[CHARACTER SET charset_name]
# 				export_options
# 			| INTO DUMPFILE 'file_name'
# 			| INTO var_name [, var_name]]
# 		 [FOR {UPDATE | SHARE} [OF tbl_name [, tbl_name] ---] [NOWAIT | SKIP lOCKED]
# 			| LOCK IN SHARE MODE]]
#
# SELECT is used to retrieve rows selected from one or more tables, and can include
# UNION statements and subqueries.
#
# See SECTION 13.2.10.3, "UNION SYNTAX" and SECTION 13.2.11, "SUBQUERY 	SYNTAX"
#
# A SELECT statement can start with a WITH clause to define common table expressions
# accessible within the SELECT.
#
# See SECTION 13.2.13, "WITH SYNTAX (COMMON TABLE EXPRESSIONS)"
#
# The most commonly used clauses of SELECT statements are these:
#
# 		) Each select_expr indicates a column that you want to retrieve.
#
# 			There must be at least one select_expr
#
# 		) table_references indicates the tables or tables from which to retrieve rows.
#
# 			Its syntax is described in SECTION 13.2.10.2, "JOIN SYNTAX"
#
# 		) SELECT supports explicit partition selection using the PARTITION with a list
# 			of partitions or subpartitions (or both) following the name of hte table
# 			in a table_refrence (see SECTION 13.2.10.2, "JOIN SYNTAX")
#
# 			In this case, rows are selected only from the partitions listed, and any
# 			other partitions of the table are ignored.
#
# 			For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# 			SELECT --- PARTITION from tables using storage engines such as MyISAM that
# 			perform table-level locks (and thus partition locks) lock only the partitions
# 			or subpartitions named by the PARTITION option.
#
# 			For more information, see PARTITIONING AND LOCKING
#
# 		) The WHERE clause, if given, indicates the condition or conditions that rows
# 			must satisfy to be selected.
#
# 			where_condition is an expression that evaluates to true for each row to be selected.
#
# 			The statement selects all rows if there is no WHERE clause.
#
# 			In the WHERE expression, you can use any of the functions and operators taht MySQL
# 			supports, except for aggregate (summary) functions.
#
# 			See SECTION 9.5, "EXPRESSIONS" and CHAPTER 12, FUNCTIONS AND OPERATORS.
#
# SELECT can also be used to retrieve rows computed without reference to any table.
#
# For example:
#
# 		SELECT 1+1;
# 			2
#
# You are permitted to specify DUAL as a dummy table name in situations where
# no tables are referneced:
#
# 		SELECT 1 +1 FROM DUAL;
# 			2
#
# DUAL is purely for the convenience of people who require that all SELECT
# statements should have FROM and possibly other clauses.
#
# MySQL may ignore the clauses.
#
# MySQL does not require FROM DUAL if no tables are referenced.
#
# In general, clauses used must be given in exactly the order shown in the 
# syntax description.
#
# For example, a HAVING clause must come after any GROUP BY clause and
# before any ORDER BY clause.
#
# The exception is that the INTO clause can appear either as shown in the syntax
# description or immediately following the select_expr list.
#
# For more information about INFO, see SECTION 13.2.10.1, "SELECT --- INTO SYNTAX"
#
# The list of select_expr terms comprises the select list that indicates which columns
# to retrieve.
#
# Terms specify a column or expression or can use *-shorthand:
#
# 		) A select list consisting only of a single unqualified * can be used
# 			as shorthand to select all columns from all tables.
#
# 				SELECT * FROM t1 INNER JOIN t2 ---
#
# 		) tbl_name.* can be used as qualified shorthand to select all columns
# 			from the named table:
#
# 				SELECT t1.*, t2.* FROM t1 INNER JOIN t2 ---
#
# 		) Use of an unqualified * with other items in the select list may produce a parse error.
#
# 			To avoid this problem, use a qualified tbl_name.* reference
#
# 				SELECT AVG(score), t1.* FROM t1 ---
#
# The following list provides additional information about other SELECT clauses:
#
# 		) A select_expr can be given an alias using AS alias_name.
#
# 			The alias is used as the expression's column name and can be used in
# 			GROUP BY, ORDER BY, or HAVING clauses.
#
# 			For example:
#
# 				SELECT CONCAT(last_name, ', ', first_name) AS full_name
# 					FROM mytable ORDER BY full_name;
#
# 			The AS keyword is optional when aliasing a select_expr with an identifier.
#
# 			The preceeding example could have been written like this:
#
# 				SELECT CONCAT(last_name, ', ',first_name) full_name
# 					FROM mytable ORDER BY full_name;
#
# 			However, because the AS is optional, a subtle problem can occur if you
# 			forget the comma between two select_expr expressions:
#
# 				MySQL interprets the second as an alias name.
#
# 				For example, in the following statement, columnb is treated
# 				as an alias name:
#
# 					SELECT columna columnb FROM mytable;
#
# 			For this reason, it is good practice to be in the habit of using AS explicitly
# 			when specifying column aliases.
#
# 			It is not permissible to refer to a column alias in a WHERE clause, because the
# 			column value might not yet be determined when the WHERE clause is executed.
#
# 			See SECTION B.6.4.4, "PROBLEMS WITH COLUMN ALIASES"
#
# 		) The FROM table_references caluse indicates the table or tables from which to
# 			retrieve rows.
#
# 			If you name more than one table, you are performing a join.
#
# 			For information on join syntax, see SECTION 13.2.10.2, "JOIN SYNTAX"
#
# 			For each table specified, you can optionally specify an alias.
#
# 				tbl_name [[AS] alias] [index_hint]
#
# 			The use of index hints provides the optimizer with information about how
# 			to choose indexes during query processing.
#
# 			For a description of the syntax for specifying these hints, see SECTION 8.9.4, "INDEX HINTS"
#
# 			You can use SET max_seeks_for_key=value as an alternative way to force MySQL
# 			to prefer key scans instead of table scans.
#
# 			See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 		) You can refer to a table within the default database as tbl_name, or as db_name.tbl_name
# 			to specify a database explicitly.
#
# 			You can refer to a column as col_name, tbl_name.col_name or db_name.tbl_name.col_name
#
# 			You need not specify a tbl_name or db_name.tbl_name prefix for a column reference
# 			unless the reference would be ambiguous.
#
# 			See SECTION 9.2.1, "IDENTIFIER QUALIFIERS", for examples of ambiguity that require
# 			the more explicit column reference forms.
#
# 		) A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name:
#
# 			SELECT t1.name, t2.salary FROM employee AS t1, info AS t2
# 				WHERE t1.name = t2.name;
#
# 			SELECT t1.name, t2.salary FROM employee t1, info t2
# 				WHERE t1.name = t2.name;
#
# 		) Columns selected for output can be referred to in ORDER BY and GROUP BY clauses
# 			using column names, column aliases or column positions.
#
# 			Column positions are integers and begin with 1:
#
# 				SELECT college, region, seed FROM tournament
# 					ORDER BY region, seed;
#
# 				SELECT college, region AS r, seed AS s FROM tournament
# 					ORDER BY r, s;
#
# 				SELECT college, region, seed FROM tournament
# 					ORDER BY 2, 3;
#
# 			To sort in reverse order, add the DESC (descending) keyword to the name of the column
# 			in the ORDER BY clause that you are sorting by.
#
# 			The default is ascending order; This can be specified explicitly using the ASC keyword.
#
# 			If ORDER BY occurs within a subquery and also is applied in the outer query, the outermost
# 			ORDER BY takes precedence.
#
# 			For example, results for the following statement are sorted in descending order,
# 			not ascending order:
#
# 				(SELECT --- ORDER BY a) ORDER BY a DESC;
#
# 			Use of column positions is deprecated because the syntax has been removed from the SQL standard.
#
# 		) Prior to MySQL 8.0.13, MySQL supported a nonstandard syntax extension that permitted explicit
# 			ASC or DESC designators for GROUP BY columns.
#
# 			MySQL 8.0.12 and later supports ORDER BY with grouping functions so that use of this extension
# 			is no longer necessary.
#
# 			(Bug #86312, Bug #26073525)
#
# 			This also means you can sort on an arbitrary column or columns when using GROUP BY, like this:
#
# 				SELECT a, b, COUNT(c) AS t FROM test_table GROUP BY a,b ORDER BY a,t DESC;
#
# 			As of MySQL 8.0.13, the GROUP BY extension is no longer supported:
#
# 				ASC or DESC designators for GROUP BY columns are not permitted.
#
# 		) When you use ORDER BY or GROUP BY to sort a column in a SELECT, the server sorts values
# 			using only the initial number of bytes indicated by the max_sort_length system variable.
#
# 		) MySQL extends the use of GROUP BY to permit selecting fields that are not mentioned in the
# 			GROUP BY clause.
#
# 			If you are not getting the results that you expect from your query, please read the 
# 			description of GROUP BY found in SECTION 12.20, "AGGREGATE (GROUP BY) FUNCTIONS"
#
# 		) GROUP BY permits a WITH ROLLUP modifier. See SECTION 12.20.2, "GROUP BY MODIFIERS"
#
# 			Previously, it was not permitted to use ORDER BY in a query having a WITH ROLLUP modifier.
#
# 			This restriction is lifted as of MySQL 8.0.12
#
# 			See SECTION 12.20.2, "GROUP BY MODIFIERS"
#
# 		) The HAVING clause is applied nearly last, just before items are sent to the client,
# 			with no optimization
#
# 			(LIMIT is applied after HAVING)
#
# 			The SQL standard requires that HAVING must reference only columns in the GROUP BY clause
# 			or columns used in aggregate functions.
#
# 			However, MySQL supports an extension to this behavior, and permits HAVING to refer
# 			to columns in the SELECT list and columns in outer subqueries as well.
#
# 			If the HAVING clause refers to a column that is ambiguous, a warning occurs.
#
# 			In the following statement, col2 is ambiguous because it is used as both an alias
# 			and a column name:
#
# 				SELECT COUNT(col1) AS col2 FROM t GROUP BY col2 HAVING col2 = 2;
#
# 			Preference is given to standard SQL behavior, so if a HAVING column name
# 			is used both in GROUP BY and as an aliased column in the output column list,
# 			preference is given to the column in the GROUP BY column.
#
# 		) Do not use HAVING for items that should be in the WHERE clause.
#
# 			For example, do not write the following:
#
# 				SELECT col_name FROM tbl_name HAVING col_name > 0;
#
# 			Write this instead:
#
# 				SELECT col_name FROM tbl_name WHERE col_name > 0;
#
# 		) The HAVING clause can refer to aggregate functions, which the WHERE clause cannot:
#
# 			SELECT user, MAX(salary) FROM users
# 				GROUP BY users HAVING MAX(salary) > 10;
#
# 			(This did not work in some older versions of MySQL)
#
# 		) MySQL permits duplicate column names.
#
# 			That is, there can be more than one select_expr with the same name.
#
# 			This is an extension to standard SQL. Because MySQL also permits
# 			GROUP BY and HAVING to refer to select_expr values, this can result
# 			in an ambiguity:
#
# 				SELECT 12 AS a, a FROM t GROUP BY a;
#
# 			In that statement, both columns have the name a.
#
# 			To ensure that the correct column is used for grouping, use different
# 			names for each select_expr
#
# 		) The WINDOW clause, if present, defines named windows that can be referred to by window functions.
#
# 			For details, see SECTION 12.21.4, "NAMED WINDOWS"
#
# 		) MySQL resolves unqualified column or alias references in ORDER BY clauses by searching
# 			in the select_expr values, then in the columns of the tables in the FROM clause.
#
# 			For GROUP BY or HAVING clauses, it searches the FROM clause before searching in the
# 			select_expr values.
#
# 			(For GROUP BY and HAVING, this differs from the pre-MySQL 5.0 behavior that used the same
# 			rules as for ORDER BY)
#
# 		) The LIMIT clause can be used to constrain the number of rows returned by the SELECT statement.
#
# 			LIMIT takes one or two numeric arguments, which must both be nonnegative integer constants,
# 			with these exceptions:
#
# 				) Within prepared statements, LIMIT parameters can be specified using ? placeholder markers.
#
# 				) Within stored programs, LIMIT parameters can be specified using integer-valued routine parameters
# 					or local variables.
#
# 			With two arguments, the first argument specifies the offset of the first row to return,
# 			and the second specifies the maximum number of rows to return.
#
# 			The offset of the initial row is 0 (not 1):
#
# 				SELECT * FROM tbl LIMIT 5,10; # Retrieve rows 6-15
#
# 			To retrieve all rows from a certain offset up to the end of the result set,
# 			you can use some large number for the second parameter.
#
# 			This statement retrieves all rows from the 96th row to the last:
#
# 				SELECT * FROM tbl LIMIT 95,<a lot>;
#
# 			With one argument, the value specifies the number of rows to return from the
# 			beginning of the result set:
#
# 				SELECT * FROM tbl LIMIT 5; #Retrieve first 5 rows
#
# 			In other words, LIMIT row_count is equivalent to LIMIT 0, row_count
#
# 			For prepared statements, you can use placeholders. The following statements will return
# 			one row from the tbl table:
#
# 				SET @a=1;
# 				PREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?';
# 				EXECUTE STMT USING @a;
#
# 			The following statements will return the second to sixth row from the tbl table:
#
# 				SET @skip=1; SET @numrows=5;;
# 				PREPARE STMT FROM 'SELECT * FROM tbl LIMIT ?, ?';
# 				EXECUTE STMT USING @skip, @numrows;
#
# 			For compatibility with PostgreSQL, MySQL also supports the LIMIT row_count OFFSET offset syntax
#
# 			If LIMIT occurs within a subquery and also is applied in the outer query, the outermost
# 			LIMIT takes precedence.
#
# 			For example, the following statement produces two rows, not one:
#
# 				(SELECT --- LIMIT 1) LIMIT 2;
#
# 		) The SELECT_---_INTO form of SELECT enables the query result to be written to a file
# 			or stored in variables.
#
# 			For more information, see SECTION 13.2.10.1, "SELECT --- INTO SYNTAX"
#
# 		) If you use FOR UPDATE with a storage engine that uses page or row locks, rows examined
# 			by the query are write-locked until the end of the current transaction.
#
# 			You cannot use FOR UPDATE as part of the SELECT in a statement such as:
#
# 				CREATE_TABLE_new_table_SELECT_---_FROM_old_table_---
#
# 			(If you attempt to do so, the statement is rejected with the error Can't
# 			update table 'old_table' while 'new_table' is being created)
#
# 			FOR SHARE and LOCK IN SHARE MODE set shared locks that permit other transactions
# 			to read the examined rows but not to update or delete them.
#
# 			FOR SHARE and LOCK IN SHARE MODE are equivalent.
#
# 			However, FOR SHARE, like FOR UPDATE, supports NOWAIT, SKIP LOCKED,
# 			and OF tbl_name options.
#
# 			FOR SHARE is a replacement for LOCK IN SHARE MODE, but LOCK IN SHARE MODE
# 			remains available for backward compatibility.
#
# 			NOWAIT causes a FOR UPDATE or FOR SHARE query to execute immediately,
# 			returning an error if a row lock cannot be obtained due to a lock
# 			held by another transaction.
#
# 			SKIP LOCKED causes a FOR UPDATE or FOR SHARE query to execute immediately,
# 			excluding rows from the result set that are locked by another transaction.
#
# 			NOWAIT and SKIP LOCKED options are unsafe for statement-based replication.
#
# 				NOTE:
#
# 					Queries that skip locked rows return an inconsistent view of the data.
#
# 					SKIP LOCKED is therefore not suitable for general transactional work.
#
# 					However, it may be used to avoid lock contention when multiple sessions
# 					access the same queue-like table.
#
# 			OF tbl_name applies FOR UPDATE and FOR SHARE queries to named tables.
#
# 			For example:
#
# 				SELECT * FROM t1, t2 FOR SHARE OF t1 FOR UPDATE OF t2;
#
# 			All tables referenced by the query block are locked when OF tbl_name
# 			is omitted.
#
# 			Consequently, using a locking clause without OF tbl_name in combination
# 			with another locking clause returns an error.
#
# 			Specifying the same table in multiple locking clauses returns an error.
#
# 			If an alias is specified as the table name in the SELECT statement,
# 			a locking clause may only use the alias.
#
# 			If the SELECT statement does not specify an alias explicitly, the locking
# 			clause may only specify the actual table name.
#
# 			For more information about FOR UPDATE and FOR SHARE, see SECTION 15.7.2.4,
# 			"LOCKING READS"
#
# 			For additional information about NOWAIT and SKIP LOCKED options, see
# 			LOCKING READ CONCURRENCY WITH NOWAIT AND SKIP LOCKED.
#
# Following the SELECT keyword, you can use a number of modifiers that affect the
# operation of the statement.
#
# HIGH_PRIORITY, STRAIGHT_JOIN and modifiers beginning with SQL_ are MySQL extensions
# to standard SQL.
#
# 		) The ALL and DISTINCT modifiers specify whether duplicate rows should be returned.
#
# 			ALL (the default) specifies that all matching rows should be returned, including
# 			duplicates.
#
# 			DISTINCT specifies removal of duplicate rows from the result set.
#
# 			It is an error to specify both modifiers. DISTINCTROW is a synonym for
# 			DISTINCT.
#
# 			In MySQL 8.0.12 and later, DISTINCT can be used with a query that also uses
# 			WITH ROLLUP. (Bug #87450, Bug #26640100)
#
# 		) HIGH_PRIORITY gives the SELECT higher priority than a statement that updates a table.
#
# 			You should use this only for queries that are very fast and must be done at once.
#
# 			A SELECT HIGH_PRIORITY query that is issued while the table is locked for reading
# 			runs even if there is an update statement waiting for the table to be free.
#
# 			This affects only storage engines that use only table-level locking (such as MyISAM, MEMORY, and MERGE)
#
# 			HIGH_PRIORITY cannot be used with SELECT statements that are part of a UNION.
#
# 		) STRAIGHT_JOIN forces the optimizer to join the tables in the order in which they are listed
# 			in the FROM clause.
#
# 			You can use this to speed up a query if the optimizer joins the tables in nonoptimal
# 			order.
#
# 			STRAIGHT_JOIN also can be used in the table_references list. See SECTION 13.2.10.2, "JOIN SYNTAX"
#
# 			STRAIGHT_JOIN does not apply to any table that the optimizer treats as a const or system table.
#
# 			Such a table produces a single row, is read during the optimization phase of query execution,
# 			and references to its columns are replaced with the appropriate column values before query
# 			execution proceeds.
#
# 			These tables will appear first in the query plan displayed by EXPLAIN.
#
# 			See SECTION 8.8.1, "OPTIMIZING QUERIES WITH EXPLAIN"
#
# 			This exception may not apply to const or system tables that are
# 			used on the NULL-complemented side of an outer join (that is, the right-side table
# 			of a LEFT JOIN or the left-side table of a RIGHT JOIN)
#
# 		) SQL_BIG_RESULT or SQL_SMALL_RESULT can be used with GROUP BY or DISTINCT to tell
# 			the optimizer that the result set has many rows or is small, respectively.
#
# 			For SQL_BIG_RESULT, MySQL directly uses disk-based temporary tables if they are created,
# 			and prefers sorting to using a temporary table with a key on the GROUP BY elements.
#
# 			For SQL_SMALL_RESULT, MySQL uses in-memory temporary tables to store the resulting table
# 			instead of using sorting.
#
# 			This should not normally be needed.
#
# 		) SQL_BUFFER_RESULT forces the result to be put into a temporary table.
#
# 			This helps MySQL free the table locks early and helps in cases where
# 			it takes a long time to send the result set to the client.
#
# 			This modifier can be used only for top-level SELECT statements,
# 			not for subqueries or following UNION.
#
# 		) SQL_CALC_FOUND_ROWS tells MySQL to calculate how many rows there would be
# 			in the result set, disregarding any LIMIT clause.
#
# 			The number of rows can then be retrieved with SELECT FOUND_ROWS()
#
# 			See SECTION 12.15, "INFORMATION FUNCTIONS"
#
# 		) The SQL_CACHE and SQL_NO_CACHE modifiers were used with the query cache prior to MySQL 8.0
#
# 			The query cache was removed in MySQL 8.0
#
# 			The SQL_CACHE modifier was removed as well.
#
# 			SQL_NO_CACHE is deprecated, has no effect, and will be removed in a future MySQL release.
#
# A SELECT from a partitioned table using a storage engine such as MyISAM that employs
# table-level locks locks only those partitions containing rows that match the SELECT
# statement WHERE clause.
#
# (This does not occur with storage engines such as InnoDB that employ row-level locking)
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.10.1 SELECT --- INTO SYNTAX
#
# The SELECT_---_INTO form of SELECT enables a query result to be stored in variables or 
# written to a file:
#
# 		) SELECT --- INTO var_list selects column values and stores them into variables
#
# 		) SELECT --- INTO OUTFILE writes the selected rows to a file. Column and line terminators can be
# 			specified to produce a specific output format.
#
# 		) SELECT --- INTO DUMPFILE writes a single row to a file without any formatting.
#
# The SELECT syntax description (see SECTION 13.2.10, "SELECT SYNTAX") shows the INTO clause
# near the end of the statement.
#
# It is also possible to use INTO immediately following the select_expr list
#
# An INTO clause should not be used in a nested SELECT because such a SELECT
# must return its result to the outer context.
#
# The INTO clause can name a list of one or more variables, which can be user-defined
# variables, stored procedure or function parameters, or stored program local variables.
#
# (Within a prepared SELECT --- INTO OUTFILE statement, only user-defined variables
# are permitted; see SECTION 13.6.4.2, "LOCAL VARIABLE SCOPE AND RESOLUTION")
#
# The selected values are assigned to the variables.
#
# The number of variables must match the number of columns.
# The query should return a single row.
#
# If the query returns no rows, a warning with error code 1329 occurs
# (No data), and the variable values remain unchanged.
#
# If the query returns multiple rows, error 1172 occurs (Result consisted of more than one row)
#
# If it is possible that the statement may retrieve multiple rows, you can use LIMIT 1 to limit
# the result set to a single row.
#
# 		SELECT id, data INTO @x, @y FROM test.t1 LIMIT 1;
#
# User variable names are not case-sensitive. See SECTION 9.4, "USER-DEFINED VARIABLES"
#
# The SELECT_---_INTO_OUTFILE 'file_name' form of SELECT writes the selected rows to a file.
#
# The file is created on the server host, so you must have the FILE privilege to use this
# syntax.
#
# file_name cannot be an existing file, which among other things prevents files such as
# /etc/passwd and database tables from being destroyed.
#
# The character_set_filesystem system variable controls the interpretation of the file name.
#
# The SELECT_---_INTO_OUTFILE statement is intended primarily to let you very quickly
# dump a table to a text file on the server machine.
#
# If you want to create the resulting file on some other host than the server host,
# you normally cannot use SELECT_---_INTO_OUTFILE since there is no way to write a path
# to the file relative to the server host's file system.
#
# However, if the MySQL client software is installed on the remote machine, you can
# instead use a client command such as mysql -e "SELECT ---" > file_name to generate
# the file on the client host.
#
# It is also possible to create the resulting file on a different host other than the
# server host, if the location of the file on the remote host can be accessed using
# a network-mapped path on the server's file system.
#
# In this case, the presence of mysql (or some other MySQL client program) is not
# required on the target host.
#
# SELECT_---_INTO_OUTFILE is the complement of LOAD_DATA_INFILE.
#
# Columns values are written converted to the character set specified in the
# CHARACTER SET clause.
#
# If no such clause is present, values are dumped using the binary character set.
#
# In effect, there is no character set conversion. 
#
# If a result set contains columns in several character sets, 
# the output data file will as well and you may not be able to reload the file correctly.
#
# The syntax for the export_options part of the statement consists of the same FIELDS
# and LINES clauses that are used with the LOAD_DATA_INFILE statement.
#
# See SECTION 13.2.7, "LOAD DATA INFILE SYNTAX", for information about the FIELDS
# and LINES clauses, including their default values and permissible values.
#
# FIELDS ESCAPED BY controls how to write special characters.
#
# If the FIELDS ESCAPED BY character is not empty, it is used when necessary to avoid
# ambiguity as a prefix that precedes following characters on output:
#
# 		) The FIELDS ESCAPED BY character
#
# 		) The FIELDS [OPTIONALLY] ENCLOSED BY character
#
# 		) The first character of the FIELDS TERMINATED BY and LINES TERMINATED BY values
#
# 		) ASCII NUL (the zero-valued byte; what is actually written following the escape character is ASCII 0,
# 			not a zero-valuted byte)
#
# The FIELDS TERMINATED BY, ENCLOSED BY, ESCAPED BY, or LINES TERMINATED BY characters must be
# escaped so that you can read the file back in reliably.
#
# ASCII NUL is escaped to make it easier to view with some pagers.
#
# The resulting file does not have to conform to SQL syntax, so nothing else need be escaped.
#
# If the FIELDS ESCAPED BY character is empty, no characters are escaped and NULL is output as
# NULL, not \N
#
# It is probably not a good idea to specify an empty escape character, particularly if field values
# in your data contain any of the characters in the list just given.
#
# Here is an example that produces a file in the comma-separated values (CSV) format used
# by many programs:
#
# 		SELECT a,b,a+b INTO OUTFILE '/tmp/result.txt'
# 			FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"'
# 			LINES TERMINATED BY '\n'
# 			FROM test_table;
#
# If you use INTO DUMPFILE instead of INTO OUTFILE, MySQL writes only one row into the file,
# without any column or line termination and without performing any escape processing.
#
# This is useful if you want to store a BLOB value in a file.
#
# 		NOTE:
#
# 			Any file created by INTO OUTFILE or INTO DUMPFILE is writable by all users on the
# 			server host.
#
# 			The reason for this is that the MySQL server cannot create a file that is owned
# 			by anyone other than the user under whose account it is running.
#
# 			(You should never run mysqld as root for this and other reasons)
#
# 			The file thus must be world-writable so that you can manipulate its contents.
#
# 			If the secure_file_priv system variable is set to a nonempty directory name,
# 			the file to be written must be located in that directory.
#
# In the context of SELECT_---_INTO statements that occur as part of events executed by the
# Event Scheduler, diagnostics messages (not only errors, but also warnings) are written
# to the error log, and, on Windows, to the application event log.
#
# For additional information, see SECTION 24.4.5, "EVENT SCHEDULER STATUS"
#
# 13.2.10.2 JOIN SYNTAX
#
# MySQL supports the following JOIN syntax for the table_references part of SELECT
# statements and multiple-table DELETE and UPDATE statements:
#
# 		table_references:
# 			escaped_table_reference [, escaped_table_reference] ---
#
# 		escaped_table_reference:
# 			table_reference
# 		 | { OJ table_reference }
#
# 		table_reference:
# 			table_factor
# 		 | join_table
#
# 		table_factor:
# 				tbl_name [PARTITION (partition_names)]
# 					[[AS] alias] [index_hint_list]
# 			| table_subquery [AS] alias [(col_list)]
# 			| ( table_references )
#
# 		join_table:
# 			table_reference [INNER | CROSS] JOIN table_factor [join_condition]
# 		 | table_reference STRAIGHT_JOIN table_factor
# 		 | table_reference STRAIGHT_JOIN table_factor ON conditional_expr
# 		 | table_reference {LEFT|RIGHT} [OUTER] JOIN table_reference join_condition
# 		 | table_reference NATURAL [INNER | {LEFT|RIGHT} [OUTER]] JOIN table_factor
#
# 		join_condition:
# 			ON conditional_expr
# 		 | USING (column_list)
#
# 		index_hint_list:
# 			index_hint [, index_hint] ---
#
# 		index_hint:
# 			USE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] ([index_list])
# 		 | IGNORE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] (index_list)
# 		 | FORCE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] (index_list)
#
# 		index_list:
# 			index_name [, index_name] ---
#
# A table reference is also known as a join expression
#
# A table reference (when it refers to a partitioned table) may contain a PARTITION option,
# including a list of comma-separated partitions, subpartitions, or both.
#
# This option follows the name of the table and precedes any alias declaration.
#
# The effect of this option is that rows are selected only from the listed partitions
# or subpartitions.
#
# Any partitions or subpartitions not named in the list are ignored.
#
# For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# The syntax of table_factor is extended in MySQL in comparison with standard SQL.
#
# The standard accepts only table_reference, not a list of them inside a pair of parentheses.
#
# This is a conservative extension if each comma in a list of table_reference items is considered
# as equivalent to an inner join.
#
# For example:
#
# 			SELECT * FROM t1 LEFT JOIN (t2, t3, t4)
# 									ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c)
#
# 		is equivalent to:
#
# 			SELECT * FROM t1 LEFT JOIN (t2 CROSS JOIN t3 CROSS JOIN t4)
# 									ON (t2.a = t1.a AND t3.b = t1.b AND t4.c = t1.c)
#
# In MySQL, JOIN, CROSS JOIN and INNER JOIN are syntactic equivalents (they can replace each other)
#
# In standard SQL, they are not equivalent. INNER JOIN is used with an ON clause, CROSS JOIN
# is used otherwise.
#
# In general, parentheses can be ignored in join expressions containing only inner join operations.
#
# MySQL also supports nested joins. See SECTION 8.2.1.7, "NESTED JOIN OPTIMIZATION"
#
# Index hints can be specified to affect how the MySQL optimizer makes use of indexes.
# For more information, see SECTION 8.9.4, "INDEX HINTS"
#
# Optimizer hints and the optimizer_switch system variable are other ways to influence
# optimizer use of indexes.
#
# See SECTION 8.9.2, "OPTIMIZER HINTS", and SECTION 8.9.3, "SWITCHABLE OPTIMIZATIONS"
#
# The following list describes general factors to take into account when writing joins:
#
# 		) A table reference can be aliased using tbl_name AS alias_name or tbl_name alias_name:
#
# 			SELECT t1.name, t2.salary
# 				FROM employee AS t1 INNER JOIN info AS t2 ON t1.name = t2.name;
#
# 			SELECT t1.name, t2.salary
# 				FROM employee t1 INNER JOIN info t2 ON t1.name = t2.name;
#
# 		) A table_subquery is also known as a derived table or subquery in the FROM clause.
#
# 			See SECTION 13.2.11.8, "DERIVED TABLES"
#
# 			Such subqueries must include an alias to give the subquery result a table name,
# 			and may optionally include a list of table column names in parentheses.
#
# 			A trivial example follows:
#
# 				SELECT * FROM (SELECT 1, 2, 3) AS t1;
#
# 		) INNER JOIN and , (comma) are semantically equivalent in the absence of a join condition:
#
# 			Both produce a Cartesian product between the specified tables (that is, each and every row
# 			in the first table is joined to each and every row in the second table)
#
# 			However, the precedence of the comma operator is less than that of INNER JOIN, CROSS JOIN,
# 			LEFT JOIN, and so on.
#
# 			If you mix comma joins with the other join types when there is a join condition, an error
# 			of the form:
#
# 				Unknown column 'col_name' in 'on clause' may occur
#
# 			Information about dealing with this problem is given later in this section.
#
# 		) The conditional_expr used with ON is any conditional expression of the form that can be used
# 			in a WHERE clause.
#
# 			Generally, the ON clause serves for conditions that specify how to join tables,
# 			and the WHERE clause restricts which rows to include in the result set
#
# 		) If there is no matching row for the right table in the ON or USING part in a LEFT JOIN,
# 			a row with all columns set to NULL is used for the right table.
#
# 			You can use this fact to find rows in a table that have no counterpart in another table:
#
# 				SELECT left_tbl.*
# 					FROM left_tbl LEFT JOIN right_tbl ON left_tbl.id = right_tbl.id
# 					WHERE right_tbl.id IS NULL;
#
# 			This example finds all rows in left_tbl with an id value that is not present in
# 			right_tbl (that is, all rows in left_tbl with no corresponding row in right_tbl)
#
# 			See SECTION 8.2.1.8, "OUTER JOIN OPTIMIZATION"
#
# 		) The USING(column_list) clause names a list of columns that must exist in both tables.
#
# 			If tables a and b both contain columns c1, c2, and c3, the following join compares
# 			corresponding columns from the two tables:
#
# 				a LEFT JOIN b USING (c1, c2, c3)
#
# 		) The NATURAL [LEFT] JOIN of two tables is defined to be semantically equivalent to an
# 			INNER JOIN or a LEFT JOIN with a USING clause that names all columns that
# 			exist in both tables.
#
# 		) RIGHT JOIN works analogously to LEFT JOIN. To keep code portable across databases,
# 			it is recommended that you use LEFT JOIN instead of RIGHT JOIN.
#
# 		) The { OJ --- } syntax shown in the join syntax description exists only for compatibility
# 			with ODBC.
#
# 			The curly braces in the syntax should be written literally, they are not metasyntax
# 			as used elsewhere in syntax desc.
#
# 				SELECT left_tbl.*
# 					FROM { OJ left_tbl LEFT OUTER JOIN right_tbl ON left_tbl.id = right_tbl.id }
# 					WHERE right_tbl.id IS NULL;
#
# 			You can use other types of joins within { OJ --- }, such as INNER JOIN or RIGHT OUTER JOIN.
#
# 			This helps with compatibility with some third-party apps, but is not official ODBC syntax
#
# 		) STRAIGHT_JOIN is similar to JOIN, except that the left table is always read before the right table.
#
# 			This can be used for those (few) cases for which the join optimizer processes the tables
# 			in a suboptimal order.
#
# 			Some join examples:
#
# 				SELECT * FROM table1, table2;
#
# 				SELECT * FROM table1 INNER JOIN table2 ON table1.id = table2.id;
#
# 				SELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id;
#
# 				SELECT * FROM table1 LEFT JOIN table2 USING (id);
#
# 				SELECT * FROM table1 LEFT JOIN table2 ON table1.id = table2.id
# 					LEFT JOIN table3 ON table2.id = table3.id;
#
# Natural joins and joins with USING, including outer join variants, are processed
# according to the SQL:2003 standard:
#
# 		) Redundant columns of a NATURAL join do not appear.
#
# 			Consider this set of statements:
#
# 				CREATE TABLE t1 (i INT, j INT);
# 				CREATE TABLE t2 (k INT, j INT);
#
# 				INSERT INTO t1 VALUES(1, 1);
# 				INSERT INTO t2 VALUES(1, 1);
#
# 				SELECT * FROM t1 NATURAL JOIN t2;
# 				SELECT * FROM t1 JOIN t2 USING (j);
#
# 			In the first SELECT statement, column j appears in both tables and thus becomes
# 			a join column, so, according to standard SQL, it should appear only once in the output,
# 			not twice.
#
# 			Similarly, in the second SELECT statement, column j is named in the USING clause and
# 			should appear only once in the output, not twice.
#
# 			Thus, the statements produce this output:
#
# 				+--------+--------+----------+
# 				| j 	   | i      | k 		  |
# 				+--------+--------+----------+
# 				| 1 		| 1 		| 1 		  |
# 				+--------+--------+----------+
#
# 				+--------+--------+----------+
# 				| j 		| i 		| k 		  |
# 				+--------+--------+----------+
# 				| 1 		| 1 		| 1 		  |
# 				+--------+--------+----------+
#
# 			Redundant column elimination and column ordering occurs according to standard SQL,
# 			producing this display order:
#
# 				) First, coalesced common columns of the two joined tables, in the order in which they occur in the first table
#
# 				) Second, columns unique to the first table, in order in which they occur in that table
#
# 				) Third, columns unique to the second table, in order in which they occur in that table
#
# 			The single result column that replaces two common columns is defined using the coalesce operation.
#
# 			That is, for two t1.a and t2.a the resulting single join column a is defined as
# 			a = COALESCE(t1.a, t2.a), where:
#
# 				COALESCE(x, y) = (CASE WHEN x IS NOT NULL THEN x ELSE y END)
#
# 			If the join operation is any other join, the result columns of the join consist of the
# 			concatenation of all columns of the joined tables.
#
# 			A consequence of the definition of coalesced columns is that, for outer joins, the coalesced column
# 			contains the value of the non-NULL column if one of the two columns is always NULL.
#
# 			If neither or both columns are NULL, both common columns have the same value, so it does not
# 			matter which one is chosen at the value of the coalesced column.
#
# 			A simple way to interpret this is to consider that a coalesced column of an outer join
# 			is represented by the common column of the inner table of a JOIN.
#
# 			Suppose that the tables t1(a, b) and t2(a, c) have the following contents:
#
# 				t1 	t2
# 				----  ----
# 				1 x   2 z
# 				2 y   3 w
#
# 			Then, for this join, column a contains the values of t1.a
#
# 				SELECT * FROM t1 NATURAL LEFT JOIN t2;
# 				+---------+--------+-----------+
# 				| a       | b 		 | c 			 |
# 				+---------+--------+-----------+
# 				| 1 		 | x 		 | NULL   	 |
# 				| 2 		 | y 		 | z 			 |
# 				+---------+--------+-----------+
#
# 			By contrast, for this join, column a contains the values of t2.a
#
# 				SELECT * FROM t1 NATURAL RIGHT JOIN t2;
# 				+---------+---------+---------+
# 				| a 		 | c 		  | b 		|
# 				+---------+---------+---------+
# 				| 2 		 | z 		  | y 		|
# 				| 3 		 | w 		  | NULL 	|
# 				+---------+---------+---------+
#
# 			Compare those results to the otherwise equivalent queries with JOIN --- ON:
#
# 				SELECT * FROM t1 LEFT JOIN t2 ON (t1.a = t2.a);
# 				+--------+---------+---------+---------+
# 				| a      | b 		 | a 		  | c 		|
# 				+--------+---------+---------+---------+
# 				| 1 		| x 		 | NULL 	  | NULL 	|
# 				| 2 		| y 		 | 2 		  | z 		|
# 				+--------+---------+---------+---------+
#
# 				SELECT * FROM t1 RIGHT JOIN t2 ON (t1.a = t2.a);
# 				+--------+---------+---------+---------+
# 				| a 		| b 		 | a 		  | c 		|
# 				+--------+---------+---------+---------+
# 				| 2 		| y 		 | 2 		  | z 		|
# 				| NULL   | NULL 	 | 3 		  | w 		|
# 				+--------+---------+---------+---------+
#
# 		) A USING clause can be rewritten as an ON clause that compares corresponding columns.
#
# 			However, although USING and ON are similar, they are not quite the same.
#
# 			Consider the following two queries:
#
# 				a LEFT JOIN b USING (c1, c2, c3)
# 				a LEFT JOIN b ON a.c1 = b.c1 AND a.c2 = b.c2 AND a.c3 = b.c3
#
# 			With respect to determining which rows satisfy the join condition, both joins
# 			are semantically identical.
#
# 			With respect to determining which columns to display for SELECT * expansion,
# 			the two joins are not semantically identical.
#
# 			The USING join selects the coalesced value of corresponding columns,
# 			whereas the ON join selects all columns from all tables.
#
# 			For the USING join, SELECT * selects these values:
#
# 				COALESCE(a.c1, b.c1), COALESCE(a.c2, b.c2), COALESCE(a.c3, b.c3)
#
# 			For the ON join, SELECT * selects these values:
#
# 				a.c1, a.c2, a.c3, b.c1, b.c2, b.c3
#
# 			With an inner join, COALESCE(a.c1, b.c1) is the same as either a.c1 or
# 			b.c1 because both columns will have teh same value.
#
# 			With an outer join (such as LEFT JOIN), one of the two columns can be NULL
#
# 			That column is omitted from the result.
#
# 		) An ON clause can refer only to its operands.
#
# 			Example:
#
# 				CREATE TABLE t1 (i1 INT);
# 				CREATE TABLE t2 (i2 INT);
# 				CREATE TABLE t3 (i3 INT);
# 				SELECT * FROM t1 JOIN t2 ON (i1 = i3) JOIN t3;
#
# 			The statement fails with an Unknown column 'i3' in 'on clause' error because
# 			i3 is a column in t3, which is not an operand of the ON clause.
#
# 			To enable the join to be processed, rewrite the statement as follows:
#
# 				SELECT * FROM t1 JOIN t2 JOIN t3 ON (i1 = i3);
#
# 		) JOIN has higher precedence than the comma operator (,), so the join expression
# 			t1, t2 JOIN t3 is interpreted as (t1, (t2 JOIN t3)), not as ((t1, t2) JOIN t3)
#
# 			This affects statements that use an ON clause because that clause can refer only
# 			to columns in the operands of the join, and the precedence affects interpretation
# 			of what those operands are.
#
# 			EXAMPLE:
#
# 				CREATE TABLE t1 (i1 INT, j1 INT);
# 				CREATE TABLE t2 (i2 INT, j2 INT);
# 				CREATE TABLE t3 (i3 INT, j3 INT);
#
# 				INSERT INTO t1 VALUES(1, 1);
# 				INSERT INTO t2 VALUES(1, 1);
# 				INSERT INTO t3 VALUES(1, 1);
#
# 				SELECT * FROM t1, t2 JOIN t3 ON (t1.i1 = t3.i3);
#
# 			The JOIN takes precedence over the comma operator, so the operands for the ON clause
# 			are t2 and t3.
#
# 			Because t1.i1 is not a column in either of the operands, the result is an
# 			Unknown column 't1.i1' in 'on clause' error
#
# 			To enable the join to be processed, use either of these strategies:
#
# 				) Group the first two tables explicitly with parentheses so that the operands
# 					for the ON clause are (t1, t2) and t3:
#
# 					SELECT * FROM (t1, t2) JOIN t3 ON (t1.i1 = t3.i3);
#
# 				) Avoid the use of the comma operator and use JOIN instead:
#
# 					SELECT * FROM t1 JOIN t2 JOIN t3 ON (t1.i1 = t3.i3);
#
# 			The same precedence interpretation also applies to statements that mix
# 			the comma operator with INNER JOIN, CROSS JOIN, LEFT JOIN, and RIGHT JOIN,
# 			all of which have higher precedence than the comma operator.
#
# 		) A MySQL extension compared to the SQL:2003 standard is that MySQL permits you to
# 			qualify the common (coalesced) columns of NATURAL or USING joins, whereas 
# 			the standard disallows that.
#
# 13.2.10.3 UNION SYNTAX
#
# 		SELECT ---
# 		UNION [ALL | DISTINCT] SELECT ---
# 		[UNION [ALL | DISTINCT] SELECT ---]
#
# UNION is used to combine the result from multiple SELECT statements into a single result set.
#
# The column names from the first SELECT statement are used as the column names for the
# results returned.
#
# Selected columns listed in corresponding positions of each SELECT statement should have
# the same data type.
#
# (For example, the first column selected by the first statement should have the same type
# as the first column selected by the other statements)
#
# If the data types of corresponding SELECT columns do not match, the types and lengths of
# the columns in the UNION result take into account the values retrieved by all of
# the SELECT statements.
#
# For example, consider the following:
#
# 		SELECT REPEAT('a',1) UNION SELECT REPEAT('b',10);
# 		+----------------------+
# 		| REPEAT('a',1) 		  |
# 		+----------------------+
# 		| a 						  |
# 		| bbbbbbbbbb 			  |
# 		+----------------------+
#
# The SELECT statements are normal select statements, but with the following restrictions:
#
# 		) Only the last SELECT statement can use INTO OUTFILE (However, the entire UNION result is written to the file)
#
# 		) HIGH_PRIORITY cannot be used with SELECT statements that are part of a UNION.
#
# 			If you specify it for the first SELECT, it has no effect.
#
# 			If you specify it for any subsequent SELECT statements, a syntax error results.
#
# The default behavior for UNION is that duplicate rows are removed from the result.
#
# The optional DISTINCT keyword has no effect other than the default because it also
# specifies duplicate-row removal.
#
# With the optional ALL keyword, duplicate-row removal does not occur and the result includes
# all matching rows from all the SELECT statements.
#
# You can mix UNION_ALL and UNION_DISTINCT in the same query.
#
# Mixed UNION types are treated such that a DISTINCT union overrides any ALL union
# to its left.
#
# A DISTINCT union can be produced explicitly by using UNION_DISTINCT or implicitly
# by using UNION with no following DISTINCT or ALL keyword.
#
# To apply ORDER BY or LIMIT to an individual SELECT, place the clause inside the
# parentheses that enclose the SELECT:
#
# 		(SELECT a FROM t1 WHERE a=10 AND B=1 ORDER BY a LIMIT 10)
# 		UNION
# 		(SELECT a FROM t2 WHERE a=11 AND B=2 ORDER BY a LIMIT 10);
#
# However, use of ORDER BY for individual SELECT statements implies nothing about
# the order in which the rows appear in the final result because UNION
# by default produces an unordered set of rows.
#
# Therefore, the use of ORDER BY in this context is typically in conjunction
# with LIMIT, so that it is used to determine the subset of the selected
# rows to retrieve for the SELECT, even though it does not necessarily affect
# the order of those rows in the final UNION result.
#
# If ORDER BY appears without LIMIT in a SELECT, it is optimized away
# because it will have no effect anyway.
#
# To use an ORDER BY or LIMIT clause to sort or limit the entire UNION result,
# parenthesize the individual SELECT statements and place the ORDER BY or
# LIMIT after the last one.
#
# The following example uses both clauses:
#
# 		(SELECT a FROM t1 WHERE a=10 AND B=1)
# 		UNION
# 		(SELECT a FROM t2 WHERE a=11 AND B=2)
# 		ORDER BY a LIMIT 10;
#
# A statement without parentheses is equivalent ot one parenthesized
# as just shown.
#
# This kind of ORDER BY cannot use column references that include a table
# name (that is, names in tbl_name.col_name format)
#
# Instead, provide a column alias in the first SELECT statement and refer
# to the alias in the ORDER BY.
#
# (Alternatively, refer to the column in the ORDER BY using its column position.
#
# However, use of column positions is deprecated)
#
# Also, if a column to be sorted is aliased, the ORDER BY clause must refer to the
# alias, not the column name.
#
# The first of the following statements will work, but the second will fail
# with an:
#
# 		Unknown column 'a' in 'order clause' error
#
# 		(SELECT a AS b FROM t) UNION (SELECT ---) ORDER BY b;
# 		(SELECT a AS b FROM t) UNION (SELECT ---) ORDER BY a;
#
# To cause rows in a UNION result to consist of the sets of rows retrieved by each
# SELECT one after the other, select an additional column in each SELECT to use
# as a sort column and add an ORDER BY following the last SELECT:
#
# 		(SELECT 1 AS sort_col, col1a, col1b, --- FROM t1)
# 		UNION
# 		(SELECT 2, col2a, col2b, --- FROM t2) ORDER BY sort_col;
#
# To additionally maintain sort order within individual SELECT results,
# add a secondary column to the ORDER BY clause:
#
# 		(SELECT 1 AS sort_col, col1a, col1b, --- FROM t1)
# 		UNION
# 		(SELECT 2, col2a, col2b, --- FROM t2) ORDER BY sort_col, col1a;
#
# Use of an additional column also enables you to determine which SELECT
# each row comes from.
#
# Extra columns can provide other identifying information as well, such as
# a string that indicates a table name.
#
# UNION queries with an aggregate function in an ORDER BY clause are rejected
# with an ER_AGGREGATE_ORDER_FOR_UNION error.
#
# Example:
#
# 		SELECT 1 AS foo UNION SELECT 2 ORDER BY MAX(1);
#
# 13.2.11 SUBQUERY SYNTAX
#
# 13.2.11.1 THE SUBQUERY AS SCALAR OPERAND
# 13.2.11.2 COMPARISONS USING SUBQUERIES
# 13.2.11.3 SUBQUERIES WITH ANY, IN, or SOME
#
# 13.2.11.4 SUBQUERIES WITH ALL
# 13.2.11.5 ROW SUBQUERIES
# 13.2.11.6 SUBQUERIES WITH EXISTS OR NOT EXISTS
#
# 13.2.11.7 CORRELATED SUBQUERIES
# 13.2.11.8 DERIVED TABLES
# 13.2.11.9 SUBQUERY ERRORS
#
# 13.2.11.10 OPTIMIZING SUBQUERIES
# 13.2.11.11 REWRITING SUBQUERIES AS JOINS
#
# A subquery is a SELECT statement within another statement.
#
# All subquery forms and operations that the SQL standard requires are supported,
# as well as a few features that are MySQL-specific.
#
# Here is an example of a subquery:
#
# 		SELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);
#
# In this example, SELECT * FROM t1 --- is the outer query (or outer statement), and
# (SELECT column1 FROM t2) is the subquery.
#
# We say that the subquery is nested within the outer query, and in fact it is possible
# to nest subqueries within other subqueries, to a considerable depth.
#
# A subquery must always appear within parentheses.
#
# The main advantages of subqueries are:
#
# 		) They allow queries that are structured so that it is possible to isolate each part of a statement
#
# 		) They provide alternative ways to perform operations that would otherwise reuqire complex joins and unions
#
# 		) Many people find subqueries more readable than complex joins or unions.
#
# Here is an example statement that shows the major points about subquery syntax as specified
# by the SQL standard and supported in MySQL:
#
# 		DELETE FROM t1
# 		WHERE s11 > ANY
# 			(SELECT COUNT(*) /* no hint */ FROM t2
# 				WHERE NOT EXISTS
# 					(SELECT * FROM t3
# 						WHERE ROW(5*t2.s1,77)=
# 						 	(SELECT 50,11*s1 FROM t4 UNION SELECT 50,77 FROM
# 								(SELECT * FROM t5) AS t5)));
#
# A subquery can return a scalar (a single value), a single row, a single column or a table
# (one or more rows of one or more columns)
#
# These are called scalar, column, row, and table subqueries.
#
# Subqueries that return a particular kind of result often can be used only in certain
# contexts, as described in teh following sections.
#
# There are few restrictions on the type of statements in which subqueries can be used.
#
# A subquery can contain many of the keywords or clauses that an ordinary SELECT
# can contain:
#
# 		DISTINCT
#
# 		GROUP BY
#
# 		ORDER BY
#
# 		LIMIT
#
# 		joins
#
# 		index hints
#
# 		UNION constructs
#
# 		comments
#
# 		functions
#
# 		etc.
#
# A subquery's outer statement can be any one of:
#
# 		SELECT
#
# 		INSERT
#
# 		UPDATE
#
# 		DELETE
#
# 		SET
#
# 		DO
#
# In MySQL, you cannot modify a table and select from the same table in a subquery.
#
# This applies to statements such as DELETE, INSERT, REPLACE, UPDATE and LOAD DATA INFILE (because subqueries can be used in the SET clause)
#
# For information about how the optimizer handles subqueries, see SECTION 8.2.2,
# "OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS"
#
# For a discussion of restrictions on subquery use, including performance issues for certain
# forms of subquery syntax, see SECTION C.4, "RESTRICTIONS ON SUBQUERIES"
#
# 13.2.11.1 THE SUBQUERY AS SCALAR OPERAND
#
# In its simplest form, a subquery is a scalar subquery that returns a single value.
#
# A scalar subquery is a simple operand, and you can use it almost anywhere a single
# column value or literal is legal, and you can expect it to have those characteristics
# that all operands have:
#
# 		a data type
#
# 		a length
#
# 		indication taht it can be NULL
#
# 		etc.
#
# For example:
#
# 		CREATE TABLE t1 (s1 INT, s2 CHAR(5) NOT NULL);
# 		INSERT INTO t1 VALUES(100, 'abcde');
# 		SELECT (SELECT s2 FROM t1);
#
# The subquery in this SELECT returns a single value ('abcde') that has a data type
# of CHAR, a length of 5, a character set and collation equal to the defaults in effect
# at CREATE_TABLE time, and an indication that the value in the column can be NULL.
#
# Nullability of the value selected by a scalar subquery is not copied because if the
# subquery result is empty,, the result is NULL.
#
# For the subquery just shown, if t1 were empty, the result would be NULL even though
# s2 is NOT NULL
#
# There are a few contexts in which a scalar subquery cannot be used.
#
# If a statement permits only a literal value, you cannot use a subquery.
#
# For example, LIMIT requires literal integer arguments, and LOAD_DATA_INFILE
# requires a literal string file name.
#
# You cannot use subqueries to supply these values.
#
# When you see examples in the following sections that contain the rather 
# spartan construct (SELECT column1 FROM t1), imagine that your own code contains
# much more diverse and complex stuff.
##
# Suppose that we make two tables:
#
# 		CREATE TABLE t1 (s1 INT);
# 		INSERT INTO t1 VALUES(1);
#
# 		CREATE TABLE t2 (s1 INT);
# 		INSERT INTO t2 VALUES(2);
#
# Then perform a SELECT:
#
# 		SELECT (SELECT s1 FROM t2) FROM t1;
#
# The result is 2 because there is a row in t2 containing a column s1 that
# has a value of 2.
#
# A scalar subquery can be part of an expression, but remember the parentheses,
# even if the subquery is an operand that provides an argument for a function.
#
# For example:
#
# 		SELECT UPPER((SELECT s1 FROM t1)) FROM t2;
#
# 13.2.11.2 COMPARISONS USING SUBQUERIES
#
# The most common use of a subquery is in the form:
#
# 		non_subquery_operand comparison_operator (subquery)
#
# Where comparison_operator is one of these operators:
#
# 		= > < >= <= <> != <=>
#
# For example:
#
# 		--- WHERE 'a' = (SELECT column1 FROM t1)
#
# MySQL also permits this construct:
#
# 		non_subquery_operand LIKE (subquery)
#
# At one time the only legal place for a subquery was on the right side of a comparison,
# and you might still find some old DBMSs that insist on this.
#
# Here is an example of a common-form subquery comparison that you cannot do with a join.
#
# It finds all the rows in table t1 for which the column1 value is equal to
# a maximum value in table t2:
#
# 		SELECT * FROM t1
# 			WHERE column1 = (SELECT MAX(column2) FROM t2);
#
# Here is another example, which again is impossible with a join because it
# involves aggregating for one of the tables.
#
# It finds all rows in table t1 containing a value that occurs twice
# in a given column:
#
# 		SELECT * FROM t1 AS t
# 			WHERE 2 = (SELECT COUNT(*) FROM t1 WHERE t1.id = t.id);
#
# For a comparison of the subquery to a scalar, the subquery must return a scalar.
#
# For a comparison of the subquery to a row constructor, the subquery must be a row
# subquery that returns a row with the same number of values as the row constructor.
#
# See SECTION 13.2.11.5, "ROW SUBQUERIES"
#
# 13.2.11.3 SUBQUERIES WITH ANY, IN, OR SOME
#
# Syntax:
#
# 		operand comparison_operator ANY (subquery)
# 		operand IN (subquery)
# 		operand comparison_operator SOME (subquery)
#
# Where comparison_operator is one of these operators:
#
# 		= > < >= <= <> !=
#
# The ANY keyword, which must follow a comparison operator, means
# "return TRUE if the comparison is TRUE for ANY of the values in teh column that the subquery returns"
#
# For example:
#
# 		SELECT s1 FROM t1 WHERE s1 > ANY (SELECT s1 FROM t2);
#
# Suppose that there is a row in table t1 containing (10)
#
# The expression is TRUE if table t2 contains (21, 14, 7) because there is a value
# 7 in t2 that is less than 10.
#
# The expression is FALSE if table t2 contains (20,10), or if table  t2 is empty
#
# The expression is unknown (that is, NULL) if table t2 contains (NULL, NULL, NULL)
#
# When used with a subquery, the word IN is an alias for = ANY
#
# Thus, these two statements are the same:
#
# 		SELECT s1 FROM t1 WHERE s1 = ANY (SELECT s1 FROM t2);
# 		SELECT s1 FROM t1 WHERE s1 IN 	(SELECT s1 FROM t2);
#
# IN and = ANY are not synonyms when used with an expression list.
#
# IN can take an expression list, but = ANY cannot.
#
# See SECTION 12.3.2, "COMPARISON FUNCTIONS AND OPERATORS"
#
# NOT IN is not an alias for <> ANY, but for <> ALL. See SECTION 13.2.11.4,, "SUBQUERIES WITH ALL"
#
# The word SOME is an alias for ANY. Thus, these two statements are the same:
#
# 		SELECT s1 FROM t1 WHERE s1 <> ANY 	(SELECT s1 FROM t2);
# 		SELECT s1 FROM t1 WHERE s1 <> SOME  (SELECT s1 FROM t2);
#
# Use of the word SOME is rare, but this example shows why it might be useful.
#
# To most people, the enlgish phrase "a is not equal to b" means "there is no b which is equal
# to a", but that is not what is meant by the SQL syntax.
#
# The <> syntax means, not equal to or !=
#
# The syntax means "there is some b to which a is not equal"
#
# Using <> SOME instead helps ensure the meaning
#
# 13.2.11.4 SUBQUERIES WITH ALL
#
# Syntax:
#
# 		operand comparison_operator ALL (subquery)
#
# The word ALL which must follow a comparison operator, means "return TRUE if the comparison is TRUE for ALL of the
# values in the column that the subquery returns"
#
# For example:
#
# 		SELECT s1 FROM t1 WHERE s1 > ALL (SELECT s1 FROM t2);
#
# Suppose that there is a row in table t1 containing (10)
#
# The expression is TRUE if table t2 contains (-5,0,+5) because 10 is greater than all
# three values in t2.
#
# The expression is FALSE if table t2 contains (12,6,NULL,-100) beause there is a single
# value 12 in table t2 that is greater than 10.
#
# The expression is unknown (that is, NULL) if table t2 contains (0,NULL,1)
#
# Finally, the expression is TRUE if table t2 is empty.
#
# So, the following expression is TRUE when table t2 is empty:
#
# 		SELECT * FROM t1 WHERE 1 > ALL (SELECT s1 FROM t2);
#
# But this expression is NULL when table t2 is empty:
#
# 		SELECT * FROM t1 WHERE 1 > (SELECT s1 FROM t2);
#
# In addition, the following expression is NULL when table t2 is empty:
#
# 		SELECT * FROM t1 WHERE 1 > ALL (SELECT MAX(s1) FROM t2);
#
# In general, tables containing NULL values and empty tables are "edge cases"
#
# When writing subqueries, always consider whether you have taken those two
# possibilities in account.
#
# NOT IN is an alias for <> ALL. Thus, these two statements are teh same:
#
# 		SELECT s1 FROM t1 WHERE s1 <> ALL (SELECT s1 FROM t2);
# 		SELECT s1 FROM t1 WHERE s1 NOT IN (SELECT s1 FROM t2);
#
# 13.2.11.5 ROW SUBQUERIES
#
# Scalar or column subqueries return a single value or a column of values.
#
# A row subquery is a subquery variant that returns a single row an can thus
# return more than one column value.
#
# Legal operators for row subquery comparisons are:
#
# 		= > < >= <= <> != <=>
#
# Here are two examples:
#
# 		SELECT * FROM t1
# 			WHERE (col1,col2) = (SELECT col3, col4 FROM t2 WHERE id = 10);
# 		SELECT * FROM t1
# 			WHERE ROW(col1,col2) = (SELECT col3, col4 FROM t2 WHERE id = 10);
#
# For both queries, if the table t2 contains a single row with id = 10, the subquery
# returns a single row.
#
# If this row has col3 and col4 values equal to the col1 and col2 values of any rows
# in t1, the WHERE expression is TRUE and each query returns those t1 rows.
#
# If the t2 row col3 and col4 values are not equal the col1 and col2 values
# of any t1 row, the expression is FALSE and the query returns an empty result set.
#
# The expression is unknown(that is,NULL) if the subquery produces no rows.
#
# An error occurs if the subquery produces multiple rows because a row subquery
# can return at most one row.
#
# For information about how each operator work for row comparisons, see SECTION 12.3.2,
# "COMPARISON FUNCTIONS AND OPERATORS"
#
# The expressions (1,2) and ROW(1,2) are sometimes called row constructors.
#
# The two are equivalent.
#
# The row constructor and the row returned by the subquery must contain the same number of values
#
# A row constructor is used for comparisons with subqueries that return two or more columns.
#
# When a subquery returns a single column, this is regarded as a scalar value and not as
# a row, so a row constructor cannot be used with a subquery that does not return at least
# two columns.
#
# Thus, the following query fails with a syntax error:
#
# 		SELECT * FROM t1 WHERE ROW(1) = (SELECT column1 FROM t2)
#
# Row constructors are legal in other contexts.
#
# For example, the following two statements are semantically equivalent 
# (and are handled in the same way by the optimizer):
#
# 		SELECT * FROM t1 WHERE (column1, column2) = (1,1);
# 		SELECT * FROM t1 WHERE column1 = 1 AND column2 = 1;
#
# The following query answers the request, "find all rows in table t1 that also exist in table t2":
#
# 		SELECT column1, column2, column3
# 			FROM t1
# 			WHERE (column1, column2, column3) IN
# 					 (SELECT column1, column2, column3 FROM t2);
#
# For more information about the optimizer and row constructors, see SECTION 8.2.1.20, "ROW CONSTRUCTOR EXPRESSION OPTIMIZATION"
#
# 13.2.11.6 SUBQUERIES WITH EXISTS OR NOT EXISTS
#
# If a subquery returns any rows at all, EXISTS subquery is TRUE, and NOT EXISTS subquery is FALSE.
#
# For example:
#
# 		SELECT column1 FROM t1 WHERE EXISTS (SELECT * FROM t2);
#
# Traditionally, an EXISTS subquery starts with SELECT *, but it could begin with SELECT 5 or SELECT column1
# or anything at all.
#
# MySQL ignores the SELECT list in such a subquery, so it makes no difference.
#
# For the preceding example, if t2 contains any rows, even rows with nothing but NULL values,
# the EXISTS condition is TRUE.
#
# This is actually an unlikely example because a [NOT] EXISTS subquery almost always
# contains correlations.
#
# Here are some more realistic examples:
#
# 		) What kind of store is present in one or more cities
#
# 			SELECT DISTINCT store_type FROM stores
# 				WHERE EXISTS (SELECT * FROM cities_stores
# 								  WHERE cities_stores.store_type = stores.store_type);
#
# 		) What kind of store is present in no cities?
#
# 			SELECT DISTINCT store_type FROM stores
# 				WHERE NOT EXISTS (SELECT * FROM cities_stores
# 										WHERE cities_stores.store_type = stores.store_type);
#
# 		) What kind of store is present in all cities?
#
# 			SELECT DISTINCT store_type FROM stores s1
# 				WHERE NOT EXISTS (
# 					SELECT * FROM cities WHERE NOT EXISTS (
# 						SELECT * FROM cities_stores
# 							WHERE cities_stores.city = cities.city
# 							AND cities_stores.store_type = stores.store_type));
#
# The last example is a double-nested NOT EXISTS query.
#
# That is, it has a NOT EXISTS clause within a NOT EXISTS clause.
#
# Formally, it answers the question "does a city exist with a store that is not in Stores"?
#
# But it is easier to say that a nested NOT EXISTS answers the question "is x TRUE for all y?"
#
# 13.2.11.7 CORRELATED SUBQUERIES
#
# A correlated subquery is a subquery that contains a reference to a table that also appears
# in the outer query.
#
# For example:
#
# 		SELECT * FROM t1
# 			WHERE column1 = ANY (SELECT column1 FROM t2
# 										WHERE t2.column2 = t1.column2);
#
# Notice that the subquery contains a reference to a column of t1, even though
# the subquery's FROM clause does not mention a table t1
#
# So, MySQL looks outside the subquery, and finds t1 in the outer query
#
# Suppose that table t1 contains a row where column1 = 5 and column2 = 6; meanwhile,
# table t2 contains a row where column1 = 5 and column2 = 7
#
# The simple expression --- WHERE column1 = ANY (SELECT column1 FROM t2) would be TRUE,
# but in this example, the WHERE clause within the subquery is FALSE (because (5,6) is
# not equal to (5,7)), so the expression as a whole is FALSE
#
# SCOPING RULE: MySQL evaluates from inside to outside.
#
# For example:
#
# 		SELECT column1 FROM t1 AS x
# 			WHERE x.column1 = (SELECT column1 FROM t2 AS x
# 				WHERE x.column1 = (SELECT column1 FROM t3
# 					WHERE x.column2 = t3.column1));
#
# In this statement, x.column2 must be a column in table t2 because SELECT column1 FROM t2 AS x ---
# renames t2 
#
# It is not a column in table t1 because SELECT column1 FROM t1 --- is an outer query that is farther out
#
# For subqueries in HAVING or ORDER BY clauses, MySQL also looks for column names
# in the outer select list.
#
# For certain cases, a correlated subquery is optimized.
#
# For example:
#
# 		val IN (SELECT key_val FROM tbl_name WHERE correlated_condition)
#
# Otherwise, they are inefficient and likely to be slow.
#
# Rewriting the query as a join might improve performance.
#
# Aggregate functions in correlated subqueries may contain outer references,
# provided the function contains nothing but outer references, and provided the
# function is not contained in another function or expression.
#
# 13.2.11.8 DERIVED TABLES
#
# A derived table is an expression that generates a table within the scope of a query
# FROM clause.
#
# For example, a subquery in a SELECT statement FROM clause is a derived table:
#
# 		SELECT --- FROM (subquery) [AS] tbl_name ---
#
# The JSON_TABLE() function generates a table and provides another way to create a derived table:
#
# 		SELECT * FROM JSON_TABLE(arg_list) [AS] tbl_name ---
#
# The [AS] tbl_name clause is mandatory because every table in a FROM clause must have
# a name.
#
# Any columns in the derived table must have unique names.
#
# Alternatively, tbl_name may be followed by a parenthesized list of names
# for the derived table columns:
#
# 		SELECT --- FROM (subquery) [AS] tbl_name (col_list) ---
#
# The number of column names must be the same as the number of table columns.
#
# For the sake of illustration, assume that you have this table:
#
# 		CREATE TABLE t1 (s1 INT, s2 CHAR(5), s3 FLOAT);
#
# Here is how to use a subquery in the FROM clause, using the example table:
#
# 		INSERT INTO t1 VALUES (1, '1', 1.0);
# 		INSERT INTO t1 VALUES (2, '2', 2.0);
# 		SELECT sb1,sb2,sb3
# 			FROM (SELECT s1 AS sb1, s2 AS sb2, s3*2 AS sb3 FROM t1) AS sb
# 			WHERE sb1 > 1;
#
# Result:
#
# 		+-------+---------+-----------+
# 		| sb1   | sb2 	   | sb3 		|
# 		+-------+---------+-----------+
# 		| 2 	  | 2 		| 4 			|
# 		+-------+---------+-----------+
#
# Here is another example: Suppose that you want to know the average of a set
# of sums for a grouped table.
#
# This does not work:
#
# 		SELECT AVG(SUM(column1)) FROM t1 GROUP BY column1;
#
# However, this query provides the desired information:
#
# 		SELECT AVG(sum_column1)
# 			FROM (SELECT SUM(column1) AS sum_column1
# 					FROM t1 GROUP BY column1) AS t1;
#
# Notice that the column name used within the subquery (sum_column1) is recognized
# in the outer query.
#
# The column names for a derived table come from its select list:
#
# 		SELECT * FROM (SELECT 1, 2, 3, 4) AS dt;
# 		+----+-----+------+------+
# 		| 1  | 2   | 3    | 4    |
# 		+----+-----+------+------+
# 		| 1  | 2   | 3    | 4 	 |
# 		+----+-----+------+------+
#
# To provide column names explicitly, follow the derived table
# name with a parenthesized list of column names:
#
# 		SELECT * FROM (SELECT 1, 2, 3, 4) AS dt (a, b, c, d);
# 		+----+------+------+---------+
# 		| a  | b    | c 	 | d 		  |
# 		+----+------+------+---------+
# 		| 1  | 2    | 3    | 4 		  |
# 		+----+------+------+---------+
#
# A derived table can return a scalar, column, row or table
#
# Derived tables are subject to these restrictions:
#
# 		) A derived table cannot be a correlated subquery
#
# 		) A derived table cannot contain references to other tables of the same SELECT
#
# 		) Prior to MySQL 8.0.14, a derived table cannot contain outer references.
#
# 			This is a MySQL restriction that is lifted in MySQL 8.0.14, not a restriction
# 			of the SQL standard.
#
# 			For example, the derived table dt in the following query contains a reference
# 			t1.b to the table t1 in the outer query:
#
# 				WHERE t1.d > (SELECT AVG(dt.a)
# 									FROM (SELECT SUM(t2.a) AS a FROM
# 											t2 WHERE t2.b = t1.b GROUP BY t2.c) dt
# 								WHERE dt.a > 10);
#
# 			The query is valid in MySQL 8.0.14 and higher.
#
# 			Before 8.0.14, it produces an error: 
#
# 				Unknown column 't1.b' in 'where clause'
#
# The optimizer determines information about derived tables in such a way that
# EXPLAIN does not need to materialize them.
#
# See SECTION 8.2.2.4, "OPTIMIZING DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE
# EXPRESSIONS WITH MERGING OR MATERIALIZATION"
#
# It is possible under certain circumstances that using EXPLAIN_SELECT will modify table
# data.
#
# This can occur if the outer query accesses any tables and an inner query invokes
# a stored function that changes one or more rows of a table.
#
# Suppose that there are two tables t1 and t2 in database d1, and a stored function
# f1 that modifies t2, created as shown here:
#
# 		CREATE DATABASE d1;
# 		USE d1;
# 		CREATE TABLE t1 (c1 INT);
# 		CREATE TABLE t2 (c1 INT);
# 		CREATE FUNCTION f1(p1 INT) RETURNS INT
# 			BEGIN
# 				INSERT INTO t2 VALUES (p1);
# 				RETURN p1;
# 			END;
#
# Referencing the function directly in an EXPLAIN_SELECT has no effect on t2,
# as shown here:
#
# 		SELECT * FROM t2;
# 		Empty set (0.02 sec)
#
# 		EXPLAIN SELECT f1(5)\G
# 		******************************* 1. row ***********************************
# 
# 								id: 1
# 					select_type: SIMPLE
# 							table: NULL
# 					partitions : NULL
# 							type : NULL
# 				possible_keys : NULL
# 				key 			  : NULL
# 						key_len : NULL
# 							ref  : NULL
# 							rows : NULL
# 						filtered: NULL
# 							Extra: No tables used
# 				1 row in set (0.01 sec)
#
# 		SELECT * FROM t2;
# 		Empty set (0.01 sec)
#
# This is because the SELECT statement did not reference any tables, as can be seen in the 
# table and Extra columns of the output.
#
# This is also true of the following nested SELECT:
#
# 		EXPLAIN SELECT NOW() AS a1, (SELECT f1(5)) AS a2\G
# 		************************* 1. row *****************************
# 
# 								id: 1
# 				select_type   : PRIMARY
# 							table: NULL
# 						   type : NULL
# 				possible_keys : NULL
# 							  key: NULL
# 						key_len : NULL
# 							  ref: NULL
# 							rows : NULL
# 						filtered: NULL
# 							Extra: No tables used
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS;
# 		+--------+----------+--------------------------------------------+
# 		| Level  | Code 	  | Message 											  |
# 		+--------+----------+--------------------------------------------+
# 		| Note   | 1249     | Select 2 was reduced during optimization   |
# 		+--------+----------+--------------------------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT * FROM t2;
# 		Empty set (0.00 se)
#
# However, if the outer SELECT references any tables, the optimizer executes the
# statement in the subquery as well, with the result that t2 is modified:
#
# 		EXPLAIN SELECT * FROM t1 AS a1, (SELECT f1(5)) AS a2\G
# 		**************************** 1. row *****************************
# 						id: 1
# 			select_type: PRIMARY
# 					table: <derived2>
# 			partitions : NULL
# 					type : system
# 		possible_keys : NULL
# 					  key: NULL
# 				key_len : NULL
# 					  ref: NULL
# 					 rows: 1
# 				filtered: 100.00
# 					Extra: NULL
# 		*************************** 2. row *******************************
# 						id: 1
# 			select_type: PRIMARY
# 					table: a1
# 			partitions : NULL
# 					type : ALL
# 		possible_keys : NULL
# 					key  : NULL
# 				key_len : NULL
# 					ref  : NULL
# 					rows : 1
# 			filtered   : 100.00
# 					Extra: NULL
# 		************************* 3. row *********************************
# 						id: 2
# 			select_type: DERIVED
# 					table: NULL
# 			partitions : NULL
# 					type : NULL
# 		possible_keys : NULL
# 					key  : NULL
# 				key_len : NULL
# 					ref  : NULL
# 					rows : NULL
# 				filtered: NULL
# 					Extra: No tables used
# 		3 rows in set (0.00 sec)
#
# 		SELECT * FROM t2;
# 		+--------+
# 		| c1 	   |
# 		+--------+
# 		| 5 	   |
# 		+--------+
# 		1 row in set (0.00 sec)
#
# This also means that an EXPLAIN_SELECT statement such as the one shown
# here may take a long time to execute because the BENCHMARK() function
# is executed once for each row in t1:
#
# 		EXPLAIN SELECT * FROM t1 AS a1, (SELECT BENCHMARK(1000000, MD5(NOW())));
#
# 13.2.11.9 SUBQUERY ERRORS
#
# There are some errors that apply only to subqueries. This section describes them.
#
# 		) Unsupported subquery syntax:
#
	# 			ERROR 1235 (ER_NOT_SUPPORTED_YET)
	# 			SQLSTATE = 42000
	# 			Message = "This version of MySQL doesn't yet support
	# 			'LIMIT & IN/ALL/ANY/SOME subquery'"
	#
# 			This means that MySQL does not support statements of the following form:
#
# 				SELECT * FROM t1 WHERE s1 IN (SELECT s2 FROM t2 ORDER BY s1 LIMIT 1)
#
# 		) Incorrect number of columns from subquery:
#
# 				ERROR 1241 (ER_OPERAND_COL)
# 				SQLSTATE = 21000
# 				Message = "Operand should contain 1 column(s)"
#
# 			This error occurs in cases like this:
#
# 				SELECT (SELECT column1, column2 FROM t2) FROM t1;
#
# 			You may use a subquery that returns multiple columns, if the purpose is row
# 			comparison.
#
# 			In other contexts, the subquery must be a scalar operand.
#
# 			See SECTION 13.2.11.5, "ROW SUBQUERIES"
#
# 		) Incorrect number of rows from subquery:
#
# 				ERROR 1242 (ER_SUBSELECT_NO_1_ROW)
# 				SQLSTATE = 21000
# 				Message = "Subquery returns more than 1 row"
#
# 		 	This error occurs for statements where the subquery must return at most one row
# 			but returns multiple rows.
#
# 			Consider the following example:
#
# 				SELECT * FROM t1 WHERE column1 = (SELECT column1 FROM t2);
#
# 			If SELECT column1 FROM t2 returns just one row,, the previous query will work.
#
# 			If the subquery returns more thhan one row, error 1242 will occur.
#
# 			In that case, the query should be rewritten as:
#
# 				SELECT * FROM t1 WHERE column1 = ANY (SELECT column1 FROM t2);
#
# 		) Incorrectly used table in subquery:
#
# 				Error 1093 (ER_UPDATE_TABLE_USED)
# 				SQLSTATE = HY000
# 				Message = "You can't specify target table 'x'
# 				for update in FROM clause"
#
# 			This error occurs in cases such as the following, which attempts to modify a table
# 			and select from the same table in the subquery:
#
# 				UPDATE t1 SET column2 = (SELECT MAX(column1) FROM t1);
#
# 			You can use a subquery for assignment within an UPDATE statement because subqueries
# 			are legal in UPDATE and DELETE statements as well as in SELECT statements.
#
# 			However, you cannot use the same table (in this case, table t1) for both the subquery
# 			FROM clause and the update target.
#
# For transactional storage engines, the failure of a subquery causes the entire statement to fail.
#
# For nontransactional storage engines, data modifications made before the error was
# encountered are preserved.
#
# 13.2.11.10 OPTIMIZING SUBQUERIES
#
# Development is ongoing, so no optimization tip is reliable for the long term.
#
# The following list provides some interesting tricks that you might want to paly
# with.
#
# See also SECTION 8.2.2, "OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS"
#
# 		) Use subquery clauses that affect the number or order of the rows in the subquery.
#
# 			For example:
#
# 				SELECT * FROM t1 WHERE t1.column1 IN
# 					(SELECT column1 FROM t2 ORDER BY column1);
#
# 				SELECT * FROM t1 WHERE t1.column1 IN
# 					(SELECT DISTINCT column1 FROM t2);
#
# 				SELECT * FROM t1 WHERE EXISTS 
# 					(SELECT * FROM t2 LIMIT 1);
#
# 		) Replace a join with a subquery. For example, try this:
#
# 				SELECT DISTINCT column1 FROM t1 WHERE t1.column1 IN (
# 					SELECT column1 FROM t2);
#
# 			Instead of this:
#
# 				SELECT DISTINCT t1.column1 FROM t1, t2
# 					WHERE t1.column1 = t2.column1;
#
# 		) Some subqueries can be transformed to joins for compatibility with older versions
# 			of MySQL that do not support subqueries.
#
# 			However, in some cases, converting a subquery to a join may improve performance.
#
# 			See SECTION 13.2.11.11, "REWRITING SUBQUERIES AS JOINS"
#
# 		) Move clauses from outside to inside the subquery. For example, use  this query:
#
# 				SELECT * FROM t1
# 					WHERE s1 IN (SELECT s1 FROM t1 UNION ALL SELECT s1 FROM t2);
#
# 			Instead of this query:
#
# 				SELECT * FROM t1
# 					WHERE s1 IN (SELECT s1 FROM t1) OR s1 IN (SELECT s1 FROM t2);
#
# 			For another example, use this query:
#
# 				SELECT (SELECT column1 + 5 FROM t1) FROM t2;
#
# 			Instead of this query:
#
# 				SELECT (SELECT column1 FROM t1) + 5 FROM t2;
#
# 		) Use a row subquery instead of a correlated subquery. For example, use this query:
#
# 				SELECT * FROM t1
# 					WHERE (column1,column2) IN (SELECT column1,column2 FROM t2);
#
# 			Instead of this query:
#
# 				SELECT * FROM t1
# 					WHERE EXISTS (SELECT * FROM t2 WHERE t2.column1=t1.column1
# 									  AND t2.column2=t1.column2);
#
# 		) Use NOT (a = ANY (---)) rather than a <> ALL (---)
#
# 		) Use x = ANY (table containing (1,2)) rather than x=1 OR x=2
#
# 		) Use = ANY rather than exists
#
# 		) For uncorrelated subqueries that always return one row, IN is always slower than =
#
# 			For example, use this query:
#
# 				SELECT * FROM t1
# 					WHERE t1.col_name = (SELECT a FROM t2 WHERE b = some_const);
#
# 			Instead of this query:
#
# 				SELECT * FROM t1
# 					WHERE t1.col_name IN (SELECT a FROM t2 WHERE b = some_const);
#
# These tricks might cause programs to go faster or slower.
#
# Using MySQL facilities like the BENCHMARK() function, you can get an idea
# about what helps in your own situation.
#
# See SECTION 12.15, "INFORMATION FUNCTIONS"
#
# Some optimizations that MySQL itself makes are:
#
# 		) MySQL executes uncorrelated subqueries only once.
#
# 			Use EXPLAIN to make sure that a given subquery really is uncorrelated.
#
# 		) MySQL rewrites IN, ALL, ANY and SOME subqueries in an attempt to take advantage
# 			of the possibility that the select-list columns in the subquery are indexed.
#
# 		) MySQL replaces subqueries of the following form with an index-lookup function,
# 			which EXPLAIN describes as a special join type (unique_subquery or index_subquery):
#
# 			--- IN (SELECT indexed_column FROM single_table ---)
#
# 		) MySQL enhances expressions of the following form with an expression involving MIN() or MAX(),
# 			unless NULL values or empty sets are involved:
#
# 				value {ALL|ANY|SOME} {> | < | >= | <=} (uncorrelated subquery)
#
# 			For example, this WHERE clause:
#
# 				WHERE 5 > ALL (SELECT x FROM t)
#
# 			might be treated by the optimizer like this:
#
# 				WHERE 5 > (SELECT MAX(x) FROM t)
#
# See also MYSQL INTERALS: HOW MYSQL TRANSFORMS SUBQUERIES
#
# 13.2.11.11 REWRITING SUBQUERIES AS JOINS
#
# Sometimes there are other ways to test membership in a set of values than by using a subquery.
#
# Also, on some ocassions - it is not only possible to rewrite a query without a subquery,
# but it can be more efficient to make use of some of these techniques rather than to use
# subqueries.
#
# One of these is the IN() construct:
#
# For example, this query:
#
# 			SELECT * FROM t1 WHERE id IN (SELECT id FROM t2);
#
# Can be rewritten as:
#
# 			SELECT DISTINCT t1.* FROM t1, t2 WHERE t1.id=t2.id;
#
# The queries:
#
# 		SELECT * FROM t1 WHERE id NOT IN (SELECT id FROM t2);
# 		SELECT * FROM t1 WHERE NOT EXISTS (SELECT id FROM t2 WHERE t1.id=t2.id);
#
# can be rewritten as:
#
# 		SELECT table1.*
# 			FROM table1 LEFT JOIN table2 ON table1.id=table2.id
# 			WHERE table2.id IS NULL;
#
# A LEFT [OUTER] JOIN can be faster than an equivalent subquery because the server might
# be able to optimizer it better - a fact that is not specific to MySQL Server alone.
#
# Prior to SQL-92, outer joins did not exist, so subqueries were the only way to do
# certain things.
#
# Today, MySQL Server and many other modern database systems offer a wide range
# of outer join types.
#
# MySQL Server supports multiple-table DELETE statements that can be used to efficiently
# delete rows based on information from one table or even from many tables at the
# same time.
#
# Multiple-table UPDATE statements are also supported.
#
# See SECTION 13.2.2, "DELETE SYNTAX" and SECTION 13.2.12, "UPDATE SYNTAX"
#
# 13.2.12 UPDATE SYNTAX
#
# UPDATE is a DML statement that modifies rows in a table.
#
# An UPDATE statement can start with a WITH clause to define common table
# expressions accessible within the UPDATE.
#
# See SECTION 13.2.13, "WITH SYNTAX (COMMON TABLE EXPRESSIONS)"
#
# Single-table syntax:
#
# 		UPDATE [LOW_PRIORITY] [IGNORE] table_reference
# 			SET assignment_list
# 			[WHERE where_condition]
# 			[ORDER BY ---]
# 			[LIMIT row_count]
#
# 		value:
# 			{expr | DEFAULT}
#
# 		assignment:
# 			col_name = value
#
# 		assignment_list:
# 			assignment [, assignment] ---
#
# Multiple-table syntax:
#
# 		UPDATE [LOW_PRIORITY] [IGNORE] table_references
# 			SET assignment_list
# 			[WHERE where_condition]
#
# For the single-table syntax, the UPDATE statement updates columns of existing
# rows in the named table with new values.
#
# The SET clause indicates which columns to modify and the values they should be given.
#
# Each value can be given as an expression, or the keyword DEFAULT to set a column
# explicitly to its default value.
#
# The WHERE clause, if given, specifies the conditions that identify which rows to update.
#
# With no WHERE clause, all rows are updated.
#
# If the ORDER BY clause is specified, the rows are updated in the order that is specified.
# The LIMIT clause places a limit on the number of rows that can be updated.
#
# For the multiple-table syntax, UPDATE updates rows in each table named in table_references
# that satisfy the conditions.
#
# Each matching row is updated once, even if it matches the conditions multiple times.
#
# For multiple-table syntax, ORDER BY and LIMIT cannot be used.
#
# For partitioned tables, both the single-single and multiple-table forms of this statement
# support the use of a PARTITION option as part of a table reference.
#
# This option takes a list of one or more partitions or subpartitions (or both)
#
# Only the partitions (or subpartitions) listed are checked for matches, and a row that
# is not in any of these partitions or subpartitions is not updated, whether it satisfies
# the where_condition or not.
#
# NOTE:
#
# 		Unlike the case when using PARTITION with an INSERT or REPLACE statement, an otherwise
# 		valid UPDATE --- PARTITION statement is considered successful even if no rows in the
# 		listed partitions (or subpartitions) match the where_condition
#
# For more information and examples, see SECTION 23.5, "PARTITION SELECTION"
#
# where_condition is an expression that evaluates to true for each row to be updated:
# For expression syntax, see SECTION 9.5, "EXPRESSIONS"
#
# table_references and where_condition are specified as described in SECTION 13.2.10, "SELECT SYNTAX"
#
# You need the UPDATE privilege only for columns referenced in an UPDATE that are actually updated.
#
# You need only the SELECT privilege for any columns that are read but not modified.
#
# The UPDATE statement supports the following modifiers:
#
# 		) With the LOW_PRIORITY modifier, execution of the UPDATE is delayed until no other clients
# 			are reading from the table.
#
# 			This affects only storage engines that use only table-level locking (such as MyISAM, MEMORY, and MERGE)
#
# 		) With the IGNORE modifier, the update statement does not abort even if errors occur during the update.
#
# 			Rows for which duplicate-key conflicts occur on a unique key value are not updated.
#
# 			Rows updated to values that would cause data conversion errors are updated to the closest
# 			valid values instead.
#
# 			For more information, see COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE
#
# UPDATE_IGNORE statements, including those having an ORDER BY clause, are flagged as unsafe
# for statement-based replication.
#
# (This is because the order in which the rows are updated determines which rows are ignored)
#
# Such statements produce a warning in the error log when using statement-based mode and are 
# written to the binary log using the row-based format when using MIXED mode.
#
# (Bug #11758262, Bug #50439)
#
# See SECTION 17.2.1.3, "DETERMINATION OF SAFE AND UNSAFE STATEMENTS IN BINARY LOGGING"
# for more information.
#
# If  you access a column from the table to be updated in an expression, UPDATE uses the current
# value of the column.
#
# For example, the following statement sets col1 to one more than its current value:
#
# 		UPDATE t1 SET col1 = col1 + 1;
#
# The second assignment in the following statement sets col2 to the current (updated)
# col1 value, not the original col1 value.
#
# The result is that col1 and col2 have the same value.
#
# This behavior differs from standard SQL.
#
# 		UPDATE t1 SET col1 = col1 + 1, col2 = col1;
#
# Single-table UPDATE assignments are generally evaluated from left to right.
#
# For multiple-table updates, there is no guarantee that assignments are carried
# out in any particular order.
#
# If you set a column to the value it currently has, MySQL notices this and does
# not update it.
#
# If you update a column that has been declared NOT NULL by setting to NULL, an error
# occurs if strict SQL mode is enabled; otherwise, the column is set to the implicit
# default value for the column data type and the warning count is incremented.
#
# The implicit default value is 0 for numeric types, the empty string('') for string
# types, and the "zero" value for date and time types.
#
# See SECTION 11.7, "DATA TYPE DEFAULT VALUES"
#
# If a generated column is updated explicitly, the only permitted value is DEFAULT.
#
# For information about generated columns, see SECTION 13.1.20.8, "CREATE TABLE AND GENERATED COLUMNS"
#
# UPDATE returns the number of rows that were actually changed.
#
# The mysql_info() C API function returns the number of rows that were matched and updated
# and the number of warnings that occurred during the UPDATE.
#
# You can use LIMIT row_count to restrict the scope of the UPDATE 
#
# A LIMIT clause is a rows-matched restriction. The statement stops as soon as it has found
# row_count rows that satisfy the WHERE clause, whether or not they actually were changed.
#
# If an UPDATE statement includes an ORDER BY clause, the rows are updated in the order specified
# by the clause.
#
# This can be useful in certain situations that might otherwise result in an error.
#
# Suppose that a table t contains a column id that has a unique index.
#
# The following statement could fail with a duplicate-key error, depending
# on the order in which rows are updated:
#
# 		UPDATE t SET id = id + 1;
#
# For example, if the table contains 1 and 2 in the id column and 1 is updated
# to 2 before 2 is updated to 3, an error occurs.
#
# To avoid this problem, add an ORDER BY clause to cause the rows with larger
# id values to be updated before those with smaller values:
#
# 		UPDATE t SET id = id + 1 ORDER BY id DESC;
#
# You can also perform UPDATE operations covering multiple tables.
#
# However, you cannot use ORDER BY or LIMIT with a multiple-table UPDATE.
#
# The table_references clause lists the tables involved in teh join.
#
# Its syntax is described in SECTION 13.2.10.2, "JOIN SYNTAX"
#
# Here is an example:
#
# 		UPDATE items,month SET items.price=month.price
# 		WHERE items.id=month.id;
#
# The preceding example shows an inner join that uses the comma operator, but multiple-table
# UPDATE statements can use any type of join permitted in SELECT statements, such as LEFT JOIN.
#
# If you use a multiple-table UPDATE statement involving InnoDB tables for which there are
# foreign key constraints, the MySQL optimizer might process tables in an order that
# differs from that of their parent/child relationship.
#
# In this case, the statement fails and rolls back.
#
# Instead, update a single table and rely on the ON UPDATE capabilities that
# InnoDB provides to cause the other tables to be modified accordingly.
#
# See SECTION 15.6.1.5, "INNODB AND FOREIGN KEY CONSTRAINTS"
#
# You cannot update a table and select from the same table in a subquery.
#
# An UPDATE on a partitioned table using a storage engine such as MyISAM that employs
# table-level locks locks only those partitions containing rows that match the
# UPDATE statement WHERE clause, as long as none of the table partitioning columns
# are updated.
#
# (For storage engines such as InnoDB that employ row-level locking, no locking of
# partitions takes place)
#
# For more information, see PARTITIONING AND LOCKING
#
# 13.2.13 WITH SYNTAX (COMMON TABLE EXPRESSIONS)
#
# A common table expression (CTE) is a named temporary result set that exists
# within the scope of a single statement and that can be referred to later
# within that statement, possibly multiple times.
#
# The following discussion describes how to write statements that use CTEs.
#
# 		) COMMON TABLE EXPRESISON SYNTAX
#
# 		) RECURSIVE COMMON TABLE EXPRESSIONS
#
# 		) LIMITING COMMON TABLE EXPRESSION RECURSION
#
# 		) RECURSIVE COMMON TABLE EXPRESSION EXAMPLES
#
# 		) COMMON TABLE EXPRESSIONS COMPARED TO SIMILAR CONSTRUCTS
#
# For informaiton about CTE optimization, see SECTION 8.2.2.4, "OPTIMIZING
# DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS WITH MERGING OR MATERIALIZATION"
#
# ADDITIONAL RESOURCES
#
# These articles contain additional information about using CTEs in MySQL, including many examples:
#
# 		<LINKS, RETURN TO AFTER COMPLETED SECTION>
#
# COMMON TABLE EXPRESSION SYNTAX
#
# To specify common table expressions, use a WITH clause that has one or more comma-separated
# subclauses.
#
# Each subclause provides a subquery that produces a result set and associates a name with the
# subquery.
#
# The following example defines CTEs named cte1 and cte2 in the WITH clause, and refers to them
# in the top-level SELECT that follows the WITH clause:
#
# 		WITH
# 			cte1 AS (SELECT a, b FROM table1),
# 			cte2 AS (SELECT c, d FROM table2)
# 		SELECT b, d FROM cte1 JOIN cte2
# 		WHERE cte1.a = cte2.c;
#
# In the statement containing the WITH clause, each CTE name can be referenced
# to access the corresponding CTE result set.
#
# A CTE name can be referenced in other CTEs, enabling CTEs to be defined based
# on other CTEs.
#
# A CTE can refer to itself to define a recursive CTE
#
# Common applications of recursive CTEs include series generation and traversal
# of hierarchial or tree-structured data.
#
# Common table expressions are an optional part of the syntax for DML statements.
#
# They are defined using a WITH clause:
#
# 		with_clause:
# 			WITH [RECURSIVE]
# 				cte_name [(col_name [, col_name] ---)] AS (subquery)
# 				[, cte_name [(col_name [, col_name] ---)] AS (subquery)] ---
#
# cte_name names a single common table expression and can be used as a table
# reference in the statement containing the WITH clause.
#
# The subquery part of AS (subquery) is called the "subquery of the CTE" and is what
# produces the CTE result set.
#
# The parentheses following AS are required.
#
# A common table expression is recursive if its subquery refers to its own name.
#
# The RECURSIVE keyword must be included if any CTE in the WITH clause is recursive.
#
# For more information, see RECURSIVE COMMON TABLE EXPRESSIONS
#
# Determination of column names for a given CTE occurs as follows:
#
# 		) If a parenthesized list of names follows the CTE name, those names are the column names:
#
# 			WITH cte (col1, col2) AS
# 			(
# 				SELECT 1, 2
# 				UNION ALL
# 				SELECT 3, 4
# 			)
# 			SELECT col1, col2 FROM cte;
#
# 			The number of names in the list must be the same as the number of columns in the result set.
#
# 		) Otherwise, the column names come from the select list of the first SELECT within the AS (subquery) part:
#
# 			WITH cte AS
# 			(
# 				SELECT 1 AS col1, 2 AS col2
# 				UNION ALL
# 				SELECT 3, 4
# 			)
# 			SELECT col1, col2 FROM cte;
#
# A WITH clause is permitted in these contexts:
#
# 		) At the beginning of SELECT, UPDATE and DELETE statements.
#
# 			WITH --- SELECT ---
# 			WITH --- UPDATE ---
# 			WITH --- DELETE ---
#
# 		) At the beginning of subqueries (including derived table subqueries):
#
# 			SELECT --- WHERE id IN (WITH --- SELECT ---) ---
# 			SELECT * FROM (WITH --- SELECT ---) AS dt ---
#
# 		) Immediately preceding SELECT for statements that include a SELECT statement:
#
# 			INSERT --- WITH --- SELECT ---
# 			REPLACE --- WITH --- SELECT ---
# 		
# 			CREATE TABLE --- WITH --- SELECT ---
# 			CREATE VIEW --- WITH --- SELECT ---
#
# 			DECLARE CURSOR --- WITH --- SELECT ---
# 			EXPLAIN --- WITH --- SELECT ---
#
# Only one WITH clause is permitted at the same level.
#
# WITH followed by WITH at the same level is not permitted, so this is illegal:
#
# 		WITH cte1 AS (---) WITH cte2 AS (---) SELECT ---
#
# To make the statement legal, use a single WITH clause that separates
# the subclauses by a comma:
#
# 		WITH cte1 AS (---), cte2 AS (---) SELECT ---
#
# However, a statement can contain multiple WITH clauses if they occur at different
# levels:
#
# 		WITH cte1 AS (SELECT 1)
# 		SELECT * FROM (WITH cte2 AS (SELECT 2) SELECT * FROM cte2 JOIN cte1) AS dt;
#
# A WITH clause can define one or more common table expressions, but each CTE name
# must be unique to the clause. This is illegal:
#
# 		WITH cte1 AS (---), cte1 AS (---) SELECT ---
#
# To make the statement legal, define the CTEs with unique names:
#
# 		WITH cte1 AS (---), cte2 AS (---) SELECT ---
#
# A CTE can refer to itself or to other CTEs:
#
# 		) A self-referencing CTE is recursive
#
# 		) A CTE can refer to CTEs defined earlier in the same WITH clause, but not those defined later.
#
# 		  This constraint rules out mutually-recursive CTEs, where cte1 references cte2 and cte2
# 			references cte1.
#
# 			One of those references must be to a CTE defined later, which is not permitted.
#
# 		) A CTE in a given query block can refer to CTEs defined in query blocks at a more outer level,
# 			but not CTEs defined in query blocks at a more inner level.
#
# For resolving references to objects with the same names, derived tables hide CTEs; and CTEs
# hide base tables, TEMPORARY tables, and views.
#
# Name resolution occurs by seaching for objects in the same query block, then proceeding
# to outer blocks in turn while no object with the name is found.
#
# Like derived tables, a CTE cannot contain outer references prior to MySQL 8.0.14
#
# This is a MySQL restriction that is lifted in MySQL 8.0.14, not a restriction of the
# SQL standard.
#
# For additional syntax considerations specific to recursive CTEs, see RECURSIVE COMMON TABLE EXPRESSIONS
#
# RECURSIVE COMMON TABLE EXPRESSIONS
#
# A recursive common table expression is one having a subquery that refers to its own name.
#
# For example:
#
# 		WITH RECURSIVE cte (n) AS
# 		(
# 			SELECT 1
# 			UNION ALL
# 			SELECT n + 1 FROM cte WHERE n < 5
# 		)
# 		SELECT * FROM cte;
#
# When executed, the statement produces this result, a single column containing a simple
# linear sequence:
#
# 		+--------+
# 		| n 		|
# 		+--------+
# 		| 1 	   |
# 		| 2 		|
# 		| 3 	   |
# 		| 4 	   |
# 		| 5 		|
# 		+--------+
#
# A recursive CTE has this structure:
#
# 		) The WITH clause must begin with WITH RECURSIVE if any CTE in the WITH clause refers to itself.
#
# 			(If no CTE refers to itself, RECURSIVE is permitted but not required)
#
# 			If you forget RECURSIVE for a recursive CTE, this error is a likely result:
#
# 				ERROR 1146 (42S02): Table 'cte_name' doesn't exist
#
# 		) The recursive CTE subquery has two parts, separated by UNION_[ALL] or UNION_DISTINCT:
#
# 			SELECT --- 			--- return initial row set
# 			UNION ALL
# 			SELECT --- 			--- return additional row sets
#
# 			The first SELECT produces the initial row or rows for the CTE and does not refer to the
# 			CTE name.
#
# 			The second SELECT produces additional rows and recurses by referring to the CTE name
# 			in its FROM clause.
#
# 			Recursion ends when this part produces no new rows.
#
# 			Thus, a recursive CTE consists of a nonrecursive SELECT part followed by a recursive SELECT part.
#
# 			Each SELECT part can itself be a union of multiple SELECT statements.
#
# 		) The types of the CTE result columns are inferred from the column types of the nonrecursive
# 			SELECT part only, and the columns are all nullable.
#
# 			For type determination, the recursive SELECT part is ignored.
#
# 		) If the nonrecursive and recursive parts are separated by UNION_DISTINCT, duplicate rows
# 			are eliminated.
#
# 			This is useful for queries that perform transitive closures, to avoid infinite loops.
#
# 		) Each iteration of the recursive part operates only on the rows produced by the previous iteration.
#
# 			If the recursive part has multiple query blocks, iterations of each query block are
# 			scheduled in unspecified order, and each query block operates on rows that have been
# 			produced either by its previous iteration or by other query blocks since that previous
# 			iteration's end.
#
# The recursive CTE subquery shown earlier has this nonrecursive part that retrieves a single row
# to produce the initial row set:
#
# 		SELECT 1
#
# The CTE subquery also has this recursive part:
#
# 		SELECT n + 1 FROM cte WHERE n < 5
#
# At each iteration, that SELECT produces a row within a new value one greater than the
# value of n from the previous row set.
#
# The first iteration operates on the initial row set (1) and produces 1+1=2; 
#
# The second iteration operates on the first iteration's row set (2) and produces
# 2+1=3; and so forth.
#
# This continues until recursion ends, which occurs when n is no longer less than 5
#
# If the recursive part of a CTE produces wider values for a column than the nonrecursive
# part, it may be necessary to widen the column in the nonrecursive part to avoid
# data truncation.
#
# Consider this statement:
#
# 		WITH RECURSIVE cte AS
# 		(
# 			SELECT 1 AS n, 'abc' AS str
# 			UNION ALL
# 			SELECT n + 1, CONCAT(str, str) FROM cte WHERE n < 3
# 		)
# 		SELECT * FROM cte;
#
# In nonstrict SQL mode, the statement produces this output:
#
# 		+--------+----------+
# 		| n 		| str 	  |
# 		+--------+----------+
# 		| 1 		| abc 	  |
# 		| 2 		| abc 	  |
# 		| 3 		| abc 	  |
# 		+--------+----------+
#
# The str column values are all 'abc' because the nonrecursive SELECT determines
# the column widths.
#
# Consequently, the wider str values produced by the recursive SELECT are truncated.
#
# In strict SQL mode, the statement produces an error:
#
# 		ERROR 1406 (22001): Data too long for column 'str' at row 1
#
# To address this issue, so that the statement does not produce truncation or errors,
# use CAST() in the nonrecursive SELECT to make the str column wider:
#
# 		WITH RECURSIVE cte AS
# 		(
# 			SELECT 1 AS n, CAST('abc' AS CHAR(20)) AS str
# 			UNION ALL
# 			SELECT n + 1, CONCAT(str, str) FROM cte WHERE n < 3
# 		)
# 		SELECT * FROM cte;
#
# Now the statement produces this result, without truncation:
#
# 		+-----+-----------------+
# 		| n   | str 				|
# 		+-----+-----------------+
# 		| 1   | abc 				|
# 		| 2   | abcabc 			|
# 		| 3   | abcabcabcabc 	|
# 		+-----+-----------------+
#
# Columns are accessed by name, not position, which means that columns in the recursive
# part can access columns in the nonrecursive part that have a different position, as
# this CTE illustrates:
#
# 		WITH RECURSIVE cte AS
# 		(
# 			SELECT 1 AS n, 1 AS p, -1 AS q
# 			UNION ALL
# 			SELECT n + 1, q * 2, p * 2 FROM cte WHERE n < 5
# 		)
# 		SELECT * FROM cte;
#
# Because p in one row is derived from q in the previous row, and vice versa,
# the positive and negative values values swap positions in each successive
# row of the output:
#
# 		+--------+-----------+------------+
# 		| n 	   | p 		   | q 			 |
# 		+--------+-----------+------------+
# 		| 1 		| 1 			| -1 			 |
# 		| 2 		| -2 			| 2 			 |
# 		| 3 		| 4 			| -4 			 |
# 		| 4 		| -8 			| 8 			 |
# 		| 5 		| 16 			| -16 		 |
# 		+--------+-----------+------------+
#
# Some syntax constraints apply within recursive CTE subqueries:
#
# 		) The recursive SELECT part must not contain these constructs:
#
# 			) Aggregate functions such as SUM()
#
# 			) Window functions
#
# 			) GROUP BY
#
# 			) ORDER BY
#
# 			) LIMIT
#
# 			) DISTINCT
#
# 			This constraint does not apply to nonrecursive SELECT part of a recursive CTE.
#
# 			The prohibition on DISTINCT applies only to UNION members; UNION DISTINCT is 
# 			permitted.
#
# 		) The recursive SELECT part must reference the CTE only once and only in its FROM clause,
# 			not in any subquery.
#
# 			It can reference tables other than the CTE and join them with the CTE:
#
# 			If used in a join like this, the CTE must not be on the right side of a LEFT JOIN
#
# These constraints come from the SQL standard, other than the MySQL-specific exclusions
# of ORDER BY, LIMIT, and DISTINCT.
#
# For recursive CTEs, EXPLAIN output rows for recursive SELECT parts display Recursive
# in the Extra column.
#
# Cost estimates displayed by EXPLAIN represents cost per iteration, which might differ
# considerably from total cost.
#
# The optimizer cannot predict the number of iterations because it cannot predict
# when the WHERE clause will become false.
#
# CTE actual cost may also be affected by result set size.
#
# A CTE that produces many rows may require an internal temporary table large enough
# to be converted from in-memory to on-disk format and may suffer a performance
# penalty.
#
# If so, increasing the permitted in-memory temporary table-size may improve performance;
# see SECTION 8.4.4, "INTERNAL TEMPORARY TABLE USE IN MYSQL"
#
# LIMITING COMMON TABLE EXPRESSION RECURSION
#
# It is important for recursive CTEs that the recursive SELECT part include a condition
# to terminate recursion.
#
# As a development technique to guard against a runaway recursive CTE; you can
# force termination by placing a limit on execution time:
#
# 		) The cte_max_recursion_depth system variable enforces a limit on the number
# 			of recursion levels for CTEs.
#
# 			The server terminates execution of any CTE that recurses more levels
# 			than the value of this variable.
#
# 		) The max_execution_time system variable enforces an execution timeout for SELECT
# 			statements executed within the current session.
#
# 		) The MAX_EXECUTION_TIME optimizer hint enforces a per-query execution timeout for the
# 			SELECT statement in which it appears.
#
# Suppose that a recursive CTE is mistakenly written with no recursion execution termination condition:
#
# 		WITH RECURSIVE cte (n) AS
# 		(
# 			SELECT 1
# 			UNION ALL
# 			SELECT n + 1 FROM cte
# 		)
# 		SELECT * FROM cte;
#
# By default, cte_max_recursion_depth has a value of 1000, causing the CTE to terminate when
# it recurses past 1000 levels.
#
# Applications can change the session value to adjust for their requirements:
#
# 		SET SESSION cte_max_recursion_depth = 10; 		-- Permit only shallow recursion
# 		SET SESSION cte_max_recursion_depth = 1000000; 	-- permit deeper recursion
#
# You can also set the global cte_max_recursion_depth value to affect all sessions
# that begin subsequently.
#
# For queries that execute and thus recurse slowly or in contexts for which there is
# reason to set the cte_max_recursion_depth value very high, another way to guard
# against deep recursion is to set a per-session timeout.
#
# To do so, execute a statement like this prior to executing the CTE statement:
#
# 		SET max_execution_time = 1000; -- impose one second timeout
#
# Alternatively, include an optimizer hint within the CTE statement itself:
#
# 		WITH RECURSIVE cte (n) AS
# 		(
# 			SELECT 1
# 			UNION ALL
# 			SELECT n + 1 FROM cte
# 		)
# 		SELECT /*+ MAX_EXECUTION_TIME(1000) */ * FROM cte;
#
# If a recursive query without an execution time limit enters an infinite loop, you can
# terminate it from another session using KILL_QUERY
#
# Within the session itself, the client program used to run the query might provide
# a way to kill the query.
#
# For example, in mysql, doing CTRL+C interuppts the current statement
#
# RECURSIVE COMMON TABLE EXPRESSION EXAMPLES
#
# As mentioned previously, recursive common table expressions (CTEs)
# are frequently used for series generation and traversing hierarchial
# or tree-structured data.
#
# This section shows some simple examples of these techniques.
#
# 		) FIBONACCI SERIES GENERATION
#
# 		) DATE SERIES GENERATION
#
# 		) HIERARCHIAL DATA TRAVERSAL
#
# FIBONACCI SERIES GENERATION
#
# A Fibonacci series begins with the two numbers 0 and 1 (or 1 and 1) and each number
# after that is the sum of the previous two numbers.
#
# A recursive common table expression can generate a Fibonacci series if each row
# produced by the recursive SELECT has access to the two previous numbers
# from the series.
#
# The following CTE generates a 10-number series using 0 and 1 as the first two numbers:
#
# 		WITH RECURSIVE fibonacci (n, fib_n, next_fib_n) AS
# 		(
# 			SELECT 1, 0, 1
# 			UNION ALL
# 			SELECT n + 1, next_fib_n, fib_n + next_fib_n
# 				FROM fibonacci WHERE n < 10
# 		)
# 		SELECT * FROM fibonacci;
#
# The CTE produces this result:
#
# 		+---------+------------+---------------------+
# 		| n 		 | fib_n 	  | next_fib_n 		   |
# 		+---------+------------+---------------------+
# 		| 1 		 | 0 			  | 1 						|
# 		| 2 		 | 1 			  | 1 						|
# 		| 3 		 | 1 			  | 2 						|
# 		| 4 		 | 2 			  | 3 					   |
# 		| 5 		 | 3 			  | 5 						|
# 		| 6 		 | 5 			  | 8 						|
# 		| 7 		 | 8 			  | 13 						|
# 		| 8 		 | 13 		  | 21 					   |
# 		| 9 		 | 21 		  | 34 						|
# 		| 10 		 | 34 		  | 55 						|
# 		+---------+------------+---------------------+
#
# How the CTE works:
#
# 		) n is a display column to indicate that the row contains the n-th Fibonacci number.
#
# 			For example, the 8th Fibonacci number is 13.
#
# 		) The fib_n column displays Fibonacci number n
#
# 		) The next_fib_n column displays the next Fibonaci number after number n.
#
# 			This column provides the next series value to the next row, so that row can
# 			produce the sum of the two previous series values in its fib_n column
#
# 		) Recursion ends when n reaches 10. This is an arbitrary choice, to limit output to
# 			a small set of rows.
#
# The preceding output shows the entire CTE result.
#
# To select just part of it, add an appropriate WHERE clause to the top-level SELECT
#
# For example, to select the 8th Fibonacci number, do this:
#
# 		WITH RECURSIVE fibonacci ---
# 		---
# 		SELECT fib_n FROM fibonacci WHERE n = 8;
# 		+-----------+
# 		| fib_n 		|
# 		+-----------+
# 		| 13 			|
# 		+-----------+
#
# DATE SERIES GENERATION
#
# A common table expression can generate a series of successive dates, which is useful
# for generating summaries that include a row for all dates in the series, including
# dates not represented in the summarized data.
#
# Suppose that a table of sales numbers contains these rows:
#
# 		SELECT * FROM sales ORDER BY date, price;
# 		+----------------+----------+
# 		| date 			  | price 	 |
# 		+----------------+----------+
# 		| 2017-01-03 	  | 100.00   |
# 		| 2017-01-03 	  | 200.00   |
# 		| 2017-01-06 	  | 50.00 	 |
# 		| 2017-01-08 	  | 10.00 	 |
# 		| 2017-01-08 	  | 20.00    |
# 		| 2017-01-08 	  | 150.00   |
# 		| 2017-01-10 	  | 5.00 	 |
# 		+----------------+----------+
#
# This query summarizes the sales per day:
#
# 		SELECT date, SUM(price) AS sum_price
# 		FROM sales
# 		GROUP BY date
# 		ORDER BY date;
# 		+----------------+------------------+
# 		| date 			  | sum_price 		   |
# 		+----------------+------------------+
# 		| 2017-01-03 	  | 300.00 				|
# 		| 2017-01-06 	  | 50.00 				|
# 		| 2017-01-08 	  | 180.00 				|
# 		| 2017-01-10 	  | 5.00 				|
# 		+----------------+------------------+
#
# However, that result contains "holes" for dates not represented in the range
# of dates spanned by the table.
#
# A result that represents all dates in the range can be produced using a recursive
# CTE to generate that set of dates, joined with a LEFT JOIN to the sales data.
#
# Here is the CTE to generate the date range series:
#
# 		WITH RECURSIVE dates (date) AS
# 		(
# 			SELECT MIN(date) FROM sales
# 			UNION ALL
# 			SELECT date + INTERVAL 1 DAY FROM dates
# 			WHERE date + INTERVAL 1 DAY <= (SELECT MAX(date) FROM sales)
# 		)
# 		SELECT * FROM dates;
#
# The CTE produces this result:
#
# 		+-------------------+
# 		| date 				  |
# 		+-------------------+
# 		| 2017-01-03 		  |
# 		| 2017-01-04 		  |
# 		| 2017-01-05 		  |
# 		| 2017-01-06 		  |
# 		| 2017-01-07 		  |
# 		| 2017-01-08 		  |
# 		| 2017-01-09 		  |
# 		| 2017-01-10 		  |
# 		+-------------------+
#
# How the CTE works:
#
# 		) The nonrecursive SELECT produces the lowest date in the date range spanned by the sales table.
#
# 		) Each row produced by the recursive SELECT adds one day to the date produced by the previous row.
#
# 		) Recursion ends after the dates reach the highest date in the date range spanned by the sales table.
#
# Joining the CTE with a LEFT JOIN against the sales table produces the sales summary with a row
# for each date in the range:
#
# 		WITH RECURSIVE dates (date) AS
# 		(
# 			SELECT MIN(date) FROM sales
# 			UNION ALL
# 			SELECT date + INTERVAL 1 DAY FROM dates
# 			WHERE date + INTERVAL 1 DAY <= (SELECT MAX(date) FROM sales)
# 		)
# 		SELECT dates.date, COALESCE(SUM(price), 0) AS sum_price
# 		FROM dates LEFT JOIN sales ON dates.date = sales.date
# 		GROUP BY dates.date
# 		ORDER BY dates.date;
#
# The output looks like this:
#
# 		+--------------------+--------------+
# 		| date 					| sum_price 	|
# 		+--------------------+--------------+
# 		| 2017-01-03 			| 300.00 		|
# 		| 2017-01-04 			| 0.00 			|
# 		| 2017-01-05 			| 0.00 			|
# 		| 2017-01-06 			| 50.00 			|
# 		| 2017-01-07 			| 0.00 			|
# 		| 2017-01-08 			| 180.00 		|
# 		| 2017-01-09 			| 0.00 			|
# 		| 2017-01-10 			| 5.00 			|
# 		+--------------------+--------------+
#
# Some points to note:
#
# 		) Are the queries inefficient, particularly the one with the MAX() subquery executed
# 			for each row in the recursive SELECT?
#
# 			Checking with EXPLAIN shows that the subqueries are optimized away for efficiency.
#
# 		) The use of COALESCE() avoids displaying NULL in the sum_price column on days for which
# 			no sales data occur in the sales table.
#
# HIERARCHIAL DATA TRAVERSAL
#
# Recursive common table expressions are useful for traversing data that forms a hierarchy.
#
# Consider these statements that create a small data set that shows, for each employee
# in a company, the employee name and ID number, and the ID of the employee's manager.
#
# The top-level employee (the CEO), has a manager ID of NULL (no manager)
#
# 		CREATE TABLE employees (
# 			id 			INT PRIMARY KEY NOT NULL,
# 			name 			VARCHAR(100) NOT NULL,
# 			manager_id 	INT NULL,
# 			INDEX (manager_id),
# 		FOREIGN KEY (manager_id) REFERENCES EMPLOYEES (id)
# 		);
# 		INSERT INTO employees VALUES
# 		(333, "Yasmina", NULL), #CEO, manager_id is NULL
# 		(198, "John", 333),
# 		(692, "Tarek", 333),
# 		(29, "Pedro", 198),
# 		(4610, "Sarah", 29),
# 		(72, "Pierre", 29),
# 		(123, "Adil", 692);
#
# The resulting data set looks like this:
#
# 		SELECT * FROM employees ORDER BY id;
# 		+-----+------------+-------------+
# 		| id  | name 		 | manager_id  |
# 		+-----+------------+-------------+
# 		| 29  | Pedro 		 | 198 		   |
# 		etc.
#
# To produce the organizational chart with the management chain for each
# employee (that is, the path from CEO to employee), use a recursive CTE:
#
# 		WITH RECURSIVE employee_paths (id, name, path) AS
# 		(
# 			SELECT id, name, CAST(id AS CHAR(200))
# 				FROM employees
# 				WHERE manager_id IS NULL
# 			UNION ALL
# 			SELECT e.id, e.name, CONCAT(ep.path, ',', e.id)
# 				FROM employee_paths AS ep JOIN employees AS e
# 					ON ep.id = e.manager_id
#		)
# 		SELECT * FROM employee_paths ORDER BY path;
#
# The CTE produces this output:
#
# 		+-------+-----------+-------------------+
# 		| id 	  | name 	  | path 				 |
# 		+-------+-----------+-------------------+
# 		| 333   | Yasmina   | 333 					 |
# 		| 198   | John 	  | 333, 198 			 |
# 		| 29 	  | Pedro 	  | 333, 198, 29 	    |
# 		| 4610  | Sarah 	  | 333, 198, 29, 4610|
# 		| 72 	  | Pierre 	  | 333, 198, 29, 72  |
# 		| 692   | Tarek 	  | 333, 692 			 |
# 		| 123   | Adil 	  | 333, 692, 123 	 |
# 		+-------+-----------+-------------------+
#
# How the CTE works:
#
# 		) The nonrecursive SELECT produces the row for the CEO (the row with a NULL-manager ID)
#
# 			The path column is widened to CHAR(200) to ensure that there is room for the longer path
# 			values produced by the recursive SELECT.
#
# 		) Each row produced by the recursive SELECT finds all employees who report directly to
# 			an employee produced by a previous row.
#
# 			For each such employee, the row includes the employee ID and name, and the employee
# 			management chain.
#
# 			The chain is the manager's chain, with the employee ID added ot the end.
#
# 		) Recursion ends when employees have no others who report to them
#
# To find the path for a specific employee or employees, add a WHERE clause
# to the top-level SELECT.
#
# For example, to display the results for Tarek and Sarah, modify that SELECT
# like this:
#
# 		WITH RECURSIVE ---
# 		---
# 		SELECT * FROM employees_extended
# 		WHERE id IN (692, 4610)
# 		ORDER BY path;
# 		+------+-------+-----------------------+
# 		| id   | name  | path 					   |
# 		+------+-------+-----------------------+
# 		| 4610 | Sarah | 333, 198, 29, 4610    |
# 		| 692  | Tarek | 333, 692 					|
# 		+------+-------+-----------------------+
#
# COMMON TABLE EXPRESSIONS COMPARED TO SIMILAR CONSTRUCTS
#
# Common table expressions (CTEs) are similar to derived tables in some ways:
#
# 		) Both constructs are named
#
# 		) Both constructs exist for the scope of a single statement
#
# Because of these similarities, CTEs and derived tables often can be used
# interchangably.
#
# As a trivial example, these statements are equivalent:
#
# 		WITH cte AS (SELECT 1) SELECT * FROM cte;
# 		SELECT * FROM (SELECT 1) AS dt;
#
# However, CTEs have some advantages over derived tables:
#
# 		) A derived table can be referenced only a single time within a query.
#
# 			A CTE can be referenced multiple times.
#
# 			To use multiple instances of a derived table result, you must derive
# 			the result multiple times.
#
# 		) A CTE can be self-referencing (recursive)
#
# 		) One CTE can refer to another
#
# 		) A CTE may be easier to read when its definition appears at the beginning
# 			of the statement rather than embedded within it.
#
# CTEs are similar to tables created with CREATE [TEMPORARY] TABLE but need not be defined
# or dropped explicitly.
#
# For a CTE, you need no privileges to create tables.
#
# 13.3 TRANSACTIONAL AND LOCKING STATEMENTS
#
# 13.3.1 START TRANSACTION, COMMIT, AND ROLLBACK SYNTAX
# 13.3.2 STATEMENTS THAT CANNOT BE ROLLED BACK
#
# 13.3.3 STATEMENTS THAT CAUSE AN IMPLICIT COMMIT
# 13.3.4 SAVEPOINT, ROLLBACK TO SAVEPOINT, AND RELEASE SAVEPOINT SYNTAX
#
# 13.3.5 LOCK INSTANCE FOR BACKUP AND UNLOCK INSTANCE SYNTAX
# 13.3.6 LOCK TABLES AND UNLOCK TABLES SYNTAX
#
# 13.3.7 SET TRANSACTION SYNTAX
# 13.3.8 XA TRANSACTIONS
#
# MySQL supports local transactions (within a given client session) through statements,
# such as SET_autocommit, START_TRANSACTION, COMMIT, and ROLLBACK.
#
# See SECTION 13.3.1, "START TRANSACTION, COMMIT, AND ROLLBACK SYNTAX"
#
# XA transaction support enables MySQL to participate in distributed transactions
# as well.
#
# See SECTION 13.3.8, "XA TRANSACTIONS"
#
# 13.3.1 START TRANSACTION, COMMIT AND ROLLBACK SYNTAX
#
# START TRANSACTION 
# 		[transaction_characteristic [, transaction_characteristic] ---]
#
# transaction_characteristic: {
# 		WITH CONSISTENT SNAPSHOT
# 	 | READ WRITE
# 	 | READ ONLY
# }
#
# BEGIN [WORK]
# COMMIT [WORK] [AND [NO] CHAIN] [[NO] RELEASE]
# ROLLBACK [WORK] [AND [NO] CHAIN] [[NO] RELEASE]
# SET autocommit = {0 | 1}
#
# These statements provide control over use of transactions:
#
# 	) START TRANSACTION or BEGIN start a new transaction
#
# 	) COMMIT commits the current transaction, making its changes permanent
#
# 	) ROLLBACK rolls back the current transaction, canceling its changes
#
# 	) SET autocommit disables or enables the default autocommit mode for the current session
#
# By default, MySQL runs with autocommit mode enabled.
#
# This means that as soon as you execute a statement that updates (modifies) table,
# MySQL stores the update on disk to make it permanent.
#
# The change cannot be rolled back.
#
# To disable autocommit mode implicitly for a single series of statements, use the
# START TRANSACTION statement:
#
# 		START TRANSACTION;
# 		SELECT @A:=SUM(salary) FROM table1 WHERE type=1;
# 		UPDATE table2 SET summary=@A WHERE type=1;
# 		COMMIT;
#
# With START TRANSACTION, autocommit remains disabled until you end the transaction
# with COMMIT or ROLLBACK.
#
# The autocommit mode then reverts to its previous state.
#
# START TRANSACTION permits several modifiers that control transaction characteristics.
#
# To specify multiple modifiers, separate them by commas.
#
# 	) The WITH CONSISTENT SNAPSHOT modifier starts a consistent read for storage engines that
# 		are capable of it.
#
# 		This applies only to InnoDB
#
# 		The effect is the same as issuing a START TRANSACTION followed by a SELECT
# 		from any InnoDB table.
#
# 		See SECTION 15.7.2.3, "CONSISTENT NONLOCKING READS"
#
# 		The WITH CONSISTENT SNAPSHOT modifier does not change the current transaction
# 		isolation level, so it provides a consistent snapshot only if the current
# 		isolation level is one that permits a consistent read.
#
# 		The only isolation level that permits a consistent read is REPEATABLE_READ
#
# 		For all other isolation levels, the WITH CONSISTENT SNAPSHOT clause is ignored.
#
# 		A warning is generated when the WITH CONSISTENT SNAPSHOT clause is ignored.
#
# 	) The READ WRITE and READ ONLY modifiers set the transaction access mode.
#
# 		They permit or prohibit changes to tables used in the transaction.
#
# 		The READ ONLY restriction prevents the transaction from modifying or locking
# 		both transactional and nontransactional tables that are visible to other
# 		transactions;
#
# 		The transaction can still modify or lock temporary tables
#
# 		MySQL enables extra optimizations for queries on InnoDB tables when
# 		the transaction is known to be read-only.
#
# 		Specifying READ ONLY ensures these optimizations are applied in cases
# 		where the read-only status cannot be determined automatically.
#
# 		See SECTION 8.5.3, "OPTIMIZING INNODB READ-ONLY TRANSACTIONS" for more information.
#
# 		If no access mode is specified, the default mode applies.
#
# 		Unless the default has been changed, it is read/write.
#
# 		it is not permitted to specify both READ WRITE and READ ONLY in the same
# 		statement.
#
# 		In read-only mode, it remains possible to change tables created with the
# 		TEMPORARY keyword using DML statements.
#
# 		Changes made with DDL statements are not permitted, just as with permanent
# 		tables.
#
# 		For additional information about transaction access mode, including ways to change
# 		the default mode, see SECTION 13.3.7, "SET TRANSACTION SYNTAX"
#
# 		If the read_only system variable is enabled, explicitly starting a transaction
# 		with START TRANSACTION READ WRITE requires the CONNECTION_ADMIN or SUPER privilege.
#
# 			IMPORTANT:
#
# 				Many APIS used for writing MySQL client applications (such as JDBC) provide
# 				their own methods for starting transactions that can (and sometimes should)
# 				be used instead of sending a START TRANSACTION statement from the client.
#
# 				See CHAPTER 28, CONNECTORS AND APIS, or the documentation for your API
# 				for more information.
#
# 		To disable autocommit mode explicitly, use the following statement:
#
# 			SET autocommit=0;
#
# 		After disabling autocommit mode by setting the autocommit variable to zero, changes to
# 		transaction-safe tables (such as those for InnoDB or NDB) are not made permanent
# 		immediately.
#
# 		You must use COMMIT to store your changes to disk or ROLLBACK to ignore the changes.
#
# 		autocommit is a session variable and must be set for each session.
#
# 		To disable autocommit mode for each new connection, see the description
# 		of the autocommit system variable at SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 		BEGIN and BEGIN WORK are supported as aliases of START TRANSACTION for initiating
# 		a transaction.
#
# 		START TRANSACTION is standard SQL syntax, is the recommended way to start an
# 		ad-hoc transaction, and permits modifiers that BEGIN does not.
#
# 		The BEGIN statement differs from the use of the BEGIN keyword that starts a BEGIN_---_END
# 		compound statement.
#
# 		The latter does not begin a transaction. See SECTION 13.6.1, "BEGIN --- END COMPOUND-STATEMENT SYNTAX"
#
# 		NOTE:
#
# 			Within all stored programs (stored procedures and functions, triggers, and events), the parser
# 			treats BEGIN [WORK] as the beginning of a BEGIN_---_END block.
#
# 			Begin a transaction in this context with START_TRANSACTION instead.
#
# 		The optional WORK keyword is supported for COMMIT and ROLLBACK, as are teh CHAIN and RELEASE
# 		clauses.
#
# 		CHAIN and RELEASE can be used for additional control over transaction completion.
#
# 		The value of the completion_type system variable determines the default completion
# 		behavior.
#
# 		See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 		The AND CHAIN clause causes a new transaction to begin as soon as the current one ends,
# 		and the new transaction has the same isolation level as the just-terminated transaction.
#
# 		The new transaction also uses the same access mode (READ WRITE or READ ONLY) as the just-terminated
# 		transaction.
#
# 		The RELEASE clause causes the server to disconnect the current client session after terminating
# 		the current transaction.
#
# 		Including the NO keyword suppresses CHAIN or RELEASE completion, which can be useful if
# 		the completion_type system variable is set to cause chaining or release completion by default.
#
# 		Beginning a transaction causes any pending transaction to be committed.
#
# 		See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT", for more information.
#
# 		Beginning a transaction also causes table locks acquired with LOCK_TABLES to be released,
# 		as though you had executed UNLOCK_TABLES
#
# 		Beginning a transaction does not release a global read lock acquired with FLUSH_TABLES_WITH_READ_LOCK
#
# 		For best results, transactions should be performed using only tables managed by a single
# 		transaction-safe storage engine.
#
# 		Otherwise, the following problems can occur:
#
# 			) If you use tables from more than one transaction-safe storage engine (such as InnoDB),
# 				and the transaction isolation level is not SERIALIZABLE, it is possible that when
# 				one transaction commits, another ongoing transaction that uses the same tables will
# 				see only some of the changes made by the first transaction.
#
# 				That is, the atomicity of transactions is not guaranteed with mixed engines and
# 				inconsistencies can result.
#
# 				(If mixed-engine transactions are infrequent, you can use SET_TRANSACTION_ISOLATION_lEVEL
# 				to set the isolation level to SERIALIZABLE on a per-transaction basis as necessary.)
#
# 			) If you use tables that are not transaction-safe within a transaction, changes to those tables
# 				are stored at once, regardless of the status of autocommit mode.
#
# 			) If you issue a ROLLBACK statement after updating a nontransactional table within a transaction,
# 				an ER_WARNING_NOT_COMPLETE_ROLLBACK warning occurs.
#
# 				Changes to transaction-safe tables are rolled back, but not changes to nontransaction-safe tables.
#
# 		Each transaction is stored in the binary log in one chunk, upon COMMIT.
#
# 		Transactions that are rolled back are not logged.
#
# 		(Exception:
#
# 			Modifications to nontransactional tables cannot be rolled back.
#
# 			If a transaction that is rolled back includes modifications to nontransactional
# 			tables, the entire transaction is logged with a ROLLBACK statement at the
# 			end to ensure that modifications to the nontransactional tables are replicated)
#
# 			See SECTION 5.4.4, "THE BINARY lOG"
#
# 			You can change the isolation level or access mode for transactions with the
# 			SET_TRANSACTION statement.
#
# 			See SECTION 13.3.7, "SET TRANSACTION SYNTAX"
#
# 			Rolling back can be a slow operation that may occur implicitly without the user
# 			having explicitly asked for it (for example, when an error occurs)
#
# 			Because of this, SHOW_PROCESSLIST displays Rolling back in the State column
# 			for the session, not only for explicit rollbacks performed with the ROLLBACK
# 			statement but also for implicit rollbacks.
#
# 				NOTE:
#
# 					In MySQL 8.0, BEGIN, COMMIT and ROLLBACK are not affected by
# 					--replicate-do-db or --replicate-ignore-db rules
#
# 13.3.2 STATEMENTS TAHT CANNOT BE ROLLED BACK
#
# Some statements cannot be rolled back.
#
# In general, these include data definition language (DDL) statements, such as those
# that create or drop databases,, those that create, drop or alter tables
# or stored routines.
#
# You should design your transactions not to include such statements.
#
# If you issue a statement early in a transaction that cannot be rolled back,
# and then another statement later fails, the full effect of the transaction
# cannot be rolled back in such cases by issuing a ROLLBACK statement.
#
# 13.3.3 STATEMENTS THAT CAUSE AN IMPLICIT COMMIT
#
# The statements listed in this section (and any synonyms for them) implicitly
# end any transaction active in the current session, as if you had done a COMMIT
# before executing the statement.
#
# Most of these statements also cause an implicit commit after executing.
#
# The intent is to handle each such statement in its own special transaction.
#
# Transaction-control and locking statements are exceptions:
#
# If an implicit commit occurs before execution, another does not occur after.
#
# 		) DATA DEFINITION LANGUAGE (DDL) STATEMENTS THAT DEFINE OR MODIFY DATABASE OBJECTS.
#
# 			ALTER_EVENT
#
# 			ALTER_FUNCTION
#
# 			ALTER_PROCEDURE
#
# 			ALTER_SERVER
#
# 			ALTER_TABLE
#
# 			ALTER_VIEW
#
# 			CREATE_DATABASE 
#
# 			CREATE_EVENT
#
# 			CREATE_FUNCTION
#
# 			CREATE_INDEX
#
# 			CREATE_PROCEDURE
#
# 			CREATE_ROLE
#
# 			CREATE_SERVER
#
# 			CREATE_SPATIAL_REFERENCE_SYSTEM
#
# 			CREATE_TABLE
#
# 			CREATE_TRIGGER
#
# 			CREATE_VIEW
#
# 			DROP_DATABASE 
#
# 			DROP_EVENT
#
# 			DROP_FUNCTION
#
# 			DROP_INDEX
#
# 			DROP_PROCEDURE 
#
# 			DROP_ROLE
#
# 			DROP_SERVER
#
# 			DROP_SPATIAL_REFERENCE_SYSTEM
#
# 			DROP_TABLE
#
# 			DROP_TRIGGER
#
# 			DROP_VIEW
#
# 			INSTALL_PLUGIN
#
# 			RENAME_TABLE
#
# 			TRUNCATE_TABLE
#
# 			UNINSTALL_PLUGIN
#
# 			CREATE_TABLE and DROP_TABLE statements do not commit a transaction
# 			if the TEMPORARY keyword is used.
#
# 			(This does not apply to other operations on temporary tables such as
# 			ALTER_TABLE and CREATE_INDEX, which do cause a commit)
#
# 			However, although no implicit commit occurs, neither can the statement
# 			be rolled back, which means that the use of such statements cause transactional
# 			atomicity to be violated.
#
# 			For example, if you use CREATE_TEMPORARY_TABLE and then roll back the
# 			transaction, the table remains in existence.
#
# 			The CREATE_TABLE statement in InnoDB is processed as a single transaction.
#
# 			This means that a ROLLBACK from the user does not undo CREATE_TABLE statements
# 			the user made during that transaction.
#
# 			CREATE_TABLE_---_SELECT causes an implicit commit before and after the statement
# 			is executed when you are creating nontemporary tables.
#
# 			(No commit occurs for CREATE TEMPORARY TABLE --- SELECT)
#
# 		) STATEMENTS THAT IMPLICITLY USE OR MODIFY TABLES IN THE mysql DATABASE.
#
# 			ALTER_USER
#
# 			CREATE_USER
#
# 			DROP_USER
#
# 			GRANT
#
# 			RENAME_USER
#
# 			REVOKE
#
# 			SET_PASSWORD
#
# 		) TRANSACTION-CONTROL AND LOCKING STATEMENTS.
#
# 			BEGIN
#
# 			LOCK_TABLES 
#
# 			SET autocommit = 1 (if the value is not already 1)
#
# 			START TRANSACTION
#
# 			UNLOCK TABLES
#
# 			UNLOCK_TABLES commits a transaction only if any tables currently
# 			have been locked with LOCK_TABLES to acquire nontransactional table
# 			locks.
#
# 			A commit does not occur for UNLOCK_TABLES following FLUSH_TABLES_WITH_READ_LOCK
# 			because the latter statement does not acquire table-level locks.
#
# 			Transactions cannot be nested.
#
# 			This is a consequence of the IMPLICIT commit performed for any current transaction
# 			when you issue a START_TRANSACTION statement or one of its synonyms.
#
# 			Statements that cause an implicit commit cannot be used in an XA transaction
# 			while the transaction is in an ACTIVE state.
#
# 			The BEGIN statement differs from the use of the BEGIN keyword that starts
# 			a BEGIN_---_END compound statement.
#
# 			The latter does not cause an implicit commit.
#
# 			See SECTION 13.6.1, "BEGIN -- END COMPOUND-STATEMENT SYNTAX"
#
# 		) DATA LOADING STATEMENTS
#
# 			LOAD_DATA_INFILE
#
# 			LOAD_DATA_INFILE causes an implicit commit only for tables using the NDB storage engine.
#
# 		) ADMINISTRATIVE STATEMENTS
#
# 			ANALYZE_TABLE
#
# 			CACHE_INDEX
#
# 			CHECK_TABLE
#
# 			FLUSH
#
# 			LOAD_INDEX_INTO_CACHE
#
# 			OPTIMIZE_TABLE
#
# 			REPAIR_TABLE
#
# 			RESET (but not RESET PERSIST)
#
# 		) REPLICATION CONTROL STATEMENTS
#
# 			START SLAVE
#
# 			STOP SLAVE
#
# 			RESET SLAVE
#
# 			CHANGE MASTER TO
#
# 13.3.4 SAVEPOINT, ROLLBACK TO SAVEPOINT, AND RELEASE SAVEPOINT SYNTAX
#
# 		SAVEPOINT identifier
# 		ROLLBACK [WORK] TO [SAVEPOINT] identifier
# 		RELEASE SAVEPOINT identifier
#
# InnoDB supports the SQL statements SAVEPOINT, ROLLBACK_TO_SAVEPOINT, RELEASE_SAVEPOINT
# and the optional WORK keyword for ROLLBACK
#
# The SAVEPOINT statement sets a named transaction savepoint with a name of identifier.
#
# If the current transaction has a savepoint with the same name, the old savepoint is deleted
# and a new one is set.
#
# The ROLLBACK_TO_SAVEPOINT statement rolls back a transaction to the named savepoint
# without terminating the transaction.
#
# Modifications that the current transaction made to rows after the savepoint was set
# are undone in the rollback, but InnoDB does not release the row locks that were stored
# in memory after the savepoint.
#
# (For a new inserted row, the lock information is carried by the transaction ID stored in the
# row; the lock is not separately stored in memory.
#
# In this case, the row lock is released in the undo)
#
# Savepoints that were set at a later time than the named savepoint are deleted.
#
# If the ROLLBACK_TO_SAVEPOINT statement returns the following error, it means that
# no savepoint with the specified name exists:
#
# 		ERROR 1305 (42000): SAVEPOINT identifier does not exist
#
# The RELEASE_SAVEPOINT statement removes the named savepoint from the set of savepoints
# of the current transaction.
#
# No commit or rollback occurs.
#
# It is an error if the savepoint does not exist.
#
# All savepoints of the current transaction are deleted if you execute a COMMIT,
# or a ROLLBACK that does not name a savepoint.
#
# A new savepoint level is created when a stored function is invoked or a trigger is activated.
#
# The savepoints on previous levels become unavailable and thus do not conflict
# with savepoints on the new level.
#
# When the function or trigger terminates, any savepoints it created are released
# and the previous savepoint level is restored.
#
# 13.3.5 LOCK INSTANCE FOR BACKUP AND UNLOCK INSTANCE SYNTAX
#
# 		LOCK INSTANCE FOR BACKUP
#
# 		UNLOCK INSTANCE
#
# LOCK INSTANCE FOR BACKUP acquires an instance-level backup lock that permits DML during
# an online backup while preventing operations that could result in an inconsistent snapshot.
#
# Executing the LOCK INSTANCE FOR BACKUP statement requires the BACKUP_ADMIN privilege.
#
# The BACKUP_ADMIN privilege is automatically granted to users with the RELOAD 
# privilege when performing an in-place upgrade to MySQL 8.0 from an earlier version.
#
# Multiple sessions can hold a backup lock simultaneously.
#
# UNLOCK INSTANCE releases a backup lock held by the current session.
#
# A backup lock held by a session is also released if the session is terminated.
#
# LOCK INSTANCE FOR BACKUP prevents files from being created, renamed or removed.
#
# REPAIR_TABLE
#
# TRUNCATE TABLE
#
# OPTIMIZE TABLE
#
# and account management statements are blocked.
#
# See SECTION 13.7.1, "ACCOUNT MANAGEMENT STATEMENTS"
#
# Operations that modify InnoDB files that are not recorded in the InnoDB
# redo log are also blocked.
#
# LOCK INSTANCE FOR BACKUP permits DDL operations that only affect user-created
# temporary tables
#
# In effect, files that belong to user-created temporary tables can be created,
# renamed or removed while a backup lock is held.
#
# Creation of binary log files is also permitted.
#
# A backup lock acquired by LOCK INSTANCE FOR BACKUP is independent of transactional
# locks and locks taken by FLUSH_TABLES_tbl_name [, tbl_name] --- WITH READ LOCK,
# and the following sequences of statements are permitted:
#
# 		LOCK INSTANCE FOR BACKUP;
# 		FLUSH TABLES tbl_name [, tbl_name] --- WITH READ LOCK;
# 		UNLOCK TABLES;
# 		UNLOCK INSTANCE;
#
# 		FLUSH TABLES tbl_name [, tbl_name] --- WITH READ LOCK;
# 		LOCK INSTANCE FOR BACKUP;
# 		UNLOCK INSTANCE;
# 		UNLOCK TABLES;
#
# The lock_wait_timeout setting defines the amount of time that a LOCK INSTANCE FOR BACKUP
# statement waits to acquire a lock before giving up.
#
# 13.3.6 LOCK TABLES AND UNLOCK TABLES SYNTAX
#
# LOCK TABLES
# 		tbl_name [[AS] alias] lock_type
# 		[, tbl_name [[AS] alias] lock_type] ---
#
# lock_type: {
# 		READ [LOCAL]
# 	 | [LOW_PRIORITY] WRITE
# }
#
# UNLOCK TABLES
#
# MySQL enables client sessions to acquire table locks explicitly for the purpose
# of cooperating with other sessions for access to tables, or to prevent other
# sessions from modifying tables during periods when a session requires exclusive
# access to them.
#
# A session can acquire or release locks only for itself
#
# One session cannot acquire locks for another session or release
# locks held by another session
#
# Locks may be used to emulate transactions or to get more speed when
# updating tables.
#
# This is explained in more detail in TABLE-LOCKING RESTRICTIONS AND CONDITIONS
#
# LOCK_TABLES explicitly acquires table locks for the current client session.
#
# Table locks can be acquired for base tables or views.
#
# You must have the LOCK_TABLES privilege, and the SELECT privilege
# for each object to be locked.
#
# For view locking, LOCK_TABLES adds all base tables used in the view to the
# set of tables to be locked and locks them automatically.
#
# If you lock a table explicitly with LOCK TABLES, any tables used in triggers
# are also locked implicitly, as described in LOCK TABLES AND TRIGGERS
#
# If you lock a table explicitly with LOCK_TABLES, any tables related by a foreign
# key constraint are opened and locked implicitly.
#
# For foreign key checks, a shared read-only lock (LOCK_TABLES_READ) is taken
# on related tables.
#
# For cascading updates, a shared-nothing write lock (LOCK_TABLES_WRITE) is taken
# on related tables that are involved in the operation.
#
# UNLOCK_TABLES explicitly releases any table locks held by the current session.
#
# LOCK_TABLES implicitly releases any table locks held by the current session before
# acquiring new locks.
#
# Another use for UNLOCK_TABLES is to release the global read lock acquired with 
# the FLUSH_TABLES_WITH_READ_LOCK statement, which enables you to lock all tables
# in all databases.
#
# See SECTION 13.7.7.3, "FLUSH SYNTAX" (This is a very convenient way to get backups
# if you  have a file system such as Veritas that can take snapshots in time)
#
# A table lock protects only against inappropriate reads or writes by other sessions.
#
# A session holding a WRITE lock can perform table-level operations such as DROP_TABLE
# or TRUNCATE_TABLE
#
# For sessions holding a READ lock, DROP_TABLE and TRUNCATE_TABLE operations are not permitted.
#
# The following discussion applies only to non-TEMPORARY tables.
#
# LOCK_TABLES is permitted (but ignored) for a TEMPORARY table.
#
# The table can be accessed freely by the session within which it was created,
# regardless of what other locking may be in effect.
#
# No lock is necessary because no other session can see the table.
#
# 		) TABLE LOCK ACQUISITION
#
# 		) TABLE LOCK RELEASE
#
# 		) INTERACTION OF TABLE LOCKING AND TRANSACTIONS
#
# 		) LOCK TABLES AND TRIGGERS
#
# 		) TABLE-LOCKING RESTRICTIONS AND CONDITIONS
#
# TABLE LOCK ACQUISITION
#
# To acquire table locks within the current session, use the LOCK_TABLES statement,
# which acquires metadata locks (see SECTION 8.11.4, "METADATA LOCKING")
#
# The following lock types are available:
#
# READ [LOCAL] lock:
#
# 		) The session that holds the lock can read the table (but not write it)
#
# 		) Multiple sessions can acquire a READ lock for the table at the same time
#
# 		) Other sessions can read the table without explicitly acquiring a READ lock
#
# 		) The LOCAL modifier enables nonconflicting INSERT statements (concurrent inserts)
# 			by other sessions to execute while the lock is held.
#
# 			(See SECTION 8.11.3, "CONCURRENT INSERTS")
#
# 			However, READ LOCAL cannot be used if you are going to manipulate the database
# 			using processes external to the server while you hold the lock.
#
# 			For InnoDB tables, READ LOCAL is the same as READ
#
# [LOW_PRIORITY] WRITE lock:
#
# 		) The session that holds the lock can read and write the table
#
# 		) Only the session that holds the lock can access the table.
#
# 			No other session can access it until the lock is released.
#
# 		) Lock requests for the table by other sessions block while the WRITE lock is held
#
# 		) The LOW_PRIORITY modifier has no effect.
#
# 			In previous versions of MySQL, it affected locking behavior, but this
# 			is no longer true.
#
# 			It is now deprecated and its use produces a warning. 
#
# 			Use WRITE without LOW_PRIORITY instead
#
# WRITE locks normally have higher priority than READ locks to ensure that updates
# are processed as soon as possible.
#
# This means that if one session obtains a READ lock and then another session
# requests a WRITE lock, subsequent READ lock requests wait until the session
# that requested the WRITE lock has obtained the lock and released it.
#
# (An exception to this policy can occur for small values of the max_write_lock_count
# 	system variable; See SECTION 8.11.4, "METADATA LOCKING")
#
# If the LOCK_TABLES statement must wait due to locks held by other sessions on any
# of the tables, it blocks until all locks can be acquired.
#
# A session taht requries locks must acquire all the locks that it needs in a single
# LOCK_TABLES statement.
#
# While the locks thus obtained are held, the session can access only the locked
# tables.
#
# For example, in the following sequence of statements, an error occurs for the attempt
# to access t2 because it was not locked in the LOCK_TABLES statement:
#
# 		LOCK TABLES t1 READ;
# 		SELECT COUNT(*) FROM t1;
# 		+---------------+
# 		| COUNT(*) 		 |
# 		+---------------+
# 		| 			3 		 |
# 		+---------------+
# 		SELECT COUNT(*) FROM t2;
# 		ERROR 1100 (HY000): Table 't2' was not locked with LOCK TABLES
#
# Tables in the INFORMATION_SCHEMA database are an exception.
#
# they can be accessed without being locked explicitly even while a session
# holds table locks obtained with LOCK_TABLES
#
# You cannot refer to a locked table multiple times in a single query using the
# same name.
#
# Use aliases instead, and obtain a separate lock for the table and each alias:
#
# 		LOCK TABLE t WRITE, t AS t1 READ;
# 		INSERT INTO t SELECT * FROM t;
# 		ERROR 1100: Table 't' was not locked with LOCK TABLES
# 		INSERT INTO t SELECT * FROM t AS t1;
#
# The error occurs for the first INSERT because there are two references to the same
# name for a locked table.
#
# The second INSERT succeeds because the references to the table use different names.
#
# If your statement refer to a table by means of an alias, you must lock the table
# using that same alias.
#
# It does not work to lock the table without specifying the alias:
#
# 		LOCK TABLE t READ;
# 		SELECT * FROM t AS myalias;
# 		ERROR 1100: Table 'myalias' was not locked with LOCK TABLES
#
# Conversely, if you lock a table using an alias, you must refer to it
# in your statements using that alias:
#
# 		LOCK TABLE t AS myalias READ;
# 		SELECT * FROM t;
# 		ERROR 1100: Table 't' was not locked with LOCK TABLES
# 		SELECT * FROM t AS myalias;
#
# NOTE:
#
# 		LOCK TABLES or UNLOCK TABLES, when applied to a partitioned table,
# 		always locks or unlocks the entire table;
#
# 		These statements do not support partition lock pruning. See PARTITIONING AND LOCKING.
#
# TABLE lOCK RELEASE
#
# When the table locks held by a session are released, they are all released at the same time.
#
# A session can release its locks explicitly, or locks may be released implicitly
# under certain conditions:
#
# 		) A session can release its locks explicitly with UNLOCK_TABLES
#
# 		) If a session issues a LOCK_TABLES statement to acquire a lock while already holding locks,
# 			its existing locks are released implicitly before the new locks are granted.
#
# 		) If a session begins a transaction (for example, with START_TRANSACTION), an implicit
# 			UNLOCK_TABLES is performed, which causes existing locks to be released.
#
# 			(For additional information about the interaction between table locking
# 			and transactions, see INTERACTION OF TABLE LOCKING AND TRANSACTIONS)
#
# If the connection for a client session terminates, whether normally or abnormally, the server
# implicitly releases all table locks held by the session (transactional and nontransactional)
#
# If the client reconnects, the locks will no longer be in effect.
#
# In addition, if the client had an active transaction, the server rolls back the transaction
# upon disconnect, and if reconnect occurs, the new session begins with autocommit enabled.
#
# For this reason, clients may wish to disable auto-reconnect
#
# With auto-reconnect in effect, the client is not notified if reconnect occurs but any table
# locks or current transaction will have been lost.
#
# With auto-reconnect disabled, if the connection drops, an error occurs for the next
# statement issued.
#
# The client can detect the error and take appropriate action such as reacquiring the locks
# or redoing the transaction.
#
# See SECTION 28.7.24, "C API AUTOMATIC RECONNECTION CONTROL"
#
# NOTE:
#
# 		If you use ALTER_TABLE on a locked table, it may become unlocked.
#
# 		For example, if you attempt a second ALTER_TABLE operation, the result
# 		may be an error Table 'tbl_name' was not locked with LOCK TABLES
#
# 		To handle this, lock the table again prior to the second alteration
#
# 		See also SECTION B.6.6.1, "PROBLEMS WITH ALTER TABLE"
#
# INTERACTION OF TABLE LOCKING AND TRANSACTIONS
#
# LOCK_TABLES and UNLOCK_TABLES interact with the use of transactions as follows:
#
# 		) LOCK_TABLES is not transaction-safe and implicitly commits any active transaction
# 			before attempting to lock the tables.
#
# 		) UNLOCK_TABLES implicitly commits any active transaction, but only if LOCK_TABLES
# 			has been used to acquire table locks.
#
# 			For example, in the following set of statements, UNLOCK_TABLE releases
# 			the global read lock but does not commit the transaction because no table
# 			locks are in effect:
#
# 				FLUSH TABLES WITH READ LOCK;
# 				START TRANSACTION;
# 				SELECT ---;
# 				UNLOCK TABLES;
#
# 		) Beginning a transaction (for example, with START_TRANSACTION) implicitly commits
# 			any current transaction and releases existing table locks.
#
# 		) FLUSH_TABLES_WITH_READ_LOCK acquires a global read lock and not table locks,
# 			so it is not subject to the same behavior as LOCK_TABLES and UNLOCK_TABLES
# 			with respect to table locking and implicit commits.
#
# 			For example, START_TRANSACTION does not release the global read lock
#
# 			See SECTION 13.7.7.3, "FLUSH SYNTAX"
#
# 		) Other statements that implicitly cause transactions to be committed do not
# 			release existing table locks.
#
# 			For a list of such statements, see SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# 		) The correct way to use LOCK_TABLES and UNLOCK_TABLES with transactional tables, such as
# 			InnoDB tables, is to begin a transaction with SET autocommit = 0 (not START TRANSACTION)
# 			followed by LOCK_TABLES, and to not call UNLOCK_TABLES until you commit the
# 			transaction explicitly.
#
# 			For example, if you need to write to table t1 and read from table t2, you can do this:
#
# 				SET autocommit=0;
# 				LOCK TABLES t1 WRITE, t2 READ, ---;
# 				--- Do something with tables t1 and t2 here ---
# 				COMMIT;
# 				UNLOCK TABLES;
#
# 			When you call LOCK_TABLES, InnoDB internally takes its own table lock, and MySQL
# 			takes its own table lock.
#
# 			InnoDB releases its internal table lock at the next commit, but for MySQL
# 			to release its table lock, you have to call UNLOCK_TABLES.
#
# 			You should not have autocommit = 1, because then InnoDB releases its internal
# 			table lock immediately afer the call of LOCK_TABLES, and deadlocks can very easily happen.
#
# 			InnoDB does not acquire the internal table lock at all if autocommit = 1, to help
# 			old applications avoid unnecessary deadlocks.
#
# 		) ROLLBACK does not release table locks
#
# LOCK TABLES AND TRIGGERS
#
# If you lock a table explicitly with LOCK_TABLES, any tables used in triggers are also
# locked implicitly:
#
# 		) The locks are taken as the same time as those acquired explicitly with the LOCK_TABLES statement
#
# 		) The lock on a table used in a trigger depends on whether the table is used only for reading.
#
# 			If so, a read lock suffices
#
# 			Otherwise, a write lock is used
#
# 		) If a table is locked explicitly for reading with LOCK_TABLES, but needs to be locked for
# 			writing because it might be modified within a trigger, a write lock is taken rather
# 			than a read lock.
#
# 			(That is, an implicit write lock needed due to the table's appearance within a trigger
# 				causes an explicit read lock request for the table to be converted to a write lock request)
#
# Suppose that you lock two tables, t1 and t2, using this statement:
#
# 		LOCK TABLES t1 WRITE, t2 READ;
#
# If t1 or t2 have any triggers, tables used within the triggers will also be locked.
#
# Suppose that t1 has a trigger defined like this:
#
# 		CREATE TRIGGER t1_a_ins AFTER INSERT ON t1 FOR EACH ROW
# 		BEGIN
# 			UPDATE t4 SET count = count+1
# 				WHERE id = NEW.id AND EXISTS (SELECT a FROM t3);
# 			INSERT INTO t2 VALUES(1, 2);
# 		END;
#
# The result of the LOCK_TABLES statement is that t1 and t2 are locked because they appear
# in the statement, and t3 and t4 are locked because they are used within the trigger:
#
# 		) t1 is locked for writing per the WRITE lock request
#
# 		) t2 is locked for writing, even though the request is for a READ lock.
#
# 			This occurs because t2 is inserted into within the trigger, so the READ
# 			request is converted to a WRITE request.
#
# 		) t3 is locked for reading because it is only read from within the trigger
#
# 		) t4 is locked for writing because it might be updated within the trigger
#
# TABLE-LOCKING RESTRICTIONS AND CONDITIONS
#
# You can safely use KILL to terminate a session that is waiting for a table lock.
#
# See SECTION 13.7.7.4, "KILL SYNTAX"
#
# LOCK_TABLES and UNLOCK_TABLES cannot be used within stored programs
#
# Tables in the performance_schema database cannot be locked with LOCK_TABLES,
# except the setup_xxx tables
#
# The following statements are prohibited while a LOCK_TABLES statement is in effect:
#
# 		CREATE_TABLE
#
# 		CREATE_TABLE_---_LIKE
#
# 		CREATE_VIEW
#
# 		DROP_VIEW
#
# and DDL statements on stored functions and procedures and events.
#
# For some operations, system tables in the mysql database must be accessed.
#
# For example, the HELP statement requires the contents of the server-side
# help tables, and CONVERT_TZ() might need to read the time zone tables.
#
# The server implicitly locks the system tables for reading as necessary
# so that you need not lock them explicitly.
#
# These tables are treated as just described:
#
# 		mysql.help_category
# 		mysql.help_keyword
#
# 		mysql.help_relation
# 		mysql.help_topic
#
# 		mysql.time_zone
# 		mysql.time_zone_leap_second
#
# 		mysql.time_zone_name
# 		mysql.time_zone_transition
#
# 		mysql.time_zone_transition_type
#
# If you want to explicitly place a WRITE lock on any of those tables with a LOCK_TABLES
# statement, the table must be the only one locked; no other table can be locked with
# the same statement.
#
# Normally, you do not need to lock tables, because all single UPDATE statements are atomic;
# no other session can interfere with any other currently executing SQL statement.
#
# However, there are a few cases when locking tables may provide an advantage:
#
# 		) If you are going to run many operations on a set of MyISAM tables, it is much faster
# 			to lock the tables you are going to use.
#
# 			Locking MyISAM tables speeds up inserting, updating or deleting on them
# 			because MySQL does not flush the key cache for the locked tables until
# 			UNLOCK_TABLES is called.
#
# 			Normally, the key cache is flushed after each SQL statement.
#
# 			The downside to locking the tables is that no session can update a READ-locked
# 			table (including the one holding the lock) and no session can access
# 			a WRITE-locked table other than the one holding the lock.
#
# 		) If you are using tables for a nontransactional storage engine, you must use
# 			LOCK_TABLES if you want to ensure that no other session modifies the tables
# 			between a SELECT and an UPDATE.
#
# 			The example shown here requires LOCK_TABLES to execute safely:
#
# 				LOCK TABLES trans READ, customer WRITE;
# 				SELECT SUM(value) FROM trans WHERE customer_id=some_id;
# 				UPDATE customer
# 					SET total_value=sum_from_previous_statement
# 					WHERE customer_id=some_id;
# 				UNLOCK TABLES;
#
# 			Without LOCK_TABLES, it is possible that another session might insert
# 			a new row in the trans table between execution of the SELECT and UPDATE statements.
#
# You can avoid using LOCK_TABLES in many cases by using relative updates (UPDATE customer SET value=value+new_value)
# or the LAST_INSERT_ID() function
#
# You can also avoid locking tables in some cases by using the user-level advisory lock functions
# GET_LOCK() and RELEASE_LOCK()
#
# These locks are saved in a hash table in the server and implemented with pthread_mutex_lock()
# and pthread_mutex_unlock() for high speed.
#
# See SECTION 12.14, "LOCKING FUNCTIONS"
#
# See SECTION 8.11.1, "INTERNAL LOCKING METHODS", for more information on locking policy.
#
# 13.3.7 SET TRANSACTION SYNTAX
#
# 		SET [GLOBAL | SESSION] TRANSACTION
# 			transaction_characteristic [, transaction_characteristic] ---
#
# 		transaction_characteristic: {
# 			ISOLATION LEVEL level
# 		 | access_mode
# 		}
#
# 		level: {
# 			REPEATABLE READ
# 		 | READ COMMITTED
# 		 | READ UNCOMMITTED
# 		 | SERIALIZABLE
# 		}
# 		
# 		access_mode: {
# 			READ WRITE
# 		 | READ ONLY
# 		}
#
# This statement specifies transaction characteristics.
#
# It takes a list of one or more characteristic values separated by commas.
#
# Each characteristic value sets the transaction isolation level or access mode.
#
# The isolation level is used for operations on InnoDB tables.
#
# The access mode specifies whether transactions operate in read/write or 
# read-only mode
#
# In addition, SET_TRANSACTION can include an optional GLOBAL or SESSION keyword
# to indicate the scope of the statement.
#
# 		) TRANSACTION ISOLATION LEVELS
#
# 		) TRANSACTION ACCESS MODE
#
# 		) TRANSACTION CHARACTERISTIC SCOPE
#
# TRANSACTION ISOLATION LEVELS
#
# To set the transaction isolation level, use an ISOLATION LEVEL level clause.
#
# It is not permitted to specify multiple ISOLATION LEVEL clauses in the same
# SET_TRANSACTION statement.
#
# The default isolation level is REPEATABLE_READ.
#
# Other permitted values are READ_COMMITTED, READ_UNCOMMITTED, and SERIALIZABLE
#
# For information about these isolation levels, see SECTION 15.7.2.1, "TRANSACTION ISOLATION LEVELS"
#
# TRANSACTION ACCESS MODE
#
# To set the transaction access mode, use a READ WRITE or READ ONLY clause.
#
# It is not permitted to specify multiple access-mode clauses in the same SET_TRANSACTION
# statement.
#
# By default, a transaction takes place in read/write mode, with both reads and writes permitted
# to tables used in the transaction.
#
# This mode may be specified explicitly using SET_TRANSACTION with an access mode of READ WRITE
#
# If the transaction access mode is set to READ ONLY, changes to tables are prohibited.
#
# This may enable storage engines to make performance improvements that are possible
# when writes are not permitted.
#
# In read-only mode, it remains possible to change tables created with the TEMPORARY keyword
# using DML statements.
#
# Changes made with DDL statements are not permitted, just as with permanent tables.
#
# The READ WRITE and READ ONLY access modes also may be specified for an individual transaction
# using the START_TRANSACTION statement.
#
# TRANSACTION CHARACTERISTIC SCOPE
#
# You can set transaction characteristic globally, for the current session, or for the
# next transaction only:
#
# 		) With the GLOBAL keyword:
#
# 			) The statement applies globally for all subsequent sessions
#
# 			) Existing sessions are unaffected
#
# 		) With the SESSION keyword:
#
# 			) The statement applies to all subsequent transactions performed within the current session.
#
# 			) The statement is permitted within transactions, but does not affect the current ongoing transaction
#
# 			) If executed between transactions, the statement overrides any preceding statement that sets the
# 				next-transaction value of the named characteristics
#
# 		) Without any SESSION or GLOBAL keyword:
#
# 			) The statement applies only to the next single transaction performed within the session
#
# 			) Subsequent transactions revert to using the session value of the named characteristics
#
# 			) The statement is not permitted within transactions:
#
# 				START TRANSACTION;
# 				Query OK, 0 rows affected (0.02 sec)
#
# 				SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
# 				ERROR 1568 (25001): Transaction characteristics can't be changed
# 				while a transaction is in progress
#
# A change to global transaction characteristics requires the CONNECTION_ADMIN or SUPER privilege.
#
# Any session is free to change its session characteristics (even in the middle of a transaction),
# or the characteristics for its next transaction (prior to the start of that transaction)
#
# To set the global isolation level at server startup, use the --transaction-isolation=level option
# on the command line or in an option file.
#
# Values of level for this option uses dashes rather than spaces, so the permissible values are
# READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, or SERIALIZABLE
#
# Similarly, to set the global transaction access mode at server startup, use the --transaction-read-only
# option
#
# The default is OFF (read/write mode) but the value can be set to ON for a mode of read only.
#
# For example, to set the isolation level to REPEATABLE READ and the access mode to READ WRITE,
# use these lines in the [mysqld] section of an option file:
#
# 		[mysqld]
# 		transaction-isolation = REPEATABLE-READ
# 		transaction-read-only = OFF
#
# At runtime, characteristics at the global, session, and next-transaction scope levels
# can be set indirectly using the SET_TRANSACTION statement, as described previously.
#
# They can also be set directly using the SET statement to assign values to the 
# transaction_isolation and transaction_read_only system variables:
#
# 		) SET_TRANSACTION permits optional GLOBAL and SESSION keywords for setting transaction
# 			characteristics at different scope levels.
#
# 		) The SET statement for assigning values to the transaction_isolation and transaction_read_only
# 			system variables has syntaxes for setting these variables at different scope levels.
#
# The following tables show the characteristic scope level set by each SET_TRANSACTION
# and variable-assignment syntax.
#
# TABLE 13.7 SET TRANSACTION SYNTAX FOR TRANSACTION CHARACTERISTICS
#
# 		SYNTAX 															AFFECTED CHARACTERISTIC SCOPE
#
# 	SET GLOBAL TRANSACTION transaction_characteristic 		Global
#
# 	SET SESSION TRANSACTION transaction_characteristic 	Session
#
# 	SET TRANSACTION transaction_characteristic 				Next transaction only
#
# TABLE 13.8 SET SYNTAX FOR TRANSACTION CHARACTERISTICS
#
# 		SYNTAX 															AFFECTED CHARACTERISTIC SCOPE
#
# 	SET GLOBAL var_name = value 									Global
#
# 	SET @@GLOBAL.var_name = value 								Global
#
# 	SET PERSIST var_name = value 									Global
#
# 	SET @@PERSIST.var_name = value 								Global
#
# 	SET PERSIST_ONLY var_name = value 							No runtime effect
#
# 	SET @@PERSIST_ONLY var_name = value 						No runtime effect
#
# 	SET SESSION var_name = value 									Session
#
# 	SET @@SESSION.var_name = value 								Session
#
# 	SET var_name = value 											Session
#
# 	SET @@var_name = value 											Next transaction only
#
# It is possible to check the global and sesion values of transaction characteristics at runtime:
#
# 		SELECT @@GLOBAL.transaction_isolation, @@GLOBAL.transaction_read_only;
# 		SELECT @@SESSION.transaction_isolation, @@SESSION.transaction_read_only;
#
# 13.3.8 XA TRANSACTIONS
#
# 13.3.8.1 XA TRANSACTION SQL SYNTAX
# 13.3.8.2 XA TRANSACTION STATES
#
# Support for XA transactions is available for the InnoDB storage engine.
#
# The MySQL XA implementation is based on the X/Open CAE document Distributed Transaction Processing: The XA specfication
#
# This document is published by The Open Group and available at <link>
#
# Limitations of the current XA implementation are described in SECTION C.6, "RESTRICTIONS ON XA TRANSACTIONS"
#
# On the client side, there are no special requirements. The XA interface to a MySQL server consists
# of SQL statements that begin with the XA keyword.
#
# MySQL client programs must be able to send SQL statements and to understand the semantics
# of the XA statement interface.
#
# They do not need be linked against a recent client library.
#
# Older client libraries also will work.
#
# Among the MySQL Connectors, MySQL Connector/J 5.0.0 and higher supports XA directly,
# by means of a class interface that handles the XA SQL statement interface for you.
#
# XA supports distributed transactions, that is, the ability to permit multiple separate
# transactional resources to participate in a global transaction.
#
# Transactional resources often are RDBMSs but may be other kinds of resources.
#
# A global transaction involves several actions that are transactional in themselves,
# but that all must either complete successfully as a group, or all be rolled back
# as a group.
#
# In essence, this extends ACID properties "up a level" so that multiple ACID transactions
# can be executed in concert as components of a global operation that also has ACID
# properties.
#
# (As with nondistributed transactions, SERIALIZABLE may be preferred if your applications
# are sensitive to read phenomena.
#
# REPEATABLE_READ may not be sufficient for distributed transactions)
#
# Some examples of distributed transactions:
#
# 		) An application may act as an integration tool that combines a messaging service
# 			with an RDBMS.
#
# 			The application makes sure that transactions dealing with message sending, retrieval
# 			and processing that also involve a transactional database all happen in a global transaction.
#
# 			You can think of this as "transactional email"
#
# 		) An application performs actions that involve different database servers, such as a MySQL
# 			server and an Oracle server (or multiple MySQL servers), where actions that involve
# 			multiple servers must happen as part of a global transaction, rather than as separate
# 			transactions local to each server.
#
# 		) A bank keeps account information in an RDBMS and distributes and receives money through
# 			automated teller machines (ATMs) 
#
# 			It is necessary to ensure that ATM actions are correctly reflected in the accounts,
# 			but this cannot be done with the RDBMS alone.
#
# 			A global transaction manager integrates the ATM and database resources to ensure
# 			overall consistency of financial transactions.
#
# Applications that use global transactions involve one or more Resource Managers and a Transaction Manager:
#
# 		) A Resource Manager (RM) provides access to transactional resources.
#
# 			A database server is one kind of resource manager. It must be possible to either commit or roll
# 			back transactions managed by the RM
#
# 		) A Transaction Manager (TM) coordinates the transactions that are part of a global transaction.
#
# 			It communicates with the RMs that handle each of these transactions.
#
# 			The individual transactions within a global transaction are "branches" of the global transaction.
#
# 			Global transactions and their branches are identified by a naming scheme described later.
#
# The MySQL implementation of XA enables a MySQL server to act as a Resource Manager that handles
# XA transactions within a global transaction.
#
# A client program that connects to the MySQL server acts as the Transaction Manager
#
# To carry out a global transaction, it is necessary to know which components are involved,
# and bring each component to a point when it can be committed or rolled back.
#
# Depending on what each component reports about its ability to succeed, they must all commit
# or roll back as an atomic group.
#
# That is, either all components must commit, or all components must roll back.
#
# To manage a global transaction, it is necessary to take into account that any
# component or the connecting network might ffail.
#
# The process for executing a global transaction uses two-phase commit (2PC)
#
# This takes place after the actions performed by the branches of the global transaction
# have been executed.
#
# 		1. In the first phase, all branches are prepared.
#
# 			That is, they are told by the TM to get ready to commit.
#
# 			Typically, this means each RM that manages a branch records the
# 			actions for the branch in stable storage.
#
# 			The branches indicate whether they are able to do this, and these
# 			results are used for the second phase.
#
# 		2. In the second phase, the TM tells the RMs whether to commit or roll back.
#
# 			If all branches indicated when they were prepared that they will be able
# 			to commit, all branches are told to commit.
#
# 			If any branch indicated when it was prepared that it will not be able to commit,
# 			all branches are told to roll back.
#
# In some cases, a global transaction might use one-phase commit (1PC)
#
# For example, when a Transaction Manager finds a global transaction consists of only
# one transactional resource (that is, a single branch), that resource can be told
# to prepare and commit at the same time.
#
# 13.3.8.1 XA TRANSACTION SQL SYNTAX
#
# To perform XA transactions in MySQL, use the following statements:
#
# 		XA {START|BEGIN} xid [JOIN|RESUME]
#
# 		XA END xid [SUSPEND [FOR MIGRATE]]
#
# 		XA PREPARE xid
#
# 		XA COMMIT xid [ONE PHASE]
#
# 		XA ROLLBACK xid
#
# 		XA RECOVER [CONVERT XID]
#
# For XA_START, the JOIN and RESUME clauses are not supported.
#
# For XA_END the SUSPEND [FOR MIGRATE] clause is not supported.
#
# Each XA statement begins with the XA keyword, and most of them require an
# xid value.
#
# An xid is an XA transaction identifier.
#
# It indicates which transaction the statement applies to.
# xid values are supplied by the client, or generated by the MySQL server.
#
# An xid value has from one to three parts:
#
# 		xid: gtrid [, bqual [, formatID ]]
#
# gtrid is a global transaction identifier, bqual is a branch qualifier, and
# formatID is a number that identifies the format used by the gtrid and bqual
# values.
#
# As indicated by the syntax, bqual and formatID are optional.
#
# The default bqual value is '' if not given.
#
# The default formatID value is 1 if not given.
#
# gtrid and bqual must be string literals, each up to 64 bytes (not characters)
# long
#
# gtrid and bqual can be specified in several ways
#
# You can use a quoted string ('ab'), hex string(X'6162', 0x6162) or bit value (b'nnnn')
#
# formatID is an unsigned integer
#
# The gtrid and bqual values are interpreted in bytes by the MySQL server's underlying
# XA support routines.
#
# However, while an SQL statement containing an XA statement is being parsed,
# the server works with some specific character set.
#
# To be safe, write gtrid and bqual as hex strings.
#
# xid values typically are generated by the Transaction Manager.
#
# Values generated by one TM must be different from values generated by other
# TMs.
#
# A given TM must be able to recognize its own xid values in a list of values
# returned by the XA_RECOVER statement.
#
# XA_START_xd starts an XA transaction with the given xid value.
#
# Each XA transaction must have a unique xid value, so the value must not 
# currently be used by another XA transaction.
#
# Uniqueness is assessed using the gtrid and bqual values. All following XA statements
# for the XA transaction must be specified using the same xid value as that
# given in the XA_START statement.
#
# If you use any of those statements but specify an xid value that does not
# correspond to some existing XA transaction, an error occurs.
#
# One or more XA transactions can be part of the same global transaction.
#
# All XA transactions within a given global transaction must use the same
# gtrid value in the xid value´.
#
# For this reason, gtrid values must be globally unique so that there is
# no ambiguity about which global transaction a given XA transaction is
# part of.
#
# The bqual part of the xid value must be different for each XA transaction
# within a global transaction.
#
# (The requirement that bqual values be different is a limitation of the
# current MySQL XA implementation.
#
# It is not part of the XA specification)
#
# The XA_RECOVER statement returns information for those XA transactions
# on the MySQL server that are in the PREPARED state.
#
# (See SECTION 13.3.8.2, "XA TRANSACTION STATES")
#
# The output includes a row for each such XA transaction on the server,
# regardless of which client started it.
#
# XA_RECOVER requires the XA_RECOVER_ADMIN privilege.
#
# This privilege requirement prevents users from discovering the XID values
# for oustanding prepared XA transactions other than their own.
#
# It does not affect normal commit or rollback of an XA transaction
# because the user who started it knows its XID
#
# XA_RECOVER output rows look like this (for an example xid value consisting of the parts 'abc', 'def', and 7):
#
# 		XA RECOVER;
# 		+----------+------------------+--------------------+-------------------+
# 		| formatID | gtrid_length 		| bqual_length 		| data 				  |
# 		+----------+------------------+--------------------+-------------------+
# 		| 		7 	  | 			3 		 	| 		3 					| 	abcdef 			  |
# 		+----------+------------------+--------------------+-------------------+
#
# The output columns have the following meanings:
#
# 		) formatID is the formatID part of the transaction xid
#
# 		) gtrid_length is the length in bytes of the gtrid part of the xid
#
# 		) bqual_length is the length in bytes of the bqual part of the xid
#
# 		) data is the concatenation of the gtrid and bqual parts of the xid
#
# XID values may contain nonprintable characters 
#
# XA_RECOVER permits an optional CONVERT XID clause so that clients can request
# XID values in hexadecimal.
#
# 13.3.8.2 XA TRANSACTION STATES
#
# An XA transaction progresses through the following states:
#
# 		1. Use XA_START to start an XA transaction and put it in the ACTIVE state
#
# 		2. For an ACTIVE XA transaction, issue the SQL statements that make up the transaction,
# 			and then issue an XA_END statement.
#
# 			XA_END puts the transaction in the IDLE state.
#
# 		3. For an IDLE XA transaction, you can issue either an XA_PREPARE statement or an
# 			XA COMMIT --- ONE phase statement:
#
# 			) XA_PREPARE puts the transaction in the PREPARED state.
#
# 				An XA_RECOVER statement at this point will include the transaction's xid value
# 				in its output, because XA_RECOVER lists all XA transactions that are in the 
# 				PREPARED state
#
# 			) XA COMMIT --- ONE PHASE prepares and commits the transaction.
#
# 				The xid value will not be listed by XA_RECOVER because the transaction terminates.
#
# 		4. For a PREPARED XA transaction, you can issue an XA_COMMIT statement to commit and
# 			terminate the transaction, or XA_ROLLBACK to roll back and terminate the transaction.
#
# Here is a simple XA transaction that inserts a row into a table as part of a global transaction:
#
# 		XA START 'xatest';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO mytable (i) VALUES(10);
# 		Query OK, 1 row affected (0.04 sec)
#
# 		XA END 'xatest';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		XA PREPARE 'xatest';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		XA COMMIT 'xatest';
# 		Query OK, 0 rows affected (0.00 sec)
#
# Within the context of a given client connection, XA transactions and local (non-XA) transactions
# are mutually exclusive.
#
# For example, if XA_START has been issued to begin an XA transaction, a local transaction
# cannot be started until the XA transaction has been committed or rolled back.
#
# Conversely, if a local transaction has been started with START_TRANSACTION,
# no XA statements can be used until the transaction has been committed or rolled back.
#
# If an XA transaction is in the ACTIVE state, you cannot issue any statements that cause
# an implicit commit.
#
# That would violate the XA contract because you could not roll back the XA transaction.
#
# You will receive the following error if you try to execute such a statement:
#
# 		ERROR 1399 (XAE07): XAER_RMFAIL: The command cannot be executed
# 		when global transaction is in the ACTIVE state
#
# Statements to which the preceding remark applies are listed at 
# SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# 13.4 REPLICATION STATEMENTS
#
# 13.4.1 SQL STATEMENTS FOR CONTROLLING MASTER SERVERS
# 13.4.2 SQL STATEMENTS FOR CONTROLLING SLAVE SERVERS
# 13.4.3 SQL STATEMENTS FOR CONTROLLING GROUP REPLICATION
#
# Replication can be controlled through the SQL interface using the statements
# described in this section.
#
# Statements are split into a group which controls master servers, a group
# which controls slave servers, and a group which can be applied to any replication
# servers.
#
# 13.4.1 SQL STATEMENTS FOR CONTROLLING MASTER SERVERS
#
# 13.4.1.1 PURGE BINARY LOGS SYNTAX
# 13.4.1.2 RESET MASTER SYNTAX
# 13.4.1.3 SET SQL_LOG_BIN SYNTAX
#
# This section discusses statements for managing master replication servers.
#
# SECTION 13.4.2, "SQL STATEMENTS FOR CONTROLLING SLAVE SERVERS", discusses
# statements for managing slave servers.
#
# In addition to the statements described here, the following SHOW statements
# are used with master servers in replication.
#
# For information about these statements, see SECTION 13.7.6, "SHOW SYNTAX"
#
# 		) SHOW BINARY LOGS
#
# 		) SHOW BINLOG EVENTS
#
# 		) SHOW MASTER STATUS
#
# 		) SHOW SLAVE HOSTS
#
# 13.4.1.1 PURGE BINARY LOGS SYNTAX
#
# 	PURGE { BINARY | MASTER } LOGS
# 		{ TO 'log_name' | BEFORE datetime_expr }
#
# The binary log is a set of files that contain information about data modifications
# made by the MySQL server.
#
# The log consists of a set of binary log files, plus an index file 
# (See SECTION 5.4.4, "THE BINARY LOG")
#
# The PURGE_BINARY_LOGS statement deletes all the binary log files listed in the
# log index file prior to the specified log file name or date.
#
# BINARY and MASTER are synonyms
#
# Deleted log files also are removed from the list recorded in the index file, so that
# the given log file becomes the first in the list.
#
# This statement has no effect if the server was not started with the --log-bin
# option to enable binary logging.
#
# Examples:
#
# 		PURGE BINARY LOGS TO 'mysql-bin.010';
# 		PURGE BINARY LOGS BEFORE '2008-04-02 22:46:26';
#
# The BEFORE variant's datetime_expr argument should evaluate to a DATETIME value
# (a value in 'YYYY-MM-DD hh:mm:ss' format)
#
# This statement is safe to run while slaves are replicating.
#
# You need not stop them. If you have an active slave that currently is reading
# one of the log files you are trying to delete, this statement does not delete
# the log file that is in use or any log files later than that one, but it deletes
# any earlier log files.
#
# A warning message is issued in this situation.
#
# However, if a slave is not connected and you happen to purge one of the log files
# it has yet to read, the slave will be unable to replicate after it reconnects.
#
# To safely purge binary log files, follow this procedure:
#
# 		1. On each slave server, use SHOW_SLAVE_STATUS to check which log file it is reading.
#
# 		2. Obtain a listing of the binary log files on the master server with SHOW_BINARY_LOGS
#
# 		3. Determine the earliest log file among all the slaves.
#
# 			This is the target file. If all the slaves are up to date, this is the last log file
# 			on the list.
#
# 		4. Make a backup of all the log files you are about to delete (optional)
#
# 		5. Purge all log files up to but not including the target file
#
# PURGE BINARY LOGS TO and PURGE BINARY LOGS BEFORE both fail with an error when binary
# log files listed in the .index file had been removed from the system by some other means
# (such as using rm on Linux)
#
# (Bug #18199, Bug #18453) 
#
# To handle such errors, edit the .index file (which is a simple text file) manually
# to ensure that it lists only the binary log files that are actually present, then
# run again the PURGE_BINARY_LOGS statement that failed.
#
# Binary log files are automatically removed after the server's binary log expiration
# period.
#
# Removal of the files can take place at startup and when the binary log is flushed.
#
# The default binary log expiration period is 30 days.
#
# You can specify an alternative expiration period using the binlog_expire_logs_seconds
# system variable.
#
# If you are using replication, you should specify an expiration period that is no lower
# than the maximum amount of time your slaves might lag behind the master.
#
# 13.4.1.2 RESET MASTER SYNTAX
#
# 		RESET MASTER [TO binary_log_file_number]
#
# RESET MASTER enables you to delete any binary log files and their related binary log
# index file, returning the master to its state before binary logging was started.
#
# WARNING:
#
# 		Use this statement with caution to ensure you do not lose binary log file data
#
# Issuing RESET MASTER without the optional TO clause deletes all binary log files listed
# in the index file, resets the binary log index file to be empty, and creates a new
# binary log file starting at 1.
#
# Use the optional TO clause to start the binary log file index from a number other than
# 1 after the reset.
#
# Issuing RESET MASTER also clears the values of the gtid_purged system variable and the
# gtid_executed system variable; that is, issuing this statement sets each of these
# values to an empty string ('')
#
# This statement also clears the mysql.gtid_executed table (see MYSQL.GTID_EXECUTED TABLE)
#
# Using RESET MASTER with the TO clause to specify a binary log file index number to start
# from simplifies failover by providing a single statement alternative to the FLUSH_BINARY_LOGS
# and PURGE_BINARY_LOGS_TO statements.
#
# The following example demonstrates TO clause usage:
#
# 		RESET MASTER TO 1234;
#
# 		SHOW BINARY LOGS;
# 		+-----------------------------+---------------+
# 		| Log_name 							| File_size 	 |
# 		+-----------------------------+---------------+
# 		| master-bin.001234 			   | 154 			 |
# 		+-----------------------------+---------------+
#
# IMPORTANT:
#
# 		The effects of RESET_MASTER without the TO clause differ from those of
# 		PURGE_BINARY_LOGS in 2 key ways:
#
# 			1. RESET_MASTER removes all binary log files that are listed in the index file,
# 				leaving only a single, empty binary log file with a numeric suffix of
# 				.000001, whereas the numbering is not reset by PURGE_BINARY_LOGS
#
# 			2. RESET_MASTER is not intended to be used while any replication slaves
# 				are running.
#
# 				The behavior of RESET_MASTER when used while slaves are running
# 				is undefined (and thus unsupported), whereas PURGE_BINARY_LOGS
# 				may be safely used while replication slaves are running.
#
# 		See also SECTION 13.4.1.1, "PURGE BINARY LOGS SYNTAX"
#
# RESET_MASTER without the TO clause can prove useful when you first set up
# the master and the slave, so that you can verify the setup as follows:
#
# 		1. Start the master and slave, and start replication (see SECTION 17.1.2, "SETTING UP BINARY LOG FILE POSITION BASED REPLICATION")
#
# 		2. Execute a few test queries on the master
#
# 		3. Check that the queries were replicated to the slave
#
# 		4. When replication is running correctly, issue STOP_SLAVE followed by
# 			RESET_SLAVE on the slave, then verify that no unwanted data from the
# 			test queries exists on the slave.
#
# 		5. Issue RESET_MASTER on the master to clean up the test queries
#
# After verifying the setup, resetting the master and slave and ensuring that no unwanted
# data or binary log files generated by testing remain on the master or slave, you can
# start the slave and begin replicating.
#
# 13.4.1.3 SET SQL_LOG_BIN_SYNTAX
#
# 		SET sql_log_bin = {OFF|ON}
#
# The sql_log_bin variable controls whether logging to the binary log is enabled
# for the current session (assuming that the binary log itself is enabled)
#
# The default value is ON
#
# To disable or enable binary logging for the current session, set the session
# sql_log_bin variable to OFF or ON
#
# Set this variable to OFF for a session to temporarily disable binary logging
# while making changes to the master you do not want replicated to the slave.
#
# Setting the session value of this system variable is a restricted operation
#
# The session user must have privileges sufficient to set restricted session
# variables.
#
# See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"
#
# It is not possible to set the session value of sql_log_bin within
# a transaction or subquery
#
# Setting this variable to OFF prevents GTIDs from being assigned to transactions
# in the binary log.
#
# If you are using GTIDs for replication, this means that even when binary logging
# is later enabled again, the GTIDs written into the log from this point do not
# account for any transactions that occurred in the meantime, so in effect those
# transactions are lost.
#
# 13.4.2 SQL STATEMENTS FOR CONTROLLING SLAVE SERVERS
#
# 13.4.2.1 CHANGE MASTER TO SYNTAX
# 13.4.2.2 CHANGE REPLICATION FILTER SYNTAX
#
# 13.4.2.3 MASTER_POS_WAIT() SYNTAX
# 13.4.2.4 RESET SLAVE SYNTAX
#
# 13.4.2.5 SET GLOBAL SQL_SLAVE_SKIP_COUNTER SYNTAX
# 13.4.2.6 START SLAVE SYNTAX
#
# 13.4.2.7 STOP SLAVE SYNTAX
#
# This section discusses statements for managing slave replication servers.
#
# SECTION 13.4.1, "SQL STATEMENTS FOR CONTROLLING MASTER SERVERS", discusses statements
# for managing master servers.
#
# In addition to the statements described here, SHOW_SLAVE_STATUS and SHOW_RELAYLOG_EVENTS
# are also used with replicaiton slaves.
#
# For information about these statements, see SECTION 13.7.6.34, "SHOW SLAVE STATUS SYNTAX"
# and SECTION 13.7.6.32, "SHOW RELAYLOG EVENTS SYNTAX"
#
# 13.4.2.1 CHANGE MASTER TO SYNTAX
#
# 	CHANGE MASTER TO option [, option] --- [ channel_option ]
#
# 	option:
# 		MASTER_BIND = 'interface_name'
#   | MASTER_HOST = 'host_name'
#   | MASTER_USER = 'user_name'
#   | MASTER_PASSWORD = 'password'
#   | MASTER_PORT = port_num
#   | MASTER_CONNECT_RETRY = interval
#   | MASTER_RETRY_COUNT = count
#   | MASTER_DELAY = interval
#
#   | MASTER_HEARTBEAT_PERIOD = interval
# 	 | MASTER_LOG_FILE = 'master_log_name'
#   | MASTER_LOG_POS = master_log_pos
#   | MASTER_AUTO_POSITION = {0|1}
#   | RELAY_LOG_FILE = 'relay_log_name'
# 	 | RELAY_LOG_POS = relay_log_pos
#
# 	 | MASTER_SSL = {0|1}
# 	 | MASTER_SSL_CA = 'ca_file_name'
#   | MASTER_SSL_CAPATH = 'ca_directory_name'
# 	 | MASTER_SSL_CERT = 'cert_file_name'
# 	 | MASTER_SSL_CRT = 'crl_file_name'
# 	 | MASTER_SSL_CRLPATH = 'crl_directory_name'
#   | MASTER_SSL_KEY = 'key_file_name'
#   | MASTER_SSL_CIPHER = 'cipher_list'
#   | MASTER_SSL_VERIFY_SERVER_CERT = {0|1}
#   | MASTER_TLS_VERSION = 'protocol_list'
#   | MASTER_PUBLIC_KEY_PATH = 'key_file_name'
#   | GET_MASTER_PUBLIC_KEY = {0|1}
#   | IGNORE_SERVER_IDS = (server_id_list)
#
# 	channel_option:
# 		FOR CHANNEL channel
#
# 	server_id_list:
# 		[server_id [, server_id] --- ]
#
# CHANGE_MASTER_TO changes the parameters that the slave server uses for
# connecting to the master server, for reading the master binary log and
# reading the slave relay log.
#
# It also updates the contents of the master info and relay log info repositories
# (see SECTION 17.2.4, "REPLICATION RELAY AND STATUS LOGS")
#
# CHANGE_MASTER_TO requires the REPLICATION_SLAVE_ADMIN or SUPER privilege
#
# You can issue CHANGE MASTER TO statements on a running slave without first
# stopping it, depending on the states of the slave SQL thread and slave I/O
# thread.
#
# The rules governing such use are provided later in this section
#
# When using a multithreaded slave (in other words slave_parallel_workers is greater
# than 0), stopping the slave can cause "gaps" in the sequence of transactions that
# have been executed from the relay log, regardless of whether the slave was stopped
# intentionally or otherwise.
#
# When such gaps exist, issuing CHANGE_MASTER_TO fails
#
# The solution in this situation is to issue START_SLAVE_UNTIL_SQL_AFTER_MTS_GAPS
# which ensures that the gaps are closed.
#
# The optional FOR CHANNEL channel clause enables you to name which replication
# channel the statement applies to.
#
# Providing a FOR CHANNEL channel clause applies the CHANGE MASTER to statement
# to a specific replication channel, and is used to add a new channel or modify
# an existing channel.
#
# For example, to add a new channel called channel2:
#
# 		CHANGE MASTER TO MASTER_HOST=host1, MASTER_PORT=3002 FOR CHANNEL 'channel2'
#
# If no clause is named and no extra channels exist, the statement applies to the
# default channel.
#
# When using multiple replication channels, if a CHANGE MASTER TO statement does not
# name a channel using a FOR CHANNEL channel clause, an error occurs.
#
# See SECTION 17.2.3, "REPLICATION CHANNELS" for more information.
#
# Options not specified retain their value, except as indicated in the following discussion.
#
# Thus, in most cases, there is no need to specify options that do not change.
#
# MASTER_HOST, MASTER_USER, MASTER_PASSWORD and MASTER_PORT provide information
# to the slave about how to connect to its master:
#
# 		) MASTER_HOST and MASTER_PORT are the host name (or IP address) of the master host and its TCP/IP port
#
# 			NOTE:
#
# 				Replication channel use UNIX socket files.
#
# 				You must be able to connect to the master MySQL server using TCP/IP
#
# 			If you specify the MASTER_HOST or MASTER_PORT option, the slave assumes that the master
# 			server is different from before (even if the option value is the same as its current value)
#
# 			In this case, the old values for the master binary log file name and position are considered
# 			no longer applicable, so if you do not specify MASTER_LOG_FILE and MASTER_lOG_POS in the
# 			statement, MASTER_LOG_FILE='' and MASTER_LOG_POS=4 are silently appended to it.
#
# 			Setting MASTER_HOST='' (that is, setting its value explicitly to an empty string) is not
# 			the same as not setting MASTER_HOST at all.
#
# 			Trying to set MASTER_HOT to an empty string fails with an error.
#
# 			Values used for MASTER_HOST and other CHANGE MASTER TO options are checked for
# 			linefeed (\n or 0x0A) characters; the presence of such characters in these values
# 			causes the statement to fail with ER_MASTER_INFO.
#
# 			(Bug #11758581, Bug #50801)
#
# 		) MASTER_USER and MASTER_PASSWORD are the user name and password of the account to use
# 			for connecting to the master.
#
# 			MASTER_USER cannot be made empty; setting MASTER_USER = '' or leaving it unset when
# 			setting a value for MASTER_PASSWORD causes an error (Bug #13427949)
#
# 			The password used for a MySQL Replication slave account in a CHANGE MASTER TO
# 			statement is limited to 32 characters in length;
#
# 			Trying to use a password of more than 32 characters causes CHANGE MASTER TO to fail
#
# 			The text of a running CHANGE_MASTER_TO statement, including values for MASTER_USER and
# 			MASTER_PASSWORD, can be seen in the output of a concurrent SHOW_PROCESSLIST statement.
#
# 			(The complete text of a START_SLAVE statement is also visible to SHOW_PROCESSLIST)
#
# The MASTER_SSL_xxx options, and the MASTER_TLS_VERSION option, specify how the slave uses
# encryption and ciphers to secure the replication connection.
#
# These options can be changed even on slaves that are compiled without SSL support.
#
# They are saved to the master info repository, but are ignored if the slave does not
# have SSL support enabled.
#
# The MASTER_SSL_xxx options perform the same functions as the --ssl-xxx options described
# in SECTION 6.4.2, "COMMAND OPTIONS FOR ENCRYPTED CONNECTIONS"
#
# The correspondence between the two sets of options, and the use of the MASTER_SSL_xxx
# and MASTER_TLS_VERSION options to set up a secure connection, is explained in
# SECTION 17.3.9, "SETTING UP REPLICATION TO USE ENCRYPTED CONNECTIONS"
#
# 		IMPORTANT:
#
# 			To connect to the replication master using a user account that authenticates
# 			with the caching_sha2_password plugin, you must either set up a secure
# 			connection as described in SECTION 17.3.9, "SETTING UP REPLICATION TO USE ENCRYPTED CONNECTIONS",
# 			or enable the unencrypted connection to support password exchange using an
# 			RSA key pair.
#
# 			The caching_sha2_password authentication plugin is the default for new users
# 			created from MySQL 8.0 (for details, see SECTION 6.5.1.3, "CACHING SHA-2 PLUGGABLE AUTHENTICATION")
#
# 			If the user account that you create or use for replication (as specified by the
# 			MASTER_USER option) uses this authentication plugin, and you are not using a
# 			secure connection, you must enable RSA key pair-based password exchange for a 
# 			successful connection.
#
# To enable RSA key pair-based password exchange, specify either the MASTER_PUBLIC_KEY_PATH
# or the GET_MASTER_PUBLIC_KEY=1 option
#
# Either of these options provides the RSA public key to the slave:
#
# 		) MASTER_PUBLIC_KEY_PATH indicates the path name to a file containing a slave-side
# 			copy of the public key required by the master for RSA key pair-based password
# 			exchange.
#
# 			The file must be in PEM format.
#
# 			This option applies to slaves that authenticate with the sha256_password
# 			or caching_sha2_password authentication plugin.
#
# 			(For sha256_password, MASTER_PUBLIC_KEY_PATH can be used only if MySQL
# 			was built using OpenSSL)
#
# 		) GET_MASTER_PUBLIC_KEY indicates whether to request from the master the public key
# 			required for RSA key pair-based password exchange.
#
# 			This option applies to slaves that authenticate with the caching_sha2_password
# 			authentication plugin.
#
# 			For connections by accounts that authenticate using this plugin, the master
# 			does not send the public key unless requested, so it must be requested or
# 			specified in the client.
#
# 			If MASTER_PUBLIC_KEY_PATH is given and specifies a valid public key file,
# 			it takes precedence over GET_MASTER_PUBLIC_KEY
#
# The MASTER_HEARTBEAT_PERIOD, MASTER_CONNECT_RETRY and MASTER_RETRY_COUNT options
# control how the slave recognizes that the connection to the master has been
# lost and makes attempts to reconnect.
#
# 		) The slave_net_timeout system variable specifies the number of seconds that
# 			 the slave waits for either more data or a heartbeat signal from the master,
# 			before the slave considers the connection broken, aborts the read, and tries
# 			to reconnect.
#
# 			The default value is 60 seconds (one minute)
#
# 		) The heartbeat interval, which stops the connection timeout occurring in the
# 			absence of data if the connection is still good, is controlled by the 
# 			MASTER_HEARTBEAT_PERIOD option.
#
# 			A heartbeat signal is sent to the slave after that number of seconds, and the
# 			waiting period is reset whenever the master's binary log is updated
# 			with an event.
#
# 			Heartbeats are therefore sent by the master only if there are no unset events
# 			in the binary log file for a period longer than this.
#
# 			The heartbeat interval interval is a decimal value having the range 0 to 4294967
# 			seconds and a resolution in milliseconds; the smallest nonzero value is 0.001
#
# 			Setting interval to 0 disables heartbeats altogether.
#
# 			The heartbeat interval defaults to half the value of the slave_net_timeout
# 			system variable.
#
# 			It is recorded in the master info log and shown in the replication_connection_configuration
# 			Performance Schema table.
#
# 			Issuing RESET_SLAVE resets the heartbeat interval to the default value.
#
# 			Note that a change to the value or default setting of slave_net_timeout does not
# 			automatically change the heartbeat interval, whether that has been set
# 			explicitly or is using a previously calculated default.
#
# 			A warning is issued if you set @@GLOBAL.slave_net_timeout to a value less than
# 			that of the current heartbeat interval.
#
# 			If slave_net_timeout is changed, you must also issue CHANGE_MASTER_TO to adjust
# 			the heartbeat interval to an appropriate value so that the heartbeat signal occurs before
# 			the connection timeout.
#
# 			If you do not do this, the heartbeat signal has no effect, and if no data is received
# 			from the master, the slave can make repeated reconnection attempts, creating zombie
# 			dump threads.
#
# 		) If the slave does need to reconnect, the first retry occurs immediately after the timeout.
#
# 			MASTER_CONNECT_RETRY specifies the interval between reconnection attempts, and MASTER_RETRY_COUNT
# 			limits the number of reconnection attempts.
#
# 			If both the default settings are used, the slave waits 60 seconds between reconnection attempts
# 			(MASTER_CONNECT_RETRY=60), and keeps attempting to reconnect at this rate for 24 hours
# 			(MASTER_RETRY_COUNT=86400)
#
# 			These values are recorded in the master info log and shown in the replication_connection_configuration
# 			Performance Schema table.
#
# 			MASTER_RETRY_COUNT supersedes the --master-retry-count server startup option.
#
# MASTER_DELAY specifies how many seconds behind the master the slave must lag.
#
# An event received from the master is not executed until at least interval seconds later
# than its execution on the master.
#
# The default is 0.
#
# An error occurs if interval is not a nonnegative integer in teh range from 0 to 2^31-1
#
# For more information, see SECTION 17.3.12, "DELAYED REPLICATION"
#
# A CHANGE MASER TO statement employing the MASTER_DELAY option can be executed on a running
# slave when the slave SQL thread is stopped.
#
# MASTER_BIND is for use on replication slaves having multiple network interfaces, and determines
# which of the slave's network interfaces is chosen for connecting to the master.
#
# The address configured with this option, if any, can be seen in the Master_Bind column
# of the output from SHOW_SLAVE_STATUS
#
# In the master info repository table mysql.slave_master_info, the value can be seen
# as the Master_bind column.
#
# The ability to bind a replicaiton slave to a specific network interface is also supported
# by NDB Cluster.
#
# MASTER_lOG_FILE and MASTER_LOG_POS are the coordinates at which the slave I/O thread should
# begin reading from the master the next time the thread starts.
#
# RELAY_LOG_FILE and RELAY_LOG_POS are the coordinates at which the slave SQL thread should
# begin reading from teh relay log the next time the thread starts.
#
# If you specify either of MASTER_LOG_FILE or MASTER_LOG_POS, you cannot specify RELAY_LOG_FILE
# or RELAY_LOG_POS
#
# If you specify either of MASTER_LOG_FILE or MASTER_LOG_POS, you also cannot specify MASTER_AUTO_POSITION = 1
# (described later in this section)
#
# If neither of MASTER_LOG_FILE or MASTER_LOG_POS is specified, the slave uses the last coordinates
# of the slave SQL thread before CHANGE_MASTER_TO was issued.
#
# This ensures that there is no discontinuity in replication, even if the slave SQL thread was
# late compared to the slave I/O thread, when you merely want to change, say, the PW.
#
# A CHANGE MASTER TO statement employing RELAY_LOG_FILE, RELAY_LOG_POS or both options
# can be executed on a running slave when the slave SQL thread is stopped.
#
# Relay logs are preserved if at least one of the slave SQL thread and the slave I/O
# thread is running; if both threads are stopped, all relay log files are deleted
# unless at least one of RELAY_LOG_FILE or RELAY_LOG_POS is specified.
#
# RELAY_LOG_FILE can use either an absolute or relative path, and uses teh same base name
# as MASTER_LOG_FILE
#
# When MASTER_AUTO_POSITION = 1 is used with CHANGE MASTER TO, the slave attempts to connect
# to the master using the GTID-based replication protocol.
#
# This option can be used with CHANGE MASTER TO only if both the slave SQL and slave I/O
# threads are stopped.
#
# Both the slave and the master must have GTIDs enabled (GTID MODE=ON, ON_PERMISSIVE or OFF_PERMISSIVE
# on the slave, and GTID_MODE=ON on the master)
#
# Auto-positioning is used for the connection, so the coordinates represented by MASTER_LOG_FILE
# and MASTER_LOG_POS are not used, and the use of either or both of these options together with
# MASTER_AUTO_POSITION = 1 causes an error.
#
# If multi-source replication is enabled on the slave, you need to set the MASTER_AUTO_POSITION = 1
# option for each applicable replication channel.
#
# With MASTER_AUTO_POSITION = 1 set, in the initial connection handshake, the slave sends a 
# GTID set containing the transactions that it has already received, committed, or both.
#
# The master responds by sending all transactions recorded in its binary log whose GTID
# is not included in the GTID set sent by the slave.
#
# This exchange ensures that the master only sends the transactions with a GTID that the slave
# has not already recorded or committed.
#
# If the slave receives transactions from more than one master, as in the case of a 
# diamond topology, the auto-skip function ensures that the transactions are not applied twice.
#
# For details of how the GTID set sent by the slave is computed, see SECTION 17.1.3.3,
# "GTID AUTO-POSITIONING"
#
# If any of the transactions that should be sent by the master have been purged from the
# master's binary log, or added to the set of GTIDs in the gtid_purged system variable
# by another method, the master sends the error:
#
# 		ER_MASTER_HAS_PURGED_REQUIRED_GTIDS
#
# to the slave, and replication does not start.
#
# The GTIDs of the missing purged transactions are identified and listed in the master's
# error log in the warning message:
#
# 		ER_FOUND_MISSING_GTIDS
#
# Also, if during the exchange of transactions it is found that the slave has recorded
# or committed transactions with the master's UUID in the GTID, but the master itself
# has not committed them, the master sends the error:
#
# 		ER_SLAVE_HAS_MORE_GTIDS_THAN_MASTER
#
# to the slave and replication does not start.
#
# For information on how to handle these situations, see SECTION 17.1.3.3,
# "GTID AUTO-POSITIONING"
#
# You can see whether replication is running with auto-positoning enabled
# by checking the Performance Schema replication_connection_status table
# or the output of SHOW_SLAVE_STATUS
#
# Disabling the MASTER_AUTO_POSITION option again makes the slave revert
# to file-based replication, in which case you must also specify one or both
# of the MASTER_LOG_FILE or MASTER_LOG_POS options.
#
# IGNORE_SERVER_IDS takes a comma-separated list of 0 or more server IDs.
#
# Events originating from the corresponding servers are ignored, with the 
# exception of log rotation and deletion events, which are still recorded
# in the relay log.
#
# In circular replication, the originating server normally acts as the terminator
# of its own events, so that they are not applied more than once.
#
# Thus, this option is useful in circular replication when one of the servers
# in the circle is removed.
#
# Suppose that you have a circular replication setup with 4 servers,
# having server IDs 1, 2, 3 and 4 and server 3 fails.
#
# When bridging the gap by starting replication from server 2 to server
# 4, you can include IGNORE_SERVER_IDS = (3) in the CHANGE_MASTER_TO
# statement that you issue on server 4 to tell it to use server 2 as its
# master instead of server 3.
#
# Doing so causes it to ignore and not to propagate any statements
# that originated with the server that is no longer in use.
#
# if IGNORE_SERVER_IDS contains the server's own ID and the server was
# started with the --replicate-same-server-id option enabled, an error results.
#
# NOTE:
#
# 		When global transaction identifiers (GTIDs) are used for replication,
# 		transactions that have already been applied are automatically ignored,
# 		so the IGNORE_SERVER_IDS function is not required and is deprecated.
#
# 		If gtid_mode=ON is set for the server, a deprecation warning is issued
# 		if you include the IGNORE_SERVER_IDS option in a CHANGE_MASTER_TO 
# 		statement.
#
# The master info repository and the output of SHOW_SLAVE_STATUS provide the list
# of servers that are currently ignored.
#
# For more information, see SECTION 17.2.4.2, "SLAVE STATUS lOGS" and
# SECTION 13.7.6.34, "SHOW SLAVE STATUS SYNTAX"
#
# If a CHANGE_MASTER_TO statement is issued without any IGNORE_SERVER_IDS
# option, any existing list is preserved.
#
# To clear the list of ignored servers, it is necessary to use the option
# with an empty list:
#
# 		CHANGE MASTER TO IGNORE_SERVER_IDS = ();
#
# RESET SLAVE ALL clears IGNORE_SERVER_IDS
#
# NOTE:
#
# 		A deprecation warning is issued if SET GTID_MODE=ON is issued
# 		when any channel has existing server IDs set with IGNORE_SERVER_IDS
#
# 		Before starting GTID-based replication, check for and clear all ignored
# 		server ID lists on the servers involved.
#
# 		The SHOW_SLAVE_STATUS statement displays the list of ignore IDs,
# 		if there is one.
#
# 		If you do receive the deprecation warning, you can still clear a 
# 		list after gtid_mode=ON is set by issuing a CHANGE_MASTER_TO statement
# 		containing the IGNORE_SERVER_IDS option with an empty list.
#
# Invoking CHANGE_MASTER_TO causes the previous values for MASTER_HOST, MASTER_PORT,
# MASTER_LOG_FILE and MASTER_LOG_POS to be written to the error log, along with
# other information about the slave's state prior to execution.
#
# CHANGE MASTER TO causes an implicit commit of an ongoing transaction.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# From MySQL 5.7, the strict requirements to execute STOP_SLAVE prior to issuing
# any CHANGE_MASTER_TO statement (and START_SLAVE afterward) is removed.
#
# Instead of depending on whether the slave is stopped, the behavior of CHANGE MASTER TO
# depends on the states of the slave SQL thread and slave I/O threads; which of these
# threads is stopped or running now determines the options that can or cannot be used
# with a CHANGE MASTER TO statement at a given point in time.
#
# The rules for making this determinaiton are listed here:
#
# 		) If hte SQL thread is stopped, you can execute CHANGE MASTER TO using
# 			any combination that is otherwise allowed of RELAY_LOG_FILE, RELAY_LOG_POS,
# 			and MASTER_DELAY options, even if the slave I/O thread is running.
#
# 			No other options may be used with this statement when the I/O thread
# 			is running.
#
# 		) If the I/O thread is stopped, you can execute CHANGE MASTER TO using any
# 			of the options for this statement (in any allowed combination) except:
#
# 				RELAY_LOG_FILE
#
# 				RELAY_LOG_POS
#
# 				MASTER_DELAY
#
# 			even when the SQL thread is running.
#
# 			These three options may not be used when the I/O thread is running.
#
# 		) Both the SQL thread and the I/O thread must be stopped before issuing a 
# 			CHANGE MASTER TO statement that employs MASTER_AUTO_POSITION = 1
#
# You can check the current state of the slave SQL and I/O threads using SHOW_SLAVE_STATUS
#
# For more information, see SECTION 17.3.8, "SWITCHING MASTERS DURING FAILOVER"
#
# If you are using statement-based replication and temporary tables, it is possible
# for a CHANGE MASTER TO statement following a STOP SLAVE statement to leave behind
# temporary tables on the slave.
#
# A warning (ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO) is now issued whenever this occurs.
#
# You can avoid this in such cases by making sure that the value of the SLAVE_OPEN_TEMP_TABLES
# system status variable is equal to 0 prior to executing such a CHANGE MASTER TO statement.
#
# CHANGE_MASTER_TO is useful for setting up a slave when you have the snapshot of the master
# and have recorded the master binary log coordinates corresponding to the time of hte
# snapshot.
#
# After loading the snapshot into the slave to synchronize it with the master, you can run
# CHANGE MASTER TO MASTER_LOG_FILE='log_name', MASTER_LOG_POS=log_pos on the slave to specify
# the coordinates at which the slave should begin reading the master binary log.
#
# The following example changes the master server the slave uses and establishes the master
# binary log coordinates from which the slave begins reading.
#
# This is used when you want to set up the slave to replicate the master:
#
# 		CHANGE MASTER TO
# 			MASTER_HOST='master2.example.com',
# 			MASTER_USER='replication',
# 			MASTER_PASSWORD='password',
# 			MASTER_PORT=3306,
# 			MASTER_LOG_FILE='master2-bin.001',
# 			MASTER_LOG_POS=4,
# 			MASTER_CONNECT_RETRY=10;
#
# The next example shows an operation that is less frequently employed.
#
# It is used when the slave has relay log files that you want it to execute
# again for some reason.
#
# To do this, the master need not be reachable.
#
# You need only use CHANGE_MASTER_TO and start the SQL thread (START SLAVE SQL_THREAD):
#
# 		CHANGE MASTER TO
# 			RELAY_LOG_FILE='slave-relay-bin.006',
# 			RELAY_LOG_POS=4025;
#
# The following table shows the maximum permissible length for hte string-valued options.
#
# OPTION 			MAX LENGTH
# 
# MASTER_HOST 			60
# 					
# MASTER_USER 			96
#
# MASTER_PASSWORD 	32
#
# MASTER_LOG_FILE 	511
#
# RELAY_LOG_FILE 		511
#
# MASTER_SSL_CA 		511
#
# MASTER_SSL_CAPATH 	511
#
# MASTER_SSL_CERT 	511
#
# MASTER_SSL_CRL 		511
#
# MASTER_SSL_CRLPATH 511
#
# MASTER_SSL_KEY 		511
#
# MASTER_SSL_CIPHER 	511
#
# MASTER_TLS_VERSION 511
#
# MASTER_PUBLIC_KEY_PATH 511
#
# 13.4.2.2 CHANGE REPLICATION FILTER SYNTAX
#
# CHANGE REPLICATION FILTER filter[, filter]
# 		[, ---] [FOR CHANNEL channel]
#
# filter:
# 		REPLICATE_DO_DB = (db_list)
#   | REPLICATE_IGNORE_DB = (db_list)
#   | REPLICATE_DO_TABLE = (tbl_list)
#   | REPLICATE_IGNORE_TABLE = (tbl_list)
#   | REPLICATE_WILD_DO_TABLE = (wild_tbl_list)
# 	 | REPLICATE_WILD_IGNORE_TABLE = (wild_tbl_list)
#   | REPLICATE_REWRITE_DB = (db_pair_list)
#
# db_list:
# 		db_name[, db_name][, ---]
#
# tbl_list:
# 		db_name.table_name[, db_name.table_name[, ---]
# wild_tbl_list:
# 		'db_pattern.table_pattern'[, 'db_pattern.table_pattern'][, ---]
#
# db_pair_list:
# 		(db_pair)[, (db_pair)][, ---]
#
# db_pair:
# 		from_db, to_db
#
# CHANGE REPLICATION FILTER sets one or more replicaiton filtering rules on the
# slave in teh same way as starting the slave mysqld with replication filtering
# options such as:
#
# 		--replicate-do-db
#
# 		or
#
# 		--replicate-wild-ignore-table
#
# Unlike the case with the server options, this statement does not require
# restarting the server to take effect, only that the slave SQL thread
# be stopped using STOP_SLAVE_SQL_THREAD first (and restarted with START_SLAVE_SQL_THREAD afterwards).
#
# CHANGE_REPLICATION_FILTER requires the REPLICATION_SLAVE_ADMIN or SUPER privilege
#
# Use the FOR CHANNEL channel clause to make a replicaiton filter specific to a replication
# channel, for example on a multi-source replication slave.
#
# Filters applied without a specific FOR CHANNEL clause are considered global filters,
# meaning that they are applied to all replication channels.
#
# 	NOTE:
#
# 		Global replication filters cannot be set on a MySQL server instance that is configured
# 		for Group Replication, because filtering transactions on some servers would make the group
# 		unable to reach agreement on a consistent state.
#
# 		Channel specific replication filters can be set on replication channels that are not
# 		directly involved with Group Replication, such as where a group member also acts
# 		as a replication slave to a master that is outside the group.
#
# 		They cannot be set on the group_replication_applier or group_replication_recovery channels
#
# The following list shows the CHANGE REPLICATION FILTER options and how they relate to 
# --replicate-* server options:
#
# 		) REPLICATE_DO_DB: Include updates based on database name. Equivalent to --replicate-do-db
#
# 		) REPLICATE_IGNORE_DB: Exclude updates based on database name. Equivalent to --replicate-ignore-db
#
# 		) REPLICATE_DO_TABLE: Include updates based on table name. Equivalent to --replicate-do-table
#
# 		) REPLICATE_IGNORE_TABLE: Exclude updates based on table name. Equivalent to --replicate-ignore-table
#
# 		) REPLICATE_WILD_DO_TABLE: Include updates based on wildcard pattern matching table name. Equivalent to --replicate-wild-do-table
#
# 		) REPLICATE_WILD_IGNORE_TABLE: Exclude updates based on wildcard pattern matching table name. Equivalent to --replicate-wild-ignore-table
#
# 		) REPLICATE_REWRITE_DB: Perform updates on slave after substituting new name on slave for specified database on master.
#
# 											Equivalent to --replicate-rewrite-db
#
# The precise effects of REPLICATE_DO_DB and REPLICATE_IGNORE_DB filters are dependent on whether statement-based
# or row-based replication is in effect.
#
# See SECTION 17.2.5, "HOW SERVERS EVALUATE REPLICATION FILTERING RULES", for more information.
#
# Multiple replication filtering rules can be created in a single CHANGE REPLICATION FILTER statement
# by separating the rules with commas, as shown here:
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_DO_DB = (d1), REPLICATE_IGNORE_DB = (d2);
#
# Issuing the statement just shown is equivalent to starting the slave mysqld with the options
# --replicate-do-db=d1 --replicate-ignore-db=d2
#
# On a multi-score replicaiton slave, which uses multiple replicaiton channels to process transaction
# from different sources, use the FOR CHANNEL channel clause to set a replication filter on
# a replication channel:
#
# 		CHANGE REPLICATION FILTER REPLICATE_DO_DB = (d1) FOR CHANNEL channel_1;
#
# This enables you to create a channel specific replication filter to filter out selected
# data from a source.
#
# When a FOR CHANNEL clause is provided, the replication filter statement acts
# on that slave replication channel removing any existing replication filter which
# has the same filter type as the specified replication filters, and replacing them
# with the specified filter.
#
# Filter types not explicitly listed in the statement are not modified
#
# If issued against a slave replication channel which is not configured,
# the statement fails with an ER_SLAVE_CONFIGURATION error
#
# If issued against Group Replication channels, the statement fails with an
# ER_SLAVE_CHANNEL_OPERATION_NOT_ALLOWED error
#
# On a replication slave with multiple replicaiton channels configured, issuing
# CHANGE_REPLICATION_FILTER with no FOR CHANNEL clause configures the replication
# filter for every configured slave replication channel, and for the global replication filters.
#
# For every filter type, if the filter type is listed in the statement, then any existing
# filter rules of that type are replaced by the filter rules specified in the most recently
# issued statement, otherwise the old value of the filter type is retained.
#
# For more information see SECTION 17.2.5.4, "REPLICATION CHANNEL BASED FILTERS"
#
# If the same filtering rule is specified multiple times, only the last such rule
# is actually used.
#
# For example, the two statements shown here have exactly the same effect,
# because the first REPLICATE_DO_DB rule in the first statement is ignored:
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_DO_DB = (db1, db2), REPLICATE_DO_DB = (db3, db4);
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_DO_DB = (db3, db4);
#
# CAUTION:
#
# 		This behavior differs from that of the --replicate-* filter options
# 		where specifying the same option multiple times causes the
# 		creation of multiple filter rules.
#
# Names of tables and database not containing any special characters need
# not be quoted.
#
# Values used with REPLICATION_WILD_TABLE and REPLICATION_WILD_IGNORE_TABLE
# are string expressions, possibly containing (special) wildard characters,
# and so must be quoted.
#
# This is shown in the following example statements:
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_WILD_DO_TABLE = ('db1.old%');
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_WILD_IGNORE_TABLE = ('db1.new%', 'db2.new%');
#
# Values used with REPLICATE_REWRITE_DB represents pairs of database names;
#
# Each such value must be enclosed in parentheses.
#
# The following statement rewrites statements occurring on database db1
# on the master to database db2 on the slave:
#
# 		CHANGE REPLICATION FILTER REPLICATE_REWRITE_DB = ((db1, db2));
#
# The statement just shown contains two sets of parentheses, one enclosing the pair
# of database names, and the other enclosing the entire list.
#
# This is perhaps more easily seen in the following example, which creates two
# rewrite-db rules, one rewriting database dbA to dbB, and one rewriting database dbC to dbD:
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_REWRITE_DB = ((dbA, dbB), (dbC, dbD));
#
# The CHANGE_REPLICATION_FILTER statement replaces replication filtering rules only
# for the filter types and replication channels affected by the statement, and leaves
# other rules and channels unchanged.
#
# If you want to unset all filters of a given type, set the filter's value to an
# explicitly empty list, as shown in this example, which removes all existing
# REPLICATE_DO_DB and REPLICATE_IGNORE_DB rules:
#
# 		CHANGE REPLICATION FILTER
# 			REPLICATE_DO_DB = (), REPLICATE_IGNORE_DB = ();
#
# Setting a filter to empty in this way removes all existing rules, does not create
# any new ones, and does not restore any rules set at mysqld startup using --replicate-*
# options on the command line or in the configuration file.
#
# The RESET_SLAVE_ALL statement removes channel specific replication filters that were
# set on channels deleted by the statement.
#
# When the deleted channel or channels are recreated, any global replication filters
# specified for the slave are copied to them, and no channel specific replication
# filters are applied.
#
# For more information, see SECTION 17.2.5, "HOW SERVERS EVALUATE REPLICATION FILTERING RULES"
#
# 13.4.2.3 MASTER_POS_WAIT() SYNTAX
#
# 		SELECT MASTER_POS_WAIT('master_log_file', master_log_pos [, timeout][, channel])
#
# This is actually a function, not a statement.
#
# It is used to ensure that the slave has read and executed events up to a given position
# in the master's binary log.
#
# See SECTION 12.23, "MISCELLANEOUS FUNCTIONS", for a full description.
#
# 13.4.2.4 RESET SLAVE SYNTAX
#
# 		RESET SLAVE [ALL] [channel_option]
#
# 		channel_option:
# 			FOR CHANNEL channel
#
# RESET_SLAVE makes the slave forget its replication channel position in the master's binary log.
#
# This statement is meant to be used for a clean start:
#
# 		it clears the master info and relay log info repositories, deletes all the relay
# 		log files, and starts a new relay log file.
#
# It also resets to 0 the applicaiton delay specified with the MASTER_DELAY option to
# CHANGE MASTER TO RESET_SLAVE does not change the values of gtid_executed or gtid_purged.
#
# NOTE:
#
# 		All relay log files are deleted, even if they have not been completely executed by the
# 		slave SQL thread.
#
# 		(This is a condition likely to exist on a replication slave if you have issued
# 		a STOP_SLAVE statement or if hte slave is highly loaded)
#
# To use RESET_SLAVE, the slave replication threads must be stopped, so on a running slave
# use STOP_SLAVE before issuing RESET_SLAVE
#
# To use RESET_SLAVE on a Group Replication group member, the member status must be 
# OFFLINE, meaning that the plugin is loaded but the member does not currently belong
# to any group.
#
# A group member can be taken offline by using a STOP_GROUP_REPLICATION statement.
#
# The optional FOR CHANNEL channel clause enables you to name which replication channel
# the statement applies to.
#
# Providing a FOR CHANNEL channel clause applies the RESET SLAVE statement to a specific
# replication channel.
#
# Combining a FOR CHANNEL channel clause with the ALL option deletes the specified
# channel.
#
# If no channel is named and no extra channels exist, the statement applies to the
# default channel.
#
# Issuing a RESET_SLAVE_ALL statement without a FOR CHANNEL channel clause when
# multiple replication channels exist deletes all replication channels and recreates
# only the default channel.
#
# See SECTION 17.2.3, "REPLICATION CHANNELS" for more information.
#
# RESET_SLAVE does not change any replication connection parameters such as
# master host, master port, master user or master password.
#
# 		) From MySQL 8.0.13, when master_info_repository=TABLE is set on the server
# 			(which is the default from MySQL 8.0), replication connection parameters
# 			are preserved in the crash-safe InnoDB table mysql.slave_master_info as
# 			part of the RESET_SLAVE operation.
#
# 			They are also retained in memory.
#
# 			In the event of a server crash or deliberate restart after issuing
# 			RESET_SLAVE but before issuing START_SLAVE, the replication connection
# 			parameters are retrieved from the table and reused for the new connection.
#
# 		) When master_info_repository=FILE is set on the server, replication connection
# 			parameters are only retained in memory.
#
# 			If the slave mysqld is restarted immediately after issuing RESET_SLAVE due
# 			to a server crash or deliberate restart, the connection parameters are lost.
#
# 			In that case, you must issue a CHANGE_MASTER_TO statement after the server
# 			start to respecify the connection parameters before issuing START_SLAVE
#
# If you want to reset the connection parameters intentionally, you need to use RESET_SLAVE_ALL,
# which clears the connection parameters.
#
# In that case, you must issue a CHANGE_MASTER_TO statement after the server start to
# specify the new connection parameters.
#
# RESET SLAVE ALL clears the IGNORE_SERVER_IDS list set by CHANGE_MASTER_TO
#
# RESET_SLAVE does not change any replication filter settings (such as --replicate-ignore-table)
# for channels affected by the statement.
#
# However, RESET SLAVE ALL removes the replication filters that were set on the channels
# deleted by the statement.
#
# When the deleted channel or channels are recreated, any global replication filters
# specified for the slave are copied to them, and no channel specific replication filters
# are applied.
#
# For more information, see SECTION 17.2.5.4, "REPLICATION CHANNEL BASED FILTERS"
#
# RESET SLAVE causes an implicit commit of an ongoing transaction.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# If the slave SQL thread was in the middle of replicating temporary tables when it was
# stopped, and RESET_SLAVE is issued, these replicated temporary tables are deleted on
# the slave.
#
# RESET SLAVE does not reset the heartbeat period (Slave_heartbeat_period) or SSL_VERIFY_SERVER_CERT
#
# NOTE:
#
# 		When used on an NDB Cluster replication slave SQL node, RESET SLAVE clears the mysql.ndb_apply_status
# 		table.
#
# 		You should keep in mind when using this statement that ndb_apply_status uses the NDB storage engine
# 		and so is shared by all SQL nodes attached to the slave cluster.
#
# 		You can override this behavior by issuing SET GLOBAL @@ndb_clear_apply_status=OFF prior to executing
# 		RESET SLAVE, which keeps the slave from purging the ndb_apply_status table in such cases.
#
# 13.4.2.5 SET GLOBAL SQL_SLAVE_SKIP_COUNTER_SYNTAX
#
# 		SET GLOBAL sql_slave_skip_counter = N
#
# This statement skips the next N events from the master.
#
# This is useful for recovering from replication stops caused by a statement.
#
# When using this statement, it is important to understand that the binary log is actually
# organized as a sequence of groups known as event groups.
#
# Each event group consists of a sequence of events.
#
# 		) For transactional tables, an event group corresponds to a transaction
#
# 		) For nontransactional tables, an event group corresponds to a single SQL statement
#
# NOTE:
#
# 		A single transaction can contain changes to both transactional and nontransactional tables
#
# When you use SET_GLOBAL_sql_slave_skip_counter to skip events and the result is in the middle
# of a group, the slave continues to skip events until it reaches the end of the group.
#
# Execution then starts with the next event group
#
# 13.4.2.6 START SLAVE SYNTAX
#
# 		START SLAVE [thread_types] [until_option] [connection_options] [channel_option]
#
# 		thread_types:
# 			[thread_type [, thread_type] ---]
#
# 		thread_type:
# 			IO_THREAD | SQL_THREAD
#
# 		until_option:
# 			UNTIL { 	{SQL_BEFORE_GTIDS | SQL_AFTER_GTIDS} = gtid_set
# 					|  MASTER_LOG_FILE = 'log_name', MASTER_LOG_POS = log_pos
# 					|  RELAY_LOG_FILE = 'log_name', RELAY_LOG_POS = log_pos
# 					|  SQL_AFTER_MTS_GAPS }
#
# 		connection_options:
# 			[USER='user_name'] [PASSWORD='user_pass'] [DEFAULT_AUTH='plugin_name'] [PLUGIN_DIR='plugin_dir']
#
# 		channel_option:
# 			FOR CHANNEL channel
#
# 		gtid_set:
# 			uuid_set [, uuid_set] ---
# 			| ''
#
# 		uuid_set:
# 			uuid:interval[:interval]---
#
# 		uuid:
# 			hhhhhhhh-hhhh-hhhh-hhhh-hhhhhhhh
#
# 		h:
# 			[0-9,A-F]
#
# 		interval:
# 			n[-n]
# 		
# 			(n >= 1)
#
# START_SLAVE with no thread_type options starts both of the slave threads.
#
# The I/O thread reads events from the master server and stores them in the relay
# log.
#
# The SQL thread reads events from the relay log and executes them.
#
# START_SLAVE requires the REPLICATION_SLAVE_ADMIN or SUPER privilege.
#
# If START_SLAVE succeeds in starting the slave threads, it returns without any
# error.
#
# However, even in that case, it might be that the slave threads start and then
# later stop (for example, because they do not manage to connect to the master or read its
# binary log, or some other problem)
#
# START_SLAVE does not warn you about this.
#
# You must check the slave's error log for error messages generated by the slave threads,
# or check that they are running satisfactorally with SHOW_SLAVE_STATUS
#
# START SLAVE causes an implicit commit of an ongoing transaction.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# gtid_next must be set to AUTOMATIC before issuing this statement.
#
# The optional FOR CHANNEL channel clause enables you to name which replication
# channel the statement applies to.
#
# Providing a FOR CHANNEL channel clause applies the START SLAVE statement to a 
# specific replication channel.
#
# If no clause is named and no extra channels exist, the statement applies to the
# default channel.
#
# If a START SLAVE statement does not have a channel defined when using multiple
# channels, this statement starts the specified threads for all channels.
#
# This statement is disallowed for the group_replication_recovery channel
#
# See SECTION 17.2.3, "REPLICATION CHANNELS" for more information
#
# MySQL supports pluggable user-password authentication with START SLAVE
# with the USER, PASSWORD, DEFAULT_AUTH and PLUGIN_DIR options, as described
# in the following list:
#
# 		) USER: User name. Cannot be set to an empty or null string, or left unset if PASSWORD is used
#
# 		) PASSWORD: Password
#
# 		) DEFAULT_AUTH: Name of plugin; default is MySQL native authentication
#
# 		) PLUGIN_DIR: Location of plugin
#
# You cannot use the SQL_THREAD option when specifying any of USER, PASSWORD,
# DEFAULT_AUTH or PLUGIN_DIR, unless the IO_THREAD option is also provided.
#
# See SECTION 6.3.10, "PLUGGABLE AUTHENTICATION" for more information
#
# If an insecure connection is used with any of these options, the server issues the warning:
#
# 		SENDING PASSWORDS IN PLAIN TEXT WITHOUT SSL/TLS IS EXTREMELY INSECURE
#
# START_SLAVE_---_UNTIL supports two additional options for use with global transaction
# identifiers (GTIDs) (see SECTION 17.1.3, "REPLICATION WITH GLOBAL TRANSACTION IDENTIFIERS")
#
# Each of these takes a set of one or more global transaction identifiers gtid_set
# as an argument (see GTID Sets, for more information)
#
# When no thread_type is specified, START SLAVE UNTIL SQL_BEFORE_GTIDS causes the slave
# SQL thread to process transactions until it has reached the first transaction whose
# GTID is listed in the gtid_set.
#
# START SLAVE UNTIL SQL_AFTER_GTIDS causes the slave threads to process all transactions
# until the last transaction in the gtid_set has been processed by both threads.
#
# In other words, START SLAVE UNTIL SQL_BEFORE_GTIDS causes the slave SQL thread to process
# all transactions occurring before the first GTID in the gtid_set is reached, and 
# START SLAVE UNTIL SQL_AFTER_GTIDS causes the slave threads to handle all transactions,
# including those whose GTIDs are found in gtid_set, until each has encountered a transaction
# whose GTID is not part of the set.
#
# SQL_BEFORE_GTIDS and SQL_AFTER_GTIDS each support the SQL_THREAD and IO_THREAD options,
# although using IO_THREAD with them currently has no effect.
#
# For example, START SLAVE SQL THREAD UNTIL SQL_BEFORE_GTIDS = <value> causes the salve
# SQL thread to process all transactions originating from the master whose server_uuid is
# <value> until it encounters the transaction having <sequence number>.
#
# It then stops without processing this transaction.
#
# In other words, all transactions up to and including the transaction with sequence
# number 10 are processed.
#
# Executing START SLAVE SQL_THREAD UNTIL SQL_AFTER_GTIDS = <Value>:<range>
#
# on the other hand, would cause the salve SQL thread to obtain all transactions just
# mentioned from the master, including all of the transactions having the sequence
# numbers of the range - and then stop without processing any additional transactions;
#
# that is, the transaction having sequence number equal to the last one in the range,
# would be the last transaction fetched by the slave SQL thread.
#
# When using a multithreaded slave with slave_preserve_commit_order=0 set, there is a 
# chance of gaps in the sequence of transactions that have been executed from the
# relay log in the following cases:
#
# 		) Killing the coordinator thread
#
# 		) After an error occurs in the applier threads
#
# 		) mysqld shuts down unexpectedly
#
# Use the START_SLAVE_UNTIL_SQL_AFTER_MTS_GAPS statement to cause a multithreaded
# slave's worker threads to only run until no more gaps are found in the relay log,
# and then to stop.
#
# This statement can take an SQL_THREAD option, but the effects of the statement
# remain unchanged.
#
# It has no effect on the slave I/O thread (and cannot be used with the IO_THREAD option)
#
# Issuing START_SLAVE on a multithreaded slave with gaps in the sequence of transactions
# executed from the relay log generates a warning.
#
# In such a situation, the solution is to use START_SLAVE_UNTIL_SQL_AFTER_MTS_GAPS,
# then issue RESET_SLAVE to remove any remaining relay logs.
#
# See SECTION 17.4.1.34, "REPLICATION AND TRANSACTION INCONSISTENCIES" for more information.
#
# To change a failed multithreaded slave to single-threaded mode, you can issue the following
# series of statements, in the order shown:
#
# 		START SLAVE UNTIL SQL_AFTER_MTS_GAPS;
#
# 		SET @@GLOBAL.slave_parallel_workers = 0;
#
# 		START SLAVE SQL_THREAD;
#
# NOTE:
#
# 		It is possible to view the entire text of a running START SLAVE --- statement,
# 		including any USER or PASSWORD values used, in the output of SHOW PROCESSLIST.
#
# 		This is also true for the text of a running CHANGE_MASTER_TO statement, including
# 		any values it employs for MASTER_USER or MASTER_PASSWORD
#
# START_SLAVE sends an acknowledgement to the user after both the I/O thread and the SQL
# thread have started.
#
# However, the I/O thread may not yet have connected.
#
# For this reason, a successful START_SLAVE causes SHOW_SLAVE_STATUS to show Slave_SQL_Running=Yes,
# but it does not guarantee that Slave_IO_Running=Yes (because Slave_IO_Running=Yes only if the
# I/O thread is running and connected)
#
# For more information, see SECTION 13.7.6.34, "SHOW SLAVE STATUS SYNTAX", and SECTION 17.1.7.1, "CHECKING REPLICATION STATUS"
#
# You can add IO_THREAD and SQL_THREAD options to the statement to name which of the threads to start.
#
# The SQL_THREAD option is disallowed when specifying any of USER, PASSWORD, DEFAULT_AUTH or
# PLUGIN_DIR, unless the IO_THREAD option is also provided.
#
# An UNTIL clause (until_option, in the preceding grammar) may be added to specify that the slave
# should start and run until the SQL thread reaches a given point in the master binary log,
# specified by the MASTER_LOG_POS and MASTER_LOG_FILE options, or a given point in the slave
# relay log, indicated with the RELAY_LOG_POS and RELAY_LOG_FILE options.
#
# When the SQL thread reaches the point specified, it stops.
#
# If the SQL_THREAD option is specified in the statement, it starts only the SQL thread
#
# Otherwise, it starts both slave threads.
#
# If the SQL thread is running, the UNTIL clause is ignored and a warning is issued.
#
# You cannot use an UNTIL clause with the IO_THREAD option
#
# It is also possible with START SLAVE UNTIL to specify a stop point relative to a given GTID
# or set of GTIDs using one of the options SQL_BEFORE_GTIDS or SQL_AFTER_GTIDS, as explained
# previously here.
#
# When using one of these options, you can specify SQL_THREAD, IO_THREAD - both of these -
# or neither of them.
#
# If you specify only SQL_THREAD, then only the slave SQL thread is affected by the statement;
#
# if only IO_THREAD is used, then only the slave I/O is affected
#
# If both SQL_THREAD and IO_THREAD are used, or if neither of them is used, then both the
# SQL and I/O threads are affected by the statement.
#
# For an UNTIL clause, you must specify any of the following:
#
# 		) Both a log file name and a position in that file
#
# 		) Either of SQL_BEFORE_GTIDS or SQL_AFTER_GTIDS
#
# 		) SQL_AFTER_MTS_GAPS
#
# Do not mix master and relay log options. Do not mix log file options with GTID options.
#
# The UNTIL clause is not supported for multithreaded slaves except when also using
# SQL_AFTER_MTS_GAPS
#
# If UNTIL is used on a multithreaded slave without SQL_AFTER_MTS_GAPS, the slave operates
# in single-threaded (sequential) mode for replication until the point specified by
# the UNTIL clause is reached.
#
# Any UNTIL condition is reset by a subsequent STOP_SLAVE statement, a START_SLAVE statement
# that includes no UNTIL clause, or a server restart.
#
# When specifying a log file and position, you can use the IO_THREAD option with START SLAVE --- UNTIL
# even though only the SQL thread is affected by this statement.
#
# The IO_THREAD option is ignored in such cases.
#
# The preceding restriction does not apply when using one of the GTID options
# (SQL_BEFORE_GTIDS and SQL_AFTER_GTIDS); the GTID options support both SQL_THREAD
# and IO_THREAD, as explained previously in this section.
#
# The UNTIL clause can be useful for debugging replication, or to cause replication
# to proceed until just before the point where you want to avoid having the slave
# replicate an event.
#
# For example, if an unwise DROP_TABLE statement was executed on the master, you acn
# use UNTIL to tell the slave to execute up to that point but no farther.
#
# To find what the event is, use mysqlbinlog with the master binary log or slave relay
# log, or by using a SHOW_BINLOG_EVENTS statement.
#
# If you are using UNTIL to have the slave process replicated queries in sections,
# it is recommended that you start the slave with the --skip-slave-start option to prevent
# the SQL thread from running when the slave server starts.
#
# It is probably best to use this option in an option file rather than on the
# command line, so that an unexpected server restart does not cause it to be forgotten.
#
# The SHOW_SLAVE_STATUS statement includes output fields that display the current values
# of the UNTIL condition.
#
# In very old versions of MySQL (before 4.0.5), this statement was called SLAVE START.
# That syntax now produces an error.
#
# 13.4.2.7 STOP SLAVE SYNTAX
#
# 		STOP SLAVE [thread_types]
#
# 		thread_types:
# 			[thread_type [, thread_type] ---]
#
# 		thread_type: IO_THREAD | SQL_THREAD
#
# 		channel_option:
# 			FOR CHANNEL channel
#
# Stops the slave threads.
#
# STOP_SLAVE requires the REPLICATION_SLAVE_ADMIN or SUPER privilege.
#
# Recommended best practice is to execute STOP SLAVE on the slave before
# stopping the slave server (see SECTION 5.1.17, "THE SERVER SHUTDOWN PROCESS", for more information)
#
# When using the row-based logging format:
#
# 	You should execute STOP SLAVE or STOP SLAVE SQL_THREAD on the slave prior to shutting down
# 	the slave server if you are replicating any tables that use a nontransactional storage engine
# 	(see the Note later in this section)
#
# Like START_SLAVE, this statement may be used with the IO_THREAD and SQL_THREAD options to
# name the thread or threads to be stopped.
#
# STOP SLAVE causes an implicit commit of an ongoing transaction.
#
# See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# gtid_next must be set to AUTOMATIC before issuing this statement.
#
# You can control how long STOP SLAVE waits before timing out by setting the rpl_stop_slave_timeout
# system variable.
#
# This can be used to avoid deadlocks between STOP SLAVE and other slave SQL statements using
# different client connections to the slave.
#
# When the timeout value is reached, the issuing client returns an error message and
# stops waiting, but the STOP SLAVE intstruction remains in effect.
#
# Once the slave threads are no longer busy, the STOP SLAVE statement is executed and 
# the slave stops.
#
# Some CHANGE MASTER TO statements are allowed while the slave is running, depending on
# the states of the slave SQL and I/O threads.
#
# However, using STOP SLAVE prior to executing CHANGE MASTER TO in such cases is still
# supported.
#
# See SECTION 13.4.2.1,"CHANGE MASTER TO SYNTAX", and SECTION 17.3.8, "SWITCHING MASTERS DURING FAILOVER",
# for more information.
#
# The optional FOR CHANNEL channel clause enables you to name which replication channel the statement
# applies to.
#
# Providing a FOR CHANNEL channel clause applies the STOP SLAVE statement to a specific replication
# channel.
#
# If no channel is named and no extra channels exist, the statement applies to the default channel.
#
# If a STOP SLAVE statement does not name a channel when using multiple channels, this statement stops the
# specified threads for all channels..
#
# This statement cannot be used with the group_replication_recovery channel.
#
# See SECTION 17.2.3, "REPLICATION CHANNELS" for more information.
#
# When using statement-based replication:
#
# 		changing the master while it has open temporary tables is potentially unsafe.
#
# 		This is one of the reasons why statement-based replication of temporary tables
# 		is not recommended.
#
# 		You can find out whether there are any temporary tables on the slave by checking
# 		the value of Slave_open_temp_tables; when using statement-based replication, this value
# 		should be 0 before executing CHANGE MASTER TO.
#
# If there are any temporary tables open on the slave, issuing a CHANGE MASTER TO statement
# after issuing a STOP SLAVE causes an ER_WARN_OPEN_TEMP_TABLES_MUST_BE_ZERO warning.
#
# When using a multithreaded slave (slave_parallel_workers is a nonzero value), any gaps in the
# sequence of transactions executed from the relay log are closed as part of stopping the
# worker threads.
#
# If the slave is stopped unexpectedly (for example due to an error in a worker thread,
# or another thread issuing KILL), while a STOP_SLAVE statement is executing, the sequence
# of executed transactions from the relay log may become inconsistent.
#
# See SECTION 17.4.1.34, "REPLICATION AND TRANSACTION INCONSISTENCIES" for more information.
#
# If the current replication event group has modified one or more nontransactional tables,
# STOP SLAVE waits for up to 60 seconds for the event grop to complete, unless you issue
# a KILL_QUERY or KILL_CONNECTION statement for the slave SQL thread.
#
# If the event group remains incomplete after the timeout, an error message is logged.
#
# 13.4.3 SQL STATEMENTS FOR CONTROLLING GROUP REPLICATION
#
# 13.4.3.1 START GROUP_REPLICATION SYNTAX
# 13.4.3.2 STOP GROUP_REPLICATION SYNTAX
#
# 13.4.3.3 FUNCTION WHICH CONFIGURES GROUP REPLICATION PRIMARY
# 13.4.3.4 FUNCTIONS WHICH CONFIGURE THE GROUP REPLICATION MODE
#
# 13.4.3.5 FUNCTIONS TO INSPECT AND CONFIGURE THE MAXIMUM CONSENSUS INSTANCES OF A GROUP
#
# This section provides information about the statements used for controlling group replication.
#
# 13.4.3.1 START GROUP_REPLICATION SYNTAX
#
# 		START GROUP_REPLICATION
#
# Starts group replication.
#
# This statement requires the GROUP_REPLICATION_ADMIN or SUPER privilege.
#
# If super_read_only=ON and the member should join as a primary, super_read_only
# is set to OFF once Group Replication successfully starts.
#
# 13.4.3.2 STOP GROUP_REPLICATION SYNTAX
#
# 		STOP GROUP_REPLICATION
#
# Stops Group Replication.
#
# This statement requires the GROUP_REPLICATION_ADMIN or SUPER privilege.
#
# As soon as you issue STOP_GROUP_REPLICATION the member is set to super_read_only=ON,
# which ensures that no writes can be made to the member while Group Replication stops.
#
# Any other replication channels running on the member are also stopped.
#
# 		WARNING:
#
# 			Use this statement with extreme caution because it removes the server
# 			instance from the group, meaning it is no longer protected by Group
# 			Replication's consistency guarantee mechanisms.
#
# 			To be completely safe, ensure that your applications can no longer
# 			connect to the instance before issuing this statement to avoid
# 			any chance of stale reads.
#
# 13.4.3.3 FUNCTION WHICH CONFIGURES GROUP REPLICATION PRIMARY
#
# The following funciton enables you to configure which member of a single-primary
# replication group is the primary.
#
# 		) group_replication_set_as_primary()
#
# 			Appoints a specific member of the group as the new primary,
# 			overriding any election process.
#
# 			Pass in member_uuid which is the server_uuid of the member that you
# 			want to become the new primary.
#
# 			Must be issued on a member of a replication group running in single-primary
# 			mode.
#
# 			Syntax:
#
# 				STRING group_replication_set_as_primary(member_uuid)
#
# 			Return value:
#
# 			A string containing the result of the operation, for example whether it was 
# 			successful or not.
#
# 			Example:
#
# 				SELECT group_replication_set_as_primary(member_uuid)
#
# 			For more information, see SECTION 18.4.2.1, "CHANGING A GROUP'S PRIMARY MEMBER"
#
# 13.4.3.4 FUNCTIONS WHICH CONFIGURE THE GROUP REPLICATION MODE
#
# The following functions enable you to control the mode which a replication group is running in,
# either single-primary or multi-primary mode.
#
# 		) group_replication_switch_to_single_primary_mode()
#
# 			Changes a group running in multi-primary mode to single-primary mode, without the need to stop
# 			Group Replication.
#
# 			Must be issued on a member of a replication group running in multi-primary mode.
#
# 			Syntax:
#
# 				STRING group_replication_switch_to_single_primary_mode([str])
#
# 			Arguments:
#
# 				str: A string containing the UUID of a member of the group which should become the
# 						new single primary.
#
# 						Other members of the group become secondaries.
#
# 			Return value:
#
# 			A string containing the result of the operation, for example whether it was successful or not.
#
# 			Example:
#
# 				SELECT group_replication_switch_to_single_primary_mode(member_uuid);
#
# 			For more information, see SECTION 18.4.2.2, "CHANGING A GROUP'S MODE"
#
# 		) group_replication_switch_to_multi_primary_mode()
#
# 			Changes a group running in single-primary mode to multi-primary mode.
#
# 			Must be issued on a member of a replication group running in single-primary mode.
#
# 			Syntax:
#
# 				STRING group_replication_switch_to_multi_primary_mode()
#
# 			This function has no parameters
#
# 			Return value:
#
# 			A string containing the result of the operation, for example whether it was successful or not.
#
# 			Example:
#
# 				SELECT group_replication_switch_to_multi_primary_mode()
#
# 			All members which belong to the group becomes primaries.
#
# 			For more information, see SECTION 18.4.2.2, "CHANGING A GROUP'S MODE"
#
# 13.4.3.5 FUNCTIONS TO INSPECT AND CONFIGURE THE MAXIMUM CONSENSUS INSTANCES OF A GROUP
#
# The following functions enable you to inspect and configure the maximum number of consensus
# instances that a group can execute in parallel.
#
# 		) group_replication_get_write_concurrency()
#
# 			Check the maximum number of consensus instances that a group can execute in parallel.
#
# 			Syntax:
#
# 				STRING group_replication_get_write_concurrency()
#
# 			This function has no parameters.
#
# 			Return value:
#
# 			Any resulting error as a string
#
# 			Example:
#
# 				SELECT group_replication_get_write_concurrency()
#
# 			For more information, see SECTION 18.4.2.3, "USING GROUP REPLICATION GROUP WRITE CONSENSUS"
#
# 		) group_replication_set_write_concurrency()
#
# 			Configures the maximum number of consensus instances that a group can execute in parallel.
#
# 			Syntax:
#
# 				STRING group_replication_set_write_concurrency(instances)
#
# 			Arguments:
#
# 				) members: Sets the maximum number of consensus instances that a group can execute
# 								in parallel.
#
# 								Default value is 10, valid values are integers in the range of 10 to 200
#
# 			Return value:
#
# 			Any resulting error as a string.
#
# 			Example:
#
# 				SELECT group_replication_set_write_concurrency(instances);
#
# 			For more information, see SECTION 18.4.2.3, "USING GROUP REPLICATION GROUP WRITE CONSENSUS"
#
# 13.5 PREPARED SQL STATEMENT SYNTAX
#
# 13.5.1 PREPARE SYNTAX
# 13.5.2 EXECUTE SYNTAX
# 13.5.3 DEALLOCATE PREPARE SYNTAX
#
# MySQL 8.0 provides support for server-side prepared statements.
#
# This support takes advantage of the efficient client/server binary protocol.
#
# Using prepared statements with placeholders for parameter values has the following benefits:
#
# 		) Less overhead for parsing the statement each time it is executed.
#
# 			Typically, database applications process large volumes of almost-identical
# 			statements, with only changes to literal or variables values in clauses such as
# 			WHERE for queries and deletes, SET for updates, and VALUES for inserts.
#
# 		) Protection against SQL injection attacks. The parameter values can contain unescaped
# 			SQL quote and delimiter characters.
#
# PREPARED STATEMENTS IN APPLICATION PROGRAMS
#
# You can use server-side prepared statements through client programming interfaces, including
# the MySQL C API CLIENT LIBRARY or MySQL CONNECTOR/C for C programs, MySQL Connector/J for
# java programs, and MySQL Connector/NET for programs using .NET tech.
#
# For example, the C API provides a set of function calls that make up its prepared statement
# API.
#
# See SECTION 28.7.8, "C API PREPARED STATEMENTS"
#
# Other language interfaces can provide support for prepared statements that use the binary
# protocol by linking in the C client library, one example being the mysqli extension, available
# in PHP 5.0 and later.
#
# PREPARED STATEMENTS IN SQL SCRIPTS
#
# An alternative SQL interface to prepared statements is available.
#
# This interface is not as efficient as using the binary protocol through a prepared
# statement API, but requires no programming because it is available directly at the SQL level:
#
# 		) You can use it when no programming interface is available to you
#
# 		) You can use it from any program that can send SQL statements to the server to be executed,
# 			such as the mysql client program.
#
# 		) You can use it even if the client is using an old version of the client library, as long
# 			as you connect to a server running MySQL 4.1 or higher
#
# SQL syntax for prepared statements is intended to be used for situations such as these:
#
# 		) To test how prepared statements work in your application before coding it
#
# 		) To use prepared statements when you do not have access to a programming API that supports them
#
# 		) To interactively troubleshoot application issues with prepared statements.
#
# 		) To create a test case that reproduces a problem with prepared statements, so that you can file a bug report
#
# PREPARE, EXECUTE, AND DEALLOCATE PREPARE STATEMENTS
#
# SQL syntax for prepared statements is based on three SQL statements:
#
# 		) PREPARE prepares a statement for execution (see SECTION 13.5.1, "PREPARE SYNTAX")
#
# 		) EXECUTE executes a prepared statement (see SECTION 13.5.2, "EXECUTE SYNTAX")
#
# 		) DEALLOCATE_PREPARE releases a prepared statement (see SECTION 13.5.3, "DEALLOCATE PREPARE SYNTAX")
#
# The following examples show two equivalent ways of preparing a statement that computes the 
# hypotenuse of a triangle given the lengths of the two sides.
#
# The first example shows how to create a prepared statement by using a string literal to supply
# the text of the statement:
#
# 		PREPARE stmt1 FROM 'SELECT SQRT(POW(?,2) + POW(?,2)) AS hypotenuse';
# 		SET @a = 3;
# 		SET @b = 4;
# 		EXECUTE stmt1 USING @a, @b;
# 		+---------------------+
# 		| hypotenuse 		    |
# 		+---------------------+
# 		| 		 5 				 |
# 		+---------------------+
# 		DEALLOCATE PREPARE stmt1;
#
# The second example is similar, but supplies the text of the statement as a user variable:
#
# 		SET @s = 'SELECT SQRT(POW(?,2) + POW(?,2)) AS hypotenuse';
# 		PREPARE stmt2 FFROM @s;
# 		SET @a = 6;
# 		SET @b = 8;
# 		EXECUTE stmt2 USING @a, @b;
# 		+------------------+
# 		| hypotenuse 		 |
# 		+------------------+
# 		| 		10 			 |
# 		+------------------+
# 		DEALLOCATE PREPARE stmt2;
#
# Here is an additional example that demonstrates how to choose the table on which
# to perform a query at runtime, by storing the name of the table as a user variable:
#
# 		USE test;
# 		CREATE TABLE t1 (a INT NOT NULL);
# 		INSERT INTO t1 VALUES (4), (8), (11), (32), (80);
#
# 		SET @table = 't1';
# 		SET @s = CONCAT('SELECT * FROM ', @table);
# 
# 		PREPARE stmt3 FROM @s;
# 		EXECUTE stmt3;
# 		+------+
# 		| a 	 |
# 		+------+
# 		| 4 	 |
# 		| 8 	 |
# 		| 11   |
# 		| 32 	 |
# 		| 80   |
# 		+------+
#
# 		DEALLOCATE PREPARE stmt3;
#
# A prepared statement is specific to the session in which it was created.
#
# If you terminate a session without deallocating a previously prepared statement,
# the server deallocates it automatically.
#
# A prepared statement is also global to the session. If you create a prepared statement
# within a stored routine, it is not deallocated when the stored routine ends.
#
# To guard against too many prepared statements being created simultaneously, set the
# max_prepared_stmt_count system variable.
#
# To prevent the use of prepared statements, set the value to 0.
#
# SQL SYNTAX ALLOWED IN PREPARED STATEMENTS
#
# The following SQL statements can be used as prepared statements:
#
# 		ALTER TABLE
# 		ALTER USER
# 		ANALYZE TABLE
#
# 		CACHE INDEX
# 		CALL
# 		CHANGE MASTER
#
# 		CHECKSUM {TABLE | TABLES}
# 		COMMIT
# 		{CREATE | DROP} INDEX
#
# 		{CREATE | RENAME | DROP} DATABASE
# 		{CREATE | DROP} TABLE
# 		{CREATE | RENAME | DROP} USER
#
# 		{CREATE | DROP} VIEW
# 		DELETE
# 		DO
#
# 		FLUSH {TABLE | TABLES | TABLES WITH READ LOCK | HOSTS | PRIVILEGES
# 			| LOGS | STATUS | MASTER | SLAVE | USER_RESOURCES}
# 		GRANT
# 		INSERT
#
# 		INSTALL PLUGIN
# 		KILL
# 		LOAD INDEX INTO CACHE
#
# 		OPTIMIZE TABLE
# 		RENAME TABLE
# 		REPAIR TABLE
#
#  	REPLACE
# 		RESET {MASTER | SLAVE}
# 		REVOKE
#
# 		SELECT
# 		SET
# 		SHOW {WARNINGS | ERRORS}
#
# 		SHOW BINLOG EVENTS
# 		SHOW CREATE {PROCEDURE | FUNCTION | EVENT | TABLE | VIEW}
# 		SHOW {MASTER | BINARY} LOGS
# 
# 		SHOW {MASTER | SLAVE} STATUS
# 		SLAVE {START | STOP}
# 		TRUNCATE TABLE
#
# 		UNINSTALL PLUGIN
# 		UPDATE
#
# For compliance with the SQL standard, which states that diagnostics statements are not preparable,
# MySQL does not support the following as prepared statements:
#
# 		) SHOW WARNINGS, SHOW COUNT(*) WARNINGS
#
# 		) SHOW ERRORS, SHOW COUNT(*) ERRORS
#
# 		) Statements containing any reference to the warning_count or error_count system variable.
#
# Other statements are not supported in MySQL 8.0
#
# Generally, statements not permitted in SQL preapred statements are also not permitted in stored
# programs.
#
# Exceptions are noted in SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# Metadata changes to tables or views referred to by prepared statements are detected
# and cause automatic repreparation of the statement when it is next executed.
#
# For more information, see SECTION 8.10.3, "CACHING OF PREPARED STATEMENTS AND STORED PROGRAMS"
#
# Placeholders can be used for the arguments of the LIMIT clause when using prepared statements.
#
# See SECTION 13.2.10, "SELECT SYNTAX"
#
# In prepared CALL statements used with PREPARE and EXECUTE, placeholder support for OUT and
# INOUT parameters is available beginning with MySQL 8.0
#
# See SECTION 13.2.1, "CALL SYNTAX", for an example and a workaround for earlier versions.
#
# Placeholders can be used for IN parameters regardless of version.
#
# SQL syntax for prepared statements cannot be used in nested fashion. That is, a statement
# passed to PREPARE cannot itself be a PREPARE, EXECUTE or DEALLOCATE_PREPARE statement.
#
# SQL syntax for prepared statements is distinct from using prepared statement API calls.
#
# For example, you cannot use the mysql_stmt_prepare() C API function to prepare a
# PREPARE, EXECUTE or DEALLOCATE_PREPARE statement.
#
# SQL syntax for prepared statements can be used within stored procedures, but not
# in stored functions or triggers.
#
# However, a cursor cannot be used for a dynamic statement that is prepared and
# executed with PREPARE and EXECUTE.
#
# The statement for a cursor is checked at cursor creation time, so the statement
# cannot be dynamic.
#
# SQL syntax for prepared statements does not support multi-statements (that is,
# multiple statements within a single string separated by ; characters)
#
# To write C programs that use the CALL SQL statement to execute stored procedures
# that contain prepared statements, the CLIENT_MULTI_RESULTS flag must be enabled.
#
# This is because each CALL returns a result to indicate the call status, in addition
# to any result sets that might be returned by statements executed within the procedure.
#
# CLIENT_MULTI_RESULTS can be enabled when you call mysql_real_connect(), either
# explicitly by passing the CLIENT_MULTI_RESULTS flag itself, or implicitly by
# passing CLIENT_MULTI_STATEMENTS (which also enables CLIENT_MULTI_RESULTS)
#
# For additional information, see SECTION 13.2.1, "CALL SYNTAX"
#
# 13.5.1 PREPARE SYNTAX
#
# 		PREPARE stmt_name FROM preparable_stmt
#
# The PREPARE statement prepares a SQL statement and assigns it a name, stmt_name, by which
# to refer to the statement later.
#
# The prepared statement is executed with EXECUTE and released with DEALLOCATE_PREPARE
#
# For examples, see SECTION 13.5, "PREPARED SQL STATEMENT SYNTAX"
#
# Statement names are not case-sensitive. preparable_stmt is either a string literal or
# a user variable that contains the text of the SQL statement.
#
# The text must represent a single statement, not multiple statements.
#
# Within the statement, ? characters can be used as parameter markers to indicate
# where data values are to be bound to the query later when you execute it.
#
# The ? characters should not be enclosed within quotation marks, even if you
# intend to bind them to string values.
#
# Parameter markers can be used only where data values should appear, not for
# SQL keywords, identifiers, and so forth.
#
# If a prepared statement with the given name already exists. It is deallocated implicitly
# before the new statement is prepared.
#
# This means that if the new statement contains an error and cannot be prepared,
# an error is returned and no statement with the given name exists.
#
# The scope of a prepared statement is the session within which it is created,
# which as several implications:
#
# 		) A prepared statement created in one session is not available to other sessions
#
# 		) When a session ends, whether normally or abnormally, its prepared statements
# 			no longer exist.
#
# 			If auto-reconnect is enabled, the client is not notified that the connection
# 			was lost.
#
# 			For this reason, clients may wish to disable auto-reconnect
#
# 			See SECTION 28.7.24, "C API AUTOMATIC RECONNECTION CONTROL"
#
# 		) A prepared statement created within a stored program continues to exist
# 			after the program finishes executing and can be executed outside the 
# 			program later.
#
# 		) A statement prepared in stored program context cannot refer to stored procedure
# 			or function parameters or local variables because they go out of scope when the
# 			program ends and would be unavailable were the statement to be executed later outside
# 			the program.
#
# 			As a workaround, refer instead to user-defined variables, which also have
# 			session scope;
#
# 			See SECTION 9.4, "USER-DEFINED VARIABLES"
#
# 13.5.2 EXECUTE SYNTAX
#
# 		EXECUTE stmt_name
# 			[USING @var_name [, @var_name] ---]
#
# After preparing a statement with PREPARE, you execute it with an EXECUTE statement
# that refers to the prepared statement name.
#
# If the prepared statement contains any parameter markers, you must supply a USING
# clause that lists user variables containing the values to be bound to the parameters.
#
# Parameter values can be supplied only by user variables, and the USING clause must
# name exactly as many variables as the number of parameter markers in the statement.
#
# You can execute a given prepared statement multiple times, passing different variables
# to it or setting the variables to different values before each execution.
#
# For examples, see SECTION 13.5, "PREPARED SQL STATEMENT SYNTAX"
#
# 13.5.3 DEALLOCATE PREPARE SYNTAX
#
# 		{DEALLOCATE | DROP} PREPARE stmt_name
#
# To deallocate a prepared statement produced with PREPARE, use a DEALLOCATE_PREPARE
# statement that refers to the prepared statement name.
#
# Attempting to execute a prepared statement after deallocating it results in an
# error.
#
# If too many prepared statements are created and not deallocated by either the
# DEALLOCATE PREPARE statement or the end of the session, you might encounter
# the upper limit enforced by the max_prepared_stmt_count system variable.
#
# For examples, see SECTION 13.5, "PREPARED SQL STATEMENT SYNTAX"
#
# 13.6 COMPOUND-STATEMENT SYNTAX
#
# 		13.6.1 BEGIN --- END COMPOUND-STATEMENT SYNTAX
# 		13.6.2 STATEMENT LABEL SYNTAX
# 
# 		13.6.3 DECLARE SYNTAX
# 		13.6.4 VARIABLES IN STORED PROGRAMS
#
# 		13.6.5 FLOW CONTROL STATEMENTS
# 		13.6.6 CURSORS
# 	
# 		13.6.7 CONDITION HANDLING
#
# This section desccribes the syntax for the BEGIN_---_END compound statement and other
# statements that can be used in the body of stored programs:
#
# 		Stored procedures and functions, triggers, and events.
#
# These objects are defined in terms of SQL code that is stored on the server
# for later invocation
#
# (See CHAPTER 24, STORED PROGRAMS AND VIEWS)
#
# A compound statement is a block that can contain other blocks; declarations
# for variables, condition handlers and cursors; and flow control constructs 
# such as loops and conditional tests.
#
# 13.6.1 BEGIN --- END COMPOUND-STATEMENT SYNTAX
#
# 		[begin_label:] BEGIN
# 			[statement_list]
# 		END [end_label]
#
# BEGIN_---_END syntax is used for writing compound statements, which can appear
# within stored programs (stored procedures and functions, triggers and events)
#
# A compound statement can contain multiple statements, enclosed by the BEGIN 
# and END keywords.
#
# statement_list represents a list of one or more statements, each terminated
# by a semicolon (;) statement delimiter.
#
# The statement_list itself is optional, so the empty compound statement
# (BEGIN END) is legal.
#
# BEGIN_---_END blocks can be nested.
#
# Use of multiple statements requires that a client is able to send statement
# strings containing the ; statement delimiter.
#
# In the mysql command-line client, this is handled with the delimiter command.
#
# Changing the ; end-of-statement delimiter (for example, to //) permit ; to
# be used in a program body.
#
# For an example, see SECTION 24.1, "DEFINING STORED PROGRAMS"
#
# A BEGIN_---_END block can be labeled. See SECTION 13.6.2, "STATEMENT LABEL SYNTAX"
#
# The optional [NOT] ATOMIC clause is not supported.
#
# This means that no transactional savepoint is set at the start of the instruction
# block and the BEGIN clause used in this context has no effect on the current transaction.
#
# NOTE:
#
# 		Within all stored programs, the parser treats BEGIN_[WORK] as the beginning of a 
# 		BEGIN_---_END block.
#
# 		To begin a transaction in this context, use START_TRANSACTION instead.
#
# 13.6.2 STATEMENT LABEL SYNTAX
#
# 		[begin_label:] BEGIN
# 			[statement_list]
# 		END [end_label]
#
# 		[begin_label:] LOOP
# 			statement_list
# 		END LOOP [end_label]
#
# 		[begin_label:] REPEAT
# 			statement_list
# 		UNTIL search_condition
# 		END REPEAT [end_label]
#
# 		[begin_label:] WHILE search_condition DO
# 			statement_list
# 		END WHILE [end_label]
#
# Labels are permitted for BEGIN_---_END blocks and for the LOOP, REPEAT and WHILE statements.
#
# Label use for those statements follows these rules:
#
# 		) begin_label must be followed by a colon
#
# 		) begin_label can be given without end_label.
#
# 			If end_label is present, it must be the same as begin_label
#
# 		) end_label cannot be given without begin_label
#
# 		) Labels at the same nesting level must be distinct.
#
# 		) Labels can be up to 16 characters long
#
# To refer to a label within the labeled construct, use an ITERATE 
# or LEAVE statement.
#
# The following example uses those statements to continue iterating or
# terminate the loop:
#
# 		CREATE PROCEDURE doiterate(p1 INT)
# 		BEGIN
# 			label1: LOOP
# 				SET p1 = p1 + 1;
# 				IF p1 < 10 THEN ITERATE label1; END IF;
# 				LEAVE label1;
# 			END LOOP label1;
# 		END;
#
# The scope of a block label does not include the code for handlers declared within the
# block.
#
# For details, see SECTION 13.6.7.2, "DECLARE --- HANDLER SYNTAX"
#
# 13.6.3 DECLARE SYNTAX
#
# The DECLARE statement is used to define various items local to a program:
#
# 		) Local variables. See SECTION 13.6.4, "VARIABLES IN STORED PROGRAMS"
#
# 		) Conditions and handlers. See SECTION 13.6.7, "CONDITION HANDLING"
#
# 		) Cursors. See SECTION 13.6.6, "CURSORS"
#
# DECLARE is permitted only inside a BEGIN_---_END compound statement and must be
# at its start, before any other statements.
#
# Declarations must follow a certain order.
#
# Cursor declarations must appear before handler declarations.
#
# Variable and condition declarations must appear before cursor or
# handler declarations.
#
# 13.6.4 VARIABLES IN STORED PROGRAMS
#
# 13.6.4.1 LOCAL VARIABLE DECLARE SYNTAX
# 13.6.4.2 LOCAL VARIABLE SCOPE AND RESOLUTION
#
# System variables and user-defined variables can be used in stored programs, just as they can be used
# outside stored-program context.
#
# In addition, stored programs can use DECLARE to define local variables, and stored routines
# (procedures and functions) can be declared to take parameters that communicate
# values between the routine and its caller.
#
# 		) To declare local variables, use the DECLARE statement, as described in SECTION 13.6.4.1, "LOCAL VARIABLE DECLARE SYNTAX"
#
# 		) Variables can be set directly with the SET statement. See SECTION 13.7.5.1, "SET SYNTAX FOR VARIABLE ASSIGNMENT"
#
# 		) Results from queries can be retrieved into local variables using SELECT_---_INTO_var_list or by opening a cursor
# 			and using FETCH_---_INTO_var_list
#
# 			See SECTION 13.2.10.1, "SELECT --- INTO SYNTAX", and SECTION 13.6.6, "CURSORS"
#
# For information about the scope of local variables and how MySQL resolves ambiguous names, see SECTION 13.6.4.2,
# "LOCAL VARIABLE SCOPE AND RESOLUTION"
#
# It is not permitted to assign the value DEFAULT to stored procedure or function parameters or stored
# program local variables (for example with a SET var_name = DEFAULT statement)
#
# In MySQL 8.0, this results in a syntax error
#
# 13.6.4.1 LOCAL VARIABLE DECLARE SYNTAX
#
# 		DECLARE var_name [, var_name] --- type [DEFAULT value]
#
# This statement declares local variables within stored programs.
#
# To provide a default value for a variable, include a DEFAULT clause.
#
# The value can be specified as an expression; it need not be a constant.
#
# If the DEFAULT clause is missing, the initial value is NULL
#
# Local variables are treated like stored routine parameters with respect to data
# type and overflow checking.
#
# See SECTION 13.1.17, "CREATE PROCEDURE AND CREATE FUNCTION SYNTAX"
#
# Variable declarations must appear before cursor or handler declarations
#
# Local variable names are not case-sensitive. Permissible characters and quoting rules
# are the same as for other identifiers, as described in SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# The scope of a local variable is the BEGIN_---_END block within which it is declared.
#
# The variable can be referred to in blocks nested within the declaring block, except
# those blocks that declare a variable with the same name.
#
# For examples of variable declarations, see SECTION 13.6.4.2, "LOCAL VARIABLE SCOPE AND RESOLUTION"
#
# 13.6.4.2 LOCAL VARIABLE SCOPE AND RESOLUTION
#
# The scope of a local variable is the BEGIN_---_END block within which it is declared.
#
# The variable can be referred to in blocks nested within the declaring block, except
# those blocks that declare a variable with the same name.
#
# Because local variables are in scope only during stored program execution, references
# to them are not permitted in prepared statements created within a stored program.
#
# Prepared statement scope is the current session, not the stored program, so the
# statement could be executed after the program ends, at which point the variables
# would no longer be in scope.
#
# For example, SELECT --- INTO local_var cannot be used as a prepared statement.
#
# This restriction also applies to stored procedure and function parameters.
#
# See SECTION 13.5.1, "PREPARE SYNTAX"
#
# A local variable should not have the same name as a table column.
#
# If an SQL statement, such as SELECT_---_INTO statement, contains a reference
# to a column and a declared local variable with the same name, MySQL currently
# interprets the reference as the name of a variable.
#
# Consider the following procedure definition:
#
# 		CREATE PROCEDURE sp1 (x VARCHAR(5))
# 		BEGIN
# 			DECLARE xname VARCHAR(5) DEFAULT 'bob';
# 			DECLARE newname VARCHAR(5);
# 			DECLARE xid INT;
#
# 			SELECT xname, id INTO newname, xid
# 				FROM table1 WHERE xname = xname;
# 			SELECT newname;
# 		END;
#
# MySQL interprets xname in the SELECT statement as a reference to the 
# xname variable rather than the xname column.
#
# Consequently, when the procedure sp1() is called, the newname variable
# returns the value 'bob' regardless of the value of the table1.xname
# column.
#
# Similarly, the cursor definition in the following procedure contains a SELECT
# statement that refers to xname.
#
# MySQL interprets this as a reference to the variable of that name rather
# than a column reference.
#
# 		CREATE PROCEDURE sp2 (x VARCHAR(5))
# 		BEGIN
# 			DECLARE xname VARCHAR(5) DEFAULT 'bob';
# 			DECLARE newname VARCHAR(5);
# 			DECLARE xid INT;
# 			DECLARE done TINYINT DEFAULT 0;
# 			DECLARE cur1 CURSOR FOR SELECT xname, id FROM table1;
# 			DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = 1;
#
# 			OPEN cur1;
# 			read_loop: LOOP
# 				FETCH FROM cur1 INTO newname, xid;
# 				IF done THEN LEAVE read_loop; END IF
# 				SELECT newname;
# 			END LOOP;
# 			CLOSE cur1;
# 		END;
#
# See also SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# 13.6.5 FLOW CONTROL STATEMENTS
#
# 13.6.5.1 CASE SYNTAX
# 13.6.5.2 IF SYNTAX
#
# 13.6.5.3 ITERATE SYNTAX
# 13.6.5.4 LEAVE SYNTAX
#
# 13.6.5.5 LOOP SYNTAX
# 13.6.5.6 REPEAT SYNTAX
#
# 13.6.5.7 RETURN SYNTAX
# 13.6.5.8 WHILE SYNTAX
#
# MySQL supports the IF, CASE, ITERATE, LEAVE LOOP, WHILE and REPEAT constructs for flow control
# within stored programs.
#
# It also supports RETURN within stored functions.
#
# Many of these constructs contain other statements, as indicated by the grammar specifications
# in the following sections.
#
# Such constructs may be nested.
#
# For example, an IF statement might contain a WHILE loop, which itself contains a CASE statement.
#
# MySQL does not support FOR Loops.
#
# 13.6.5.1 CASE SYNTAX
#
# 		CASE case_value
# 			WHEN when_value THEN statement_list
# 			[WHEN when_value THEN statement_list]
# 			[ELSE statement_list]
# 		END CASE
#
# Or:
#
# 		CASE
# 			WHEN search_condition THEN statement_list
# 			[WHEN search_condition THEN statement_list]
# 			[ELSE statement_list]
# 		END CASE
#
# The CASE statement for stored programs implements a complex conditional construct.
#
# NOTE:
#
# 		There is also a CASE expression, which differs from the CASE statement described here.
#
# 		See SECTION 12.4, "CONTROL FLOW FUNCTIONS"
#
# 		The CASE statement cannot have an ELSE NULL clause, and it is terminated with 
# 		END CASE instead of END
#
# For the first syntax, case_value is an expression.
#
# This value is compared to the when_value expression in each WHEN clause until one of them
# is equal.
#
# When an equal when_value is found, the corresponding THEN clause statement_list executes.
#
# If no when_value is equal, the ELSE clause statement_list executes, if there is one.
#
# This syntax cannot be used to test for equalit with NULL because NULL = NULL is false.
#
# See SECTION 3.3.4.6, "WORKING WITH NULL VALUES"
#
# For the second syntax, each WHEN clause search_condition expression is evaluated until one
# is true, at which point its corresponding THEN clause statement_list executes.
#
# If no search_condition is equal, the ELSE clause statement_list executes, if there is one.
#
# If no when_value or search_condition matches the value tested and the CASE statement contains
# no ELSE clause, a:
#
# 		Case not found for CASE statement
#
# error results.
#
# Each statement_list consists of one or more SQL statements; an empty statement_list
# is not permitted.
#
# To handle situations where no value is matched by any WHEN clause, use an ELSE containing
# an empty BEGIN_---_END block, as shown in this example.
#
# (The indentation used here in the ELSE clause is for purposes of clarity only,
# and is not otherwise significant)
#
# DELIMITER |
#
# CREATE PROCEDURE p()
# 		BEGIN
# 			DECLARE v INT DEFAULT 1;
#
# 			CASE v
# 				WHEN 2 THEN SELECT v;
# 				WHEN 3 THEN SELECT 0;
# 				ELSE
# 					BEGIN
# 					END;
# 			END CASE;
# 		END;
# 		|
#
# 13.6.5.2 IF SYNTAX
#
# IF search_condition THEN statement_list
# 		[ELSEIF search_condition THEN statement_list] ---
# 		[ELSE statement_list]
# END IF
#
# The IF statement for stored programs implements a basic conditional construct.
#
# NOTE:
#
# 		There is also an IF() funciton, which differs from the IF statement described here.
#
# 		See SECTION 12.4, "CONTROL FLOW FUNCTIONS"
#
# 		The IF statement can have THEN, ELSE and ELSEIF clauses, and it is
# 		terminated with END IF.
#
# If the search_condition evaluates to true, the corresponding THEN or ELSEIF clause
# statement_list executes.
#
# If no search_condition matches, the ELSE clause statement_list executes.
#
# Each statement_list consists of one or more SQL statements; an empty statement_list is
# not permitted.
#
# An IF --- END IF block, like all other flow-control blocks used within stored programs,
# must be terminated with a semicolon, as shown in this example:
#
# 		DELIMITER //
#
# 		CREATE FUNCTION SimpleCompare(n INT, m INT)
# 			RETURNS VARCHAR(20)
#
# 			BEGIN
# 				DECLARE s VARCHAR(20);
#
# 				IF n > m THEN SET s = '>';
# 				ELSEIF n = m THEN SET s = '=';
# 				ELSE SET s = '<';
# 				END IF;
#
# 				SET s = CONCAT(n, ' ', s, ' ', m);
#
# 				RETURN s;
# 			END //
#
# 		DELIMITER;
#
# AS with other flow-control constructs, IF --- END IF blocks may be nested within other
# flow-control constructs, including other IF statements.
#
# Each IF must be terminated by its own END IF followed by a semicolon.
#
# You can use indentation to make nested flow-control blocks more easily readable
# by humans (although this is not required by MySQL), as shown here:
#
# 		DELIMITER //
#
# 		CREATE FUNCTION VerboseCompare (n INT, m INT)
# 			RETURNS VARCHAR(50)
#
# 			BEGIN
# 				DECLARE s VARCHAR(50);
#
# 				IF n = m THEN SET s = 'equals';
# 				ELSE
# 					IF n > m THEN SET s = 'greater';
# 					ELSE SET s = 'less';
# 					END IF;
#
# 					SET s = CONCAT('is', s, ' than');
# 				END IF;
#
# 				SET s = CONCAT(n, ' ', s, ' ', m, '.');
#
# 				RETURN s;
# 			END //
#
# 		DELIMITER ;
#
# In this example, the inner IF is evaluated only if n is not equal to m
#
# 13.6.5.3 ITERATE SYNTAX
#
# 		ITERATE label
#
# ITERATE can appear only within LOOP, REPEAT, and WHILE statements.
#
# ITERATE means "start the loop again"
#
# For an example, see SECTION 13.6.5.5, "LOOP SYNTAX"
#
# 13.6.5.4 LEAVE SYNTAX
#
# 		LEAVE label
#
# This statement is used to exit the flow control construct that has the given label.
#
# If the label is for the outermost stored program block, LEAVE exits the program
#
# LEAVE can be used within BEGIN_---_END or loop constructs (LOOP, REPEAT, WHILE)
#
# For an example, see SECTION 13.6.5.5, "LOOP SYNTAX"
#
# 13.6.5.5 LOOP SYNTAX
#
# 		[begin_label:] LOOP
# 			statement_list
# 		END LOOP [end_label]
#
# LOOP implements a simple loop construct, enabling repeated execution of the statement
# list, which consists of one or more statements, each terminated by a semicolon (;) 
# statement delimiter.
#
# The statements within the loop are repeated until the loop is terminated.
#
# Usually, this is accomplished with a LEAVE statement.
#
# Within a stored function, RETURN can also be used, which exits the function entirely
#
# Neglecting to include a loop-termination statement results in an infinite loop
#
# A LOOP statement can be labeled. For the rules regarding label use, see SECTION 13.6.2, "STATEMENT LABEL SYNTAX"
#
# Example:
#
# 		CREATE PROCEDURE doiterate(p1 INT)
# 		BEGIN
# 			label1: LOOP
# 				SET p1 = p1 + 1;
# 				IF p1 < 10 THEN
# 					ITERATE label1;
# 				END IF;
# 				LEAVE label1;
# 			END LOOP label1;
# 			SET @x = p1;
# 		END;
#
# 13.6.5.6 REPEAT SYNTAX
#
# 	[begin_label:] REPEAT
# 		statement_list
# 	UNTIL search_condition
# 	END REPEAT [end_label]
#
# The statement list within a REPEAT statement is repeated until the search_condition expression
# is true.
#
# Thus, a REPEAT always enters the loop at least once.
#
# statement_list consists of one or more statements, each terminated by a semicolon (;) statement delimiter
#
# A REPEAT statement can be labeled. For the rules regarding label use, see SECTION 13.6.2,
# "STATEMENT LABEL SYNTAX"
#
# Example:
#
# 		delimiter //
#
# 		CREATE PROCEDURE dorepeat(p1 INT)
# 		BEGIN
# 			SET @x = 0;
# 			REPEAT
# 				SET @x = @x + 1;
# 			UNTIL @x > p1 END REPEAT;
# 		END
# 		//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CALL dorepeat(1000)//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT @x//
# 		+---------+
# 		| @x 	    |
# 		+---------+
# 		| 1001 	 |
# 		+---------+
# 		1 row in set (0.00 sec)
#
# 13.6.5.7 RETURN SYNTAX
#
# 		RETURN expr
#
# The RETURN statement terminates execution of a stored function and returns the value expr to
# the function caller.
#
# There must be at least one RETURN statement in a stored function.
#
# There may be more than one if the function has multiple exit points.
#
# This statement is not used in stored procedures, triggers, or events.
#
# The LEAVE statement can be used to exit a stored program of those types.
#
# 13.6.5.8 WHILE SYNTAX
#
# 		[begin_label:] WHILE search_condition DO
# 			statement_list
# 		END WHILE [end_label]
#
# The statement list within a WHILE statement is repeated as long as the search_condition
# expression is true.
#
# statement_list consists of one or more SQL statements, each terminated by a semicolon
# (;) statement delimiter.
#
# A WHILE statement can be labeled. For the rules regarding label use,
# see SECTION 13.6.2, "STATEMENT LABEL SYNTAX"
#
# Example:
#
# 		CREATE PROCEDURE dowhile()
# 		BEGIN
# 			DECLARE v1 INT DEFAULT 5;
#
# 			WHILE v1 > 0 DO
# 				---
# 				SET v1 = v1 - 1;
# 			END WHILE;
# 		END;
#
# 13.6.6 CURSORS
#
# 13.6.6.1 CURSOR CLOSE SYNTAX
# 13.6.6.2 CURSOR DECLARE SYNTAX
# 13.6.6.3 CURSOR FETCH SYNTAX
# 13.6.6.4 CURSOR OPEN SYNTAX
#
# MySQL supports cursors inside stored programs.
#
# The syntax is as in embedded SQL. Cursors have these properties:
#
# 		) Asensitive: The server may or may not make a copy of its result table
#
# 		) Read only: Not updatable
#
# 		) Nonscrollable: Can be traversed only in one direction and cannot skip rows
#
# Cursor declarations must appear before handler declarations and after variable and condition
# declarations.
#
# Example:
#
# 		CREATE PROCEDURE curdemo()
# 		BEGIN
# 			DECLARE done INT DEFAULT FALSE;
# 			DECLARE a CHAR(16);
# 			DECLARE b, c INT;
# 			DECLARE cur1 CURSOR FOR SELECT id, data FROM test.t1;
# 			DECLARE cur2 CURSOR FOR SELECT i FROM test.t2;
# 			DECLARE CONTINUE HANDLER FOR NOT FOUND SET done = TRUE;
#
# 			OPEN cur1;
# 			OPEN cur2;
#
# 			read_loop: LOOP
# 				FETCH cur1 INTO a, b;
# 				FETCH cur2 INTO c;
# 				IF done THEN
# 					LEAVE read_loop;
# 				END IF;
# 				IF b < c THEN
# 					INSERT INTO test.t3 VALUES (a,b);
# 				ELSE
# 					INSERT INTO test.t3 VALUES (a,c);
# 				END IF;
# 			END LOOP;
#
# 			CLOSE cur1;
# 			CLOSE cur2;
# 		END;
#
# 13.6.6.1 CURSOR CLOSE SYNTAX
#
# 		CLOSE cursor_name
#
# This statement closes a previously opened cursor.
#
# For an example, see SECTION 13.6.6, "CURSORS"
#
# An error occurs if the cursor is not open.
#
# If not closed explicitly, a cursor is closed at the end of the
# BEGIN_---_END block in which it was declared.
#
# 13.6.6.2 CURSOR DECLARE SYNTAX
#
# 		DECLARE cursor_name CURSOR FOR select_statement
#
# This statement declares a cursor and associates it with a SELECT statement that
# retrieves the rows to be traversed by the cursor.
#
# To fetch the rows later, use a FETCH statement.
#
# The number of columns retrieved by the SELECT statement must match the number
# of output variables specified in the FETCH statement.
#
# The SELECT statement cannot have an INTO clause.
#
# Cursor declarations must appear before handler declarations and after variable
# and condition declarations.
#
# A stored program may contain multiple cursor declarations, but each cursor declared
# in a given block must have a unique name.
#
# For an example, see SECTION 13.6.6, "CURSORS"
#
# For information available through SHOW statements, it is possible in many cases
# to obtain equivalent information by using a cursor with an INFORMATION_SCHEMA table.
#
# 13.6.6.3 CURSOR FETCH SYNTAX
#
# 		FETCH [[NEXT] FROM] cursor_name INTO var_name [, var_name] ---
#
# This statement fetches the next row for the SELECT statement associated with the
# specified cursor (which must be open), and advances the cursor pointer.
#
# If a row exists, the fetched columns are stored in the named variables.
#
# The number of columns retrieved by the SELECT statement must match the number
# of output variables specified in the FETCH statement.
#
# If no more rows are available, a No Data condition occurs with SQLSTATE
# value '02000'
#
# To detect this condition, you can set up a handler for it (or for a NOT FOUND condition)
# 
# For an example, see SECTION 13.6.6, "CURSORS"
#
# Be aware that another operation, such as a SELECT or another FETCH, may also cause
# the handler to execute by raising the same condition.
#
# If it is necessary to distinguish which operation raised the condition,
# place the operation within its own BEGIN_---_END block so that it can be
# associated with its own handler.
#
# 13.6.6.4 CURSOR OPEN SYNTAX
#
# 		OPEN cursor_name
#
# This statement opens a previously declared cursor. For an example, see SECTION 13.6.6, "CURSORS"
#
# 13.6.7 CONDITION HANDLING
#
# 13.6.7.1 DECLARE --- CONDITION SYNTAX
# 13.6.7.2 DECLARE --- HANDLER SYNTAX
#
# 13.6.7.3 GET DIAGNOSTICS SYNTAX
# 13.6.7.4 RESIGNAL SYNTAX
#
# 13.6.7.5 SIGNAL SYNTAX
# 13.6.7.6 SCOPE RULES FOR HANDLERS
#
# 13.6.7.7 THE MYSQL DIAGNOSTICS AREA
# 13.6.7.8 CONDITION HANDLING AND OUT OR INOUT PARAMETERS
#
# Conditions may arise during stored program execution that require special handling,
# such as exiting the current program block or continuing execution.
#
# Handlers can be defined for general conditions such as warnings or exceptions,
# or for specific conditions such as particular error code.
#
# Specific conditions can be assigned names and referred to that way in handlers.
#
# To name a condition, use the DECLARE_---_CONDITION statement.
#
# To declare a handler, use the DECLARE_---_HANDLER statement.
#
# See SECTION 13.6.7.1, "DECLARE --- CONDITION SYNTAX", and SECTION 13.6.7.2, "DECLARE_---_HANDLER SYNTAX"
#
# For information about how the server chooses handlers when a condition occurs,
# see SECTION 13.6.7.6, "SCOPE RULES FOR HANDLERS"
#
# To raise a condition, use the SIGNAL statement. To modify condition information within
# a condition handler, use RESIGNAL.
#
# See SECTION 13.6.7.1, "DECLARE --- CONDITION SYNTAX", and SECTION 13.6.7.2, "DECLARE --- HANDLER SYNTAX"
#
# To retrieve information from the diagnostics area, use the GET_DIAGNOSTICS statement (see SECTION 13.6.7.3,
# "GET DIAGNOSTICS SYNTAX")
#
# For information about the diagnostics area, see SECTION 13.6.7.7, "THE MYSQL DIAGNOSTICS AREA"
#
# 13.6.7.1 DECLARE --- CONDITION SYNTAX
#
# DECLARE condition_name CONDITION FOR condition_value
#
# condition_value: {
# 		mysql_error_code
# 	 | SQLSTATE [VALUE] sqlstate_value
# }
#
# The DECLARE_---_CONDITION statement declares a named error condition, associating
# a name with a condition that needs specific handling.
#
# The name can be referred to in a subsequent DECLARE_---_HANDLER statement (see SECTION 13.6.7.2, "DECLARE_---_HANDLER SYNTAX")
#
# Condition declarations must appear before cursor or handler declarations.
#
# The condition_value for DECLARE_---_CONDITION indicates the specific condition or class of conditions
# to associate with the condition name.
#
# It can take the following forms:
#
# 		) mysql_error_code: An integer literal indicating a MySQL error code.
#
# 			Do not use MySQL error code 0 because that indicates success rather than an error
# 			condition.
#
# 			For a list of MySQL error codes, see SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# 		) SQLSTATE[VALUE] sqlstate_value: A 5-character string literal indicating an SQLSTATE value.
#
# 			Do not use SQLSTATE values that begin with '00' because those indicate success rather
# 			than an error condition.
#
# 			For a list of SQLSTATE values, see SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# Condition names referred to in SIGNAL or use RESIGNAL statements must be associated with
# SQLSTATE values, not MySQL error codes.
#
# Using names for conditions can help make stored program code clearer.
#
# For example, this handler applies to attempts to drop a nonexistent table,
# but that is apparent only if you know that 1051 is the MySQL error code for "unknown table":
#
# 		DECLARE CONTINUE HANDLER FOR 1051
# 			BEGIN
# 				-- body of handler
# 			END;
#
# By declaring a name for the condition, the purpose of the handler is more readily seen:
#
# 		DECLARE no_such_table CONDITION FOR 1051;
# 		DECLARE CONTINUE HANDLER FOR no_such_table
# 			BEGIN
# 				-- body of handler
# 			END;
#
# Here is a named condition for the same condition, but based on the corresponding
# SQLSTATE value rather than the MySQL error code:
#
# 		DECLARE no_such_table CONDITION FOR SQLSTATE '42S02';
# 		DECLARE CONTINUE HANDLER FOR no_such_table
# 			BEGIN
# 				-- body of handler
# 			END;
#
# 13.6.7.2 DECLARE --- HANDLER SYNTAX
#
# 	DECLARE handler_action HANDLER
# 		FOR condition_value [, condition_value]
# 		statement
#
# 	handler_action: {
# 		CONTINUE
# 	 | EXIT
#   | UNDO
# 	}
#
# 	condition_value: {
# 		mysql_error_code
#   | SQLSTATE [VALUE] sqlstate_value
# 	 | condition_name
# 	 | SQLWARNING
# 	 | NOT FOUND
#   | SQLEXCEPTION
#  }
#
# The DECLARE_---_HANDLER statement specifies a handler that deals with one or more
# conditions.
#
# If one of these conditions occurs, the specified statement executes.
#
# statement can be a simple statement such as SET var_name = value, or a compound statement
# written using BEGIN and END (see SECTION 13.6.1, "BEGIN --- END COMPOUND-STATEMENT SYNTAX")
#
# Handler declarations must appear after variable or condition declarations.
#
# The handler_action value indicates what action the handler takes after execution
# of the handler statement:
#
# 		) CONTINUE: Execution of the current program continues
#
# 		) EXIT: Execution terminates for the BEGIN_---_END compound statement in which the handler
# 			is declared.
#
# 			This is true even if the condition occurs in an inner block.
#
# 		) UNDO: Not supported.
#
# The condition_value for DECLARE_---_HANDLER indicates the specific condition or class
# of conditions that activates the handler.
#
# It can take the following forms:
#
# 		) mysql_error_code: An integer literal indicating a MySQL error code, such as 1051 to specify "Unknown table":
#
# 			DECLARE CONTINUE HANDLER FOR 1051
# 				BEGIN
# 					-- body of handler
# 				END;
#
# 			Do not use MySQL error code 0 because that indicates success rather than an error condition.
#
# 			For a list of MySQL error codes, see SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# 		) SQLSTATE[VALUE] sqlstate_value: A 5-character string literal indicating an SQLSTATE value,
# 			such as '42S01' to specify "unknown table":
#
# 				DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'
# 					BEGIN
# 						-- body of handler
# 					END;
#
# 			Do not use SQLSTATE values that begin with '00' because those indicate success
# 			rather than an error condition.
#
# 			For a list of SQLSTATE values, see SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# 		) condition_name: A condition name previously specified with DECLARE_---_CONDITION
#
# 			A condition name can be associated with a MySQL error code or SQLSTATE value.
#
# 			See SECTION 13.6.7.1, "DECLARE --- CONDITION SYNTAX"
#
# 		) SQLWARNING: Shorthand for the class of SQLSTATE values that begin with '01'
#
# 			DECLARE CONTINUE HANDLER FOR SQLWARNING
# 				BEGIN
# 					--- body of handler
# 				END;
#
# 		) NOT FOUND:
#
# 			Shorthand for the class of SQLSTATE values that begin with '02'
#
# 			This is relevant within the context of cursors and is used to control
# 			what happens when a cursor reaches the end of a data set.
#
# 			If no more rows are available, a No Data condition occurs with SQLSTATE 
# 			value '02000'
#
# 			To detect this condition, you can set up a handler for it or for a NOT FOUND
# 			condition.
#
# 				DECLARE CONTINUE HANDLER FOR NOT FOUND
# 					BEGIN
# 						-- body of handler
# 					END;
#
# 			For another example, see SECTION 13.6.6, "CURSORS"
#
# 			The NOT FOUND condition also occurs for SELECT --- INTO var_list statements
# 			that retrieve no rows.
#
# 		) SQLEXCEPTION:
#
# 			Shorthand for the class of SQLSTATE values that do not begin with 
# 			'00', '01', or '02'
#
# 				DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 					BEGIN
# 						-- body of handler
# 					END;
#
# For information about how the server chooses handlers when a condition occurs,
# see SECTION 13.6.7.6, "SCOPE RULES FOR HANDLERS"
#
# If a condition occurs for which no handler has been declared, the action taken
# depends on the condition class:
#
# 		) For SQLEXCEPTION conditions, the stored program terminates at the statement
# 			that raised the condition, as if there were an EXIT handler.
#
# 			If the program was called by another stored program, the calling program
# 			handles the condition using the handler selection rules applied to
# 			its own handlers.
#
# 		) For SQLWARNING conditions, the program continues executing, as if there were a CONTINUE handler.
#
# 		) For NOT FOUND conditions, if the condition was raised normally, the action is CONTINUE.
#
# 			If it was raised by SIGNAL or RESIGNAL, the action is EXIT.
#
# The following example uses a handler for SQLSTATE '23000', which occurs for a 
# duplicate-key error:
#
# 		CREATE TABLE test.t (s1 INT, PRIMARY KEY (s1));
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		delimiter //
#
# 		CREATE PROCEDURE handlerdemo ()
# 		BEGIN
# 			DECLARE CONTINUE HANDLER FOR SQLSTATE '23000' SET @x2 = 1;
# 			SET @x = 1;
# 			INSERT INTO test.t VALUES (1);
# 			SET @x = 2;
# 			INSERT INTO test.t VALUES (1);
# 			SET @x = 3;
# 		END;
# 		//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CALL handlerdemo()//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT @x//
# 		+------------+
# 		| @x 			 |
# 		+------------+
# 		| 3 			 |
# 		+------------+
# 		1 row in set (0.00 sec)
#
# Notice that @x is 3 after the procedure executes, which shows that execution continued
# to the end of the procedure after the error occurred.
#
# If the DECLARE_---_HANDLER statement had not been present, MySQL would have taken the
# default action (EXIT) after the second INSERT failed due to the PRIMARY KEY constraint,
# and SELECT @x would have returned 2.
#
# To ignore a condition, declare a CONTINUE handler for it and associate it with an empty block.
#
# For example:
#
# 		DECLARE CONTINUE HANDLER FOR SQLWARNING BEGIN END;
#
# The scope of a block label does not include the code for handlers declared within the block.
#
# Therefore, the statement associated with a handler cannot use ITERATE or LEAVE to refer
# to labels for blocks that enclose the handler declaration.
#
# Consider the following example, where the REPEAT block has a label of retry:
#
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE i INT DEFAULT 3;
# 			retry:
# 				REPEAT
# 					BEGIN
# 						DECLARE CONTINUE HANDLER FOR SQLWARNING
# 							BEGIN
# 								ITERATE retry; #Illegal
# 							END;
# 						IF i < 0 THEN
# 							LEAVE retry; #legal
# 						END IF;
# 						SET i = i - 1;
# 					END;
# 				UNTIL FALSE END REPEAT;
# 		END;
#
# The retry label is in scope for the IF statement within the block.
#
# It is not in scope for the CONTINUE handler, so the reference there is invalid
# and results in an error:
#
# 		ERROR 1308 (42000): LEAVE with no matching label: retry
#
# To avoid references to outer labels in handlers, use one of these strategies:
#
# 		) To leave the block, use an EXIT handler. If no block cleanup is required, the
# 			BEGIN_---_END handler body can be empty:
#
# 				DECLARE EXIT HANDLER FOR SQLWARNING BEGIN END;
#
# 			Otherwise, put the cleanup statements in the handler body:
#
# 				DECLARE EXIT HANDLER FOR SQLWARNING
# 					BEGIN
# 						block cleanup statements
# 					END;
#
# 		) To continue execution, set a status variable in a CONTINUE handler that can be checked
# 			in the enclosing block to determine whether the handler was invoked.
#
# 			The following example uses the variable done for this purpose:
#
# 				CREATE PROCEDURE p ()
# 				BEGIN
# 					DECLARE i INT DEFAULT 3;
# 					DECLARE done INT DEFAULT FALSE;
# 					retry:
# 						REPEAT
# 							BEGIN
# 								DECLARE CONTINUE HANDLER FOR SQLWARNING
# 									BEGIN
# 										SET done = TRUE;
# 									END;
# 								IF done OR i < 0 THEN
# 									LEAVE retry;
# 								END IF;
# 								SET i = i - 1;
# 							END;
# 						UNTIL FALSE END REPEAT;
# 				END; 
#
# 13.6.7.3 GET DIAGNOSTICS SYNTAX
#
# 		GET [CURRENT | STACKED] DIAGNOSTICS
# 		{
# 			statement_information_item
# 			[, statement_information_item] ---
# 		 | CONDITION condition_number
# 			condition_information_item
# 		 	[, condition_information_item] ---
# 		}
#
# 		statement_information_item:
# 			target = statement_information_item_name
#
# 		condition_information_item:
# 			target = condition_information_item_name
#
# 		statement_information_item_name:
# 			NUMBER
# 		 | ROW_COUNT
#
# 		condition_information_item_name: {
# 			CLASS_ORIGIN
# 		 | SUBCLASS_ORIGIN
# 		 | RETURNED_SQLSTATE
# 		 | MESSAGE_TEXT
# 		 | MYSQL_ERRNO
# 		 | CONSTRAINT_CATALOG
# 		 | CONSTRAINT_SCHEMA
# 		 | CONSTRAINT_NAME
# 		 | CATALOG_NAME
# 		 | SCHEMA_NAME
# 		 | TABLE_NAME
# 		 | COLUMN_NAME
# 		 | CURSOR_NAME
# 		}
#
# 		condition_number, target:
# 			(see following discussion)
#
# SQL statements produce diagnostic information that populates the diagnostics area.
#
# The GET_DIAGNOSTICS statement enables applications to inspect this information.
#
# (You can also use SHOW_WARNINGS or SHOW_ERRORS to see conditions or errors)
#
# No special privileges are required to execute GET_DIAGNOSTICS
#
# The keyword CURRENT means to retrieve information from the current diagnostics area.
#
# The keyword STACKED means to retrieve information from the second diagnostics
# area, which is available only if the current context is a condition handler.
#
# If neither keyword is given, the default is to use the current diagnostics area.
#
# The GET_DIAGNOSTICS statement is typically used in a handler within a stored program.
#
# It is a MySQL extension that GET_[CURRENT]_DIAGNOSTICS is permitted outside
# handler context to check the execution of any SQL statement.
#
# For example, if you invoke the mysql client program, you can enter these statements
# at the prompt:
#
# 		DROP TABLE test.no_such_table;
# 		ERROR 1051 (42S02): Unknown table 'test.no_such_table'
# 		GET DIAGNOSTICS CONDITION 1
# 			@p1 = RETURNED_SQLSTATE, @p2 = MESSSAGE_TEXT;
# 		SELECT @p1, @p2;
# 		+-------+------------------------------------+
# 		| @p1   | @p2 									      |
# 		+-------+------------------------------------+
# 		| 42S02 | Unknown table 'test.no_such_table' |
# 		+-------+------------------------------------+
#
# This extension applies only to the current diagnostics area.
#
# It does not apply to the second diagnostics area because GET STACKED DIAGNOSTICS
# is permitted only if the current context is a condition handler.
#
# If that is not the case, a:
#
# 	 GET STACKED DIAGNOSTICS when handler not active
#
# error occurs
#
# For a description of the diagnostics area, see SECTION 13.6.7.7, "THE MySQL DIAGNOSTICS AREA"
#
# Briefly, it contains two kinds of information:
#
# 		) Statement information, such as the number of conditions that occurred or the affected-rows count
#
# 		) Condition information, such as the error code and message.
#
# 			If a statement raises multiple conditions, this part of the diagnostics area has
# 			a condition area for each one.
#
# 			If a statement raises no conditions, this part of the diagnostics area is empty.
#
# For a statement that produces three conditions, the diagnostics area contains statement
# and condition information like this:
#
# 		Statement information:
# 			row count
# 			--- other statement information items ---
# 		Condition area list:
# 			Condition area 1:
# 				error code for condition 1
# 				error message for condition 1
# 				--- other condition information items ---
# 			Condition area 2:
# 				error code for condition 2:
# 				error message for condition 2
# 				--- other condition information items ---
# 			Condition area 3:
# 				error code for condition 3
# 				error message for condition 3
# 				--- other condition information items --
#
# GET_DIAGNOSTICS can obtain either statement or condition information, but not
# both in the same statement:
#
# 		) To obtain statement information, retrieve the desired statement items into target
# 			variables.
#
# 			This instance of GET_DIAGNOSTICS assigns the number of available conditions
# 			and the rows-affected count to the user variables @p1 and @p2:
#
# 				GET DIAGNOSTICS @p1 = NUMBER, @p2 = ROW_COUNT;
#
# 		) To obtain condition information, specify the condition number and retrieve the desired
# 			condition items into target variables.
#
# 			This instance of GET_DIAGNOSTICS assigns the SQLSTATE value and error message
# 			to the user variables @p3 and @p4:
#
# 				GET DIAGNOSTICS CONDITION 1
# 					@p3 = RETURNED_SQLSTATE, @p4 = MESSAGE_TEXT;
#
# The retreival list specifies one or more target = item_name assignments, separated by commas.
#
# Each assignment names a target variable and either a statement_information_item_name or
# condition_information_item_name designator, depending on whether the statement retrieves
# statement or condition information.
#
# Valid target designators for storing item information can be stored procedure or
# function parameters, stored program local variables declared with DECLARE,
# or user-defined variables.
#
# Valid condition_number designators can be stored procedure or function parameters,
# stored program local variables declared with DECLARE, user-defined variables,
# system variables, or literals.
#
# A character literal may include a _charset introducer.
#
# A warning occurs if the condition number is not in the range from 1 to the
# number of condition areas that have information.
#
# In this case, the warning is added to the diagnostics area without clearing it.
#
# When a condition occurs, MySQL does not populate all condition items recognized
# by GET_DIAGNOSTICS.
#
# For example:
#
# 		GET DIAGNOSTICS CONDITION 1
# 			@p5 = SCHEMA_NAME, @p6 = TABLE_NAME;
# 		SELECT @p5, @p6;
# 		+------+-----------+
# 		| @p5  | @p6 		 |
# 		+------+-----------+
# 		|  	 | 			 |
# 		+------+-----------+
#
# In standard SQL, if there are multiple conditions, the first condition relates
# to the SQLSTATE value returned for the previous SQL statement.
#
# In MySQL, this is not guaranteed.
#
# To get the main error, you cannot do this:
#
# 		GET DIAGNOSTICS CONDITION 1 @errno = MYSQL_ERRNO;
#
# Instead, retrieve the condition count first, then use it to specify
# which condition number to inspect:
#
# 		GET DIAGNOSTICS @cno = NUMBER;
# 		GET DIAGNOSTICS CONDITION @cno @errno = MYSQL_ERRNO;
#
# For information about permissible statement and condition information items,
# and which ones are populated when a condition occurs, see DIAGNOSTICS AREA INFORMATION ITEMS
#
# Here is an example that uses GET_DIAGNOSTICS and an exception handler in stored procedure
# context to assess the outcome of an insert operation.
#
# If the insert was successful, the procedure uses GET_DIAGNOSTICS to get the rows-affected
# count.
#
# This shows that you can use GET_DIAGNOSTICS multiple times to retrieve information about
# a statement as long as the current diagnostics area has not been cleared.
#
# 		CREATE PROCEDURE do_insert(value INT)
# 		BEGIN
# 			--- DECLARE variables to hold diagnostics area information
# 			DECLARE code CHAR(5) DEFAULT '00000';
# 			DECLARE msg TEXT;
# 			DECLARE rows INT;
# 			DECLARE result TEXT;
# 			-- Declare exception handler for failed insert
# 			DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 				BEGIN
# 					GET DIAGNOSTICS CONDITION 1
# 						code = RETURNED_SQLSTATE, msg = MESSAGE_TEXT;
# 				END;
#
# 			-- Perform the insert
# 			INSERT INTO t1 (int_col) VALUES(value);
# 			-- Check whether the insert was successful
# 			IF code = '00000' THEN
# 				GET DIAGNOSTICS rows = ROW_COUNT;
# 				SET result = CONCAT('insert succeeded, row count = ',rows);
# 			ELSE
# 				SET result = CONCAT('insert failed, error = ',code,', message = ',msg);
# 			END IF;
# 			-- Say what happened
# 			SELECT result;
# 		END;
#
# Suppose that t1.int_col is an integer column that is declared as NOT NULL.
#
# The procedure produces these results when invoked to insert non-NULL and
# NULL values, respectively:
#
# 		CALL do_insert(1);
# 		+---------------------------------+
# 		| result 							    |
# 		+---------------------------------+
# 		| insert succeeded, row count = 1 |
# 		+---------------------------------+
#
# 		CALL do_insert(NULL);
# 		+-------------------------------------------------------------------------+
# 		| result 																					  |
# 		+-------------------------------------------------------------------------+
# 		| insert failed, error = 23000, message = Column 'int_col' cannot be null |
# 		+-------------------------------------------------------------------------+
#
# When a condition handler activates, a push to the diagnostics area stack occurs:
#
# 		) The first (current) diagnostics area becomes the second (stacked) diagnostics area
# 			and a new current diagnostics area is created as a copy of it.
#
# 		) GET_[CURRENT]_DIAGNOSTICS and GET_STACKED_DIAGNOSTICS can be used within the handler
# 			to access the contents of the current and stacked diagnostics areas.
#
# 		) Initially, both diagnostics areas return the same result, so it is possible to get
# 			information from the current diagnostics area about the condition that activated
# 			the handler, as long as you execute no statements within the handler that change
# 			its current diagnostics area.
#
# 		) However, statements executing within the handler can modify the current diagnostics area,
# 			clearing and setting its contents according to the normal rules (see HOW THE DIAGNOSTICS AREA IS CLEARED AND POPULATED)
#
# 			A more reliable way to obtain information about the handler-activating condition is to use the
# 			stacked diagnostics area, which cannot be modified by statements executing within the handler
# 			except RESINGAL.
#
# 			For information about when the current diagnostics area is set and cleared, see
# 			SECTION 13.6.7.7, "THE MYSQL DIAGNOSTICS AREA"
#
# The next example shows how GET STACKED DIAGNOSTICS can be used within a handler to obtain
# information about the handled exception, even after the current diagnostics area has been
# modified by handler statements.
#
# Within a stored procedure p(), we attempt to insert two values into a table that contains a
# TEXT NOT NULL column.
#
# The first value is a non-NULL string and the second is NULL
#
# The column prohibits NULL values, so the first insert succeeds but the
# second causes an exception.
#
# The procedure includes an exception handler that maps attempts to insert
# NULL into inserts of the empty string:
#
# 		DROP TABLE IF EXISTS t1;
# 		CREATE TABLE t1 (c1 TEXT NOT NULL);
# 		DROP PROCEDURE IF EXISTS p;
# 		delimiter //
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			-- Declare variables to hold diagnostics area information
# 			DECLARE errcount INT;
# 			DECLARE errno INT;
# 			DECLARE msg TEXT;
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTIOn
# 			BEGIN
# 				-- Here the current DA is nonempty because no prior statements
# 				-- executing within the handler have cleared it
# 				GET CURRENT DIAGNOSTICS CONDITION 1
# 					errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 				SELECT 'current DA before mapped insert' AS op, errno, msg;
# 				GET STACKED DIAGNOSTICS CONDITION 1
# 					errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 				SELECT 'stacked DA before mapped insert' AS op, errno, msg;
#
# 				-- Map attempted NULL insert to empty string insert
# 				INSERT INTO t1 (c1) VALUES('');
#
# 				-- Here the current DA should be empty (if the INSERT succeeded),
# 				-- so check whether there are conditions before attempting to
# 				-- obtain condition information
# 				GET CURRENT DIAGNOSTICS errcount = NUMBER;
# 				IF errcount = 0
# 				THEN
# 					SELECT 'mapped insert succeeded, current DA is empty' AS op;
# 				ELSE
# 					GET CURRENT DIAGNOSTICS CONDITION 1
# 						errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 					SELECT 'current DA after mapped insert' AS op, errno, msg;
# 				END IF ;
# 				GET STACKED DIAGNOSTICS CONDITION 1
# 					errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 				SELECT 'stacked DA after mapped insert' AS op, errno, msg;
# 			END;
# 			INSERT INTO t1 (c1) VALUES('string 1');
# 			INSERT INTO t1 (c1) VALUES(NULL);
# 		END;
# 		//
# 		delimiter ;
# 		CALL p();
# 		SELECT * FROM t1;
#
# When the handler activates, a copy of the current diagnostics area is pushed to the
# diagnostics area stack.
#
# The handler first displays the contents of the current and stacked diagnostics areas,
# which are both the same initially:
#
# 		+-------------------------------------------+-----------+-------------------------------------+
# 		| op 													  | errno 	  | msg 											 |
# 		+-------------------------------------------+-----------+-------------------------------------+
# 		| current DA before mapped insert 			  | 1048 	  | Column 'c1' cannot be null 			 |
# 		+-------------------------------------------+-----------+-------------------------------------+
#
# 		+-------------------------------------------+-----------+-------------------------------------+
# 		| op 													  | errno 	  | msg 											 |
# 		+-------------------------------------------+-----------+-------------------------------------+
# 		| stacked DA before mapped insert 			  | 1048 	  | Column 'c1' cannot be null 			 |
# 		+-------------------------------------------+-----------+-------------------------------------+
#
# Statements executing after the GET_DIAGNOSTICS statements may reset the current diagnostics area.
#
# Statements may reset the current diagnostics area.
#
# For example, the handler maps the NULL insert to an empty string insert and displays the result.
#
# The new insert succeeds and clears the current diagnostics area, but the stacked diagnostics
# area remains unchanged and still contains information about the condition that activated the handler:
#
# 		+-----------------------------------------------+
# 		| op 															|
# 		+-----------------------------------------------+
# 		| mapped insert succeeded, current DA is empty  |
# 		+-----------------------------------------------+
#
# 		+-----------------------------------------------+---------+--------------------------------+
# 		| op 															| errno 	 | msg 									 |
# 		+-----------------------------------------------+---------+--------------------------------+
# 		| stacked DA after mapped insert 					| 1048 	 | Column 'c1' cannot be null     |
# 		+-----------------------------------------------+---------+--------------------------------+
#
# When the condition handler ends, its current diagnostics area is popped from the stack and the stacked
# diagnostics area becomes the current diagnostics area in the stored procedure.
#
# After the procedure returns, the table contains two rows.
#
# The empty row results from the attempt to insert NULL that was mapped to an empty string insert:
#
# 		+---------------+
# 		| c1 				 |
# 		+---------------+
# 		| string 1 		 |
# 		| 					 |
# 		+---------------+
#
# In the preceding example, the first two GET_DIAGNOSTICS statements within the condition handler
# that retrieve information from the current and stacked diagnostics areas return the same values.
#
# This will not be the case if statements that reset the current diagnostics area execute earlier
# within the handler.
#
# Suppose that p() is rewritten to place the DECLARE statements within the handler definition
# rather than preceding it:
#
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION
# 			BEGIN
# 				-- Declare variables to hold diagnostics area information
# 				DECLARE errcount INT;
# 				DECLARE errno INT;
# 				DECLARE msg TEXT;
# 				GET CURRENT DIAGNOSTICS CONDITION 1
# 					errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 				SELECT 'current DA before mapped insert' AS op, errno, msg;
# 				GET STACKED DIAGNOSTICS CONDITION 1
# 					errno = MYSQL_ERRNO, msg = MESSAGE_TEXT;
# 				SELECT 'stacked DA before mapped insert' AS op, errno, msg;
# 		---
#
# In this case, the result is version dependent:
#
# 		) Before MySQL 5.7.2, DECLARE does not change the current diagnostics area, so the first two
# 			GET_DIAGNOSTICS statements return the same result, just as in the original version of p()
#
# 			In MySQL 5.7.2, work was done to ensure that all nondiagnostic statements populate the
# 			diagnostics area, per the SQL standard.
#
# 			DECLARE is one of them, so in 5.7.2 and higher, DECLARE statements executing at the 
# 			beginning of the handler clear the current diagnostics area and the GET_DIAGNOSTICS
# 			statements produce different results:
#
# 				+-----------------------------------+-----------+-----------+
# 				| op 											| errno 	   | msg 		|
# 				+-----------------------------------+-----------+-----------+
# 				| current DA before mapped insert   | NULL 		| NULL 		|
# 				+-----------------------------------+-----------+-----------+
#
# 				+-----------------------------------+-----------+---------------------------------------+
# 				| op 											| errno 	   | msg 											 |
# 				+-----------------------------------+-----------+---------------------------------------+
# 				| stacked DA before mapped insert   | 1048 		| Column 'c1' cannot be null 				 |
# 				+-----------------------------------+-----------+---------------------------------------+
#
# To avoid this issue within a condition handler when seeking to obtain information about the condition
# that activated the handler, be sure to access the stacked diagnostics area, not the current
# diagnostics area.
#
# 13.6.7.4 RESIGNAL SYNTAX
#
# 		RESIGNAL [condition_value]
# 			[SET signal_information_item
# 			[, signal_information_item] ---]
#
# 		condition_value: {
# 			SQLSTATE [VALUE] sqlstate_value
# 		 | condition_name
# 		}
#
# 		signal_information_item:
# 			condition_information_item_name = simple_value_specification
#
# 		condition_information_item_name: {
# 			CLASS_ORIGIN
# 		 | SUBCLASS_ORIGIN
# 		 | MESSAGE_TEXT
# 		 | MYSQL_ERRNO
# 		 | CONSTRAINT_CATALOG
# 		 | CONSTRAINT_SCHEMA
# 		 | CONSTRAINT_NAME
# 		 | CATALOG_NAME
# 		 | SCHEMA_NAME
# 		 | TABLE_NAME
# 		 | COLUMN_NAME
# 		 | CURSOR_NAME
# 		}
#
# 		condition_name, simple_value_specification:
# 			(see following discussion)
#
# RESIGNAL passes on the error condition information that is available during
# execution of a condition handler within a compound statement inside a stored
# procedure or function, trigger, or event.
#
# RESIGNAL may change some or all information before passing it on.
#
# RESIGNAL is related to SIGNAL, but instead of originating a condition
# as SIGNAL does, RESIGNAL relays existing condition information, possibly
# after modifying it.
#
# RESIGNAL makes it possible to both handle an error and return the error information.
#
# Otherwise, by executing an SQL statement within the handler, information that caused
# the handler's activation is destroyed.
#
# RESIGNAL also can make some procedures shorter if a given handler can handle part
# of a situation, then pass the condition "up the line" to another handler.
#
# No privileges are required to execute the RESIGNAL statement.
#
# All forms of RESIGNAL require that the current context be a condition handler.
#
# Otherwise, RESIGNAL is illegal and a:
#
# 		RESIGNAL when handler not active
#
# error occurs.
#
# To retrieve information from the diagnostics area, use the GET_DIAGNOSTICS
# statement (see SECTION 13.6.7.3, "GET DIAGNOSTICS SYNTAX")
#
# FOr information about the diagnostics area, see SECTION 13.6.7.7,
# "THE MYSQL DIAGNOSTICS AREA"
#
# 		) RESIGNAL OVERVIEW
#
# 		) RESIGNAL ALONE
#
# 		) RESIGNAL WITH NEW SIGNAL INFORMATION
#
# 		) RESIGNAL WITH A CONDITION VALUE AND OPTIONAL NEW SIGNAL INFORMATION
#
# 		) RESIGNAL REQUIRES CONDITION HANDLER CONTEXT
#
# RESIGNAL OVERVIEW
#
# For condition_value and signal_information_item, the definitions and rules are the same
# for RESIGNAL as for SIGNAL.
#
# For example, the condition_value can be an SQLSTATE value, and the value can indicate errors,
# warnings, or "not found".
#
# For additional information, see SECTION 13.6.7.5, "SIGNAL SYNTAX"
#
# The RESIGNAL statement takes condition_value and SET clauses, both of which are optional.
#
# This leads to several possible uses:
#
# 		) RESIGNAL alone:
#
# 			RESIGNAL;
#
# 		) RESIGNAL with new signal information:
#
# 			RESIGNAL SET signal_information_item [, signal_information_item] ---;
#
# 		) RESIGNAL with a condition value and possibly new signal information:
#
# 			RESIGNAL condition_value
# 				[SET signal_information_item [, signal_information_item] ---];
#
# These use cases all cause changes to the diagnostics and condition areas:
#
# 		) A diagnostics area contains one or more condition areas.
#
# 		) A condition area contains condition information items, such as the SQLSTATE value, MYSQL_ERRNO,
# 			or MESSAGE_TEXT
#
# There is a stack of diagnostics areas.
#
# When a handler takes control, it pushes a diagnostics area to the top of the stack, so there
# are two diagnostics areas during handler execution:
#
# 		) The first (current) diagnostics area, which starts as a copy of the last diagnostics area,
# 			but will be overwritten by the first statement in the handler that changes the current
# 			diagnostics area.
#
# 		) The last (stacked) diagnostics area, which has the condition areas that were set up before the handler
# 			took control.
#
# The maximum number of condition areas in a diagnostics area is determined by the value of the max_error_count
# system variable.
#
# See DIAGNOSTICS AREA-RELATED SYSTEM VARIABLES
#
# RESIGNAL ALONE
#
# A simple RESIGNAL alone means "pass on the error with no change."
#
# It restores the last diagnostics area and makes it the current diagnostics area.
#
# That is, it "Pops" the diagnostics area stack.
#
# Within a condition handler that catches a condition, one use for RESIGNAL alone is to
# perform some other actions, and then pass on without change the original condition
# information (the information that existed before entry into the handler)
#
# Example:
#
# 		DROP TABLE IF EXISTS xx;
# 		delimiter //
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION
# 			BEGIN
# 				SET @error_count = @error_count + 1;
# 				IF @a = 0 THEN RESIGNAL; END IF;
# 			END;
# 			DROP TABLE xx;
# 		END//
# 		delimiter ;
# 		SET @error_count = 0;
# 		SET @a = 0;
# 		CALL p();
#
# Suppose that the DROP TABLE xx statement fails. The diagnostics area stack looks like this:
#
# 		DA 1. ERROR 1051 (42S02): Unknown table 'xx'
#
# Then execution enters the EXIT handler. It starts by pushing a diagnostics area to the top of
# the stack, which now looks like this:
#
# 		DA 1. ERROR 1051 (42S02): Unknown table 'xx'
# 		DA 2. ERROR 1051 (42S02): Unknown table 'xx'
#
# At this point, the contents of the first (current) and second (stacked) diagnostics areas are
# teh same.
#
# The first diagnostics area may be modified by statements executing subsequently within
# the handler.
#
# Usually a procedure statement clears the first diagnostics area.
#
# BEGIN is an exception, it does not clear, it does nothing.
#
# SET is not an exception, it clears,performs the operation, and produces a result of
# "success"
#
# The diagnostics area stack now looks like this:
#
# 		DA 1. ERROR 0000 (00000): Successful operation
# 		DA 2. ERROR 1051 (42S02): Unknown table 'xx'
#
# At this point, if @a = 0, RESIGNAL pops the diagnostics area stack, which now looks
# like this:
#
# 		DA 1. ERROR 1051 (42S02): Unknown table 'xx'
#
# And that is what the caller sees.
#
# If @a is not 0, the handler simply ends, which means that there is no more use for the
# current diagnostics area (it has been "handled"), so it can be thrown away, causing
# the stacked diagnostics area to become the current diagnostics area again.
#
# The diagnostics area stack looks like this:
#
# 		DA 1. ERROR 0000 (00000): Successful operation
#
# The details make it look complex, but the end result is quite useful:
#
# 		Handlers can execute without destroying information about the condition
# 		that caused activation of the handler.
#
# RESIGNAL WITH NEW SIGNAL INFORMATION
#
# RESIGNAL with a SET clause provides new signal information, so the statement means
# "pass on the error with changes"
#
# 		RESIGNAL SET signal_information_item [, signal_information_item] ---;
#
# As with RESIGNAL alone the idea is to pop the diagnostics area stack so that
# the original information will go out.
#
# Unlike RESIGNAL alone, anything specified in the SET clause changes.
#
# Example:
#
# 		DROP TABLE IF EXISTS xx;
# 		delimiter //
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION
# 			BEGIN
# 				SET @error_count = @error_count + 1;
# 				IF @a = 0 THEN RESIGNAL SET MYSQL_ERRNO = 5; END IF;
# 			END;
# 			DROP TABLE xx;
# 		END//
# 		delimiter ;
# 		SET @error_count = 0;
# 		SET @a = 0;
# 		CALL p();
#
# Remember from the previous discussion that RESIGNAL alone results in a diagnostics
# area stack like this:
#
# 		DA 1. ERROR 1051 (42S02): Unknown table 'xx'
#
# The RESIGNAL SET MYSQL_ERRNO = 5 statement results in this stack instead, which is what the caller sees:
#
# 		DA 1. ERROR 5 (42S02): Unknown table 'xx'
#
# In other words, it changes the error number, and nothing else.
#
# The RESIGNAL statement can change any or all of the signal information items, making
# the first condition area of the diagnostics area look quite different.
#
# RESIGNAL WITH A CONDITION VALUE AND OPTIONAL NEW SIGNAL INFORMATION
#
# RESIGNAL with a condition value means "push a condition into the current diagnostics area"
#
# If the SET clause is present, it also changes the error information.
#
# 		RESIGNAL condition_value
# 			[SET signal_information_item [, signal_information_item] ---];
#
# This form of RESIGNAL restores the last diagnostics area and makes it the current
# diagnostics area.
#
# That is, it "pops" the diagnostics area stack, which is the same as what a simple
# RESIGNAL alone would do.
#
# However, it also changes the diagnostics area depending on the condition value or
# signal information.
#
# Example:
#
# 		DROP TABLE IF EXISTS xx;
# 		delimiter //
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION
# 			BEGIN
# 				SET @error_count = @error_count + 1;
# 				IF @a = 0 THEN RESIGNAL SQLSTATE '45000' SET MYSQL_ERRNO=5; END IF;
# 			END;
# 			DROP TABLE xx;
# 		END//
# 		delimiter ;
# 		SET @error_count = 0;
# 		SET @a = 0;
# 		SET @@max_error_count = 2;
# 		CALL p();
# 		SHOW ERRORS;
#
# This is similar to the previous example, and the effects are the same, except that if
# RESIGNAL happens, the current condition area looks different at the end.
#
# (The reason the condition adds to rather than replaces the existing condition is the
# use of a condition value)
#
# The RESIGNAL statement includes a condition value (SQLSTATE '45000'), so it adds a new
# condition area, resulting in a diagnostics area stack that looks like this:
#
# 		DA 1. (condition 2) ERROR 1051 (42S02): Unknown table 'xx'
# 				(condition 1) ERROR 5 (45000) Unknown table 'xx'
#
# The result of CALL_p() and SHOW_ERRORS for this example is:
#
# 		CALL p();
# 		ERROR 5 (45000): Unknown table 'xx'
# 		SHOW ERRORS;
# 		+--------+---------+--------------------------------------------------+
# 		| Level  | Code    | Message 														 |
# 		+--------+---------+--------------------------------------------------+
# 		| Error  | 1051 	 | Unknown table 'xx' 										 |
# 		| Error  | 5 		 | Unknown table 'xx' 										 |
# 		+--------+---------+--------------------------------------------------+
#
# RESIGNAL REQUIRES CONDITION HANDLER CONTEXT
#
# All forms of RESIGNAL require that the current context be a condition handler.
#
# Otherwise, RESIGNAL is illegal and a RESIGNAL when handler not active error
# occurs.
#
# For example:
#
# 		CREATE PROCEDURE p () RESIGNAL;
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CALL p();
# 		ERROR 1645 (0K000): RESIGNAL when handler not active
#
# Here is a more dificult example:
#
# 		delimiter //
# 		CREATE FUNCTION f () RETURNS INT
# 		BEGIN
# 			RESIGNAL;
# 			RETURN 5;
# 		END//
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION SET @a=f();
# 			SIGNAL SQLSTATE '55555';
# 		END//
# 		delimiter ;
# 		CALL p();
#
# RESIGNAL occurs within the stored function f()
#
# Although f() itself is invoked within the context of the EXIT handler, execution
# within f() has its own context, which is not handler context.
#
# Thus, RESIGNAL within f() results in a "handler not active" error.
#
# 13.6.7.5 SIGNAL SYNTAX
#
# 		SIGNAL condition_value
# 			[SET signal_information_item
# 			[, signal_information_item] ---]
#
# 		condition_value: {
# 			SQLSTATE [VALUE] sqlstate_value
# 		 | condition_name
# 		}
#
# 		signal_information_item:
# 			condition_information_item_name = simple_value_specification
#
# 		condition_information_item_name: {
# 			CLASS_ORIGIN
# 		 | SUBCLASS_ORIGIN
# 		 | MESSAGE_TEXT
# 		 | MYSQL_ERRNO
# 		 | CONSTRAINT_CATALOG
# 		 | CONSTRAINT_SCHEMA
# 		 | CONSTRAINT_NAME
# 		 | CATALOG_NAME
# 		 | SCHEMA_NAME
# 		 | TABLE_NAME
# 		 | COLUMN_NAME
# 		 | CURSOR_NAME
# 		}
#
# 		condition_name, simple_value_specification:
# 			(see following discussion)
#
# SIGNAL is the way to "return" an error.
#
# SIGNAL provides error information to a handler, to an outer portion
# of the application, or to the client.
#
# Also, it provides control over the error's characteristics (error number,
# SQLSTATE value, message)
#
# Without SIGNAL, it is necessary to resort to workarounds such as deliberately
# referring to a nonexistent table to cause a routine to return an error.
#
# No privileges are required to execute the SIGNAL statement.
#
# To retrieve information from the diagnostics area, use the GET_DIAGNOSTICS
# statement (see SECTION 13.6.7.3, "GET DIAGNOSTICS SYNTAX")
#
# For information about the diagnostics area, see SECTION 13.6.7.7, "THE MYSQL DIAGNOSTICS AREA"
#
# 		) SIGNAL OVERVIEW
#
# 		) SIGNAL CONDITION INFORMATION ITEMS
#
# 		) EFFECT OF SIGNALS ON HANDLERS, CURSORS AND STATEMENTS
#
# SIGNAL OVERVIEW
#
# The condition_value in a SIGNAL statement indicates the error value to be returned.
#
# It can be an SQLSTATE value (a 5-character string literal) or a condition_name
# that refers to a named condition previously defined with DECLARE_---_CONDITION
# (See SECTION 13.6.7.1, "DECLARE --- CONDITION SYNTAX")
#
# An SQLSTATE value can indicate errors, warnings, or "not found"
#
# The first two characters of the value indicates its error class, as discussed
# in SIGNAL CONDITION INFORMATION ITEMS.
#
# Some signal values cause statement termination: see EFFECT OF SIGNALS ON HANDLERS, CURSORS AND STATEMENTS
#
# The SQLSTATE value for a SIGNAL statement should not start with '00' because such values
# indicate success and are not valid for signaling an error.
#
# This is true whether the SQLSTATE value is specified directly in the SIGNAL statement or in
# a named condition referred to in the statement.
#
# If the value is invalid, a BAD SQLSTATE error occurs.
#
# To signal a generic SQLSTATE value, use '45000', which means "unhandled user-defined exception"
#
# The SIGNAL statement optionally includes a SET clause that contains multiple signal items,
# in a list of condition_information_item_name = simple_value_specification assignments,
# separated by commas.
#
# Each condition_information_item_name may be specified only once in the SET clause.
#
# Otherwise, a Duplicate condition information item error occurs.
#
# Valid simple_value_specification designators can be specified using stored procedure
# or function parameters, stored program local variables declared with DECLARE,
# user-defined variables, system variables, or literals.
#
# A character literal may include a _charset introducer.
#
# For information about permissible condition_information_item_name values, see SIGNAL CONDITION INFORMATION ITEMS
#
# The following procedure signals an error or warning depending on the value of pval, its
# input parameter:
#
# 		CREATE PROCEDURE p (pval INT)
# 		BEGIN
# 			DECLARE speciality CONDITION FOR SQLSTATE '45000';
# 			IF pval = 0 THEN
# 				SIGNAL SQLSTATE '01000';
# 			ELSEIF pval = 1 THEN
# 				SIGNAL SQLSTATE '45000'
# 					SET MESSAGE_TEXT = 'An error occurred';
# 			ELSEIF pval = 2 THEN
# 				SIGNAL speciality
# 					SET MESSAGE_TEXT = 'An error occurred';
# 			ELSE
# 				SIGNAL SQLSTATE '01000'
# 					SET MESSAGE_TEXT = 'A warning occurred', MYSQL_ERRNO = 1000;
# 				SIGNAL SQLSTATE '45000'
# 					SET MESSAGE_TEXT = 'An error occurred', MYSQL_ERRNO = 1001;
# 			END IF;
# 		END;
#
# If pval is 0, p() signals a warning because SQLSTATE values that begin with '01' are signals
# in the warning class.
#
# The warning does not terminate the procedure, and can be seen with SHOW_WARNINGS after the
# procedure returns.
#
# If pval is 1, p() signals an error and sets the MESSAGE_TEXT condition information item.
#
# The error terminates the procedure, and the text is returned with the error information.
#
# If pval is 2, the same error is signaled, although the SQLSTATE value is specified using
# a named condition in this case.
#
# If pval is anything else, p() first signals a warning and sets the message text and error
# number condition information items.
#
# This warning does not terminate the procedure, so execution continues and p() then signals
# an error.
#
# The error does terminate the procedure. The message text and error number set by the warning
# are replaced by the values set by the error, which are returned with the error information.
#
# SIGNAL is typically used within stored programs, but it is a MySQL extension that it is permitted
# outside handler context.
#
# For example, if you invoke the mysql client program, you can enter any of these statements
# at the prompt:
#
# 		SIGNAL SQLSTATE '77777';
#
# 		CREATE TRIGGER t_bi BEFORE INSERT ON t
# 			FOR EACH ROW SIGNAL SQLSTATE '77777';
#
# 		CREATE EVENT e ON SCHEDULE EVERY 1 SECOND
# 			DO SIGNAL SQLSTATE '77777';
#
# SIGNAL executes according to the following rules:
#
# 	If the SIGNAL statement indicates a particular SQLSTATE value, that value is used to
# 	signal the condition specified.
#
# Example:
#
# 		CREATE PROCEDURE p (divisor INT)
# 		BEGIN
# 			IF divisor = 0 THEN
# 				SIGNAL SQLSTATE '22012';
# 			END IF;
# 		END;
#
# If the SIGNAL statement uses a named condition, the condition must be declared in some
# scope that applies to the SIGNAL statement, and must be defined using an SQLSTATE value,
# not a MySQL error number.
#
# Example:
#
# 		CREATE PROCEDURE p (divisor INT)
# 		BEGIN
# 			DECLARE divide_by_zero CONDITION FOR SQLSTATE '22012';
#			IF divisor = 0 THEN
# 				SIGNAL divide_by_zero;
# 			END IF;
# 		END;
#
# If the named condition does not exist in the scope of the SIGNAL statement, an 
# Undefined CONDITION error occurs.
#
# If SIGNAL refers to a named condition that is defined with a MySQL error number rather
# than an SQLSTATE value, a:
#
# 	 SIGNAL/RESIGNAL can only use a CONDITION defined with SQLSTATE error
#
# occurs.
#
# The following statements cause that error because the named condition is associated
# with a MySQL error number:
#
# 		DECLARE no_such_table CONDITION FOR 1051;
# 		SIGNAL no_such_table;
#
# If a condition with a given name is declared multiple times in different scopes,
# the declaration with the most local scope applies.
#
# Consider the following procedure:
#
# 		CREATE PROCEDURE p (divisor INT)
# 		BEGIN
# 			DECLARE my_error CONDITION FOR SQLSTATE '45000';
# 			IF divisor = 0 THEN
# 				BEGIN
# 					DECLARE my_error CONDITION FOR SQLSTATE '22012';
# 					SIGNAL my_error;
# 				END;
# 			END IF;
# 			SIGNAL my_error;
# 		END;
#
# If divisor is 0, the first SIGNAL statement executes.
#
# The innermost my_error condition declaration applies, raising SQLSTATE '22012'
#
# If divisor is not 0, the second SIGNAL statement executes. The outermost my_error
# condition declaration applies, raising SQLSTATE '45000'
#
# For information about how the server chooses handlers when a condition occurs,
# see SECTION 13.6.7.6, "SCOPE RULES FOR HANDLERS"
#
# Signals can be raised within exception handlers:
#
# 		CREATE PROCEDURE p ()
# 		BEGIN
# 			DECLARE EXIT HANDLER FOR SQLEXCEPTION
# 			BEGIN
# 				SIGNAL SQLSTATE VALUE '99999'
# 					SET MESSAGE_TEXT = 'An error occurred';
# 			END;
# 			DROP TABLE no_such_table;
# 		END;
#
# CALL p() reaches the DROP_TABLE statement.
#
# There is no table named no_such_table, so the error handler is activated.
#
# The error handler destroys the original error ("No such table") and makes a
# new error with SQLSTATE '99999' and message An error occurred.
#
# SIGNAL CONDITION INFORMATION ITEMS
#
# The following table lists the names of diagnostics area condition information items
# that can be set in a SIGNAL (or RESIGNAL) statement.
#
# All items are standard SQL except MYSQL_ERRNO, which is a MySQL extension.
#
# For more information about these items see SECTION 13.6.7.7, "THE MYSQL DIAGNOSTICS AREA"
#
# 		Item Name 					Definition
# 		---------- 					----------
# 		CLASS_ORIGIN 				VARCHAR(64)
# 		SUBCLASS_ORIGIN 			VARCHAR(64)
#
# 		CONSTRAINT_CATALOG 		VARCHAR(64)
# 		CONSTRAINT_SCHEMA 		VARCHAR(64)
#
# 		CONSTRAINT_NAME 			VARCHAR(64)
# 		CATALOG_NAME 				VARCHAR(64)
#
# 		SCHEMA_NAME 				VARCHAR(64)
# 		TABLE_NAME 					VARCHAR(64)
#
# 		COLUMN_NAME 				VARCHAR(64)
# 		CURSOR_NAME 				VARCHAR(64)
#
# 		MESSAGE_TEXT 				VARCHAR(128)
# 		MYSQL_ERRNO 				SMALLINT UNSIGNED
#
# The character set of character items is UTF-8
#
# It is illegal to assign NULL to a condition information item in a SIGNAL statement.
#
# A SIGNAL statement always specifies an SQLSTATE value, either directly, or indirectly
# by referring to a named condition defined with an SQLSTATE value.
#
# The first two characters of an SQLSTATE value are its class, and the class
# determines the default value for the condition information items:
#
# 		) Class = '00' (success)
#
# 			Illegal. SQLSTATE values that begin with '00' indicate success and are not valid for SIGNAL
#
# 		) Class = '01' (warning)
#
# 			MESSAGE_TEXT = 'Unhandled user-defined warning condition';
# 			MYSQL_ERRNO = ER_SIGNAL_WARN
#
# 		) Class = '02' (not found)
#
# 			MESSAGE_TEXT = 'Unhandled user-defined not found condition';
# 			MYSQL_ERRNO = ER_SIGNAL_NOT_FOUND
#
# 		) Class > '02' (exception)
#
# 			MESSAGE_TEXT = 'Unhandled user-defined exception condition';
# 			MYSQL_ERRNO = ER_SIGNAL_EXCEPTION
#
# For legal classes, the other condition information items are set as follows:
#
# 		CLASS_ORIGIN = SUBCLASS_ORIGIN = '';
# 		CONSTRAINT_CATALOG = CONSTRAINT_SCHEMA = CONSTRAINT_NAME = '';
# 		CATALOG_NAME = SCHEMA_NAME = TABLE_NAME = COLUMN_NAME = '';
# 		CURSOR_NAME = '';
#
# The error values that are accessible after SIGNAL executes are the SQLSTATE value
# raised by the SIGNAL statement and the MESSAGE_TEXT and MySQL_ERRNO items.
#
# These values are available from the C API:
#
# 		) mysql_sqlstate() returns the SQLSTATE value
#
# 		) mysql_errno() returns the MYSQL_ERRNO value
#
# 		) mysql_error() returns the MESSAGE_TEXT value
#
# At the SQL level, the output from SHOW_WARNINGS and SHOW_ERRORS indicates the MYSQL_ERRNO
# and MESSAGE_TEXT values in the Code and Message columns.
#
# To retrieve information from the diagnostics area, use the GET_DIAGNOSTICS statement
# (see SECTION 13.6.7.3, "GET DIAGNOSTICS SYNTAX")
#
# For information about the diagnostics area, see SECTION 13.6.7.7, "THE MYSQL DIAGNOSTICS AREA"
#
# EFFECT OF SIGNALS ON HANDLERS, CURSORS, AND STATEMENTS
#
# Signals have different effects on statement execution depending on the signal class.
#
# The class determines how severe an error is. MySQL ignores the value of the sql_mode
# system variable; in particular, strict SQL mode does not matter.
#
# MySQL also ignores IGNORE: The intent of SIGNAL is to raise a user-generated error
# explicitly, so a signal is never ignored.
#
# In the following descriptions, "unhandled" means that no handler for the signaled
# SQLSTATE value has been defined with DECLARE_---_HANDLER
#
# 		) Class = '00' (success)
#
# 			Illegal. SQLSTATE values that begin with '00' indicates success and are not valid for SIGNAL
#
# 		) Class = '01' (warning)
#
# 			The value of the warning_count system variable goes up.
#
# 			SHOW_WARNINGS shows the signal. SQLWARNING handlers catch the signal.
#
# 			Warnings cannot be returned from stored functions because the RETURN statement that causes
# 			the function to return clears the diagnostic area.
#
# 			The statement thus clears any warnings that may have been present there 
# 			(and resets warning_count to 0)
#
# 		) Class = '02' (not found)
#
# 			NOT FOUND handlers catch the signal.
#
# 			There is no effect on cursors. If the signal is unhandled in a stored function,
# 			statements end.
#
# 		) Class > '02' (exception)
#
# 			SQLEXCEPTION handlers catch the signal.
#
# 			if the signal is unhandled in a stored function, statements end.
#
# 		) Class = '40'
#
# 			Treated as an ordinary exception
#
# 13.6.7.6 SCOPE RULES FOR HANDLERS
#
# A stored program may include handlers to be invoked when certain conditions occur within
# the program.
#
# The applicability of each handler depends on its location within the program definition
# and on the condition or conditions that it handles:
#
# 		) A handler declared in a BEGIN_---_END block is in scope only for the SQL statements
# 			following the handler declarations in the block.
#
# 			If the handler itself raises a condition, it cannot handle that condition, nor 
# 			can any other handlers declared in the block.
#
# 			In the following example, handlers H1 and H2 are in scope for conditions
# 			raised by statements stmt1 and stmt2.
#
# 			But neither H1 nor H2 are in scope for conditions raised in the body of H1 or H2.
#
# 				BEGIN -- outer block
# 					DECLARE EXIT HANDLER FOR ---; --- handler H1
# 					DECLARE EXIT HANDLER FOR ---; --- handler H2
# 					stmt1;
# 					stmt2;
# 				END;
#
# 		) A handler is in scope only for the block in which it is declared, and cannot be
# 			activated for conditions occurring outside that block.
#
# 			In the following example, handler H1 is in scope for stmt1 in the inner block,
# 			but not for stmt2 in the outer block:
#
# 				BEGIN -- outer block
# 					BEGIN -- inner block
# 						DECLARE EXIT HANDLER FOR ---; --- handler H1
# 						stmt1;
# 					END;
# 					stmt2;
# 				END;
#
# 		) A handler can be specific or general.
#
# 			A specific handler is for a MySQL error code, SQLSTATE value, or condition name.
#
# 			A general handler is for a condition in the SQLWARNING, SQLEXCEPTION, or NOT FOUND
# 			class.
#
# 			Condition specificity is related to condition precedence, as described later.
#
# Multiple handlers can be declared in different scopes and with different specifities.
#
# For example, there might be a specific MySQL error code handler in an outer block,
# and a general SQLWARNING handler in an inner block.
#
# Or there might be handlers for a specific MySQL error code and the general SQLWARNING
# class in the same block.
#
# Whether a handler is activated depends not only on its own scope and condition value,
# but on what other handlers are present.
#
# When a condition occurs in a stored program, the server searches for applicable handlers
# in the current scope (current BEGIN_---_END block)
#
# If there are no applicable handlers, the search continues outward with the handlers
# in each successive containing scope (block).
#
# When the server finds one or more applicable handlers at a given scope, it chooses
# among them based on condition precdence:
#
# 		) A MySQL error code handler takes precedence over an SQLSTATE value handler
#
# 		) An SQLSTATE value handler takes precedence over general SQLWARNING, SQLEXCEPTION,
# 			or NOT FOUND handlers.
#
# 		) An SQLEXCEPTION handler takes precedence over an SQLWARNING handler
#
# 		) It is possible to have several applicable handlers with the same precedence.
#
# 			For example, a statement could generate multiple warnings with different#
# 			error codes, for each of which an error-specific handler exists.
#
# 			In this case, the choice of which handler the server activates is
# 			nondeterministic, and may change depending on the circumstances under which
# 			the condition occurs.
#
# One implication of the handler selection rules is that if multiple applicable handlers
# occur in different scopes, handlers with the most local scope take precedence
# over handlers in outer scopes, even over those for more specific conditions.
#
# If there is no appropriate handler when a condition occurs, the action taken depends
# on the class of the condition:
#
# 		) For SQLEXCEPTION conditions, the stored program terminates at the statement that
# 			raised the condition, as if there were an EXIT handler.
#
# 			If the program was called by another stored program, the calling program handles
# 			the condition using the handler selection rules applied to its own handlers.
#
# 		) For SQLWARNING conditions, the program continues executing, as if there were a CONTINUE handler
#
# 		) For NOT FOUND conditions, if the condition was raised normally, the action is CONTINUE.
#
# 			If it was raised by SIGNAL or RESIGNAL, the action is EXIT.
#
# The following examples demonstrate how MySQL applies the handler selection rules.
#
# This procedure contains two handlers, one for the specific SQLSTATE value ('42S02')
# that occurs for attempts to drop a nonexistent table, and one for the general
# SQLEXCEPTION class:
#
# 		CREATE PROCEDURE p1()
# 		BEGIN
# 			DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'
# 				SELECT 'SQLSTATE handler was activated' AS msg;
# 			DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 				SELECT 'SQLEXCEPTION handler was activated' AS msg;
#
# 			DROP TABLE test.t;
# 		END;
#
# Both handlers are declared in the same block and have the same scope.
#
# However, SQLSTATE handlers take precedence over SQLEXCEPTION handlers,
# so if the table t is nonexistent, the DROP_TABLE statement raises a condition
# that activates the SQLSTATE handler:
#
# 		CALL p1();
# 		+--------------------------------------+
# 		| msg 										   |
# 		+--------------------------------------+
# 		| SQLSTATE handler was activated 		|
# 		+--------------------------------------+
#
# This procedure contains the same two handlers. But this time, the DROP_TABLE statement
# and SQLEXCEPTION handler are in an inner block relative to the SQLSTATE handler:
#
# 		CREATE PROCEDURE p2()
# 		BEGIN -- outer block
# 				DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'
# 					SELECT 'SQLSTATE handler was activated' AS msg;
# 			BEGIN -- inner block
# 				DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 					SELECT 'SQLEXCEPTION handler was activated' AS msg;
#
# 				DROP TABLE test.t; -- occurs within inner block
# 			END;
# 		END;
#
# In this case, the handler that is more local to where the condition occurs
# takes precedence.
#
# The SQLEXCEPTION handler activates, even though it is more general than the
# SQLSTATE handler:
#
# 		CALL p2();
# 		+-------------------------------------------------+
# 		| msg 														  |
# 		+-------------------------------------------------+
# 		| SQLEXCEPTION handler was activated 				  |
# 		+-------------------------------------------------+
#
# In this procedure, one of the handlers is declared in a block inner to the scope of the
# DROP_TABLE statement:
#
# 		CREATE PROCEDURE p3()
# 		BEGIN -- outer block
# 			DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 				SELECT 'SQLEXCEPTION handler was activated' AS msg;
# 			BEGIN -- inner block
# 				DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'
# 					SELECT 'SQLSTATE handler was activated' AS msg;
# 			END;
#
# 			DROP TABLE test.t; -- occurs within outer block
# 		END;
#
# Only the SQLEXCEPTION handler applies because the other one is not in scope
# for the condition raised by the DROP_TABLE:
#
# 		CALL p3();
# 		+------------------------------------------+
# 		| msg 												 |
# 		+------------------------------------------+
# 		| SQLEXCEPTION handler was activated 		 |
# 		+------------------------------------------+
#
# In this procedure, both handlers are declared in a block inner to the scope of the
# DROP_TABLE statement:
#
# 		CREATE PROCEDURE p4()
# 		BEGIN -- Outer block
# 			BEGIN -- Inner block
# 				DECLARE CONTINUE HANDLER FOR SQLEXCEPTION
# 					SELECT 'SQLEXCEPTION handler was activated' AS msg;
# 				DECLARE CONTINUE HANDLER FOR SQLSTATE '42S02'
# 					SELECT 'SQLSTATE handler was activated' AS msg;
# 			END;
#
# 			DROP TABLE test.t -- Occurs within outer block
# 		END;
#
# Neither handler applies because they are not in scope for the DROP_TABLE 
#
# The condition raised by the statement goes unhandled and terminates the procedure
# with an error:
#
# 		CALL p4();
# 		ERROR 1051 (42S02): UNKNOWN TABLE 'test.t'
#
# 13.6.7.7 THE MYSQL DIAGNOSTICS AREA
#
# SQL statements produce diagnostic information that populates the diagnostics area.
#
# Standard SQL has a diagnostics area stack, containing a diagnostics area for each
# nested execution context.
#
# Standard SQL also supports GET_STACKED_DIAGNOSTICS syntax for referring to the
# second diagnostics area during condition handler execution.
#
# The following discussion describes the structure of the diagnostics area in MySQL,
# the information items recognized by MySQL, how statements clear and set the
# diagnostics area, and how diagnostics areas are pushed to and popped from the stack.
#
# 		) DIAGNOSTICS AREA STRUCTURE
#
# 		) DIAGNOSTICS AREA INFORMATION ITEMS
#
# 		) HOW THE DIAGNOSTICS AREA IS CLEARED AND POPULATED
#
# 		) HOW THE DIAGNOSTICS AREA STACK WORKS
#
# 		) DIAGNOSTICS AREA-RELATED SYSTEM VARIABLES
#
# DIAGNOSTICS AREA STRUCTURE
#
# The diagnostics area contains two kinds of information:
#
# 		) Statement information, such as the number of conditions that occurred or the affected-rows
# 			count.
#
# 		) Condition information, such as the error code and message.
#
# 			If a statement raises multiple conditions, this part of the diagnostics area has
# 			a condition area for each one.
#
# 			If a statement raises no conditions, this part of the diagnostics area is empty.
#
# For a statement that produces three conditions, the diagnostics area contains statement
# and condition information like this:
#
# 		Statement information:
# 			row count
# 			--- other statement information items ---
# 		Condition area list:
# 			Condition area 1:
# 				error code for condition 1
# 				error message for condition 1
# 				--- other condition information items ---
# 			Condition area 2:
# 				error code for condition 2:
# 				error message for condition 2
# 				--- other condition information items ---
# 			Condition area 3:
# 				error code for condition 3
# 				error message for condition 3
# 				--- other condition information items ---
#
# DIAGNOSTICS AREA INFORMATION ITEMS
#
# The diagnostics area contains statement and condition information items.
#
# Numeric items are integers.
#
# The character set for character items is UTF-8. No item can be NULL.
#
# If a statement or condition item is not set by a statement that populates
# the diagnostics area, its value is 0 or the empty string, depending on the
# item data type.
#
# The statement information part of the diagnostics area contains these items:
#
# 		) NUMBER: An integer indicating the number of condition areas that have information
#
# 		) ROW_COUNT: An integer indicating the number of rows affected by the statement 
#
# 			ROW_COUNT has the same value as the ROW_COUNT() function (see SECTION 12.15,
# 			"INFORMATION FUNCTIONS")
#
# The condition information part of the diagnostics area contains a condition area for
# each condition.
#
# Condition areas are numbered from 1 to the value of the NUMBER statement condition
# item
#
# If NUMBER is 0, there are no condition areas
#
# Each condition area contains the items in the following list.
#
# All items are standard SQL except MySQL_ERRNO, which is a MySQL extension.
#
# The definitions apply for conditions generated other than by a signal (that is,
# by a SIGNAL or RESIGNAL statement)
#
# For nonsignal conditions, MySQL populates only those condition items not
# described as always empty.
#
# The effects of signals on the condition area are described later.
#
# 		) CLASS_ORIGIN: A string containing the class of the RETURNED_SQLSTATE value.
#
# 			If the RETURNED_SQLSTATE value begins with a class value defined in SQL
# 			standards document ISO 9075-2 (SECTION 24.1, SQLSTATE), CLASS_ORIGIN is 'ISO 9075'
#
# 			Otherwise, CLASS_ORIGIN is 'MySQL'
#
# 		) SUBCLASS_ORIGIN: A string containing the subclass of the RETURNED_SQLSTATE value.
#
# 			If CLASS_ORIGIN is 'ISO 9075' or RETURNED_SQLSTATE ends with '000'
#
# 			SUBCLASS_ORIGIN is 'ISO 9075'. Otherwise, SUBCLASS_ORIGIN is 'MySQL'
#
# 		) RETURNED_SQLSTATE: A string that indicates the SQLSTATE value for the condition
#
# 		) MESSAGE_TEXT: A string that indicates the error message for the condition
#
# 		) MYSQL_ERRNO: An integer that indicates the MySQL error code for the condition
#
# 		) CONSTRAINT_CATALOG, CONSTRAINT_SCHEMA, CONSTRAINT_NAME: Strings that indicate the catalog,
# 			schema, and name for a violated constraint.
#
# 			They are always empty.
#
# 		) CATALOG_NAME, SCHEMA_NAME, TABLE_NAME, COLUMN_NAME: Strings that indicate the catalog, schema, table,
# 			and column related to the condition.
#
# 			They are always empty.
#
# 		) CURSOR_NAME: A string that indicates the cursor name. This is always empty
#
# For the RETURNED_SQLSTATE, MESSAGE_TEXT and MYSQL_ERRNO values for particular errors,
# see SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# If a SIGNAL (or RESIGNAL) statement populates the diagnostics area, its SET clause can
# assign to any condition information item except RETURNED_SQLSTATE any value that is
# legal for the item data type.
#
# SIGNAL also sets the RETURNED_SQLSTATE value, but not directly in its SET clause.
#
# That value comes from the SIGNAL statement SQLSTATE argument.
#
# SIGNAL also sets statement information items. It sets NUMBER to 1.
#
# It sets ROW_COUNT to -1 for errors and 0 otherwise.
#
# HOW THE DIAGNOSTICS AREA IS CLEARED AND POPULATED
#
# Nondiagnostic SQL statements populate the diagnostics area automatically,
# and its contents can be set explicitly with the SIGNAL and RESIGNAL statements.
#
# The diagnostics area can be examined with GET_DIAGNOSTICS to extract specific
# items, or with SHOW_WARNINGS or SHOW_ERRORS to see conditions of errors.
#
# SQL statements clear and set the diagnostics area as follows:
#
# 		) When the server starts executing a statement after parsing it, it clears the diagnostics
# 			area for nondiagnostic statements.
#
# 			Diagnostic statements do not clear the diagnostics area.
#
# 			These statements are diagnostic:
#
# 				) GET_DIAGNOSTICS
#
# 				) SHOW_ERRORS
#
# 				) SHOW_WARNINGS
#
# 		) If a statement raises a condition, the diagnostics area is cleared of conditions
# 			that belong to earlier statements.
#
# 			The exception is that conditions raised by GET DIAGNOSTICS and RESIGNAL
# 			are added to the diagnostics area without clearing it.
#
# Thus, even a statement that does not normally clear the diagnostics area when it begins
# executing clears it if the statement raises a condition.
#
# The following example shows the effect of various statements on the diagnostics area,
# using SHOW_WARNINGS to display information about conditions stored there.
#
# This DROP_TABLE statement clears the diagnostics area and populates it when the condition occurs:
#
# 		DROP TABLE IF EXISTS test.no_such_table;
# 		Query OK, 0 rows affected, 1 warning (0.01 sec)
#
# 		SHOW WARNINGS;
# 		+--------+-----------+----------------------------------------+
# 		| Level  | Code 		| Message 										  |
# 		+--------+-----------+----------------------------------------+
# 		| note   | 1051 		| Unknown table 'test.no_such_table' 	  |
# 		+--------+-----------+----------------------------------------+
# 		1 row in set (0.00 sec)
#
# This SET statement generates an error, so it clears and populates the
# diagnostics area:
#
# 		SET @x = @@x;
# 		ERROR 1193 (HY000): Unknown system variable 'x'
#
# 		SHOW WARNINGS;
# 		+--------+---------+-------------------------------------------+
# 		| Level  | Code 	 | Message 												|
# 		+--------+---------+-------------------------------------------+
# 		| Error  | 1193 	 | Unknown system variable 'x' 					|
# 		+--------+---------+-------------------------------------------+
# 		1 row in set (0.00 sec)
#
# The previous SET statement produced a single condition, so 1 is the only valid
# condition number for GET_DIAGNOSTICS at this point.
#
# The following statement uses a condition number of 2, which produces a warning
# that is added to the diagnostics area without clearing it:
#
# 		GET DIAGNOSTICS CONDITION 2 @p = MESSAGE_TEXT;
# 		Query OK, 0 rows affected, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS;
# 		+-------+-----------+----------------------------------------+
# 		| Level | Code 	  | Message 										 |
# 		+-------+-----------+----------------------------------------+
# 		| Error | 1193 	  | Unknown system variable 'xx' 			 |
# 		| Error | 1753 	  | Invalid condition number 					 |
# 		+-------+-----------+----------------------------------------+
# 		2 rows in set (0.00 sec)
#
# Now there are two conditions in the diagnostics area, so the same 
# GET_DIAGNOSTICS statement succeeds:
#
# 		GET DIAGNOSTICS CONDITION 2 @p = MESSAGE_TEXT;
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT @p;
# 		+-------------------------------------+
# 		| @p 											  |
# 		+-------------------------------------+
# 		| Invalid condition number 			  |
# 		+-------------------------------------+
# 		1 row in set (0.01 sec)
#
# HOW THE DIAGNOSTICS AREA STACK WORKS
#
# When a push to the diagnostics area stack occurs, the first (current) diagnostics area
# becomes the second (stacked) diagnostics area and a new current diagnostics area
# is created as a copy of it.
#
# Diagnostics areas are pushed to and popped from the stack under the following circumstances:
#
# 		) Execution of a stored program
#
# 			A push occurs before the program executes and a pop occurs afterward.
#
# 			If the stored program ends while handlers are executing, there can be more than
# 			one diagnostics area to pop; this occurs due to an exception for which there
# 			are no appropriate handlers or due to RETURN in the handler.
#
# 			Any warning or error conditions in the popped diagnostics areas then are added to the
# 			current diagnostics area, except that, for triggers, only errors are added.
#
# 			When the stored program ends, the caller sees these conditions in its current
# 			diagnostics area.
#
# 		) Execution of a condition handler within a stored program
#
# 			When a push occurs as a result of condition handler activation, the stacked
# 			diagnostics area is the area that was current within the stored program
# 			prior to the push.
#
# 			The new now-current diagnostics area is the handler's current diagnostics area.
#
# 			GET_[CURRENT]_DIAGNOSTICS and GET_STACKED_DIAGNOSTICS can be used within the
# 			handler to access the contents of the current (handler) and stacked (stored program)
# 			diagnostics areas.
#
# 			Initially, they return the same result, but statements executing within the
# 			handler modify the current diagnostics area, clearing and setting its contents
# 			according to the normal rules (see HOW THE DIAGNOSTICS AREA IS CLEARED AND POPULATED)
#
# 			The stacked diagnostics area cannot be modified by statements executing within the
# 			handler except RESIGNAL.
#
# 			If the handler executes successfully, the current (handler) diagnostics area is popped
# 			and the stacked (stored program) diagnostics area again becomes the current diagnostics area.
#
# 			Conditions added to the handler diagnostics area during handler execution are added to the
# 			current diagnostics area.
#
# 		) Execution of RESIGNAL
#
# 			The RESIGNAL statement passes on the error condition information that is available during
# 			execution of a condition handler within a compound statement inside a stored program.
#
# 			RESIGNAL may change some or all information before passing it on, modifying the diagnostics
# 			stack as described in SECTION 13.6.7.4, "RESIGNAL SYNTAX"
#
# DIAGNOSTICS AREA-RELATED SYSTEM VARIABLES
#
# Certain system variables control or are related to some aspects of the diagnostics area:
#
# 		) max_error_count controls the number of condition areas in the diagnostics area.
#
# 			If more conditions than this occur, MySQL silently discards information for the excess
# 			conditions.
#
# 			(Conditions added by RESIGNAL are always added, with older conditions being discarded
# 			as necessary to make room)
#
# 		) warning_count indicates the number of conditions that occurred.
#
# 			This includes errors, warnings, and notes.
#
# 			Normally, NUMBER and warning_count are teh same.
#
# 			However, as the number of conditions generated exceeds max_error_count,
# 			the value of warning_count continues to rise whereas NUMBER remains capped
# 			at max_error_count because no additional conditions are stored in the
# 			diagnostics area.
#
# 		) error_count indicates the number of errors that occurred.
#
# 			This value includes "not found" and exception conditions, but excludes
# 			warnings and notes.
#
# 			Like warning_count, its value can exceed max_error_count
#
# 		) If the sql_notes system variable is set to 0, notes are not stored and do
# 			not increment warning_count
#
# Example:
#
# 		If max_error_count is 10, the diagnostics area can contain a maximum of 10 condition areas.
#
# 		Suppose that a statement raises 20 conditions, 12 of which are errors.
#
# 		In that case, the diagnostics area contains the first 10 conditions, NUMBER
# 		is 10, warning_count is 20 and error_count is 12.
#
# Changes to the value of max_error_count have no effect until the next attempt to
# modify the diagnostics area.
#
# If the diagnostics area contains 10 condition areas and max_error_count is set
# to 5, that has no immediate effect on the size or content of the diagnostics area.
#
# 13.6.7.8 CONDITION HANDLING AND OUT OR INOUT PARAMETERS
#
# If a stored procedure exits with an unhandled exception, modified values of OUT and
# INOUT parameters are not propogated back to the caller.
#
# If an exception is handled by a CONTINUE or EXIT handler that contains a RESIGNAL
# statement, execution of RESIGNAL pops the Diagnostics Area stack, thus signalling the
# exception (that is, the information that existed before entry into the handler)
#
# If the exception is an error, the values of OUT and INOUT parameters are not propogated
# back to the caller.
#
# 13.7 DATABASE ADMINISTRATION STATEMENTS
#
# 13.7.1 ACCOUNT MANAGEMENT STATEMENTS
# 13.7.2 RESOURCE GROUP MANAGEMENT STATEMENTS
#
# 13.7.3 TABLE MAINTENANCE STATEMENTS
# 13.7.4 COMPONENT, PLUGIN, AND USER-DEFINED FUNCTION STATEMENTS
#
# 13.7.5 SET SYNTAX
# 13.7.6 SHOW SYNTAX
#
# 13.7.7 OTHER ADMINISTRATIVE STATEMENTS
#
# 13.7.1 ACCOUNT MANAGEMENT STATEMENTS
#
# 13.7.1.1 ALTER USER SYNTAX
# 13.7.1.2 CREATE ROLE SYNTAX
#
# 13.7.1.3 CREATE USER SYNTAX
# 13.7.1.4 DROP ROLE SYNTAX
#
# 13.7.1.5 DROP USER SYNTAX
# 13.7.1.6 GRANT SYNTAX
#
# 13.7.1.7 RENAME USER SYNTAX
# 13.7.1.8 REVOKE SYNTAX
#
# 13.7.1.9 SET DEFAULT ROLE SYNTAX
# 13.7.1.10 SET PASSWORD SYNTAX
#
# 13.7.1.11 SET ROLE SYNTAX
#
# MySQL account information is stored in teh tables of the mysql system database.
#
# This database and the access control system are discussed extensively in
# CHAPTER 5, MYSQL SERVER ADMINISTRATION, which you should consult for additional details.
#
# IMPORTANT:
#
# 		Some MySQL releases introduce changes to the grant tables to add new privileges
# 		or features.
#
# 		To make sure that you can take advantage of any new capabilities, update your
# 		grant tables to the current structure whenever you upgrade MySQL.
#
# 		See SECTION 4.4.5, "MYSQL_UPGRADE -- CHECK AND UPGRADE MYSQL TABLES"
#
# When the read_only system variable is enabled, account-management statements
# require the CONNECTION_ADMIN or SUPER privilege, in addition to any other
# required privileges.
#
# This is because they modify tables in the mysql system database
#
# Account management statements are atomic and crash safe.
#
# For more information, see SECTION 13.1.1, "ATOMIC DATA DEFINITION STATEMENT SUPPORT"
#
# 13.7.1.1 ALTER USER SYNTAX
#
# 	ALTER USER [IF EXISTS]
# 		user [auth_option] [, user [auth_option]] ---
# 		[REQUIRE {NONE | tls_option [[AND] tls_option] ---}]
# 		[WITH resource_option [resource_option] ---]
# 		[password_option | lock_option] ---
#
# 	ALTER USER [IF EXISTS] USER() user_func_auth_option
#
# 	ALTER USER [IF EXISTS]
# 		user DEFAULT ROLE
# 		{NONE | ALL | role [, role ] ---}
#
# 	user:
# 		(see Section 6.2.4, "Specifying Account Names")
#
# 	auth_option: {
# 		IDENTIFIED BY 'auth_string'
# 			[REPLACE 'current_auth_string']
# 			[RETAIN CURRENT_PASSWORD]
# 	 | IDENTIFIED WITH auth_plugin
# 	 | IDENTIFIED WITH auth_plugin BY 'auth_string'
# 			[REPLACE 'current_auth_string']
# 			[RETAIN CURRENT PASSWORD]
# 	 | IDENTIFIED WITH auth_plugin AS 'hash_string'
# 	 | DISCARD OLD PASSWORD
# }
#
# user_func_auth_option: {
# 		IDENTIFIED BY 'auth_string'
# 			[REPLACE 'current_auth_string']
# 			[RETAIN CURRENT PASSWORD]
# 	 | DISCARD OLD PASSWORD
# }
#
# tls_option: {
# 	 SSL
# | X509
# | CIPHER 'cipher'
# | ISSUER 'issuer'
# | SUBJECT 'subject'
# }
#
# resource_option: {
# 		MAX_QUERIES_PER_HOUR count
#   | MAX_UPDATES_PER_HOUR count
#   | MAX_CONNECTIONS_PER_HOUR count
# 	 | MAX_USER_CONNECTIONS count
# }
#
# password_option: {
# 		PASSWORD EXPIRE [DEFAULT | NEVER | INTERVAL N DAY]
# 	 | PASSWORD HISTORY {DEFAULT | N}
#   | PASSWORD REUSE INTERVAL {DEFAULT | N DAY}
#   | PASSWORD REQUIRE CURRENT [DEFAULT | OPTIONAL]
# }
#
# lock_option: {
# 		ACCOUNT LOCK
#   | ACCOUNT UNLOCK
# }
#
# The ALTER_USER statement modifies MySQL accounts.
#
# It enables authentication, role, SSL/TLS, resource-limit and password-management
# properties to be modified for existing accounts.
#
# It can also be used to lock and unlock accounts.
#
# In most cases, ALTER_USER requires the global CREATE_USER privilege, or the UPDATE
# privilege for the mysql system database.
#
# The exceptions are:
#
# 		) Any client who connects to the server using a nonanonymous account can change the password
# 			for that account.
#
# 			(In particular, you can change your own password)
#
# 			To see which account the server authenticated you as, invoke the CURRENT_USER() function:
#
# 				SELECT CURRENT_USER();
#
# 		) For DEFAULT ROLE syntax, ALTER_USER requires these privileges:
#
# 			) Setting the default roles for another user requires the global CREATE_USER
# 				privilege, or the UPDATE privilege for the mysql.default_roles system table.
#
# 			) Setting the default roles for yourself requires no special privileges, as long 
# 				as the roles you want as the default have been granted to you.
#
# 		) Statements that modify secondary passwords require these privileges:
#
# 			) The APPLICATION_PASSWORD_ADMIN privilege is required to use the RETAIN CURRENT PASSWORD
# 				or DISCARD OLD PASSWORD clause for ALTER_USER statements that apply to your own account.
#
# 				The privilege is required to manipulate your own secondary password because most users
# 				require only one password.
#
# 			) If an account is to be permitted to manipulate secondary passwords for all accounts,
# 				it should be granted the CREATE_USER privilege rather than APPLICATION_PASSWORD_ADMIN
#
# When the read_only system variable is enabled, ALTER_USER additionally requires the CONNECTION_ADMIN
# or SUPER privilege.
#
# By default, an error occurs if you try to modify a user that does not exist.
#
# If the IF EXISTS clause is given, the statement produces a warning for each named user that
# does not exist, rather than an error.
#
# 	IMPORTANT:
#
# 		Under some circumstances, ALTER_USER may be recorded in server logs or on the client
# 		side in a history file such as ~/.mysql_history, which means that cleartext passwords
# 		may be read by anyone having read access to that information.
#
# 		For information about the conditions under which this occurs for the server logs
# 		and how to control it, see SECTION 6.1.2.3, "PASSWORDS AND LOGGING"
#
# 		For similar information about client-side logging, see SECTION 4.5.1.3, "MYSQL CLIENT LOGGING"
#
# There are several aspects to the ALTER_USER statement, described under the following topics:
#
# 		) ALTER USER OVERVIEW
#
# 		) ALTER USER AUTHENTICATION OPTIONS
#
# 		) ALTER USER ROLE OPTIONS
#
# 		) ALTER USER SSL/TLS OPTIONS
#
# 		) ALTER USER RESOURCE-LIMIT OPTIONS
#
# 		) ALTER USER PASSWORD-MANAGEMENT OPTIONS
#
# 		) ALTER USER ACCOUNT-LOCKING OPTIONS
#
# 		) ALTER USER BINARY LOGGING
#
# ALTER USER OVERVIEW
#
# For each affected account, ALTER_USER modifies the corresponding row in the mysql.user
# system table to reflect the properties specified in the statement.
#
# Unspecified properties retain their current values.
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# The host name part of the account name, if omitted, defaults to '%'
#
# It is also possible to specify CURRENT_USER or CURRENT_USER() to refer to the account
# associated with the current session.
#
# For one syntax only, the account may be specified with the USER() function:
#
# 		ALTER USER USER() IDENTIFIED BY 'auth_string';
#
# This syntax enables changing your own password without naming your account literally.
#
# (The syntax also supports the REPLICATE RETAIN CURRENT PASSWORD, and DISCARD OLD PASSWORD
# clauses described at ALTER USER AUTHENTICATION OPTIONS)
#
# For ALTER_USER syntaxes that permit an auth_option value to follow a user value,
# auth_option indicates how the account authenticates by specifying an account authentication
# plugin, credentials (for example, a password), or both.
#
# Each auth_option value applies only to the account named immediately preceding it.
#
# Following the user specifications, the statement may include options for SSL/TLS,
# resource-limit, password-management, and locking properties.
#
# All such options are global to the statement and apply to all accounts named
# in the statement.
#
# Example:
#
# 		Change an account's password and expire it. As a result, the user must connect with
# 		the named password and choose a new one at the next connection:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED BY 'new_password' PASSWORD EXPIRE;
#
# Example:
#
# 		Modify an account to use the sha256_password authentication plugin and the given
# 		password.
#
# 		Require that a new password be chosen every 180 days:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH sha256_password BY 'new_password'
# 				PASSWORD EXPIRE INTERVAL 180 DAY;
#
# Example:
#
# 		Lock or unlock an account
#
# 			ALTER USER 'jeffrey'@'localhost' ACCOUNT LOCK;
# 			ALTER USER 'jeffrey'@'localhost' ACCOUNT UNLOCK;
#
# Example:
#
# 		Require an account to connect using SSL and establish a limit of 20 connections per hour:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				REQUIRE SSL WITH MAX_CONNECTIONS_PER_HOUR 20;
#
# Example:
#
# 		Alter multiple accounts, specifying some per-account properties and some global properties:
#
# 			ALTER USER
# 				'jeffrey'@'localhost'
# 					IDENTIFIED BY 'jeffrey_new_password',
# 				'jeanne'@'localhost',
# 				'josh'@'localhost'
# 					IDENTIFIED BY 'josh_new_password'
# 					REPLACE 'josh_current_password'
# 					RETAIN CURRENT PASSWORD
# 				REQUIRE SSL WITH MAX_USER_CONNECTIONS 2
# 				PASSWORD HISTORY 5;
#
# The IDENTIFIED BY value following jeffrey applies only to its immediately preceeding
# account, so it changes the password to 'jeffrey_new_password' only for jeffrey.
#
# For jeanne, there is no per-account value (thus leaving the password unchanged)
#
# For josh, IDENTIFIED BY establishes a new password ('josh_new_password'), REPLACE
# is specified to verify that hte user issuing the ALTER_USER statement knows the
# current password ('josh_current_password'), and that current password is also retained
# as the account secondary password.
#
# (As a result, josh can connect with either the primary or secondary password)
#
# The remaining properties apply globally to all accounts named in the statement,
# so for both accounts:
#
# 		) Connections are required to use SSL
#
# 		) The account can be used for a maximum of two simultaneous connections
#
# 		) Password changes cannot reuse any of the five most recent PWs
#
# Example:
#
# 		Discard the secondary password for josh, leaving the account with only
# 		its primary password:
#
# 			ALTER USER 'josh'@'localhost' DISCARD OLD PASSWORD;
#
# In the absence of a particular type of option, the account remains unchanged
# in that respect.
#
# FOr example, with no locking option, the locking state of the account is not
# changed.
#
# ALTER USER AUTHENTICATION OPTIONS
#
# An account name may be followed by an auth_option authentication option that specifies
# the account authentication plugin, credentials or both.
#
# It may also include a password-verification clause that specifies the account current password
# to be replaced, and clauses that manage whether an account has a seondary password.
#
# NOTE:
#
# 		Clauses for password verification and secondary passwords apply only to accounts that
# 		store credentials internally in the mysql.user system table
#
# 		(mysql_native_password, sha256_password, or caching_sha2_password)
#
# 		For accounts that use plugins that perform authentication against an
# 		external credential system, password management must be handled externally
# 		against the system as well.
#
# 	) auth_plugin names an authentication plugin.
#
# 		The plugin name can be a quoted string literal or an unquoted name.
#
# 		Plugin names are stored in the plugin column of the mysql.user system system table.
#
# 		For auth_option syntaxes that do not specify an authentication plugin, the default
# 		plugin is indicated by the value of the default_authentication_plugin system
# 		variable.
#
# 		For descriptions of each plugin, see SECTION 6.5.1, "AUTHENTICATION PLUGINS"
#
# 	) Credentials are stored in the mysql.user system table.
#
# 		An 'auth_string' or 'hash_string' value specifies account credentials, either
# 		as a cleartext (unencrypted) string or hashed in the format except by the
# 		authentication plugin associated with the account, respectively:
#
# 			) For syntaxes that use 'auth_string', the string is cleartext and is passed
# 				to the authentication plugin for possible hashing.
#
# 				The result returned by the plugin is stored in the mysql.user table
#
# 				A plugin may use the value as specified, in which case no hashing occurs.
#
# 			) For syntaxes that use 'hash_string', the string is assumed to be already
# 				hashed in the format required by the authentication plugin.
#
# 				If the hash format is inappropriate for the plugin, it will not be usable
# 				and correct authentication of client connections will not occur.
#
# 	) The REPLACE 'current_auth_string' clause is available as of MySQL 8.0.13
#
# 		If given:
#
# 			) REPLACE specifies the account current password to be replaced, as a cleartext (unencrypted) string
#
# 			) The clause must be given if password changes for the are required to specify the current password,
# 				as verification that the user attempting to make the change actually knows the current PW.
#
# 			) THe clause is optional if password changes for the account may but need not specify the current password
#
# 			) The statement fails if the clause is given but does not match the current password, even if the clause is optional
#
# 			) REPLACE can be specified only when changing the account password for the current user
#
# 		For more information about password verification by specifying the current password, see SECTION 6.3.8, "PASSWORD MANAGEMENT"
#
# 	) The RETAIN CURRENT PASSWORD and DISCARD OLD PASSWORD clauses implement dual-password capability
# 		and are available as of MySQL 8.0.14
#
# 		Both are optional, but if given, have the following effects:
#
# 			) RETAIN CURRENT PASSWORD retains an account current password as its secondary password,
# 				replacing any existing secondary password.
#
# 				The new password becomes the primary password, but clients can use the account to connect
# 				to the server using either the primary or secondary password.
#
# 				(Exception: if the new password specified by the ALTER_USER statement is empty, the secondary
# 					password becomes empty as well, even if RETAIN CURRENT PASSWORD is given)
#
# 			) If you specify RETAIN CURRENT PASSWORD for an account that has an empty primary password, the statement fails
#
# 			) If an account has a secondary password and you change its primary password without specifying
# 				RETAIN CURRENT PASSWORD, the secondary password remains unchanged.
#
# 			) If you change the authentication plugin assigned to the account, the secondary password is discarded.
#
# 				If you change the authentication plugin and also specify RETAIN CURRENT PASSWORD, the statement fails.
#
# 			) DISCARD OLD PASSWORD discards the secondary password, if one exists.
#
# 				The account retains only its primary password, and clients can use the account
# 				to connect to the server only with the primary password.
#
# 		FOr more information about use of dual passwords, see SECTION 6.3.8, "PASSWORD MANAGEMENT"
#
# ALTER_USER permits these auth_option syntaxes:
#
# 		) IDENTIFIED BY 'auth_string' [REPLACE 'current_auth_string'] [RETAIN CURRENT PASSWORD]
#
# 			Sets the account authentication plugin to the default plugin, passes the cleartext 
# 			'auth_string' value to the plugin for hashing, and stores the result in the account
# 			row in the mysql.user system table.
#
# 			The REPLACE clause, if given, specifies the account current password, as described
# 			previously in this section.
#
# 			The RETAIN CURRENT PASSWORD clause, if given, causes the account current password 
# 			to be retained as its secondary password, as described previously in this section.
#
# 		) IDENTIFIED WITH auth_plugin
#
# 			Sets the account authentication plugin to auth_plugin, clears the credentials
# 			to the empty string (the credentials are associated with the old authentication
# 			plugin, not the new one), and stores the result in the account row in the mysql.user
# 			system table
#
# 			In addition, the password is marked expired.
#
# 			the user must choose a new one when next connecting
#
# 		) IDENTIFIED WITH auth_plugin BY 'auth_string' [REPLACE 'current_auth_string'] [RETAIN CURRENT PASSWORD]
#
# 			Sets the account authentication plugin to auth_plugin, passes the cleartext 'auth_string'
# 			value to the plugin for hashing, and stores the result in the account row
# 			in the mysql.user system table
#
# 			The REPLACE clause, if given, specifies the account current password, as described
# 			previously in this section
#
# 			The RETAIN CURRENT PASSWORD clause, if given, causes the account current password
# 			to be retained as its secondary password, as described previously in this section.
#
# 		) IDENTIFIED WITH auth_plugin AS 'hash_string'
#
# 			Sets the account authentication plugin to auth_plugin and stores the hashed
# 			'hash_string' value as in the mysql.user account row.
#
# 			The string is assumed to be already hashed in the format required by the plugin
#
# 		) DISCARD OLD PASSWORD
#
# 			Discards the account secondary password, if there is one, as described previously
#
# Example:
#
# 		Specify the password as cleartext; the default plugin is used:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED BY 'password';
#
# Example:
#
# 		Specify the authentication plugin, along with a cleartext password value:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH mysql_native_password
# 								BY 'password';
#
# Example:
#
# 		Like the preceding example, but in addition, specify the current password as a cleartext
# 		value to satisfy any account requirement that the user making the change knows that password:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH mysql_native_password
# 								BY 'password'
# 								REPLACE 'current_password';
#
# 		The preceding statement fails unless the current user is jeffrey because REPLACE is permitted
# 		only for changes to the current user's password.
#
# Example:
#
# 		Establish a new primary password and retain the existing password as the secondary password:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED BY 'new_password'
# 				RETAIN CURRENT PASSWORD;
#
# Example:
#
# 		Discard the secondary password, leaving the account with only its primary password:
#
# 			ALTER USER 'jeffrey'@'localhost' DISCARD OLD PASSWORD;
#
# Example:
#
# 		Specify the authentication plugin, along with a hashed password value:
#
# 			ALTER USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH mysql_native_password
# 					AS '<value>';
#
# For additional information about setting passwords and authentication plugins,
# see SECTION 6.3.7, "ASSIGNING ACCOUNT PASSWORDS" and SECTION 6.3.10, "PLUGGABLE AUTHENTICATION"
#
# ALTER USER ROLE OPTIONS
#
# ALTER_USER_---_DEFAULT_ROLE defines which roles become active when the user connects to the server
# and authenticates, or when the user executes the SET_ROLE_DEFAULT statement during a session.
#
# ALTER_USER_---_DEFAULT_ROLE is alternative syntax for SET_DEFAULT_ROLE (see SECTION 13.7.1.9, "SET DEFAULT ROLE SYNTAX")
#
# However, ALTER_USER can set the default for only a single user, whereas SET_DEFAULT_ROLE can set the
# default for multiple users.
#
# On the other hand, you can specify CURRENT_USER as the user name for the
# ALTER_USER statement, whereas you cannot for SET_DEFAULT_ROLE
#
# Each user account name uses the format described previously.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		ALTER USER 'joe'@'10.0.0.1' DEFAULT ROLE administrator, developer;
#
# The host name part of the role name, if omitted, defaults to '%'
#
# The clause following the DEFAULT ROLE keywords permites these values:
#
# 		) NONE: Set the default to NONE (no roles)
#
# 		) ALL: Set the default to all roles granted to the account
#
# 		) role [, role] ---. Set the default to the named roles, which must exist
# 			and be granted to the account at the time ALTER_USER_---_DEFAULT_ROLE
# 			is executed.
#
# ALTER USER SSL/TLS OPTIONS
#
# MySQL can check X.509 cert attributes in addition to the usual authentication
# that is based on the user name and credentials.
#
# For background information on the use of SSL/TLS with MySQL, see SECTION 6.4, "USING ENCRYPTED CONNECTIONS"
#
# To specify SSL/TLS-related options for a MySQL account, use a REQUIRE clause that specifies
# one or more tls_option values.
#
# Order of REQUIRE options does not matter, but no option can be specified twice.
#
# The AND keyword is optional between REQUIRE options.
#
# ALTER_USER permits these tls_option values:
#
# 		) NONE:
#
# 			Indicates that all accounts named by the statement have no SSL or X.509 requirements.
#
# 			Unencrypted connections are permitted if the user name and password are valid.
#
# 			Encrypted connections can be used, at the client's option, if the client has the proper
# 			certificate and key files.
#
# 				ALTER USER 'jeffrey'@'localhost' REQUIRE NONE;
#
# 			Clients attempt to establish a secure connection by default.
#
# 			For clients that have REQUIRE NONE, the connection attempt falls back to
# 			an unencrypted connection if a secure connection cannot be established.
#
# 			To require an encrypted connection, a client need specify only the --ssl-mode=REQUIRED
# 			option; the connection attempt fails if a secure connection cannot be established.
#
# 		) SSL:
#
# 			Tells the server to permit only encrypted connections for all accounts named by the
# 			statement.
#
# 				ALTER USER 'jeffrey'@'localhost' REQUIRE SSL;
#
# 			Clients attempt to establish a secure connection by default. For accounts that have
# 			REQUIRE SSL, the connection attempt fails if a secure connection cannot be
# 			established.
#
# 		) X509
#
# 			For all accounts named by the statement, requires that clients present a valid certificate,
# 			but the exact certificate, issuer and subject do not matter.
#
# 			The only requirement is that it should be possible to verify its signature with one of
# 			the CA certificates.
#
# 			Use of X.509 certificates always implies encryption, so the SSL option is unnecessary
# 			in this case.
#
# 				ALTER USER 'jeffrey'@'localhost' REQUIRE X509;
#
# 			For accounts with REQUIRE X509, clients must specify the --ssl-key and --ssl-cert
# 			options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified so that the
# 			public certificate provided by the server can be verified)
#
# 			This is true for ISSUER and SUBJECT as well because those REQUIRE options imply the
# 			requirements of X509
#
# 		) ISSUER 'issuer'
#
# 			For all accounts named by the statement, requires that clients present a valid X.509
# 			certificate issued by CA 'issuer'.
#
# 			If a client presents a certificate that is valid but has a different issuer;
# 			the server rejects the connection.
#
# 			Use of X.509 certificates always implies encryption, so the SSL option is
# 			unnecessary in this case.
#
# 				ALTER USER 'jeffrey'@'localhost'
# 					REQUIRE ISSUER '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL/CN=CA/emailAddress=ca@example.com';
#
# 			Because ISSUER implies the requirements of X509, clients must specify
# 			the --ssl-key and --ssl-cert options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified
# 			so that the public certificate provided by the server can be verified)
#
# 		) SUBJECT 'subject'
#
# 			For all accounts named by the statement, requires that clients present a valid
# 			X.509 certificate containing the subject subject.
#
# 			If a client presents a certificate that is valid but has a different subject,
# 			the server rejects the connection.
#
# 			Use of X.509 certificates always implies encryption, so the SSL option is unnecessary
# 			in this case.
#
# 				ALTER USER 'jeffrey'@'localhost'
# 					REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL demo client certificate/
# 						CN=client/emailAddress=client@example.com';
#
# 			MySQL does a simple string comparison of the 'subject' value to the value
# 			in the certificate, so lettercase and component ordering must be given
# 			exactly as present in the certificate.
#
# 			Because SUBJECT implies the requirements of X509, clients must specify the
# 			--ssl-key and --ssl-cert options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified so that
# 			the public certificate provided by the server can be verified.)
#
# 		) CIPHER 'cipher'
#
# 			For all accounts named by the statement, requires a specific cipher method
# 			for encrypting connections.
#
# 			This option is needed to ensure that ciphers and key lengths of sufficient
# 			strength are used.
#
# 			Encryption can be weak if old algorithms using short encryption keys are used.
#
# 				ALTER USER 'jeffrey'@'localhost'
# 					REQUIRE CIPHER 'EDH-RSA-DES-CBC3-SHA';
#
# 			The SUBJECT, ISSUER and CIPHER options can be combined in the REQUIRE clause:
#
# 				ALTER USER 'jeffrey'@'localhost'
# 					REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL demo client certificate/
# 						CN=client/emailAddress=client@example.com'
# 					AND ISSUER '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL/CN=CA/emailAddress=ca@example.com'
# 					AND CIPHER 'EDH-RSA-DES-CBC3-SHA';
#
# ALTER USER RESOURCE-LIMIT OPTIONS
#
# It is possible to place limits on use of server resources by an account, as discussed
# in SECTION 6.3.6, "SETTING ACCOUNT RESOURCE LIMITS"
#
# To do so, use a WITH clause that specifies one or more resource_option values.
#
# Order of WITH options does not matter, except that if a given resource limit is
# specified multiple times, the last instance takes precedence.
#
# ALTER_USER permits these resource_option values:
#
# 		) MAX_QUERIES_PER_HOUR count, MAX_UPDATES_PER_HOUR count, MAX_CONNECTIONS_PER_HOUR count
#
# 			For all accounts named by the statement, these options restrict how many queries,
# 			updates and connections to the server are permitted to each account during any
# 			given one-hour period.
#
# 			If count is 0 (the default), this means that there is no limitation for the account.
#
# 		) MAX_USER_CONNECTIONS count
#
# 			For all accounts named by the statement, restricts the maximum number of simultaneous
# 			connections to the server by each account.
#
# 			A nonzero count specifies the limit for the account explicitly.
#
# 			If count is 0 (the default), the server determines the number of simultaneous
# 			connections for the account from the global value of the max_user_connections
# 			system variable.
#
# 			If max_user_connections is also zero, there is no limit for the account.
#
# 			Example:
#
# 				ALTER USER 'jeffrey'@'localhost'
# 					WITH MAX_QUERIES_PER_HOUR 500 MAX_UPDATES_PER_HOUR 100;
#
# ALTER USER PASSWORD-MANAGEMENT OPTIONS
#
# ALTER_USER supports several password_option values for password management:
#
# 		) Password expiration options: You can expire an account password manually and establish
# 			its password expiration policy.
#
# 			Policy options do not expire the password.
#
# 			Instead, they determine how the server applies automatic expiration to the
# 			account based on password age, which is assessed from the date and time of
# 			the most recent account password change.
#
# 		) Password reuse options: You can restrict password reuse based on number of password
# 			changes, time elapsed or both.
#
# 		) Password verification-required options: You can indicate whether attempts to change an
# 			account password must specify the current password, as verification that the
# 			user attempting to make the change actually knows the current password.
#
# This section describes the syntax for password-management options. For information about
# establishing policy for password management, see SECTION 6.3.8, "PASSWORD MANAGEMENT"
#
# If multiple password-management options of a given type (PASSWORD EXPIRE, PASSWORD HISTORY,
# PASSWORD REUSE INTERVAL, PASSWORD REQUIRE) are specified, the last one takes precedence.
#
# 		NOTE:
#
# 			Password-management options apply only to accounts that store credentials internally
# 			in the mysql.user system table (mysql_native_password, sha256_password,
# 			or caching_sha2_password)
#
# 			For accounts that use plugins that perform authentication against an external
# 			credential system, password management must be handled externally against that
# 			system as well.
#
# A client has an expired password if the account password was expired manually or the password
# age is considered greater than its permitted lifetime per the automatic expiration policy.
#
# In this case, the server either disconnects the client or restricts the operations permitted
# to it (see SECTION 6.3.9, "SERVER HANDLING OF EXPIRED PASSWORDS")
#
# Operations performed by a restricted client result in an error until the user establishes
# a new account password.
#
# NOTE:
#
# 		It is possible to "reset" a password by setting it to its current value.
#
# 		As a matter of good policy, it is preferable to choose a different password.
#
# 		DBAs can enforce non-reuse by establishing an appropriate password-reuse policy.
#
# 		See PASSWORD REUSE POLICY
#
# ALTER_USER permits these password_option values for controlling password expiration:
#
# 		) PASSWORD EXPIRE
#
# 			Immediately marks the password expired for all accounts named by the statement.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE;
#
# 		) PASSWORD EXPIRE DEFAULT
#
# 			Sets all accounts named by the statement so that the global expiration
# 			policy applies, as specified by the default_password_lifetime system variable.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;
#
# 		) PASSWORD EXPIRE NEVER
#
# 			This expiration option overrides the global policy for all accounts named by the
# 			statement.
#
# 			For each, it disables password expiration so that the password never expires.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;
#
# 		) PASSWORD EXPIRE INTERVAL N DAY
#
# 			This expiration option overrides the global policy for all accounts named
# 			by the statement.
#
# 			For each, it sets the password lifetime to N days.
#
# 			The following statement requires the password to be changed every 180 days:
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 180 DAY;
#
# ALTER_USER permits these password_option values for controlling reuse of previous passwords
# based on required minimum number of password changes:
#
# 		) PASSWORD HISTORY DEFAULT
#
# 			Sets all acounts named by the statement so that the global policy about password
# 			history length applies, to prohibit reuse of passwords before the number of
# 			changes specified by the password_history system variable.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD HISTORY DEFAULT;
#
# 		) PASSWORD HISTORY N
#
# 			This history-length option overrides the global policy for all accounts
# 			named by the statement.
#
# 			For each, it sets the password history length to N passwords, to prohibit
# 			reusing any of the N most recently chosen passwords.
#
# 			The following statement prohibits reuse of any of the previous 6 passwords:
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD HISTORY 6;
#
# ALTER_USER permits these password_option values for controlling reuse of previous
# passwords based on time elapsed:
#
# 		) PASSWORD REUSE INTERVAL DEFAULT
#
# 			Sets all statements named by the account so that the global policy about time
# 			elapsed applies, to prohibit reuse of passwords newer than the number of days
# 			specified by the password_reuse_interval system variable.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL DEFAULT;
#
# 		) PASSWORD REUSE INTERVAL N DAY
#
# 			This time-elapsed option overrides the global policy for all accounts named
# 			by the statement.
#
# 			For each, it sets the password reuse interval to N days, to prohibit reuse
# 			of passwords newer than that many days.
#
# 			The following statement prohibits password reuse for 360 days:
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 360 DAY;
#
# ALTER_USER permits these password_option values for controlling whether attempts to
# change an account password must specify the current password, as verification
# that the user attempting to make the change actually knows the current password:
#
# 		) PASSWORD REQUIRE CURRENT
#
# 			This verification option overrides the global policy for all accounts named
# 			by the statement.
#
# 			For each, it requires that password changes specify the current password.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;
#
# 		) PASSWORD REQUIRE CURRENT OPTIONAL
#
# 			This verification option overrides the global policy for all accounts named by
# 			the statement.
#
# 			For each, it does not require that password changes specify the current
# 			password.
#
# 			(The current password may but need not be given)
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;
#
# 		) PASSWORD REQUIRE CURRENT DEFAULT
#
# 			Sets all statements named by the account so that the global policy
# 			about password verification applies, as specified by the password_require_current
# 			system variable.
#
# 				ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;
#
# ALTER USER ACCOUNT-LOCKING OPTIONS
#
# MySQL supports account locking and unlocking using the ACCOUNT LOCK and ACCOUNT UNLOCK
# options, which specify the locking state for an account.
#
# For additional discussion, see SECTION 6.3.12, "USER ACCOUNT LOCKING"
#
# If multiple account-locking options are specified, the last one takes precedence.
#
# ALTER USER BINARY LOGGING
#
# ALTER_USER is written to the binary log if it succeeds, but not if it fails; in that
# case, rollback occurs and no changes are made.
#
# A statement written to the binary log includes all named users.
#
# If the IF EXISTS clause is given, this includes even users that do not exist
# and were not altered.
#
# If the original statement changes the credentials for a user, the statement
# written to the binary log specifies the applicable authentication plugin for
# that user, determined as follows:
#
# 		) The plugin named in the original statement, if one was specified.
#
# 		) Otherwise, the plugin associated with the user account if the user exists,
# 			or the default authentication plugin if the user does not exist.
#
# 			(If the statement written to the binary log must specify a particular
# 			authentication plugin for a user, include it in the original statement)
#
# If the server adds the default authentication plugin for any users in the statement
# written to the binary log, it writes a warning to the error log naming those users.
#
# 13.7.1.2 CREATE ROLE SYNTAX
#
# 		CREATE ROLE [IF NOT EXISTS] role [, role] ---
#
# CREATE_ROLE creates one or more roles, which are named collections of privileges.
#
# To use this statement, you must have the global CREATE_ROLE or CREATE_USER privilege.
#
# When the read_only system variable is enabled, CREATE_ROLE additionally requires the
# CONNECTION_ADMIN or SUPER privilege.
#
# A role when created is locked, has no passwords, and is assigned the default authentication plugin.
#
# CREATE_ROLE either succeeds for all named roles or rolls back and has no effect if any error
# occurs.
#
# By default, an error occurs if you try to create a role that already exists.
#
# If the IF NOT EXISTS clause is given, the statement produces a warning for each named
# role that already exists, rather than an error.
#
# The statement is written to the binary log if it succeeds, but not if it fails; in that case,
# rollback occurs and no changes are made.
#
# A statement written to the binary log includes all named roles.
#
# If the IF NOT EXISTS clause is given, this includes even roles that already
# exist and were not created.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		CREATE ROLE 'administrator', 'developer';
# 		CREATE ROLE 'webapp'@'localhost';
#
# The host name part of the role name, if omitted, defaults to '%'
#
# For role usage examples, see SECTION 6.3.4, "USING ROLES"
#
# 13.7.1.3 CREATE USER SYNTAX
#
# 		CREATE USER [IF NOT EXISTS]
# 			user [auth_option] [, user [auth_option]] ---
# 			DEFAULT ROLE role [, role ] ---
# 			[REQUIRE {NONE | tls_option [[AND] tls_option] ---}]
# 			[WITH resource_option [resource_option] ---]
# 			[password_option | lock_option] ---
#
# 		user:
# 			(see Section 6.2.4, "SPECIFYING ACCOUNT NAMES")
#
# 		auth_option: {
# 			IDENTIFIED BY 'auth_string'
# 		 | IDENTIFIED WITH auth_plugin
# 		 | IDENTIFIED WITH auth_plugin BY 'auth_string'
# 		 | IDENTIFIED WITH auth_plugin AS 'hash_string'
# 		}
#
# 		tls_option: {
# 			SSL
# 		 | X509
# 		 | CIPHER 'cipher'
# 		 | ISSUER 'issuer'
# 		 | SUBJECT 'subject'
# 		}
#
# 		resource_option: {
# 			MAX_QUERIES_PER_HOUR count
# 		 | MAX_UPDATES_PER_HOUR count
# 		 | MAX_CONNECTIONS_PER_HOUR count
# 		 | MAX_USER_CONNECTIONS count
# 		}
#
# 		password_option: {
# 			PASSWORD EXPIRE [DEFAULT | NEVER | INTERVAL N DAY]
# 		 | PASSWORD HISTORY {DEFAULT | N}
# 		 | PASSWORD REUSE INTERVAL {DEFAULT | N DAY}
# 		 | PASSWORD REQUIRE CURRENT [DEFAULT | OPTIONAL]
# 		}
#
# 		lock_option: {
# 			ACCOUNT LOCK
# 		 | ACCOUNT UNLOCK
# 		}
#
# The CREATE_USER statement creates new MySQL accounts.
#
# It enables authentication, role, SSL/TLS, resource-limit, and password-management
# properties to be established for new accounts.
#
# It also controls whether accounts are initially locked or unlocked.
#
# To use CREATE_USER, you must have the global CREATE_USER privilege, or the
# INSERT privilege for the mysql system database.
#
# When the read_only system variable is enabled, CREATE_USER additionally requires
# the CONNECTION_ADMIN or SUPER privilege.
#
# CREATE_USER either succeeds for all named users or rolls back and has no effect
# if any error occurs.
#
# By default, an error occurs if you try to create a user that already exists.
#
# If the IF NOT EXISTS clause is given, the statement produces a warning for each
# named user that already exists, rather than an error.
#
# iMPORTANT:
#
# 		Under some circumstances,  CREATE_USER may be recorded in server logs or on the
# 		client side in a history file such as ~/.mysql_history, which means that cleartext
# 		passwords may be read by anyone having read access to that information.
#
# 		For information about the conditions under which this occurs for the server
# 		logs and how to control it, see SECTION 6.1.2.3, "PASSWORDS AND LOGGING"
#
# 		For similar information about client-side logging, see SECTION 4.5.1.3,
# 		"MYSQL CLIENT LOGGING"
#
# There are several aspects to the CREATE_USER statement, described under the following
# topics:
#
# 		) CREATE USER OVERVIEW
#
# 		) CREATE USER AUTHENTICATION OPTIONS
#
# 		) CREATE USER ROLE OPTIONS
#
# 		) CREATE USER SSL/TLS OPTIONS
#
# 		) CREATE USER RESOURCE-LIMIT OPTIONS
#
# 		) CREATE USER PASSWORD-MANAGEMENT OPTIONS
#
# 		) CREATE USER ACCOUNT-LOCKING OPTIONS
#
# 		) CREATE USER BINARY LOGGING
#
# CREATE USER OVERVIEW
#
# For each account, CREATE_USER creates a new row in the mysql.user system table.
#
# The account row reflects the properties specified in the statement.
#
# Unspecified properties are set to their default values:
#
# 		) Authentication: The authentication plugin defined by the default_authentication_plugin
# 			system variable, and empty credentials.
#
# 		) Default role: NONE
#
# 		) SSL/TLS: NONE
#
# 		) Resource limits: Unlimited
#
# 		) Password management: PASSWORD EXPIRE DEFAULT PASSWORD HISTORY DEFAULT PASSWORD REUSE INTERVAL DEFAULT 
# 			PASSWORD REQUIRE CURRENT DEFAULT
#
# 		) Account locking: ACCOUNT UNLOCK
#
# An account when first created has no privileges and a default role of NONE.
#
# To assign privileges or roles, use the GRANT statement.
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# For example:
#
# 		CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';
#
# The host name part of the account name, if omitted, defaults to '%'
#
# Each user value naming an account may be followed by an optional auth_option value
# that indicates how the account authenticates.
#
# These values enable account authentication plugins and credentials (for example, a password)
# to be specified.
#
# Each auth_option value applies only to the account named immediately preceding it.
#
# Following the user specifications, the statement may include options for SSL/TLS, resource-limit,
# password-management, and locking properties.
#
# All such options are global to the statement and apply to all accounts named in the statement.
#
# Example:
#
# 		Create an account that uses the default authentication plugin and the given password.
#
# 		Mark the password expired so that the user must choose a new one at the first
# 		connection to the server:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				IDENTIFIED BY 'new_password' PASSWORD EXPIRE;
#
# Example:
#
# 		Create an account that uses the sha256_password authentication plugin and
# 		the given password.
#
# 		Require that a new password be chosen every 180 days:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH sha256_password BY 'new_password'
# 				PASSWORD EXPIRE INTERVAL 180 DAY;
#
# Example:
#
# 		Create multiple accounts, specifying some per-account properties
# 		and some global properties:
#
# 			CREATE USER
# 				'jeffrey'@'localhost' IDENTIFIED WITH mysql_native_password
# 															BY 'new_password1',
# 				'jeanne'@'localhost' IDENTIFIED WITH sha256_password
# 															BY 'new_password2'
# 				REQUIRE X509 WITH MAX_QUERIES_PER_HOUR 60
# 				PASSWORD HISTORY 5
# 				ACCOUNT LOCK;
#
# Each auth_option value (IDENTIFIED WITH --- BY in this case) applies only
# to the account named immediately preceding it, so each account uses
# the immediately following authentication plugin and password.
#
# The remaining properties apply globally to all accounts named in the statement,
# so for both accounts:
#
# 		) Connections must be made using a valid X.509 certificate
#
# 		) Up to 60 queries per hour are permitted.
#
# 		) Password changes cannot reuse any of the five most recent passwords
#
# 		) The account is locked initially, so effectively it is a placeholder and
# 			cannot be used until an administrator unlocks it.
#
# CREATE USER AUTHENTICATION OPTIONS
#
# An account name may be followed by an auth_option authentication option that
# specifies the account authentication plugin, credentials, or both:
#
# 		) auth_plugin names an authentication plugin. The plugin name can be a quoted
# 			string literal or an unquoted name.
#
# 			Plugin names are stored in the plugin column of the mysql.user system table
#
# 			For auth_option syntaxes that do not specify an authentication plugin,
# 			the default plugin is indicated by the value of the default_authentication_plugin
# 			system variable.
#
# 			For descriptions of each plugin, see SECTION 6.5.1, "AUTHENTICATION PLUGINS"
#
# 		) Credentials are stored in the mysql.user system table.
#
# 			An 'auth_string' or 'hash_string' value specifies account credentials,
# 			either as a cleartext (unencrypted) string or hashed in the format
# 			expected by the authentication plugin associated with the account, respectively:
#
# 				) For syntaxes that use 'auth_string', the string is cleartext and is passed
# 					to the authentication plugin for possible hashing.
#
# 					The result returned by the plugin is stored in the mysql.user
# 					table.
#
# 					plugin may use the value as specified, in which case no hashing occurs.
#
# 				) For syntaxes that use 'hash_string', the string is assumed to be already
# 					hashed in the format required by the authentication plugin.
#
# 					If the hash format is inappropriate for the plugin, it will not be usable
# 					and correct authentication of client connections will not occur.
#
# CREATE_USER permits these auth_option syntaxes:
#
# 		) IDENTIFIED BY 'auth_string'
#
# 			Sets the account authentication plugin to the default plugin, passes the cleartext
# 			'auth_string' value to the plugin for hashing, and stores the result in the account
# 			row in the mysql.user system table
#
# 		) IDENTIFIED WITH auth_plugin
#
# 			Sets the account authentication plugin to auth_plugin, clears the credentials
# 			to the empty string, and stores the result in the account row in the mysql.user
# 			system table.
#
# 		) IDENTIFIED WITH auth_plugin BY 'auth_string'
#
# 			Sets the account authentication plugin to auth_plugin, passes the cleartext
# 			'auth_string' value to the plugin for hashing, and stores the result in the
# 			account row in the mysql.user system table
#
# 		) IDENTIFIED WITH auth_plugin AS 'hash_string'
#
# 			Sets the account authentication plugin to auth_plugin and stores the hashed
# 			'hash_string' value as is in the mysql.user account row
#
# 			The string is assumed to be already hashed in the format required by the plugin
#
# Example:
#
# 		Specify the password as cleartext; the default plugin is used:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				IDENTIFIED BY 'password';
#
# Example:
#
# 		Specify the authentication plugin, along with a cleartext password value:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				IDENTIFIED WITH mysql_native_password BY 'password';
#
# In each case, the password value stored in the account row is the cleartext value
# 'password' after it has been hashed by the authentication plugin associated with
# the account.
#
# For additional information about setting passwords and authentication plugins,
# see SECTION 6.3.7, "ASSIGNING ACCOUNT PASSWORDS", and SECTION 6.3.10, "PLUGGABLE AUTHENTICATION"
#
# CREATE USER ROLE OPTIONS
#
# The DEFAULT ROLE clause defines which roles become active when the user connects to the server
# and authenticates, or when the user executes the SET_ROLE_DEFAULT statement during a session.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		CREATE USER 'joe'@'10.0.0.1' DEFAULT ROLE administrator, developer;
#
# The host name part of the role name, if omitted, defaults to '%'
#
# The DEFAULT ROLE clause permits a list of one or more comma-separated role names.
#
# These roles need not exist at the time CREATE_USER is executed
#
# CREATE USER SSL/TLS OPTIONS
#
# MySQL can check X.509 certificate attributes in addition to the usual authentication
# that is based on the user name and credentials.
#
# For background information on the use of SSL/TLS with MySQL, see SECTION 6.4, "USING ENCRYPTED CONNECTIONS"
#
# To specify SSL/TLS-related options for a MySQL account, use a REQUIRE clause that specifies
# one or more tls_option values.
#
# Order of REQUIRE options does not matter, but no option can be specified twice.
#
# The AND keyword is optional between REQUIRE options.
#
# CREATE_USER permits these tls_option values:
#
# 		) NONE
#
# 			Indicates that all accounts named by the statement have no SSL or X.509
# 			requirements.
#
# 			Unencrypted connections are permitted if the user name and password are
# 			valid.
#
# 			Encrypted connections can be used, at the client's option, if the client
# 			has the proper certificate and key files.
#
# 				CREATE USER 'jeffrey'@'localhost' REQUIRE NONE;
#
# 			Clients attempt to establish a secure connection by default.
#
# 			For clients that have REQUIRE NONE, the connection attempt falls
# 			back to an unencrypted connection if a secure connection cannot be
# 			established.
#
# 			To require an encrypted connection, a client need specify only the
# 			--ssl-mode=REQUIRED option; the connection attempt fails if a secure
# 			connection cannot be established.
#
# 			NONE is the default if no SSL-related REQUIRE options are specified
#
# 		) SSL
#
# 			Tells the server to permit only encrypted connections for all accounts
# 			named by the statement.
#
# 				CREATE USER 'jeffrey'@'localhost' REQUIRE SSL;
#
# 			Clients attempt to establish a secure connection by default.
#
# 			For accounts that have REQUIRE SSL, the connection attempt fails
# 			if a secure connection cannot be established.
#
# 		) X509
#
# 			For all accounts named by the statement, requires that clients present
# 			a valid certificate, but the exact certificate, issuer, and subject do
# 			not matter.
#
# 			The only requirement is that it be possible to verify its signature
# 			with one of the CA certificates.
#
# 			Use of X.509 certificates always implies encryption, so the SSL
# 			option is unnecessary in this case.
#
# 				CREATE USER 'jeffrey'@'localhost' REQUIRE X509;
#
# 			For accounts with REQUIRE X509, clients must specify the --ssl-key
# 			and --ssl-cert options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified
# 			so that the public certificate provided by the server can be verified)
#
# 			This is true for ISSUER and SUBJECT as well because those REQUIRE
# 			options imply the requirements of X509.
#
# 		) ISSUER 'issuer'
#
# 			For all accounts named by the statement, requires that clients present a valid
# 			X.509 certificate issued by CA 'issuer'
#
# 			If a client presents a certificate that is valid but has a different
# 			issuer, the server rejects the connection.
#
# 			Use of X.509 certificates always implies encryption, so the SSL option
# 			is unnecessary in this case.
#
# 				CREATE USER 'jeffrey'@'localhost'
# 					REQUIRE ISSUER '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL/CN=CA/emailAddress=ca@example.com';
#
# 			Because ISSUER implies the requirements of X509, clients must specify
# 			the --ssl-key and --ssl-cert options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified
# 				so that the public certificate provided by teh server can be verified)
#
# 		) SUBJECT 'subject'
#
# 			For all accounts named by the statement, requires that clients present a valid
# 			X.509 certificate containing the subject subject.
#
# 			If a client presents a certificate that is valid but has a different subject,
# 			the server rejects teh connection.
#
# 			Use of X.509 certificates always implies encryption, so the SSL option is 
# 			unnecessary in this case.
#
# 				CREATE USER 'jeffrey'@'localhost'
# 					REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/
# 						0=MySQL demo client certificate/
# 						CN=client/emailAddress=client@example.com';
#
# 			MySQL does a simple string comparison of the 'subject' value to the value
# 			in the certificate, so lettercase and component ordering must be given exactly
# 			as present in the certificate.
#
# 			Because SUBJECT implies the requirements of X509, clients must specify the
# 			--ssl-key and --ssl-cert options to connect.
#
# 			(It is recommended but not required that --ssl-ca also be specified so that hte public
# 			certificate provided by the server can be verified)
#
# 		) CIPHER 'cipher'
#
# 			For all accounts named by the statement, requires a specific cipher method for encrypting
# 			connections.
#
# 			This option is needed to ensure that ciphers and key lengths of sufficient
# 			strength are used.
#
# 			Encryption can be weak if old algorithms using short encryption keys are used.
#
# 				CREATE USER 'jeffrey'@'localhost'
# 					REQUIRE CIPHER 'EDH-RSA-DES-CBC3-SHA';
#
# The SUBJECT, ISSUER and CIPHER options can be combined in the REQUIRE clause:
#
# 		CREATE USER 'jeffrey'@'localhost'
# 			REQUIRE SUBJECT '/C=SE/ST=Stockholm/L=Stockholm/
# 				0=MySQL demo client certificate/
# 				CN=client/emailAddress=client@example.com'
# 			AND ISSUER '/C=SE/ST=Stockholm/L=Stockholm/
# 				0=MySQL/CN=CA/emailAddress=ca@example.com'
# 			AND CIPHER 'EDH-RSA-DES-CBC3-SHA';
#
# CREATE USER RESOURCE-LIMIT OPTIONS
#
# It is possible to place limits on use of server resources by an account, as discussed
# in SECTION 6.3.6, "SETTING ACCOUNT RESOURCE LIMITS"
#
# To do so, use a WITH clause that specifies one or more resource_option values.
#
# Order of WITH options does not matter, except that if a given resource limit is specified
# multiple times, the last instance takes precedence.
#
# CREATE_USER permits these resource_option values:
#
# 		) MAX_QUERIES_PER_HOUR count, MAX_UPDATES_PER_HOUR count, MAX_CONNECTIONS_PER_HOUR count
#
# 			For all accounts named by the statement, these options restrict how many queries, updates
# 			and connections to the server are permitted to each account during any given one-hour
# 			period.
#
# 			If count is 0 (the default), this means that there is no limitation for the account
#
# 		) MAX_USER_CONNECTIONS count
#
# 			For all accounts named by the statement, restricts the maximum number of simultaneous
# 			connections to the server by each account.
#
# 			A nonzero count specifies the limit for the account explicitly.
#
# 			If count is 0 (the default), the server determines the number of simultaneous
# 			connections for the account from the global value of the max_user_connections
# 			system variable.
#
# 			If max_user_connections is also zero, there is no limit for the account
#
# Example:
#
# 		CREATE USER 'jeffrey'@'localhost'
# 			WITH MAX_QUERIES_PER_HOUR 500 MAX_UPDATES_PER_HOUR 100;
#
# CREATE USER PASSWORD-MANAGEMENT OPTIONS
#
# CREATE_USER supports several password_option values for password management:
#
# 		) Password expiration options:
#
# 			You can expire an account password manually and establish its password
# 			expiration policy.
#
# 			Policy options do not expire the password.
#
# 			Instead, they determine how the server applies automatic expiration
# 			to the account based on password age, which is assessed from the date
# 			and time of the most recent account password change.
#
# 		) Password reuse options: You can restrict password reuse based on number
# 			of password changes, time elapsed, or both.
#
# 		) Password verification-required options: You can indicate whether attempts to change
# 			an account password must specify the current password, as verification that the
# 			user attempting to make the change actually knows the current password.
#
# This section describes the syntax for password-management options.
#
# For information about establishing policy for password management, see
# SECTION 6.3.8, "PASSWORD MANAGEMENT"
#
# If multiple password-management options of a given type (PASSWORD EXPIRE,
# PASSWORD HISTORY, PASSWORD REUSE INTERVAL, PASSWORD REQUIRE) are specified,
# the last one takes precedence.
#
# NOTE:
#
# 		Password-management options apply only to accounts that store credentials
# 		internally in the mysql.user system table (mysql_native_password,
# 		sha256_password, or caching_sha2_password)
#
# 		For accounts that use plugins that perform authentication against an
# 		external credential system, password management must be handled
# 		externally against that system as well.
#
# A client has an expired password if the account password was expired manually
# or the password age is considered greater than its permitted lifetime per
# the automatic expiration policy.
#
# In this case, the server either disconnects the client or restricts the operations
# permitted to it (see SECTION 6.3.9, "SERVER HANDLING OF EXPIRED PASSWORDS")
#
# Operations performed by a restricted client result in an error until the user
# establishes a new account password.
#
# CREATE_USER permits these password_option values for controlling password expiration:
#
# 		) PASSWORD EXPIRE
#
# 			Immediately marks the password expired for all accounts named by the statement
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE;
#
# 		) PASSWORD EXPIRE DEFAULT
#
# 			Sets all accounts named by the statement so that the global expiration policy
# 			applies, as specified by the default_password_lifetime system variable.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;
#
# 		) PASSWORD EXPIRE NEVER
#
# 			This expiration option overrides the global policy for all accounts named by the
# 			statement.
#
# 			For each, it disables password expiration so that the password never expires.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;
#
# 		) PASSWORD EXPIRE INTERVAL N DAY
#
# 			This expiration option overrides the global policy for all accounts named by the
# 			statement.
#
# 			For each, it sets the password lifetime to N days.
#
# 			The following statement requires the password to be changed every 180 days:
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 180 DAY;
#
# CREATE_USER permits these password_option values for controlling reuse of previous passwords
# based on required minimum number of password changes:
#
# 		) PASSWORD HISTORY DEFAULT
#
# 			Sets all accounts named by the statement so that the global policy about password
# 			history length applies, to prohibit reuse of passwords before the number of
# 			changes specified by the password_history system variable.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD HISTORY DEFAULT;
#
# 		) PASSWORD HISTORY N
#
# 			This history-length option overrides the global policy for all accounts named by
# 			the statement.
#
# 			For each, it sets the password history length to N passwords, to prohibit
# 			reusing any of the N most recently chosen passwords.
#
# 			The following statement prohibits reuse of any of the previous 6 passwords:
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD HISTORY 6;
#
# CREATE_USER permits these password_option values for controlling reuse of previous
# passwords based on time elapsed:
#
# 		) PASSWORD REUSE INTERVAL DEFAULT
#
# 			Sets all statements named by the account so that the global policy about time
# 			elapsed applies, to prohibit reuse of passwords newer than the number of days
# 			specified by the password_reuse_interval system variable.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL DEFAULT;
#
# 		) PASSWORD REUSE INTERVAL N DAY
#
# 			This time-elapsed option overrides the global policy for all accounts
# 			named by the statement.
#
# 			For each, it sets the password reuse interval to N days, to prohibit
# 			reuse of passwords newer than that many days.
#
# 			The following statement prohibits password reuse for 360 days:
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 360 DAY;
#
# CREATE_USER permits these password_option values for controlling whether attempts
# to change an account password must specify the current password, as verification
# that hte user attempting to make the change actually knows the current PW:
#
# 		) PASSWORD REQUIRE CURRENT
#
# 			This verification option overrides the global policy for all accounts named
# 			by the statement.
#
# 			For each, it requires that password changes specify the current password.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;
#
# 		) PASSWORD REQUIRE CURRENT OPTIONAL
#
# 			This verification option overrides the global policy for all accounts
# 			named by the statement.
#
# 			For each, it does not require that password changes specify the current
# 			password.
#
# 			(The current password may but need not be given)
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;
#
# 		) PASSWORD REQUIRE CURRENT DEFAULT
#
# 			Sets all statements named by the account so that the global policy about
# 			password verification applies, as specified by the password_require_current
# 			system variable.
#
# 				CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;
#
# CREATE USER ACCOUNT-LOCKING OPTIONS
#
# MySQL supports account locking and unlocking using the ACCOUNT LOCK and ACCOUNT UNLOCK
# options, which specify the locking state for an account.
#
# For additional discussion, see SECTION 6.3.12, "USER ACCOUNT LOCKING"
#
# If multiple account-locking options are specified, the last one takes
# precedence.
#
# CREATE USER BINARY LOGGING
#
# CREATE_USER is written to the binary log if it succeeds, but not if it fails; in that case,
# rollback occurs and no changes are made.
#
# A statement written to the binary log includes all named users.
#
# If the IF NOT EXISTS clause is given, this includes even users that already exist
# and were not created.
#
# The statement written to the binary log specifies an authentication plugin for each
# user, determined as follows:
#
# 		) The plugin named in the original statement, if one was specified
#
# 		) Otherwise, the default authentication plugin.
#
# 			In particular, if a user u1 already exists and uses a nondefault authentication
# 			plugin, the statement written to the binary log for CREATE USER IF NOT EXISTS u1
# 			names the default authentication plugin.
#
# 			(If the statement written to the binary log must specify a nondefault authentication
# 			plugin for a user, include it in the original statement)
#
# If the server adds the default authentication plugin for any nonexisting users in the
# statement written to the binary log, it writes a warning to the error log naming those
# users.
#
# 13.7.1.4 DROP ROLE SYNTAX
#
# 		DROP ROLE [IF EXISTS] role [, role ] ---
#
# DROP_ROLE removes one or more roles (named collections of privileges)
#
# To use this statement, you must have the global DROP_ROLE or CREATE_USER
# privilege.
#
# When the read_only system variable is enabled, DROP_ROLE additionally requires
# the CONNECTION_ADMIN or SUPER privilege.
#
# Roles named in the mandatory_roles system variable value cannot be dropped.
#
# DROP_ROLE either succeeds for all named roles or rolls back and has no effect
# if any error occurs.
#
# By default, an error occurs if you try to drop a role that does not exist.
#
# If the IF EXISTS clause is given, the statement produces a warning for each named
# role that does not exist, rather than an error.
#
# The statement is written to the binary log if it succeeds, but not if it fails;
# in that case, rollback occurs and no changes are made.
#
# A statement written to the binary log includes all named roles.
#
# If the IF EXISTS clause is given, this includes even roles that do not exist
# and were not dropped.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		DROP ROLE 'administrator', 'developer';
# 		DROP ROLE 'webapp'@'localhost';
#
# The host name part of the role name, if omitted, defaults to '%'
#
# A dropped role is automatically revoked from any user account (or role)
# to which the role was granted.
#
# Within any current session for such an account, its privileges are adjusted
# for the next statement executed.
#
# 13.7.1.5 DROP USER SYNTAX
#
# 		DROP USER [IF EXISTS] user [, user] ---
#
# The DROP_USER statement removes one or more MySQL accounts and their privileges.
#
# It removes privilege rows for the account from all grant tables.
#
# Roles named in the mandatory_roles system variable value cannot be dropped.
#
# To use DROP_USER, you must have the global CREATE_USER privilege, or the
# DELETE privilege for the mysql system database.
#
# When the read_only system variable is enabled, DROP_USER additionally
# requires the CONNECTION_ADMIN or SUPER privilege.
#
# DROP_USER either succeeds for all named users or rolls back and has no effect
# if any error occurs.
#
# By default, an error occurs if you try to drop a user that does not exist.
#
# If the IF EXISTS clause is given, the statement produces a warning for each
# named user that does not exist, rather than an error.
#
# The statement is written to the binary log if it succeeds, but not if it fails;
# in that case, rollback occurs and no changes are made.
#
# A statement written to the binary log includes all named users.
#
# If the IF EXISTS clause is given, this includes even users that do not exist
# and were not dropped.
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# For example:
#
# 		DROP USER 'jeffrey'@'localhost';
#
# The host name part of the account name, if omitted, defaults to '%'
#
# IMPORTANT:
#
# 		DROP_USER does not automatically close any open user sessions.
#
# 		Rather, in the event that a user with an open session is dropped,
# 		the statement does not take effect until that user's session is closed.
#
#		Once the session is closed, the user is dropped, and that user's next
# 		attempt to log in will fail.
#
# 		This is by design.
#
# DROP_USER does not automatically drop or invalidate databases or objects
# within them that the old user created.
#
# This includes stored programs or views for which the DEFINER attribute names
# the dropped user.
#
# Attempts to access such objects may produce an error if they execute in definer
# security context.
#
# (For information about security context, see SECTION 24.6, "ACCESS CONTROL FOR STORED
# PROGRAMS AND VIEWS")
#
# 13.7.1.6 GRANT SYNTAX
#
# 		GRANT
# 			priv_type [(column_list)]
# 				[, priv_type [(column_list)]] ---
# 			ON [object_type] priv_level
# 			TO user_or_role [, user_or_role] ---
# 			[WITH GRANT OPTION]
#
# 		GRANT PROXY ON user_or_role
# 			TO user_or_role [, user_or_role] ---
# 			[WITH GRANT OPTION]
#
# 		GRANT role [, role] ---
# 			TO user_or_role [, user_or_role] ---
# 			[WITH ADMIN OPTION]
#
# 		object_type: {
# 			TABLE
# 		 | FUNCTION
# 		 | PROCEDURE
# 		}
#
# 		priv_level: {
# 			*
# 		 | *.*
# 		 | db_name.*
# 		 | db_name.tbl_name
# 		 | tbl_name
# 		 | db_name.routine_name
# 		}
#
# 		user_or_role: {
# 			user
# 		 | role
# 		}
#
# 		user:
# 			(see Section 6.2.4, "Specifying Account Names")
#
# 		role:
# 			(see Section 6.2.5, "Specifying Role Names")
#
# The GRANT statement assigns privileges and roles to MySQL user accounts and roles.
#
# There are several aspects to the GRANT statement, described under the following
# topics:
#
# 		) GRANT GENERAL OVERVIEW
#
# 		) OBJECT QUOTING GUIDELINES
#
# 		) ACCOUNT NAMES
#
# 		) PRIVILEGES SUPPORTED BY MYSQL
#
# 		) GLOBAL PRIVILEGES
#
# 		) DATABASE PRIVILEGES
#
# 		) TABLE PRIVILEGES
#
# 		) COLUMN PRIVILEGES
#
# 		) STORED ROUTINE PRIVILEGES
#
# 		) PROXY USER PRIVILEGES
#
# 		) GRANTING ROLES
#
# 		) OTHER ACCOUNT CHARACTERISTICS 
#
# 		) MYSQL AND STANDARD SQL VERSIONS OF GRANT
#
# GRANT GENERAL OVERVIEW
#
# The GRANT statement enables system administrators to grant privileges and roles,
# which can be granted to user accounts and roles.
#
# These syntax restrictions apply: 
#
# 		) GRANT cannot mix granting both privileges and roles in the same statement.
#
# 			A given GRANT statement must grant either privileges or roles.
#
# 		) The ON clause distinguishes whether the statement grants privileges or roles:
#
# 			) With ON, the statement grants privileges.
#
# 			) Without ON, the statement grants roles
#
# 			) It is permitted to assign both privileges and roles to an account, but you
# 				must use separate GRANT statements, each with syntax appropriate to what is
# 				to be granted.
#
# For more information about roles, see SECTION 6.3.4, "USING ROLES"
#
# To use GRANT, you must have the GRANT_OPTION privilege, and you must have the
# privileges that you are granting.
#
# When the read_only system variable is enabled, GRANT additionally requires the
# CONNECTION_ADMIN or SUPER privilege.
#
# GRANT either succeeds for all named users and roles or rolls back and has no
# effect if any error occurs.
#
# The statement is written to the binary log only if it succeeds for all
# named users and roles.
#
# The REVOKE statement is related to GRANT and enables administrators to remove
# account privileges.
#
# See SECTION 13.7.1.8, "REVOKE SYNTAX"
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		GRANT ALL ON db1.* TO 'jeffrey'@'localhost';
# 		GRANT 'role1', 'role2' TO 'user1'@'localhost', 'user2'@'localhost';
# 		GRANT SELECT ON world.* TO 'role3';
#
# The host name part of the account or role name, if omitted, defaults to '%'
#
# Normally, a database administrator first uses CREATE_USER to create an account
# and define its nonprivilege characteristics such as its password, whether it uses
# secure connections, and limits on access to server resources, then uses GRANT
# to define its privileges.
#
# ALTER_USER may be used to change the nonprivilege characteristics of existing accounts.
#
# For example:
#
# 		CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';
# 		GRANT ALL ON db1.* TO 'jeffrey'@'localhost';
# 		GRANT SELECT ON db2.invoice TO 'jeffrey'@'localhost';
# 		ALTER USER 'jeffrey'@'localhost' WITH MAX_QUERIES_PER_HOUR 90;
#
# From the mysql program, GRANT responds with Query OK, 0 rows affected when executed
# successfully.
#
# To determine what privileges result from the operation, use SHOW_GRANTS
#
# See SECTION 13.7.6.21, "SHOW GRANTS SYNTAX"
#
# 	IMPORTANT:
#
# 		Under some circumstances, GRANT may be recorded in server logs or on the
# 		client side in a history file such as ~/.mysql_history, which means that 
# 		cleartext passwords may be read by anyone having read access to that
# 		information.
#
# 		For information about the conditions under which this occurs for the
# 		server logs and how to control it, see SECTION 6.1.2.3, "PASSWORDS AND LOGGING"
#
# 		For similar information about client-side logging, see SECTION 4.5.1.3,
# 		"MYSQL CLIENT LOGGING"
#
# GRANT supports host names up to 60 characters long.
#
# User names can be up to 32 characters. Database, table, column and routine names
# can be up to 64 characters.
#
# 		WARNING:
#
# 			Do not attempt to change the permissible length for user names by altering
# 			the mysql.user system table.
#
# 			Doing so results in unpredictable behavior which may even make it impossible
# 			for users to log into the MySQL server.
#
# 			Never alter the structure of tables in the mysql system database in any manner
# 			except by means of the procedure described in SECTION 4.4.5, "MYSQL_UPGRADE --- CHECK AND UPGRADE MYSQL TABLES"
#
# OBJECT QUOTING GUIDELINES
#
# Several objects within GRANT statements are subject to quoting, although quoting is optional
# in many cases:
#
# 		Account, role, database, table, column and routine names.
#
# For example, if a user_name or host_name value in an account name is legal as an unquoted
# identifier, you need not quote it.
#
# However, quotation marks are necessary to specify a user_name string containing special characters
# (such as -), or a host_name string containing special characters or wildcard characters
# (such as %); for example, 'test-user'@'%.com'
#
# Quote the user name and host name separately
#
# To specify quoted values:
#
# 		) Quote database, table, column and routine names as identifiers
#
# 		) Quote user names, and host names as identifiers or as strings
#
# 		) Quote passwords as strings
#
# For string-quoting and identifier-quoting guidelines, see SECTION 9.1.1, "STRING LITERALS",
# and SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# The _ and % wildcards are permitted when specifying database names in GRANT statements
# that grant privileges at the database level (GRANT --- ON db_name.*)
#
# This means, for example, that to use a _ character as part of a database name
# specify it as \_ in the GRANT statement, to prevent the user from being able
# to access additional databases matching the wildcard pattern;
#
# For example, GRANT --- ON `foo\_bar`.* TO ---
#
# When a database name not is used to grant privileges at the database level, but as
# a qualifier for granting privileges to some other objects such as a table
# or routine (for example, GRANT --- ON db_name.tbl_name), wildcard characters
# are treated as normal characters.
#
# ACCOUNT NAMES
#
# A user value in a GRANT statement indicates a MySQL account to which the statement
# applies.
#
# To accommodate granting rights to users from arbitrary hosts, MySQL supports
# specifying the user value in the form 'user_name'@'host_name'
#
# You can specify wildcards in the host name. For example, 'user_name'@'%.example.com'
# applies to user_name for any host in the example.com domain, and 'user_name'@'198.51.100.%'
# applies to user_name for any host in the 198.51.100 class C subnet.
#
# The simple form 'user_name' is a synonym for 'user_name'@'%'
#
# MySQL does not support wildcards in user names.
#
# To refer to an anonymous user, specify an account with an empty user name
# with the GRANT statement:
#
# 		GRANT ALL ON test.* TO ''@'localhost' ---;
#
# In this case, any user who connects from the local host with the correct password
# for the anonymous user will be permitted access, with the privileges associated
# with the anonymous-user account.
#
# For additional information about user name and host name values in account names,
# see SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# WARNING:
#
# 		If you permit local anonymous users to connect to the MySQL server, you should
# 		also grant privileges to all local users as 'user_name'@'localhost'
#
# 		Otherwise, the anonymous user account for localhost in the mysql.user system
# 		table is used when named users try to log in to the MySQL server from the local
# 		machine.
#
# 		For details, see SECTION 6.2.6, "ACCESS CONTROL, STAGE 1: CONNECTION VERIFICATION"
#
# 		To determine whether this issue applies to you, execute the following query, which
# 		lists any anonymous users:
#
# 			SELECT host, User FROM mysql.user WHERE User='';
#
# 		To avoid the problem just described, delete the local anonymous user account
# 		using this statement:
#
# 			DROP USER ''@'localhost';
#
# PRIVILEGES SUPPORTED BY MYSQL
#
# The following tables summarize the permissible static and dynamic priv_type privilege types
# that can be specified for the GRANT and REVOKE statements, and the levels at which each
# privilege can be granted.
#
# For additional information about each privilege, see SECTION 6.2.1, "PRIVILEGES PROVIDED BY MYSQL"
#
# For information about the differences between static and dynamic privileges,
# see SECTION 6.2.2, "STATIC VERSUS DYNAMIC PRIVILEGES"
#
# TABLE 13.9 PERMISSIBLE STATIC PRIVILEGES FOR GRANT AND REVOKE
#
# PRIVILEGE 					MEANING AND GRANTABLE LEVELS
#
# ALL_[PRIVILEGES] 			Grant all privileges at specified access level except GRANT_OPTION and PROXY
#
# ALTER 							Enable use of ALTER_TABLE. Levels: Global, database, table
#
# ALTER_ROUTINE 				Enable stored routines to be altered or dropped. Levels: Global, database, routine
#
# CREATE 						Enable database and table creation. levels: Global, database, table
#
# CREATE_ROLE 					Enable role creation. Level: Global
#
# CREATE_ROUTINE 				Enable stored routine creation. Levels: Global, database
#
# CREATE_TABLESPACE 			Enable tablespaces and log file groups to be created, altered, or dropped. Level: Global
#
# CREATE_TEMPORARY_TABLES	Enable use of CREATE_TEMPORARY_TABLE. Levels: Global, database
#
# CREATE_USER 					Enable use of CREATE_USER, DROP_USER, RENAME_USER, and REVOKE_ALL_PRIVILEGES. Level: Global
#
# CREATE_VIEW 					Enable views to be created or altered. Levels: Global, database, table
#
# DELETE 						Enable use of DELETE. Level: Global, database, table
#
# DROP 							Enable databases, tables, and views to be dropped. Levels: Global, database, table
#
# DROP_ROLE 					Enable roles to be dropped. Level: Global
#
# EVENT 							Enable use of events for the Event Scheduler. levels: Global, database
#
# EXECUTE 						Enable the user to execute stored routines. Levels: Global, database, routine
#
# FILE 							Enable the user to cause the server to read or write files. Level: Global
#
# GRANT_OPTION 				Enables privileges to be granted to or removed from other accounts. Levels: Global, database, table, routine, proxy
#
# INDEX 							Enables indexes to be created or dropped. Levels: Global, database, table
#
# INSERT 						Enable use of INSERT. Levels: Global, database, table, column
#
# LOCK_TABLES 					Enable use of LOCK_TABLES on tables for which you have the SELECT privilege. Levels: Global, database
#
# PROCESS 						Enable the user to see all processes with SHOW_PROCESSLIST. Level: Global
#
# PROXY 							Enable user proxying. Level: From user to user
#
# REFERENCES 					Enable foreign key creation. Levels: Global, database, table, column
#
# RELOAD 						Enable use of FLUSH operations. Level: Global
#
# REPLICATION_CLIENT 		Enable the user to ask where master or slave servers are. Level: Global
#
# REPLICATION_SLAVE 			Enable replication slaves to read binary log events from the master. Level: Global
#
# SELECT 						Enable use of SELECT. Levels: Global, database, table, column
#
# SHOW_DATABASES 				Enable SHOW_DATABASES to show all databases. Level: Global
#
# SHOW_VIEW 					Enable use of SHOW_CREATE_VIEW. Levels: Global, database, table
#
# SHUTDOWN 						Enable use of mysqladmin shutdown. Level: Global
#
# SUPER 							Enable use of other administrative operations such as CHANGE_MASTER_TO,
# 									KILL, PURGE_BINARY_LOGS, SET_GLOBAL and mysqladmin debug command. Level: Global
#
# TRIGGER 						Enable trigger operations. Levels: Global, database, table
#
# UPDATE 						Enable use of UPDATE. Levels: Global, database, table, column
#
# USAGE 							Synonym for "no privileges"
#
# TABLE 13.10 PERMISSIBLE DYNAMIC PRIVILEGES FOR GRANT AND REVOKE
#
# PRIVILEGE 							Meaning and Grantable Levels
#
# APPLICATION_PASSWORD_ADMIN		Enable dual password administration. Level: Global
#
# AUDIT_ADMIN 							Enable audit log configuration. Level: Global
#
# BACKUP_ADMIN 						Enable backup administration. level: Global
#
# BINLOG_ADMIN 						Enable binary log control. Level: Global
#
# BINLOG_ENCRYPTION_ADMIN 			Enable activation and deactivation of binary log encryption. Level: Global
#
# CONNECTION_ADMIN 					Enable connection limit/restriction control. Level: Global
#
# ENCRYPTION_KEY_ADMIN 				Enable InnoDB key rotation. Level: Global
#
# FIREWALL_ADMIN 						Enable firewall rule administration, any user. Level: GLobal
#
# FIREWALL_USER 						Enable firewall rule administration, self. Level: Global
#
# GROUP_REPLICATION_ADMIN 			Enable Group Replication control. level: Global
#
# PERSIST_RO_VARIABLES_ADMIN 		Enable persisting read-only system variables. Level: Global
#
# REPLICATION_SLAVE_ADMIN 			Enable regular replication control. Level: GLobal
#
# RESOURCE_GROUP_ADMIN 				Enable resource group administration. Level: Global
#
# RESOURCE_GROUP_USER 				Enable resource group administration. Level: Global
#
# ROLE_ADMIN 							Enable use of WITH ADMIN OPTION. Level: GLobal
#
# SESSION_VARIABLES_ADMIN 			Enable setting restricted session system variables. Level: Global
#
# SET_USER_ID 							Enable setting non-self DEFINER values. Level: Global
#
# SYSTEM_VARIABLES_ADMIN 			Enable modifying or persisting global system variables. Level: Global
#
# VERSION_TOKEN_ADMIN 				Enable use of Version Tokens UDFs. Level: Global
#
# XA_RECOVER_ADMIN 					Enable XA_RECOVER execution. Level: Global
#
# A trigger is associated with a table. To create or drop a trigger, you must have the TRIGGER privilege
# for the table, not the trigger.
#
# In GRANT statements, the ALL_[PRIVILEGES] or PROXY privilege must be named by itself
# and cannot be specified along with other privileges.
#
# ALL_[PRIVILEGES] stands for all privileges available for the level at which privileges
# are to be granted except for the GRANT_OPTION and PROXY privileges.
#
# MySQL account information is stored in the tables of the mysql system database.
#
# For additional details, consult SECTION 6.2, "THE MYSQL ACCESS PRIVILEGE SYSTEM",
# which discusses the mysql system database and the access control system extensively.
#
# If the grant tables hold privilege rows that contain mixed-case database or table
# names and the lower_case_table_names system variable is set to a nonzero value,
# REVOKE cannot be used to revoke these privileges.
#
# It will be necessary to manipulate the grant tables directly.
#
# (GRANT will not create such rows when lower_case_table_names is
# set, but such rows might have been created prior to setting that variable.
#
# The lower_case_table_names setting can only be configured at server startup)
#
# Privileges can be granted at several levels, depending on the syntax used
# for the ON clause.
#
# For REVOKE, the same ON syntax specifies which privileges to remove.
#
# For the global, database, table and routine levels, GRANT_ALL assigns only
# the privileges that exist at the level you are granting.
#
# For example, GRANT ALL ON db_name.* is a database-level statement,
# so it does not grant any global-only privileges such as FILE.
#
# Granting ALL does not assign the GRANT_OPTION or PROXY privilege.
#
# The object_type clause, if present, should be specified as TABLE FUNCTION,
# or PROCEDURE when the following object is a table, a stored function,
# or a stored procedure.
#
# The privileges that a user holds for a database, table, column, or routine
# are formed additively as the logical OR of the account privileges at each
# of the privilege levels.
#
# FOr example, if a user has a global SELECT privilege, the privilege cannot be
# denied by an absence of the privilege at the database, table, or column level.
#
# Details of the privilege-checking procedure are presented in SECTION 6.2.7,
# "ACCESS CONTROL, STAGE 2: REQUEST VERIFICATION"
#
# If you are using table, column, or routine privileges for even one user,
# the server examines table, column, and routine privileges for all users
# and this slows down MySQL a bit.
#
# Similarly, if you limit the number of queries, updates or connections
# for any users, the server must monitor these values.
#
# MySQL enables you to grant privileges on databases or tables that do not
# exist.
#
# For tables, the privileges to be granted must include the CREATE privilege.
#
# This behavior is by design, and is intended to enable the DB admin to prepare
# user accounts and privileges for databases or tables that are to be 
# created at a later time.
#
# IMPORTANT:
#
# 		MySQL does not automatically revoke any privileges when you drop
# 		a database or table.
#
# 		However, if you drop a routine, any routine-level privileges granted
# 		for that routine are revoked.
#
# GLOBAL PRIVILEGES
#
# Global privileges are administrative or apply to all databases on a given
# server.
#
# To assign global privileges, use ON *.* syntax:
#
# 		GRANT ALL ON *.* TO 'someuser'@'somehost';
# 		GRANT SELECT, INSERT ON *.* TO 'someuser'@'somehost';
#
# The CREATE_TABLESPACE, CREATE_USER, FILE, PROCESS, RELOAD, REPLICATION_CLIENT,
# REPLICATION_SLAVE, SHOW_DATABASES, SHUTDOWN and SUPER static privileges are
# administrative and can only be granted globally.
#
# Dynamic privileges are all global and can only be granted globally.
#
# Other privileges can be granted globally or at more specific levels.
#
# The effect of GRANT_OPTION granted at the global level differs for static
# and dynamic privileges:
#
# 		) GRANT_OPTION granted for any static global privilege applies to all static global privileges
#
# 		) GRANT_OPTION granted for any dynamic privilege applies only to that dynamic privilege
#
# GRANT ALL at the global level grants all static global privileges and all currently registered
# dynamic privileges.
#
# A dynamic privilege registered subsequent to execution of the GRANT statement is not granted
# retroactively to any account.
#
# MySQL stores global privileges in the mysql.user system table
#
# DATABASE PRIVILEGES
#
# Database privileges apply to all objects in a given database. To assign database-level
# privileges, use ON db_name.* syntax:
#
# 		GRANT ALL ON mydb.* TO 'someuser'@'somehost';
# 		GRANT SELECT, INSERT ON mydb.* TO 'someuser'@'somehost';
#
# If you use ON * syntax (rather than ON *.*), privileges are assigned at the database
# level for the default database.
#
# An error occurs if there is no default database.
#
# The CREATE, DROP, EVENT, GRANT_OPTION, LOCK_TABLES and REFERENCES privileges can be
# specified at the database level.
#
# Table or routine privileges also can be specified at the database level, in which
# case they apply to all tables or routines in the database.
#
# MySQL stores database privileges in the mysql.db system table
#
# TABLE PRIVILEGES
#
# Table privileges apply to all columns in a given table. To assign table-level privileges,
# use ON db_name.tbl_name syntax:
#
# 		GRANT ALL ON mydb.mytbl TO 'someuser'@'somehost';
# 		GRANT SELECT, INSERT ON mydb.mytbl TO 'someuser'@'somehost';
#
# If you specify tbl_name rather than db_name.tbl_name, the statement applies to tbl_name
# in the default database.
#
# An error occurs if there is no default database.
#
# The permissible priv_type values at the table level are ALTER, CREATE_VIEW, CREATE,
# DELETE, DROP, GRANT_OPTION, INDEX, INSERT, REFERENCES, SELECT, SHOW_VIEW, TRIGGER
# and UPDATE.
#
# Table-level privileges apply to base tables and views.
#
# They do not apply to tables created with CREATE_TEMPORARY_TABLE, even if
# the table names match.
#
# For information about TEMPORARY table privileges, see SECTION 13.1.20.3, "CREATE TEMPORARY TABLE SYNTAX"
#
# MySQL stores table privileges in the mysql.tables_priv system table
#
# COLUMN PRIVILEGES
#
# Column privileges apply to single columns in a given table.
#
# Each privilege to be granted at the column level must be followed by the column
# or columns, enclosed within parentheses.
#
# 		GRANT SELECT (col1), INSERT (col1, col2) ON mydb.mytbl TO 'someuser'@'somehost';
#
# The permissible priv_type values for a column (that is, when you use a column_list clause)
# are INSERT, REFERENCES, SELECT, and UPDATE.
#
# MySQL stores column privileges in the mysql.columns_priv system table.
#
# STORED ROUTINE PRIVILEGES
#
# The ALTER_ROUTINE, CREATE_ROUTINE, EXECUTE and GRANT_OPTION privileges apply to
# stored routines (procedures and functions).
#
# They can be granted at the global and database levels.
#
# Except for CREATE_ROUTINE, these privileges can be granted at the routine level
# for individual routines.
#
# 		GRANT CREATE ROUTINE ON mydb.* TO 'someuser'@'somehost';
# 		GRANT EXECUTE ON PROCEDURE mydb.myproc TO 'someuser'@'somehost';
#
# The permissible priv_type values at the routine level are ALTER_ROUTINE, EXECUTE
# and GRANT_OPTION
#
# CREATE_ROUTINE is not a routine-level privilege because you must have the privilege
# at the global or database level to create a routine in the first place.
#
# MySQL stores routine-level privileges in the mysql.procs_priv system table
#
# PROXY USER PRIVILEGES
#
# The PROXY privilege enables one user to be a proxy for another.
#
# The proxy user impersonates or takes the identity of the proxied user;
# that is, it assumes the privileges of the proxied user.
#
# 		GRANT PROXY ON 'localuser'@'localhost' TO 'externaluser'@'somehost';
#
# When PROXY is granted, it must be the only privilege named in the GRANT
# statement, and the only permitted WITH option is WITH GRANT OPTION.
#
# Proxying requires that the proxy user authenticate through a plugin that
# returns the name of the proxied user ot the server when the proxy
# user connects, and that the proxy user have the PROXY privilege for the
# proxied user.
#
# For details and examples, see SECTION 6.3.11, "PROXY USERS"
#
# MySQL stores proxy privileges in the mysql.proxies_priv system table
#
# GRANTING ROLES
#
# GRANT syntax without an ON clause grants roles rather than individual privileges.
#
# A role is a named collection of privileges; See SECTION 6.3.4, "USING ROLES"
#
# For example:
#
# 		GRANT 'role1', 'role2' TO 'user1'@'localhost', 'user2'@'localhost';
#
# Each role to be granted must exist, as well as each user account or role
# to which it is to be granted.
#
# If the GRANT statement includes the WITH ADMIN OPTION clause, each named user
# becomes able to grant the named roles to other users or roles, or revoke
# them from other users or roles.
#
# This includes the ability to use WITH ADMIN OPTION itself
#
# It is possible to create circular references with GRANT. For example:
#
# 		CREATE USER 'u1', 'u2';
# 		CREATE ROLE 'r1', 'r2';
#
# 		GRANT 'u1' TO 'u1'; -- SImple loop: u1 => u1
# 		GRANT 'r1' TO 'r1'; -- simple loop: r1 => r1
#
# 		GRANT 'r2' TO 'u2'; 
# 		GRANT 'u2' TO 'r2'; -- mixed user/role loop: u2 => r2 => u2
#
# Circular grant references are permitted, but add no new privileges or roles to the grantee
# because a user or role already has its privileges and roles.
#
# OTHER ACCOUNT CHARACTERISTICS 
#
# The optional WITH clause is used to enable a user to grant privileges to other users.
#
# The WITH GRANT OPTION clause gives the user the ability to give to other users
# any privileges the user has at the specified privilege level.
#
# To grant the GRANT_OPTION privilege to an account without otherwise changing its 
# privileges, do this:
#
# 		GRANT USAGE ON *.* TO 'someuser'@'somehost' WITH GRANT OPTION;
#
# Be careful to whom you give the GRANT_OPTION privilege because two users with
# different privileges may be able to combine privileges.
#
# You cannot grant another user a privilege which you yourself do not have; the GRANT_OPTION
# privilege enables you to assign only those privileges which you yourself possess.
#
# Be aware that when you grant a user the GRANT_OPTION privilege at a particular privilege level,
# any privileges that user possesses (or may be given in the future) at that level, 
# can also be granted by that user to other users.
#
# Suppose that you grant a user the INSERT privilege on a database.
#
# If you then grant the SELECT privilege on the database and specify WITH GRANT OPTION,
# that user can give to other users not only the SELECT privilege, but also INSERT.
#
# If oyu then grant the UPDATE privilege to the user on the database,
# the user can grant INSERT, SELECT and UPDATE.
#
# For a nonadminsitrative user, you should not grant the ALTER privilege globally
# or for the mysql system database.
#
# If you do that,the user can try to subvert the privilege system by renaming tables.
#
# FOr additional information about security risks associated with a particular privileges,
# See SECTION 6.2.1, "PRIVILEGES PROVIDED BY MYSQL"
#
# MYSQL AND STANDARD SQL VERSIONS OF GRANT
#
# The biggest differences between the MySQL and standard SQL versions of GRANT are:
#
# 		) MySQL associates privileges with the combination of a host name and user name
# 			and not with only a user name.
#
# 		) Standard SQL does not have global or database-level privileges, nor does it support
# 			all the privilege types that MySQL supports.
#
# 		) MySQL does not support the standard SQL UNDER privilege
#
# 		) Standard SQL privileges are structured in a hierarchial manner.
#
# 			If you remove a user, all privileges the user has been granted are revoked.
#
# 			This is also true in MySQL, if you use DROP_USER.
#
# 			See SECTION 13.7.1.5, "DROP USER SYNTAX"
#
# 		) In standard SQL, when you drop a table, all privileges for the table are revoked.
#
# 			In standard SQL, when you revoke a privilege, all privileges that were granted based
# 			on that privilege are also revoked.
#
# 			In MySQL, privileges can be dropped with DROP_USER or REVOKE statements.
#
# 		) In MySQL, it is possible to have the INSERT privilege for only some of the
# 			columns in a table.
#
# 			In this case, you can still execute INSERT statements on the table, provided
# 			that you insert values only for those columns for which you have the INSERT privilege.
#
# 			The omitted columns are set to their implicit default values if strict SQL mode
# 			is not enabled.
#
# 			In strict mode, the statement is rejected if any of the omitted columns have no
# 			default value.
#
# 			(Standard SQL requires you to have the INSERT privilege on all columns)
#
# 			For information about strict SQL mode and implicit default values, see SECTION 5.1.11,
# 			"SERVER SQL MODES" and SECTION 11.7, "DATA TYPE DEFAULT VALUES"
#
# 13.7.1.7 RENAME USER SYNTAX
#
# 		RENAME USER old_user TO new_user
# 			[, old_user TO new_user] ---
#
# The RENAME_USER statement renames existing MySQL accounts.
#
# An error occurs for old accounts that do not exist or new accounts that already exist.
#
# To use RENAME_USER, you must have the global CREATE_USER privilege, or the UPDATE
# privilege for the mysql system database.
#
# When the read_only system variable is enabled, RENAME_USER additionally
# requires the CONNECTION_ADMIN or SUPER privilege.
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# For example:
#
# 		RENAME USER 'jeffrey'@'localhost' TO 'jeff'@'127.0.0.1';
#
# The host name part of the account name, if omitted, defaults ot '%'
#
# RENAME_USER causes the privileges held by the old user to be those held by the
# new user.
#
# However, RENAME_USER does not automatically drop or invalidate databases or
# objects within them that the old user created.
#
# This includes stored programs or views for which the DEFINER attribute names
# the old user.
#
# Attempts to access such objects may produce an error if they execute in definer
# security context.
#
# (For information about security context, see SECTION 24.6, "ACCESS CONTROL FOR STORED PROGRAMS AND VIEWS")
#
# The privilege changes take effect as indicated in SECTION 6.2.8, "WHEN PRIVILEGE CHANGES TAKE EFFECT"
#
# 13.7.1.8 REVOKE SYNTAX
#
# REVOKE
# 		priv_type [(column_list)]
# 			[, priv_type [(column_list)] ---
# 		ON [object_type] priv_leveL
# 		FROM user_or_role [, user_or_role] ---
#
# REVOKE ALL [PRIVILEGES], GRANT OPTION
# 		FROM user_or_role [, user_or_role] ---
#
# REVOKE PROXY ON user_or_role
# 		FROM user_or_role [, user_or_role] ---
#
# REVOKE role [, role ] ---
# 		FROM user_or_role [, user_or_role ] ---
#
# user_or_role: {
# 		user
# 	 | role
# }
#
# user:
# 		(see SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES")
#
# role:
# 		(see SECTION 6.2.5, "SPECIFYING ROLE NAMES")
#
# The REVOKE statment enables system administrators to revoke privileges
# and roles, which can be revoked from user accounts and roles.
#
# For information about roles, see SECTION 6.3.4, "USING ROLES"
#
# When the read_only system variable is enabled, REVOKE requires the CONNECTION_ADMIN
# or SUPER privilege in addition to any other required privileges described in the
# following discussion.
#
# REVOKE either succeeds for all named users and roles or rolls back and has no effect
# if any error occurs.
#
# The statement is written to the binary log only if it succeeds for all named users
# and roles.
#
# Each account name uses the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		REVOKE INSERT ON *.* FROM 'jeffrey'@'localhost';
# 		REVOKE 'role1', 'role2' FROM 'user1'@'localhost', 'user2'@'localhost';
# 		REVOKE SELECT ON world.* FROM 'role3';
#
# The host name part of the account or role name, if omitted, defaults to '%'
#
# For details on the levels at which privileges exist, the permissible priv_type,
# priv_level and object_type values, and the syntax for specifying users and
# passwords, see SECTION 13.7.1.6, "GRANT SYNTAX"
#
# To use the first REVOKE syntax, you must have the GRANT_OPTION privilege,
# and you must have the privileges that you are revoking.
#
# To revoke all privileges, use the second syntax, which drops all global,
# database, table, column and routine privileges for the named users or roles:
#
# 		REVOKE ALL PRIVILEGES, GRANT OPTION
# 			FROM user_or_role [, user_or_role] ---
#
# REVOKE ALL PRIVILEGES, GRANT OPTION does not revoke any roles.
#
# To use this REVOKE syntax, you must have the global CREATE_USER privilege,
# or the UPDATE privilege for the mysql system database.
#
# The syntax for which the REVOKE keyword is followed by one or more role names
# takes a FROM clause indicating one or more users or roles from which to revoke
# the roles.
#
# Roles named in the mandatory_roles system variable value cannot be revoked.
#
# A revoked role immediately affects any user account from which it was revoked,
# such that within any current session for the account, its privileges are adjusted
# for the next statement executed.
#
# Revoking a role revokes the role itself, not the privileges that it represents.
#
# If an account is granted a role that includes a given privilege, and is also granted
# the privilege explicitly or another role that includes the privilege, the account still
# is granted that privilege after the first role is revoked.
#
# For example, if an account is granted two roles that each include SELECT, the account
# still can select after either role is revoked.
#
# REVOKE ALL ON *.* (at the global level) revokes all granted static global privileges
# and all granted dynamic privileges.
#
# User accounts and roles from which privileges and roles are to be revoked must exist,
# but the roles to be revoked need not be currently granted to them.
#
# REVOKE removes privileges, but does not drop mysql.user system table entries.
#
# To remove a user account entirely, use DROP_USER. See SECTION 13.7.1.5, "DROP USER SYNTAX"
#
# If the grant tables hold privilege rows that contain mixed-case database or table names
# and the lower_case_table_names system variable is set to a nonzero value, REVOKE cannot
# be used to revoke these privileges.
#
# It will be necessary to manipulate the grant tables directly.
#
# (GRANT will not create such rows when lower_case_table_names is set, but such
# rows might have been created prior to setting the variable.
#
# The lower_case_table_names setting  can only be configured when initializing the server)
#
# When successfully executed from the mysql program, REVOKE responds with Query OK, 0 rows affected.
#
# To determine what privileges remain after the operation, use SHOW_GRANTS.
#
# See SECTION 13.7.6.21, "SHOW GRANTS SYNTAX"
#
# 13.7.1.9 SET DEFAULT ROLE SYNTAX
#
# 		SET DEFAULT ROLE
# 			{NONE | ALL | role [, role ] ---}
# 			TO user [, user ] ---
#
# For each user named immediately after the TO keyword, this statement defines which
# roles become active when the user connects to the server and authenticates, or when
# the user executes the SET_ROLE_DEFAULT statement during a session.
#
# SET_DEFAULT_ROLE is alternative syntax for ALTER_USER_---_DEFAULT_ROLE
# (See SECTION 13.7.1.1, "ALTER USER SYNAX")
#
# However, ALTER_USER can set the default for only a single user, whereas SET_DEFAULT_ROLE
# can set the default for multiple users.
#
# On the other hand, you can specify CURRENT_USER as the user name for the ALTER_USER
# statement, whereas you cannot for SET_DEFAULT_ROLE
#
# SET_DEFAULT_ROLE requires these privileges:
#
# 		) Setting the default roles for another user requires the global CREATE_USER privilege,
# 			or the UPDATE privilege for the mysql.default_roles system table.
#
# 		) Setting the default roles for yourself requires no special privileges, as long as the
# 			roles you want as the default have been granted to you.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# For example:
#
# 		SET DEFAULT ROLE administrator, developer TO 'joe'@'10.0.0.1';
#
# The host name part of the role name, if omitted, defaults to '%'
#
# The clause following the DEFAULT ROLE keywords permits these values:
#
# 		) NONE: Set the default to NONE (no roles)
#
# 		) ALL: Set the default to all roles granted to the account
#
# 		) role [, role ] ---: Set the default to the named roles, which must exist and be granted
# 			to the account at the time SET_DEFAULT_ROLE is executed.
#
# NOTE:
#
# 		SET_DEFAULT_ROLE and SET_ROLE_DEFAULT are different statements:
#
# 			) SET_DEFAULT_ROLE defines which account roles to activate by default within account sessions.
#
# 			) SET_ROLE_DEFAULT sets the active roles within the current session to the current account default roles.
#
# 13.7.1.10 SET PASSWORD SYNTAX
#
# 		SET PASSWORD [FOR user] = 'auth_string'
# 			[REPLACE 'current_auth_string']
# 			[RETAIN CURRENT PASSWORD]
#
# The SET_PASSWORD statement assigns a password to a MySQL user account.
#
# It may also include a password-verification clause that specifies the account
# current password to be replaced, and a clause that manages whether an account
# has a secondary password.
#
# 'auth_string' and 'current_auth_string' each represents a cleartext (unencrypted) password.
#
# NOTE:
#
# 		Clauses for password verification and secondary passwords apply only to accounts
# 		that store credentials interally in the mysql.user system table (mysql_native_password, sha256_password,
# 		or caching_sha2_password)
#
# 		For accounts that use plugins that perform authentication against an external
# 		credential system, password management must be handled externally against that
# 		system as well.
#
# The REPLACE 'current_auth_string' clause is available as of MySQL 8.0.13.
#
# If given:
#
# 		) REPLACE specifies the account current password to be replaced, as a cleartext (unencrypted) string
#
# 		) The clause must be given if password changes for the account are required to specify
# 			the current password, as verification that the user attempting to make the change
# 			actually knows the current password.
#
# 		) The clause is optional if password changes for the account may but need not specify the current password
#
# 		) The statement fails if the clause is given but does not match the current password, even if the clause is optional
#
# 		) REPLACE can be specified only when changing the account password for the current user
#
# For more information about password verification by specifying the current password, see SECTION 6.3.8,
# "PASSWORD MANAGEMENT"
#
# The RETAIN CURRENT PASSWORD clause implements dual-password capability and is available
# as of MySQL 8.0.14.
#
# If given:
#
# 		) RETAIN CURRENT PASSWORD retains an account current password as its secondary password,
# 			replacing any existing secondary password.
#
# 			The new password becomes the primary password, but clients can use the account to
# 			connect to the server using either the primary or secondary password.
#
# 			(Exception:
#
# 				If the new password specified by the SET_PASSWORD statement is empty,
# 				the secondary password becomes empty as well, even if RETAIN CURRENT PASSWORD
# 				is given)
#
# 		) If you specify RETAIN CURRENT PASSWORD for an account that has an empty primary password, the statement fails
#
# 		) If an account has a secondary password and you change its primary password without specifying
# 			RETAIN CURRENT PASSWORD, the secondary password remains unchanged.
#
# For more information about use of dual passwords, see SECTION 6.3.8, "PASSWORD MANAGEMENT"
#
# NOTE:
#
# 		Rather than using SET_PASSWORD_---_=_'auth_string' syntax, ALTER_USER syntax is the preferred
# 		statement for account alterations, including assigning passwords.
#
# 		For example:
#
# 			ALTER USER user IDENTIFIED BY 'auth_string';
#
# IMPORTANT:
#
# 		Under some circumstances, SET_PASSWORD may be recorded in server logs or on the client
# 		side in a history file such as ~/.mysql_history, which means that cleartext passwords
# 		may be read by anyone having read access t othat information.
#
# 		For information about the conditions under which this occurs for the server logs
# 		and how to control it, see SECTION 6.1.2.3, "PASSWORDS AND LOGGING"
#
# 		For similar information about client-side logging, see SECTION 4.5.1.3, "MYSQL CLIENT LOGGING"
#
# SET_PASSWORD can be used with or without a FOR clause that explicitly names a user account:
#
# 		) With a FOR user clause, the statement sets the password for the named account, which must exist:
#
# 			SET PASSWORD FOR 'jeffrey'@'localhost' = 'auth_string';
#
# 		) With no FOR user clause, the statement sets the password for the current user:
#
# 				SET PASSWORD = 'auth_string';
#
# 			Any client who connects to the server using a nonanonymous account can change the
# 			password for that account.
#
# 			(In particular, you can change your own password)
#
# 			To see which account the server authenticated you as, invoke the CURRENT_USER()
# 			function:
#
# 				SELECT CURRENT_USER();
#
# If a FOR user clause is given, the account name uses the format described in SECTION 6.2.4,
# SPECIFYING ACCOUNT NAMES".
#
# For example:
#
# 		SET PASSWORD FOR 'bob'@'%.example.org' = 'auth_string';
#
# The host name part of the account name, if omitted, defaults to '%'
#
# SET_PASSWORD interprets the string as a cleartext string, passes it to the
# authentication plugin associated with the account, and stores the result 
# returned by the plugin in the account row in the mysql.user system table.
#
# (The plugin is given the opportunity to hash the value into the encryption
# format it expects.
#
# The plugin may use the value as specified, in which case no hashing occurs)
#
# Setting the password for a named account (with a FOR clause) requires the
# UPDATE privilege for the mysql system database.
#
# Setting the password for yourself (for a nonanonymous account with no 
# FOR clause) requires no special privileges.
#
# Statements that modify secondary passwords require these privileges:
#
# 		) The APPLICATION_PASSWORD_ADMIN privilege is required to use the RETAIN
# 			CURRENT PASSWORD clause for SET_PASSWORD statements that apply to your
# 			own account.
#
# 			the privilege is required to manipulate your own secondary password
# 			because most users require only one password
#
# 		) If an account is to be permitted to manipulate secondary passwords for
# 			all accounts, it should be granted the CREATE_USER privilege rather than
# 			APPLICATION_PASSWORD_ADMIN
#
# When the read_only system variable is enabled, SET_PASSWORD requires the CONNECTION_ADMIN
# or SUPER privilege in addition to any other required privileges.
#
# For additional information about setting passwords and authentication plugins, see
# SECTION 6.3.7, "ASSIGNING ACCOUNT PASSWORDS", and SECTION 6.3.10, "PLUGGABLE AUTHENTICATION"
#
# 13.7.1.11 SET ROLE SYNTAX
#
# 		SET ROLE {
# 			DEFAULT
# 		 | NONE
# 		 | ALL
# 		 | ALL EXCEPT role [, role ] ---
# 		 | role [, role ] ---
# 		}
#
# SET_ROLE modifies the current user's effective privileges within the current session by
# specifying which of its granted roles are active.
#
# Granted roles include those granted explicitly to the user and those named
# in the mandatory_roles system variable value.
#
# Privileges that the user has been granted directly (rather than through roles) remain
# unaffected by changes to the active roles.
#
# Each role name uses the format described in SECTION 6.2.5, "SPECIFYING ROLE NAMES".
#
# For example:
#
# 		SET ROLE DEFAULT;
# 		SET ROLE 'role1', 'role2';
# 		SET ROLE ALL;
# 		SET ROLE ALL EXCEPT 'role1', 'role2';
#
# The host name part of the role name, if omitted, defaults to '%'
#
# The statement permits these role specifiers:
#
# 		) DEFAULT:
#
# 			Activate the account default roles. Default roles are those specified with SET_DEFAULT_ROLE
#
# 			When a user connects to the server and authenticates successfully, the server determines
# 			which roles to activate as the default roles.
#
# 			If the activate_all_roles_on_login system variable is enabled, the server activates all granted
# 			roles.
#
# 			Otherwise, The server executes SET_ROLE_DEFAULT implicitly.
#
# 			The server activates only default roles that can be activated.
#
# 			The server wites warnings to its error log for default roles that cannot be	
# 			activated, but the client receives no warnings.
#
# 			If a user executes SET_ROLE_DEFAULT during a session, an error occurs if any
# 			default role cannot be activated (for example, if it does not exist or is not
# 			granted to the user)
#
# 			In this case, the currrent active roles are not changed.
#
# 		) NONE:
#
# 			Set the active roles to NONE (no active roles)
#
# 		) ALL:
#
# 			Activate all roles granted to the account
#
# 		) ALL EXCEPT role [, role ] ---:
#
# 			Activate all roles granted to the account except those named.
#
# 			The named roles need not exist or be granted to the account.
#
# 		) role [, role ] ---: 
#
# 			Activate the named roles, which must be granted to the account.
#
# NOTE:
#
# 		SET_DEFAULT_ROLE and SET_ROLE_DEFAULT are different statements:
#
# 			) SET_DEFAULT_ROLE defines which account roles to activate by default within account sessions.
#
# 			) SET_ROLE_DEFAULT sets the active roles within the current session to the current account default roles.
#
# 13.7.2 RESOURCE GROUP MANAGEMENT STATEMENTS
#
# 13.7.2.1 ALTER RESOURCE GROUP SYNTAX
# 13.7.2.2 CREATE RESOURCE GROUP SYNTAX
#
# 13.7.2.3 DROP RESOURCE GROUP SYNTAX
# 13.7.2.4 SET RESOURCE GROUP SYNTAX
#
# MySQL supports creation and management of resource groups, and permits assigning threads
# running within the server to particular groups so that threads execute according to the
# resources available to the group.
#
# This section describes the SQL statements available for resource group management.
#
# For general discussion of the resource group capability, see SECTION 8.12.5, "RESOURCE GROUPS"
#
# 13.7.2.1 ALTER RESOURCE GROUP SYNTAX
#
# 		ALTER RESOURCE GROUP group_name
# 			[VCPU [=] vcpu_spec [, vcpu_spec] ---]
# 			[THREAD_PRIORITY [=] N]
# 			[ENABLE|DISABLE [FORCE]]
#
# 		vcpu_spec: {N | M - N}
#
# ALTER_RESOURCE_GROUP is used for resource group management (see SECTION 8.12.5, "RESOURCE GROUPS")
#
# This statement alters modifiable attributes of an existing resource group.
#
# It requires the RESOURCE_GROUP_ADMIN privilege.
#
# group_name identifies which resource group to alter. If the group does not exist,
# an error occurs.
#
# The attributes for CPU affinity, priority, and whether the group is enabled can be
# modified with ALTER_RESOURCE_GROUP.
#
# These attributes are specified the same way as described for CREATE_RESOURCE_GROUP
# (see SECTION 13.7.2.2, "CREATE RESOURCE GROUP SYNTAX")
#
# Only the attributes specified are altered. Unspecified attributes retain their
# current values.
#
# The FORCE modifier is used with DISABLE.
#
# It determines statement behavior if the resource group has any threads assigned to it:
#
# 		) If FORCE is not given, existing threads in the group continue to run until they terminate,
# 			but new threads cannot be assigned to the group.
#
# 		) If FORCE is given, existing threads in the group are moved to their respective default group
# 			(system threads to SYS_default, user threads to USR_default)
#
# The name and type attributes are set at group creation time and cannot be modified thereafter
# with ALTER_RESOURCE_GROUP.
#
# Examples:
#
# 		) Alter a group CPU affinity:
#
# 			ALTER RESOURCE GROUP rg1 VCPU = 0-63;
#
# 		) Alter a group thread priority:
#
# 			ALTER RESOURCE GROUP rg2 THREAD_PRIORITY = 5;
#
# 		) Disable a group, moving any threads assigned to it to the default groups:
#
# 			ALTER RESOURCE GROUP rg3 DISABLE FORCE;
#
# Resource group management is local to the server on which it occurs.
#
# ALTER_RESOURCE_GROUP statements are not written to the binary log and are not
# replicated.
#
# 13.7.2.2 CREATE RESOURCE GROUP SYNTAX
#
# 		CREATE RESOURCE GROUP group_name
# 			TYPE = {SYSTEM|USER}
# 			[VCPU [=] vcpu_spec [, vcpu_spec] ---]
# 			[THREAD_PRIORITY [=] N]
# 			[ENABLE|DISABLE]
#
# 		vcpu_spec: {N | M - N}
#
# CREATE_RESOURCE_GROUP is used for resource group management (see SECTION 8.12.5, "RESOURCE GROUPS")
#
# This statement creates a new resource group and assigns its initial attribute values.
#
# It requires the RESOURCE_GROUP_ADMIN privilege.
#
# group_name identifies which resource group to create. If the group already exists,
# an error occurs.
#
# The TYPE attribute is required. It should be SYSTEM for a system resource group,
# USER for a user resource group.
#
# The group type affects permitted THREAD_PRIORITY values, as described later.
#
# The VCPU attribute indicates the CPU affinity; that is, the set of virtual CPUs
# the group can use:
#
# 		) If VCPU is not given, the resource group has no CPU affinity and can use all available CPUs.
#
# 		) If VCPU is given, the attribute value is a list of comma-separated CPU numbers or ranges:
#
# 			) Each number must be an integer in the range from 0 to the number of CPUs - 1.
#
# 				For example, on a system with 64 CPUs, the number can range from 0 to 63.
#
# 			) A range is given in the form M - N, where M is less than or equal to N and both
# 				numbers are in the CPU range.
#
# 			) If a CPU number is an integer outside the permitted range or is not an integer,
# 				an error occurs.
#
# Example VCPU specifiers (these are all equivalent):
#
# 		VCPU = 0,1,2,3,9,10
# 		VCPU = 0-3,9-10
# 		VCPU = 9,10,0-3
# 		VCPU = 0,10,1,9,3,2
#
# The THREAD_PRIORITY attribute indicates the priority for threads assigned to the group:
#
# 		) If THREAD_PRIORITY is not given, the default priority is 0
#
# 		) If THREAD_PRIORITY is given, the attribute value must be in the range from -20 (highest priority)
# 			to 19 (lowest priority)
#
# 			The priority for system resource groups must be in the range from -20 to 0.
#
# 			The priority for user resource groups must be in the range from 0 to 19
#
# 			Use of different ranges for system and user groups ensures that user threads
# 			never have a higher priority than system threads.
#
# ENABLE and DISABLE specify that the resource group is initially enabled or disabled.
#
# If neither is specified, the group is enabled by default.
#
# A disabled group cannot have threads assigned to it.
#
# Examples:
#
# 		) Create an enabled user group that has a single GPU and the lowest priority:
#
# 			CREATE RESOURCE GROUP rg1
# 				TYPE = USER
# 				VCPU = 0
# 				THREAD_PRIORITY = 19;
#
# 		) Create a disabled system group that has no CPU affinity (can use all CPUs) and the
# 			highest priority:
#
# 				CREATE RESOURCE GROUP rg2
# 					TYPE = SYSTEM
# 					THREAD_PRIORITY = -20
# 					DISABLE;
#
# Resource group management is local to the server on which it occurs.
#
# CREATE_RESOURCE_GROUP statements are not written to the binary log and 
# are not replicated.
#
# 13.7.2.3 DROP RESOURCE GROUP SYNTAX
#
# 		DROP RESOURCE GROUP group_name [FORCE]
#
# DROP_RESOURCE_GROUP is used for resource group management (see SECTION 8.12.5, "RESOURCE GROUPS")
#
# This statement drops a resource group. It requires the RESOURCE_GROUP_ADMIN privilege.
#
# group_name identifies which resource group to drop. If the group does not exist, an error occurs.
#
# The FORCE modifier determines statement behavior if the resource group has any threads assigned to it:
#
# 		) If FORCE is not given and any threads are assigned to the group, an error occurs.
#
# 		) If FORCE is given, existing threads in the group are moved to their respective default group
# 			(system threads to SYS_default, user threads to USR_default)
#
# Examples:
#
# 		) Drop a group, failing if the group contains any threads:
#
# 			DROP RESOURCE GROUP rg1;
#
# 		) Drop a group and move existing threads to the default groups:
#
# 			DROP RESOURCE GROUP rg2 FORCE;
#
# Resource group management is local to the server on which it occurs.
#
# DROP_RESOURCE_GROUP statements are not written to the binary log and are not replicated.
#
# 13.7.2.4 SET RESOURCE GROUP SYNTAX
#
# 		SET RESOURCE GROUP group_name
# 			[FOR thread_id [, thread_id] ---]
#
# SET_RESOURCE_GROUP is used for resource group management (see SECTION 8.12.5, "RESOURCE GROUPS")
#
# This statement assigns threads to a resource group.
#
# It requires the RESOURCE_GROUP_ADMIN or RESOURCE_GROUP_USER privilege.
#
# group_name identifies which resource group to be assigned. Any thread_id values indicate
# threads to assign to the group.
#
# Thread IDs can be determined from the Performance Schema threads table.
#
# If the resource group or any named thread ID does not exist, an error occurs.
#
# With no FOR clause, the statement assigns the current thread for the session to the
# resource group.
#
# With a FOR clause that names thread IDs, the statement assigns those threads to the
# resource group.
#
# For attempts to assign a system thread to a user resource group or a user thread to
# a system resource group, a warning occurs.
#
# Examples:
#
# 		) Assign the current session thread to a group:
#
# 			SET RESOURCE GROUP rg1;
#
# 		) Assign the named threads to a group:
#
# 			SET RESOURCE GROUP rg2 FOR 14, 78, 4;
#
# Resource group management is local to the server on which it occurs.
#
# SET_RESOURCE_GROUP statements are not written to the binary log and are not replicated.
#
# An alternative to SET_RESOURCE_GROUP is the RESOURCE_GROUP optimizer hint, which assigns
# individual statements to a resource group.
#
# See SECTION 8.9.2, "OPTIMIZER HINTS"
#
# 13.7.3 TABLE MAINTENANCE STATEMENTS
#
# 13.7.3.1 ANALYZE TABLE SYNTAX
# 13.7.3.2 CHECK TABLE SYNTAX
#
# 13.7.3.3 CHECKSUM TABLE SYNTAX
# 13.7.3.4 OPTIMIZE TABLE SYNTAX
#
# 13.7.3.5 REPAIR TABLE SYNTAX
#
# 13.7.3.1 ANALYZE TABLE SYNTAX
#
# 		ANALYZE [NO_WRITE_TO_BINLOG | LOCAL]
# 			TABLE tbl_name [, tbl_name] ---
#
# 		ANALYZE [NO_WRITE_TO_BINLOG | LOCAL]
# 			TABLE tbl_name
# 			UPDATE HISTOGRAM ON col_name [, col_name] ---
# 				[WITH N BUCKETS]
#
# 		ANALYZE [NO_WRITE_TO_BINLOG | LOCAL]
# 			TABLE tbl_name
# 			DROP HISTOGRAM ON col_name [, col_name] ---
#
# ANALYZE_TABLE generates table statistics:
#
# 		) ANALYZE_TABLE without either HISTOGRAM clause performs a key distribution analysis
# 			and stores the distribution for the named table or tables.
#
# 			For MyISAM tables, ANALYZE_TABLE for key distribution analysis is equivalent to using
# 			myisamchk --analyze
#
# 		) ANALYZE_TABLE with the UPDATE HISTOGRAM clause generates histogram statistics for the named
# 			table columns and stores them in the data dictionary.
#
# 			Only one table name is permitted for this syntax
#
# 		) ANALYZE_TABLE with the DROP HISTOGRAM clause removes histogram statistics for the named table
# 			columns from the data dictionary.
#
# 			Only one table name is permitted for this syntax.
#
# NOTE:
#
# 		If the innodb_read_only system variable is enabled, ANALYZE_TABLE may fail because it
# 		cannot update statistics tables in the data dictionary, which use InnoDB.
#
# 		For ANALYZE_TABLE operations that update the key distribution, failure may occur even
# 		if the operation updates the table itself (for example, if it is a MyISAM table)
#
# 		To obtain the updated distribution statistics, set information_schema_stats_expiry=0
#
# This statement requires SELECT and INSERT privileges for the table.
#
# ANALYZE_TABLE works with InnoDB, NDB and MyISAM tables. It does not work with views.
#
# ANALYZE_TABLE is supported for partitioned tables, and you can use ALTER TABLE --- ANALYZE PARTITION
# to analyze one or more partitions, for more information, see SECTION 13.1.9, "ALTER TABLE SYNTAX"
# and SECTION 23.3.4, "MAINTENANCE OF PARTITIONS"
#
# During the analysis, the table is locked with a read lock for InnoDB and MyISAM.
#
# By default, the server writes ANALYZE_TABLE statements to the binary log so that they replicate
# to replication slaves.
#
# To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL.
#
# 		) ANALYZE TABLE OUTPUT
#
# 		) KEY DISTRIBUTION ANALYSIS
#
# 		) HISTOGRAM STATISTICS ANALYSIS
#
# ANALYZE TABLE OUTPUT
#
# ANALYZE_TABLE returns a result set with the columns shown in the following table.
#
# 		COLUMN 					VALUE
#
# 		Table 					The table name
#
# 		Op 						analyze or histogram
#
# 		Msg_type 				status, error, info, note or warning
#
# 		Msg_text 				An informational message
#
# KEY DISTRIBUTION ANALYSIS
#
# ANALYZE_TABLE without either HISTOGRAM clause performs a key distribution analysis
# and stores the distribution for the table or tables.
#
# Any existing histogram statistics remain unaffected.
#
# If the table has not changed since the last key distribution analysis,
# the table is not analyzed again.
#
# MySQL uses the stored key distribution to decide the order in which tables should be
# joined for joins on something other than a constant.
#
# In addition, key distributions can be used when deciding which indexes to use
# for a specific table within a query.
#
# For more information on how key distribution analysis works within InnoDB,
# see SECTION 15.8.10.1, "CONFIGURING PERSISTENT OPTIMIZER STATISTICS PARAMETERS"
# and SECTION 15.8.10.3, "ESTIMATING ANALYZE TABLE COMPLEXITY FOR INNODB TABLES"
#
# Also see SECTION 15.6.1.6, "LIMITS ON INNODB TABLES"
#
# In particular, when you enable the innodb_stats_persistent option,
# you must run ANALYZE_TABLE after loading substansial data into an InnoDB
# table, or creating a new index for one.
#
# To check the stored key distribution cardinality, use the SHOW_INDEX statement
# or the INFORMATION_SCHEMA STATISTICS table.
#
# See SECTION 13.7.6.22, "SHOW INDEX SYNTAX", and SECTION 25.25, "THE INFORMATION_SCHEMA STATISTICS TABLE"
#
# HISTOGRAM STATISTICS ANALYSIS
#
# ANALYZE_TABLE with the HISTOGRAM clauses enables management of histogram statistics for table
# column values.
#
# For information about histogram statistics, see SECTION 8.9.6, "OPTIMIZER STATISTICS"
#
# These histogram operations are available:
#
# 		) ANALYZE_TABLE with an UPDATE HISTOGRAM clause generates histogram statistics for the
# 			named table columns and stores them in the data dictionary.
#
# 			Only one table name is permitted for this syntax.
#
# 			The optional WITH N BUCKETS clauses specifies the number of buckets for the histogram.
#
# 			The value of N must be an integer in the range from 1 to 1024.
#
# 			If this clause is omitted, the number of buckets is 100.
#
# 		) ANALYZE_TABLE with a DROP HISTOGRAM clause removes histogram statistics for the named
# 			table columns from the data dictionary.
#
# 			Only one table name is permitted for this syntax.
#
# Stored histogram management statements affect only the named columns.
#
# Consider these statements:
#
# 		ANALYZE TABLE t UPDATE HISTOGRAM ON c1, c2, c3 WITH 10 BUCKETS;
# 		ANALYZE TABLE t UPDATE HISTOGRAM ON c1, c3 WITH 10 BUCKETS;
# 		ANALYZE TABLE t DROP HISTOGRAM ON c2;
#
# The first statement updates the histograms for columns c1, c2, and c3, replacing
# any existing histograms for those columns.
#
# The second statement updates the histograms for c1 and c3, leaving the c2 histogram
# unaffected.
#
# The third statement removes the histogram for c2, leaving those for c1 and c3 unaffected.
#
# Histogram generation is not supported for encrypted tables (to avoid exposing data in the statistics) or TEMPORARY tables.
#
# Histogram generation applies to columns of all data types except geometry types (spatial data) and JSON.
#
# Histograms can be generated for stored and virtual generated columns.
#
# Histograms cannot be generated for columns that are covered by single-column unique indexes.
#
# Histogram management statements attempt to perform as much of the requested operation as possible,
# and report diagnostic messages for the remainder.
#
# For example, if an UPDATE HISTOGRAM statement names multiple columns, but some of them do not
# exist or have an unsupported data type, histograms are generated for the other columns,
# and messages are produced for the invalid columns.
#
# The histogram_generation_max_mem_size system variable controls the maximum amount of memory
# available for histogram generation.
#
# The global and session values may be set at runtime.
#
# Changing the global histogram_generation_max_mem_size value requires privileges
# sufficient to set global system variables.
#
# Changing the session histogram_generation_max_mem_size value requires privileges
# sufficient to set restricted session system variables.
#
# See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"
#
# For information about memory allocations performed for histogram generation, monitor
# the Performance Schema memory/sql/histograms instrument.
#
# See SECTION 26.12.16.10, "MEMORY SUMMARY TABLES"
#
# Histograms are affected by these DDL statements:
#
# 		) DROP_TABLE removes histograms for columns in the dropped table
#
# 		) DROP_DATABASE removes histograms for any table in the dropped database because the statement drops all tables in the database
#
# 		) RENAME_TABLE does not remove histograms. Instead, it renames histograms for the renamed table to be associated with the new table name
#
# 		) ALTER_TABLE statements that remove or modify a column remove histograms for that column
#
# 		) ALTER_TABLE_---_CONVERT_TO_CHARACTER_SET removes histograms for character columns because they are
# 			affected by the change of character set.
#
# 			Histograms for noncharacter columns remain unaffected.
#
# 13.7.3.2 CHECK TABLE SYNTAX
#
# 		CHECK TABLE tbl_name [, tbl_name] --- [option] ---
#
# 		option: {
# 			FOR UPGRADE
# 		 | QUICK
# 		 | FAST
# 		 | MEDIUM
# 		 | EXTENDED
# 		 | CHANGED
# 		}
#
# CHECK_TABLE checks a table or tables for errors.
#
# CHECK_TABLE can also check views for problems, such as tables that are referenced
# in the view definition that no longer exist.
#
# To check a table, you must have some privilege for it.
#
# CHECK_TABLE works for InnoDB, MyISAM, ARCHIVE and CSV tables.
#
# Before running CHECK_TABLE on InnoDB tables, see CHECK TABLE USAGE NOTES FOR INNODB TABLES.
#
# CHECK_TABLE is supported for partitioned tables, and you can use ALTER TABLE --- CHECK PARTITION
# to check one or more partitions; for more information, see SECTION 13.1.9, "ALTER TABLE SYNTAX",
# and SECTION 23.3.4, "MAINTENANCE OF PARTITIONS"
#
# CHECK_TABLE ignores virtual generated columns that are not indexed.
#
# 		) CHECK TABLE OUTPUT
#
# 		) CHECKING VERSION COMPATIBILITY
#
# 		) CHECKING DATA CONSISTENCY
#
# 		) CHECK TABLE USAGE NOTES FOR INNODB TABLES
#
# 		) CHECK TABLE USAGE NOTES FOR MYISAM TABLES
#
# CHECK TABLE OUTPUT
#
# CHECK_TABLE returns a result set with the columns shown in the following table.
#
# 		COLUMN 				VALUE
#
# 		Table 				The table name
#
# 		Op 					Always check
#
# 		Msg_type 			status, error, info, note or warning
#
# 		Msg_text 			An informational message
#
# The statement might produce many rows of information for each checked table.
#
# The last row has a Msg_type value of status and the Msg_text normally should be
# OK.
#
# Table is already up to date means that the storage engine for the table indicated
# that there was no need to check the table.
#
# CHECKING VERSION COMPATIBILITY
#
# The FOR UPGRADE option checks whether the named tables are compatible with the
# current version of MySQL.
#
# With FOR UPGRADE, the server checks each table to determine whether there
# have been any incompatible changes in any of the table's data types or indexes
# since the table was created.
#
# If not, the check succeeds.
#
# Otherwise, if there is a possible incompatibility, the server runs a full check
# on the table (which might take some time)
#
# Incompatibilities might occur because the storage format for a data type has
# changed or because its sort order has changed.
#
# Our aim is to avoid these changes, but occasionally they are necessary to correct
# problems that would be worse than an incompatibility between releases.
#
# FOR UPGRADE discovers these incompatibilities:
#
# 		) The indexing order for end-space in TEXT columns for InnoDB and MyISAM tables
# 			changed between MySQL 4.1 and MySQL 5.0
#
# 		) The storage method of the new DECIMAL data type changed between MySQL 5.0.3 and 5.0.5
#
# 		) Changes are sometimes made to character sets or collations that require table indexes
# 			to be rebuilt.
#
# 			For details about such changes, see SECTION 2.11.1.3, "CHANGES IN MYSQL 8.0"
#
# 			For information about rebuilding tables, see SECTION 2.11.3, "REBUILDING OR REPAIRING TABLES OR INDEXES"
#
# 		) MySQL 8.0 does not support the YEAR(2) data type permitted in older versions of MySQL.
#
# 			For tables containing YEAR(2) columns, CHECK_TABLE recommends REPAIR_TABLE, which converts
# 			YEAR(2) to YEAR(4)
#
# 		) Trigger creation time is maintained.
#
# 		) A table is reported as needing a rebuild if it contains old temporal columns in pre
# 			5.6.4 format (TIME, DATETIME, and TIMESTAMP columns without support for fractional
# 			seconds precision) and the avoid_temporal_upgrade system variable is disabled.
#
# 			This helps mysql_upgrade detect and upgrade tables containing old temporal
# 			columns.
#
# 			If avoid_temporal_upgrade is enabled, FOR UPGRADE ignores the old temporal
# 			columns present in the table; consequently, mysql_upgrade does not upgrade them.
#
# 			To check for tables that contain such temporal columns and need a rebuild,
# 			disable avoid_temporal_upgrade before executing CHECK_TABLE_---_FOR_UPGRADE
#
# 		) Warnings are issued for tables that use nonnative partitioning because nonnative
# 			partitioning is removed in MySQL 8.0
#
# 			See CHAPTER 23, PARTITIONING
#
# CHECKING DATA CONSISTENCY
#
# The following table shows the other check options that can be given.
#
# These options are passed to the storage engine, which may use or ignore them.
#
# 		TYPE 					MEANING
#
# 		QUICK 				Do not scan the rows to check for incorrect links. Applies to InnoDB and MyISAM tables and views.
#
# 		FAST 					Check only tables that have not been closed properly. Ignored for InnoDB; applies only to MyISAM tables and views.
#
# 		CHANGED 				Check only tables that have been changed since the last check or that have not been closed
# 								properly.
#
# 								Ignored for InnoDB; applies only to MyISAM tables and views.
#
# 		MEDIUM 				Scan rows to verify that deleted links are valid.
#
# 								This also calculates a key checksum for the rows and verifies this with
# 								a calculated checksum for the keys.
#
# 								Ignored for InnoDB; applies only to MyISAM tables and views.
#
# 		EXTENDED 			Do a full key lookup for all keys for each row.
#
# 								This ensures that the table is 100% consistent, but takes a long time.
# 								Ignored for InnoDB; applies only to MyISAM tables and views.
#
# You can combine check options, as in the following example that does a quick check on the table
# to determine whether it was closed properly:
#
# 		CHECK TABLE test_table FAST QUICK;
#
# NOTE:
#
# 		If CHECK_TABLE finds no problems with a table that is marked as "corrupted" or
# 		"not closed properly", CHECK_TABLE may remove the mark.
#
# If a table is corrupted, the problem is most likely in the indexes and not in teh data part.
#
# All of the preceeding check types check the indexes thoroughly and should thus find
# most errors.
#
# To check a table that you assume is okay, use no check options or the QUICK option.
#
# The latter should be used when you are in a hurry and can take the very small
# risk that QUICK does not find an error in the data file.
#
# (In most cases, under normal usage, MySQL should find any error in the data file.
#
# If this happens, the table is marked as "corrupted" and cannot be used until it is
# repaired.)
#
# FAST and CHANGED are mostly intended to be used from a script (for example, to be executed
# from cron) to check tables periodically.
#
# In most cases, FAST is to be preferred over CHANGED. (The only case when it is not preferred
# is when you suspect that you have found a bug in the MyISAM code)
#
# EXTENDED is to be used only after you have run a normal check but still get errors from
# a table when MySQL tries to update a row or find a row by key.
#
# This is very unlikely if a normal check has succeeded.
#
# Use of CHECK_TABLE_---_EXTENDED might influence execution plans generated by the query optimizer.
#
# Some problems reported by CHECK_TABLE cannot be corrected automatically:
#
# 		) Found row where the auto_increment column has the value 0
#
# 			This means that you have a row in the table where the AUTO_INCREMENT index column
# 			contains the value 0.
#
# 			(It is possible to create a row where the AUTO_INCREMENT column is 0 by explicitly
# 			setting the column to 0 with an UPDATE statement)
#
# 			This is not an error in itself, but could cause trouble if you decide to dump the
# 			table and restore it or do an ALTER_TABLE on the table.
#
# 			In this case, the AUTO_INCREMENT column changes value according to the rules
# 			of AUTO_INCREMENT columns, which could cause problems such as a duplicate-key
# 			error.
#
# 			To get rid of the warning, execute an UPDATE statement to set the column to some value
# 			other than 0.
#
# CHECK TABLE USAGE NOTES FOR INNODB TABLES
#
# The following notes apply to InnoDB tables:
#
# 		) If CHECK_TABLE encounters a corrupt page, the server exits to prevent error propagation
# 			(Bug #10132)
#
# 			If the corruption occurs in a secondary index but table data is readable, running
# 			CHECK_TABLE can still cause a server exit.
#
# 		) If CHECK_TABLE encounters a corrupted DB_TRX_ID or DB_ROLL_PTR field in a clustered index,
# 			CHECK_TABLE can cause InnoDB to access an invalid undo log record, resulting
# 			in an MVCC-related server exit.
#
# 		) If CHECK_TABLE encounters errors in InnoDB tables or indexes, it reports an error, and usually
# 			marks the index and sometimes marks the table as corrupted, preventing further use
# 			of the index or table.
#
# 			Such errors include an incorrect number of entries in a secondary index or incorrect links.
#
# 		) If CHECK_TABLE finds an incorrect number of entries in a secondary index, it reports an error
# 			but does not cause a server exit or prevent access to the file.
#
# 		) CHECK_TABLE surveys the index page structure, then surveys each key entry.
#
# 			It does not validate the key pointer to a clustered record or follow
# 			the path for BLOB pointers.
#
# 		) When an InnoDB table is stored in its own .ibd file, the first 3 pages of the
# 			.ibd file contain header information rather than table or index data.
#
# 			The CHECK_TABLE statement does not detect inconsistencies that affect only
# 			the header data.
#
# 			To verify the entire contents of an InnoDB .ibd file, use the innochecksum
# 			command.
#
# 		) When running CHECK_TABLE on large InnoDB tables, other threads may be blocked
# 			during CHECK_TABLE execution.
#
# 			To avoid timeouts, the semaphore wait threshold (600 seconds) is extended
# 			by 2 hours (7200 seconds) for CHECK_TABLE operations.
#
# 			If InnoDB detects semaphore waits of 240 seconds or more, it starts
# 			printing InnoDB monitor output to the error log.
#
# 			If a lock request extends beyond the semaphore wait threshold, InnoDB
# 			aborts the process.
#
# 			To avoid the possibility of a semaphore wait timeout entirely, run
# 			CHECK_TABLE_QUICK instead of CHECK_TABLE
#
# 		) CHECK_TABLE functionality for InnoDB SPATIAL indexes includes an R-tree
# 			validity check and a check to ensure that the R-tree row count matches
# 			the clustered index.
#
# 		) CHECK_TABLE supports secondary indexes on virtual generated columns, which
# 			are supported by InnoDB.
#
# 		) As of MySQL 8.0.14, InnoDB supports parallel index reads, which helps improve
# 			CHECK_TABLE performance.
#
# 			The innodb_parallel_read_threads session variable must be set to a value
# 			greater than 1 for parallel index reads to occur.
#
# 			THe default value is 4.
#
# 			The actual number of threads used to perform a parallel index read
# 			is determined by the innodb_parallel_read_threads setting or the
# 			number of index subtrees to scan, whichever is smaller.
#
# 			The pages read into the buffer pool during the scan are kept at the tail
# 			of the buffer pool LRU list so that they can be discarded quickly when
# 			free buffer pool pages are required.
#
# CHECK TABLE USAGE NOTES FOR MYISAM TABLES
#
# The following notes apply to MyISAM tables:
#
# 		) CHECK_TABLE updates key statistics for MyISAM tables
#
# 		) If CHECK_TABLE output does not return OK or Table is already up to date,
# 			you should normally run a repair of the table.
#
# 			See SECTION 7.6, "MyISAM TABLE MAINTENANCE AND CRASH RECOVERY"
#
# 		) If none of the CHECK_TABLE options QUICK, MEDIUM or EXTENDED are specified,
# 			the default check type for dynamic-format MyISAM tables is MEDIUM.
#
# 			This has the same result as running myisamchk --medium-check tbl_name
# 			on the table.
#
# 			The default check type also is MEDIUM for static-format MyISAM tables,
# 			unless CHANGED or FAST is specified.
#
# 			In that case, the default is QUICK.
#
# 			The row scan is skipped for CHANGED and FAST because the rows are
# 			very seldom corrupted.
#
# 13.7.3.3 CHECKSUM TABLE SYNTAX
#
# 		CHECKSUM TABLE tbl_name [, tbl_name] --- [QUICK | EXTENDED]
#
# CHECKSUM_TABLE reports a checksum for the contents of a table.
#
# You can use this statement to verify that the contents are the same before
# and after a backup, rollback, or other operation that is intended to put
# the data back to a known state.
#
# This statement requires the SELECT privilege for the table.
#
# This statement is not supported for views. If you run CHECKSUM_TABLE against
# a view, the Checksum value is always NULL, and a warning is returned.
#
# For a nonexistent table, CHECKSUM_TABLE returns NULL and generates a warning
#
# During the checksum operation, the table is locked with a read lock for InnoDB
# and MyISAM.
#
# PERFORMANCE CONSIDERATIONS
#
# By default, the entire table is read row by row and the checksum is calculated.
#
# For large tables, this could take a long time, thus you would only perform this
# operation occasionally.
#
# This row-by-row calculation is what you get with the EXTENDED clause, with InnoDB
# and all other storage engines other than MyISAM, and with MyISAM tables not created
# with the CHECKSUM=1 clause.
#
# For MyISAM tables created with the CHECKSUM=1 clause, CHECKSUM_TABLE or CHECKSUM_TABLE_---_QUICK
# returns the "live" table checksum that can be returned very fast.
#
# If the table does not meet all these conditions, the QUICK method returns NULL.
#
# THe QUICK method is not supported with InnoDB tables. See SECTION 13.1.20, "CREATE TABLE SYNTAX"
# for the syntax of the CHECKSUM clause.
#
# The checksum value depends on the table row format. If the row format changes, the checksum
# also changes.
#
# For example, the storage format for temporal types such as TIME, DATETIME and TIMESTAMP
# changed in MySQL 5.6 prior to MySQL 5.6.5, so if a 5.5 table is upgraded to MySQL 5.6,
# the checksum value may change.
#
# IMPORTANT:
#
# 		If the checksums for two tables are different, then it is almost certain that
# 		the tables are different in some way.
#
# 		However, because the hashing function used by CHECKSUM_TABLE is not guaranteed
# 		to be collision-free, there is a slight chance that two tables which are not
# 		identical can produce the same checksum.
#
# 13.7.3.4 OPTIMIZE TABLE SYNTAX
#
# 		OPTIMIZE [NO_WRITE_TO_BINLOG | LOCAL]
# 			TABLE tbl_name [, tbl_name] ---
#
# OPTIMIZE_TABLE reorganizes the physical storage of table data and associated
# index data, to reduce storage space and improve I/O efficiency when accessing
# the table.
#
# The exact changes made to each table depend on the storage engine used by that
# table.
#
# Use OPTIMIZE_TABLE in these cases, depending on the type of table:
#
# 		) After doing substansial insert, update or delete operations on an
# 			InnoDB table that has its own .ibd file because it was created with the
# 			innodb_file_per_table option enabled.
#
# 			The table and indexes are reorganized, and disk space can be reclaimed
# 			for use by the operating system.
#
# 		) After doing substansial insert, update or delete operations on columns
# 			that are part of a FULLTEXT index in an InnoDB table.
#
# 			Set the configuration option innodb_optimize_fulltext_only=1 first
#
# 			To keep the index maintenance period to a reasonable time, set the
# 			innodb_ft_num_word_optimize option to specify how many words to update
# 			in the search index, and run a sequence of OPTIMIZE TABLE statements
# 			until the search index is fully updated.
#
# 		) After deleting a large part of a MyISAM or ARCHIVE table, or making many
# 			changes to a MyISAM or ARCHIVE table with variable-length rows
# 			(tables that have VARCHAR, VARBINARY, BLOB or TEXT columns)
#
# 			Deleted rows are maintained in a linked list and subsequent INSERT
# 			operations reuse old row positions.
#
# 			You can use OPTIMIZE TABLE to reclaim the unused space and to
# 			defragment the data file.
#
# 			After extensive changes to a table, this statement may also
# 			improve performance of statements that use the table, 
# 			sometimes significantly.
#
# This statement requires SELECT and INSERT privileges for the table.
#
# OPTIMIZE_TABLE works for InnoDB, MyISAM and ARCHIVE tables.
#
# OPTIMIZE_TABLE is also supported for dynamic columns of in-memory NDB
# tables.
#
# It does not work for fixed-width columns of in-memory tables, nor does it
# work for Disk Data tables.
#
# The performance of OPTIMIZE on NDB Cluster tables can be tuned using
# --ndb_optimization_delay, which controls the length of time to wait
# between processing batches of rows by OPTIMIZE_TABLE.
#
# For more information, see PREVIOUS NDB CLUSTER ISSUES RESOLVED IN NDB
# CLUSTER 7.3
#
# For NDB Cluster tables, OPTIMIZE_TABLE can be interuppted by (for example)
# killing the SQL thread performing the OPTIMIZE operation.
#
# By default, OPTIMIZE_TABLE does not work for tables created using any
# other storage engine and returns a result indicating this lack of support.
#
# You can make OPTIMIZE TABLE work for other storage engines by starting
# mysqld with the --skip-new option.
#
# In this case, OPTIMIZE_TABLE is just mapped to ALTER_TABLE
#
# This statement does not work with views
#
# OPTIMIZE_TABLE is supported for partitioned tables. For information about using
# this statement with partitioned tables and table partitions, see SECTION 23.3.4,
# "MAINTENANCE OF PARTITIONS"
#
# By default, the server writes OPTIMIZE_TABLE statements to the binary log so that
# they replicate to replication slaves.
#
# To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its
# alias LOCAL.
#
# 		) OPTIMIZE TABLE OUTPUT
#
# 		) INNODB DETAILS
#
# 		) MYISAM DETAILS
#
# 		) OTHER CONSIDERATIONS
#
# OPTIMIZE TABLE OUTPUT
#
# OPTIMIZE_TABLE returns a result set with the columns shown in the following table.
#
# 		COLUMN 				VALUE
#
# 		Table 				The table name
#
# 		Op 					Always optimize
#
# 		Msg_type 			status, error, info, note, or warning
#
# 		Msg_text 			An informational message
#
# OPTIMIZE_TABLE table catches and throws any errors that occur while copying
# table statistics from the old file to the newly created file.
#
# For example, if the user ID of the owner of the .MYD or .MYI file is
# different from the user ID of the mysqld process, OPTIMIZE_TABLE generates
# a "cannot change ownership of the file" error unless mysqld is started
# by the root user.
#
# INNODB DETAILS
#
# For InnoDB tables, OPTIMIZE_TABLE is mapped to ALTER_TABLE_---_FORCE,
# which rebuilds the table to update index statistics and free unused
# space in the clustered index.
#
# THis is displayed in the output of OPTIMIZE_TABLE when you run it on
# an InnoDB table, as shown here:
#
# 		OPTIMIZE TABLE foo;
# 		+--------------+------------------+-------------------+-------------------------------------------------------------------+
# 		| Table 			| Op 					 | Msg_type 			| Msg_text 																 			  |
# 		+--------------+------------------+-------------------+-------------------------------------------------------------------+
# 		| test.foo 		| optimize 			 | note 					| Table does not support optimize, doing recreate + analyze instead |
# 		| test.foo 		| optimize 			 | status 				| OK 																					  |
# 		+--------------+------------------+-------------------+-------------------------------------------------------------------+
#
# OPTIMIZE_TABLE uses online DDL for regular and partitioned InnoDB tables, which reduces downtime
# for concurrent DML operations.
#
# The table rebuild triggered by OPTIMIZE_TABLE and performed under the cover by ALTER_TABLE_---_FORCE is completed
# in place.
#
# An exclusive table lock is only taken briefly during the prepare phase and the commit phase of the operation.
#
# During the prepare phase, metadata is updated and an intermediate table is created.
#
# During the commit phase, table metadata changes are committed.
#
# OPTIMIZE_TABLE rebuilds the table using the table copy method under the following conditions:
#
# 		) When the old_alter_table system variable is enabled
#
# 		) When the mysqld --skip-new option is enabled
#
# OPTIMIZE_TABLE using online DDL is not supported for InnoDB tables that contain
# FULLTEXT indexes.
#
# The table copy method is used instead.
#
# InnoDB stores data using a page-allocation method and does not suffer from fragmentation
# in the same way that legacy storage engines (such as MyISAM) will.
#
# When considering whether or not to run optimize, consider the workload of transactions
# that your server will process:
#
# 		) Some level of fragmentation is expected. InnoDB only fills pages 93% full, to leave room
# 			for updates without having to split pages.
#
# 		) Delete operations might leave gaps that leave gaps less filled than desired, which could make
# 			it worthwhile to optimize the table
#
# 		) Updates to rows usually rewrite the data within the same page, depending on the data type
# 			and row format, when sufficient space is available.
#
# 			See SECTION 15.9.1.5, "HOW COMPRESSION WORKS FOR INNODB TABLES" and
# 			SECTION 15.10, "INNODB ROW FORMATS"
#
# 		) High-concurrency workloads might leave gaps in indexes over time, as InnoDB
# 			retains multiple versions of the same data due through its MVCC
# 			mechanism.
#
# 			See SECTION 15.3, "INNODB MULTI-VERSIONING"
#
# MYISAM DETAILS
#
# For MyISAM tables, OPTIMIZE_TABLE works as follows:
#
# 		1. If the table has deleted or split rows, repair the table
#
# 		2. If the index pages are not sorted, sort them
#
# 		3. If the table's statistics are not up to date (and the repair could not be accomplished by sorting the index),
# 			update them.
#
# OTHER CONSIDERATIONS
#
# OPTIMIZE_TABLE is performed online for regular and partitioned InnoDB tables.
#
# Otherwise, MySQL locks the table during the time OPTIMIZE_TABLE is running.
#
# OPTIMIZE_TABLE does not sort R-tree indexes, such as spatial indexes on POINT columns.
# (Bug #23578)
#
# 13.7.3.5 REPAIR TABLE SYNTAX
#
# 		REPAIR [NO_WRITE_TO_BINLOG | LOCAL]
# 			TABLE tbl_name [, tbl_name] ---
# 			[QUICK] [EXTENDED] [USE_FRM]
#
# REPAIR_TABLE repairs a possibly corrupted table, for certain storage engines only.
#
# This statement requires SELECT and INSERT privileges for the table.
#
# Although normally you should never have to run REPAIR_TABLE, if disaster strikes,
# This statement is very likely to get back all your data from a MyISAM table.
#
# If your tables become corrupted often, try to find the reason for it, to
# eliminate the need to use REPAIR_TABLE
#
# See SECTION B.6.3.3, "WHAT TO DO IF MYSQL KEEPS CRASHING", and SECTION 16.2.4, "MYISAM TABLE PROBLEMS"
#
# REPAIR_TABLE checks the table to see whether an upgrade is required.
#
# If so, it performs the upgrade, following the same rule as CHECK_TABLE_---_FOR_UPGRADE
#
# See SECTION 13.7.3.2, "CHECK TABLE SYNTAX", for more information.
#
# IMPORTANT:
#
# 		) Make a backup of a table before performing a table repair operation; under some circumstances
# 			the operation might cause data loss.
#
# 			Possible causes include but are not limited to file system errors.
#
# 			See CHAPTER 7, BACKUP AND RECOVERY
#
# 		) If the server crashes during a REPAIR_TABLE operation, it is essential after restarting it
# 			that you immediately execute another REPAIR_TABLE statement for the table before performing
# 			any other operations on it.
#
# 			In the worst case, you might have a new clean index file without information
# 			about the data file, and then the next operation you perform could overwrite
# 			the data file.
#
# 			This is an unlikely but possible scenario that underscores the value of making a backup first.
#
# 		) In the event that a table on the master becomes corrupted and you run REPAIR_TABLE on it,
# 			any resulting changes to the original table are not propagated to slaves.
#
# 	) REPAIR TABLE STORAGE ENGINE AND PARTITIONING SUPPORT
#
# 	) REPAIR TABLE OPTIONS
#
# 	) REPAIR TABLE OUTPUT
#
# 	) TABLE REPAIR CONSIDERATIONS
#
# REPAIR TABLE STORAGE ENGINE AND PARTITIONING SUPPORT
#
# REPAIR_TABLE works for MyISAM, ARCHIVE and CSV tables.
#
# For MyISAM tables, it has the same effect as myisamchk --recover tbl_name by default.
#
# This statement does not work with views.
#
# REPAIR_TABLE is supported for partitioned tables. However, the USE_FRM option cannot be
# used with this statement on a partitioned table.
#
# You can use ALTER TABLE --- REPAIR PARTITION to repair one or more partitions; for more 
# information, see SECTION 13.1.9, "ALTER TABLE SYNTAX" and SECTION 23.3.4, "MAINTENANCE OF PARTITIONS"
#
# REPAIR TABLE OPTIONS
#
# 		) NO_WRITE_TO_BINLOG or LOCAL
#
# 			By default, the server writes REPAIR_TABLE statements to the binary log so that they
# 			replicate to replication slaves.
#
# 			To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL
#
# 		) QUICK
#
# 			If you use the QUICK option, REPAIR_TABLE tries to repair only the index file, and not the
# 			data file.
#
# 			This type of repair is like that done by myisamchk --recover --quick
#
# 		) EXTENDED
#
# 			If you use the EXTENDED option, MySQL creates the index row instead of creating
# 			one index at a time with sorting.
#
# 			This type of repair is like that done by myisamchk --safe-recover
#
# 		) USE_FRM
#
# 			the USE_FRM option is available for use if the .MYI index file is missing or if its header
# 			is corrupted.
#
# 			This option tells MySQL not to trust the information in the .MYI file header
# 			and to re-create it using information from the data dictionary.
#
# 			This kind of repair cannot be done with myisamchk.
#
# 			CAUTION:
#
# 				Use the USE_FRM option only if you cannot use regular REPAIR modes.
#
# 				Telling the server to ignore the .MYI file makes important table metadata
# 				stored in the .MYI unavailable to the repair process, which can have deleterious
# 				consequences:
#
# 					) The current AUTO_INCREMENT value is lost
#
# 					) The link to deleted records in the table is lost, which means that free space
# 						for deleted records will remain unoccupied thereafter.
#
# 					) The .MYI header indicates whether the table is compressed. If the server
# 						ignores this information, it cannot tell that a table is compressed and
# 						repair can cause change or loss of table contents.
#
# 						This means that USE_FRM should not be used with compressed tables.
#
# 						That should not be necessary, anyway: Compressed tables are read only,
# 						so they should not become corrupt.
#
# 				If you use USE_FRM for a table that was created by a different version of the
# 				MySQL server than the one you are currently running, REPAIR_TABLE does not attempt
# 				to repair the table.
#
# 				In this case, the result set returned by REPAIR_TABLE contains a line with a 
# 				Msg_type value of error and a Msg_text value of Failed repairing incompatible .FRM file
#
# 				If USE_FRM is used, REPAIR_TABLE does not check the table to see whether an upgrade is required.
#
# REPAIR TABLE OUTPUT
#
# REPAIR_TABLE returns a result set with the columns shown in the following table.
#
# 		COLUMN 				VALUE
#
# 		Table 				The table name
#
# 		Op 					Always repair
#
# 		Msg_type 			status, error, info, note or warning
#
# 		Msg_text 			An informational message
#
# The REPAIR_TABLE statement might produce many rows of information for each repaired table.
#
# The last row has a Msg_type value of status and Msg_test normally should be OK.
#
# For a MyISAM table, if you do not get OK, you should try repairing it with myisamchk --safe-recover
#
# (REPAIR_TABLE does not implement all the options of myisamchk. With myisamchk --safe-recover, you can
# also use options that REPAIR_TABLE does not support, such as --max-record-length)
#
# REPAIR_TABLE table catches and throws any errors that occur while copying table statistics from the old
# corrupted file to the newly created file.
#
# For example, if the user ID of the owner of the .MYD or .MYI file is different from the user ID of the
# mysqld process, REPAIR_TABLE generates a "cannot change ownership of the file" error unless mysqld
# is started by the root user.
#
# TABLE REPAIR CONSIDERATIONS
#
# REPAIR_TABLE upgrades a table if it contains old temporal columns in pre-5.6.4 format
# (TIME, DATETIME, and TIMESTAMP columns without support for fractional seconds precision)
# and the avoid_temporal_upgrade system variable is disabled.
#
# If avoid_temporal_upgrade is enabled, REPAIR_TABLE ignores the old temporal columns present
# in the table and does not upgrade them.
#
# To upgrade tables that contain such temporal columns, disable avoid_temporal_upgrade before
# executing REPAIR_TABLE
#
# You may be able to increase REPAIR_TABLE performance by setting certain system variables,
# see SECTION 8.6.3, "OPTIMIZING REPAIR TABLE STATEMENTS"
#
# 13.7.4 COMPONENT, PLUGIN, AND USER-DEFINED FUNCTION STATEMENTS
#
# 	13.7.4.1 CREATE FUNCTION SYNTAX FOR USER-DEFINED FUNCTIONS
# 	13.7.4.2 DROP FUNCTION SYNTAX
#
# 	13.7.4.3 INSTALL COMPONENT SYNTAX
# 	13.7.4.4 INSTALL PLUGIN SYNTAX
#
# 	13.7.4.5 UNINSTALL COMPONENT SYNTAX
# 	13.7.4.6 UNINSTALL PLUGIN SYNTAX
#
# 13.7.4.1 CREATE FUNCTION SYNTAX FOR USER-DEFINED FUNCTIONS
#
# 		CREATE [AGGREGATE] FUNCTION function_name
# 			RETURNS {STRING|INTEGER|REAL|DECIMAL}
# 			SONAME shared_library_name
#
# A user-defined function (UDF) is a way to extend MySQL with a new function that
# works like a native (built-in) MySQL function such as ABS() or CONCAT()
#
# function_name is the name that should be used in SQL statements to invoke the function.
#
# The RETURNS clause indicates the type of the function's return value.
#
# DECIMAL is a legal value after RETURNS, but currently DECIMAL functions return string
# values and should be written like STRING functions.
#
# shared_library_name is the base name of the shared library file that contains the code that
# implements the function.
#
# The file must be located in the plugin directory. This directory is given by the value 
# of the plugin_dir system variable.
#
# For more information, see SECTION 5.7.1, "INSTALLING AND UNINSTALLING USER-DEFINED FUNCTIONS"
#
# To create a function, you must have the INSERT privilege for the mysql system database.
#
# This is necessary because CREATE_FUNCTION adds a row to the mysql.func system table that
# records the function's name, type, and shared library name.
#
# UDFs registered using CREATE_FUNCTION are listed in the Performance Schema user_defined_functions
# table; See SECTION 26.12.17.6, "THE USER_DEFINED_FUNCTIONS TABLE"
#
# An active function is one that has been loaded with CREATE_FUNCTION and not removed with DROP_FUNCTION.
#
# All active functions are reloaded each time the server starts, unless you start mysqld
# with the --skip-grant-tables option. In this case, UDF initialization is skipped and
# UDFs are unavailable.
#
# For instructions on writing user-defined functions, see SECTION 29.4.2, "ADDING A NEW USER-DEFINED FUNCTION"
#
# For the UDF mechanism to work, functions must be written in C or C++ (or another language that can use
# C calling conventions), your operating system must support dynamic loading and you must have
# compiled mysqld dynamically (not statically)
#
# An AGGREGATE function works exactly like a native MySQL aggregate (summary) function such as
# SUM or COUNT()
#
# NOTE:
#
# 		To upgrade the shared library associated with a UDF, issue a DROP_FUNCTION statement, upgrade
# 		the shared library, and then issue a CREATE_FUNCTION statement.
#
# 		If you upgrade the shared library first and then use DROP_FUNCTION, the server may crash.
#
# 13.7.4.2 DROP FUNCTION SYNTAX
#
# 		DROP FUNCTION function_name
#
# This statement drops the user-defined function (UDF) named function_name
#
# To drop a function, you must have the DELETE privilege for the mysql system database.
#
# This is because DROP_FUNCTION removes a row from the mysql.func system table that
# records the function's name, type and shared library name.
#
# NOTE:
#
# 		To upgrade the shared library associated with a UDF, issue a DROP_FUNCTION statement,
# 		upgrade the shared library, and then issue a CREATE_FUNCTION statement.
#
# 		If you upgrade the shared library first and then use DROP_FUNCTION, the server may crash.
#
# DROP_FUNCTION is also used to drop stored functions (see SECTION 13.1.29, "DROP PROCEDURE AND DROP FUNCTION SYNTAX")
#
# 13.7.4.3 INSTALL COMPONENT SYNTAX
#
# 		INSTALL COMPONENT component_name [, component_name ] ---
#
# This statement installs one or more server components, which become active immediately.
#
# A component provides services that are available to the server and other components;
# see SECTION 5.5, "MYSQL SERVER COMPONENTS"
#
# INSTALL_COMPONENT requires the INSERT privilege for the mysql.component system table.
#
# Example:
#
# 		INSTALL COMPONENT 'file://component1', 'file://component2';
#
# Component names are URNs that begin with file:// and indicate the base name of the file
# that implements the component, located in the directory named by the plugin_dir
# system variable.
#
# Component names do not include any platform-dependent file name suffix such as .so
# or .dll (These naming details are subject to change because component name interpretation
# is itself performed by a service and the component infrastructure makes it possible
# to replace the default service implementation with alternative implementations.)
#
# If any error occurs, the statement fails and has no effect.
#
# For example, this happens if a component name is errornous, a named component
# does not exist or is already installed, or component initialization fails.
#
# A loader service handles component loading, which includes adding installed components
# to the mysql.component system table that serves as a registry.
#
# For subsequent server restarts, any components listed in mysql.component are loaded
# by the loader service during the startup sequence.
#
# This occurs even if the server is started with the --skip-grant-tables option
#
# If a component depends on services not present in the registry and you attempt
# to install the component without also installing the component or components that
# provide the services on which it depends, an error occurs:
#
# 		ERROR 3527 (HY000): Cannot satisfy dependency for service 'component_a'
# 		required by component 'component_b'
#
# To avoid this problem, either install all components in the same statement, or install
# the dependent component after installing any components on which it depends.
#
# 13.7.4.4 INSTALL PLUGIN SYNTAX
#
# 		INSTALL PLUGIN plugin_name SONAME 'shared_library_name'
#
# This statement installs a server plugin. It requires the INSERT privilege for the
# mysql.plugin system table.
#
# plugin_name is the name of the plugin as defined in the plugin descriptor structure
# contained in the library file (see SECTION 29.2.4.2, "PLUGIN DATA STRUCTURES")
#
# Plugin names are not case-sensitive. For maximal compatibility, plugin names should
# be limited to ASCII letters, digits and underscore because they are used in C
# source files, shell command lines, M4 and Bourne shell scripts, and SQL environments.
#
# shared_library_name is the name of the shared library that contains the plugin code.
#
# The name includes the file name extension (for example, libmyplugin.so, libmyplugin.dll
# or libmyplugin.dylib)
#
# The shared library must be located in the plugin directory (the directory named by the
# plugin_dir system variable)
#
# The library must be in the plugin directory itself, not in a subdirectory.
#
# By default, plugin_dir is the plugin directory under the directory named by the
# pkglibdir configuration variable, but it can be changed by setting the value of
# plugin_dir at server startup.
#
# For example, set its value in a my.cnf file:
#
# 		[mysqld]
# 		plugin_dir=/path/to/plugin/directory
#
# If the value of plugin_dir is a relative path name, it is taken to be relative
# to the MySQL base directory (the value of the basedir system variable)
#
# INSTALL_PLUGIN loads and initializes the plugin code to make the plugin available
# for use.
#
# A plugin is initialized by executing its initialization function, which handles
# any setup that the plugin must perform before it can be used.
#
# When the server shuts down, it executes the deinitialization function for each
# plugin that is loaded so that the plugin has a chance to perform any final cleanup.
#
# INSTALL_PLUGIN also registers the plugin by adding a line that indicates the plugin
# name and library file name to the mysql.plugin system table.
#
# At server startup, the server loads and initializes any plugin that is listed in
# mysql.plugin
#
# This means that a plugin is installed with INSTALL_PLUGIN only once, not every
# time the server starts.
#
# Plugin loading at startup does not occur if the server is started with the --skip-grant-tables
# option.
#
# A plugin library can contain multiple plugins. For each of them to be installed, use a separate
# INSTALL_PLUGIN statement.
#
# Each statement names a different plugin, but all of them specify the same library name.
#
# INSTALL_PLUGIN causes the server to read option (my.cnf) files just as during server
# startup.
#
# This enables the plugin to pick up any relevant options from those files. It is
# possible to add plugin options to an option file even before loading a plugin
# (if the loose prefix is used)
#
# It is also possible to uninstall a plugin, edit my.cnf, and install the plugin again.
#
# Restarting the plugin this way enables it to the new option values without a server restart.
#
# For options that control individual plugin loading at server startup, see SECTION 5.6.1,
# "INSTALLING AND UNINSTALLING PLUGINS"
#
# If you need to load plugins for a single server startup when the --skip-grant-tables
# option is given (which tells the server not to read system tables), use the --plugin-load
# option.
#
# See SECTION 5.1.7, "SERVER COMMAND OPTIONS"
#
# To remove a plugin, use the UNINSTALL_PLUGIN statement
#
# For additional information about plugin loading, see SECTION 5.6.1, "INSTALLING AND UNINSTALLING PLUGINS"
#
# To see what plugins are installed, use the SHOW_PLUGINS statement or query the INFORMATION_SCHEMA
# the PLUGINS table.
#
# If you recompile a plugin library and need to reinstall it, you can use either of the following methods:
#
# 		) Use UNINSTALL_PLUGIN to uninstall all plugins in the library, install the new plugin library file
# 			in the plugin directory, and then use INSTALL_PLUGIN to install all plugins in the library.
#
# 			This procedure has the advantage that it can be used without stopping the server.
#
# 			However, if the plugin library contains many plugins, you must issue many INSTALL_PLUGIN
# 			and UNINSTALL_PLUGIN statements.
#
# 		) Stop the server, install the new plugin library file in the plugin directory, and restart the server.
#
# 13.7.4.5 UNINSTALL COMPONENT SYNTAX
#
# 		UNINSTALL COMPONENT component_name [, component_name ] ---
#
# This statement deactivates and uninstalls one or more server components.
#
# A component provides services that are available to the server and other components;
# see SECTION 5.5, "MYSQL SERVER COMPONENTS"
#
# UNINSTALL_COMPONENT is the complement of INSTALL_COMPONENT
#
# It requires the DELETE privilege for the mysql.component system table
#
# Example:
#
# 		UNINSTALL COMPONENT 'file://component1', 'file://component2';
#
# For information about component naming, see SECTION 13.7.4.3, "INSTALLING COMPONENT SYNTAX"
#
# If any error occurs, the statement fails and has no effect. For example, this happens if a 
# component name is errorneous, a named component is not installed, or cannot be uninstalled
# because other installed components depend on it.
#
# A loader service handles component unloading, which includes removing uninstalled
# components from the mysql.component system table that serves as a registry.
#
# As a result, unloaded components are not loaded during the startup sequence
# for subsequent server restarts.
#
# 13.7.4.6 UNINSTALL PLUGIN SYNTAX
#
# 		UNINSTALL PLUGIN plugin_name
#
# This statement removes an installed server plugin. It requires the DELETE privilege
# for the mysql.plugin system table.
#
# UNINSTALL_PLUGIN is the complement of INSTALL_PLUGIN
#
# plugin_name must be the name of some plugin that is listed in the mysql.plugin table.
#
# The server executes the plugin's deinitialization function and removes the row for
# the plugin from the mysql.plugin system table, so that subsequent server restarts will
# not load and initialize the plugin.
#
# UNINSTALL_PLUGIN does not remove the plugin's shared library file
#
# You cannot uninstall a plugin if any table that uses it is open
#
# Plugin removal has implications for the use of associated tables.
#
# For example, if a full-text parser plugin is associated with a FULLTEXT
# index on the table, uninstalling the plugin makes the table unusable.
#
# Any attempt to access the table results in an error.
#
# The table cannot even be opened, so you cannot drop an index for which
# the plugin is used.
#
# THis means that uninstalling a plugin is something to do with care unless
# you do not care about the table contents.
#
# If you are uninstalling a plugin with no intention of reinstalling it later
# and you care about the table contents, you should dump the table with mysqldump
# and remove the WITH PARSER clause from the dumped CREATE_TABLE statement
# so that you can reload the table later.
#
# If you do not care about the table, DROP_TABLE can be used even if any plugins
# associated with the table are missing.
#
# For additional information about plugin loading, see SECTION 5.6.1, "INSTALLING AND UNINSTALLING PLUGINS"
#
# 13.7.5 SET SYNTAX
#
# 13.7.5.1 SET SYNTAX FOR VARIABLE ASSIGNMENT
# 13.7.5.2 SET CHARACTER SET SYNTAX
# 13.7.5.3 SET NAMES SYNTAX
#
# The SET statement has several forms.
#
# Descriptions for those forms that are not associated with a specific server capability
# appear in subsections of this section:
#
# 		) SET_var_name = value enables you to assign values to variables that affect the
# 			operation of the server or clients.
#
# 			See SECTION 13.7.5.1, "SET SYNTAX FOR VARIABLE ASSIGNMENT"
#
# 		) SET_CHARACTER_SET and SET_NAMES assign values to character set and collation
# 			variables associated with the current connection to the server.
#
# 			See SECTION 13.7.5.2, "SET CHARACTER SET SYNTAX", and SECTION 13.7.5.3, "SET NAMES SYNTAX"
#
# Descriptions for the other forms appear elsewhere, grouped with other statements related
# to the capability they help implement:
#
# 		) SET_DEFAULT_ROLE and SET_ROLE set the default role and current role for user accounts.
#
# 			See SECTION 13.7.1.9, "SET DEFAULT ROLE SYNTAX" and SECTION 13.7.1.11, "SET ROLE SYNTAX"
#
# 		) SET_PASSWORD assigns account passwords. See SECTION 13.7.1.10, "SET PASSWORD SYNTAX"
#
# 		) SET RESOURCE GROUP assigns threads to a resource group. See SECTION 13.7.2.4, "SET RESOURCE GROUP SYNTAX"
#
# 		) SET_TRANSACTION_ISOLATION_LEVEL sets the isolation level for transaction processing.
#
# 			See SECTION 13.3.7, "SET TRANSACTION SYNTAX"
#
# 13.7.5.1 SET SYNTAX FOR VARIABLE ASSIGNMENT
#
# 		SET variable = expr [, variable = expr] ---
#
# 		variable: {
# 			user_var name
# 		 | param_name
# 		 | local_var_name
# 		 | {GLOBAL | @@GLOBAL.} system_var_name
# 		 | {PERSIST | @@PERSIST.} system_var_name
# 		 | {PERSIST_ONLY | @@PERSIST_ONLY.} system_var_name
# 		 | [SESSION | @@SESSION. | @@] system_var_name
# 		}
#
# SET syntax for variable assignment enables you to assign values to different types
# of variables that affect the operation of the server or clients:
#
# 		) User-defined variables. See SECTION 9.4, "USER-DEFINED VARIABLES"
#
# 		) Stored procedure and function parameters, and stored program local variables. See SECTION 13.6.4, "VARIABLES IN STORED PROGRAMS"
#
# 		) System variables. See SECTION 5.1.8, "SERVER SYSTEM VARIABLES". System variables also can be set at server startup, as described
# 			in SECTION 5.1.9, "USING SYSTEM VARIABLES"
#
# A SET statement that assigns variable values is not written to the binary log, so in replication
# scenarios it affects only the host on which you execute it.
#
# To affect all replication hosts, execute the statement on each host.
#
# The following sections describe SET syntax for setting variables.
#
# They use the = assignment operator, but the := assignment operator is
# also permitted for this purpose.
#
# 		) USER-DEFINED VARIABLE ASSIGNMENT
#
# 		) PARAMETER AND LOCAL VARIABLE ASSIGNMENT
#
# 		) SYSTEM VARIABLE ASSIGNMENT
#
# 		) SET ERROR HANDLING
#
# 		) MULTIPLE VARIABLE ASSIGNMENT
#
# 		) SYSTEM VARIABLE REFERENCES IN EXPRESSIONS
#
# USER-DEFINED VARIABLE ASSIGNMENT
#
# User-defined variables are created locally within a session and exist only
# within the context of that session; see SECTION 9.4, "USER-DEFINED VARIABLES"
#
# A user-defined variable is written as @var_name and is assigned an expression
# value as follows:
#
# 		SET @var_name = expr;
#
# Examples:
#
# 		SET @name = 43;
# 		SET @total_tax = (SELECT SUM(tax) FROM taxable_transactions);
#
# As demonstrated by those statements, expr can range from simple (a literal value) to more complex
# (the value returned by a scalar subquery)
#
# The Performance Schema user_variable_by_thread table contains information about user-defined
# variables.
#
# See SECTION 26.12.10, "PERFORMANCE SCHEMA USER-DEFINED VARIABLE TABLES"
#
# PARAMETER AND LOCAL VARIABLE ASSIGNMENT
#
# SET applies to parameters and local variables in the contexts of the stored object within
# which they are defined.
#
# The following procedure uses the increment procedure parameter and counter local variable:
#
# 		CREATE PROCEDURE p(increment INT)
# 		BEGIN
# 			DECLARE counter INT DEFAULT 0;
# 			WHILE counter < 10 DO
# 				--- do work ---
# 				SET counter = counter + increment;
# 			END WHILE;
# 		END;
#
# SYSTEM VARIABLE ASSIGNMENT
#
# The MySQL server maintains system variables that configure its operation.
#
# A system variable can have a global value that affects server operation
# as a whole, a session value that affects the current session, or both.
#
# Many system variables are dynamic and can be changed at runtime using the SET
# statement to affect operation of the current server instance.
#
# SET can also be used to persist certain system variables to the mysqld-auto.cnf
# file in the data directory, to affect server operation for subsequent
# startups.
#
# If you change a session system variable, the value remains in effect within
# your session until you change the variable to a different value or the 
# session ends.
#
# The change has no effect on other sessions.
#
# If you change a global system variable, the value is remembered and used to
# initialize the session value for new sessions until you change the variable
# to a different value or the server exits.
#
# The change is visible to any client that accesses the global value.
#
# However, the change affects the corresponding session value only for clients
# that connect after the change.
#
# The global variable change does not affect the session value for any current
# client sessions (not even the session within which the global value change occurs)
#
# To make a global system variable setting permanent so that it applies across
# server restarts, you can persist it to the mysqld-auto.cnf file in the data directory.
#
# It is also possible to make persistent configuration changes by manually modifying
# a my.cnf option file, but that is more cumbersome, and an error in a manually
# entered setting might not be discovered until much later.
#
# SET statements that persist system variables are more convenient and avoid the
# possibility of malformed settings because settings with syntax errors do not
# succeed and do not change server configuration.
#
# For more information about persisting system variables and the mysqld-auto.cnf
# file, see SECTION 5.1.9.3, "PERSISTED SYSTEM VARIABLES"
#
# NOTE:
#
# 		Setting or persisting a global system variable value always requires special
# 		privileges.
#
# 		Setting a session system variable value normally requires no special privileges
# 		and can be done by any user, although there are exceptions.
#
# 		For more information, see SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"
#
# The following discussion describes the syntax options for setting and persisting
# system variables:
#
# 		) To assign a value to a global system variable, precede the variable name by the
# 			GLOBAL keyword or the @@GLOBAL. qualifier:
#
# 			SET GLOBAL max_connections = 1000;
# 			SET @@GLOBAL.max_connections = 1000;
#
# 		) To assign a value to a session system variable, precede the variable name by the
# 			SESSION or LOCAL keyword, by the @@SESSION., @@LOCAL., or @@ qualifier, or by
# 			no keyword or no modifier at all:
#
# 				SET SESSION sql_mode = 'TRADITIONAL';
# 				SET LOCAL sql_mode = 'TRADITIONAL';
# 				SET @@SESSION.sql_mode = 'TRADITIONAL';
# 				SET @@LOCAL.sql_mode = 'TRADITIONAL';
# 				SET @@sql_mode = 'TRADITIONAL';
# 				SET sql_mode = 'TRADITIONAL';
#
# 			A client can change its own session variables, but not those of any other client.
#
# 		) To persist a global system variable to the mysqld-auto.cnf option file in the data
# 			directory, precede the variable name by the PERSIST keyword or the @@PERSIST.
# 			qualifier:
#
# 				SET PERSIST max_connections = 1000;
# 				SET @@PERSIST.max_connections = 1000;
#
# 			This SET syntax enables you to make configuration changes at runtime that also
# 			persist across server restarts.
#
# 			Like SET_GLOBAL, SET_PERSIST sets the global variable runtime value, but also
# 			writes the variable setting to the mysqld-auto.cnf file (replacing any existing
# 			variable setting if there is one)
#
# 		) To persist a global system variable to the mysqld-auto.cnf file without setting the
# 			global variable runtime value, precede the variable name by the PERSIST_ONLY
# 			keyword or the @@PERSIST_ONLY. qualifier:
#
# 				SET PERSIST_ONLY back_log = 100;
# 				SET @@PERSIST_ONLY.back_log = 100;
# 	
# 			Like PERSIST, PERSIST_ONLY writes the variable setting to mysqld-auto.cnf
#
# 			However, unlike PERSIST, PERSIST_ONLY does not modify the global variable
# 			runtime value.
#
# 			This makes PERSIST_ONLY suitable for configuring read-only system variables
# 			that can be set only at server startup.
#
# To set a global system variable value to the compiled-in MySQL default value or
# a session system variable to the current corresponding global value, set the
# variable to the value DEFAULT.
#
# For example, the following two statements are identical in setting the session
# value of max_join_size to the current global value:
#
# 		SET @@SESSION.max_join_size = DEFAULT;
# 		SET @@SESSION.max_join_size = @@GLOBAL.max_join_size;
#
# Using SET to persist a global system variable to a value of DEFAULT or to its
# literal default value assigns the variable its default value and adds a 
# setting for the variable to mysqld-auto.cnf 
#
# To remove the variable from the file, use RESET_PERSIST
#
# Some system variables cannot be persisted or are persist-restricted.
#
# See SECTION 5.1.9.4, "NONPERSISTIBLE AND PERSIST-RESTRICTED SYSTEM VARIABLES"
#
# A system variable implemented by a plugin can be persisted if the plugin is installed
# when the SET statement is executed.
#
# Assignment of the persisted plugin variable takes effect for subsequent server
# restarts if the plugin is still installed.
#
# If the plugin is no longer installed, the plugin variable will not exist
# when the server reads the mysqld-auto.cnf file
#
# In this case, the server writes a warning to the error log and continues:
#
# 		currently unknown variable 'var_name'
# 		was read from the persisted config file
#
# To display system variable names and values:
#
# 		) Use the SHOW_VARIABLES statement; see SECTION 13.7.6.39, "SHOW VARIABLES SYNTAX"
#
# 		) Several Performance Schema tables provide system variable information. See SECTION 26.12.13, "PERFORMANCE SCHEMA SYSTEM VARIABLE TABLES"
#
# 		) The Performance Schema variables_info table contains information showing when and by
# 			which user each system variable was most recently set.
#
# 			See SECTION 26.12.13.2, "PERFORMANCE SCHEMA VARIABLES_INFO TABLE"
#
# 		) The Performance Schema persisted_variables table provides an SQL interface to the
# 			mysqld-auto.cnf file, enabling its contents to be inspected at runtime using
# 			SELECT statements.
#
# 			See SECTION 26.12.13.1, "PERFORMANCE SCHEMA PERSISTED_VARIABLES TABLE"
#
# SET ERROR HANDLING
#
# If any variable assignment in a SET statement fails, the entire statement fails and no variables
# are changed, nor is the mysqld-auto.cnf file changed.
#
# SET produces an error under the circumstances described here.
#
# Most of the examples show SET statements that use keyword syntax 
# (for example, GLOBAL or SESSION), but the principles are also true
# for statements that use the corresponding modifiers (for example, @@GLOBAL. or @@SESSION.)
#
# 		) Use of SET (any variant) to set a read-only variable:
#
# 			SET GLOBAL version = 'abc';
# 			ERROR 1238 (HY000): Variable 'version' is a read only variable
#
# 		) Use of GLOBAL, PERSIST, or PERSIST_ONLY to set a variable that has only a session value:
#
# 			SET GLOBAL sql_log_bin = ON;
# 			ERROR 1228 (HY000): Variable 'sql_log_bin' is a SESSION
# 			variable and can't be used with SET GLOBAL
#
# 		) Use of SESSION to set a variable that has only a global value:
#
# 			SET SESSION max_connections = 1000;
# 			ERROR 1229 (HY000): Variable 'max_connections' is a 
# 			GLOBAL variable and should be set with SET GLOBAL
#
# 		) Omission of GLOBAL, PERSIST, or PERSIST_ONLY to set a variable that
# 			has only a global value:
#
# 			SET max_connections = 1000;
# 			ERROR 1229 (HY000): Variable 'max_connections' is a
# 			GLOBAL variable and should be set with SET GLOBAL
#
# 		) Use of PERSIST or PERSIST_ONLY to set a variable that cannot be persisted:
#
# 			SET PERSIST port = 3307;
# 			ERROR 1238 (HY000): Variable 'port' is a read only variable
# 			SET PERSIST_ONLY port = 3307;
# 			ERROR 1238 (HY000): Variable 'port' is a non-persistent read only variable
#
# 		) The @@GLOBAL., @@PERSIST., @@PERSIST_ONLY., @@SESSION., and @@ modifiers apply only
# 			to system variables.
#
# 			An error occurs for attempts to apply them to user-defined variables, stored procedure
# 			or function parameters, or stored program local variables.
#
# 		) Not all system variables can be set to DEFAULT. In such cases, assigning DEFAULT results in an error.
#
# 		) An error occurs for attempts to assign DEFAULT to user-defined variables, stored procedure
# 			or function parameters, or stored program local variables.
#
# MULTIPLE VARIABLE ASSIGNMENT
#
# A SET statement can contain multiple variable assignments, separated by commas.
#
# This statement assigns values to a user-defined variable and a system variable:
#
# 		SET @x = 1, SESSION sql_mode = '';
#
# If you set multiple system variables in a single statement, the most recent GLOBAL,
# PERSIST, PERSIST_ONLY or SESSION keyword in the statement is used for following
# assignments that have no keyword specified.
#
# Examples of multiple-variable assignment:
#
# 		SET GLOBAL sort_buffer_size = 1000000, SESSION sort_buffer_size = 1000000;
# 		SET @@GLOBAL.sort_buffer_size = 1000000, @@LOCAL.sort_buffer_size = 1000000;
# 		SET GLOBAL max_connections = 1000, sort_buffer_size = 1000000;
#
# The @@GLOBAL., @@PERSIST., @@PERSIST_ONLY., @@SESSION., and @@ modifiers apply only
# to the immediately following system variable, not any remaining system variables.
#
# This statement sets the sort_buffer_size global value to 50000 and the session
# value to 1000000:
#
# 		SET @@GLOBAL.sort_buffer_size = 50000, sort_buffer_size = 1000000;
#
# SYSTEM VARIABLE REFERENCES IN EXPRESSIONS
#
# To refer to the value of a system variable in expressions, use one of the
# @@-modifiers (except @@PERSIST. and @@PERSIST_ONLY., which are not permitted
# in expressions)
#
# For example, you can retrieve system variable values in a SELECT statement
# like this:
#
# 		SELECT @@GLOBAL.sql_mode, @@SESSION.sql_mode, @@sql_mode;
#
# NOTE:
#
# 		A reference to a system variable in an expression as @@var_name
# 		(with @@ rather than @@GLOBAL. or @@SESSION.) returns the session
# 		value if it exists and the global value otherwise.
#
# 		This differs from SET @@var_name = expr, which always refers to the session value.
#
# 13.7.5.2 SET CHARACTER SYNTAX
#
# 		SET {CHARACTER SET | CHARSET}
# 			 {'charset_name' | DEFAULT}
#
# This statement maps all strings sent between the server and the current client with the
# given mapping.
#
# SET CHARACTER SET sets three session system variables:
#
# 		character_set_client and character_set_results are set to the given character set
#
# 		and character_set_connection to the value of character_set_database
#
# See SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"
#
# charset_name may be quoted or unquoted.
#
# The default character set mapping can be restored by using the value DEFAULT.
#
# The default depends on the server configuration.
#
# Some character sets cannot be used as the client character set.
# Attempting to use them with SET_CHARACTER_SET produces an error.
#
# See IMPERMISSIBLE CLIENT CHARACTER SETS
#
# 13.7.5.3 SET NAMES SYNTAX
#
# 		SET NAMES {'charset_name'
# 			[COLLATE 'collation_name'] | DEFAULT}
#
# This statement sets the three session system variables character_set_client, character_set_connection,
# and character_set_results to the given character set.
#
# Setting character_set_connection to charset_name also sets collation_connection to the default collation
# for charset_name.
#
# See SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"
#
# The optional COLLATE clause may be used to specify a collation explicitly.
#
# If given, the collation must one of the permitted collations for charset_name.
#
# charset_name and collation_name may be quoted or unquoted.
#
# The default mapping can be restored by using a value of DEFAULT.
# The default depends on the server configuration.
#
# Some character sets cannot be used as the client character set. Attempting ot use
# them with SET_NAMES produces an error.
#
# See IMPERMISSIBLE CLIENT CHARACTER SETS
#
# 13.7.6 SHOW SYNTAX
#
# 		13.7.6.1 SHOW BINARY LOGS SYNTAX
# 		13.7.6.2 SHOW BINLOG EVENTS SYNTAX
#
# 		13.7.6.3 SHOW CHARACTER SET SYNTAX
# 		13.7.6.4 SHOW COLLATION SYNTAX
#
# 		13.7.6.5 SHOW COLUMNS SYNTAX
# 		13.7.6.6 SHOW CREATE DATABASE SYNTAX
#
# 		13.7.6.7 SHOW CREATE EVENT SYNTAX
# 		13.7.6.8 SHOW CREATE FUNCTION SYNTAX
#
# 		13.7.6.9 SHOW CREATE PROCEDURE SYNTAX
# 		13.7.6.10 SHOW CREATE TABLE SYNTAX
#
# 		13.7.6.11 SHOW CREATE TRIGGER SYNTAX
# 		13.7.6.12 SHOW CREATE USER SYNTAX
#
# 		13.7.6.13 SHOW CREATE VIEW SYNTAX
# 		13.7.6.14 SHOW DATABASES SYNTAX
#
# 		13.7.6.15 SHOW ENGINE SYNTAX
# 		13.7.6.16 SHOW ENGINES SYNTAX
#
# 		13.7.6.17 SHOW ERRORS SYNTAX
# 		13.7.6.18 SHOW EVENTS SYNTAX
#
# 		13.7.6.19 SHOW FUNCTION CODE SYNTAX
# 		13.7.6.20 SHOW FUNCTION STATUS SYNTAX
#
# 		13.7.6.21 SHOW GRANTS SYNTAX
# 		13.7.6.22 SHOW INDEX SYNTAX
#
# 		13.7.6.23 SHOW MASTER STATUS SYNTAX
# 		13.7.6.24 SHOW OPEN TABLES SYNTAX
#
# 		13.7.6.25 SHOW PLUGINS SYNTAX
# 		13.7.6.26 SHOW PRIVILEGES SYNTAX
#
# 		13.7.6.27 SHOW PROCEDURE CODE SYNTAX
# 		13.7.6.28 SHOW PROCEDURE STATUS SYNTAX
#
# 		13.7.6.29 SHOW PROCESSLIST SYNTAX
# 		13.7.6.30 SHOW PROFILE SYNTAX
#
# 		13.7.6.31 SHOW PROFILES SYNTAX
# 		13.7.6.32 SHOW RELAYLOG EVENTS SYNTAX
#
# 		13.7.6.33 SHOW SLAVE HOSTS SYNTAX
# 		13.7.6.34 SHOW SLAVE STATUS SYNTAX
#
# 		13.7.6.35 SHOW STATUS SYNTAX
# 		13.7.6.36 SHOW TABLE STATUS SYNTAX
#
# 		13.7.6.37 SHOW TABLES SYNTAX
# 		13.7.6.38 SHOW TRIGGERS SYNTAX
#
# 		13.7.6.39 SHOW VARIABLES SYNTAX
# 		13.7.6.40 SHOW WARNINGS SYNTAX
#
# SHOW has many forms that provide information about databases, tables, columns, or status information
# about the server.
#
# This section describes those following:
#
# 		SHOW {BINARY | MASTER} LOGS
# 		SHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]
#
# 		SHOW CHARACTER SET [like_or_where]
# 		SHOW COLLATION [like_or_where]
#
# 		SHOW [FULL] COLUMNS FROM tbl_name [FROM db_name] [like_or_where]
# 		SHOW CREATE DATABASE db_name
#
# 		SHOW CREATE EVENT event_name
# 		SHOW CREATE FUNCTION func_name
#
# 		SHOW CREATE PROCEDURE proc_name
# 		SHOW CREATE TABLE tbl_name
#
# 		SHOW CREATE TRIGGER trigger_name
# 		SHOW CREATE VIEW view_name
#
# 		SHOW DATABASES [like_or_where]
# 		SHOW ENGINE engine_name {STATUS | MUTEX}
#
# 		SHOW [STORAGE] ENGINES
# 		SHOW ERRORS [LIMIT [offset,] row_count]
#
# 		SHOW EVENTS
# 		SHOW FUNCTION CODE func_name
#
# 		SHOW FUNCTION STATUS [like_or_where]
# 		SHOW GRANTS FOR user
#
# 		SHOW INDEX FROM tbl_name [FROM db_name]
# 		SHOW MASTER STATUS
#
# 		SHOW OPEN TABLES [FROM db_name] [like_or_where]
# 		SHOW PLUGINS
#
# 		SHOW PROCEDURE CODE proc_name
# 		SHOW PROCEDURE STATUS [like_or_where]
#
# 		SHOW PRIVILEGES
# 		SHOW [FULL] PROCESSLIST
#
# 		SHOW PROFILE [types] [FOR QUERY n] [OFFSET n] [LIMIT n]
# 		SHOW PROFILES
#
# 		SHOW RELAYLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]
# 		SHOW SLAVE HOSTS
#
# 		SHOW SLAVE STATUS [FOR CHANNEL channel]
# 		SHOW [GLOBAL | SESSION] STATUS [like_or_where]
#
# 		SHOW TABLE STATUS [FROM db_name] [like_or_where]
# 		SHOW [FULL] TABLES [FROM db_name] [like_or_where]
#
# 		SHOW TRIGGERS [FROM db_name] [like_or_where]
# 		SHOW [GLOBAL | SESSION] VARIABLES [like_or_where]
#
# 		SHOW WARNINGS [LIMIT [offset,] row_count]
#
# 		like_or_where:
# 			LIKE 'pattern'
# 		 | WHERE expr
#
# If the syntax for a given SHOW statement includes a LIKE_'pattern' part,
# 'pattern' is a string that can contain the SQL % and _ wildcard characters.
#
# The pattern is useful for restricting statement output to matching values.
#
# Several SHOW statements also accept a WHERE clause that provides more flexibility
# in specifying which rows to display.
#
# See SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# Many MySQL APIs (such as PHP) enable you to treat the result returned from a SHOW
# statement as you would a result set from a SELECT, see CHAPTER 28, CONNECTORS AND APIs,
# or your API documentation for more information.
#
# In addition, you can work in SQL with results from queries on tables in the INFORMATION_SCHEMA
# database, which you cannot easily do with results from SHOW statements.
#
# See CHAPTER 25, INFORMATION_SCHEMA TABLES
#
# 13.7.6.1 SHOW BINARY LOGS SYNTAX
#
# 		SHOW BINARY LOGS
# 		SHOW MASTER LOGS
#
# Lists the binary log files on the server.
#
# This statement is used as part of the procedure described in SECTION 13.4.1.1,
# "PURGE BINARY LOGS SYNTAX", that shows how to determine which logs can be purged.
#
# Encrypted binary log files have a 512-byte file header that stores information
# required for encryption and decryption of the file.
#
# This is included in the file size displayed by SHOW_BINARY_LOGS
#
# The Encrypted column shows whether or not the binary log file is encrypted.
#
# Binary log encryption is active if binlog_encryption=ON is set for the 
# server.
#
# Existing binary log files are not encrypted or decrypted if binary log encryption
# is activated or deactivated while the server is running.
#
# 		SHOW BINARY LOGS;
# 		+-----------------------+-----------------+---------------------+
# 		| Log_name 					| File_size 		| Encrypted 			 |
# 		+-----------------------+-----------------+---------------------+
# 		| binlog.000015 			| 724935 			| Yes 					 |
# 		| binlog.000016 			| 733481 			| Yes 					 |
# 		+-----------------------+-----------------+---------------------+
#
# SHOW_MASTER_LOG is equivalent to SHOW_BINARY_LOGS
#
# A user with the SUPER or REPLICATION_CLIENT privilege may execute this statement.
#
# 13.7.6.2 SHOW BINLOG EVENTS SYNTAX
#
# 		SHOW BINLOG EVENTS
# 			[IN 'log_name']
# 			[FROM pos]
# 			[LIMIT [offset,] row_count]
#
# Shows the events in the binary log. If you do not specify 'log_name', the first binary log is displayed.
#
# The LIMIT clause has the same syntax as for the SELECT statement.
#
# See SECTION 13.2.10, "SELECT SYNTAX"
#
# NOTE:
#
# 		Issuing a SHOW_BINLOG_EVENTS with no LIMIT clause could start a very time- and resource-consuming
# 		process because the server returns to the client the complete contents of the binary log
# 		(which includes all statements executed by the server that modify data)
#
# 		As an alternative to SHOW_BINLOG_EVENTS, use the mysqlbinlog utility to save the binary
# 		log to a text file for later examination and analysis.
#
# 		See SECTION 4.6.8, "mysqlbinlog -- Utility for processing binary log files"
#
# SHOW_BINLOG_EVENTS displays the following fields for each event in the binary log:
#
# 		) Log_name
#
# 			THe name of the file that is being listed.
#
# 		) Pos
#
# 			THe position at which the event occurs.
#
# 		) Event_type
#
# 			An identifier that describes the event type
#
# 		) Server_id
#
# 			The server ID of the server on which the event originated
#
# 		) End_log_pos
#
# 			The position at which the next event begins, which is equal to Pos plus the size of the event
#
# 		) Info
#
# 			More detailed information about the event type.
#
# 			The format of this information depends on the event type.
#
# NOTE:
#
# 		Some events relating to the setting of user and system variables are not included
# 		in the output from SHOW_BINLOG_EVENTS
#
# 		To get complete coverage of events within a binary log, use mysqlbinlog
#
# NOTE:
#
# 		SHOW_BINLOG_EVENTS does not work with relay log files.
#
# 		You can use SHOW_RELAYLOG_EVENTS for this purpose.
#
# 13.7.6.3 SHOW CHARACTER SET SYNTAX
#
# 		SHOW CHARACTER SET
# 			[LIKE 'pattern' | WHERE expr]
#
# The SHOW_CHARACTER_SET statement shows all available character sets.
#
# The LIKE clause, if present, indicates which character set names to match.
#
# The WHERE clause can be given to select rows using more general conditions
# , as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS".
#
# For example:
#
# 		SHOW CHARACTER SET LIKE 'latin%';
# 		+----------+----------------------------+---------------------+-------------------+
# 		| Charset  | Description 					 | Default collation   | Maxlen 				 |
# 		+----------+----------------------------+---------------------+-------------------+
# 		| latin1   | cp1252 West European 		 | latin1_swedish_ci   | 1 					 |
# 		| latin2   | ISO 8859-2 Central European| latin2_general_ci   | 1 					 |
# 		| latin5   | ISO 8859-9 Turkish 		    | latin5_turkish_ci   | 1 					 |
# 		| latin7   | ISO 8859-13 Baltic 			 | latin7_general_ci   | 1 					 |
# 		+----------+----------------------------+---------------------+-------------------+
#
# SHOW_CHARACTER_SET output has these columns:
#
# 		) Charset
#
# 			The character set name
#
# 		) Description
#
# 			A description of the character set
#
# 		) Default collation
#
# 			THe default collation for the character set
#
# 		) Maxlen
#
# 			The maximum number of bytes required to store one character
#
# The filename character set is for internal use only; consequently, SHOW_CHARACTER_SET does not display it.
#
# Character set information is also available from the INFORMATION_SCHEMA CHARACTER_SETS table.
#
# See SECTION 25.2, "THE INFORMATION_SCHEMA CHARACTER_SETS TABLE"
#
# 13.7.6.4 SHOW COLLATION SYNTAX
#
# 		SHOW COLLATION
# 			[LIKE 'pattern' | WHERE expr]
#
# This statement lists collations supported by the server.
#
# By default, the output from SHOW_COLLATION includes all available collations.
#
# The LIKE clause, if present, indicates which collation names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS".
#
# For example:
#
# 		SHOW COLLATION WHERE Charset = 'latin1';
# 		+--------------------+-----------+------+--------------+--------------+------------------+
# 		| Collation 			| Charset 	| Id   | Default 		 | Compiled 	 | Sortlen 			  |
# 		+--------------------+-----------+------+--------------+--------------+------------------+
# 		| latin1_german1_ci  | latin1 	| 5 	 | 				 | Yes 			 | 	1 				  |
# 		| latin1_swedish_ci  | latin1 	| 8 	 | Yes 			 | Yes 			 | 	1 				  |
# 		| latin1_danish_ci   | latin1 	| 15 	 | 				 | Yes 			 | 	1 				  |
# 		| etc.
#
# SHOW_COLLATION output has these columns:
#
# 		) Collation
#
# 			The collation name
#
# 		) Charset
#
# 			The name of the character set with which the collation is associated
#
# 		) Id
#
# 			The collation ID
#
# 		) Default
#
# 			Whether the collation is the default for its character set
#
# 		) Compiled
#
# 			Whether hte character set is compiled into the server
#
# 		) Sortlen
#
# 			This is related to the amount of memory required to sort strings expressed in the char set
#
# To see the default collation for each character set, use the following statement.
#
# Default is a reserved word, so to use it as an identifier, it must be quoted as such:
#
# 		SHOW COLLATION WHERE `Default` = 'Yes';
# 		+--------------------------+----------+-----------+------------+------------------+-------------+
# 		| Collation 				   | Charset  | Id 		  | Default    | Compiled 			 | Sortlen 		|
# 		+--------------------------+----------+-----------+------------+------------------+-------------+
# 		| big5_chinese_ci 			| big5 	  | 1 		  | Yes 	      | Yes 				 | 1 				|
# 		etc.
#
# Collation information is also available from the INFORMATION_SCHEMA COLLATIONS table.
#
# See SECTION 25.3, "THE INFORMATION_SCHEMA COLLATIONS TABLE"
#
# 13.7.6.5 SHOW COLUMNS SYNTAX
#
# 		SHOW [EXTENDED] [FULL] {COLUMNS | FIELDS}
# 			{FROM | IN} tbl_name
# 			[{FROM | IN} db_name]
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_COLUMNS displays information about the columns in a given table.
#
# It also works for views. SHOW_COLUMNS displays information only for those
# columns for which you have some privilege.
#
# 		SHOW COLUMNS FROM City;
# 		+-----------+------------+---------+---------+--------------+-----------------+
# 		| Field 		| Type 		 | Null 	  | Key 		| Default 		| Extra 				|
# 		+-----------+------------+---------+---------+--------------+-----------------+
# 		| ID 			| int(11) 	 | NO 	  | PRI 		| NULL 			| auto_increment 	|
# 		| Name 		| char(35) 	 | NO 	  | 			| 					| 						|
# 		| etc.
#
# An alternative to tbl_name FROM db_name syntax is db_name.tbl_name
#
# These two statements are equivalent:
#
# 		SHOW COLUMNS FROM mytable FROM mydb;
# 		SHOW COLUMNS FROM mydb.mytable;
#
# The optional EXTENDED keyword causes the output to include information
# about hidden columns that MySQL uses internally and are not accessible by users.
#
# The optional FULL keyword causes the output to include the column collation
# and comments, as well as the privileges you have for each column.
#
# The LIKE clause, if present, indicates which column names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# THe data types may differ from what you expect them to be based on a CREATE_TABLE
# statement because MySQL sometimes changes data types when you create or alter a
# table.
#
# The conditions under which this occurs are described in SECTION 13.1.20.7,
# "SILENT COLUMN SPECIFICATION CHANGES"
#
# SHOW_COLUMNS displays the following values for each table column:
#
# 		) Field
#
# 			THe name of the column
#
# 		) Type
#
# 			THe column data type
#
# 		) Collation
#
# 			THe collation for nonbinary string columns, or NULL for other columns.
#
# 			This value is displayed only if you use the FULL keyword
#
# 		) Null
#
# 			The column nullability. The value is YES if NULL values can be stored
# 			in the column, NO if not.
#
# 		) Key
#
# 			Whether the column is indexed:
#
# 				) If Key is empty, the column either is not indexed or is indexed only as a secondary
# 					column in a multiple-column, nonunique index.
#
# 				) If Key is PRI, the column is a PRIMARY KEY or is one of the columns in a multiple-column PRIMARY KEY
#
# 				) If Key is UNI, the column is the first column of a UNIQUE index. (A UNIQUE index permits multiple NULL values,
# 					but you can tell whether the column permits NULL by checking the Null field)
#
# 				) If Key is MUL, the column is the first column of a nonunique index in which multiple occurences
# 					of a given value are permitted within the column.
#
# If more than one of the Key values applies to a given column of a table, Key displays the one with the
# highest priority, in the order PRI, UNI, MUL.
#
# A UNIQUE index may be displayed as PRI if it cannot contain NULL values and there is no PRIMARY KEY
# in the table.
#
# A UNIQUE index may display as MUL if several columns form a composite UNIQUE index; although
# the combination of the columns is unique, each column can still hold multiple occurrences
# of a given value.
#
# 		) Default
#
# 			The default value for the column. This is NULL if the column has an explicit default of NULL,
# 			or if the column definition includes no DEFAULT clause.
#
# 		) Extra
#
# 			Any additional information that is available about a given column.
#
# 			The value is nonempty in these cases:
#
# 				) auto_increment for columns that have the AUTO_INCREMENT attribute
#
# 				) on update CURRENT_TIMESTAMP for TIMESTAMP or DATETIME columns that have the ON UPDATE CURRENT_TIMESTAMP attribute
#
# 				) VIRTUAL GENERATED or VIRTUAL STORED for generated columns
#
# 				) DEFAULT_GENERATED for columns that have an expression default value
#
# 		) Privileges
#
# 			THe privileges you have for the column.
#
# 			THis value is displayed only if you use the FULL keyword
#
# 		) Comment
#
# 			ANy comment included in the column definition. 
#
# 			This value is displayed only if you use the FULL keyword
#
# Table column information is also available from the INFORMATION_SCHEMA COLUMNS table.
#
# See SECTION 25.5, "THE INFORMATION_SCHEMA COLUMNS TABLE"
#
# The extended information about hidden columns is available only using
# SHOW EXTENDED COLUMNS; it cannot be obtained from the COLUMNS table.
#
# You can list a table's columns with the mysqlshow db_name tbl_name command
#
# The DESCRIBE statement provides information similar to SHOW_COLUMNS.
# See SECTION 13.8.1, "DESCRIBE SYNTAX"
#
# The SHOW_CREATE_TABLE, SHOW_TABLE_STATUS and SHOW_INDEX statements also
# provide information about tables.
#
# See SECTION 13.7.6, "SHOW SYNTAX"
#
# 13.7.6.6 SHOW CREATE DATABASE SYNTAX
#
# 		SHOW CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name
#
# Shows the CREATE_DATABASE statement that creates the named database.
#
# If the SHOW statement includes an IF NOT EXISTS clause, the output too includes
# such a clause.
#
# SHOW_CREATE_SCHEMA is a synonym for SHOW_CREATE_DATABASE
#
# 		SHOW CREATE DATABASE test\G
# 		************************* 1. row *******************************
# 				Database: test
# 		Create Database: CREATE DATABASE `test`
# 								/*!40100 DEFAULT CHARACTER SET utf8mb4 */
#
# 		SHOW CREATE SCHEMA test\G
# 		************************* 1. row *******************************
# 				Database: test
# 		Create Database: CREATE DATABASE `test`
# 								/*!40100 DEFAULT CHARACTER SET utf8mb4 */
#
# SHOW_CREATE_DATABASE quotes table and column names according to the value of the sql_quote_show_create option.
#
# See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 13.7.6.7 SHOW CREATE EVENT SYNTAX
#
# 		SHOW CREATE EVENT event_name
#
# THis statement displays the CREATE_EVENT statement needed to re-create a given event.
#
# it requires the EVENT privilege for the database from which the event is to be 
# shown.
#
# For example (using the same event e_daily defined and then altered in SECTION 13.7.6.18, "SHOW EVENTS SYNTAX")
#
# 		SHOW CREATE EVENT myschema..e_daily\G
# 		*********************** 1. row ***************************
# 						Event: e_daily
# 					sql_mode: ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES,
# 								 NO_ZERO_IN_DATE, NO_ZERO_DATE,
# 								 ERROR_FOR_DIVISION_BY_ZERO,
# 								 NO_ENGINE_SUBSTITUTION
# 					time_zone: SYSTEM
#				Create event: CREATE DEFINER=`jon`@`ghidora` EVENT `e_daily`
# 									ON SCHEDULE EVERY 1 DAY
# 									STARTS CURRENT_TIMESTAMP + INTERVAL 6 HOUR
# 									ON COMPLETION NOT PRESERVE
# 									ENABLE
# 									COMMENT 'Saves total number of sessions then 
# 												clears the table each day'
# 									DO BEGIN
# 										INSERT INTO site_activity.totals (time, total)
# 											SELECT CURRENT_TIMESTAMP, COUNT(*)
# 												FROM site_activity.sessions;
# 										DELETE FROM site_activity.sessions;
# 									END
# 		character_set_client: utf8mb4
# 		collation_connection: utf8mb4_0900_ai_ci
# 			Database Collation: utf8mb4_0900_ai_ci
#
# character_set_client is the session value of the character_set_client system variable
# when the event was created.
#
# collation_connection is the session value of the collation_connection system variable
# when the event was created.
#
# Database Collation is the collation of the database with which the event is associated.
#
# The output reflects the current status of the event (ENABLE) rather than the status with which
# it was created.
#
# 13.7.6.8 SHOW CREATE FUNCTION SYNTAX
#
# 		SHOW CREATE FUNCTION func_name
#
# This statement is similar to SHOW_CREATE_PROCEDURE but for stored functions.
#
# See SECTION 13.7.6.9, "SHOW CREATE PROCEDURE SYNTAX"
#
# 13.7.6.9 SHOW CREATE PROCEDURE SYNTAX
#
# 		SHOW CREATE PROCEDURE proc_name
#
# This statement is a MySQL extension.
#
# It returns the exact string that can be used to re-create the named stored procedure.
#
# A similar statement, SHOW_CREATE_FUNCTION, displays information about stored functions
# (see SECTION 13.7.6.8, "SHOW CREATE FUNCTION SYNTAX")
#
# To use either statement, you must have the global SELECT privilege.
#
# 		SHOW CREATE PROCEDURE test.simpleproc\G
# 		********************* 1. row ***************************
# 						Procedure: simpleproc
# 						sql_mode : ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES,
# 									  NO_ZERO_IN_DATE, NO_ZERO_DATE,
# 									  ERROR_FOR_DIVISION_BY_ZERO,
# 									  NO_ENGINE_SUBSTITUTION
# 			  Create Procedure: CREATE PROCEDURE `simpleproc` (OUT param1 INT)
# 									  BEGIN
# 									  SELECT COUNT(*) INTO param1 FROM t;
# 									  END
# 		 character_set_client: utf8mb4
# 		collation_connection : utf8mb4_0900_ai_ci
# 			Database Collation: utf8mb4_0900_ai_ci
#
# 		SHOW CREATE FUNCTION test.hello\G
# 		********************* 1. row ****************************
# 						Function: hello
# 						sql_mode: ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES,
# 									 NO_ZERO_IN_DATE, NO_ZERO_DATE,
# 									 ERROR_FOR_DIVISION_BY_ZERO,
# 									 NO_ENGINE_SUBSTITUTION
# 			  Create function: CREATE FUNCTION `hello`(s CHAR(20))
# 									 RETURNS char(50) CHARSET utf8mb4
# 									 RETURN CONCAT('Hello, ',s,'!')
# 		character_set_client: utf8mb4
# 		collation_connection: utf8mb4_0900_ai_ci
# 		  Database Collation: utf8mb4_0900_ai_ci
#
# character_set_client is the session value of the character_set_client system variable
# when the routine was created.
#
# collation_connection is the session value of the collation_connection system variable
# when the routine was created.
#
# Database Collation is the collation of the database with which the routine is associated.
#
# 13.7.6.10 SHOW CREATE TABLE SYNTAX
#
# 		SHOW CREATE TABLE tbl_name
#
# Shows the CREATE_TABLE statement that creates the named table.
#
# To use this statement, you must have some privilege for the table.
# This statement also works with views.
#
# 		SHOW CREATE TABLE t\G
# 		********************** 1. row **********************
# 			 	 Table: t
# 		Create Table: CREATE TABLE `t` (
# 			`id` int(11) NOT NULL AUTO_INCREMENT,
# 			`s` char(60) DEFAULT NULL,
# 			PRIMARY KEY (`id`)
# 		) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
#
# SHOW_CREATE_TABLE quotes table and column names according to the value of the sql_quote_show_create
# option.
#
# See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# For information about how CREATE_TABLE statements are stored by MySQL,
# see SECTION 13.1.20.1, "CREATE TABLE STATEMENT RETENTION"
#
# 13.7.6.11 SHOW CREATE TRIGGER SYNTAX
#
# 		SHOW CREATE TRIGGER trigger_name
#
# This statement shows the CREATE_TRIGGER statement that creates the named trigger.
#
# This statement requires the TRIGGER privilege for the table associated with the trigger.
#
# 		SHOW CREATE TRIGGER ins_sum\G
# 		*************************** 1. row ******************************
# 							Trigger: ins_sum
# 						  sql_mode: ONLY_FULL_GROUP_BY,STRICT_TRANS_TABLES,
# 										NO_ZERO_IN_DATE,NO_ZERO_DATE,
# 										ERROR_FOR_DIVISION_BY_ZERO,
# 										NO_ENGINE_SUBSTITUTION
# 		SQL Original Statement: CREATE DEFINER=`me`@`localhost` TRIGGER `ins_sum`
# 										BEFORE INSERT ON `account`
# 										FOR EACH ROW SET @sum = @sum + NEW.amount
# 		 character_set_client : utf8mb4
# 		  collation_connection: utf8mb4_0900_ai_ci
# 		   Database Collation : utf8mb4_0900_ai_ci
# 							Created: 2018-08-08 10:10:12.61
#
# SHOW_CREATE_TRIGGER output has these columns:
#
# 		) Trigger: The trigger name
#
# 		) sql_mode: The SQL mode in effect when the trigger executes
#
# 		) SQL Original Statement: The CREATE_TRIGGER statement that defines the trigger
#
# 		) character_set_client: The session value of the character_set_client system variable when the trigger was created
#
# 		) collation_connection: The session value of the collation_connection system variable when the trigger was created
#
# 		) Database Collation: The collation of the database with which the trigger is associated
#
# 		) Created: The date and time when the trigger was created. This is a TIMESTAMP(2) value (with a fractional part in hundredths of seconds) for triggers.
#
# Trigger information is also available from the INFORMATION_SCHEMA TRIGGERS table.
#
# See SECTION 25.33, "THE INFORMATION_SCHEMA TRIGGERS TABLE"
#
# 13.7.6.12 SHOW CREATE USER SYNTAX
#
# 		SHOW CREATE USER user
#
# This statement shows the CREATE_USER statement that creates the named user.
#
# An error occurs if the user does not exist. The statement requires the SELECT privilege
# for the mysql system database, except to see information for the current user.
#
# For the current user, the SELECT privilege for the mysql.user system table is required
# for display of the password hash in the IDENTIFIED AS clause; otherwise, the hash displays
# as <secret>
#
# To name the account, use the format described in SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES"
#
# The host name part of the account name, if omitted, defaults to '%'.
#
# It is also possible to specify CURRENT_USER or CURRENT_USER() to refer to the account
# associated with the current session.
#
# 		SHOW CREATE USER 'root'@'localhost'\G
# 		********************* 1.  row **************************
# 		CREATE USER for root@localhost: CREATE USER 'root'@'localhost'
# 		IDENTIFIED WITH 'mysql_native_password'
# 		AS '*<serial>'
# 		REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK
#
# TO display the privileges granted to an account, use the SHOW_GRANTS statement.
#
# See SECTION 13.7.6.21, "SHOW GRANTS SYNTAX"
#
# 13.7.6.13 SHOW CREATE VIEW SYNTAX
#
# 		SHOW CREATE VIEW view_name
#
# This statement shows the CREATE_VIEW statement that creates the named view.
#
# 		SHOW CREATE VIEW v\G
# 		************************* 1. row **************************
# 								View: v
# 					Create View  : CREATE ALGORITHM=UNDEFINED
# 										DEFINER=`bob`@`localhost`
# 										SQL SECURITY DEFINER VIEW
# 										`v` AS select 1 AS `a`,2 AS `b`
# 		  character_set_client: utf8mb4
# 		  collation_connection: utf8mb4_0900_ai_ci
#
# character_set_client is the session value of the character_set_client system variable
# when the view was created.
#
# collation_connection is the session value of the collation_connection system variable
# when the view was created.
#
# Use of SHOW_CREATE_VIEW requires the SHOW_VIEW privilege, and the SELECT privilege
# for the view in question.
#
# View information is also available from the INFORMATION_SCHEMA VIEWS table. See SECTION 25.35, "THE INFORMATION_SCHEMA VIEWS TABLE"
#
# MySQL lets you use different sql_mode settings to tell the server the type of SQL syntax to support.
# For example, you might use the ANSI SQL mode to ensure MySQL correctly interprets the standard
# SQL concatenation operator, the double bar (||), in your queries.
#
# If you then create a view that concatenates items, you might worry that changing the sql_mode
# setting to a value different from ANSI could cause the view to become invalid.
#
# But this is not the case. No matter how you write out a view definition, MySQL always
# stores in the same way, in a canonical form.
#
# Here is an example that shows how the server changes a double bar concatenation operator
# to a CONCAT() function:
#
# 		SET sql_mode = 'ANSI';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CREATE VIEW test.v AS SELECT 'a' || 'b' as col1;
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		SHOW CREATE VIEW test.v\G
# 		************************** 1. row **************************************
# 								View: v
# 					  Create View: CREATE VIEW "v" AS select concat('a', 'b') AS "col1"
# 		---
# 		1 row in set (0.00 sec)
#
# The advantage of storing a view definition in canonical form is that changes made
# later to the value of sql_mode will not affect the results from the view.
#
# However an additional consequence is that comments prior to SELECT are stripped
# from the definition by the server.
#
# 13.7.6.14 SHOW DATABASES SYNTAX
#
# 		SHOW {DATABASES | SCHEMAS}
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_DATABASES lists the databases on the MySQL server host.
#
# SHOW_SCHEMAS is a synonym for SHOW_DATABASES.. The LIKE clause, if present,
# indicates which database names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# You see only those databases for which you have some kind of privilege, unless
# you have the global SHOW_DATABASES privilege.
#
# You can also get this list using the mysqlshow command.
#
# If the server was started with the --skip-show-database option, you cannot use
# this statement at all unless you have the SHOW_DATABASES privilege.
#
# MySQL implements databases as directories in the data directory, so this statement
# simply lists directories in that location.
#
# However, the output may include names of directories that do not correspond to actual
# databases.
#
# Database information is also available from the INFORMATION_SCHEMA SCHEMATA table.
#
# See SECTION 25.23, "THE INFORMATION_SCHEMA SCHEMATA TABLE"
#
# 13.7.6.15 SHOW ENGINE SYNTAX
#
# 		SHOW ENGINE engine_name {STATUS | MUTEX}
#
# SHOW_ENGINE displays operational information about a storage engine.
# It requires the PROCESS privilege.
#
# The statement has three variants:
#
# 		SHOW ENGINE INNODB STATUS
# 		SHOW ENGINE INNODB MUTEX
# 		SHOW ENGINE PERFORMANCE_SCHEMA STATUS
#
# SHOW_ENGINE_INNODB_STATUS displays extensive information from the standard
# InnoDB Monitor about the state of the InnoDB storage engine.
#
# For information about the standard monitor and other InnoDB monitors
# that provide information about InnoDB processing, see SECTION 15.16,
# "InnoDB Monitors"
#
# SHOW_ENGINE_INNODB_MUTEX displays InnoDB mutex and rw-lock statistics.
#
# NOTE:
#
# 		InnoDB mutexes and rwlocks can also be monitored using PERFORMANCE SCHEMA tables.
#
# 		See SECTION 15.15.2, "MONITORING INNODB MUTEX WAITS USING PERFORMANCE SCHEMA"
#
# Mutex statistics collection is configured dynamically using the following options:
#
# 		) To enable the collection of mutex statisitcs, run:
#
# 			SET GLOBAL innodb_monitor_enable='latch';
#
# 		) To reset mutex statistics, run:
#
# 			SET GLOBAL innodb_monitor_reset='latch';
#
# 		) To disable the collection of mutex statistics, run:
#
# 			SET GLOBAL innodb_monitor_disable='latch';
#
# Collection of mutex statistics for SHOW_ENGINE_INNODB_MUTEX can also be enabled
# by setting innodb_monitor_enable='all', or disable by setting innodb_monitor_disable='all'
#
# SHOW_ENGINE_INNODB_MUTEX output has these columns:
#
# 		) Type
# 			
# 			Always InnoDB
#
# 		) Name
#
# 			For mutexes, the Name field reports only the mutex name.
#
# 			For rwlocks, the Name field reports the source file where the rwlock
# 			is implemented, and the line number in the file where the rwlock is created.
#
# 			The line number is specific to your version of MySQL.
#
# 		) Status
#
# 			The mutex status.
#
# 			The field reports the number of spins, waits and calls. Statistics for low-level
# 			operating system mutexes, which are implemented outside of InnoDB, are not reported.
#
# 				) spins indicates the number of spins
#
# 				) waits indicates the number of mutex waits
#
# 				) calls indicates how many times the mutex was requested
#
# 			SHOW ENGINE INNODB MUTEX skips the mutexes and rw-locks of buffer pool blocks,
# 			as the amount of output can be overwhelming on systems with a large buffer pool.
#
# 			(There is one mutex and one rw-lock in each 16K buffer pool block, and there are 
# 			65,536 blocks per gigabyte)
#
# 			SHOW ENGINE INNODB MUTEX also does not list any mutexes or rw-locks that have never
# 			been waited on (os_waits=0)
#
# 			Thus, SHOW ENGINE INNODB MUTEX only displays information about mutexes and rw-locks
# 			outside of the buffer pool that have caused at least one OS-level wait.
#
# 			Use SHOW_ENGINE_PERFORMANCE_SCHEMA_STATUS to inspect the internal operation of the
# 			Performance Schema code:
#
# 				SHOW ENGINE PERFORMANCE_SCHEMA STATUS\G
# 				---
# 				************************* 3. row ***************************************
# 					Type: performance_schema
# 					Name: events_waits_history.size
# 					Status: 76
#				************************* 4. row ***************************************
# 					Type: performance_schema
# 					Name: events_waits_history.count
# 					Status: 10000
# 				************************* 5. row ***************************************
# 					Type: performance_schema
# 					name: events_waits_history.memory
# 					Status: 760000
# 				---
# 				************************* 57. row ***************************************
# 					Type: performance_schema
# 					Name: performance_schema.memory
# 				Status : 26459600
# 				---
#
# This statement is intended to help the DBA understand the effects that different Performance
# Schema options have on memory requirements.
#
# Name values consist of two parts, which name an internal buffer and a buffer attribute,
# respectively. Interpret buffer names as follows:
#
# 		) An internal buffer that is not exposed as a table is named within parentheses.
#
# 			Examples: (pfs_cond_class).size, (pfs_mutex_class).memory
#
# 		) An internal buffer that is exposed as a table in the performance_schema database
# 			is named after the table, without parentheses.
#
# 			Examples: events_waits_history.size, mutex_instances.count
#
# 		) A value that applies to the Performance Schema as a whole begins with
# 			performance_schema. 
#
# 			Example: performance_schema.memory
#
# Buffer attributes have these meanings:
#
# 		) size is the size of the internal record used by the implementation, such as the size of a row
# 			in a table.
#
# 			size values cannot be changed
#
# 		) count is the number of internal records, such as the number of rows in a table. 
#
# 			count values can be changed using Performance Schema configuration options.
#
# 		) For a table, tbl_name.memory is the product of size and count.
#
# 			For the Performance Schema as a whole, performance_schema.memory is
# 			the sum of all the memory used (the sum of all other memory values)
#
# In some cases, there is a direct relationship between a Performance Schema configuration
# parameter and a SHOW ENGINE value.
#
# For example, events_waits_history_long.count corresponds to performance_schema_waits_history_long_size
#
# In other cases, the relationship is more complex. 
#
# For example, events_waits_history.count corresponds to performance_schema_events_waits_history_size 
# (the number of rows per thread) multiplied by performance_schema_max_thread_instances (the number of threads)
#
# SHOW ENGINE NDB STATUS
#
# If the server has the NDB storage engine enabled, SHOW ENGINE NDB STATUS displays cluster
# status information such as the number of connected data nodes, the cluster connectstring,
# and cluster binary log epochs, as well as counts of various Cluster API objects created
# by the MySQL Server when connected to the cluster.
#
# Sample output from this statement is shown here:
#
# 		SHOW ENGINE NDB STATUS;
# 		+------------+--------------------------------+--------------------------------------------+
# 		| Type 		 | Name 									 | Status 												 |
# 		+------------+--------------------------------+--------------------------------------------+
# 		| ndbcluster | connection 							 | cluster_node_id=7, 								 |
# 		  connected_host=198.51.100.103, connected_port=1186, number_of_data_nodes=4,
# 		  number_of_ready_data_nodes=3, connect_count=0
# 		| ndbcluster | NdbTransaction 					 | created=6, free=0, sizeof=212 			 	 |
# 		| ndbcluster | NdbOperation 						 | created=8, free=8, sizeof=660 				 |
# 		| ndbcluster | NdbIndexScanOperation 			 | created=1, free=1, sizeof=744 				 |
# 		| ndbcluster | NdbIndexOperation 				 | created=0, free=0, sizeof=664 				 |
# 		| ndbcluster | NdbRecAttr 							 | created=1285, free=1285, sizeof=60 			 |
# 		| ndbcluster | NdbApiSignal 						 | created=16, free=16, sizeof=136 				 |
# 		| ndbcluster | NdbLabel 							 | created=0, free=0, sizeof=196 				 |
# 		| ndbcluster | NdbBranch 							 | created=0, free=0, sizeof=24 					 |
# 		| ndbcluster | NdbSubroutine 						 | created=0, free=0, sizeof=68 					 |
# 		| ndbcluster | NdbCall 								 | created=0, free=0, sizeof=16 					 |
# 		| ndbcluster | NdbBlob 								 | created=1, free=1, sizeof=264 				 |
# 		| ndbcluster | NdbReceiver 						 | created=4, free=0, sizeof=68 					 |
# 		| ndbcluster | binlog 								 | latest_epoch=155467, latest_trans_epoch=148126,
# 		  latest_received_binlog_epoch=0, latest_handled_binlog_epoch=0,
# 		  latest_applied_binlog_epoch=0 																				 |
# 		+------------------------------------------------------------------------------------------+
# 
#
# The Status column in each of these rows provides information about the MySQL server's connection
# to the cluster and about the cluster binary log's status, respectively.
#
# The Status information is in the form of comma-delimited set of name/value pairs.
#
# The connection row's Status column contains the name/value pairs described in the following table.
#
# 		NAME 													VALUE
#
# 	cluster_node_id 								The node ID of the MySQL server in the cluster
#
# 	connected_host 								The host name or IP address of the cluster management server to which the MySQL server is connected
#
# 	connected_port 								The port used by the MySQL server to connect to the management server (connected_host)
#
# 	number_of_data_nodes 						The number of data nodes configured for the cluster (that is, the number of [ndbd] sections in
# 														the cluster config.ini file)
#
# 	number_of_ready_data_nodes 				The number of data nodes in the cluster that are actually running
#
# 	connect_count 									The number of times this mysqld has connected or reconnected to cluster data nodes
#
# The binlog row's Status column contains information relating to NDB Cluster Replication.
#
# The name/value pairs it contains are described in the following table.
#
# 		NAME 													VALUE
#
# latest_epoch 										The most recent epoch most recently run on this MySQL server (that is, the sequence
# 															number of the most recent transaction run on the server)
#
# latest_trans_epoch 								The most recent epoch processed by the cluster's data nodes
#
# latest_received_binlog_epoch 					The most recent epoch received by the binary log thread
#
# latest_handled_binlog_epoch 					The most recent epoch processed by the binary log thread (for writing to the binary log)
#
# latest_applied_binlog_epoch 					The most recent epoch actually written to the binary log
#
# See SECTION 22.6, "NDB CLUSTER REPLICATION", for more information.
#
# The remaining rows from the output of SHOW ENGINE NDB STATUS which are most likely to prove useful
# in monitoring the cluster are listed here by Name:
#
# 		) NdbTransaction: The number and size of NdbTransaction objects that have been created.
#
# 			An NdbTransaction is created each time a table schema operation (such as CREATE_TABLE or ALTER_TABLE)
# 			is performed on an NDB table.
#
# 		) NdbOperation: The number and size of NdbOperation objects that have been created.
#
# 		) NdbIndexScanOperation: The number and size of NdbIndexScanOperation objects that have been created.
#
# 		) NdbIndexOperation: The number and size of NdbIndexOperation objects that have been created.
#
# 		) NdbRecAttr: The number and size of NdbRecAttr objects that have been created.
# 		
# 			In general, one of these is created each time a data manipulation statement is performed
# 			by an SQL node.
#
# 		) NdbBlob: The number and size of NdbBlob objects that have been created. An NdbBlob is created for each
# 			new operation involving a BLOB column in an NDB table.
#
# 		) NdbReceiver: The number and size of any NdbReceiver object that have been created.
#
# 			The number in the created column is the same as the number of data nodes in the cluster
# 			to which the MySQL server was connected.
#
# 			NOTE:
#
# 				SHOW ENGINE NDB STATUS returns an empty result if no operations involving NDB tables
# 				have been performed during the current session by the MySQL client accessing
# 				the SQL node on which this statement is run.
#
# 13.7.6.16 SHOW ENGINES SYNTAX
#
# 		SHOW [STORAGE] ENGINES
#
# SHOW_ENGINES displays status information about the server's storage engines.
#
# This is particularly useful for checking whether a storage engine is supported,
# or to see what the default engine is.
#
# For information about MySQL storage engines, see CHAPTER 15, THE INNODB STORAGE ENGINE, and CHAPTER 16, ALTERNATIVE STORAGE ENGINES
#
# 		SHOW ENGINES\G
# 		*********************** 1. row ********************************
# 				Engine: ARCHIVE
# 			Support  : YES
# 			  Comment: Archive storage engine
# 		Transactions: NO
# 					 XA: NO
# 	   Savepoints  : NO
# 		************************ 2. row **********************************
# 				Engine: BLACKHOLE
# 			 Support : YES
# 			Comment  : /dev/null storage engine (anything you write to it disappears)
# 	Transactions   : NO
# 					 XA: NO
# 		Savepoints  : NO
# 		************************* 3. row ***********************************
# 				Engine: MRG_MYISAM
# 			Support  : YES
# 			Comment  : Collection of identical MyISAM tables
# 		Transactions: NO
# 					XA : NO
# 		Savepoints  : NO
# 		************************* 4. row ************************************
# 				Engine: FEDERATED
# 			Support  : NO
# 			Comment  : Federated MySQL storage engine
# 		Transactions: NULL
# 					XA : NULL
# 		 Savepoints : NULL
# 		************************** 5. row ************************************
# 				Engine: MyISAM
# 			Support  : YES
# 			  Comment: MyISAM storage engine
# 		Transactions: NO
# 					XA : NO
# 		Savepoints  : NO
# 		************************** 6. row **************************************
# 				Engine: PERFORMANCE_SCHEMA
# 			  Support: YES
# 			  Comment: Performance Schema
# 		Transactions: NO
# 					XA : NO
# 		  Savepoints: NO
# 		************************** 7. row **************************************
# 				Engine: InnoDB
# 			  Support: DEFAULT
# 			  Comment: Supports transactions, row-level locking, and foreign keys
# 		Transactions: YES
# 					XA : YES
# 		Savepoints  : YES
# 		************************** 8. row ***************************************
# 				Engine: MEMORY
# 			Support  : YES
# 			  Comment: Hash based, stored in memory, useful for temporary tables
# 		Transactions: NO
# 					XA : NO
# 	    Savepoints : NO
# 		************************** 9. row ***************************************
# 				Engine: CSV
# 			  Support: YES
# 			  Comment: CSV storage engine
# 		Transactions: NO
# 					XA : NO
# 		  Savepoints: NO
#
# The output from SHOW_ENGINES may vary according to the MySQL version used and other factors.
#
# SHOW_ENGINES output has these columns:
#
# 		) Engine
#
# 			The name of the storage engine
#
# 		) Support
#
# 			The server's level of support for the storage engine, as shown in the following table.
#
# 			VALUE 		MEANING
#
# 			YES 			The engine is supported and is active
#
# 			DEFAULT 		Like YES, plus this is the default engine
#
# 			NO 			The engine is not supported
#
# 			DISABLED 	The engine is supported but has been disabled
#
# 			A value of NO means that the server was compiled without support for the engine,
# 			so it cannot be enabled at runtime.
#
# 			A value of DISABLED occurs either because the server was started with an option that
# 			disables the engine, or because not all options required to enable it were given.
#
# 			In the latter case, the error log should contain a reason indicating why the option
# 			is disabled.
#
# 			See SECTION 5.4.2, "THE ERROR LOG"
#
# 			You might also see DISABLED for a storage engine if the server was compiled to support
# 			it, but was started with a --skip-engine_name option.
#
# 			For the NDB storage engine, DISABLED means the server was compiled with support
# 			for NDB Cluster, but was not started with the --ndbcluster option
#
# 			All MySQL servers support MyISAM tables. It is not possible to disable MyISAM
#
# 		) Comment
#
# 			A brief desription of the storage engine
#
# 		) Transactions
#
# 			Whether the storage engine supports transactions
#
# 		) XA
#
# 			Whether the storage engine supports XA transactions
#
# 		) Savepoints
#
# 			Whether the storage engine supports savepoints
#
# Storage engine information is also available from the INFORMATION_SCHEMA ENGINES table.
#
# See SECTION 25.8, "THE INFORMATION_SCHEMA ENGINES TABLE"
#
# 13.7.6.17 SHOW ERRORS SYNTAX
#
# 		SHOW ERRORS [LIMIT [offset,] row_count]
# 		SHOW COUNT(*) ERRORS
#
# SHOW_ERRORS is a diagnostic statement that is similar to SHOW_WARNINGS, except that
# it displays information only for errors, rather than for errors, warnings, and notes.
#
# The LIMIT clause has the same syntax as for the SELECT statement. See SECTION 13.2.10, "SELECT SYNTAX"
#
# The SHOW_COUNT(*)_ERRORS statement displays the number of errors. You can also retrieve this
# number from the error_count variable:
#
# 		SHOW COUNT(*) ERRORS;
# 		SELECT @@error_count;
#
# SHOW_ERRORS and error_count apply only to errors, not warnings or notes.
#
# In other respects, they are similar to SHOW_WARNINGS and warning_count.
#
# In particular, SHOW_ERRORS cannot display information for more than max_error_count
# messages, and error_count can exceed the value of max_error_count if the number
# of errors exceeds max_error_count
#
# For more information, see SECTION 13.7.6.40, "SHOW WARNINGS SYNTAX"
#
# 13.7.6.18 SHOW EVENTS SYNTAX
#
# SHOW EVENTS
# 		[{FROM | IN} schema_name]
# 		[LIKE 'pattern' | WHERE expr]
#
# This statement displays information about Event Manager events, which are discussed
# in SECTION 24.4, "USING THE EVENT SCHEDULER"
#
# It requires the EVENT privilege for the database from which the events are to be shown.
#
# In its simplest form, SHOW_EVENTS lists all of the events in the current schema:
#
# 		SELECT CURRENT_USER(), SCHEMA();
# 		+-----------------+-----------+
# 		| CURRENT_USER()  | SCHEMA()  |
# 		+-----------------+-----------+
# 		| jon@ghidora     | myschema  |
# 		+-----------------+-----------+
# 		1 row in set (0.00 sec)
#
# 		SHOW EVENTS\G
# 		*********************** 1. row ***************************************
# 							Db: myschema
# 						 Name: e_daily
# 					Definer : jon@ghidora
# 				Time zone  : SYSTEM
# 					  Type  : RECURRING
# 			Execute at    : NULL
# 			Interval value: 1
# 			Interval field: DAY
# 					Starts  : 2018-08-08 11:06:34
# 					  Ends  : NULL
# 					Status  : ENABLED
# 				Originator : 1
# 	character_set_client: utf8mb4
# 	collation_connection: utf8mb4_0900_ai_ci
#   Database Collation : utf8mb4_0900_ai_ci
#
# To see events for a specific schema, use the FROM clause. For example, to see events
# for the test schema, use the following statement:
#
# 		SHOW EVENTS FROM test;
#
# The LIKE clause, if present, indicates which event names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# SHOW_EVENTS output has these columns:
#
# 		) Db
# 			
# 			The name of the schema (database) to which the event belongs
#
# 		) Name
#
# 			The name of the event
#
# 		) Definer
#
# 			The account of the user who created the event, in 'user_name'@'host_name' format.
#
# 		) Time zone
#
# 			The event time zone, which is the time zone used for scheduling the event and that
# 			is in effect within the event as it executes.
#
# 			The default value is SYSTEM
#
# 		) Type
#
# 			The event repetition type, either ONE TIME (transient) or RECURRING (repeating)
#
# 		) Execute At
#
# 			For a one-time event, this is the DATETIME value specified in the AT clause of the
# 			CREATE_EVENT statement used to create the event, or of the last ALTER_EVENT
# 			statement that modified the event.
#
# 			The value shown in this column reflects the addition or subtraction of any
# 			INTERVAL value included in the event's AT clause.
#
# 			For example, if an event is created using ON SCHEDULE AT CURRENT_TIMESTAMP + '1:6' DAY_HOUR,
# 			and the event was created at 2018-02-09 14:05:30, the value shown in this column
# 			would be '2018-02-10 20:05:30'
#
# 			If the event's timing is determined by an EVERY clause instead of an AT clause
# 			(that is, if the event is recurring), the value of this column is NULL
#
# 		) Interval Value
#
# 			For a recurring event, the number of intervals to wait between event executions.
#
# 			For a transient event, the value of this column is always NULL
#
# 		) Interval Field
#
# 			The time units used for the interval which a recurring event waits before repeating.
#
# 			For a transient event, the value of this column is always NULL
#
# 		) Starts
#
# 			The start date and time for a recurring event.
#
# 			This is displayed as a DATETIME value, and is NULL if no start date and
# 			time are defined for the event.
#
# 			For a transient event, this column is always NULL. For a recurring event
# 			whose definition includes a STARTS clause, this column contains the corresponding
# 			DATETIME value.
#
# 			As with the Execute At column, this value resolves any expressions used.
#
# 			If there is no STARTS clause affecting the timing of the event, this column is NULL
#
# 		) ENDS
#
# 			For a recurring event whose definition includes a ENDS clause, this column contains the
# 			corresponding DATETIME value.
#
# 			As with the Execute At column, this value resolves any expressions used.
#
# 			If there is no ENDS clause affecting the timing of the event, this column is NULL
#
# 		) Status
#
# 			The event status. One of ENABLED, DISABLED or SLAVESIDE_DISABLED.
#
# 			SLAVESIDE_DISABLED indicates that hte creation of the event occurred
# 			on another MySQL server acting as a replication master and replicated
# 			to the current MySQL server which is acting as a slave, but the event
# 			is not presently being executed on the slave.
#
# 			For more information, see SECTION 17.4.1.16, "REPLICATION OF INVOKED FEATURES"
# 			information
#
# 		) Originator
#
# 			The server ID of the MySQL server on which the event was created; used in replication.
#
# 			The default value is 0
#
# 		) character_set_client
#
# 			The session value of the character_set_client system variable when the event
# 			was created.
#
# 		) collation_connection
#
# 			The session value of the collation_connection system variable when the event
# 			was created.
#
# 		) Database Collation
#
# 			The collation of the database with which the event is associated
#
# For more information about SLAVESIDE_DISABLED and the Originator column, see SECTION 17.4.1.16,
# "REPLICATION OF INVOKED FEATURES"
#
# Times displayed by SHOW_EVENTS are given in the event time zone, as discussed in SECTION 24.4.4, "EVENT METADATA"
#
# Event information is also available from the INFORMATION_SCHEMA EVENTS table. See SECTION 25.9, "THE INFORMATION_SCHEMA EVENTS TABLE"
#
# The event action statement is not shown in the output of SHOW_EVENTS.
#
# Use SHOW_CREATE_EVENT or the INFORMATION_SCHEMA EVENTS table.
#
# 13.7.6.19 SHOW FUNCTION CODE SYNTAX
#
# 		SHOW FUNCTION CODE func_name
#
# This statement is similar to SHOW_PROCEDURE_CODE but for stored functions.
#
# See SECTION 13.7.6.27, "SHOW PROCEDURE CODE SYNTAX"
#
# 13.7.6.20 SHOW FUNCTION STATUS SYNTAX
#
# 		SHOW FUNCTION STATUS
# 			[LIKE 'pattern' | WHERE expr]
#
# This statement is similar to SHOW_PROCEDURE_STATUS but for stored functions.
#
# See SECTION 13.7.6.28, "SHOW PROCEDURE STATUS SYNTAX"
#
# 13.7.6.21 SHOW GRANTS SYNTAX
#
# 		SHOW GRANTS
# 			[FOR user_or_role
# 				[USING role [, role] ---]]
#
# 		user_or_role: {
# 			user
# 		 | role
# 		}
#
# This statement displays the privileges and roles that are assigned to a MySQL
# user account or role, in the form of GRANT statements that must be executed
# to duplicate the privilege and role assignments.
#
# NOTE:
#
# 		To display nonprivilege information for MySQL accounts, use the SHOW_CREATE_USER
# 		statement.
#
# 		See SECTION 13.7.6.12, "SHOW CREATE USER SYNTAX"
#
# SHOW_GRANTS requires the SELECT privilege for the mysql system database, except to
# display privileges and roles for the current user.
#
# To name the account or role for SHOW_GRANTS, use the same format as for the  GRANT
# statement; for example, 'jeffrey'@'localhost':
#
# 		SHOW GRANTS FOR 'jeffrey'@'localhost';
# 		+-----------------------------------------------------------------+
# 		| Grants for jeffrey@localhost 												|
# 		+-----------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `jeffrey`@`localhost`   						|
# 		| GRANT SELECT, INSERT, UPDATE ON `db1`.* TO `jeffrey`@`localhost`|
# 		+-----------------------------------------------------------------+
#
# The host part, if omitted, defaults to '%'
#
# For additional information about specifying account and role names,
# See SECTION 6.2.4, "SPECIFYING ACCOUNT NAMES", and SECTION 6.2.5, "SPECIFYING ROLE NAMES"
#
# To display the privileges granted to the current user (the account you are using to connect
# to the server), you can use any of the following statements:
#
# 		SHOW GRANTS;
# 		SHOW GRANTS FOR CURRENT_USER;
# 		SHOW GRANTS FOR CURRENT_USER();
#
# If SHOW GRANTS FOR CURRENT_USER (or any of the equivalent syntaxes) is used in
# definer context, such as within a stored procedure that executes with definer
# rather than invoker privileges, the grants displayed are those of the definer
# and not hte invoker.
#
# In MySQL 8.0 compared to previous series, SHOW_GRANTS no longer displays ALL_PRIVILEGES
# in its global-privileges output because the meaning of ALL_PRIVILEGES at the
# global level varies depending on which dynamic privileges are defined.
#
# Instead, SHOW_GRANTS explicitly lists each granted global privilege:
#
# 		SHOW GRANTS FOR 'root'@'localhost';
# 		+-------------------------------------------------------+
# 		| Grants for root@localhost 								     |
# 		+-------------------------------------------------------+
# 		| GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, DROP,   |
# 		| RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX,   |
# 		| ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES,|
# 		| LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION  |
# 		| CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, 		  |
# 		| ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE    |
# 		| TABLESPACE, CREATE ROLE, DROP ROLE ON *.* TO  		  |
# 		| `root`@`localhost` WITH GRANT  							  |
# 		| OPTION  															  |
# 		| GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH       |
# 		|  GRANT OPTION       											  |
# 		+-------------------------------------------------------+
#
# Applications that process SHOW_GRANTS output should be adjusted accordingly.
#
# At the global level, GRANT_OPTION applies to all granted static global
# privileges if granted for any of them, but applies individually to granted
# dynamic privileges.
#
# SHOW_GRANTS displays global privileges this way:
#
# 		) One line listing all granted static privileges, if there are any, including WITH GRANT OPTION if appropriate
#
# 		) One line listing all granted dynamic privileges for which GRANT_OPTION is granted, if there are any,
# 			including WITH GRANT OPTION
#
# 		) One line listing all granted dynamic privileges for which GRANT_OPTION is not granted, if there
# 			are any, without WITH GRANT OPTION
#
# With the optional USING clause, SHOW_GRANTS enables you to examine the privileges associated
# with roles for the user.
#
# Each role named in the USING clause must be granted to the user.
#
# Suppose that user u1 is assigned roles r1 and r2, as follows:
#
# 		CREATE ROLE 'r1', 'r2';
# 		GRANT SELECT ON db1.* TO 'r1';
# 		GRANT INSERT, UPDATE, DELETE ON db1.* TO 'r2';
# 		CREATE USER 'u1'@'localhost' IDENTIFIED BY 'u1pass';
# 		GRANT 'r1', 'r2' TO 'u1'@'localhost';
#
# SHOW_GRANTS without USING shows the granted roles:
#
# 		SHOW GRANTS FOR 'u1'@'localhost';
# 		+-----------------------------------------------+
# 		| Grants for u1@localhost 								|
# 		+-----------------------------------------------+
# 		| GRANT USAGE ON *.* TO `u1`@`localhost`  		|
# 		| GRANT `r1`@`%`, `r2`@`%` TO `u1`@`localhost`  |
# 		+-----------------------------------------------+
#
# Adding a USING clause causes the statement to also display the privileges
# associated with each role named in the clause:
#
# 		SHOW GRANTS FOR 'u1'@'localhost' USING 'r1';
# 		+--------------------------------------------+
# 		| Grants for u1@localhost 					 		|
# 		+--------------------------------------------+
# 		| GRANT USAGE ON *.* TO `u1`@`localhost`		|
# 		| GRANT SELECT ON `db1`.* TO `u1`@`localhost`|
# 		| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost`|
# 		+--------------------------------------------+
# 		SHOW GRANTS FOR 'u1'@'localhost' USING 'r2';
# 		+------------------------------------------------------------+
# 		| Grants for u1@localhost 												 |
# 		+------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `u1`@`localhost` 							 |
# 		| GRANT INSERT, UPDATE, DELETE ON `db1`.* TO `u1`@`localhost`|
# 		| GRANT `r1`@`%`, `r2`@`%` TO `u1`@`localhost`					 |
# 		+------------------------------------------------------------+
# 		SHOW GRANTS FOR 'u1'@'localhost' USING 'r1', 'r2';
# 		+--------------------------------------------------------------------+
# 		| Grants for u1@localhost 												 			|
# 		+--------------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `u1`@`localhost` 							 			|
# 		| GRANT SELECT, INSERT, UPDATE, DELETE ON `db1`.* TO `u1`@`localhost`|
# 		| GRANT `r1`@`%`,`r2`@`%` TO `u1`@`localhost`								|
# 		+--------------------------------------------------------------------+
#
# NOTE:
#
# 		A privilege granted to an account is always in effect, but a role is not.
#
# 		The active roles for an account can differ across and within sessions,
# 		depending on the value of the activate_all_roles_on_login system
# 		variable, the account default roles, and whether SET_ROLE has been executed
# 		within a session.
#
# SHOW_GRANTS does not display privileges that are available to the named account
# but are granted to a different account.
#
# For example, if an anonymous account exists, the named account might be able to
# use its privileges, but SHOW_GRANTS does not display them.
#
# SHOW_GRANTS displays mandatory roles named in the mandatory_roles system variable
# value as follows:
#
# 		) SHOW_GRANTS without a FOR clause displays privileges for the current user,
# 			and includes mandatory roles
#
# 		) SHOW_GRANTS_FOR_user displays privileges for the name used, and does not include
# 			mandatory roles.
#
# This behavior is for the benefit of applications that use the output of SHOW_GRANTS_FOR_user
# to determine which privileges are granted explicitly to the named user.
#
# Were that output to include mandatory roles, it would be difficult to distinguish roles
# granted explicitly to the user from mandatory roles.
#
# For the current user, applications can determine privileges with or without mandatory
# roles by using SHOW_GRANTS or SHOW_GRANTS_FOR_CURRENT_USER, respectively.
#
# 13.7.6.22 SHOW INDEX SYNTAX
#
# 		SHOW [EXTENDED] {INDEX | INDEXES | KEYS}
# 			{FROM | IN} tbl_name
# 			[{FROM | IN} db_name]
# 			[WHERE expr]
#
# SHOW_INDEX returns table index information.
#
# The format resembles that of the SQLStatistics call in ODBC.
#
# This statement requires some privilege for any column in the table.
#
# 		SHOW INDEX FROM City\G
# 		*********************** 1. row ******************************
# 					Table: city
# 			Non_unique : 0
# 				Key_name: PRIMARY
# 		Seq_in_index  : 1
# 		Column_name   : ID
# 			Collation  : A
# 		Cardinality   : 4188
# 			Sub_part   : NULL
# 			  Packed   : NULL
# 				NULL    : 
# 		Index_type    : BTREE
# 				Comment : 
# 		Index_comment :
# 			Visible    : YES
# 		  Expression  : NULL
# 		*********************** 2. row *********************************
# 					Table: city
# 			Non_unique : 1
# 				Key_name: CountryCode
# 			Seq_in_index: 1
# 			Column_name: CountryCode
# 			 Collation : A
# 			Cardinality: 232
# 				Sub_part: NULL
# 				 Packed : NULL
# 					Null :
# 			Index_type : BTREE
# 			  Comment  :
# 		Index_comment :
# 			Visible    : YES
# 			Expression : NULL
#
# An alternative to tbl_name FROM db_name syntax is db_name.tbl_name
#
# These two statements are equivalent:
#
# 		SHOW INDEX FROM mytable FROM mydb;
# 		SHOW INDEX FROM mydb.mytable;
#
# The optional EXTENDED keyword causes the output to include information about
# hidden indexes that MySQL uses internally and are not accessible by users.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# SHOW_INDEX returns the following fields:
#
# 		) Table
#
# 			The name of the table
#
# 		) Non_unique
#
# 			0 if the index cannot contain duplicates, 1 if it can
#
# 		) Key_name
#
# 			The name of the index. If the index is the primary key, the name
# 			is always PRIMARY
#
# 		) Seq_in_index
# 
# 			The column sequence number in the index, starting with 1
#
# 		) Column_name
#
# 			The column name. See also the description for the Expression column
#
# 		) Collation
#
# 			How the column is sorted in the index. This can have values A (ascending), D (descending)
# 			or NULL (not sorted)
#
# 		) Cardinality
#
# 			An estimate of the number of unique values in the index.
#
# 			To update this number, run ANALYZE_TABLE or (for MyISAM tables) myisamchk -a
#
# 			Cardinality is counted based on statistics stored as integers, so the value is not
# 			necessarily exact even for small tables.
#
# 			The higher hte cardinality, the greater the chance that MySQL uses the index when doing joins
#
# 		) Sub_part
#
# 			The index prefix.
#
# 			That is, the number of indexed characters if the column is only partly indexed,
# 			NULL if the entire column is indexed.
#
# 			NOTE:
#
# 				Prefix limits are measured in bytes. However, prefix lengths for index
# 				specifications in CREATE_TABLE, ALTER_TABLE, and CREATE_INDEX statements
# 				are interpreted as number of characters for nonbinary string types
# 				(CHAR, VARCHAR, TEXT) and number of bytes for binary string types
# 				(BINARY, VARBINARY, BLOB)
#
# 				Take this into account when specifying a prefix length for a nonbinary string
# 				column that uses a multibyte character set.
#
# 			For additional information about index prefixes, see SECTION 8.3.5, "COLUMN INDEXES",
# 			and SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# 		) PACKED
#
# 			Indicates how the key is packed. NULL if it is not
#
# 		) NULL
#
# 			Contains YES if the column may contain NULL values and '' if not
#
# 		) INDEX_TYPE
#
# 			The index method used (BTREE, FULLTEXT, HASH, RTREE)
#
# 		) COMMENT
#
# 			Information about the index not described in its own column, such as disabled if the index is disabled.
#
# 		) INDEX_COMMENT
#
# 			Any comment provided for the index with a COMMENT attribute when the index was created.
#
# 		) VISIBLE
#
# 			Whether the index is visible to the optimizer. See SECTION 8.3.12, "INVISIBLE INDEXES"
#
# 		) EXPRESSION
#
# 			MySQL 8.0.13 and higher supports functional key parts (see FUNCTIONAL KEY PARTS),
# 			which affects both the Column_name and Expression columns:
#
# 				) For a nonfunctional key part, Column_name indicates the column indexed
# 					by the key part and Expression is NULL
#
# 				) For a functional key part, Column_name column is NULL and Expression indicates
# 					the expression for the key part.
#
# Information about table indexes is also available from the INFORMATION_SCHEMA STATISTICS
# table.
#
# See SECTION 25.25, "THE INFORMATION_SCHEMA STATISTICS TABLE"
#
# The extended information about hidden indexes is available only using
# SHOW EXTENDED INDEX; it cannot be obtained from the STATISTICS table.
#
# You can list a table's indexes with the mysqlshow -k db_name tbl_name command
#
# 13.7.6.23 SHOW MASTER STATUS SYNTAX
#
# 		SHOW MASTER STATUS
#
# This statement provides status information about the binary log files of the master.
#
# It requires either the SUPER or REPLICATION_CLIENT privilege.
#
# Example:
#
# 		SHOW MASTER STATUS\G
# 		********************** 1. row **************************
# 						File: master-bin.000002
# 				Position  : 1307
# 			Binlog_Do_DB : test
# 		Binlog_Ignore_DB: manual, mysql
# 	  Executed_Gtid_Set: <serial>
# 		1 row in set (0.00 sec)
#
# When global transaction IDs are in use, Executed_Gtid_Set shows the set of
# GTIDs for transactions that have been executed on the master.
#
# This is the same as the value for the gtid_executed system variable
# on this server, as well as the value for Executed_Gtid_Set in the
# output of SHOW_SLAVE_STATUS on this server.
#
# 13.7.6.24 SHOW OPEN TABLES SYNTAX
#
# 		SHOW OPEN TABLES
# 			[{FROM | IN} db_name]
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_OPEN_TABLES lists the non-TEMPORARY tables that are currently open in the
# table cache.
#
# See SECTION 8.4.3.1, "HOW MYSQL OPENS AND CLOSES TABLES"
#
# The FROM clause, if present, restricts the tables shown to those
# present in the db_name database.
#
# The LIKE clause, if present, indicates which table names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# SHOW_OPEN_TABLES output has these columns:
#
# 		) Database
#
# 			The database containing the table
#
# 		) Table
#
# 			The table name
#
# 		) In_use
#
# 			The number of table locks or lock requests there are for the table.
#
# 			For example, if one client acquires a lock for a table using:
#
# 				LOCK TABLE t1 WRITE
#
# 			In_use will be 1.
#
# 			If another client issues LOCK TABLE t1 WRITE while the table remains
# 			locked, the client will block waiting for the lock, but the lock request
# 			causes In_use to be 2.
#
# 			If the count is zero, the table is open but not currently being used.
#
# 			In_use is also increased by the HANDLER_---_OPEN statement and decreases
# 			by HANDLER_---_CLOSE
#
# 		) Name_locked
#
# 			Whether the table name is locked. Name locking is used for operations
# 			such as dropping or renaming tables.
#
# If you have no privileges for a table, it does not show up in the ouput from
# SHOW_OPEN_TABLES
#
# 13.7.6.25 SHOW PLUGINS SYNTAX
#
# 		SHOW PLUGINS
#
# SHOW_PLUGINS displays information about server plugins
#
# Example of SHOW_PLUGINS output:
#
# 		SHOW PLUGINS\G
# 		********************* 1. row ************************
# 			Name: binlog
# 		 Status: ACTIVE
# 		  Type : STORAGE ENGINE
# 		Library: NULL
# 		License: GPL
# 		********************** 2. row ************************
# 			Name: CSV
# 		 Status: ACTIVE
# 		  Type : STORAGE ENGINE
# 		Library: NULL
# 		License: GPL
#		*********************** 3. row ************************
# 			Name: MEMORY
# 		 Status: ACTIVE
# 		  Type : STORAGE ENGINE
# 		Library: NULL
# 		License: GPL
# 		*********************** 4. row *************************
# 			Name: MyISAM
# 		  Status: ACTIVE
# 		Type   : STORAGE ENGINE
# 		Library: NULL
# 		License: GPL
# 		---
#
# SHOW_PLUGINS output has these columns:
#
# 		) Name
#
# 			The name used to refer to the plugin in statements such as INSTALL_PLUGIN
# 			and UNINSTALL_PLUGIN
#
# 		) Status
#
# 			The plugin status, one of ACTIVE, INACTIVE, DISABLED, DELETING or DELETED.
#
# 		) Type
#
# 			The type of plugin, such as STORAGE ENGINE, INFORMATION_SCHEMA, or AUTHENTICATION
#
# 		) Library
#
# 			The name of the plugin shared library file.
#
# 			This is the name used to refer to the plugin file in statements such as
# 			INSTALL_PLUGIN and UNINSTALL_PLUGIN
#
# 			This file is located in the direcotry named by the plugin_dir system variable.
#
# 			If the library name is NULL, the plugin is compiled in and cannot be uninstalled
# 			with UNINSTALL_PLUGIN
#
# 		) License
#
# 			How the plugin is licensed; for example, GPL
#
# For plugins installed with INSTALL_PLUGIN, the Name and Library values are also
# registered in the mysql.plugin system table.
#
# For information about plugin data structures that form the basis of the information
# displayed by SHOW_PLUGINS, see SECTION 29.2, "THE MYSQL PLUGIN API"
#
# Plugin information is also available from the INFORMATION_SCHEMA.PLUGINS table
#
# See SECTION 25.17, "THE INFORMATION_SCHEMA PLUGINS TABLE"
#
# 13.7.6.26 SHOW PRIVILEGES SYNTAX
#
# 		SHOW PRIVILEGES
#
# SHOW_PRIVILEGES shows the list of system privileges that the MySQL server supports.
#
# The privileges displayed include all static privileges, and all currently registered
# dynamic privileges.
#
# 		SHOW PRIVILEGES\G
# 		********************** 1. row *************************
# 		Privilege: Alter
# 		Context: Tables
# 		Comment: To alter the table
# 		********************** 2. row **************************
# 		Privilege: Alter routine
# 		Context: Functions, Procedures
# 		Comment: To alter or drop stored functions/procedures
# 		********************** 3. row ***************************
# 		Privilege: Create
# 		Context: Databases, Tables, Indexes
# 		Comment: To create new databases and tables
# 		********************** 4. row ****************************
# 		Privilege: Create routine
# 		Context: Databases
# 		Comment: To use CREATE FUNCTION/PROCEDURE
# 		********************** 5. row *****************************
# 		Privilege: Create temporary tables
# 		Context: Databases
# 		Comment: To use CREATE TEMPORARY TABLE
# 		---
#
# Privileges belonging to a specific user are displayed by the SHOW_GRANTS statement.
#
# See SECTION 13.7.6.21, "SHOW GRANTS SYNTAX", for more information.
#
# 13.7.6.27 SHOW PROCEDURE CODE SYNTAX
#
# 		SHOW PROCEDURE CODE proc_name
#
# this statement is a MySQL extension that is available only for servers that
# have been built with debugging support.
#
# It displays a representation of the internal implementation of the named
# stored procedure.
#
# A similar statement, SHOW_FUNCTION_CODE, displays information about stored
# functions (see SECTION 13.7.6.19, "SHOW FUNCTION CODE SYNTAX")
#
# To use either statement, you must have the global SELECT privilege.
#
# If the named routine is available, each statement produces a result set.
# Each row in the result set corresponds to one "instruction" in the routine.
#
# The first column is Pos, which is an ordinal number beginning with 0.
#
# The second column is Instruction, which contains an SQL statement (usually
# changed from the original source), or a directive which has meaning only to
# the stored-routine handler.
#
# 		DELIMITER //
# 		CREATE PROCEDURE p1 ()
# 		BEGIN
# 			DECLARE fanta INT DEFAULT 55;
# 			DROP TABLE t2;
# 			LOOP
# 				INSERT INTO t3 VALUES (fanta);
# 				END LOOP;
# 			END//
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SHOW PROCEDURE CODE p1//
# 		+------+----------------------------------------+
# 		| Pos  | Instruction 								   |
# 		+------+----------------------------------------+
# 		| 0    | set fanta@0 55 							   |
# 		| 1    | stmt 9 "DROP TABLE t2" 				      |
# 		| 2    | stmt 5 "INSERT INTO t3 VALUES (fanta)" |
# 		| 3  	 | jump 2 											|
# 		+------+----------------------------------------+
# 		4 rows in set (0.00 sec)
#
# In this example, the nonexecutable BEGIN and END statements have disappeared, and for
# the DECLARE variable_name statement, only the executable part appears (the part where
# the default is assigned)
#
# For each statement that is taken from source, there is a code word stmt followed
# by a type (9 means DROP, 5 means INSERT, and so on)
#
# Tthe final row contains an instruction jump 2, meaning GOTO instruction #2
#
# 13.7.6.28 SHOW PROCEDURE STATUS SYNTAX
#
# 		SHOW PROCEDURE STATUS
# 			[LIKE 'pattern' | WHERE expr]
#
# This statement is a MySQL extension. It returns characteristics of a stored procedure,
# such as the database, name, type, creator, creation and modification dates, and
# character set information.
#
# A similar statement, SHOW_FUNCTION_STATUS, displays information about stored functions
# (see SECTION 13.7.6.20, "SHOW FUNCTION STATUS SYNTAX")
#
# The LIKE clause, if present, indicates which procedure or function names to match.
#
# The WHERE clause can be given to select rows using more general conditions, as
# discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# 		SHOW PROCEDURE STATUS LIKE 'sp1'\G
# 		************************** 1. row *****************************
# 								Db: test
# 							Name : sp1
# 							 Type: PROCEDURE
# 						 Definer: testuser@localhost
# 					  Modified : 2018-08-08 13:54:11
# 					   Created : 2018-08-08 13:54:11
# 				Security_type : DEFINER
# 						Comment : 
# 		character_set_client: utf8mb4
# 		collation_connection: utf8mb4_0900_ai_ci
# 		  Database Collation: utf8mb4_0900_ai_ci
#
# character_set_client is the session value of the character_set_client system variable
# when the routine was created.
#
# collation_connection is the session value of the collation_connection system variable
# when the routine was created.
#
# Database Collation is the collation of the database with which the routine is associated.
#
# Stored routine information is also available from the INFORMATION_SCHEMA PARAMETERS
# and ROUTINES tables.
#
# See SECTION 25.15, "THE INFORMATION_SCHEMA PARAMETERS TABLE", and SECTION 25.22, "THE INFORMATION_SCHEMA ROUTINES TABLE"
#
# 13.7.6.29 SHOW PROCESSLIST SYNTAX
#
# 		SHOW [FULL] PROCESSLIST
#
# SHOW_PROCESSLIST shows which threads are running. If you have the PROCESS privilege,
# you can see all threads.
#
# Otherwise, you can see only your own threads (that is, threads associated with the
# MySQL account that you are using)
#
# If you do not use the FULL keyword, only the first 100 characters of each statement
# are shown in the Info field.
#
# The SHOW_PROCESSLIST statement is very useful if you get the "too many connections"
# error message and want to find out what is going on.
#
# MySQL reserves one extra connection to be used by accounts that have the CONNECTION_ADMIN
# or SUPER privilege, to ensure that administrators should always be able to connect
# and check the system (assuming that you are not giving this privilege to all your users)
#
# Threads can be killed with the KILL statement. See SECTION 13.7.7.4, "KILL SYNTAX"
#
# Example of SHOW_PROCESSLIST output:
#
# 		SHOW FULL PROCESSLIST\G
# 		********************** 1. row *******************************
# 		Id: 1
# 		User: system user
# 		Host:
# 		db: NULL
# 		Command: Connect
# 		Time: 1030455
# 		State: Waiting for master to send event
# 		Info: NULL
# 		********************* 2. row *********************************
# 		Id: 2
# 		User: system user
# 		Host:
# 		db: NULL
# 		Command: Connect
# 		Time: 1004
# 		State: Has read all relay log; waiting for the slave I/O thread to update it
# 		Info: NULL
# 		********************** 3. row *********************************
# 		Id: 3112
# 		User: replikator
# 		Host: artemis:2204
# 		db: NULL
# 		Command: Binlog Dump
# 		Time: 2144
# 		State: Has sent all binlog to slave; waiting for binlog to be updated
# 		Info: NULL
# 		********************* 4. row ***********************************
# 		Id: 3113
# 		User: replikator
# 		Host: iconnect2:45781
# 		db: NULL
# 		Command: Binlog Dump
# 		Time: 2086
# 		State: Has sent all binlog to slave; waiting for binlog to be updated
# 		Info: NULL
# 		******************** 5. row ************************************
# 		Id: 3123
# 		User: stefan
# 		Host: localhost
# 		db: apollon
# 		Command: Query
# 		Time: 0
# 		State: NULL
# 		Info: SHOW FULL PROCESSLIST
# 		5 rows in set (0.00 sec)
#
# SHOW_PROCESSLIST output has these columns:
#
# 		) Id
#
# 			The connection identifier.
#
# 			This is the same type of value displayed in the ID column of the
# 			INFORMATION_SCHEMA PROCESSLIST table, the PROCESSLIST_ID column of
# 			the Performance Schema threads table, and returned by the CONNECTION_ID() function.
#
# 		) User
#
# 			THe MySQL user who issued the statement. A value of system user refers to a nonclient
# 			thread spawned by the server to handle tasks internally.
#
# 			This could be the I/O or SQL thread used on replication slaves or a delayed-row handler.
#
# 			For system user, there is no host specified in the Host column.
#
# 			unauthenticated user refers to a thread that has become associated with a client connection
# 			but for which authentication of the client user has not yet been done.
#
# 			event_scheduler refers ot the thread that monitors scheduled events
# 			(see SECTION 24.4, "USING THE EVENT SCHEDULER")
#
# 		) Host
#
# 			The host name of the client issuing the statement (except for system user, for which
# 			there is no host)
#
# 			The host name for TCP/IP connections is reported in host_name:client_port format
# 			to make it easier to determine which client is doing what.
#
# 		) db
#
# 			The default database, if one is selected; otherwise NULL
#
# 		) Command
#
# 			The type of command the thread is executing.
#
# 			For descriptions for thread commands, see SECTION 8.14, "EXAMINING THREAD INFORMATION"
#
# 			The value of this column corresponds to the COM_xxx commands of the client/server
# 			protocol and Com_xxx status variables.
#
# 			See SECTION 5.1.10, "SERVER STATUS VARIABLES"
#
# 		) Time
#
# 			The time in seconds that the thread has been in its current state.
#
# 			For a slave SQL thread, the value is the number of seconds between
# 			the timestamp of the last replicated event and the real time of the slave
# 			machine.
#
# 			See SECTION 17.2.2, "REPLICATION IMPLEMENTATION DETAILS"
#
# 		) State
#
# 			An action, event or state that indicates what the thread is doing.
#
# 			Descriptions for State values can be found at SECTION 8.14, "EXAMINING THREAD INFORMATION"
#
# 			Most states correspond to very quick operations. If a thread stays in a given state
# 			for many seconds, there might be a problem that needs to be investigated.
#
# 			For the SHOW_PROCESSLIST statement, the value of State is NULL
#
# 		) Info
#
# 			The statement the thread is executing, or NULL if it is not executing any statement.
#
# 			The statement might be the one sent ot the server, or an innermost statement if the
# 			statement executes other statements.
#
# 			For example, if a CALL statement executes a stored procedure that is executing
# 			a SELECT statement, the Info value shows the SELECT statement.
#
# Process information is also available from the mysqladmin processlist command, the
# INFORMATION_SCHEMA PROCESSLIST table, and the Performance Schema threads table
#
# (see SECTION 4.5.2, "MYSQLADMIN -- CLIENT FOR ADMINISTERING A MYSQL SERVER", SECTION 25.18, "THE INFORMATION_SCHEMA PROCESSLIST TABLE",
# and SECTION 26.12.17.5, "THE THREADS TABLE")
#
# In contrast to the INFORMATION_SCHEMA PROCESSLIST table and SHOW_PROCESSLIST statement,
# which have negative performance consequences because they require a mutex, access to 
# threads does not require a mutex and has minimal impact on the server performance.
#
# The threads table also shows information about background threads, which the PROCESSLIST
# table and SHOW_PROCESSLIST do not.
#
# This means that threads can be used to monitor activity the other thread information
# sources cannot.
#
# 13.7.6.30 SHOW PROFILE SYNTAX
#
# 		SHOW PROFILE [type [, type] --- ]
# 			[FOR QUERY n]
# 			[LIMIT row_count [OFFSET offset]]
#
# 		type: {
# 			ALL
# 		 | BLOCK IO
# 		 | CONTEXT SWITCHES
#      | CPU
#      | IPC
# 	    | MEMORY
# 		 | PAGE FAULTS
# 		 | SOURCE
# 		 | SWAPS
# 		}
#
# The SHOW_PROFILE and SHOW_PROFILES statements display profiling information that indicates
# resource usage for statements executed during the course of the current session.
#
# NOTE:
#
# 		The SHOW_PROFILE and SHOW_PROFILES statements are deprecated and will be removed in a future
# 		MySQL release.
#
# 		Use the PERFORMANCE SCHEMA instead; see SECTION 26.19.1, "QUERY PROFILING USING PERFORMANCE SCHEMA"
#
# To control profiling, use the profiling session variable, which has a default value of 0 (OFF)
#
# Enable profiling by setting profiling to 1 or ON:
#
# 		SET profiling = 1;
#
# SHOW_PROFILES displays a list of the most recent statements sent to the server.
#
# The size of the list is controlled by the profiling_history_size session variable,
# which has a default value of 15.
#
# The maximum value is 100.
#
# Setting the value to 0 has the practical effect of disabling profiling.
#
# All statements are profiled except SHOW_PROFILE and SHOW_PROFILES, so you will find
# neither of those statements in the profile list.
#
# Malformed statements are profiled. For example, SHOW PROFILING is an illegal statement,
# and a syntax error occurs if you try to execute it, but it will show up in the
# profiling list.
#
# SHOW_PROFILE displays detailed information about a single statement.
#
# Without the FOR QUERY n clause, the output pertains to the most recently
# executed statement.
#
# If FOR QUERY n is included, SHOW_PROFILE displays information for statement n.
#
# The values of n correspond to the Query_ID values displayed by SHOW_PROFILES.
#
# The LIMIT row_count clause may be given to limit the output to row_count rows.
#
# If LIMIT is given, OFFSET offset may be added to begin the output offset rows
# into the full set of rows.
#
# By default, SHOW_PROFILE displays Status and Duration columns.
#
# The Status values are like the State values displayed by SHOW_PROCESSLIST,
# although there might be some minor differences in interpretation for the two
# statements for some status values (see SECTION 8.14, "EXAMINING THREAD INFORMATION")
#
# Optional type values may be specified to display specific additional types of information:
#
# 		) ALL displays all information
#
# 		) BLOCK IO displays counts for block input and output operations
#
# 		) CONTEXT SWITCHES displays counts for voluntary and involuntary context switches
#
# 		) CPU displays user and system CPU usage times
#
# 		) IPC displays counts for messages sent and received
#
# 		) MEMORY is not currently implemented
#
# 		) PAGE FAULTS displays counts for major and minor page faults
#
# 		) SOURCE displays the names of functions from the source code, together with the name
# 			and line number of the file in which the function occurs
#
# 		) SWAPS displays swap counts
#
# Profiling is enabled per session.
#
# When a session ends, its profiling information is lost.
#
# SELECT @@profiling;
# +-----------------------+
# | @@profiling 			  |
# +-----------------------+
# | 			0 				  |
# +-----------------------+
# 1 row in set (0.00 sec)
#
# SET profiling = 1;
# Query OK, 0 rows affected (0.00 sec)
#
# DROP TABLE IF EXISTS t1;
# Query OK, 0 rows affected, 1 warning (0.00 sec)
#
# CREATE TABLE T1 (id INT);
# Query OK, 0 rows affected (0.01 sec)
#
# SHOW PROFILES;
# +-----------+-------------+-----------------------------------+
# | Query_ID  | Duration 	 | Query 									 |
# +-----------+-------------+-----------------------------------+
# | 0 		  | 0.000088    | SET PROFILING = 1 					 |
# | 1 		  | 0.000136    | DROP TABLE IF EXISTS t1 			 |
# | 2 		  | 0.011947    | CREATE TABLE t1 (id INT) 			 |
# +-----------+-------------+-----------------------------------+
# 3 rows in set (0.00 sec)
#
# SHOW PROFILE;
# +------------------------------+---------------+
# | Status 								| Duration 		 |
# +------------------------------+---------------+
# | checking permissions 			| 0.000040 		 |
# | creating table 					| etc. 			 |
# | After create 						| etc. 			 |
# | query end 							| 0.000375 		 |
# | freeing items 				   | 0.000089 		 |
# | logging slow query 				| 0.000019 		 |
# | cleaning up 						| 0.000005 		 |
# +------------------------------+---------------+
# 7 rows in set (0.00 sec)
#
# SHOW PROFILE FOR QUERY 1;
# +--------------------------+----------------+
# | Status 						  | Duration 		 |
# +--------------------------+----------------+
# | query end  				  | 0.000107 		 |
# | freeing items 			  | 0.000008 		 |
# | logging slow query 		  | 0.000015 		 |
# | cleaning up 				  | 0.000006 		 |
# +--------------------------+----------------+
# 4 rows in set (0.00 sec)
#
# SHOW PROFILE CPU FOR QUERY 2;
# +--------------------------+----------------+-------------+-----------------+
# | Status 						  | 	Duration 	 | CPU_user 	| CPU_system 		|
# +--------------------------+----------------+-------------+-----------------+
# | checking permissions 	  | 0.000040 		 | 0.000038 	| 0.000002 			|
# | creating table 			  | 0.000056 		 | 0.000028 	| 0.000028 			|
# | After create 				  | 0.011363 		 | 0.000217 	| 0.001571 			|
# | query end 					  | 0.000375 		 | 0.000013 	| 0.000028 			|
# | freeing items 			  | 0.000089 		 | 0.000010 	| 0.000014 			|
# | logging slow query 		  | 0.000019 		 | 0.000009 	| 0.000010 			|
# | cleaning up 				  | 0.000005 		 | 0.000003 	| 0.000002 			|
# +--------------------------+----------------+-------------+-----------------+
# 7 rows in set (0.00 sec)
#
# NOTE:
#
# 		Profiling is only partially functional on some architechtures.
#
# 		For values that depend on the getrusage() system call, NULL is returned
# 		on systems such as Windows that do not support the call.
#
# 		In addition, profiling is per process and not per thread.
#
# 		This means that activity on threads within the server other than your
# 		own may affect the timing information that you see
#
# Profiling information is also available from the INFORMATION_SCHEMA
# PROFILING table.
#
# See SECTION 25.19, "THE INFORMATION_SCHEMA PROFILING TABLE"
#
# For example, the following queries are equivalent:
#
# 		SHOW PROFILE FOR QUERY 2;
#
# 		SELECT STATE, FORMAT(DURATION, 6) AS DURATION
# 		FROM INFORMATION_SCHEMA.PROFILING
# 		WHERE QUERY_ID = 2 ORDER BY SEQ;
#
# 13.7.6.31 SHOW PROFILES SYNTAX
#
# 		SHOW PROFILES
#
# the SHOW_PROFILES statement, together with SHOW_PROFILE, displays
# profiling information that indicates resource usage for statements executed
# during the course of the current session.
#
# For more information, see SECTION 13.7.6.30, "SHOW PROFILE SYNTAX"
#
# NOTE:
#
# 		The SHOW_PROFILE and SHOW_PROFILES statements are deprecated and will be
# 		removed in a future MySQL release.
#
# 		Use the Performance Schema instead; see SECTION 26.19.1, "QUERY PROFILING USING PERFORMANCE SCHEMA"
#
# 13.7.6.32 SHOW RELAYLOG EVENTS SYNTAX
#
# 		SHOW RELAYLOG EVENTS
# 			[IN 'log_name']
# 			[FROM pos]
# 			[LIMIT [offset,] row_count]
# 			[channel_option]
#
# 		channel_option:
# 			FOR CHANNEL channel
#
# Shows the events in the relay log of a replication slave.
#
# If you do not specify 'log_name', the first relay log is displayed.
#
# This statement has no effect on the master.
#
# The LIMIT clause has the same syntax as for the SELECT statement.
# See SECTION 13.2.10, "SELECT SYNTAX"
#
# NOTE:
#
# 		Issuing a SHOW_RELAYLOG_EVENTS with no LIMIT clause could start
# 		a very time- and resource-consuming process because the server returns
# 		to the client the complete contents of the relay log
#
# 		(including all statements modifying data that have been received by the slave)
#
# The optional FOR CHANNEL channel clause enables you to name which replication channel
# the statement applies to.
#
# Providing a FOR CHANNEL channel clause applies the statement to a specific replication
# channel.
#
# If no channel is named and no extra channels exist, the statement applies to the default channel.
#
# When using multiple replication channels, if a SHOW_RELAYLOG_EVENTS statement does not have
# a channel defined using a FOR CHANNEL channel clause an error is generated.
#
# See SECTION 17.2.3, "REPLICATION CHANNELS" for more information
#
# SHOW_RELAYLOG_EVENTS displays the following fields for each event in the relay log:
#
# 		) Log_name
#
# 			the name of the file that is being listed
#
# 		) Pos
#
# 			The position at which the event occurs
#
# 		) Event_type
#
# 			An identifier that describes the event type
#
# 		) Server_id
#
# 			The server ID of hte server on which the event originated
#
# 		) End_log_pos
#
# 			The value of End_log_pos for htis event in the master's binary log
#
# 		) Info
#
# 			More detailed information about the event type.
#
# 			The format of this information depends on the event type.
#
# NOTE:
#
# 		Some events relating to the setting of user and system variables are not included
# 		in the output from SHOW_RELAYLOG_EVENTS
#
# 		To get complete coverage of events within a relay log, use mysqlbinlog
#
# 13.7.6.33 SHOW SLAVE HOSTS SYNTAX
#
# 		SHOW SLAVE HOSTS
#
# Displaying a list of replication slaves currently registered with the master
#
# SHOW SLAVE HOSTS should be executed on a server that acts as a replication master.
#
# The statement displays information about servers that are or have been connected
# as replication slaves, with each row of the result corresponding to one slave server,
# as shown here:
#
# 		SHOW SLAVE HOSTS;
# 		+------------+-------------+-------+---------------+------------------------------+
# 		| Server_id  | Host 			| Port  | Master_id 		| Slave_UUID 						 |
# 		+------------+-------------+-------+---------------+------------------------------+
# 		| <id> 	    | iconnect2 	| 3306  | <id> 			| <serial> 							 |
# 		| <id> 		 | athena 		| 3306  | <id> 			| <serial> 							 |
# 		+------------+-------------+-------+---------------+------------------------------+
#
# 		) Server_id: The unique server ID of the slave server, as configured in the slave server's
# 			option file, or on the command line with --server-id=value
#
# 		) Host: The host name of the slave server as specified on the slave with the --report-host
# 			option.
#
# 			THis can differ from the machine name as configured in the operating system
#
# 		) User: The slave server uses name as, specified on the slave with the --report-user option
#
# 			Statement output includes this column only if the master server is started with the
# 			--show-slave-auth-info option
#
# 		) Password: The slave server password as, specified on the slave with --report-password option
#
# 			Statement output includes this column only if the master server is started with the
# 			--show-slave-auth-info option
#
# 		) Port: The port on the master to which the slave server is listening, as specified
# 			on the slave with the --report-port option
#
# 			A zero in this column means that the slave port (--report-port) was not set
#
# 		) Master_id: The unique server ID of the master server that the slave server is
# 			replicating from.
#
# 			This is the server ID of the server on which SHOW SLAVE HOSTS is executed,
# 			so this same value is listed for each row in the result.
#
# 		) Slave_UUID: The globally unique Id of this slave, as generated on the slave
# 			and found in the slave's auto.cnf file
#
# 13.7.6.34 SHOW SLAVE STATUS SYNTAX
#
# 		SHOW SLAVE STATUS [FOR CHANNEL channel]
#
# This statement provides status information on essential parameters of the slave threads.
#
# It requires either the SUPER or REPLICATION_CLIENT privilege.
#
# SHOW SLAVE STATUS is nonblocking.
#
# When run concurrently with STOP_SLAVE, SHOW SLAVE STATUS returns without waiting for
# STOP SLAVE to finish shutting down the slave SQL thread or slave I/O thread (or both)
#
# This permits use in monitoring and other applications where getting an immediate
# response from SHOW SLAVE STATUS more important than ensuring that it returned
# the latest data.
#
# If you issue this statement using the mysql client, you can use a \G statement terminator
# rather than a semicolon to obtain a more readable vertical layout:
#
# 		SHOW SLAVE STATUS\G
# 		******************************** 1. row ***********************************
# 								Slave_IO_State: Waiting for master to send event
# 								 Master_Host  : localhost
# 								   Master_User: repl
# 								   Master_Port: 13000
# 								 Connect_Retry: 60
# 							  Master_Log_File: master-bin.000002
# 						 Read_Master_Log_Pos: 1307
# 								Relay_Log_File: slave-relay-bin.000003
# 								 Relay_Log_Pos: 1508
# 					  Relay_Master_Log_File: master-bin.000002
# 						Slave_IO_Running    : Yes
# 							SLave_SQL_Running: Yes
# 							  Replicate_Do_DB: 
# 						Replicate_Ignore_DB : 
# 						  Replicate_Do_Table:
# 					 Replicate_Ignore_Table: 		
#  				Replicate_Wild_Do_Table: 
# 			  Replicate_Wild_Ignore_Table:
# 								Last_Errno    : 0
# 									Last_Error : 
# 								Skip_Counter  : 0
# 						Exec_Master_Log_Pos : 1307
# 							Relay_Log_Space  : 1858
# 							Until_Condition  : None
# 							 Until_Log_File  : 
# 							   Until_Log_Pos : 0
# 						Master_SSL_Allowed  : No
# 						Master_SSL_CA_File  : 
# 						Master_SSL_CA_Path  :
# 							Master_SSL_Cert  :
# 						Master_SSL_Cipher   : 
# 					Seconds_Behind_Master  : 0
# 			Master_SSL_Verify_Server_Cert: No
# 						Last_IO_Errno 		  : 0
# 						Last_IO_Error 		  :
# 						Last_SQL_Errno 	  : 0
# 						Last_SQL_Error 	  : 
# 			Replicate_Ignore_Server_Ids  : 
# 					Master_Server_Id  	  : 1
# 							Master_UUID 	  : <serial>
# 					Master_Info_File 		  : /var/mysqld.2/data/master.info
# 								SQL_Delay 	  : 0
# 					SQL_Remaining_Delay 	  : NULL
# 					Slave_SQL_Running_State: Reading event from the relay log
# 						Master_Retry_Count  : 10
# 						Master_Bind 		  : 
# 					Last_IO_Error_Timestamp:
# 				 Last_SQL_Error_Timestamp : 
# 						Master_SSL_Crl 	  : 
# 						Master_SSL_Crlpath  :
# 						Retrieved_Gtid_Set  : <serial>
# 						Executed_Gtid_Set   : <serial>
# 							Auto_Position    : 1
# 						Replicate_Rewrite_DB:
# 							Channel_name 	  :
# 						Master_TLS_Version  : TLSv1.2
# 					Master_public_key_path : public_key.pem
# 					  Get_master_public_key: 0
#
# The Performance Schema provides tables that expose replication information.
#
# This is similar to the information available from the SHOW_SLAVE_STATUS statement,
# but represented in table form.
#
# For details, see SECTION 26.12.11, "PERFORMANCE SCHEMA REPLICATION TABLES"
#
# The following list describes the fields returned by SHOW_SLAVE_STATUS
#
# For additional information about interpreting their meanings, see SECTION 17.1.7.1,
# "CHECKING REPLICATION STATUS"
#
# 		) Slave_IO_State
#
# 			A copy of the State field of the SHOW_PROCESSLIST output for the slave I/O thread.
#
# 			This tells you what the thread is doing: trying to connect to the master, waiting
# 			for events from the master, reconnecting to the master, and so on.
#
# 			For a listing of possible states, see SECTION 8.14.4, "REPLICATION SLAVE Ì/O THREAD STATES"
#
# 		) Master_Host
#
# 			The master host that the slave is connected to
#
# 		) Master_User
#
# 			The user name of the account used to connect to the master
#
# 		) Master_Port
#
# 			The port used to connect to the master
#
# 		) Connect_Retry
#
# 			The number of seconds between connect retries (default 60)
#
# 			This can be set with the CHANGE_MASTER_TO statement
#
# 		) Master_Log_File
#
# 			The name of the master binary log file from which the I/O thread is currently reading
#
# 		) Read_Master_Log_Pos
#
# 			The position in the current master binary log file up to which the I/O thread has read
#
# 		) Relay_Log_File
#
# 			The name of the relay log file from which the SQL thread is currently reading and executing
#
# 		) Relay_Log_Pos
#
# 			The position in the current relay log file up to which the SQL thread has read and executed.
#
# 		) Relay_Master_Log_File
#
# 			The name of the master binary log file containing the most recent event executed by the SQL thread
#
# 		) Slave_IO_Running
#
# 			Whether the I/O thread is started and has connected successfully to the master.
#
# 			Internally, the state of this thread is represented by one of the following three values:
#
# 				) MYSQL_SLAVE_NOT_RUN. The slave I/O thread is not running. For this state, Slave_IO_Running is No
#
# 				) MYSQL_SLAVE_RUN_NOT_CONNECT. The slave I/O thread is running, but is not connected to a replication master.
# 
# 					For this state, Slave_IO_Running is Connecting
#
# 				) MYSQL_SLAVE_RUN_CONNECT.
#
# 					The slave I/O thread is running, and is connected to a replication master.
#
# 					For this state, Slave_IO_Running is Yes
#
# 			The value of the Slave_running system status variable corresponds with this value
#
# 		) Slave_SQL_Running
#
# 			Whether the SQL thread is started
#
# 		) Replicate_Do_DB, Replicate_Ignore_DB
#
# 			The names of any databases that were specified with the --replicate-do-db and
# 			--replicate-ignore-db options, or the CHANGE_REPLICATION_FILTER statement.
#
# 			If the FOR CHANNEL clause was used, the channel specific replication filters are shown.
#
# 			Otherwise, the replication filters for every replication channel are shown.
#
# 		) Replicate_Do_Table, Replicate_Ignore_Table, Replicate_Wild_Do_Table, Replicate_Wild_Ignore_Table
#
# 			The names of any tables that were specified with the --replicate-do-table, --replicate-ignore-table,
# 			--replicate-wild-do-table and --replicate-wild-ignore-table options, or the CHANGE_REPLICATION_FILTER
# 			statement.
#
# 			If the FOR CHANNEL clause was used, the channel specific replication filters are shown.
#
# 			Otherwise, the replication filters for every replication channel are shown.
#
# 		) Last_Errno, Last_Error
#
# 			These columns are aliases for Last_SQL_Errno and Last_SQL_Error
#
# 			Issuing RESET_MASTER or RESET_SLAVE resets the values shown in these columns.
#
# 			NOTE:
#
#				When the slave SQL thread receives an error, it reports the error first, then
# 				stops the SQL thread.
#
# 				This means that there is a small window of time during which SHOW_SLAVE_STATUS
# 				shows a nonzero value for Last_SQL_Errno even though Slave_SQL_Running still displays Yes.
#
# 		) Skip_Counter
#
# 			The current value of the sql_slave_skip_counter system variable.
#
# 			See SECTION 13.4.2.5, "SET GLOBAL SQL_SLAVE_SKIP_COUNTER SYNTAX"
#
# 		) Exec_Master_Log_Pos
#
# 			The position in the current master binary log file to which the SQL thread has read
# 			and executed, marking the start of the next transaction or event to be processed.
#
# 			You can use this value with the CHANGE_MASTER_TO statement's MASTER_LOG_POS option
# 			when starting a new slave from an existing slave, so that the new slave reads
# 			from this point.
#
# 			The coordinates given by (Relay_Master_Log_File, Exec_Master_Log_Pos) in the
# 			master's binary log correspond to the coordinates given by (Relay_Log_File, Relay_Log_Pos)
# 			in the relay log.
#
# 			Inconsistencies in the sequence of transactions from the relay log which have been 
# 			executed can cause this value to be a "low-water mark".
#
# 			In other words, transactions appearing before the position are guaranteed to have committed,
# 			but transactions after the position may have committed or not.
#
# 			If these gaps need to be corrected, use START_SLAVE_UNTIL_SQL_AFTER_MTS_GAPS
#
# 			See SECTION 17.4.1.34, "REPLICATION AND TRANSACTION INCONSISTENCIES" for more information
#
# 		) Relay_Log_Space
#
# 			The total combined size of all existing relay log files
#
# 		) Until_Condition, Until_Log_File, Until_Log_Pos
#
# 			The values specified in the UNTIL clause of the START_SLAVE statement.
#
# 			Until_Condition has these values:
#
# 				) None if no UNTIL clause was specified
#
# 				) Master if the slave is reading until a given position in the master's binary log
#
# 				) Relay if the slave is reading until a given position in its relay log
#
# 				) SQL_BEFORE_GTIDS if the slave SQL thread is processing transactions until it has reached
# 					the first transaction whose GTID is listed in the gtid_set
#
# 				) SQL_AFTER_GTIDS if the slave threads are processing all transactions until the last transaction
# 					in the gtid_set has been processed by both threads.
#
# 				) SQL_AFTER_MTS_GAPS if a multithreaded slave's SQL threads are running until no more gaps are found in the relay log
#
# 			Until_Log_File and Until_Log_Pos indicate the log file name and position that define the coordinates
# 			at which the SQL thread stops executing.
#
# 			For more information on UNTIL clauses, see SECTION 13.4.2.6, "START SLAVE SYNTAX"
#
# 		) Master_SSL_Allowed, Master_SSL_CA_File, Master_SSL_CA_Path, Master_SSL_Cert, Master_SSL_Cipher,
# 			Master_SSL_CRL_File, Master_SSL_CRL_Path, Master_SSL_Key, Master_SSL_Verify_Server_Cert
#
# 			These fields show the SSL parameters used by the slave to connect to the master, if any.
#
# 			Master_SSL_Allowed has these values:
#
# 				) Yes if an SSL connection to the master is permitted
#
# 				) No if an SSL connection to the master is not permitted
#
# 				) Ignored if an SSL connection is permitted but the slave server does not have SSL support enabled
#
# 			The values of the other SSL-related fields correspond to the values of the MASTER_SSL_CA,
# 			MASTER_SSL_CAPATH, MASTER_SSL_CERT, MASTER_SSL_CIPHER, MASTER_SSL_CRL, MASTER_SSL_CRLPATH,
# 			MASTER_SSL_KEY and MASTER_SSL_VERIFY_SERVER_CERT options to the CHANGE_MASTER_TO statement.
#
# 			See SECTION 13.4.2.1, "CHANGE MASTER TO SYNTAX"
#
# 		) Seconds_Behind_Master
#
# 			This field is an indication of how "late" the slave is:
#
# 				) When the slave is actively processing updates, this field shows the difference between the
# 					current timestamp on the slave and the original timestamp logged on the master for the
# 					event currently being processed on the slave.
#
# 				) When no event is currently being processed on the slave, this value is 0
#
# 			In essence, this field measures the time difference in seconds between the slave SQL thread
# 			and the slave I/O thread.
#
# 			If the network connection between master and slave is fast, the slave I/O thread is very close
# 			to the master, so this field is a good approximation of how late the slave SQL thread is compared
# 			to the master.
#
# 			If the network is slow, this is not a good approximation; the slave SQL thread may quite often
# 			be caught up with the slow-reading slave I/O thread, so Seconds_Behind_Master often shows
# 			a value of 0, even if the I/O thread is late compared to the master.
#
# 			In other words, this column is useful only for fast networks.
#
# 			This time difference computation works even if the master and slave do not have identical
# 			clock times, provided that the difference, computed when the slave I/O thread strats,
# 			remains constant from then on.
#
# 			Any changes - including NTP updates - can lead to clock skews that can make calculation
# 			of Seconds_Behind_Master less reliable.
#
# 			In MySQL 8.0, this field is NULL (undefined or unknown) if the slave SQL thread is not running,
# 			or if the SQL thread has consumed all of the relay log and the slave I/O thread is not running.
#
# 			(In older versions of MySQL, this field was NULL if the slave SQL thread or the slave I/O thread
# 			was not running or was not connected to the master)
#
# 			If the I/O thread is running but the relay log is exhausted, Seconds_Behind_Master is set to 0
#
# 			The value of Seconds_Behind_Master is based on the timestamps stored in events, which are preserved
# 			through replication.
#
# 			This means that if a master M1 is itself a slave of M0, any event from M1's binary log that originates
# 			from M0's binary log has M0's timestamp for that event.
#
# 			This enables MySQL to replicate TIMESTAMP successfully.
#
# 			However, the problem for Seconds_Behind_Master is that if M1 also receives direct
# 			updates from clients, the Seconds_Behind_Master value randomly fluctuates because
# 			sometimes the last event from M1 originates from M0 and sometimes is the result
# 			of a direct update on M1.
#
# 			When using a multithreaded slave, you should keep in mind that this value is based on
# 			Exec_Master_Log_Pos, and so may not reflect the position of the most recently
# 			committed transaction.
#
# 		) Last_IO_Errno, Last_IO_Error
#
# 			The error number and error message of the most recent error that caused the I/O
# 			thread to stop.
#
# 			An error number of 0 and message of the empty string mean "no error"
#
# 			If the Last_IO_Error value is not empty, the error values also appear in the
# 			slave's error log.
#
# 			I/O error information includes a timestamp showing when the most recent I/O
# 			thread error occurred.
#
# 			This timestamp uses the format YYMMDD HH:MM:SS, and appears in the Last_IO_Error_Timestamp
# 			column.
#
# 			Issuing RESET_MASTER or RESET_SLAVE resets the values shown in these columns.
#
# 		) Last_SQL_Errno, Last_SQL_Error
#
# 			The error number and error message of the most recent error that caused the SQL thread
# 			to stop.
#
# 			An error number of 0 and message of the empty string mean "no error"
#
# 			If the Last_SQL_Error value is not empty, the error values also appear in the
# 			slave's error log.
#
# 			If the slave is multithreaded, the SQL thread is the coordinator for worker threads.
#
# 			In this case, the Last_SQL_Error field shows exactly what the Last_Error_Message
# 			column in the Performance Schema replication_applier_status_by_coordinator table shows.
#
# 			The field value is modified to suggest that there may be more failures in the other
# 			worker threads which can be seen in the replication_applier_status_by_worker table that
# 			shows each worker thread's status.
#
# 			If that table is not available, the slave error log can be used.
#
# 			The log or the replication_applier_status_by_worker table should also be used
# 			to learn more about the failure shown by SHOW_SLAVE_STATUS or the coordinator table.
#
# 			SQL error information includes a timestamp showing when the most recent SQL thread error occurred.
#
# 			This timestamp uses the format YYMMDD HH:MM:SS, and appears in the Last_SQL_Error_Timestamp column
#
# 			Issuing RESET_MASTER or RESET_SLAVE resets the values shown in these columns.
#
# 			In MySQL 8.0, all error codes and messages displayed in the Last_SQL_Errno and Last_SQL_Error
# 			columns correspond to error values listed in SECTION B.3, "SERVER ERROR MESSAGE REFERENCE"
#
# 			This was not always true in previous versions. (Bug #11760365, Bug #52768)
#
# 		) Replicate_Ignore_Server_Ids
#
# 			Any server IDs that have been specified using the IGNORE_SERVER_IDS option of the
# 			CHANGE_MASTER_TO statement, so that the slave ignores events from these servers.
#
# 			This option is used in a circular or other multi-master replication setup when
# 			one of the servers is removed.
#
# 			If any server IDs have been set in this way, a comma-delimited list of one
# 			or more numbers is shown. If no server IDs have been set, the field is blank.
#
# 			NOTE:
#
# 				The Ignored_server_ids value in the slave_master_info table also shows the
# 				server IDs to be ignored, but as a space-delimited list, preceded by the total
# 				number of server IDs to be ignored.
#
# 				For example, if a CHANGE_MASTER_TO statement containing the IGNORE_SERVER_IDS = (2,6,9)
# 				option has been issued to tell a slave to ignore masters having the server ID
# 				2, 6 or 9, that information appears as shown here:
#
# 					Replicate_Ignore_Server_Ids: 2, 6, 9
# 
# 					Ignored_server_ids: 3, 2, 6, 9
#
# 			Replicate_Ignore_Server_Ids filtering is performed by the I/O thread, rather than by the
# 			SQL thread, which means that events which are filtered out are not written to the relay log.
#
# 			This differs from the filtering actions taken by server options such --replicate-do-table,
# 			which apply to the SQL thread.
#
# 			NOTE:
#
# 				From MySQL 8.0.3, a deprecation warning is issued if SET GTID_MODE=ON is issued
# 				when any channel has existing server IDs set with IGNORE_SERVER_IDS.
#
# 				Before starting GTID-based replication, use SHOW_SLAVE_STATUS to check
# 				for and clear all ignored server ID lists on the servers involved.
#
# 				You can clear a list by issuing a CHANGE_MASTER_TO statement containing
# 				the IGNORE_SERVER_IDS option with an empty list.
#
# 		) Master_Server_Id
#
# 			The server_id value from the master.
#
# 		) Master_UUID
#
# 			THe server_uuid value from the master
#
# 		) Master_Info_File
#
# 			The location of the master.info file, if a file rather than a table is used for
# 			the slave's master info repository
#
# 		) SQL_Delay
#
# 			The number of seconds that the slave must lag the master
#
# 		) SQL_Remaining_Delay
#
# 			When Slave_SQL_Running_State is Waiting until MASTER_DELAY seconds after master
# 			executed event, this field contains the number of delay seconds remaining.
#
# 			At other times, this field is NULL
#
# 		) Slave_SQL_Running_State
#
# 			The state of the SQL thread (analogous to Slave_IO_State)
#
# 			The value is identical to the State value of the SQL thread as displayed
# 			by SHOW_PROCESSLIST.
#
# 			SECTION 8.14.5, "REPLICATION SLAVE SQL THREAD STATES", provides a listing
# 			of possible states
#
# 		) Master_Retry_Count
#
# 			The number of times the slave can attempt to reconnect to the master in the event
# 			of a lost connection.
#
# 			This value can be set using the MASTER_RETRY_COUNT option of the
# 			CHANGE_MASTER_TO statement (preferred) or the older --master-retry-count server
# 			option (still supported for backward compatibility)
#
# 		) Master_Bind
#
# 			The network interface that the slave is bound to, if any.
#
# 			This is set using the MASTER_BIND option for the CHANGE_MASTER_TO statement
#
# 		) Last_IO_Error_Timestamp
#
# 			A timestamp in YYMMDD HH:MM:SS format that shows when the most recent I/O error took place
#
# 		) Last_SQL_Error_Timestamp
#
# 			A timestamp in YYMMDD HH:MM:SS format that shows when the last SQL error occurred.
#
# 		) Retrieved_Gtid_Set
#
# 			The set of global transaction IDs corresponding to all transactions received by this slave.
#
# 			Empty if GTIDs are not in use. See GTID Sets for more information.
#
# 			This is the set of all GTIDs that exist or have existed in the relay logs.
#
# 			Each GTID is added as soon as the Gtid_log_event is received.
#
# 			This can cause partially transmitted transactions to have their GTIDs included in the set.
#
# 			When all relay logs are lost due to executing RESET_SLAVE or CHANGE_MASTER_TO, or due
# 			to the effects of the --relay-log-recovery option, the set is cleared.
#
# 			When relay_log_purge = 1, the newest relay log is always kept, and the set is not cleared.
#
# 		) Executed_Gtid_Set
#
# 			The set of global transaction IDs written in the binary log.
#
# 			This is the same as the value for the global gtid_executed system variable
# 			on this server, as well as the value for Executed_Gtid_Set in the output of
# 			SHOW_MASTER_STATUS on this server.
#
# 			Empty if GTIDs are not in use.
#
# 			See GTID SETS for more information.
#
# 		) Auto_Position
#
# 			1 if autopositioning is in use; otherwise 0.
#
# 		) Replicate_Rewrite_DB
#
# 			The Replicate_Rewrite_DB value displays any replication filtering rules that were
# 			specified.
#
# 			For example, if the following replication filter rule was set:
#
# 				CHANGE REPLICATION FILTER REPLICATE_REWRITE_DB=((db1,db2), (db3,db4));
#
# 			the Replicate_Rewrite_DB value displays:
#
# 				Replicate_Rewrite_DB: (db1,db2), (db3,db4)
#
# 			For more information, see SECTION 13.4.2.2, "CHANGE REPLICATION FILTER SYNTAX"
#
# 		) Channel_name
#
# 			The replication channel which is being displayed.
#
# 			There is always a default replication channel, and more replication channels
# 			can be added.
#
# 			See SECTION 17.2.3, "REPLICATION CHANNELS" for more information.
#
#		) Master_TLS_Version
#
# 		 	The TLS version used on the master.
#
# 			For TLS version information, see SECTION 6.4.6, "ENCRYPTED CONNECTION PROTOCOLS AND CIPHERS"
#
# 		) Master_public_key_path
#
# 			The path name to a file containing a slave-side copy of the public key required by the master
# 			for RSA key pair-based password exchange.
#
# 			The file must be in PEM format.
#
# 			This column applies to slaves that authenticate with the sha256_password
# 			or caching_sha2_password authentication plugin.
#
# 			If Master_public_key_path is given and specifies a valid public key file, it takes
# 			precedence over Get_master_public_key
#
# 		) Get_master_public_key
#
# 			Whether to request from the master the public key required for RSA key pair-based
# 			password exchange.
#
# 			This column applies to slaves that authenticate with the caching_sha2_password
# 			authentication plugin.
#
# 			For that plugin, the master does not send the public key unless requested.
#
# 			If Master_public_key_path is given and specifies a valid public key file,
# 			it takes precedence over Get_master_public_key
#
# 13.7.6.35 SHOW STATUS SYNTAX
#
# 		SHOW [GLOBAL | SESSION] STATUS
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_STATUS provided server status information (see SECTION 5.1.10, "SERVER STATUS VARIABLES")
#
# This statement does not require any privilege. It requires only the ability to
# connect to the server.
#
# Status variable information is also available from these sources:
#
# 		) Performance Schema tables. See SECTION 26.12.14, "PERFORMANCE SCHEMA STATUS VARIABLE TABLES"
#
# 		) The mysqladmin extended-status command. See SECTION 4.5.2, "mysqladmin -- CLIENT FOR ADMINISTERING A MYSQL SERVER"
#
# For SHOW_STATUS, a LIKE clause, if present, indicates which variable names to match.
#
# A WHERE clause can be given to select rows using more general conditions, as discussed
# in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# SHOW_STATUS accepts an optional GLOBAL or SESSION variable scope modifier:
#
# 		) With a GLOBAL modifier, the statement displays the global status values.
#
# 			A global status variable may represent status for some aspect of the server
# 			itself (for example, Aborted_connects), or the aggregated status over all
# 			connections to MySQL (for example, Bytes_received and Bytes_sent)
#
# 			If a variable has no global value, the session value is displayed
#
# 		) With a SESSION modifier, the statement displays the status variable values for the
# 			current connection.
#
# 			If a variable has no session value, the global value is displayed.
#
# 			LOCAL is a synonym for SESSION
#
# 		) If no modifier is present, the default is SESSION
#
# The scope for each status variable is listed at SECTION 5.1.10, "SERVER STATUS VARIABLES"
#
# Each invocation of the SHOW_STATUS statement uses an internal temporary table and increments
# the global Created_tmp_tables value.
#
# Partial output is shown here.
#
# The list of names and value may differ for your server.
#
# The meaning of each variable is given in SECTION 5.1.10, "SERVER STATUS VARIABLES"
#
# 		SHOW STATUS;
# 		+---------------------------------------+--------------+
# 		| Variable_name 								 | Value 		 |
# 		+---------------------------------------+--------------+
# 		| Aborted_clients 							 | 0 				 |
# 		| Aborted_connects 							 | 0 				 |
# 		| Bytes_received 								 | 155372598 	 |
# 		| Bytes_sent 									 | 1176560426   |
# 		| Connections 									 | 30023 		 |
# 		| Created_tmp_disk_tables 					 | 0 				 |
# 		| Created_tmp_tables 						 | 8340 			 |
# 		| Created_tmp_files 							 | 60 			 |
# 		---
# 		| Open_tables 									 | 1 				 |
# 		| Open_files 									 | 2 				 |
# 		| Open_streams 								 | 0 				 |
# 		| Opened_tables 								 | 44600 		 |
# 		| Questions 									 | 2026873 		 |
# 		---
# 		| Table_locks_immediate 					 | 1920382 		 |
# 		| Table_locks_waited 						 | 0 				 |
# 		| Threads_cached 								 | 0 				 |
# 		| Threads_created 							 | 30022 		 |
# 		| Threads_connected 							 | 1 				 |
# 		| Threads_running 							 | 1 				 |
# 		| Uptime 										 | 80380 		 |
# 		+---------------------------------------+--------------+
#
# With a LIKE clause, the statement displays only rows for those variables with names
# that match the pattern:
#
# 		SHOW STATUS LIKE 'Key%';
# 		+---------------------+-----------+
# 		| Variable_name 		 | Value 	 |
# 		+---------------------+-----------+
# 		| Key_blocks_used 	 | 14955 	 |
# 		| Key_read_requests   | 96854827  |
# 		| Key_reads 			 | 162040 	 |
# 		| Key_write_requests  | 7589728   |
# 		| Key_writes 			 | 3813196   |
# 		+---------------------+-----------+
#
# 13.7.6.36 SHOW TABLE STATUS SYNTAX
#
# 		SHOW TABLE STATUS
# 			[{FROM | IN} db_name]
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_TABLE_STATUS works likes SHOW_TABLES, but provides a lot of information about each
# non-TEMPORARY table.
#
# You can also get this list using the mysqlshow --status db_name command.
#
# The LIKE clause, if present, indicates which table names to match.
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# This statement also displays information about views.
#
# SHOW_TABLE_STATUS output has these columns:
#
# 		) Name
#
# 			The name of the table
#
# 		) Engine
#
# 			The storage engine for the table.
#
# 			See CHAPTER 15, THE INNODB STORAGE ENGINE, and CHAPTER 16, ALTERNATIVE STORAGE ENGINES
#
# 			For partitioned tables, Engine shows the name of the storage engine used by all partitions
#
# 		) Version
#
# 			This column is unused. With the removal of .frm files in MySQL 8.0, this column now
# 			reports a hardcoded value of 10, which is the last .frm file version used in MySQL
# 			5.7
#
# 		) Row_format
#
# 			The row-storage format (Fixed, Dynamic, Compressed, Redundant, Compact)
#
# 			For MyISAM tables, Dynamic corresponds to what myisamchk -dvv reports as Packed.
#
# 		) Rows
#
# 			The number of rows.
#
# 			Some storage engines, such as MyISAM, store the exact count.
#
# 			For other storage engines, such as InnoDB, this value is an approximation
# 			and may vary from the actual value by as much as 40% to 50%.
#
# 			In such cases, use SELECT COUNT(*) to obtain an accurate count.
#
# 			The Rows value is NULL for INFORMATION_SCHEMA tables.
#
# 			For InnoDB tables, the row count is only a rough estimate used in SQL optimization.
#
# 			(This is also true if the InnoDB table is partitioned)
#
# 		) Avg_row_length
#
# 			The average row length
#
# 		) Data_length
#
# 			For MyISAM, Data_length is the length of the data file, in bytes.
#
# 			For InnoDB, Data_length is the approximate amount of memory allocated
# 			for the clustered index, in bytes.
#
# 			Specifically, it is the clustered index size, in pages, multiplied by
# 			the InnoDB page size.
#
# 			Refer to the notes at the end of this section for information regarding
# 			other storage engines.
#
# 		) Max_data_length
#
# 			For MyISAM, Max_data_length is maximum length of the data file.
#
# 			This is the total number of bytes of data that can be stored in the table,
# 			given the data pointer size used.
#
# 			Unused for InnoDB.
#
# 			Refer to the notes at the end of this section for information regarding other
# 			storage engines.
#
# 		) Index_length
#
# 			For MyISAM, Index_length is the length of the index file, in bytes.
#
# 			For InnoDB, Index_length is the approximate amount of memory allocated for
# 			non-clustered indexes, in bytes.
#
# 			Specifically, it is the sum of non-clustered index sizes, in pages,
# 			multiplied by the InnoDB page size.
#
# 			Refer to the notes at the end of this section for information regarding other
# 			storage engines.
#
# 		) Data_free
#
# 			The number of allocated but unused bytes.
#
# 			InnoDB tables report the free space of the tablespace to which the table belongs.
#
# 			For a table located in the shared tablespace, this is the free space of the shared
# 			tablespace.
#
# 			If you are using multiple tablespaces and the table has its own tablespace,
# 			the free space is for only that table.
#
# 			Free space means the number of bytes in completely free extents minus a safety
# 			margin.
#
# 			Even if free space displays as 0, it may be possible to insert rows as long
# 			as new extents need not be allocated.
#
# 			For NDB Cluster, Data_free shows the space allocated on disk for, but not
# 			used by, a Disk Data table or fragment on disk.
#
# 			(In-memory data resource usage is reported by the Data_length column)
#
# 			For partitioned tables, this value is only an estimate and may not be absolutely
# 			correct.
#
# 			A more accurate model of obtaining this information in such cases is to query
# 			the INFORMATION_SCHEMA PARTITIONS table, as shown in this example:
#
# 				SELECT SUM(DATA_FREE)
# 					FROM INFORMATION_SCHEMA.PARTITIONS
# 					WHERE TABLE_SCHEMA = 'mydb'
# 					AND TABLE_NAME = 'mytable';
#
# 			For more information, see SECTION 25.16, "THE INFORMATION_SCHEMA PARTITIONS TABLE"
#
# 		) Auto_increment
#
# 			The next AUTO_INCREMENT value
#
# 		) Create_time
#
# 			When the table was created.
#
# 		) Update_time
#
# 			When the data file was last updated. For some storage engines, this value is NULL.
#
# 			For example, InnoDB stores multiple tables in its system tablespace and the data
# 			file timestamp does not apply.
#
# 			Even with file-per-table mode with each InnoDB table in a separate .ibd file,
# 			change buffering can delay the write to the data file, so the file modification
# 			time is different from the time of the last insert, update, or delete.
#
# 			For MyISAM, the data file timestamp is used; however, on Windows the timestamp
# 			is not updated by updates, so the value is inaccurate.
#
# 			Update_time displays a timestamp value for the last UPDATE, INSERT, or DELETE
# 			performed on InnoDB tables that are not partitioned.
#
# 			For MVCC, the timestamp value reflects the COMMIT time, which is considered
# 			the last update time.
#
# 			Timestamps are not persisted when the server is restarted or when the table is evicted
# 			from the InnoDB data dictionary cache.
#
# 		) Check_time
#
# 			When the table was last checked. Not all storage engines update this time, in which case,
# 			the value is always NULL
#
# 			For partitioned InnoDB tables, Check_time is always NULL
#
# 		) Collation
#
# 			The table default collation. The output does not explicitly list the table default character
# 			set, but the collation name begins with the character set name
#
# 		) Checksum
#
# 			The live checksum value, if any
#
# 		) Create_options
#
# 			Extra options used with CREATE_TABLE.
#
# 			The original options from when CREATE_TABLE was executed are retained
# 			and the options reported here may differ from the active table settings and options.
#
# 			For InnoDB tables, the actual ROW_FORMAT and KEY_BLOCK_SIZE options are reported.
#
# 			Prior to MySQL 8.0, Create_options reports the originally supplied ROW_FORMAT
# 			and KEY_BLOCK_SIZE.
#
# 			For more information, see SECTION 13.1.20, "CREATE TABLE SYNTAX"
#
# 			Create_options shows partitioned if the table is partitioned.
#
# 			It also shows the ENCRYPTION option specified when creating or altering
# 			a file-per-table tablespace.
#
# 			This column does not show the encryption option specified when creating
# 			or altering a general tablespace.
#
# 			The ENCRYPTION column of the INNODB_TABLESPACES table is applicable
# 			to both file-per-table and general tablespaces.
#
# 		) Comment
#
# 			The comment used when creating the table (or information as to why MySQL could not
# 			access the table information)
#
# NOTES
#
# 		) For NDB tables, the output of this statement shows appropriate values for the Avg_row_length
# 			and Data_length columns, with the exception that BLOB columns are not taken into account.
#
# 		) For NDB tables, Data_length includes data stored in main memory only; the Max_data_length
# 			and Data_free columns apply to Disk Data
#
# 		) For NDB Cluster Disk Data tables, Max_data_length shows the space allocated for the disk part
# 			of a Disk Data table or fragment.
#
# 			(In-memory data resource usage is reported by the Data_length column)
#
# 		) For MEMORY tables, the Data_length, Max_data_length, and Index_length values
# 			approximate the actual amount of allocated memory.
#
# 			The allocation algorithm reserves memory in large amounts to reduce the number
# 			of allocation operations.
#
# 		) For views, most columns displayed by SHOW_TABLE_STATUS are 0 or NULL except
# 			that Name indicates the view name, Create_time indicates the creation time,
# 			and Comment says VIEW.
#
# Table information is also available from the INFORMATION_SCHEMA TABLES table.
#
# See SECTION 25.29, "THE INFORMATION_SCHEMA TABLES TABLE"
#
# 13.7.6.37 SHOW TABLES SYNTAX
#
# 		SHOW [EXTENDED] [FULL] TABLES
# 			[{FROM | IN} db_name]
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_TABLES lists the non-TEMPORARY tables in a given database.
#
# You can also get this list using the mysqlshow db_name command.
#
# The LIKE clause, if present, indicates which table names to match:
#
# The WHERE clause can be given to select rows using more general conditions,
# as discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# Matching performed by the LIKE clause is dependent on the setting of the lower_case_table_names
# system variable.
#
# The optional EXTENDED modifier causes SHOW_TABLES to list hidden tables created by failed
# ALTER_TABLE statements.
#
# These temporary tables have names beginning with #sql and can be dropped using
# DROP_TABLE
#
# This statement also lists any views in the database. The optional FULL modifier
# causes SHOW_TABLES to display a second output column with values of BASE TABLE
# for a table, VIEW for a view, or SYSTEM VIEW for an INFORMATION_SCHEMA table
#
# If you have no privileges for a base table or view, it does not show up in the
# output from SHOW_TABLES or mysqlshow db_name
#
# Table information is also available from the INFORMATION_SCHEMA TABLES table.
#
# See SECTION 25.29, "THE INFORMATION_SCHEMA TABLES TABLE"
#
# 13.7.6.38 SHOW TRIGGERS SYNTAX
#
# 		SHOW TRIGGERS
# 			[{FROM | IN} db_name]
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_TRIGGERS lists the triggers currently defined for tables in a database
# (The default database unless a FROM clause is given)
#
# This statement returns results only for databases and tables for which you have
# the TRIGGER privilege.
#
# The LIKE clause, if present, indicates which table names (not trigger names)
# to match and causes the statement to display triggers for those tables.
#
# The WHERE clause can be given to select rows using more general conditions,
# as dicussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# For the ins_sum trigger defined in SECTION 24.3, "USING TRIGGERS",
# the output of SHOW_TRIGGERS is as shown here:
#
# 		SHOW TRIGGERS LIKE 'acc%'\G
# 		*********************** 1. row ********************************
# 						Trigger: ins_sum
# 						 Event : INSERT
# 					    Table : account
# 					Statement : SET @sum = @sum + NEW.amount
# 						Timing : BEFORE
# 						Created: 2018-08-08 10:10:12.61
# 					sql_mode  : ONLY_FULL_GROUP_BY, STRICT_TRANS_TABLES,
# 									NO_ZERO_IN_DATE, NO_ZERO_DATE,
# 									ERROR_FOR_DIVISION_BY_ZERO,
# 									NO_ENGINE_SUBSTITUTION
# 						Definer: me@localhost
# 	  character_set_client: utf8mb4
# 	  collation_connection: utf8mb4_0900_ai_ci
# 		Database Collation : utf8mb4_0900_ai_ci
#
# SHOW_TRIGGERS output has these columns:
#
# 		) Trigger
#
# 			The name of the trigger
#
# 		) Event
#
# 			The trigger event. This is the type of operation on the associated table for which
# 			the trigger activates.
#
# 			The value is INSERT (a row was inserted), DELETE (a row was deleted), or
# 			UPDATE (a row was modified)
#
# 		) Table
#
# 			The table for which the trigger is defined
#
# 		) Statement
#
# 			The trigger body; that is, the statement executed when the trigger activates.
#
# 		) Timing
#
# 			Whether hte trigger activates before or after the triggering event.
#
# 			The value is BEFORE or AFTER.
#
# 		) Created
#
# 			The date and time when the trigger was created. This is a TIMESTAMP(2) value
# 			(with a fractional part in hundreths of seconds) for triggers.
#
# 		) sql_mode
#
# 			The SQL mode in effect when the trigger was created, and under which the
# 			trigger executes.
#
# 			For the permitted values, see SECTION 5.1.11, "SERVER SQL MODES"
#
# 		) Definer
#
# 			The account of the user who created the trigger, in 'user_name'@'host_name' format
#
# 		) character_set_client
#
# 			The session value of the character_set_client system variable when the trigger was created.
#
# 		) collation_connection
#
# 			The session value of the collation_connection system variable when the trigger was created.
#
# 		) Database Collation
#
# 			The collation of the database with which the trigger is associated
#
# Trigger information is also available from the INFORMATION_SCHEMA TRIGGERS table.
#
# See SECTION 25.33, "THE INFORMATION_SCHEMA TRIGGERS TABLE"
#
# 13.7.6.39 SHOW VARIABLES SYNTAX
#
# 		SHOW [GLOBAL | SESSION] VARIABLES
# 			[LIKE 'pattern' | WHERE expr]
#
# SHOW_VARIABLES shows the values of MySQL system variables (see SECTION 5.1.8, "SERVER SYSTEM VARIABLES")
#
# This statement does not require any privilege. It requires only the ability to connect to the server.
#
# System variable information is also available from these sources:
#
# 		) Performance Schema tables. See SECTION 26.12.13, "PERFORMANCE SCHEMA SYSTEM VARIABLE TABLES"
#
# 		) The mysqladmin variables command. See SECTION 4.5.2, "mysqladmin -- Client for Administering a MySQL Server"
#
# For SHOW_VARIABLES, a LIKE clause, if present, indicates which variable names to match.
#
# A WHERE clause can be given to select rows using more general conditions, as
# discussed in SECTION 25.41, "EXTENSIONS TO SHOW STATEMENTS"
#
# SHOW_VARIABLES accepts an optional GLOBAL or SESSION variable scope modifier:
#
# 		) With a GLOBAL modifier, the statement displays global system variable values.
#
# 			These are the values used to initialize the corresponding session variables
# 			for new connections to MySQL.
#
# 			If a variable has no global value, no value is displayed
#
# 		) With a SESSION modifier, the statement displays the system variable values that are
# 			in effect for the current connection.
#
# 			If a variable has no session value, the global value is displayed.
#
# 			LOCAL is a synonym for SESSION
#
# 		) If no modifier is present, the default is SESSION
#
# The scope for each system variable is listed at SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# SHOW_VARIABLES is subject to a version-dependent display-width limit.
#
# For variables with very long values that are not completely displayed, use SELECT
# as a workaround.
#
# For example:
#
# 		SELECT @@GLOBAL.innodb_data_file_path;
#
# Most system variables can be set at server startup (read-only variables such as
# version_comment are exceptions)
#
# Many can be changed at runtime with the SET statement.
#
# See SECTION 5.1.9, "USING SYSTEM VARIABLES", and SECTION 13.7.5.1, "SET SYNTAX FOR VARIABLE ASSIGNMENT"
#
# Partial output is shown here.
#
# The list of names and values may differ for your server.
#
# SECTION 5.1.8, "SERVER SYSTEM VARIABLES", describes the meaning of each variable,
# and SECTION 5.1.1, "CONFIGURING THE SERVER", provides information about tuning them.
#
# 		SHOW VARIABLES;
# 		+--------------------------------------------+--------------------------+
# 		| Variable_name 							 			| Value 						   |
# 		+--------------------------------------------+--------------------------+
# 		| activate_all_roles_on_login 		 			| OFF 							|
# 		| auto_generate_certs 					 			| ON 							   |
# 		| auto_increment_increment 			 			| 1 								|
# 		| auto_increment_offset 				 			| 1 								|
# 		| autocommit 								 			| ON 							   |
# 		| automatic_sp_privileges 				 			| ON 							   |
# 		| avoid_temporal_upgrade 				 			| OFF 							|
# 		| back_log 									 			| 151 							|
# 		| basedir 									 			| /usr/ 						   |
# 		| big_tables 								 			| OFF 							|
# 		| bind_address 							 			| * 								|
# 		| binlog_cache_size 						 			| 32768 						   |
# 		| binlog_checksum 						 			| CRC32 						   |
# 		| binlog_direct_non_transactional_updates 	| OFF 							|
# 		| binlog_error_action 								| ABORT_SERVER 				|
# 		| binlog_expire_logs_seconds 						| 2592000 						|
# 		| binlog_format 										| ROW 							|
# 		| binlog_group_commit_sync_delay 				| 0 								|
# 		| binlog_group_commit_sync_no_delay_count 	| 0 								|
# 		| binlog_gtid_simple_recovery 					| ON 								|
# 		| binlog_max_flush_queue_time 					| 0 								|
# 		| binlog_order_commits 								| ON 								|
# 		| binlog_row_image 									| FULL 							|
# 		| binlog_row_metadata 								| MINIMAL 						|
# 		| binlog_row_value_options 						| 									|
# 		| binlog_rows_query_log_events 					| OFF 							|
# 		| binlog_stmt_cache_size 							| 32768 							|
# 		| binlog_transaction_dependency_history_size | 25000 							|
# 		| binlog_transaction_dependency_tracking 	   | COMMIT_ORDER 				|
# 		| block_encryption_mode 							| aes-128-ecb 					|
# 		| bulk_insert_buffer_size 							| 8388608 						|
# 		---
# 		---
# 		---
# 		| max_allowed_packet 								| 67108864 						|
# 		| max_binlog_cache_size 							| 18446744073709547520 		|
# 		| max_binlog_size 									| 1073741824 					|
# 		| max_binlog_stmt_cache_size 						| 1844674073709547520 		|
# 		| max_connect_errors 								| 100 							|
# 		| max_connections 									| 151 							|
# 		| max_delayed_threads 								| 20 								|
# 		| max_digest_length 									| 1024 							|
# 		| max_error_count 									| 1024 							|
# 		| max_execution_time 								| 0 								|
# 		| max_heap_table_size 								| 16777216 						|
# 		| max_insert_delayed_threads 						| 20 								|
# 		| max_join_size 										| 18446744073709551615 		|
# 		---
# 		---
# 		---
# 		| thread_handling 									| one-thread-per-connection|
# 		| thread_stack 										| 286720 						|
# 		| time_zone 											| SYSTEM 						|
# 		| timestamp 											| 1530906638.765316 			|
# 		| tls_version 											| TLSv1, TLSv1.1,TLSv1.2   |
# 		| tmp_table_size 										| 16777216 						|
# 		| tmpdir 												| /tmp 							|
# 		| transaction_alloc_block_size 					| 8192 							|
# 		| transaction_allow_batching 						| OFF 							|
# 		| transaction_isolation 							| REPEATABLE-READ 			|
# 		| transaction_prealloc_size 						| 4096 							|
# 		| transaction_read_only 							| OFF 							|
# 		| transaction_write_set_extraction 			 	| XXHASH64 						|
# 		| unique_checks 										| ON 								|
# 		| updatable_views_with_limit 						| YES 							|
# 		| version 												| 8.0.12 						|
# 		| version_comment 									| MySQL Community Server - GPL |
# 		| version_compile_machine 							| x86_64 						|
# 		| version_compile_os 								| Linux 							|
# 		| version_compile_zlib 								| 1.2.11 						|
# 		| wait_timeout 										| 28800 							|
# 		| warning_count 										| 0 								|
# 		| windowing_use_high_precision 					| ON 								|
# 		+--------------------------------------------+--------------------------+
#
# With a LIKE clause, the statement displays only rows for those variables with names that
# match the pattern.
#
# To obtain the row for a specific variable, use a LIKE clause as shown:
#
# 		SHOW VARIABLES LIKE 'max_join_size';
# 		SHOW SESSION VARIABLES LIKE 'max_join_size';
#
# To get a list of variables whose name match a pattern, use the % wildcard character
# in a LIKE clause:
#
# 		SHOW VARIABLES LIKE '%size%';
# 		SHOW GLOBAL VARIABLES LIKE '%size%';
#
# Wildcard characters can be used in any position within the pattern to be matched.
#
# Strictly speaking, because _ is a wildcard that matches any single character,
# you should escape it as \_ to match it literally.
#
# In practice, this is rarely necessary.
#
# 13.7.6.40 SHOW WARNINGS SYNTAX
#
# 		SHOW WARNINGS [LIMIT [offset,] row_count]
# 		SHOW COUNT(*) WARNINGS
#
# SHOW_WARNINGS is a diagnostic statement that displays information about the conditions
# (errors, warnings and notes) resulting from executing a statement in the current session.
#
# Warnings are generated for DML statements such as INSERT, UPDATE, and LOAD_DATA_INFILE
# as well as DDL statements such as CREATE_TABLE and ALTER_TABLE
#
# The LIMIT clause has the same syntax as for the SELECT statement. See SECTION 13.2.10, "SELECT SYNTAX"
#
# SHOW_WARNINGS is also used following EXPLAIN, to display the extended information generated
# by EXPLAIN.
#
# See SECTION 8.8.3, "EXTENDED EXPLAIN OUTPUT FORMAT"
#
# SHOW_WARNINGS displays information about the conditions resulting from execution
# of the most recent nondiagnostic statement in the current session.
#
# If the most recent statement resulted in an error during parsing, SHOW_WARNINGS
# shows the resulting conditions, regardless of statement type (diagnostic or nondiagnostic)
#
# The SHOW_COUNT(*)_WARNINGS diagnostic statement displays the total number of errors,
# warnings, and notes.
#
# You can also retrieve this number from the warning_count system variable:
#
# 		SHOW COUNT(*) WARNINGS;
# 		SELECT @@warning_count;
#
# A difference in these statements is that the first is a diagnostic statement that
# does not clear the message list.
#
# The second, because it is a SELECT statement is considered nondiagnostic and does
# clear the message list.
#
# A related diagnostic statement, SHOW_ERRORS, shows only error conditions (it excludes
# warnings and notes), and SHOW_COUNT(*)_ERRORS statement displays the total number
# of errors.
#
# See SECTION 13.7.6.17, "SHOW ERRORS SYNTAX"
#
# GET_DIAGNOSTICS can be used to examine information for individual conditions.
#
# See SECTION 13.6.7.3, "GET DIAGNOSTICS SYNTAX"
#
# Here is a simple example that shows data-conversion warnings for INSERT.
#
# The example assumes that strict SQL mode is disabled. With strict mode
# enabled, the warnings would become errors and terminate the INSERT.
#
# 		CREATE TABLE t1 (a TINYINT NOT NULL, b CHAR(4));
# 		Query OK, 0 rows affected (0.05 sec)
#
# 		INSERT INTO t1 VALUES(10,'mysql'), (NULL,'test'), (300, 'xyz');
# 		Query OK, 3 rows affected, 3 warnings (0.00 sec)
# 		Records: 3 Duplicates: 0 Warnings: 3
#
# 		SHOW WARNINGS\G
# 		************************ 1. row ******************************
# 			Level: Warning
# 			Code : 1265
# 		Message : Data truncated for column 'b' at row 1
# 		************************ 2. row ******************************
# 			Level: Warning
# 			Code : 1048
# 		Message : Column 'a' cannot be null
# 		************************ 3. row ******************************
# 			Level: Warning
# 			Code : 1264
# 		Message : Out of range value for column 'a' at row 3
# 		3 rows in set (0.00 sec)
#
# The max_error_count system variable controls the maximum number of error, warning,
# and note messages for which the server stores information, and thus the number
# of messages that SHOW_WARNINGS displays.
#
# To change the number of messages the server can store, change the value of max_error_count
#
# max_error_count controls only how many messages are stored, not how many are counted.
#
# The value of warning_count is not limited by max_error_count, even if the number of
# messages generated exceeds max_error_count.
#
# The following example demonstrates this.
#
# The ALTER_TABLE statement produces three warning messages (strict SQL mode is disabled
# for the example to prevent an error from occuring after a single conversion issue).
#
# Only one message is stored and displayed because max_error_count has been set to 1,
# but all three are counted (as shown by the value of warning_count):
#
# 		SHOW VARIABLES LIKE 'max_error_count';
# 		+-----------------+-----------+
# 		| Variable_name   | Value 		|
# 		+-----------------+-----------+
# 		| max_error_count | 1024 		|
# 		+-----------------+-----------+
# 		1 row in set (0.00 sec)
#
# 		SET max_error_count=1, sql_mode = '';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		ALTER TABLE t1 MODIFY b CHAR;
# 		Query OK, 3 rows affected, 3 warnings (0.00 sec)
# 		Records: 3 Duplicates: 0 Warnings: 3
#
# 		SHOW WARNINGS;
# 		+---------+-------+----------------------------------------+
# 		| Level   | Code  | Message 										  |
# 		+---------+-------+----------------------------------------+
# 		| Warning | 1263  | Data truncated for column 'b' at row 1 |
# 		+---------+-------+----------------------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT @@warning_count;
# 		+------------------------+
# 		| @@warning_count 		 |
# 		+------------------------+
# 		| 			3 					 |
# 		+------------------------+
# 		1 row in set (0.01 sec)
#
# To disable message storage, set max_error_count to 0.
#
# In this case, warning_count still indicates how many warnings occurred, but messages
# are not stored and cannot be displayed.
#
# The sql_notes system variable controls whether note messages increment warning_count
# and whether the server stores them.
#
# By default, sql_notes is 1, but if set to 0, notes do not increment warning_count and
# the server does not store them:
#
# 		SET sql_notes = 1;
# 		DROP TABLE IF EXISTS test.no_such_table;
# 		Query OK, 0 rows affected, 1 warning (0.00 sec)
# 		SHOW WARNINGS;
# 		+-------+--------+------------------------------------+
# 		| Level | Code   | Message 							 		|
# 		+-------+--------+------------------------------------+
# 		| Note  | 1051   | Unknown table 'test.no_such_table' |
# 		+-------+--------+------------------------------------+
# 		1 row in set (0.00 sec)
#
# 		SET sql_notes = 0;
# 		DROP TABLE IF EXISTS test.no_such_table;
# 		Query OK, 0 rows affected (0.00 sec)
# 		SHOW WARNINGS;
# 		Empty set (0.00 sec)
#
# The MySQL server sends to each client a count indicating the total number of errors,
# warnings and notes resulting from the most recent statement executed by that client.
#
# From the C API, this value can be obtained by calling mysql_warning_count()
#
# See SECTION 28.7.7.82, "MYSQL_WARNING_COUNT()"
#
# In the mysql client, you can enable and disable automatic warnings display using the
# warnings and nowarning commands, respectively, or their shortcuts, \W and \w
# (see SECTION 4.5.1.2, "MYSQL CLIENT COMMANDS").
#
# For example:
#
# 		\W
# 		Show warnings enabled
# 		SELECT 1/0;
# 		+---------+
# 		| 1/0     |
# 		+---------+
# 		| NULL 	 |
# 		+---------+
# 		1 row in set, 1 warning (0.03 sec)
#
# 		Warning (Code 1365): Division by 0
# 		\w
# 		Show warnings disabled
#
# 13.7.7 OTHER ADMINISTRATIVE STATEMENTS
#
# 13.7.7.1 BINLOG SYNTAX
# 13.7.7.2 CACHE INDEX SYNTAX
#
# 13.7.7.3 FLUSH SYNTAX
# 13.7.7.4 KILL SYNTAX
#
# 13.7.7.5 LOAD INDEX INTO CACHE SYNTAX
# 13.7.7.6 RESET SYNTAX
#
# 13.7.7.7 RESET PERSIST SYNTAX
# 13.7.7.8 RESTART SYNTAX
#
# 13.7.7.9 SHUTDOWN SYNTAX
#
# 13.7.7.1 BINLOG SYNTAX
#
# 		BINLOG 'str'
#
# BINLOG is an internal-use statement. It is generated by the mysqlbinlog program
# as the printable representation of certain events in binary log files.
#
# (See SECTION 4.6.8, "MYSQLBINLOG -- UTILITY FOR PROCESSING BINARY LOG FILES")
#
# The 'str' value is base 64-encoded string that the server decodes to determine
# the data change indicated by the corresponding event.
#
# This statement requires the BINLOG_ADMIN or SUPER privilege.
#
# This statement can execute only format description events and row events.
#
# 13.7.7.2 CACHE INDEX SYNTAX
#
# 		CACHE INDEX
# 			tbl_index_list [, tbl_index_list]
# 			[PARTITION (partition_list | ALL)]
# 			IN key_cache_name
#
# 		tbl_index_list:
# 			tbl_name [[INDEX|KEY] (index_name[, index_name] ---)]
#
# 		partition_list:
# 			partition_name[, partition_name][, ---]
#
# The CACHE_INDEX statement assigns table indexes to a specific key cache.
#
# It is used only for MyISAM tables. After the indexes have been assigned,
# they can be preloaded into the cache if desired with LOAD_INDEX_INTO_CACHE
#
# The following statement assigns indexes from the tables t1, t2, and t3 to the
# key cache named hot_cache:
#
# 		CACHE INDEX t1, t2, t3 IN hot_cache;
# 		+----------+------------------------+----------+------------+
# 		| Table 	  | Op 							| Msg_type | Msg_text 	|
# 		+----------+------------------------+----------+------------+
# 		| test.t1  | assign_to_keycache 		| status   | OK 			|
# 		| test.t2  | assign_to_keycache 		| status   | OK 			|
# 		| test.t3  | assign_to_keycache 		| status   | OK 			|
# 		+----------+------------------------+----------+------------+
#
# The syntax of CACHE_INDEX enables you to specify that only particular indexes from
# a table should be assigned to the cache.
#
# The current implementation assigns all the table's indexes to the cache, so there
# is no reason to specify anything other than the table name.
#
# The key cache referred to in a CACHE_INDEX statement can be created by setting its
# size with a parameter setting statement or in the server parameter settings.
#
# For example:
#
# 		SET GLOBAL keycache1.key_buffer_size=128*1024;
#
# Key cache parameters can be accessed as members of a structured system variable.
# See SECTION 5.1.9.5, "STRUCTURED SYSTEM VARIABLES"
#
# A key cache must exist before you can assign indexes to it:
#
# 		CACHE INDEX t1 IN non_existent_cache;
# 		ERROR 1284 (HY000): Unknown key cache 'non_existent_cache'
#
# By default, table indexes are assigned to the main (default) key cache created at the
# server startup.
#
# When a key cache is destroyed, all indexes assigned to it become assigned to the
# default key cache again.
#
# Index assignment affects the server globally: If one client assigns an index to a given cache,
# This cache is used for all queries involving the index, no matter which client issues
# the queries.
#
# In MySQL 8.0, this statement is also supported for partitioned MyISAM tables.
#
# You can assign one or more indexes for one, several, or all partitions to a given
# key cache.
#
# For example, you can do the following:
#
# 		CREATE TABLE pt (c1 INT, c2 VARCHAR(50), INDEX i(c1))
# 			ENGINE=MyISAM
# 			PARTITION BY HASH(c1)
# 			PARTITIONS 4;
#
# 		SET GLOBAL kc_fast.key_buffer_size = 128 * 1024;
# 		SET GLOBAL kc_slow.key_buffer_size = 128 * 1024;
#
# 		CACHE INDEX pt PARTITION (p0) IN kc_fast;
# 		CACHE INDEX pt PARTITION (p1, p3) IN kc_slow;
#
# The previous set of statements performs the following actions:
#
# 		) Creates a partitioned table with 4 partitions; these partitions are automatically named p0, ---, p3;
# 			This table has an index named i on column c1
#
# 		) Creates 2 key caches named kc_fast and kc_slow
#
# 		) Assigns the index for partition p0 to the kc_fast key cache and the index
# 			for partitions p1 and p3 to the kc_slow key cache;
#
# 			The index for the remaining partition (p2) uses the servers
# 			default key cache
#
# If you wish instead to assign the indexes for all partitions in table pt to a single
# key cache named kc_all, you can use either one of the following 2 statements:
#
# 		CACHE INDEX pt PARTITION (ALL) IN kc_all;
#
# 		CACHE INDEX pt IN kc_all;
#
# The two statements just shown are equivalent, and issuing either one of them
# has exactly the same effect.
#
# In other words, if you wish to assign indexes for all partitions of a partitioned
# table to the same key cache, then the PARTITION (ALL) clause is optional.
#
# When assigning indexes for multiple partitions to a key cache, the partitions
# do not have to be contiguous, and you are not required to list their names
# in any particular order.
#
# Indexes for any partitions that are not explicitly assigned to a key cache automatically
# use the server's default key cache.
#
# In MySQL 8.0, index preloading is also supported for partitioned MyISAM tables.
#
# For more information, see SECTION 13.7.7.5, "LOAD INDEX INTO CACHE SYNTAX"
#
# 13.7.7.3 FLUSH SYNTAX
#
# 		FLUSH [NO_WRITE_TO_BINLOG | LOCAL] {
# 			flush_option [, flush_option] ---
# 		 | tables_option
# 		}
#
# 		flush_option: {
# 			BINARY LOGS
# 		 | ENGINE LOGS
# 		 | ERROR LOGS
# 		 | GENERAL LOGS
# 		 | HOSTS
# 		 | LOGS
# 		 | PRIVILEGES
# 		 | OPTIMIZER_COSTS
# 		 | RELAY LOGS [FOR CHANNEL channel]
# 		 | SLOW LOGS
# 		 | STATUS
# 		 | USER_RESOURCES
# 		}
#
# 		tables_option: {
# 			TABLES
# 		 | TABLES tbl_name [, tbl_name] ---
# 		 | TABLES WITH READ LOCK
# 		 | TABLES tbl_name [, tbl_name] --- WITH READ LOCK
# 		 | TABLES tbl_name [, tbl_name] --- FOR EXPORT
# 		}
#
# The FLUSH statement has several variant forms that clear or reload various internal caches,
# flush tables, or acquire locks.
#
# To execute FLUSH, you must have the RELOAD privilege.
#
# Specific flush options might require additional privileges, as described later.
#
# NOTE:
#
# 		It is not possible to issue FLUSH statements within stored functions or triggers.
#
# 		However, you may use FLUSH in stored procedures, so long as these are not called
# 		from stored functions or triggers.
#
# 		See SECTION C.1, "RESTRICTIONS ON STORED PROGRAMS"
#
# By default, the server writes FLUSH statements to the binary log so that they replicate
# to replication slaves.
#
# To suppress logging, specify the optional NO_WRITE_TO_BINLOG keyword or its alias LOCAL.
#
# NOTE:
#
# 		FLUSH_LOGS, FLUSH_BINARY_LOGS, FLUSH_TABLES_WITH_READ_LOCK (with or without a table list),
# 		and FLUSH_TABLES_tbl_name_---_FOR_EXPORT are not written to the binary log in any case
# 		because they would cause problems if replicated to a slave.
#
# The FLUSH statement causes an implicit commit. See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# The mysqladmin utility provides a command-line interface to some flush operations, using commands such
# as flush-hosts, flush-logs, flush-privileges, flush-status, and flush-tables.
#
# See SECTION 4.5.2, "MYSQLADMIN -- CLIENT FOR ADMINISTERING A MYSQL SERVER"
#
# Sending a SIGHUP signal to the server causes several flush operations to occur that are similar
# to various forms of the FLUSH statement.
#
# See SECTION 5.1.16, "SERVER RESPONSE TO SIGNALS"
#
# The RESET statement is similar to FLUSH
#
# See SECTION 13.7.7.6, "RESET SYNTAX", for information about using the RESET statement with replication.
#
# The following list describes the permitted FLUSH statement flush_option values.
#
# For descriptions of FLUSH_TABLES variants, see FLUSH TABLES SYNTAX
#
# 		) FLUSH_BINARY_LOGS
#
# 			Closes and reopens any binary log file to which the server is writing.
#
# 			If binary logging is enabled, the sequence number of the binary log file is
# 			incremented by one relative to the previous file.
#
# 		) FLUSH_ENGINE_LOGS
#
# 			Closes and reopens any flushable logs for installed storage engines.
#
# 			This causes InnoDB to flush its logs to disk.
#
# 		) FLUSH_ERROR_LOGS
#
# 			Closes and reopens any error log file to which the server is writing
#
# 		) FLUSH_GENERAL_LOGS
#
# 			Closes and reopens any general query log file to which the server is writing.
#
# 		) FLUSH_HOSTS
#
# 			Empties the host cache and the Performance Schema host_cache table that exposes
# 			the cache contents, and unblocks any blocked hosts.
#
# 			See SECTION 8.12.4.2, "DNS LOOKUP OPTIMIZATION AND THE HOST CACHE"
#
# 			Flush the host cache if some of your host change IP address or if the error message
# 			Host 'host_name' is blocked occurs for connections from legitimate hosts.
#
# 			(See SECTION B.6.2.5, "HOST 'host_name' IS BLOCKED")
#
# 			When more than max_connect_errors errors occur successively for a given host
# 			while connecting to the MySQL server, MySQL assumes that something is wrong
# 			and blocks the host from further connection requests.
#
# 			Flushing the host cache enables further connection attempts from the host.
#
# 			The default value of max_connect_errors is 100
#
# 			To avoid this error message, start the server with max_connect_errors
# 			set to a large value.
#
# 		) FLUSH_LOGS
#
# 			Closes and reopens any log file to which the server is writing.
#
# 			If binary logging is enabled, the sequence number of the binary log file
# 			is incremented by one relative to the previous file.
#
# 			If relay logging is enabled, the sequence number of the relay log file
# 			is incremented by one relative to the previous file.
#
# 			FLUSH_LOGS has no effect on tables used for the general query log or
# 			for the slow query log (see SECTION 5.4.1, "SELECTING GENERAL QUERY LOG AND SLOW QUERY LOG OUTPUT DESTINATIONS")
#
# 		) FLUSH_OPTIMIZER_COSTS
#
# 			Rereads the cost model tables so that the optimizer starts using the current cost estimates stored
# 			in them.
#
# 			The server writes a warning to the error log for any unrecognized entries.
#
# 			(For information about these tables, see SECTION 8.9.5, "THE OPTIMIZER COST MODEL")
#
# 			This operation affects only sessions that begin subsequent to the flush.
#
# 			Existing sessions continue to use the cost estimates that were current when they began.
#
# 		) FLUSH_PRIVILEGES
#
# 			Reloads the privileges from the grant tables in the mysql system database, and clears
# 			the in-memory cache used by the caching_sha2_password authentication plugin.
#
# 			As part of this operation, the server reads the global_grants table containing
# 			dynamic privilege assignments and registers any unregistered privileges found there.
#
# 			The server cache information in memory as a result of GRANT, CREATE_USER, CREATE_SERVER,
# 			and INSTALL_PLUGIN statements.
#
# 			This memory is not released by the corresponding REVOKE, DROP_USER, DROP_SERVER and
# 			UNINSTALL_PLUGIN statements, so for a server that executes many instances of the statements
# 			that cause caching, there will be an increase in memory use.
#
# 			This cached memory can be freed with FLUSH_PRIVILEGES
#
# 		) FLUSH_RELAY_LOGS_[FOR_CHANNEL_channel]
#
# 			Closes and reopens any relay log file to which the server is writing.
#
# 			If relay logging is enabled, the sequence number of the relay log file is
# 			incremented by one relative to the previous file.
#
# 			The FOR CHANNEL channel clause enables you to name which replication channel the
# 			statement applies to.
#
# 			Execute FLUSH_RELAY_LOGS_FOR_CHANNEL_channel to flush the relay log for a specific
# 			replication channel.
#
# 			If no channel is named and no extra replication channels exist, the statement
# 			applies to the default channel.
#
# 			If no channel is named and multiple replication channels exist, the statement
# 			applies to all replication channels.
#
# 			For more information, see SECTION 17.2.3, "REPLICATION CHANNELS"
#
# 		) FLUSH_SLOW_LOGS
#
# 			Closes and reopens any slow query log file to which the server is writing.
#
# 		) FLUSH_STATUS
#
# 			This option adds the session status from all active sessions to the global
# 			status variables, resets the status of all active sessions, and resets account,
# 			host, and user status values aggregated from disconnected sessions.
#
# 			See SECTION 26.12.14, "PERFORMANCE SCHEMA STATUS VARIABLE TABLES"
#
# 			This information may be of use when debugging a query. See SECTION 1.7, "HOW TO REPORT BUGS OR PROBLEMS"
#
# 		) FLUSH_USER_RESOURCES
#
# 			Resets all per-hour user resources to zero.
#
# 			This enables clients that have reached their hourly connection, query, or update
# 			limits to resume activity immediately.
#
# 			FLUSH_USER_RESOURCES does not apply to the limit on maximum simultaneous connections
# 			that is controlled by the max_user_connections system variable.
#
# 			See SECTION 6.3.6, "SETTING ACCOUNT RESOURCE LIMITS"
#
# FLUSH TABLES SYNTAX
#
# 	FLUSH_TABLES flushes tables, and depending on the variant used, acquires locks.
#
# Any TABLES variant used in a FLUSH statement must be the only option used.
#
# FLUSH_TABLE is a synonym for FLUSH_TABLES
#
# NOTE:
#
# 		The descriptions here that indicate tables are flushed by closing them apply differently
# 		for InnoDB, which flushes table contents to disk but leaves them open.
#
# 		This still permits table files to be copied while the tables are open, as long as other
# 		activity does not modify them.
#
# 		) FLUSH_TABLES
#
# 			Closes all open tables,, forces all tables in use to be closed, and flushes the prepared
# 			statement cache.
#
# 			For information about prepared statement caching, see SECTION 8.10.3, "CACHING OF PREPARED STATEMENTS AND STORED PROGRAMS"
#
# 			FLUSH_TABLES is not permitted when there is an active LOCK_TABLES_---_READ 
#
# 			To flush and lock tables, use FLUSH_TABLES_tbl_name_---_WITH_READ_LOCK instead.
#
# 		) FLUSH_TABLES_tbl_name_[, tbl_name] ---
#
# 			With a list of one or more comma-separated table names, this statement is like FLUSH_TABLES
# 			with no names except that the server flushes only the named tables.
#
# 			If a named table does not exist, no error occurs.
#
# 		) FLUSH_TABLES_WITH_READ_LOCK
#
# 			Closes all open tables and locks all tables for all databases with a global read lock.
#
# 			This is a very convenient way to get backups if you have a file system such as
# 			Veritas or ZFS that can take snapshots in time.
#
# 			Use UNLOCK_TABLES to release the lock.
#
# 			FLUSH_TABLES_WITH_READ_LOCK acquires a global read lock rather  than table locks, so it is
# 			not subject to the same behavior as LOCK_TABLES and UNLOCK_TABLES with respect to table
# 			locking and implicit commits:
#
# 				) UNLOCK_TABLES implicitly commits any active transaction only if any tables currently
# 					have been locked with LOCK_TABLES.
#
# 					The commit does not occur for UNLOCK_TABLES following FLUSH_TABLES_WITH_READ_LOCK
# 					because the latter statement does not acquire table locks.
#
# 				) Beginning a transaction causes table locks acquired with LOCK_TABLES to be released,
# 					as though you had executed UNLOCK_TABLES
#
# 					Beginning a transaction does not release a global read lock acquired with
# 					FLUSH_TABLES_WITH_READ_LOCK
#
# 			FLUSH_TABLES_WITH_READ_LOCK does not prevent the server from inserting rows into the log tables
# 			(see SECTION 5.4.1, "SELECTING GENERAL QUERY LOG AND SLOW QUERY LOG OUTPUT DESTINATIONS")
#
# 		) FLUSH_TABLES_tbl_name [, tbl_name] --- WITH_READ_LOCK
#
# 			This statement flushes and acquires read locks for the named tables.
#
# 			The statement first acquires exclusive metadata locks for the tables, so it waits
# 			for transactions that have those tables open to complete.
#
# 			Then the statement flushes the tables from the table cache, reopens the tables, acquires
# 			table locks (like LOCK_TABLES_---_READ), and downgrades the metadata locks from exclusive
# 			to shared.
#
# 			After the statement acquires locks and downgrades the metadata locks, other sessions can read
# 			but not modify the tables.
#
# 			Because this statement acquires table locks, you must have the LOCK_TABLES privilege for each
# 			table, in addition to the RELOAD privilege that is required to use any FLUSH Statement.
#
# 			This statement applies only to existing base (non-TEMPORARY) tables.
#
# 			If a name refers to a base table, that table is used.
#
# 			If it refers to a TEMPORARY table, it is ignored.
#
# 			If a name applies to a view, an ER_WRONG_OBJECT error occurs.
#
# 			Otherwise, an ER_NO_SUCH_TABLE error occurs.
#
# 			Use UNLOCK_TABLES to release the locks, LOCK_TABLES to release the locks
# 			and acquire other locks, or START_TRANSACTION to release the locks and begin
# 			a new transaction.
#
# 			This FLUSH_TABLES variant enables tables to be flushed and locked in a single operation.
#
# 			It provides a workaround for the restriction that FLUSH_TABLES is not permitted
# 			when there is an active LOCK_TABLES_---_READ
#
# 			This statement does not perform an implicit UNLOCK_TABLES, so an error results if
# 			you use the statement while there is any active LOCK_TABLES or use it a second
# 			time without first releasing the locks acquired.
#
# 			If a flushed table was opened with HANDLER, the handler is implicitly flushed and
# 			loses its position.
#
# 		) FLUSH_TABLES_tbl_name_[, tbl_name]_---_FOR_EXPORT
#
# 			This FLUSH_TABLES variant applies to InnoDB tables.
#
# 			It ensures that changes to the named tables have been flushed to disk so that
# 			binary table copies can be made while the server is running.
#
# 			The statement works like this:
#
# 				a. It acquires shared metadata locks for the named tables.
#
# 					The statement blocks as long as other sessions have active transactions
# 					that have modified those tables or hold table locks for them.
#
# 					When the locks have been acquired, the statement blocks transactions
# 					that attempt to update the tables, while permitting read-only operations
# 					to continue.
#
# 				b. It checks whether all storage engines for the tables support FOR EXPORT.
#
# 					If any do not, an ER_ILLGAL_HA error occurs and the statement fails.
#
# 				c. The statement notifies the storage engine for each table to make the table ready
# 					for export.
#
# 					The storage engine must ensure that any pending changes are written to disk.
#
# 				d. THe statement puts the session in lock-tables mode so that the metadata locks acquired
# 					earlier are not released when the FOR EXPORT statement completes.
#
# The FLUSH_TABLES_---_FOR_EXPORT statement requires that you have the SELECT privilege for each table.
#
# Because this statement acquires table locks, you must also have the LOCK_TABLES privilege for each
# table, in addition to the RELOAD privilege that is required to use any FLUSH statement.
#
# This statement applies only to existing base (non-TEMPORARY) tables.
#
# If a name refers to a base table, that table is used. If it refers to a TEMPORARY table,
# it is ignored.
#
# if a name applies to a view, an ER_WRONG_OBJECT error occurs. Otherwise, an ER_NO_SUCH_TABLE error occurs.
#
# InnoDB supports FOR EXPORT for tables that have their own .ibd file file (that is, tables created with the
# innodb_file_per_table setting enabled)
#
# InnoDB ensures when notidifed by the FOR EXPORT statement that any changes have been flushed to disk.
#
# This permits a binary copy of table contents to be made while the FOR EXPORT statement is in effect
# because the .ibd file is transaction consistent and can be copied while the server is running.
#
# FOR EXPORT does not apply to InnoDB system tablespace files, or to InnoDB tables that have FULLTEXT
# indexes.
#
# FLUSH_TABLES_---_FOR_EXPORT is supported for partitioned InnoDB tables.
#
# When notified by FOR EXPORT, InnoDB writes to disk certain kinds of data that is normally
# held in memory or in separate disk buffers outside the tablespace files.
#
# For each table, InnoDB also produces a file named table_name.cfg in the same database
# directory as the table.
#
# The .cfg contains metadata needed to reimport the tablespace files later, into the same or
# different server.
#
# When the FOR EXPORT statement completes, InnoDB will have flushed all dirty pages to the table
# data files.
#
# ANy change buffer entries are merged prior to flushing.
#
# At this point, the tables are locked and quiescent: The tables are in a transactionally
# consistent state on disk and you can copy the .ibd tablespace files along with the corresponding
# .cfg files to get a consistent snapshot of those tables.
#
# For the procedure to reimport the copied table data into a MySQL instance, see SECTION 15.6.3.7, "COPYING TABLESPACES TO ANOTHER INSTANCE"
#
# After you are done with the tables, use UNLOCK_TABLES to release the locks, LOCK_TABLES to release
# the locks and acquire other locks, or START_TRANSACTION to release the locks and begin a new 
# transaction.
#
# While any of these statements is in effect within the session, attempts to use FLUSH_TABLES_---_FOR_EXPORT
# produce an error:
#
# 		FLUSH TABLES --- WITH READ LOCK
# 		FLUSH TABLES --- FOR EXPORT
# 		LOCK TABLES --- READ
# 		LOCK TABLES --- WRITE
#
# While FLUSH_TABLES_---_FOR_EXPORT is in effect within the session, attempts to use any of these
# statements produce an error:
#
# 		FLUSH TABLES WITH READ LOCK
# 		FLUSH TABLES --- WITH READ LOCK
# 		FLUSH TABLES --- FOR EXPORT
#
# 13.7.7.4 KILL SYNTAX
#
# 		KILL [CONNECTION | QUERY] processlist_id
#
# Each connection to mysqld runs in a separate thread. You can kill a thread with the KILL processlist_id statement.
#
# Thread processlist identifiers can be determined from the ID column of the INFORMATION_SCHEMA PROCESSLIST table,
# the Id column of SHOW_PROCESSLIST output, and the PROCESSLIST_ID column of the Performance Schema threads table.
#
# The value for the current thread is returned by the CONNECTION_ID() function.
#
# KILL permits an optional CONNECTION or QUERY modifier:
#
# 		) KILL_CONNECTION is the same as KILL with no modifier:
#
# 			It terminates the connection associated with the given processlist_id, after terminating
# 			any statement the connection is executing.
#
# 		) KILL_QUERY terminates the statement the connection is currently executing, but leaves the connection
# 			itself intact.
#
# If you have the PROCESS privilege, you can see all threads.
#
# If you have the CONNECTION_ADMIN or SUPER privilege, you can kill all threads and statements.
#
# Otherwise, you can see and kill only your own threads and statements.
#
# You can also use the mysqladmin processlist and mysqladmin kill commands to examine and kill threads.
#
# When you use a KILL, a thread-specific kill flag is set for the thread.
#
# In most cases, it might take some time for the thread to die because the kill flag
# is checked only at specific intervals:
#
# 		) During SELECT operations, for ORDER BY and GROUP BY loops, the flag is checked after reading
# 			a block of rows.
#
# 			If the kill flag is set, the statement is aborted.
#
# 		) ALTER_TABLE operations that make a table copy check the kill flag periodically for each few copied
# 			rows read from the original table.
#
# 			If the kill flag was set, the statement is aborted and the temporary table is deleted.
#
# 			The KILL statement returns without waiting for confirmation, but the kill flag check aborts the
# 			operation within a reasonably small amount of time.
#
# 			Aborting the operation to perform any necessary cleanup also takes some time.
#
# 		) During UPDATE or DELETE operations, the kill flag is checked after each block read
# 			and after each updated or deleted row.
#
# 			If the kill flag is set, the statement is aborted.
#
# 			If you are not using transactions, the changes are not rolled back.
#
# 		) GET_LOCK() aborts and returns NULL
#
# 		) If the thread is in the table lock handler (state: Locked), the table lock is quickly aborted
#
# 		) If the thread is waiting for free disk space in a write cell, the write is aborted with a 
# 			"disk full" error message.
#
# WARNING:
#
# 		Killing a REPAIR_TABLE or OPTIMIZE_TABLE operation on a MyISAM table results in a table that is
# 		corrupted and unusable.
#
# 		Any reads or writes to such a table fail until you optimize or repair it again (without interruption)
#
# 13.7.7.5 LOAD INDEX INTO CACHE SYNTAX
#
# 		LOAD INDEX INTO CACHE
# 			tbl_index_list [, tbl_index_list] ---
#
# 		tbl_index_list:
# 			tbl_name
# 				[PARTITION (partition_list | ALL)]
# 				[[INDEX|KEY] (index_name[, index_name] ---)]
# 				[IGNORE LEAVES]
#
# 		partition_list:
# 			partition_name[, partition_name][, ---]
#
# The LOAD_INDEX_INTO_CACHE statement preloads a table index into the key cache to which
# it has been assigned by an explicit CACHE_INDEX statement, or into the default key cache
# otherwise.
#
# LOAD_INDEX_INTO_CACHE is used only for MyISAM tables. In MySQL 8.0, it is also supported
# for partitioned MyISAM tables; in addition, indexes on partitioned tables can be
# preloaded for one, several or all partitions.
#
# The IGNORE LEAVES modifier causes only blocks for the nonleaf nodes of the index to be preloaded.
#
# IGNORE LEAVES is also supported for partitioned MyISAM tables.
#
# The following statement preloads nodes (index blocks) of indexes for the tables t1 and t2:
#
# 		LOAD INDEX INTO CACHE t1, t2 IGNORE LEAVES;
# 		+-----------+--------------------+----------+-------------+
# 		| Table 		| Op 						| Msg_type | Msg_text 	 |
# 		+-----------+--------------------+----------+-------------+
# 		| test.t1   | preload_keys 	   | status   | OK 			 |
# 		| test.t2   | preload_keys 		| status   | OK 			 |
# 		+-----------+--------------------+----------+-------------+
#
# This statement preloads all index blocks from t1.
#
# It preloads only blocks for the nonleaf nodes from t2.
#
# The syntax of LOAD_INDEX_INTO_CACHE enables you to specify that only particular
# indexes from a table should be preloaded.
#
# The current implementation preloads all the table's indexes into the cache,
# so there is no reason to specify anything other than the table name.
#
# It is possible to preload indexes on specific partitions of partitioned MyISAM tables.
#
# For example, of the following 2 statements, the first preloads indexes for partition
# p0 of a partitioned table pt, while the second preloads the indexes for partitions
# p1 and p3 of the same table:
#
# 		LOAD INDEX INTO CACHE pt PARTITION (p0);
# 		LOAD INDEX INTO CACHE pt PARTITION (p1, p3);
#
# To preload the indexes for all partitions in table pt, you can use either one of the
# following 2 statements:
#
# 		LOAD INDEX INTO CACHE pt PARTITION (ALL);
# 
# 		LOAD INDEX INTO CACHE pt;
#
# The two statements just shown are equivalent, and issuing either one of them has exactly
# the same effect.
#
# In other words, if you wish to preload indexes for all partitions of a partitioned table,
# then the PARTITION (ALL) clause is optional.
#
# When preloading indexes for multiple partitions, the partitions do not have to be contiguous,
# and you are not required to list their names in any particular order.
#
# LOAD_INDEX_INTO_CACHE_---_IGNORE_LEAVES fails unless all indexes in a table have the
# same block size.
#
# You can determine index block size for a table by using myisamchk -dv and checking
# the Blocksize column.
#
# 13.7.7.6 RESET SYNTAX
#
# 		RESET reset_option [, reset_option] ---
#
# 		reset_option: {
# 			MASTER
# 		 | SLAVE
# 		}
#
# The RESET statement is used to clear the state of various server operations.
#
# You must have the RELOAD privilege to execute RESET.
#
# For information about the RESET_PERSIST statement that removes persisted global
# system variables, see SECTION 13.7.7.7, "RESET PERSIST SYNTAX"
#
# RESET acts as a stronger version of the FLUSH statement. See SECTION 13.7.7.3, "FLUSH SYNTAX"
#
# The RESET statement causes an implicit commit. See SECTION 13.3.3, "STATEMENTS THAT CAUSE AN IMPLICIT COMMIT"
#
# The following list describes the permitted RESET statement reset_option values:
#
# 		) RESET MASTER
#
# 			Deletes all binary logs listed in the index file, resets the binary log index file
# 			to be empty and creates a new binary log file
#
# 		) RESET SLAVE
#
# 			Makes the slave forget its replication position in the master binary logs.
#
# 			Also resets the relay log by deleting any existing relay log files and beginning
# 			a new one.
#
# 13.7.7.7 RESET PERSIST SYNTAX
#
# 		RESET PERSIST [[IF EXISTS] system_var_name]
#
# RESET_PERSIST removes persisted global system variable settings from the mysqld-auto.cnf option file
# in the data directory.
#
# Removing a persisted system variable causes the variable no longer to be initialized from mysqld-auto.cnf
# at server startup.
#
# For more information about persisting system variables and the mysqld-auto.cnf file, see SECTION 5.1.9.3, "PERSISTED SYSTEM VARIABLES"
#
# THe privileges required for RESET_PERSIST depend on the type of system variable to be removed:
#
# 		) For dynamic system variables, this statement requires the SYSTEM_VARIABLES_ADMIN or SUPER privilege
#
# 		) For read-only system variables, this statement requires the SYSTEM_VARIABLES_ADMIN and PERSIST_RO_VARIABLES_ADMIN privileges
#
# See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"
#
# Depending on whether the variable name and IF EXISTS clauses are present, the RESET_PERSIST
# statement has these forms:
#
# 		) To remove all persisted variables from mysqld-auto.cnf, use RESET_PERSIST without naming any system variable:
#
# 			RESET PERSIST;
#
# 			You must have privileges for removing both dynamic and read-only system variables if mysqld-auto.cnf
# 			contains both kinds of variables.
#
# 		) To remove a specific persisted variable from mysqld-auto.cnf, name it in the statement:
#
# 			RESET PERSIST system_var_name;
#
# 			This includes plugin system variables, even if the plugin is not currently installed.
#
# 			If the variable is not present in the file, an error occurs.
#
# 		) To remove a specific persisted variable from mysqld-auto.cnf, but produces a warning rather than an error
# 			if the variable is not present in the file, add an IF EXISTS clause to the previous syntax:
#
# 			RESET PERSIST IF EXISTS system_var_name;
#
# RESET_PERSIST is not affected by the value of the persisted_globals_load system variable.
#
# RESET_PERSIST affects the contents of the Performance Schema persisted_variables table because the tables
# contents correspond to the contents of the mysqld-auto.cnf file.
#
# On the other hand, because RESET_PERSIST does not change variable values, it has no effect on the contents
# of the Performance Schema variables_info table until the server is restarted.
#
# For information about RESET statement variants that clear the state of other server operations,
# see SECTION 13.7.7.6, "RESET SYNTAX"
#
# 13.7.7.8 RESTART SYNTAX
#
# 		RESTART
#
# This statement stops and restarts the MySQL server. It requires the SHUTDOWN privilege.
#
# One use for RESTART is when it is not possible or convenient to gain command-line access
# to the MySQL server on the server host to restart it.
#
# For example, SET_PERSIST_ONLY can be used at runtime to make configuration changes to
# system variables that can be set only at server startup, but the server must still be 
# restarted for those changes to take effect.
#
# The RESTART statement provides a way to do so from within client sessions, without requiring
# command-line access on the server host.
#
# NOTE:
#
# 		After executing a RESTART statement, the client can expect the current connection to be lost.
#
# 		If auto-reconnect is enabled, the connection will be reestablished after the server
# 		restarts.
#
# 		Otherwise, the connection must be reestablished manually.
#
# A successful RESTART operation requires mysqld to be running in an environment that has a monitoring
# process available to detect a server shutdown performed for restart purposes:
#
# 		) In the presence of a monitoring process, RESTART causes mysqld to terminate such that the monitoring
# 			process can determine that it hsould start a new mysqld instance
#
# 		) If no monitoring process is present, RESTART fails with an error
#
# These platforms provide the necessary monitoring support for the RESTART statement:
#
# 		) Windows, when mysqld is started as a Windows service or standalone.
#
# 			(mysqld forks, and one process acts as a monitor to the other, which acts as
# 			the server)
#
# 		) Unix and Unix-like systems that use systemd or mysqld_safe to manage mysqld
#
# On Windows, the forking used to implement RESTART makes determining the server process to attach
# to for debugging more difficult.
#
# To alleviate this, starting the server with --gdb suppresses forking, in addition to its other
# actions done to set up a debugging environment.
#
# In non-debug settings, --no-monitor may be used for the sole purpose of suppressing
# forking at the monitor process.
#
# For a server started with either --gdb or --no-monitor, executing RESTART causes the server
# to simply exit without restarting.
#
# 13.7.7.9 SHUTDOWN SYNTAX
#
# 		SHUTDOWN
#
# THis statement stops the MySQL server. It requires the SHUTDOWN privilege.
#
# SHUTDOWN provides an SQL-level interface to the same functionality available
# using the mysqladmin shutdown command.
#
# 13.8 UTILITY STATEMENTS
#
# 13.8.1 DESCRIBE SYNTAX
#
# 		The DESCRIBE and EXPLAIN statements are synonyms, used either to obtain information about
# 		table structure or query execution plans.
#
# 		For more information, see SECTION 13.7.6.5, "SHOW COLUMNS SYNTAX" and SECTION 13.8.2, "EXPLAIN SYNTAX"
#
# 13.8.2 EXPLAIN SYNTAX
#
# 		{EXPLAIN | DESCRIBE | DESC}
# 			tbl_name [col_name | wild]
#
# 		{EXPLAIN | DESCRIBE | DESC}
# 			[explain_type]
# 			{explainable_stmt | FOR CONNECTION connection_id}
#
# 		explain_type: {
# 			FORMAT = format_name
# 		}
#
# 		format_name: {
# 			TRADITIONAL
# 		 | JSON
# 		}
#
# 		explainable_stmt: {
# 			SELECT statement
# 		 | DELETE statement
# 		 | INSERT statement
# 		 | REPLACE statement
# 		 | UPDATE statement
# 		}
#
# The DESCRIBE and EXPLAIN statements are synonyms. In practice, the DESCRIBE keyword is more often
# used to obtain information about table structure, whereas EXPLAIN is used to obtain a query
# execution plan (that is, an explanation of how MySQL would execute a query)
#
# The following discussion uses the DESCRIBE and EXPLAIN keywords in accordance with those uses,
# but the MySQL parser treats them as complete synonyms.
#
# 		) OBTAINING TABLE STRUCTURE INFORMATION
#
# 		) OBTAINING EXECUTION PLAN INFORMATION
#
# OBTAINING TABLE STRUCTURE INFORMATION
#
# DESCRIBE provides information about the columns in a table:
#
# 		DESCRIBE City;
# 		+-------------------+-------------------+---------+---------+-------------------+--------------------------+
# 		| Field 				  | Type 				 | Null    | Key 		| Default 			  | Extra 						  |
# 		+-------------------+-------------------+---------+---------+-------------------+--------------------------+
# 		| Id 					  | int(11) 			 | NO 	  | PRI 	   | NULL 				  | auto_increment 			  |
# 		| Name 				  | char(35) 			 | NO 	  | 			| 						  | 								  |
# 		| Country 			  | char(3) 			 | NO 	  | UNI 	   | 						  | 								  |
# 		| District 			  | char(20) 			 | YES 	  | MUL     | 						  | 								  |
# 		| Population 		  | int(11) 			 | NO 	  | 		   | 0 					  | 								  |
# 		+-------------------+-------------------+---------+---------+-------------------+--------------------------+
#
# DESCRIBE is a shortcut for SHOW_COLUMNS
#
# These statements also display information for views. The description for SHOW_COLUMNS provides more information
# about the output columns.
#
# See SECTION 13.7.6.5, "SHOW COLUMNS SYNTAX"
#
# By default, DESCRIBE displays information about all columns in the table.
#
# col_name, if given, is the name of a column in the table. In this case, the statement displays
# information only for the named column.
#
# wild, if given, is a pattern string. It can contain the SQL % and _ wildcard characters.
#
# In this case, the statement displays output only for the columns with names matching the string.
#
# There is no need to enclose the string within quotation marks unless it contains spaces or
# other special characters.
#
# The DESCRIBE statement is provided for compatibility with Oracle
#
# The SHOW_CREATE_TABLE, SHOW_TABLE_STATUS and SHOW_INDEX statements also provide information
# about tables.
#
# See SECTION 13.7.6, "SHOW SYNTAX"
#
# OBTAINING EXECUTION PLAN INFORMATION
#
# The EXPLAIN statement provides information about how MySQL executes statements:
#
# 		) EXPLAIN works with SELECT, DELETE, INSERT, REPLACE and UPDATE statements.
#
# 		) When EXPLAIN is used with an explainable statement, MySQL displays information from the
# 			optimizer about the statement execution plan.
#
# 			That is, MySQL explains how it would process the statement, including information about how
# 			tables are joined and in which order.
#
# 			FOr information about using EXPLAIN to obtain execution plan information.
#
# 			See SECTION 8.8.2, "EXPLAIN OUTPUT FORMAT"
#
# 		) When EXPLAIN is used with FOR CONNECTION connection_id rather than an explainable
# 			statement, it displays the execution for the statement executing in the named connection.
#
# 			See SECTION 8.8.4, "OBTAINING EXECUTION PLAN INFORMATION FOR A NAMED CONNECTION"
#
# 		) For explainable statements, EXPLAIN produces additional execution plan information that
# 			can be displayed using SHOW_WARNINGS.
#
# 			See SECTION 8.8.3, "EXTENDED EXPLAIN OUTPUT FORMAT"
#
# 		) EXPLAIN is useful for examining queries involving partitioned tables. See SECTION 23.3.5, "OBTAINING INFORMATION ABOUT PARTITIONS"
#
# 		) The FORMAT option can be used to select the output format.
#
# 			TRADITIONAL presents the output in tabular format.
#
# 			THis is the default if no FORMAT option is present. JSON format displays the information
# 			in JSON format.
#
# EXPLAIN requires the SELECT privilege for any tables or views accessed, including any underlying
# tables of views.
#
# For views, EXPLAIN also requires the SHOW_VIEW privilege.
#
# With the help of EXPLAIN, you can see where you should add indexes to tables so that the statement
# executes faster by using indexes to find rows.
#
# You can also use EXPLAIN to check whether the optimizer joins the tables in an optimal order.
#
# To give a hint to the optimizer to use a join order corresponding to the order in which the
# tables are named in a SELECT statement, begin the statement with SELECT STRAIGHT_JOIN rather
# than just SELECT.
#
# (See SECTION 13.2.10, "SELECT SYNTAX")
#
# The optimizer trace may sometimes provide information complementary to that of EXPLAIN
#
# However, the optimizer trace format and content are subject to change between versions.
#
# For details, see MYSQL INTERNALS: TRACING THE OPTIMIZER
#
# If you have a problem with indexes not being used when you believe that they should be,
# run ANALYZE_TABLE to update table statistics, such as cardinality of keys, that can
# affect the choices the optimizer makes.
#
# See SECTION 13.7.3.1, "ANALYZE TABLE SYNTAX"
#
# NOTE:
#
# 		MYSQL Workbench has a Visual Explain capability that provides a visual representation
# 		of EXPLAIN output.
#
# 		See TUTORIAL: USING EXPLAIN TO IMPROVE QUERY PERFORMANCE
#
# 13.8.3 HELP SYNTAX
#
# 		HELP 'search_string'
#
# The HELP statement returns online information from the MySQL Reference manual.
#
# Its proper operation requires that the help tables in the mysql database be
# initialized with help topic information (see SECTION 5.1.15, "SERVER-SIDE HELP")
#
# The HELP statement searches the help tables for the given search string and displays the result of the search.
#
# The search string is not case-sensitive.
#
# The search string can contain the wildcard characters % and _
#
# These have the same meaning as for pattern-matching operations performed with the LIKE
# operator.
#
# For example, HELP 'rep%' returns a list of topics that begin with rep.
#
# The HELP statement understands several types of search strings:
#
# 		) At the most general level, use contents to retrieve a list of the top-level help categories:
#
# 			HELP 'contents'
#
# 		) For a list of topics in a given help category, such as Data Types, use the category name:
#
# 			HELP 'data types'
#
# 		) For help on a specific help topic, such as the ASCII() function or the CREATE_TABLE statement,
# 			use the associated keyword or keywords:
#
# 			HELP 'ascii'
# 			HELP 'create table'
#
# In other words, the search string matches a category, many topics or a single topic.
#
# You cannot necessarily tell in advance whether a given search string will return a list
# of items or the help information for a single help topic.
#
# However, you can tell what kind of response HELP returned by examining the number of rows
# and columns in the result set.
#
# The following descriptions indicate the forms that the result set can take.
#
# Output for the example statements is shown using the familiar "tabular" or "vertical"
# format that you see when using the mysql client, but note that mysql itself reformats
# HELP result sets in a different way.
#
# 		) Empty result set
#
# 			No match could be found for the search string.
#
# 		) Result set containing a single row with three columns
#
# 			THis means that the search string yielded a hit for the help topic.
#
# 			The result has three columns:
#
# 				) name: The topic name
#
# 				) description: Descriptive help text for the topic
#
# 				) example: Usage example or examples. This column might be blank
#
# 			Example: HELP 'replace'
#
# 			Yields:
#
# 				name: REPLACE
# 				description: Syntax:
# 				REPLACE(str,from_str,to_str)
#
# 				Returns the string str with all occurrences of the string from_str
# 				replaced by the string to_str. REPLACE() performs a case-sensitive
# 				match when searching for from_str.
#
# 				example: mysql> SELECT REPLACE('www.mysql.com', 'w', 'WW');
# 						-> 'WWWWWW.mysql.com'
#
# 		) Result set containing multiple rows with two columns
#
# 			This means that the search string matched many help topics.
#
# 			The result set indicates the help topic names:
#
# 				) name: THe help topic name.
#
# 				) is_it_category: Y if the name represents a help category, N if it does not.
#
# 					If it does not, the name value when specified as the argument to the HELP
# 					statement should yield a single-row result set containing a description for the named item.
#
# 			Example: HELP 'status'
#
# 			Yields:
#
# 				+--------------------------------------+----------------+
# 				| name 											| is_it_category |
# 				+--------------------------------------+----------------+
# 				| SHOW 										   | N 				  |
# 				| SHOW ENGINE 									| N 				  |
# 				| SHOW MASTER STATUS 						| N 				  |
# 				| SHOW PROCEDURE STATUS 					| N 				  |
# 				| SHOW SLAVE STATUS 							| N 				  |
# 				| SHOW STATUS 									| N 				  |
# 				| SHOW TABLE STATUS 							| N 				  |
# 				+--------------------------------------+----------------+
#
# 		) Result set containing multiple rows with three columns
#
# 			This means the search string matches a category. The result set contains category entries:
#
# 				) source_category_name: The help category name
#
# 				) name: The category or topic name
#
# 				) is_it_category: Y if the name represents a help category, N if it does not.
#
# 					If it does not, the name value when specified as the argument to the HELP statement
# 					should yield a single-row result set containing a description for the named item.
#
# 			Example: HELP 'functions'
#
# 			Yields:
#
# 				+-----------------------------------------+----------------------------------+------------------------+
# 				| source_category_name 							| name 									  | is_it_category 		   |
# 				+-----------------------------------------+----------------------------------+------------------------+
# 				| Functions 										| CREATE FUNCTION 					  | N 							|
# 				| Functions 										| DROP FUNCTION 						  | N 							|
# 				| Functions 										| Bit Functions 						  | Y 							|
# 				| Functions 										| Comparison operators 				  | Y 							|
# 				| Functions 										| Control flow functions 			  | Y 							|
# 				| Functions 										| Date and Time Functions 			  | Y 							|
# 				| Functions 										| Encryption Functions 				  | Y 							|
# 				| Functions 										| Information Functions 			  | Y 							|
# 				| Functions 										| Logical operators 					  | Y 							|
# 				| Functions 										| Miscellaneous Functions 			  | Y 							|
# 				| Functions 										| Numeric Functions 					  | Y 							|
# 				| Functions 										| String Functions 					  | Y 							|
# 				+-----------------------------------------+----------------------------------+------------------------+
#
# 
# 13.8.4 USE SYNTAX
#
# 		USE db_name
#
# The USE db_name statement tells MySQL to use the db_name database as the default (current) database
# for subsequent statements.
#
# The database remains the default until the end of the session or another USE statement is issued:
#
# 		USE db1;
# 		SELECT COUNT(*) FROM mytable; #selects from db1.mytable
# 		USE db2;
# 		SELECT COUNT(*) FROM mytable; #selects from db2.mytable
#
# The database name must be specified on a single line. Newlines in database names are not supported.
#
# Making a particular database the default by means of the USE statement does not preclude accessing
# tables in other databases.
#
# The following example accesses the author table from the db1 database and the editor
# table from the db2 database:
#
# 		USE db1;
# 		SELECT author_name.editor_name FROM author,db2.editor
# 			WHERE author.editor_id = db2.editor.editor_id;
#
# CHAPTER 14 MYSQL DATA DICTIONARY
#
# TABLE OF CONTENTS
#
# 14.1 DATA DICTIONARY SCHEMA
# 14.2 REMOVAL OF FILE-BASED METADATA STORAGE
# 14.3 TRANSACTIONAL STORAGE OF DICTIONARY DATA
# 14.4 DICTIONARY OBJECT CACHE
#
# 14.5 INFORMATION_SCHEMA AND DATA DICTIONARY INTEGRATION
# 14.6 SERIALIZED DICTIONARY INFORMATION (SDI)
# 14.7 DATA DICTIONARY USAGE DIFFERENCES
# 14.8 DATA DICTIONARY LIMITATIONS
#
# MySQL Server incorporates a transactional data dictionary that stores information about database
# objects.
#
# In previous MySQL releases, dictionary data was stored in metadata files, nontransactional tables,
# and storage engine-specific data dictionaries.
#
# This chapter describes the main features, benefits, usage differences, and limitations of the data
# dictionary.
#
# For other implications of the data dictionary feature, refer to the "Data Dictionary notes" section
# in the MySQL 8.0 RELEASE NOTES.
#
# Benefits of the MySQL data dictionary include:
#
# 		) Simplicity of a centralized data dictionary schema that uniformly stores dictionary data. See SECTION 14.1, "DATA DICTIONARY SCHEMA"
#
# 		) Removal of file-based metadata storage. See SECTION 14.2,, "REMOVAL OF FILE-BASED METADATA STORAGE"
#
# 		) Transactional, crash-safe storage of dictionary data. See SECTION 14.3, "TRANSACTIONAL STORAGE OF DICTIONARY DATA"
#
# 		) Uniform and centralized caching for dictionary objects. See SECTION 14.4, "DICTIONARY OBJECT CACHE"
#
# 		) A simpler and improved implementation for some INFORMATION_SCHEMA tables. See SECTION 14.5, "INFORMATION_SCHEMA AND DATA DICTIONARY INTEGRATION"
#
# 		) Atomic DDL. See SECTION 13.1.1, "ATOMIC DATA DEFINITION STATEMENT SUPPORT"
#
# IMPORTANT:
#
# 		A data dictionary-enabled server entails some general operational differences compared to a server
# 		that does not have a data dictionary; see SECTION 14.7, "DATA DICTIONARY USAGE DIFFERENCES"
#
# 		Also, for upgrades to MySQL 8.0, the upgrade procedure differs somewhat from previous MySQL
# 		releases and requires that you verify the upgrade readiness of your installation by checking
# 		specific prerequisites.
#
# 		For more information, see SECTION 2.11.1, "UPGRADING MYSQL", particularly SECTION 2.11.1.4,
# 		"PREPARING YOUR INSTALLATION FOR UPGRADE"
#
# 14.1 DATA DICTIONARY SCHEMA
#
# Data dictionary tables are protected and may only be accessed in debug builds of MySQL.
#
# However, MySQL supports access to data stored in data dictionary tables through INFORMATION_SCHEMA
# tables and SHOW statements.
#
# For an overview of the tables that comprise the data dictionary, see DATA DICTIONARY TABLES.
#
# MySQL system tables still exist in MySQL 8.0 and can be viewed by issuing a SHOW_TABLES
# statement on the mysql system database.
#
# Generally, the difference between MySQL system tables and data dictionary tables is that system
# tables contain auxiliary data such as time zone and help information, whereas data dictionary
# tables contain data required to execute SQL queries.
#
# MySQL system tables and data dictionary tables also differ in how they are upgraded.
#
# Upgrading MySQL system tables requires running mysql_upgrade. Data dictionary upgrades
# are managed by the MySQL server.
#
# See How The Data Dictionary is Upgraded.
#
# HOW THE DATA DICTIONARY IS UPGRADED
#
# New versions of MYSQL may include changes to data dictionary table definitions.
#
# Such changes are present in newly installed versions of MySQL, but when performing an
# in-place upgrade of MySQL binaries, changes are applied when the MySQL server is restarted
# using the new binaries.
#
# At startup, the data dictionary version of the server is compared to the version information
# stored in the data dictionary to determine if data dictionary tables should be upgraded.
#
# If an upgrade is necessary and supported, the server creates data dictionary tables with
# updated definitions, copies persisted metadata to the new tables, atomically replaces
# the old tables with the new ones, and reinitializes the data dictionary.
#
# If an upgrade is not necessary, startup continues without updating the data dictionary
# tables.
#
# Upgrade of data dictionary tables is an atomic operation, which means that all of the
# data dictionary tables are upgraded as necessary or the operation fails.
#
# If the upgrade operation fails, server startup fails with an error.
#
# In this case, the old server binaries can be used with the old data directory to start
# the server.
#
# When the new server binaries are used again to start the server, the data dictionary upgrade
# is reattempted.
#
# Generally, after data dictionary tables are successfully upgraded, it is not possible to restart
# the server using the old server binaries.
#
# As a result, downgrading MySQL server binaries to a previous MySQL version is not supported
# after data dictionary tables are upgraded.
#
# The mysqld --no-dd-upgrade option can be used to prevent automatic upgrade of data dictionary
# tables at startup.
#
# When --no-dd-upgrade is specified, and the server finds that the data dictionary version of the
# server is different from the version stored in the data dictionary, startup fails with an error
# stating that the data dictionary upgrade is prohibited.
#
# VIEWING DATA DICTIONARY TABLES USING A DEBUG BUILD OF MYSQL
#
# Data dictionary tables are protected by default but can be accessed by compiling MySQL
# with debugging support (using the -DWITH_DEBUG=1 CMake option) and specifying the
# +d, skip_dd_table_access_check debug option and modifier.
#
# For information about compiling debug builds, see SECTION 29.5.1.1, "COMPILING MYSQL FOR DEBUGGING"
#
# WARNING:
#
# 		Modifying or writing to data dictionary tables directly is not recommended and may render
# 		your MySQL instance inoperable.
#
# After compiling MySQL with debugging support, use this SET statement to make data dictionary
# tables visible to the mysql client session:
#
# 		SET SESSION debug='+d,skip_dd_table_access_check';
#
# Use this query to retrieve a list of data dictionary tables:
#
# 		SELECT name, schema_id, hidden, type FROM mysql.tables WHERE schema_id=1 AND hidden='System';
#
# Use SHOW_CREATE_TABLE to view data dictionary table definitions. For example:
#
# 		SHOW CREATE TABLE mysql.catalogs\G
#
# 14.2 REMOVAL OF FILE-BASED METADATA STORAGE
#
# In previous MySQL releases, dictionary data was partially stored in metadata files.
#
# Issues with file-based metadata storage included expensive file scans, suspectibiblity
# to file system-related bugs, complex code for handling of replication and crash recovery
# failure states, and a lack of extensibility that made it difficult to add metadata for new
# features and relational objects.
#
# The metadata files listed below are removed from MySQL. Unless otherwise noted, data previously
# stored in metadata files is now stored in data dictionary tables.
#
# 		) .frm files: Table metadata files. With the removal of .frm files:
#
# 			) The 64KB table definition size limit imposed by the .frm file structure is removed.
#
# 			) The INFORMATION_SCHEMA.TABLES VERSION column reports a hardcoded value of 10, which is the
# 				last .frm file version used in MySQL 5.7
#
# 		) .par files: Partition definition files. InnoDB stopped using partition definition files in MySQL 5.7
#			with the introduction of native partitioning support for InnoDB tables.
#
# 		) .TRN files: Trigger namespace files
#
# 		) .TRG files: Trigger parameter files
#
# 		) .isl files: InnoDB Symbolic Link files containing the location of file-per-table tablespace files
# 			created outside of the data directory.
#
# 		) db.opt files: Database configuration files. These files, one per database directory, contained database
# 			default character set attributes.
#
# 14.3 TRANSACTIONAL STORAGE OF DICTIONARY DATA
#
# The data dictionary schema stores dictionary data in transactional (InnoDB) tables.
#
# Data dictionary tables are located in the mysql database together with non-data dictionary
# system tables.
#
# Data dictionary tables are created in a single InnoDB tablespace named mysql.ibd, which resides
# in the MySQL data directory.
#
# The mysql.ibd tablespace file must reside in the MySQL data directory and its name cannot be
# modified or used by another tablespace.
#
# Dictionary data is protected by the same commit, rollback and crash-recovery capabilities
# that protect user data that is stored in InnoDB tables.
#
# 14.4 DICTIONARY OBJECT CACHE
#
# The dictionary object cache is a shared global cache that stores previously accessed data dictionary
# objects in memory to enable object reuse and minimize disk I/O.
#
# Similar to other cache mechanisms used by MySQL, the dictionary object cache uses an LRU-based
# eviction strategy to evict least recently used objects from memory.
#
# The dictionary object cache comprises cache partitions that store different object types.
#
# Some cache partition size limits are configurable, whereas others are hardcoded.
#
# 		) tablespace definition cache partition: Stores tablespace definition objects.
#
# 			The tablespace_definition_cache option sets a limit for the number of tablespace
# 			definition objects that can be stored in the dictionary object cache.
#
# 			The default value is 256.
#
# 		) schema definition cache partition: Stores schema definition objects.
#
# 			The schema_definition_cache option sets a limit for the number of schema
# 			definition objects that can be stored in the dictionary object cache.
#
# 			THe default value is 256.
#
# 		) table definition cache partition: Stores table definition objects.
#
# 			The object limit is set to the value of max_connections, which has a default
# 			value of 151.
#
# 			The table definition cache partition exists in parallel with the table definition
# 			cache that is configured using the table_definition_cache configuration option.
#
# 			Both caches store table definitions but serve different parts of the MySQL server.
#
# 			Objects in one cache have no dependence on the existence of objects in the other.
#
# 		) stored program definition cache partition: Stores stored program definition objects.
#
# 			The stored_program_definition_cache option sets a limit for the number of stored
# 			program definition objects that can be stored in the dictionary object cache.
#
# 			The default value is 256.
#
# 			The stored program definition cache partition exists in parallel with the stored procedure
# 			and stored function caches that are configured using the stored_program_cache option.
#
# 			The stored_program_cache option sets a soft upper limit for the number of cached stored
# 			procedures or functions per connection, and the limit is checked each time a connection
# 			executes a stored procedure or function.
#
# 			The stored program definition cache partition, on the other hand, is a shared cache that
# 			stores stored program definition objects for other purposes.
#
# 			The existence of objects in the stored program definition cache partition has no dependence
# 			on the existence of objects in the stored procedure cache or stored function cache, and 
# 			vice versa.
#
# 		) character set definition cache partition: Stores character set definition objects and has a hardcoded object
# 			limit of 256.
#
# 		) collation definition cache partition: Stores collation definition objects and has a hardcoded object limit of 256
#
# For information about valid values for dictionary object cache configuration options, refer to SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 14.5 INFORMATION_SCHEMA AND DATA DICTIONARY INTEGRATION
#
# With the introduction of the data dictionary, the following INFORMATION_SCHEMA tables are implemented as views on
# data dictionary tables:
#
# 		) CHARACTER_SETS
#
# 		) COLLATIONS
#
# 		) COLLATION_CHARACTER_SET_APPLICABILITY
#
# 		) COLUMNS
#
# 		) COLUMN_STATISTICS
#
# 		) EVENTS
#
# 		) FILES
#
# 		) INNODB_COLUMNS
#
# 		) INNODB_DATAFILES
#
# 		) INNODB_FIELDS
#
# 		) INNODB_FOREIGN
#
# 		) INNODB_FOREIGN_COLS
#
# 		) INNODB_INDEXES
#
# 		) INNODB_TABLES
#
# 		) INNODB_TABLESPACES
#
# 		) INNODB_TABLESPACES_BRIEF
#
# 		) INNODB_TABLESTATS
#
# 		) KEY_COLUMN_USAGE
#
# 		) KEYWORDS
#
# 		) PARAMETERS
#
# 		) PARTITIONS
#
# 		) REFERENTIAL_CONSTRAINTS
#
# 		) RESOURCE_GROUPS
#
# 		) ROUTINES
#
# 		) SCHEMATA
#
# 		) STATISTICS
#
# 		) ST_GEOMETRY_COLUMNS
#
# 		) ST_SPATIAL_REFERENCE_SYSTEMS
#
# 		) TABLES
#
# 		) TABLE_CONSTRAINTS
#
# 		) TRIGGERS
#
# 		) VIEWS
#
# 		) VIEW_ROUTINE_USAGE
#
# 		) VIEW_TABLE_USAGE
#
# Queries on those tables are now more efficient because they obtain information from data dictionary
# tables rather than by other, slower means.
#
# In particular, for each INFORMATION_SCHEMA table that is a view on data dictionary tables:
#
# 		) The server no longer must create a temporary table for each query of the INFORMATION_SCHEMA table
#
# 		) When the underlying data dictionary tables store values previously obtained by directory scans (for example,
# 			to enumerate database names or table names within databases) or file-opening operations (for example, to read
# 			information from .frm files), INFORMATION_SCHEMA queries for those values now use table lookups instead.
#
# 			(Additionally, even for a non-view INFORMATION_SCHEMA table, values such as database and table names are retrieved
# 			by lookups from the data dictionary and do not require directory or file scans)
#
# 		) Indexes on the underlying data dictionary tables permit the optimizer to construct efficient query execution
# 			plans, something not true for the previous implementation that processed the INFORMATION_SCHEMA table
# 			using a temporary table per query.
#
# The preceding improvements also apply to SHOW statements that display information corresponding to the INFORMATION_SCHEMA
# tables that are views on data dictionary tables.
#
# For example, SHOW_DATABASES displays the same information as the SCHEMATA table.
#
# In addition to the introduction of views on data dictionary tables, table statistics contained in the STATISTICS and
# TABLES is now cached to improve INFORMATION_SCHEMA query performance.
#
# The information_schema_stats_expiry system variable defines the period of time before cached table statistics expire.
#
# The default is 86400 seconds (24 hours). If there are no cached statistics or statistics have expired, statistics
# are retrieved from storage engine when querying table statistics columns.
#
# To update cached values at any time for a given table, use ANALYZE_TABLE
#
# information_schema_stats_expiry can be set to 0 to have INFORMATION_SCHEMA queries retrieve the latest statistics
# directly from the storage engine, which is not as fast as retrieving cached statistics.
#
# For more information, see SECTION 8.2.3, "OPTIMIZING INFORMATION_SCHEMA QUERIES"
#
# 14.6 SERIALIZED DICTIONARY INFORMATION (SDI)
#
# In addition to storing metadata about database objects in the data dictionary, MySQL stores it in
# serialized form.
#
# This data is referred to as Serialized Dictionary Information (SDI)
#
# InnoDB stores SDI data within its tablespace files. Other storage engines store SDI data in .sdi files
# that are created in the schema directory.
#
# SDI data is generated in a compact JSON format.
#
# Serialized Dictionary Information (SDI) is present in all InnoDB tablespace files except for temporary
# tablespace and undo tablespace files.
#
# SDI records in an InnoDB tablespace file only describe table and tablespace objects contained within
# the tablespace.
#
# SDI data in within an InnoDB tablespace file is only updated by DDL operations on tables within the tablespace.
#
# The presence of SDI data provides metadata redundancy. For example, if the data dictionary becomes unavailable,
# object metadata can be extracted directly from InnoDB tablespace files using the ibd2sdi tool.
#
# For InnoDB, an SDI record requires a single index page, which is 16kb in size by default.
#
# However, SDI data is compressed to reduce the storage footprint.
#
# For partitioned InnoDB tables comprised of multiple tablespaces, SDI data is stored in the tablespace
# file of the first partition.
#
# The MySQL server uses an internal API that is accessed during DDL operations to create and maintain SDI
# records.
#
# The IMPORT_TABLE statement imports MyISAM tables based on information contained in .sdi files.
#
# For more information, see SECTION 13.2.5, "IMPORT TABLE SYNTAX"
#
# 14.7 DATA DICTIONARY USAGE DIFFERENCES
#
# Use of a data dictionary enabled MySQL server entails some operational differences compared to a server
# that does not have a data dictionary:
#
# 		) Previously, enabling the innodb_read_only system variable prevented creating and dropping tables only
# 			for the InnoDB storage.
#
# 			As of MySQL 8.0, enabling innodb_read_only prevents these operations for all storage engines.
#
# 			Table creation and drop operations for any storage engine modify data dictionary tables in the mysql
# 			system database, but those tables use the InnoDB storage engine and cannot be modified when innodb_read_only
# 			is enabled.
#
# 			The same principle applies to other table operations that require modifying data dictionary tables.
#
# 			Examples:
#
# 				) ANALYZE TABLE fails because it updates table statistics, which are stored in the data dictionary
#
# 				) ALTER_TABLE_tbl_name_ENGINE=engine_name fails because it updates the storage engine designation,
# 					which is stored in the data dictionary.
#
# NOTE:
#
# 		Enabling innodb_read_only also has important implications for non-data dictionary tables in the mysql
# 		system database.
#
# 		For details, see the description of innodb_read_only in SECTION 15.13, "INNODB STARTUP OPTIONS AND SYSTEM VARIABLES"
#
# 		) Previously, tables in the mysql system database were visible to DML and DDL statements.
#
# 			As of MySQL 8.0, data dictionary tables are invisible and cannot be modified or queried directly.
#
# 			However, in most cases there are corresponding INFORMATION_SCHEMA tables that can be queried
# 			instead.
#
# 			This enables the underlying data dictionary tables to be changed as server development proceeds,
# 			while maintaining a stable INFORMATION_SCHEMA interface for application use.
#
# 		) INFORMATION_SCHEMA tables in MySQL 8.0 are closely tried to the data dictionary, resulting in several
# 			usage differences:
#
# 			) Previously, INFORMATION_SCHEMA queries for table statistics in the STATISTICS and TABLES tables
# 				retrieved statistics directly from storage engines.
#
# 				As of MySQL 8.0, cached table statistics are used by default.
#
# 				The information_schema_stats_expiry system variable defines the period of time before cached
# 				table statistics expire.
#
# 				The default is 86400 (24 hours). (To update the cached values at any time for a given table,
# 				use ANALYZE_TABLE)
#
# 				If there are no cached statistics or statistics have expired, statistics are retrieved from storage
# 				engines when querying table statistics columns.
#
# 				To always retrieve the latest statistics directly from storage engines, set information_schema_stats_expiry
# 				to 0.
#
# 				For more information, see SECTION 8.2.3, "OPTIMIZING INFORMATION_SCHEMA QUERIES"
#
# 			) Several INFORMATION_SCHEMA tables are views on data dictionary tables, which enables the optimizer
# 				to use indexes on those underlying tables.
#
# 				Consequently, depending on optimizer choices, the row order of results for INFORMATION_SCHEMA
# 				queries might differ from previous results.
#
# 				If a query result must have specific row ordering characteristics, include an ORDER BY clause.
#
# 			) mysqldump and mysqlpump no longer dump the INFORMATION_SCHEMA database, even if explicitly
# 				named on the command line.
#
# 			) CREATE_TABLE_dst_tbl_LIKE_src_tbl requires that src_tbl be a base table and fails if it is an
# 				INFORMATION_SCHEMA table that is a view on data dictionary tables.
#
# 			) Previously, result set headers of columns selected from INFORMATION_SCHEMA tables used the
# 				capitalization specified in the query.
#
# 				This query produces a result set with a header of table_name:
#
# 					SELECT table_name FROM INFORMATION_SCHEMA.TABLES;
#
# 				As of MySQL 8.0, these headers are capitalized; the preceding query produces a result set
# 				with a header of TABLE_NAME.
#
# 				If necessary, a column alias can be used to achieve a different lettercase.
#
# 				For example:
#
# 					SELECT table_name AS 'table_name' FROM INFORMATION_SCHEMA.TABLES;
#
# 		) The data directory affects how mysqldump and mysqlpump dump information from the mysql system database:
#
# 			) Previously, it was possible to dump all tables in the mysql system database.
#
# 				As of MySQL 8.0, mysqldump and mysqlpump dump only non-data dictionary tables in that database.
#
# 			) Previously, the --routines and --events options were not required to include stored routines and events
# 				when using the --all-databases option:
#
# 					The dump included the mysql system database, and therefore also the proc and event tables containing
# 					stored routine and event definitions.
#
# 					As of MySQL 8.0, the event and proc tables are not used.
#
# 					Definitions for the corresponding objects are stored in data dictionary tables, but those 
# 					tables are not dumped.
#
# 					To include stored routines and events in a dump made using --all-databases, use the --routines
# 					and --events options explicitly.
#
# 			) Previously, the --routines option required the SELECT privilege for the proc table.
#
# 				AS of MySQL 8.0, that table is not used;
#
# 				--routines requires the global SELECT privilege instead.
#
# 			) Previously, it was possible to dump stored routine and event definitions together with their
# 				creation and modification timestamps, by dumping the proc and event tables.
#
# 				As of MySQL 8.0, those tables are not used, so it is not possible to dump timestamps.
#
# 		) Previously, creating a stored routine that contains illegal characters produced a warning.
#
# 			As of MySQL 8.0, this is an error.
#
# 14.8 DATA DICTIONARY LIMITATIONS
#
# This section describes temporary limitations introduced with the MySQL data dictionary.
#
# 		) Manual creation of database directories under the data directory (for example, with mkdir)
# 			is unsupported.
#
# 			Manually created database directories are not recognized by the MySQL server.
#
# 		) DDL operations take longer due to writing to storage, undo logs, and redo logs instead of .frm files
#
# CHAPTER 15 THE INNODB STORAGE ENGINE
#
# TABLE OF CONTENTS
#
# 15.1 INTRODUCTION TO INNODB
# 15.2 INNODB AND THE ACID MODEL
#
# 15.3 INNODB MULTI-VERSIONING
# 15.4 INNODB ARCHITECHTURE
#
# 15.5 INNODB IN-MEMORY STRUCTURES
# 15.6 INNODB ON-DISK STRUCTURES
#
# 15.7 INNODB LOCKING AND TRANSACTION MODEL
# 15.8 INNODB CONFIGURATION
#
# 15.9 INNODB TABLE AND PAGE COMPRESSION
# 15.10 INNODB ROW FORMATS
#
# 15.11 INNODB DISK I/O AND FILE SPACE MANAGEMENT
# 15.12 INNODB AND ONLINE DDL
#
# 15.13 INNODB STARTUP OPTIONS AND SYSTEM VARIABLES
# 15.14 INNODB INFORMATION_SCHEMA TABLES
#
# 15.15 INNODB INTEGRATION WITH MYSQL PERFORMANCE SCHEMA
# 15.16 INNODB MONITORS
#
# 15.17 INNODB BACKUP AND RECOVERY
# 15.18 INNODB AND MYSQL REPLICATION
#
# 15.19 INNODB MEMCACHED PLUGIN
# 15.20 INNODB TROUBLESHOOTING
#
# 15.1 INTRODUCTION TO INNODB
#
# 15.1.1 BENEFITS OF USING INNODB TABLES
# 15.1.2 BEST PRACTICES FOR INNODB TABLES
#
# 15.1.3 VERIFYING THAT INNODB IS THE DEFAULT STORAGE ENGINE
# 15.1.4 TESTING AND BENCHMARKING WITH INNODB
#
# InnoDB is a general-purpose storage engine that balances high reliability and high performance.
#
# In MySQL 8.0, InnoDB is the default MySQL storage engine. Unless you have configured a different
# default storage engine, issuing a CREATE_TABLE statement without an ENGINE= clause creates
# an InnoDB table.
#
# KEY ADVANTAGES OF INNODB
#
# 		) Its DML operations follow the ACID model, with transactions featuring commit, rollback, and crash-recovery
# 			capabilities to protect user data.
#
# 			See SECTION 15.2, "INNODB AND THE ACID MODEL" for more information
#
# 		) Row-level locking and Oracle-style consistent reads increase multi-user concurrency
# 			and performance.
#
# 			See SECTION 15.7, "InnoDB LOCKING AND TRANSACTION MODEL" for more information.
#
# 		) InnoDB tables arrange your data on disk to optimize queries based on primary keys.
#
# 			Each InnoDB table has a primary key index called the clustered index that organizes
# 			the data to minimize I/O for primary key lookups.
#
# 			See SECTION 15.6.2.1, "CLUSTERED AND SECONDARY INDEXES" for more information
#
# 		) To maintain data integrity, InnoDB supports FOREIGN_KEY constraints.
#
# 			With foreign keys, inserts, updates, and deletes are checked to ensure they do
# 			not result in inconsistencies across different tables.
#
# 			See SECTION 15.6.1.5, "InnoDB AND FOREIGN KEY CONSTRAINTS" for more information
#
# TABLE 15.1 INNODB STORAGE ENGINE FEATURES
#
# 		FEATURE 																											Support
#
# B-tree indexes 											Yes
# 
# Backup/point-in-time recovery (Implemented in the server, rather than in the storage engine) 	Yes
#
# Cluster database support 							No
#
# Clustered indexes 										Yes
#
# Compressed data 										Yes
#
# Data caches 												Yes
#
# Encrypted data 											Yes (Implemented in the server via encryption functions;
# 																In MySQL 5.7 and later, data-at-rest tablespace encryption is supported)
#
# Foreign key support 									Yes
#
# Full-text search indexes 							Yes (InnoDB support for FULLTEXT indexes is available in MySQL 5.6 and later)
#
# Geospatial data type support 						Yes
#
# Geospatial indexing support 						Yes (InnoDB support for geospatial indexing is available in MySQL 5.7 and later)
#
# Hash indexes 											No (InnoDB utilizes hash indexes internally for its Adaptive Hash Index feature)
#
# Index caches 											Yes
#
# Locking granularity 									Row
#
# MVCC 														Yes
#
# Replication support (Implemented in the server, rather than in the storage engine) 		Yes
#
# Storage limits 											64TB
#
# T-tree indexes 											No
#
# Transactions 											Yes
#
# Update statistics for data dictionary 			Yes
#
# To compare the features of InnoDB with other storage engines provided with MySQL, see the
# Storage Engine Features table in CHAPTER 16, ALTERNATIVE STORAGE ENGINES
#
# INNODB ENHANCEMENTS AND NEW FEATURES
#
# For information about InnoDB enhancements and new features, refer to:
#
# 		) The InnoDB enhancements list in SECTION 1.4, "WHAT IS NEW IN MYSQL 8.0"
#
# 		) The RELEASE NOTES
#
# ADDITIONAL INNODB INFORMATION AND RESOURCES
#
# 		) For InnoDB related terms and definitions, see the MySQL Glossary
#
# 		) For a forum dedicated to the InnoDB storage engine, see MySQL Forums::InnoDB
#
# 		) InnoDB is published under the same GNU GPL License Version 2 (of June 1991) as MySQL.
#
# 			For more information on MySQL licensin, see <links>
#
# 15.1.1 BENEFITS OF USING INNODB TABLES
#
# You may find InnoDB tables beneficial for the following reasons:
#
# 		) If your server crashes because of a hardware or software issue, regardless of what was happening
# 			in the database at the time, you do not need to do anything special after restarting the database.
#
# 			InnoDB crash recovery automatically finalizes any changes that were committed before the time of the
# 			crash, and undoes any changes that were in process but not committed.
#
# 			Just restart and continue where you left off.
#
# 		) The InnoDB storage engine maintains its own buffer pool that caches table and index data in main memory
# 			as data is accessed.
#
# 			Frequently used data is processed directly from memory.
#
# 			This cache applies to many types of information and speeds up processing.
#
# 			On dedicated database servers, up to 80% of physical memory is often assigned
# 			to the buffer pool.
#
# 		) If you split up related data into different tables, you can set up foreign keys that enforce
# 			referential integrity.
#
# 			Update or delete data, and the related data in other tables is updated or deleted automatically.
#
# 			Try to insert data into a secondary table without corresponding data in the primary table, and
# 			the bad data gets kicked out automatically.
#
# 		) If data becomes corrupted on disk or in memory, a checksum mechanism alerts you to the bogus data
# 			before you use it.
#
# 		) When you design your database with appropriate primary key columns for each table, operations involving
# 			those columns are automatically optimized.
#
# 			It is very fast to reference the primary key columns in WHERE clauses, ORDER_BY clauses, GROUP_BY clauses,
# 			and join operations.
#
# 		) Inserts, updates, and deletes are optimized by an automatic mechanism called change buffering.
#
# 			InnoDB not only allows concurrent read and write access to the same table, it caches changed
# 			data to streamline disk I/O
#
# 		) Performance benefits are not limited to giant tables with long-running queries.
#
# 			When the same rows are accessed over and over from a table, a feature called the Adaptive Hash Index
# 			takes over to make these lookups even faster, as if they came out of a hash table.
#
# 		) You can compress tables and associated indexes.
#
# 		) You can create and drop indexes with much less impact on performance and availability
#
# 		) Truncating a file-per-table tablespace is very fast, and can free up disk space for the operating
# 			system to reuse, rather than freeing up space within the system tablespace that only InnoDB can reuse.
#
# 		) The storage layout for table data is more efficient for BLOB and long text fields, with the DYNAMIC row format.
#
# 		) You can monitor the internal workings of the storage engine by querying INFORMATION_SCHEMA tables
#
# 		) You can monitor the performance details of the storage engine by querying Performance Schema tables.
#
# 		) You can freely mix InnoDB tables with tables from other MySQL storage engines, even within the same statement.
#
# 			For example, you can use a join operation to combine data from InnoDB and MEMORY tables in a single query.
#
# 		) InnoDB has been designed for CPU efficiency and maximum performance when processing large data volumes
#
# 		) InnoDB tables can handle large quantities of data, even on operating systems where file size is limited to 2GB
#
# For InnoDB-specific tuning techniques you can apply in your application code, see SECTION 8.5, "OPTIMIZING FOR INNODB TABLES"
#
# 15.1.2 BEST PRACTICES FOR INNODB TABLES
#
# This section describes best practices when using InnoDB tables.
#
# 		) Specifying a primary key for every table using the most frequently queried column or columns,
# 			or an auto-increment value if there is no obvious primary key
#
# 		) Using joins wherever data is pulled from multiple tables based on identical ID values from those tables.
#
# 			For fast join performance, define foreign keys on the join columns, and declare those columns with the same
# 			data type in each table.
#
# 			Adding foreign keys ensures that referenced columns are indexed, which can improve performance.
#
# 			Foreign key also propagate deletes or updates to all affected tables, and prevent insertion of data
# 			in a child table if the corresponding IDs are not present in the parent table.
#
# 		) Turning off autocommit. Committing hundreds of times a second puts a cap on performance (limited by the write speed
# 			of your storage device)
#
# 		) Grouping sets of related DML operations into transactions, by bracketing them with START TRANSACTION and COMMIT
# 			statements.
#
# 			While you don't want to commit too often, you also don't want to issue huge batches of INSERT, UPDATE or DELETE
# 			statements that run for hours without committing.
#
# 		) Not using LOCK_TABLES statements.
#
# 			InnoDB can handle multiple sessions all reading and writing to the same table at once,
# 			without sacrificing reliability or high performance.
#
# 			To get exclusive write access to a set of rows, use the SELECT_---_FOR_UPDATE syntax to
# 			lock just the rows you intend to update.
#
# 		) Enabling the innodb_file_per_table option or using general tablespaces to put the data and indexes
# 			for tables into separate files, instead of the system tablespace.
#
# 			The innodb_file_per_table option is enabled by default.
#
# 		) Evaluating whether your data and access patterns benefit from the InnoDB table or page compression
# 			features.
#
# 			You can compress InnoDB tables without sacrificing read/write capability.
#
# 		) Running your server with the option --sql_mode=NO_ENGINE_SUBSTITUTION to prevent tables being created
# 			with a different storage engine if there is an issue with the engine specified in the ENGINE=
# 			clause of CREATE_TABLE
#
# 15.1.3 VERIFYING THAT INNODB IS THE DEFAULT STORAGE ENGINE
#
# Issue the SHOW_ENGINES statement to view the available MySQL storage engines.
#
# Look for DEFAULT in the InnoDB line.
#
# 		SHOW ENGINES;
#
# Alternatively, query the INFORMATION_SCHEMA.ENGINES table.
#
# 		SELECT * FROM INFORMATION_SCHEMA.ENGINES;
#
# 15.1.4 TESTING AND BENCHMARKING WITH INNODB
#
# If InnoDB is not your default storage engine, you can determine if your database server or applications
# work correctly with InnoDB by restarting the server with --default-storage-engine=InnoDB defined on the
# command line or with default-storage-engine=innodb defined in the [mysqld] section of your MySQL server
# option file.
#
# Since changing the default storage engine only affects new tables as they are created, run all your
# application installation and setup steps to confirm that everything installs properly.
#
# Then exercise all the application features to make sure all the data loading, editing, and querying
# features work.
#
# If a table relies on a feature that is specific to another storage engine, you will receive an error;
# add the ENGINE=other_engine_name clause to the CREATE_TABLE statement to avoid the error.
#
# If you did not make a deliberate decision about the storage engine, and you want to preview how
# certain tables work when created using InnoDB, issue the command ALTER_TABLE_table_name_ENGINE=InnoDB;
# for each table.
#
# Or, to run test queries and other statements without disturbing the original table, make a copy:
#
# 		CREATE TABLE InnoDB_Table (---) ENGINE=InnoDB AS SELECT * FROM other_engine_table;
#
# To assess performance with a full application under a realistic workload, install the latest
# MySQL server and run benchmarks.
#
# Test the full application lifecycle, from installation, through heavy usage, and server restart.
#
# Kill the server process while the database is busy to simulate a power failure, and verify that
# the data is recovered successfully when you restart the server.
#
# Test any replication configurations, especially if you use different MySQL versions and options
# on the master and slaves.
#
# 15.2 InnoDB AND THE ACID MODEL
#
# The ACID model is a set of database design principles that emphasize aspects of reliability that are
# important for business data and mission-critical applications.
#
# MySQL includes components such as the InnoDB storage engine that adhere closely to the ACID model,
# so that data is not corrupted and results are not distorted by exceptional conditions such as
# software crashes and hardware malfunctions.
#
# When you rely on ACID-compliant features, you do not need to reinvent the wheel of consistency
# checking and crash recovery mechanisms.
#
# In cases where you have additional software safeguards, ultra-reliable hardware, or an application
# that can tolerate a small amount of data loss or inconsistency, you can adjust MySQL settings to trade
# some of the ACID reliability for greater performance or throughput.
#
# The following sections discuss how MySQL features, in particular the InnoDB storage engine, interact
# with the categories of the ACID model:
#
# 		) A: atomicity
#
# 		) C: Consistency
#
# 		) I: Isolation
#
# 		) D: durability
#
# ATOMICITY
#
# The atomicity aspect of the ACID model mainly involves InnoDB transactions.
#
# Related MySQL features include:
#
# 		) Autocommit setting
#
# 		) COMMIT statement
#
# 		) ROLLBACK statement
#
# 		) Operational data from the INFORMATION_SCHEMA tables
#
# CONSISTENCY
#
# The consistency aspect of the ACID model mainly involves internal InnoDB processing to
# protect data from crashes.
#
# Related MySQL features include:
#
# 		) InnoDB doublewrite buffer
#
# 		) InnoDB crash recovery
#
# ISOLATION
#
# The isolation aspect of the ACID model mainly involves InnoDB transactions, in particular the isolation level 
# that applies to each transaction.
#
# Related MySQL features include:
#
# 		) Autocommit setting
#
# 		) SET ISOLATION LEVEL statement
#
# 		) The low-level details of InnoDB locking. During performance tuning, you see these details through
# 			INFORMATION_SCHEMA tables.
#
# DURABILITY
#
# The durability aspect of the ACID model involves MySQL software features interacting with your
# particular hardware configuration.
#
# Because of the many possibilities depending on the capabilities of your CPU, network, and storage
# devices, this aspect is the most complicated to provide concrete guidelines for.
#
# (And those guidelines might take the form of buy "new hardware")
#
# Related MySQL features include:
#
# 		) InnoDB doublewrite buffer, turned on and off by the innodb_doublewrite configuration option
#
# 		) Configuration option innodb_flush_log_at_trx_commit
#
# 		) Configuration option sync_binlog
#
# 		) Configuration option innodb_file_per_table
#
# 		) Write buffer in a storage device, such as a disk drive, SSD, or RAID array
#
# 		) Battery-backed cache in a storage device
#
# 		) The operating system used to MySQL, in particular its support for the fsync() system call
#
# 		) Uninterruptible power supply (UPS) protecting the electrical power to all computer servers and storage
# 			devices that run MySQL servers and store MySQL data.
#
# 		) Your backup strategy, such as frequency and types of backups, and backup retention periods.
#
# 		) For distributed or hosted data applications, the particular characteristics of the data centers
# 			where the hardware for the MySQL servers is located, and network connections between the data
# 			centers.
#
# 15.3 INNODB MULTI-VERSIONING
#
# InnoDB is a multi-versioned storage engine: it keeps information about old versions of changed rows,
# to support transactional features such as concurrency and rollback.
#
# This information is stored in the tablespace in a data structure called a rollback segment (after an
# analogous data structure in Oracle)
#
# InnoDB uses the information in the rollback segment to perform the undo operations needed in a transaction
# rollback.
#
# It also uses the information to build earlier versions of a row for a consistent read.
#
# Internally, InnoDB adds three fields to each row stored in the database. A 6-byte DB_TRX_ID
# field indicates the transaction identifier for the last transaction that inserted or updated
# the row.
#
# Also, a deletion is treated internally as an update where a special bit in the row is set
# to mark it as deleted.
#
# Each row also contains a 7-byte DB_ROLL_PTR field called the roll pointer.
#
# The roll pointer points to an undo log record written to the rollback segment.
#
# If the row was updated, the undo log record contains the information necessary
# to rebuild the content of the row before it was updated.
#
# A 6-byte DB_ROW_ID field contains a row ID that increases monotonically as new rows are
# inserted.
#
# If InnoDB generates a clustered index automatically, the index contains row ID values.
#
# Otherwise, the DB_ROW_ID column does not appear in any index.
#
# Undo logs in the rollback segment are divided into insert and update undo logs.
# Insert undo logs are needed only in transaction rollback and can be discarded as
# soon as the transaction commits.
#
# Update undo logs are used also in consistent reads, but they can be discarded
# only after there is no transaction present for which InnoDB has assigned a snapshot
# that in a consistent read could need the information in the update undo log to build
# an earlier version of a database row.
#
# Commit your transactions regularly, including those transactions that issue only consistent
# reads.
#
# Otherwise, InnoDB cannot discard data from the update undo logs, and the rollback segment
# may grow too big, filling up your tablespace.
#
# The physical size of an undo log record in the rollback segment is typically smaller than the
# corresponding inserted or updated row.
#
# You can use this information to calculate the space needed for your rollback segment.
#
# In the InnoDB multi-versioning scheme, a row is not physically removed from the database
# immediately when you delete it with an SQL statement.
#
# InnoDB only physically removes the corresponding row and its index records when it discards
# the update undo log record written for the deletion.
#
# This removal operation is called a purge, and it is quite fast, usually taking the same order
# of time as the SQL statement that did the deletion.
#
# If you insert and delete rows in smallish batches at about the same rate in the table, the purge
# thread can start to lag behind and the table can grow bigger and bigger because of all the
# "dead" rows, making everything disk-bound and very slow.
#
# In such a case, throttle new row operations, and allocate more resources to the purge thread
# by tuning the innodb_max_purge_lag system variable.
#
# See SECTION 15.13, "InnoDB STARTUP OPTIONS AND SYSTEM VARIABLES" for more information
#
# MULTI-VERSIONING AND SECONDARY INDEXES
#
# InnoDB multiversion concurrency control (MVCC) treats secondary indexes differently than
# clustered indexes.
#
# Records in a clustered index are updated-in-place, and their hidden system columns point
# undo log entries from which earlier versions of records can be reconstructed.
#
# Unlike clustered index records, secondary index records do not contain hidden system
# columns nor are they updated in-place.
#
# When a secondary index column is updated, old secondary index records are delete-marked,
# new records are inserted, and delete-marked records are eventually purged.
#
# When a secondary index record is delete-marked or the secondary index page is updated
# by a newer transaction, InnoDB looks up the database record in the clustered index.
#
# In the clustered index, the record's DB_TRX_ID is checked, and the correct version of
# the record is retrieved from the undo log if the record was modified after the reading 
# transaction was initiated.
#
# If a secondary index record is marked for deletion or the secondary index page is updated
# by a newer transaction, the covering index technique is not used.
#
# Instead of returning values from the index structure, InnoDB looks up the record in the
# clustered index.
#
# However, if the index condition pushdown (ICP) optimization is enabled, and parts of the
# WHERE condition can be evaluated using only fields from the index, the MySQL server still
# pushes this part of the WHERE condition down to the storage engine where it is evaluated
# using the index.
#
# If no matching records are found, the clustered index lookup is avoided.
#
# If matching records are found, even among delete-marked records, InnoDB looks
# up the record in the clustered index.
#
# 15.4 INNODB ARCITECHTURE
#
# The following refers to in-memory and on-disk structures that comprise the InnoDB
# storage engine architechture.
#
# For information about each structure, see SECTION 15.5, "InnoDB IN-MEMORY STRUCTURES"
# and SECTION 15.6, "INNODB ON-DISK STRUCTURES"
#
# FIGURE 15.1 INNODB ARCHITECHTURE
#
# 		In-Memory Structures 												On-Disk Structures 				File-per-table tablespaces
# 		
# 			Buffer Pool -> O_DIRECT | OS CACHE | -> O_DIRECT  |	System Tablespace	| 				innodb_file_per_table=ON
# 			 																		(ibdata1)  								t1.ibd t2.ibd
# 	Adaptive Hash INdex  													
# 																					Doublewrite Buffer 
#
# 																					Change Buffer
#											| OS CACHE |
# 																																General Tablespaces
#												VVVVVV 
# 																															ts1.ibd -> t3 t4 t5
# 																															ts2.ibd -> t6 t7 t8
#
# 			Change Buffer 														Undo Tablespaces
#											| OS CACHE | 
# 																					undo_001 undo_003.ibu
# 												VVVVV
# 																					undo_002 (system) 
# 											| OS CACHE | 						undo_004.ibu (user-defined) 				Temporary Tablespaces

# 		|	Log Buffer 		| 			| OS CACHE |							| Redo Log | 										ibtmp1 (global)
#
# 																				V	| ib_logfile0 | <									temp_1.ibt, temp_2.ibt, temp_3.ibt (Session)
# 																				>  | ib_logfile1 | ^
# 			
#
# 
# 15.5 INNODB IN-MEMORY STRUCTURES
#
# 15.5.1 BUFFER POOL
# 15.5.2 CHANGE BUFFER
# 15.5.3 ADAPTIVE HASH INDEX
# 15.5.4 LOG BUFFER
#
# This section describes InnoDB in-memory structures and related topics.
#
# 15.5.1 BUFFER POOL
#
# The buffer pool is an area in main memory where caches table and index data as it is
# accessed.
#
# The buffer pool permits frequently used data to be processed directly from memory,
# which speeds up processing.
#
# On dedicated servers, up to 80% of physical memory is often assigned to the buffer pool.
#
# For efficiency of high-volume read operations, the buffer pool is divided into pages that
# can potentially hold multiple rows.
#
# For efficiency of cache management, the buffer pool is implemented as a linked list of
# pages; data that is rarely used is aged out of the cache using a variation of the LRU
# algorithm.
#
# Knowing how to take advantage of the buffer pool to keep frequently accessed data in
# memory is an important aspect of MySQL tuning.
#
# BUFFER POOL LRU ALGORITHM
#
# The buffer pool is managed as a list using a variation of the least recently used (LRU)
# algorithm.
#
# When room is needed to add a new page to the buffer pool, the least recently used
# page is evicted and a new page is added to the middle of the list.
#
# This midpoint insertion strategy treats the list as two sublists:
#
# 		) At the head, a sublist of new ("young") pages that were accessed recently
#
# 		) At the tail, a sublist of old pages that were accessed less recently
#
# FIGURE 15.2 BUFFER POOL LIST
#							+------+ ^
# 							| HEAD | | Accessed pages are made young
# 							+------+ |
# 							|  5/8 | 	| Unused pages become old
# 			New Sublist	|buffer|    |
# 							| pool |		v
# 							|      |
# 							+------+
# Midpoint insertion | Tail |
# 			------------+------+
# of pages read into	| Head |
# the buffer pool 	+------+
# 							| 3/8  |
# 			Old Sublist	|buffer|
# 							| pool |
# 							+------+
# 							| Tail |
# 							+------+
# 							  V V V Pages that remain unused are eventually evicted
#
# The algorithm keeps pages that are heavily used by queries in the new sublist.
#
# The old sublist contains less-used pages; these pages are candidates for eviction.
#
# By default, the algorithm operates as follows:
#
# 		) 3/8 of the buffer pool is devoted to the old sublist
#
# 		) The midpoint of the list is the boundary where the tail of the new sublist meets the head of the old sublist
#
# 		) When InnoDB reads a page into the buffer pool, it initially inserts it at the midpoint
# 			(the head of the old sublist)
#
# 			A page can be read because it is required for a user-specified operation such as an SQL
# 			query, or as part of a read-ahead operation performed automatically by InnoDB
#
# 		) Accessing a page in the old sublist makes it "young", moving it to the head of the buffer pool
# 			(the head of the new sublist)
#
# 			If the page was read because it was required, the first access occurs immediately and the
# 			page is made young.
#
# 			If the page was read due to read-ahead, the first access does not occur immediately (and might
# 			not occur at all before the page is evicted)
#
# 		) As the database operates, pages in the buffer pool that are not accessed "age" by moving toward the
# 			tail of the list.
#
# 			Pages in both the new and old sublists age as other pages are made new.
#
# 			Pages in the old sublist also age as pages are inserted at the midpoint.
#
# 			Eventually, a page that remains unused reaches the tail of the old sublist
# 			and is evicted.
#
# By default, pages read by queries immediately move into the new sublist, meaning they stay
# in the buffer pool longer.
#
# A table scan (such as performed for a mysqldump operation, or a SELECT statement with no WHERE
# clause) can bring a large amount of data into the buffer pool and evict an equivalent amount of older
# data, even if the new data is never used again.
#
# Similarly, pages that are loaded by the read-ahead background thread and then accessed only once move
# to the head of the new list.
#
# These situations can push frequently used pages to the old sublist where they become subject to eviction.
#
# For information about optimizing this behavior, see SECTION 15.8.3.3, "MAKING THE BUFFER POOL SCAN RESISTANT"
# and SECTION 15.8.3.4, "CONFIGURING INNODB BUFFER POOL PREFETCHING (READ-AHEAD)"
#
# InnoDB Standard Monitor output contains several fields in the BUFFER POOL AND MEMORY section regarding
# operation of the buffer pool LRU algorithm.
#
# For details, see MONITORING THE BUFFER POOL USING THE INNODB STANDARD MONITOR
#
# BUFFER POOL CONFIGURATION
#
# You can configure the various aspects of the buffer pool to improve performance.
#
# 		) Ideally, you set the size of the buffer pool to as large a value as practical, leaving enough
# 			memory for other processes on the server to run without excessive paging.
#
# 			The larger the buffer pool, the more InnoDB acts like an in-memory database, reading data from
# 			disk once and then accessing the data from memory during subsequent reads.
#
# 			See SECTION 15.8.3.1, "CONFIGURING INNODB BUFFER POOL SIZE"
#
# 		) On 64-bit systems with sufficient memory, you can split the buffer pool into multiple parts
# 			to minimize contention for memory structures among concurrent operations.
#
# 			For details, see SECTION 15.8.3.2, "CONFIGURING MULTIPLE BUFFER POOL INSTANCES"
#
# 		) You can keep frequently accessed data in memory regardless of sudden spikes of activity
# 			from operations that would bring large amounts of infrequently accessed data into the
# 			buffer pool.
#
# 			For details, see SECTION 15.8.3.3, "MAKING THE BUFFER POOL SCAN RESISTANT"
#
# 		) You can control when and how to perform read-ahead requests to prefetch pages into the buffer
# 			pool asynchronously in anticipation that the pages will be needed soon.
#
# 			For details, see SECTION 15.8.3.4, "CONFIGURING INNODB BUFFER POOL PREFETCHING (READ-AHEAD)"
#
# 		) You can control when background flushing occurs and whether or not the rate of flushing is dynamically
# 			adjusted based on workload.
#
# 			For details, see SECTION 15.8.3.5, "CONFIGURING INNODB BUFFER POOL FLUSHING"
#
# 		) You can fine-tune aspects of buffer pool flushing behavior to improve performance.
#
# 			For details, see SECTION 15.8.3.6, "FINE-TUNING INNODB BUFFER POOL FLUSHING"
#
# 		) You can configure how InnoDB preserves the current buffer pool state to avoid a lengthy
# 			warmup period after a server restart.
#
# 			For details, see SECTION 15.8.3.7, "SAVING AND RESTORING THE BUFFER POOL STATE"
#
# MONITORING THE BUFFER POOL USING THE INNODB STANDARD MONITOR
#
# InnoDB Standard Monitor output, which can be accessed using SHOW_ENGINE_INNODB_STATUS, provides
# metrics regarding operation of the buffer pool.
#
# Buffer pool metrics are located in the BUFFER POOL AND MEMORY section of InnoDB Standard Monitor
# output and appear similar to the following:
#
# 		--------------------------
# 		BUFFER POOL AND MEMORY
# 		--------------------------
# 		Total large memory allocated 2198863872
# 		Dictionary memory allocated 776332
# 		Buffer pool size 				 131072
# 		Free buffers 	  				 124908
# 		Database pages   				 5720
# 		Old database pages 			 2071
# 		Modified db pages 			 910
# 		Pending reads 					 0
# 		Pending writes: LRU 0, flush list 0, single page 0
# 		Pages made young 4, not young 0
# 		0.10 youngs/s, 0.00 non-youngs/s
# 		Pages read 197, 190.89 creates/s, 244.94 writes/s
# 		0.00 reads/s, 190.89 creates/s, 244.94 writes/s
# 		Buffer pool hit rate 1000 / 1000, young-making rate 0 / 1000 not
# 		0 / 1000
# 		Pages read ahead 0.00/s, evicted without access 0.00/s Random read
# 		ahead 0.00/s
# 		LRU len: 5720, unzip_LRU len: 0
# 		I/O sum[0]:cur[0], unzip sum[0]:cur[0]
#
# The following table describes buffer pool metrics reported by the InnoDB Standard Monitor.
#
# NOTE:
#
# 		Per second averages provided in InnoDB Standard Monitor output are based on the elapsed
# 		time since InnoDB Standard Monitor output was last printed.
#
# TABLE 15.2 INNODB BUFFER POOL METRICS
#
# 		NAME 													DESCRIPTION
#
# Total memory allocated 			The total memory allocated for the buffer pool in bytes.
#
# Dictionary memory allocated 	The total memory allocated for the InnoDB data dictionary in bytes.
#
# Buffer pool size 					The total size in pages allocated to the buffer pool
#
# Free buffers 						The total size in pages of the buffer pool free list
#
# Database pages 						The total size in pages of the buffer pool LRU list
#
# Old database pages 				The total size in pages of the buffer pool old LRU sublist
#
# Modified db pages 					The current number of pages modified in the buffer pool
#
# Pending reads 						The number of buffer pool pages waiting to be read into the buffer pool
#
# Pending writes LRU 				The number of old dirty pages within the buffer pool to be written from the bottom of the LRU list
#
# Pending writes flush list 		The number of buffer pool pages to be flushed during checkpointing
#
# Pending writes single page 		The number of pending independent page writes within the buffer pool
#
# Pages made young 					The total number of pages made young in the buffer pool LRU list (moved to the head of sublist of "new" pages)
#
# Pages made not young 				The total number of pages not made young in the buffer pool LRU list (pages that have remained in the "old" sublist
# 											without being made young)
#
# youngs/s 								The per second average of accesses to old pages in the buffer pool LRU list that have resulted in making
# 											pages young. See the notes that follow this table for more information.
#
# non-youngs/s 						The per second average of accesses to old pages in the buffer pool LRU list that have resulted in not making
# 											pages young. See the notes that follow this table for more information.
#
# Pages read 							The total number of pages read from the buffer pool
#
# Pages created 						The total number of pages created within the buffer pool
#
# Pages written 						The total number of pages written from the buffer pool
#
# reads/s 								The per second average number of buffer pool page reads per second
#
# creates/s 							The per second average number of buffer pool pages created per second
#
# writes/s 								The per second average number of buffer pool page writes per second
#
# Buffer pool hit rate 				The buffer pool page hit rate for pages read from the buffer pool memory vs from disk storage
#
# young-making rate 					The average hit rate at which page accesses have resulted in making pages young.
#
# 											See the notes that follow this table for more information
#
# not (young-making rate) 			The average hit rate at which page accesses have not resulted in making pages young.
#
# 											See the notes that follow this table for more information
#
# Pages read ahead 					The per second average of read ahead operations
#
# Pages evicted without access 	The per second average of the pages evicted without being accessed from the buffer pool
#
# Random read ahead 					The per second average of random read ahead operations
#
# LRU len 								The total size in pages of the buffer pool LRU list
#
# unzip_LRU len 						The total size in pages of the buffer pool unzip_LRU list
#
# I/O sum 								The total number of buffer pool LRU list pages accessed, for the last 50 seconds
#
# I/O cur 								The total number of buffer pool LRU list pages accessed
#
# I/O unzip sum 						The total number of buffer pool unzip_LRU list pages accessed
#
# I/O unzip cur 						The total number of buffer pool unzip_LRU list pages accessed
#
# NOTES:
#
# 		) The young/s metric is applicable only to old pages.
#
# 			It is based on the number of accesses to pages and not the number of pages.
#
# 			There can be multiple accesses to a given page, all of which are counted.
#
# 			If you see very low youngs/s values when there are no large scans occurring,
# 			you might need to reduce the delay time or increase the percentage of the buffer
# 			pool used for the old sublist.
#
# 			Increasing the percentage makes the old sublist larger, so pages in that sublist
# 			take longer to move to the tail, which increases the likelihood that those pages
# 			will be accessed again and made young.
#
# 		) The non-youngs/s metric is applicable only to old pages.
#
# 			It is based on the number of accesses to pages and not the number of pages.
#
# 			There can be multiple accesses to a given page, all of which are counted.
# 			If you do not see a higher non-youngs/s value when performing large table scans
# 			(and a higher youngs/s value), increase the delay value.
#
# 		) The young-making rate accounts for accesses to all buffer pool pages, not just
# 			accesses to pages in the old sublist.
#
# 			The young-making rate and not rate do not normally add up to the overall buffer
# 			pool hit rate.
#
# 			Page hits in the old sublist cause pages to move to the new sublist, but page hits
# 			in the new sublist causes pages to move to the head of the list only if they are
# 			a certain distance from the head.
#
# 		) not (young-making rate) is the average hit rate at which page accesses have not resulted
# 			in making pages young due to the delay defined by innodb_old_blocks_time not being met,
# 			or due to page hits in the new sublist that did not result in pages being moved to the head.
#
# 			This rate accounts for accesses to all buffer pool pages, not just accesses to pages in the
# 			old sublist.
#
# Buffer pool server status variables and the INNODB_BUFFER_POOL_STATS table provide many of the
# same buffer pool metrics found in InnoDB Standard Monitor output.
#
# For more information, see EXAMPLE 15.10, "QUERYING THE INNODB_BUFFER_POOL_STATS TABLE"
#
# 15.5.2 CHANGE BUFFER
#
# The change buffer is a special data structure that caches changes to secondary index pages when
# those pages are not in the buffer pool.
#
# The buffered changes, which may result from INSERT, UPDATE or DELETE operations (DML), are merged
# later when the pages are loaded into the buffer pool by other read operations.
#
# 											FIGURE 15.3 CHANGE BUFFER
#
# 										The purge operation periodically and efficiently writes 
# 										updated index pages to disk
#
# 											| Buffer Pool | -> DISK
#
# Changes to secondary index  			^ ^ ^ 			V
# pages that are not in the  									--> Changes are periodically merged as secondary index pages 
# buffer pool are cached in >>	| Change Buffer |    ^ 	 are read into the buffer pool
# the change buffer
#
# Unlike clustered indexes, secondary indexes are usually nonunique, and inserts into secondary
# indexes happen in a relatively random order.
#
# Similarly, deletes and updates may affect secondary index pages that are not adjacently located
# in an index tree.
#
# Merging cached changes at a later time, when affected pages are read into the buffer
# pool by other operations, avoids substansial random access I/O that would be required to
# read secondary index pages into the buffer pool from disk.
#
# Periodically, the purge operation that runs when the system is mostly idle, or during a slow
# shutdown, writes the updated index pages to disk.
#
# The purge operation can write disk blocks for a series of index values more efficiently
# than if each value were written to disk immediately.
#
# Change buffer merging may take several hours when there are many affected rows and numerous
# secondary indexes to update.
#
# During this time, disk I/O is increased, which can cause a significant slowdown for disk-bound
# queries.
#
# Change buffer merging may also continue to occur after a transaction is committed, and even
# after a server shutdown and restart (see SECTION 15.20.2, "FORCING INNODB RECOVERY" for more information)
#
# In memory, the change buffer occupies part of the buffer pool. On disk, the change buffer is part of
# the system tablespace, where index changes are buffered when the database server is shut down.
#
# The type of data cached in the change buffer is governed by the innodb_change_buffering variable.
#
# For more information, see CONFIGURING CHANGE BUFFERING. You can also configure the maximum change
# buffer size.
#
# For more information, see CONFIGURING THE CHANGE BUFFER MAXIMUM SIZE
#
# Change buffering is not supported for a secondary index if the index contains a descending
# index column or if the primary key includes a descending index column.
#
# For answers to frequently asked questions about the change buffer, see SECTION A.15, "MYSQL 8.0 FAQ: INNODB CHANGE BUFFER"
#
# CONFIGURING CHANGE BUFFERING
#
# When INSERT, UPDATE and DELETE operations are performed on a table, the values of indexed columns
# (particularly the values of secondary keys) are often in an unsorted order, requiring substansial
# I/O to bring secondary indexes up to date.
#
# The change buffer caches changes to secondary index entries when the relevant page is not in the
# buffer pool, thus avoiding expensive I/O operations by not immediately reading in the page from disk.
#
# The buffered changes are merged when the page is loaded into the buffer pool, and the updated page
# is later flushed to disk.
#
# The InnoDB main thread merges buffered changes when the server is nearly idle, and during
# a slow shutdown.
#
# Because it can result in fewer disk reads and writes, the change buffer feature is most valuable
# for workloads that are I/O-bound, for example applications with a high volume of DML operations
# such as bulk inserts.
#
# However, the change buffer occupies a part of the buffer pool, reducing the memory available to cache
# data pages.
#
# If the working set almost fits in the buffer pool, or if your tables have relatively few secondary
# indexes, it may be useful to disable change buffering.
#
# If the working data set fits entirely within the buffer pool, change buffering does not impose extra
# overhead, because it only applies to pages that are not in the buffer pool.
#
# You can control the extent to which InnoDB performs change buffering using the innodb_change_buffering
# configuration parameter.
#
# You can enable or disable buffering for inserts, delete operations (when index records are initially
# marked for deletion) and purge operations (when index records are physically deleted)
#
# An update operation is a combination of an insert and a delete. The default innodb_change_buffering
# value is all.
#
# Permitted innodb_change_buffering values include:
#
# 		) all
#
# 			The default value: buffer inserts, delete-marking operations and purges
#
# 		) none
#
# 			Do not buffer any operations
#
# 		) inserts
#
# 			Buffer insert operations
#
# 		) deletes
#
# 			Buffer delete-marking operations
#
# 		) changes
#
# 			Buffer both inserts and delete-marking operations
#
# 		) purges
#
# 			Buffer the physical deletion operations that happen in the background
#
# You can set the innodb_change_buffering parameter in the MySQL option file (my.cnf or my.ini)
# or change it dynamically with the SET_GLOBAL statement, which requires privileges sufficient
# to set global system variables.
#
# See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES"
#
# Changing the setting affects the buffering of new operations; the merging of existing
# buffered entries is not affected.
#
# CONFIGURING THE CHANGE BUFFER MAXIMUM SIZE
#
# The innodb_change_buffer_max_size variable permits configuring the maximum size of the
# change buffer as a percentage of the total size of the buffer pool.
#
# By default, innodb_change_buffer_max_size is set to 25
#
# The maximum setting is 50
#
# Consider increasing innodb_change_buffer_max_size on a MySQL server with heavy insert,
# update and delete activity, where change buffer merging does not keep pace with new
# change buffer entries, causing the change buffer to reach its maximum size limit.
#
# Consider decreasing innodb_change_buffer_max_size on a MySQL server with static data
# used for reporting, or if the change buffer consumes too much of the memory space shared
# with the buffer pool, causing pages to age out of the buffer pool sooner than desired.
#
# Test different settings with a representative workload to determine an optimal configuration.
#
# The innodb_change_buffer_max_size setting is dynamic, which permits modifying the setting
# without restarting the server.
#
# MONITORING THE CHANGE BUFFER
#
# The following options are available for change buffer monitoring:
#
# 		) InnoDB Standard Monitor output includes change buffer status information.
#
# 			To view monitor data, issue the SHOW ENGINE INNODB STATUS statement.
#
# 				SHOW ENGINE INNODB STATUS\G
#
# 			Change buffer status information is located under the INSERT BUFFER AND ADAPTIVE HASH INDEX
# 			heading and appears similar to the following:
#
# 				----------------------------------
# 				INSERT BUFFER AND ADAPTIVE HASH INDEX
# 				----------------------------------
# 				Ibuf: size 1, free list len 0, seg size 2, 0 merges
# 				merged operations:
# 					insert 0, delete mark 0, delete 0
# 				discarded operations:
# 					insert 0, delete mark 0, delete 0
# 				Hash table size 4425293, used cells 32, node heap has 1 buffer(s)
# 				13577.57 hash searches/s, 202.47 non-hash searches/s
#
# 			For more information, see SECTION 15.16.3, "INNODB STANDARD MONITOR AND LOCK MONITOR OUTPUT"
#
# 		) The INFORMATION_SCHEMA.INNODB_METRICS table provides most of the data points found in InnoDB
# 			Standard Monitor output, plus other data points.
#
# 			To view change buffer metrics and a description of each, issue the following query:
#
# 				SELECT NAME, COMMENT FROM INFORMATION_SCHEMA.INNODB_METRICS WHERE NAME LIKE '%ibuf%'\G
#
# 			For INNODB_METRICS table usage information, see SECTION 15.14.6, "INNODB INFORMATION_SCHEMA METRICS TABLE"
#
# 		) The INFORMATION_SCHEMA.INNODB_BUFFER_PAGE table provides metadata about each page in the buffer pool,
# 			including change buffer index and change buffer bitmap pages.
#
# 			Change buffer pages are identified by PAGE_TYPE.IBUF_INDEX is the page type for change buffer index pages,
# 			and IBUF_BITMAP is the page type for change buffer bitmap pages.
#
# 				WARNING:
#
# 					Querying the INNODB_BUFFER_PAGE table can introduce significant performance overhead.
#
# 					To avoid impacting performance, reproduce the issue you want to investigate on a test
# 					instance and run your queries on the test instance.
#
# 			For example, you can query the INNODB_BUFFER_PAGE table to determine the approximate number of
# 			IBUF_INDEX and IBUF_BITMAP pages as a percentage of total buffer pool pages.
#
# 				SELECT (SELECT COUNT(*) FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGE
# 				WHERE PAGE_TYPE LIKE 'IBUF%') AS change_buffer_pages,
# 				(SELECT COUNT(*) FROM INFORMATION_SCHEMA.INNODB_BUFFER_PAGE) AS total_pages,
# 				(SELECT ((change_buffer_pages/total_pages)*100))
# 				AS change_buffer_page_percentage;
# 				+-------------------------------+--------------------+------------------------------------------+
# 				| change_buffer_pages 			  | total_pages 		  | change_buffer_page_percentage 				|
# 				+-------------------------------+--------------------+------------------------------------------+
# 				| 25 									  | 8192 				  | 0.3052 												|
# 				+-------------------------------+--------------------+------------------------------------------+
#
# 			For information about other data provided by the INNODB_BUFFER_PAGE table, see SECTION 25.38.1, "THE INFORMATION_SCHEMA
# 			INNODB_BUFFER_PAGE TABLE"
#
# 			For related usage information, see SECTION 15.14.5, "INNODB INFORMATION_SCHEMA BUFFER POOL TABLES"
#
# 		) Performance Schema provides change buffer mutex wait instrumentation for advanced performance monitoring.
#
# 			To view change buffer instrumentation, issue the following query:
#
# 				SELECT * FROM performance_schema.setup_instruments
# 				WHERE NAME LIKE '%wait/synch/mutex/innodb/ibuf%';
# 				+--------------------------------------------------------+--------------+------------+
# 				| NAME 																 	| ENABLED 		 | TIMED 	 |
# 				+--------------------------------------------------------+--------------+------------+
# 				| wait/synch/mutex/innodb/ibuf_bitmap_mutex 				 	| YES 			 | YES 		 |
# 				| wait/synch/mutex/innodb/ibuf_mutex 						 	| YES 			 | YES 		 |
# 				| wait/synch/mutex/innodb/ibuf_pessimistic_insert_mutex  | YES 			 | YES 		 |
# 				+--------------------------------------------------------+---------------+-----------+
#
# 			For information about monitoring InnoDB mutex waits, see SECTION 15.15.2, "MONITORING INNODB MUTEX WAITS USING PERFORMANCE SCHEMA"
#
# 15.5.3 ADAPTIVE HASH INDEX
#
# The adaptive hash index feature enables InnoDB to perform more like an in-memory database
# on systems with appropriate combinations of workload and sufficient memory for the buffer
# pool without sacrificing transactional features or reliability.
#
# The adaptive hash index feature is enabled by the innodb_adaptive_hash_index variable,
# or turned off at server startup by --skip-innodb-adaptive-hash-index
#
# Based on the observed pattern of searches, a hash index is built using a prefix of the index key.
#
# The prefix can be any length, and it may be that only some values in the B-tree appear in the
# hash index.
#
# Hash indexes are built on demand for the pages of the index that are accessed often.
#
# If a table fits almost entirely in main memory, a hash index can speed up queries by enabling
# direct lookup of any element, turning the index value into a sort of pointer.
#
# InnoDB has a mechanism that monitors index searches.
#
# If InnoDB notices that queries could benefit from building a hash index, it does so automatically.
#
# With some workloads, the speedup from hash index lookups greatly outweighs the extra work to monitor
# index lookups and maintain the hash index structure.
#
# Access to the adaptive hash index can sometimes become a source of contention under heavy workloads,
# such as multiple concurrent joins.
#
# Queries with LIKE operators and % wildcards also tend not to benefit.
#
# For workloads that do not benefit from the adaptive hash index feature, turning it
# off reduces unnecessary performance overhead.
#
# Because it is difficult to predict in advance whether the adaptive hash index feature
# is appropriate for a particular system and workload, consider running benchmarks with
# it enabled and disabled.
#
# Architechtural changes in MySQL 5.6 make it more suitable to disable the adaptive hash
# index feature than in earlier releases.
#
# The adaptive hash index feature is partitioned. Each index is bound to a specific partition,
# and each partition is protected by a separate latch.
#
# Partitioning is controlled by the innodb_adaptive_hash_index_parts variable.
#
# The innodb_adaptive_hash_index_parts variable is set to 8 by default. The maximum setting is 512.
#
# You can monitor adaptive hash index use and contention in the SEMAPHORES section of SHOW_ENGINE_INNODB_STATUS
# output.
#
# If there are numerous threads waiting on RW-latches created in btr0sea.c, consider increasing the number of
# adaptive hash index partitions or disabling the adaptive hash index feature.
#
# For information about the performance characteristics of hash indexes, see SECTION 8.3.9, "COMPARISON OF B-TREE AND HASH INDEXES"
#
# 15.5.4 LOG BUFFER
#
# The log buffer is the memory area that holds data to be written to the log files on disk.
#
# Log buffer size is defined by the innodb_log_buffer_size variable. The default size is 16MB.
#
# The contents of the log buffer are periodically flushed to disk. A large log buffer enables
# large transactions to run without the need to write redo log data to disk before the transaction
# commit.
#
# Thus, if you have transactions that update, insert, or delete many rows, increasing the size
# of the log buffer saves disk I/O
#
# The innodb_flush_log_at_trx_commit variable controls how the contents of the log buffer are written and 
# flushed to disk.
#
# The innodb_flush_log_at_timeout variable controls log flushing frequency.
#
# For related information, see MEMORY CONFIGURATION, see SECTION 8.5.4, "OPTIMIZING INNODB REDO LOGGING"
#
# 15.6 INNODB ON-DISK STRUCTURES
#
# 15.6.1 TABLES
# 15.6.2 INDEXES
#
# 15.6.3 TABLESPACES
# 15.6.4 DOUBLEWRITE BUFFER
#
# 15.6.5 REDO LOG
# 15.6.6 UNDO LOGS
#
# This section describes InnoDB on-disk structures and related topics.
#
# 15.6.1 TABLES
#
# 15.6.1.1 CREATING INNODB TABLES
# 15.6.1.2 MOVING OR COPYING INNODB TABLES
#
# 15.6.1.3 CONVERTING TABLES FROM MYISAM TO INNODB
# 15.6.1.4 AUTO_INCREMENT HANDLING IN INNODB
#
# 15.6.1.5 INNODB AND FOREIGN KEY CONSTRAINTS
# 15.6.1.6 LIMITS ON INNODB TABLES
#
# This section covers topics related to InnoDB tables.
#
# 15.6.1.1 CREATING INNODB TABLES
#
# To create an InnoDB table, use the CREATE_TABLE statement
#
# 		CREATE TABLE t1 (a INT, b CHAR (20), PRIMARY KEY (a)) ENGINE=InnoDB;
#
# You do not need to specify the ENGINE=InnoDB clause if InnoDB is defined as the default
# storage engine, which it is by default.
#
# To check the default storage engine, issue the following statement:
#
# 		SELECT @@default_storage_engine;
# 		+------------------------------+
# 		| @@default_storage_engine 	 |
# 		+------------------------------+
# 		| InnoDB 							 |
# 		+------------------------------+
#
# You might still use ENGINE=InnoDB clause if you plan to use mysqldump or replication to replay the
# CREATE_TABLE statement on a server where the default storage engine is not InnoDB.
#
# An InnoDB table and its indexes can be created in the system tablespace, in a file-per-table
# tablespace, or in a general tablespace.
#
# When innodb_file_per_table is enabled, which is the default, an InnoDB table is implicitly created
# in an individual file-per-table tablespace.
#
# Conversely, when innodb_file_per_table is disabled, an InnoDB table is implicitly created in the
# InnoDB system tablespace.
#
# To create a table in a general tablespace, use CREATE_TABLE_---_TABLESPACE syntax.
#
# For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# When you create a table in a file-per-table tablespace, MySQL creates an .ibd tablespace file in
# a database directory under the MySQL data directory, by default.
#
# A table created in the InnoDB system tablespace is created in an existing ibdata file, which resides
# in the MySQL data directory.
#
# A table created in a general tablespace is created in an existing general tablespace .ibd file.
#
# General tablespace files can be created inside or outside of the MySQL data directory.
#
# For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# Internally, InnoDB adds an entry for each table to the data dictionary.
#
# The entry includes the database name. For example, if table t1 is created in the
# test database, the data dictionary entry for the database name is 'test/t1'
#
# This means you can create a table of the same name (t1) in a different database,
# and the table names do not collide inside InnoDB.
#
# INNODB TABLES AND ROW FORMATS
#
# The default row format for InnoDB tables is defined by the innodb_default_row_format configuration
# option, which has a default value of DYNAMIC.
#
# Dynamic and Compressed row format allow you to take advantage of InnoDB features such as table
# compression and efficient off-page storage of long column values.
#
# To use these row formats, innodb_file_per_table must be enabled (the default)
#
# 		SET GLOBAL innodb_file_per_table=1;
# 		CREATE TABLE t3 (a INT, b CHAR (20), PRIMARY KEY (a)) ROW_FORMAT=DYNAMIC;
# 		CREATE TABLE t4 (a INT, b CHAR (20), PRIMARY KEY (a)) ROW_FORMAT=COMPRESSED;
#
# Alternatively, you can use CREATE_TABLE_---_TABLESPACE syntax to create an InnoDB table in
# a general tablespace.
#
# General tablespaces support all row formats. For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# 		CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1 ROW_FORMAT=DYNAMIC;
#
# CREATE_TABLE_---_TABLESPACE syntax can also be used to create InnoDB tables with a Dynamic row format
# in the system tablespace, alongside tables with a Compact or Redundant row format.
#
# 		CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE = innodb_system ROW_FORMAT=DYNAMIC;
#
# For more information about InnoDB row formats, see SECTION 15.10, "InnoDB ROW FORMATS"
#
# For how to determine the row format of an InnoDB table and the physical characteristics
# of InnoDB row formats, see SECTION 15.10, "InnoDB ROW FORMATS"
#
# InnoDB TABLES AND PRIMARY KEYS
#
# Always define a primary key for an InnoDB table, specifying the column or columns that:
#
# 		) Are referenced by the most important queries
#
# 		) Are never left blank
#
# 		) Never have duplicate values
#
# 		) Rarely if ever change value once inserted
#
# For example, in a table containing information about people, you would not create a primary key
# on (firstname, lastname) because more than one person can have the same name, some people have
# blank last names, and sometimes people change their names.
#
# With so many constraints, often there is not an obvious set of columns to use as a primary key,
# so you create a new column with a numeric ID to serve as all or part of the primary key.
#
# You can declare an auto-increment column so that ascending values are filled in automatically
# as rows are inserted:
#
# 		#The value of ID can act like a pointer between related items in different tables
# 		CREATE TABLE t5 (id INT AUTO_INCREMENT, b CHAR (20), PRIMARY KEY (id));
#
# 		#The primary key can consist of more than one column. Any autoinc column must come first.
# 		CREATE TABLE t6 (id INT AUTO_INCREMENT, a INT, b CHAR (20), PRIMARY KEY (id,a));
#
# Although the table works correctly without defining a primary key, the primary key is involved
# with many aspects of performance and is a crucial design aspect for any large or frequently
# used table.
#
# It is recommended that you always specify a primary key in the CREATE_TABLE statement.
#
# If you create the table, load data, and then run ALTER_TABLE to add a primary key later,
# that operation is much slower than defining the primary key when creating the table.
#
# VIEWING INNODB TABLE PROPERTIES
#
# To view the properties of an InnoDB table, issue a SHOW_TABLE_STATUS statement:
#
# 		SHOW TABLE STATUS FROM test LIKE 't%' \G;
# 		****************************** 1. row *******************************
# 						Name: t1
# 					 Engine: InnoDB
# 					Version: 10
# 				Row_format: Compact
# 						Rows: 0
# 		  Avg_row_length: 0
# 			 Data_length : 16384
# 		Max_data_length : 0
# 			Index_length : 0
# 				Data_free : 0
# 		Auto_increment  : NULL
# 			Create_time  : 2015-03-16 15:13:31
# 			Update_time  : NULL
# 			 Check_time  : NULL
# 				Collation : utf8mb4_0900_ai_ci
# 				 Checksum : NULL
# 		Create_options  : 
# 				Comment   : 
#
# For information about SHOW_TABLE_STATUS output, see SECTION 13.7.6.36, "SHOW TABLE STATUS SYNTAX"
#
# InnoDB table properties may also be queried using the InnoDB Information Schema system tables:
#
# 		SELECT * FROM INFORMATION_SCHEMA.INNODB_TABLES WHERE NAME='test/t1' \G
# 		******************************* 1. row ***************************************
# 					TABLE_ID: 45
# 						NAME : test/t1
# 						FLAG : 1
# 					 N_COLS : 5
# 						SPACE: 35
# 				ROW_FORMAT : Compact
# 			ZIP_PAGE_SIZE : 0
# 				SPACE_TYPE : Single
#
# For more information, see SECTION 15.14.3, "INNODB INFORMATION_SCHEMA SCHEMA OBJECT TABLES"
#
# 15.6.1.2 MOVING OR COPYING INNODB TABLES
#
# This section describes techniques for moving or copying some or all InnoDB tables to a different
# server or instance.
#
# For example, you might move an entire MySQL instance to a larger, faster server; you might clone an
# entire MySQL instance to a new replication slave server; you might copy individual tables to another
# instance to develop and test an app - Or to a data warehouse server to produce reports.
#
# On Windows, InnoDB always stores database and table names internally in lowercase.
#
# To move databases in a binary format from Unix to Windows or from Windows to Unix, create all
# databases and tables using lowercase names.
#
# A convenient way to accomplish this is to add the following line to the [mysqld] section of your
# my.cnf or my.ini file before creating any databases or tables:
#
# 		[mysqld]
# 		lower_case_table_names=1
#
# NOTE:
#
# 		It is prohibited to start the server with a lower_case_table_names setting that is different
# 		from the setting used when the server was initialized.
#
# Techniques for moving or copying InnoDB tables include:
#
# 		) Transportable Tablespaces
#
# 		) MySQL Enterprise Backup
#
# 		) Copying Data Files (Cold Backup Method)
#
# 		) Export and Import (mysqldump)
#
# TRANSPORTABLE TABLESPACES
#
# The transportable tablespaces features uses FLUSH_TABLES_---_FOR_EXPORT to ready
# InnoDB tables for copying from one server instnace to another.
#
# To use this feature, InnoDB tables must be created with innodb_file_per_table
# set to ON so that each InnoDB table has its own tablespace.
#
# For usage information, see SECTION 15.6.3.7, "COPYING TABLESPACES TO ANOTHER INSTANCE"
#
# MYSQL ENTERPRISE BACKUP
#
# The MySQL Enterprise Backup product lets you back up a running MySQL database with minimal
# disruption to operations while producing a consistent snapshot of the database.
#
# When MySQL Enterprise Backup is copying tables, reads and writes can continue.
#
# In addition, MySQL Enterprise Backup can create compressed backup files, and back
# up subsets of tables.
#
# In conjunction with the MySQL binary log, you can perform point-in-time recovery.
#
# MySQL Enterprise Backup is included as part of the MySQL Enterprise Subscription.
#
# For more details about MySQL Enterprise Backup, see SECTION 30.2, "MySQL ENTERPRISE BACKUP OVERVIEW"
#
# COPYING DATA FILES (COLD BACKUP METHOD)
#
# You can move an InnoDB database simply by copying all the relevant files listed under "Cold Backups"
# in SECTION 15.17.1, "INNODB BACKUP"
#
# InnoDB data and log files are binary-compatible on all platforms having the same floating-point number
# format.
#
# If the floating-point formats differ but you have not used FLOAT or DOUBLE data types in your tables,
# then the procedure is the same: simply copy the relevant files.
#
# When you move or copy file-per-table .ibd files, the database directory name must be the same on the
# source and destination systems.
#
# The table definition stored in the InnoDB shared tablespace includes the database name.
#
# The transaction IDs and log sequence numbers stored in the tablespace files also differ
# between databases.
#
# To move an .ibd file and the associated table from one database to another, use a RENAME_TABLE
# statement:
#
# 		RENAME TABLE db1.tbl_name TO db2.tbl_name;
#
# If you have a "clean" backup of an .ibd file, you can restore it to the MySQL installation from which
# it originated as follows:
#
# 		1. The table must not have been dropped or truncated since you copied the .ibd file, because doing so
# 			changes the table ID stored inside the tablespace.
#
# 		2. Issue this ALTER_TABLE statement to delete the current .ibd file:
#
# 			ALTER TABLE tbl_name DISCARD TABLESPACE;
#
# 		3. Copy the backup .ibd file to the proper database directory
#
# 		4. Issue this ALTER_TABLE statement to tell InnoDB to use the new .ibd file for the table:
#
# 			ALTER TABLE tbl_name IMPORT TABLESPACE;
#
# NOTE:
#
# 		The ALTER_TABLE_---_IMPORT_TABLESPACE feature does not enforce foreign key constraints on imported data.
#
# In this context, a "clean" .ibd file backup is one for which the following requirements are satisfied:
#
# 		) There are no uncommitted modifications by transactions in the .ibd file
#
# 		) There are no unmerged insert buffer entries in the .ibd file
#
# 		) Purge has removed all delete-marked index records from the .ibd file
#
# 		) mysqld has flushed all modified pages of the .ibd file from the buffer pool to the file
#
# You can make a clean backup .ibd file using the following method:
#
# 		1. Stop all activity from the mysqld server and commit all transactions.
#
# 		2. Wait until SHOW_ENGINE_INNODB_STATUS shows that there are no active transactions
# 			in the database, and the main thread status of InnoDB is Waiting for server activity.
#
# 			Then you can make a copy of the .ibd file
#
# Another method for making a clean copy of an .ibd file is to use the MySQL Enterprise Backup product:
#
# 		1. Use MySQL Enterprise Backup to back up the InnoDB installation
#
# 		2. Start a second mysqld server on the backup and let it clean up the .ibd files in the backup
#
# EXPORT AND IMPORT (MYSQLDUMP)
#
# You can use mysqldump to dump your tables on one machine and then import the dump files on
# the other machine.
#
# Using this method, it does not matter whether the formats differ or if your tables contain floating-point data.
#
# One way to increase the performance of this method is to switch off autocommit mode when importing data,
# assuming that the tablespace has enough space for the big rollback segment that the import transactions
# generate.
#
# Do the commit only after importing a whole table or a segment of a table.
#
# 15.6.1.3 CONVERTING TABLES FROM MYISAM TO INNODB
#
# If you have MyISAM tables that you want to convert to InnoDB for better reliability and scalability,
# review the following guidelines and tips before converting.
#
# NOTE:
#
# 		Partitioned MyISAM tables created in previous versions of MySQL are not compatible with MySQL 8.0
#
# 		Such tables must be prepared prior to upgrade, either by removing the partitioning, or by converting
# 		them to InnoDB.
#
# 		See SECTION 23.6.2, "PARTITIONING LIMITATIONS RELATING TO STORAGE ENGINES", for more information.
#
# 		) ADJUSTING MEMORY USAGE FOR MYISAM AND INNODB
#
# 		) HANDLING TOO-LONG OR TOO-SHORT TRANSACTIONS
#
# 		) HANDLING DEADLOCKS
#
# 		) PLANNING THE STORAGE LAYOUT
#
# 		) CONVERTING AN EXISTING TABLE
#
# 		) CLONING THE STRUCTURE OF A TABLE
#
# 		) TRANSFERRING EXISTING DATA
#
# 		) STORAGE REQUIREMENTS
#
# 		) DEFINING A PRIMARY KEY FOR EACH TABLE
#
# 		) APPLICATION PERFORMANCE CONSIDERATIONS
#
# 		) UNDERSTANDING FILES ASSOCIATED WITH INNODB TABLES
#
# ADJUSTING MEMORY USAGE FOR MYISAM AND INNODB
#
# As you transition away from MyISAM tables, lower the value of the key_buffer_size configuration
# option to free memory no longer needed for caching results.
#
# Increase the value of the innodb_buffer_pool_size configuration option, which performs a similar
# role of allocating cache memory for InnoDB tables.
#
# The InnoDB buffer pool caches both table data and index data, speeding up lookups for queries
# and keeping query results in memory for reuse.
#
# For guidance regarding buffer pool size configuration, see SECTION 8.12.3.1, "HOW MYSQL USES MEMORY"
#
# HANDLING TOO-LONG OR TOO-SHORT TRANSACTIONS
#
# Because MyISAM tables do not support transactions, you might not have paid much attention to the
# autocommit configuration option and the COMMIT and ROLLBACK statements.
#
# These keywords are important to allow multiple sessions to read and write InnoDB tables concurrently,
# providing substantial scalability benefits in write-heavy workloads.
#
# While a transaction is open, the system keeps a snapshot of the data as seen at the beginning of the
# transaction, which can cause substantial overhead if the system inserts, updates and deletes millions
# of rows while a stray transaction keeps running.
#
# Thus, take care to avoid transactions that run for too long:
#
# 		) If you are using a mysql session for interactive experiments, always COMMIT (to finalize the changes)
# 			or ROLLBACK (to undo the changes) when finished.
#
# 			Close down interactive sessions rather than leave them open for long periods, to avoid keeping
# 			transactions open for long periods by accident.
#
# 		) Make sure that any error handlers in your application also ROLLBACK incomplete changes or COMMIT completed changes
#
# 		) ROLLBACK is a relatively expensive operation, because INSERT, UPDATE and DELETE operations are written to InnoDB
# 			tables prior to the COMMIT, with the expectation that most changes are committed successfully and rollbacks are
# 			rare.
#
# 			When experimenting with large volumes of data, avoid making changes to large numbers of rows and then rolling
# 			back those changes.
#
# 		) When loading large volumes of data with a sequence of INSERT statements, periodically COMMIT the results to avoid
# 			having transactions that last for hours.
#
# 			In typical load operations for data warehousing, if something goes wrong, you truncate the table (using TRUNCATE_TABLE)
# 			and start over from the beginning rather than doing a ROLLBACK
#
# The preceding tips save memory and disk space that can be wasted during too-long transactions.
#
# When transactions are shorter than they should be, the problem is excessive I/O. With each COMMIT,
# MySQL makes sure each change is safely recorded to disk, which involves some I/O
#
# 		) For most operations on InnoDB tables, you should use the setting autocommit=0 
#
# 			From an efficiency perspective, this avoids unnecessary I/O when you issue large
# 			numbers of consecutive INSERT, UPDATE or DELETE statements.
#
# 			From a safety perspective, this allows you to issue a ROLLBACK statement to recover
# 			lost or garbled data if you make a mistake on the mysql command line, or in an exception
# 			handler in your application.
#
# 		) The time when autocommit=1 is suitable for InnoDB tables is when running a sequence of queries
# 			for generating reports or analyzing statistics.
#
# 			In this situation, there is no I/O penalty related to COMMIT or ROLLBACK, and InnoDB can 
# 			automatically optimize the read-only workload
#
# 		) If you make a series of related changes, finalize all the changes at once with a single COMMIT at the end.
#
# 			For example, if you insert related pieces of information into several tables, do a single COMMIT
# 			after making all the changes.
#
# 			Or if you run many consecutive INSERT statements, do a single COMMIT after all the data is loaded;
# 			if you are doing millions of INSERT statements, perhaps split up the huge transaction by issuing
# 			a COMMIT every ten thousand or hundred thousand records, so the transaction does not grow too large.
#
# 		) Remember that even a SELECT statement opens a transaction, so after running some report or debugging
# 			queries in an interactive mysql session, either issue a COMMIT or close the mysql session
#
# HANDLING DEADLOCKS
#
# You might see warning messages referring to "deadlocks" in the MySQl error log, or the output of
# SHOW_ENGINE_INNODB_STATUS
#
# Despite the scary-sounding name, a deadlock is not a serious issue for InnoDB tables, and often does not
# require any corrective action.
#
# When two transactions start modifying multiple tables, accessing the tables in a different order, they
# can reach a state where each transaction is waiting for the other and neither can proceed.
#
# When deadlock detection is enabled (the default), MySQL immediately detects this condition and cancels
# (rolls back) the "smaller" transaction, allowing the other to proceed.
#
# If deadlock detection is disabled using the innodb_deadlock_detect configuration option, InnoDB
# relies on the innodb_lock_wait_timeout setting to roll back transactions in case of a deadlock.
#
# Either way, your applications need error-handling logic to restart a transaction that is forcibly
# cancelled due to a deadlock.
#
# When you re-issue the same SQL statements as before, the original timing issue no longer applies.
#
# Either the other transaction has already finished and yours can proceed, or the other transaction
# is still in progress and your transaction waits until it finishes.
#
# If deadlock warnings occur constantly, you might review the application code to reorder the SQL
# operations in a consistent way, or to shorten the transactions.
#
# You can test with the innodb_print_all_deadlocks option enabled to see all deadlock warnings
# in the MySQL error log, rather than only the last warning in the SHOW_ENGINE_INNODB_STATUS
# output.
#
# For more information, see SECTION 15.7.5, "DEADLOCKS IN INNODB"
#
# PLANNING THE STORAGE LAYOUT
#
# To get the best performance from InnoDB tables, you can adjust a number of parameters related
# to storage layout.
#
# When you convert MyISAM tables that are large, frequently accessed and hold vital data - investigate
# and consider the innodb_file_per_table and innodb_page_size configuration options, and the ROW_FORMAT
# and KEY_BLOCK_SIZE clauses of the CREATE_TABLE statement.
#
# During your initial experiments, the most important setting is innodb_file_per_table
#
# When this setting is enabled, which is the default, new InnoDB tables are implicitly
# created in file-per-table tablespaces.
#
# In contrast with the InnoDB system tablespace, file-per-table tablespaces allow disk space
# to be reclaimed by the operating system when a table is truncated or dropped.
#
# File-per-table tablespaces also support DYNAMIC and COMPRESSED row formats and associated
# features such as table compression, efficient off-page storage for long variable-length
# columns, and large index prefixes.
#
# For more information, see SECTION 15.6.3.2, "FILE-PER-TABLE TABLESPACES"
#
# You can also store InnoDB tables in a shared general tablespace, which support multiple
# tables and all row formats.
#
# For more information, see SECTION 15.6.3.3, "GENERAL TABLESPACES"
#
# CONVERTING AN EXISTING TABLE
#
# TO convert a non-InnoDB table to use InnoDB use ALTER_TABLE:
#
# 		ALTER TABLE table-name ENGINE=InnoDB;
#
# CLONING THE STRUCTURE OF A TABLE
#
# You might make an InnoDB table that is a clone of a MyISAM table, rather than using
# ALTER_TABLE to perform conversion, to test the old and new table side-by-side before
# switching.
#
# Create an empty InnoDB table with identical column and index definitions.
#
# Use SHOW CREATE TABLE table_name\G to see the full CREATE_TABLE statement to use.
#
# Change the ENGINE clause to ENGINE=INNODB
#
# TRANSFERRING EXISTING DATA
#
# To transfer a large volume of data into an empty InnoDB table created as shown in the previous section,
# insert the rows with INSERT INTO innodb_table SELECT * FROM myisam_table ORDER BY primary_key_columns
#
# You can also create the indexes for the InnoDB table after inserting the data.
#
# Historically, creating a new secondary indexes was a slow operation for InnoDB, but now you can
# create the indexes after the data is loaded with relatively little overhead from the index
# creation step.
#
# If you have UNIQUE constraints on secondary keys, you can speed up a table import by turning
# off the unqiueness checks temporarily during the import operation:
#
# 		SET unique_checks=0;
# 		------ IMPORT OPERATION -------
# 		SET unique_checks=1;
#
# For big tables, this saves disk I/O because InnoDB can use its change buffer to write secondary
# index records as a batch.
#
# Be certain that the data contains no duplicate keys.
#
# unique_checks permits but does not require storage engines to ignore duplicate keys.
#
# For better control over the insertion process, you can insert big tables in pieces:
#
# 		INSERT INTO newtable SELECT * FROM oldtable
# 			WHERE yourkey > something AND yourkey <= somethingelse;
#
# After all records are inserted, you can rename the tables.
#
# During the conversion of big tables, increase the size of the InnoDB buffer pool to reduce
# disk I/O, to a maximum of 80% of physical memory.
#
# You can also increase the size of InnoDB log files.
#
# STORAGE REQUIREMENTS
#
# If you intend to make several temporary copies of your data in InnoDB tables during the conversion
# process, it is recommended that you create the tables in file-per-table tablespaces so that you
# can reclaim the disk space when you drop the tables.
#
# When the innodb_file_per_table configuration option is enabled (the default), newly created InnoDB
# tables are implicitly created in file-per-table tablespaces.
#
# Whether you convert the MyISAM table directly or create a cloned InnoDB table, make sure that you
# have sufficient disk space to hold both the old and new tables during the process.
#
# InnoDB tables require more disk space than MyISAM tables.
#
# If an ALTER_TABLE operation runs out of space, it starts a rollback, and that can take hours
# if it is disk-bound.
#
# For inserts, InnoDB uses the insert buffer to merge secondary index records to indexes in batches.
#
# That saves a lot of disk I/O.
#
# For rollback, no such mechanism is used and the rollback can take 30 times longer than the insertion.
#
# In the case of a runaway rollback, if you do not have valuable data in your database, it may be advisable
# to kill the database process rather than wait for millions of disk I/O operations to complete.
#
# For the complete procedure, see SECTION 15.20.2, "FORCING INNODB RECOVERY"
#
# DEFINING A PRIMARY KEY FOR EACH TABLE
#
# The PRIMARY KEY clause is a critical factor affecting the performance of MySQL queries and the space
# usage for tables and indexes.
#
# THe primary key uniquely identifies a row in a table.
#
# Every row in the table must have a primary key value, and no two rows can have the same primary key value.
#
# THese are guidelines for the primary key, followed by more detailed explanations.
#
# 		) Declare a PRIMARY KEY for each table. Typically, it is the most important column that you refer to in
# 			WHERE clauses when looking up a single row.
#
# 		) Declare the PRIMARY KEY clause in the original CREATE_TABLE statement, rather than adding it later
# 			through an ALTER_TABLE statement
#
# 		) Choose the column and its data type carefully. Prefer numeric columns over character or string ones.
#
# 		) Consider using an auto-increment column if there is not another stable, unique, non-null, numeric column to use
#
# 		) An auto-increment column is also a good choice if there is any doubt whether the value of the primary key
# 			column could ever change.
#
# 			Changing the value of a primary key column is an expensive operation, possibly involving rearraging data within
# 			the table and within each secondary index.
#
# Consider adding a primary key to any table that does not already have one.
#
# Use the smallest practical numerical type based on the maximum projected size of the table.
#
# This can make each row slightly more compact, which can yield substantial space savings for
# large tables.
#
# The space savings are multiplied if the table has any secondary indexes, because the primary key
# value is repeated in each secondary index entry.
#
# In addition to reducing data size on disk, a small primary key also lets more data fit into
# the buffer pool, speeding up all kinds of operations and improving concurrency.
#
# If the table already has a primary key on some longer column, such as a VARCHAR, consider adding
# a new unsigned AUTO_INCREMENT column and switching the primary key to that, even if that column
# is not referenced in queries.
#
# This design change can produce substantial space savings in the secondary indexes.
#
# You can designate the former primary key columns as UNIQUE NOT NULL to enforce the same constraints
# as the PRIMARY KEY clause, that is, to prevent duplicate or null values across all those columns.
#
# If you spread related information across multiple tables, typically each table uses the same column
# for its primary key.
#
# For example, a personnel database might have several tables, each with a primary key of employee number.
#
# A sales database might have some tables with a primary key of customer number, and other tables
# with a primary key of order number.
#
# Because lookups using the primary key are very fast, you can construct efficient join queries
# for such tables.
#
# If you leave the PRIMARY KEY clause out entirely, MySQL creates an invisible one for you.
#
# It is a 6-byte value that might be longer than you need, thus wasting space.
#
# Because it is hidden, you cannot refer to it in queries.
#
# APPLICATION PERFORMANCE CONSIDERATIONS
#
# The reliability and scalability features of InnoDB require more disk storage than equivalent
# MyISAM tables.
#
# You might change the column and index definitions slightly, for better space utilization,
# reduced I/O and memory consumption when processing result sets, and better query optimization
# plans making efficient use of index lookups.
#
# If you do set up a numeric ID column for the primary key, use that value to cross-reference
# with related values in any other tables, particularly for join queries.
#
# For example, rather than accepting a country name as input and doing queries searching for the
# same name, do one lookup to determine the country ID, then do other queries (or a single join query)
# to look up relevant information across several tables.
#
# Rather than storing a customer or catalog item number as a string of digits, potentially using up
# several bytes, convert it to a numeric ID for storing and querying.
#
# A 4-byte unsigned INT column can index over 4 billion items (with the US meaning of BIllion: 1k Mils)
#
# For the ranges of the different integer types, see SECTION 11.2.1, "INTEGER TYPES (EXACT VALUE) - INTEGER, INT, SMALLINT,
# TINYINT, MEDIUMINT, BIGINT"
#
# UNDERSTANDING FILES ASSOCIATED WITH INNODB TABLES
#
# InnoDB files require more care and planning than MyISAM files do.
#
# 		) You must not delete the ibdata files that represent the InnoDB system tablespace
#
# 		) Methods of moving or copying InnoDB tables to a different server are described in SECTION 15.6.1.2, "MOVING OR COPYING INNODB TABLES"
#
# 15.6.1.4 AUTO_INCREMENT HANDLING IN INNODB
#
# InnoDB provides a configurable locking mechanism that can significantly improve scalability and performance
# of SQL statements that add rows to tables with AUTO_INCREMENT columns.
#
# To use the AUTO_INCREMENT mechanism with an InnoDB table, an AUTO_INCREMENT column must be defined as part
# of an index such that it is possible to perform the equivalent of an indexed SELECT MAX(ai_col) lookup on
# the table to obtain the maximum column value.
#
# Typically, this is achieved by making the column the first column of some table index.
#
# This section describes the behavior of AUTO_INCREMENT lock modes, usage implications for different
# AUTO_INCREMENT lock mode settings, and how InnoDB initializes the AUTO_INCREMENT counter.
#
# 		) InnoDB AUTO_INCREMENT LOCK MODES
#
# 		) InnoDB AUTO_INCREMENT LOCK MODE USAGE IMPLICATIONS
#
# 		) InnoDB AUTO_INCREMENT COUNTER INITIALIZATION
#
# InnoDB AUTO_INCREMENT LOCK MODES
#
# This section describes the behavior of AUTO_INCREMENT lock modes used to generate auto-increment values,
# and how each lock mode affects replication.
#
# Auto-increment lock modes are configured at startup using the innodb_autoinc_lock_mode configuration
# parameter.
#
# The following terms are used in describing innodb_autoinc_lock_mode settings:
#
# 		) "INSERT-like" statements
#
# 			All statements that generate new rows in a table, including INSERT, INSERT_---_SELECT, REPLACE,
# 			REPLACE_---_SELECT and LOAD_DATA
#
# 			Includes "simple-inserts", "bulk-inserts" and "mixed-mode" inserts
#
# 		) "Simple inserts"
#
# 			Statements for which the number of rows to be inserted can be determined in advance (when the statement
# 			is initially processed)
#
# 			This includes single-row and multiple-row INSERT and REPLACE statements that do not have a nested
# 			subquery, but not INSERT_---_ON_DUPLICATE_KEY_UPDATE
#
# 		) "Bulk Inserts"
#
# 			Statements for which the number of rows to be inserted (and the number of required auto-increment values)
# 			is not known in advance.
#
# 			This includes INSERT_---_SELECT, REPLACE_---_SELECT and LOAD_DATA statements, but not plain INSERT.

# 			InnoDB assigns new values for the AUTO_INCREMENT column one at a time as each row is processed.
#
# 		) "Mixed-mode inserts"
#
# 			These are "simple insert" statements that specify the auto-increment value for some (but not all)
# 			of the new rows.
#
# 			An example follows, where c1 is an AUTO_INCREMENT column of table t1:
#
# 				INSERT INTO t1 (c1,c2) VALUES (1,'a'), (NULL,'b'), (5,'c'), (NULL,'d');
#
# 			Another type of "mixed-mode insert" is INSERT_---_ON_DUPLICATE_KEY_UPDATE, which in the worst
# 			case is in effect an INSERT followed by a UPDATE, where the allocated value for the AUTO_INCREMENT
# 			column may or may not be used during the update phase.
#
# There are three possible settings for the innodb_autoinc_lock_mode configuration parameter.
#
# The settings are 0, 1, or 2 for "traditional", "consecutive" or "interleaved" lock mode, respectively.
#
# As of MySQL 8.0, interleaved lock mode (innodb_autoinc_lock_mode=2) is the default setting
#
# Prior to MySQL 8.0, consecutive lock mode is the default (innodb_autoinc_lock_mode=1)
#
# The default setting of interleaved lock mode in MySQL 8.0 reflects the change from statement-based
# replication to row based replication as the default replication type.
#
# Statement-based replication requires the consecutive auto-increment lock mode to ensure that auto-increment
# values are assigned in a predictable and repeatable order for a given sequence of SQL statements, whereas
# row-based replication is not sensitive to the execution order of SQL statements.
#
# 		) innodb_autoinc_lock_mode = 0 ("traditional" lock mode)
#
# 			The traditional lock mode provides the same behavior that existed before the innodb_autoinc_lock_mode
# 			configuration parameter was introduced in MySQL 5.1
#
# 			The traditional lock mode option is provided for backward compatibility, performance testing,
# 			and working around issues with "mixed-mode inserts", due to possible differences in semantics.
#
# 			In this lock mode, all "INSERT-like" statements obtain a special table-level AUTO-INC lock
# 			for inserts into tables with AUTO_INCREMENT columns.
#
# 			This lock is normally held to the end of the statement (not to the end of the transaction)
# 			to ensure that auto-increment values are assigned in a predictable and repeatable order for
# 			a given sequence of INSERT statements, and to ensure that auto-increment values assigned by
# 			any given statement are consecutive.
#
# 			In the case of statement-based replication, this means that when an SQL statement is replicated
# 			on a slave server, the same values are used for the auto-increment column as on the master server.
#
# 			The result of execution of multiple INSERT statements is deterministic, and the slave reproduces
# 			the same data as on the master.
#
# 			If auto-increment value generated by multiple INSERT statements were interleaved, the result of
# 			two concurrent INSERT statements would be nondeterministic, and could not reliably be propagated
# 			to a slave server using statement-based replication.
#
# 			To make this clear, consider an example that uses this table:
#
# 				CREATE TABLE t1 (
# 					c1 INT(11) NOT NULL AUTO_INCREMENT,
# 					c2 VARCHAR(10) DEFAULT NULL,
# 					PRIMARY KEY (c1)
# 				) ENGINE=InnoDB;
#
# 			Suppose that there are two transactions running, each inserting rows into a table with an
# 			AUTO_INCREMENT column.
#
# 			One transaction is using an INSERT_---_SELECT statement that inserts 1000 rows, and another
# 			is using a simple INSERT statement that inserts one row:
#
# 				Tx1: INSERT INTO t1 (c2) SELECT 1000 ROWS FROM another TABLE ---
# 				Tx2: INSERT INTO t1 (c2) VALUES ('xxx');
#
# 			InnoDB cannot tell in advance how many rows are retrieved from the SELECT in the INSERT
# 			statement in Tx1, and it assigns the auto-increment values one at a time as the statement
# 			proceeds.
#
# 			With a table-level lock, held to the end of the statement, only one INSERT statement referring
# 			to table t1 can execute at a time, and the generation of auto-increment numbers by different
# 			statements is not interleaved.
#
# 			The auto-increment value generated by the Tx1 INSERT_---_SELECT statement are consecutive,
# 			and the (single) auto-increment value used by the INSERT statement in Tx2 are either smaller
# 			or larger than all those used for Tx1, depending on which statement executes first.
#
# 			As long as the SQL statements execute in the same order when replayed from the binary log
# 			(when using statement-based replication, or in recovery scenarios), the results are the same
# 			as they were when Tx1 and Tx2 first ran.
#
# 			Thus, table-level locks held until the end of a statement make INSERT statements using auto-increment
# 			safe for use with statement-based replication.
#
# 			However, those table-level locks limit concurrency and scalability when multiple transactions
# 			are executing insert statements at the same time.
#
# 			In the preceding example, if there were no table-level lock, the value of the auto-increment
# 			column used for the INSERT in Tx2 depends on precisely when the statement executes.
#
# 			If the INSERT of Tx2 executes while the INSERT of Tx1 is running (rather than before it starts
# 			or after it completes), the specific auto-increment value assigned by the two INSERT statements
# 			are nondeterministic, and may vary from run to run.
#
# 			Under the consecutive lock mode, InnoDB can avoid using table-level AUTO-INC locks for 
# 			"simple insert" statements where the number of rows is known in advance, and still preserve
# 			deterministic execution and safety for statement-based replication.
#
# 			If you are not using the binary log to replay SQL statements as part of recovery or replication,
# 			the interleaved lock mode can be used to eliminate all use of table-level AUTO-INC locks for even
# 			greater concurrency and performance, at hte cost of permitting gaps in auto-increment numbers assigned
# 			by a statement and potentially having the numbers assigned by concurrently executing statements interleaved.
#
# 		) innodb_autoinc_lock_mode = 1 ("consecutive" lock mode)
#
# 			In this mode, "bulk inserts" use the special AUTO-INC table-level lock and hold it until the end
# 			of the statement.
#
# 			This applies to all INSERT_---_SELECT, REPLACE_---_SELECT and LOAD_DATA statements.
#
# 			Only one statement holding the AUTO-INC lock can execute at a time.
#
# 			If the source table of the bulk insert operation is different from the target table,
# 			the AUTO-INC lock on the target table is taken after a shared lock is taken on the first
# 			row selected from the source table.
#
# 			If the source and target of the bulk insert operation are the same table, the AUTO-INC
# 			lock is taken after shared locks are taken on all selected rows.
#
# 			"Simple inserts" (for which the number of rows to be inserted is known in advanced) avoid table
# 			level AUTO-INC locks by obtaining the required number of auto-increment values under the
# 			control of a mutex (a light-weight lock) that is only held for the duration of the allocation
# 			process, not until the statement completes.
#
# 			No table-level AUTO-INC lock is used unless an AUTO-INC lock is held by another transaction.
#
# 			If another transaction holds an AUTO-INC lock, a "simple insert" waits for the AUTO-INC lock,
# 			as if it were a "bulk insert"
#
# 			This lock mode ensures that, in the presence of INSERT statements where the number of rows
# 			is not known in advance (and where auto-increment numbers are assigned as the statement
# 			progresses), all auto-increment values assigned by any "INSERT-like" statement are consecutive,
# 			and operations are safe for statement-based replication.
#
# 			Simply put, this lock mode significantly improves scalability while being safe for use with
# 			statement-based replication.
#
# 			Further, as with "traditional" lock mode, auto-increment numbers assigned by any given statement
# 			are consecutive.
#
# 			There is no change in semantics compared to "traditional" mode for any statement that uses
# 			auto-increment, with one important exception.
#
# 			The exception is for "mixed-mode inserts", where the user provides explicit values for an
# 			AUTO_INCREMENT column for some, but not all, rows in a multiple-row "simple insert".
#
# 			For such inserts, InnoDB allocates more auto-increment values than the number of rows to be
# 			inserted.
#
# 			However, all values automatically assigned are consecutively generated (and thus higher than)
# 			the auto-increment value generated by the most recently executed previous statement.
#
# 			"Excess" numbers are lost.
#
# 		) innodb_autoinc_lock_mode = 2 ("interleaved" lock mode)
#
# 			In this lock mode, no "INSERT-like" statements use the table-level AUTO-INC lock, and
# 			multiple statements can execute at the same time.
#
# 			This is the fastest and most scalable lock mode, but it is not safe when using statement-based
# 			replication or recovery scenarios when SQL statements are replayed from the binary log.
#
# 			In this lock mode, auto-increment values are guaranteed to be unique and monotonically increasing
# 			across all concurrently executing "INSERT-like" statements.
#
# 			However, because multiple statements can be generating numbers at the same time (that is, allocation
# 			of numbers is interleaved across statements), the values generated for the rows inserted by any given
# 			statement may not be consecutive.
#
# 			If the only statements executing are "simple inserts" where the number of rows to be inserted
# 			is known ahead of time, there are no gaps in the numbers generated for a single statement,
# 			except for "mixed-mode inserts"
#
# 			However, when "bulk inserts" are executed, there may be gaps in the auto-increment values
# 			assigned by any given statement.
#
# INNODB AUTO_INCREMENT LOCK MODE USAGE IMPLICATIONS
#
# 		) Using auto-increment with replication
#
# 			If you are using statement-based replication, set innodb_autoinc_lock_mode to 0 or 1
# 			and use the same value on the master and its slaves.
#
# 			Auto-increment values are not ensured to be the same on the slaves as on the master
# 			if you use innodb_autoinc_lock_mode = 2 ("interleaved") or configurations where the
# 			master and slaves do not use the same lock mode.
#
# 			If you are using row-based or mixed-format replication, all of the auto-increment lock
# 			modes are safe, since row-based replication is not sensitive to the order of execution
# 			of the SQL statements (and the mixed format uses row-based replication for any statements
# 			that are unsafe for statement-based replication)
#
# 		) "Lost" auto-increment values and sequence gaps
#
# 			In all lock modes (0, 1, 2) if a transaction that generated auto-increment values rolls back,
# 			those auto-increment values are "lost".
#
# 			Once a value is generated for an auto-increment column, it cannot be rolled back, whether or
# 			not the "INSERT-like" statement is completed, and whether or not the containing transaction
# 			is rolled back.
#
# 			Such lost values are not reused. Thus, there may be gaps in the values stored in an AUTO_INCREMENT
# 			column of a table.
#
# 		) Specifying NULL or 0 for the AUTO_INCREMENT column
#
# 			In all lock modes (0, 1, and 2), if a user specifies NULL or 0 for the AUTO_INCREMENT
# 			column in an INSERT, InnoDB treats the row as if the value was not specified and generates
# 			a new value for it.
#
# 		) Assigning a negative value to the AUTO_INCREMENT column
#
# 			In all lock modes (0, 1, and 2), the behavior of the auto-increment mechanism
# 			is not defined if you assign a negative value to the AUTO_INCREMENT column.
#
# 		) If the AUTO_INCREMENT value becomes larger than the maximum integer for the specified integer type
#
# 			In all lock modes (0, 1, and 2), the behavior of the auto-increment mechanism is not defined
# 			if the value becomes larger than the maximum integer that can be stored in the specified
# 			integer type.
#
# 		) Gaps in auto-increment values for "bulk inserts"
#
# 			With innodb_autoinc_lock_mode set to 0 ("traditional") or 1 ("consecutive"), the auto-increment
# 			values generated by any given statement are consecutive, without gaps, because the table-level
# 			AUTO-INC lock is held until the end of the statement, and only one such statement can execute
# 			at a time.
#
# 			With innodb_autoinc_lock_mode set to 2 ("interleaved"), there may be gaps in the auto-increment
# 			values generated by "bulk inserts", but only if there are concurrently executing "INSERT-like"
# 			statements.
#
# 			For lock modes 1 or 2, gaps may occur between successive statements because for bulk inserts
# 			the exact number of auto-increment values required by each statement may not be known and
# 			overestimation is possible.
#
# 		) Auto-increment values assigned by "mixed-mode inserts"
#
# 			Consider a "mixed-mode insert", where a "simple insert" specifies the auto-increment value
# 			for some (but not all) resulting rows.
#
# 			Such a statement behaves differently in lock modes 0, 1 and 2.
#
# 			For example, assume c1 is an AUTO_INCREMENT column of table t1, and that the most
# 			recent automatically generated sequence number is 100.
#
# 				CREATE TABLE t1 (
# 					c1 INT UNSIGNED NOT NULL AUTO_INCREMENT PRIMARY KEY,
# 					c2 CHAR(1)
# 				) ENGINE = INNODB;
#
# 			Now, consider the following "mixed-mode insert" statement:
#
# 				INSERT INTO t1 (c1, c2) VALUES (1,'a'), (NULL, 'b'), (5,'c'), (NULL,'d');
#
# 			With innodb_autoinc_lock_mode set to 0 ("traditional"), the four new rows are:
#
# 				SELECT c1, c2 FROM t1 ORDER BY c2;
# 				+------+---------+
# 				| c1   | c2 	  |
# 				+------+---------+
# 				| 1 	 | a 		  |
# 				| 101  | b 		  |
# 				| 5 	 | c 		  |
# 				| 102  | d 		  |
# 				+------+---------+
#
# 			The next available auto-increment value is 103 because the auto-increment values
# 			are allocated one at a time, not all at once at the beginning of statement execution.
#
# 			This result is true whether or not there are concurrently executing "INSERT-like"
# 			statements (of any type)
#
# 			With innodb_autoinc_lock_mode set to 1 ("consecutive"), the four new rows are also:
#
# 				SELECT c1, c2 FROM t1 ORDER BY c2;
# 				+-----+------+
# 				| c1  | c2 	 |
# 				+-----+------+
# 				| 1   | a    |
# 				| 101 | b 	 |
# 				| 5 	| c 	 |
# 				| 102 | d 	 |
# 				+-----+------+
#
# 			However, in this case, the next available auto-increment value is 105, not 103, because
# 			four auto-increment values are allocated at the time the statement is processed, but
# 			only two are used.
#
# 			The result is true whether or not there are concurrently executing "INSERT-like" statements
# 			(of any type)
#
# 			With innodb_autoinc_lock_mode set to mode 2 ("interleaved"), the four new rows are:
#
# 				SELECT c1, c2 FROM t1 ORDER BY c2;
# 				+------+------+
# 				| c1   | c2   |
# 				+------+------+
# 				| 1 	 | a 	  |
# 				| x    | b 	  |
# 				| 5    | c 	  |
# 				| y 	 | d 	  |
# 				+------+------+
#
# 			The values of x and y are unique and larger than any previously generated rows.
#
# 			However, the specific values of x and y depend on the number of auto-increment
# 			values generated by concurrently executing statements.
#
# 			Finally, consider the following statement, issued when the most-recently generated
# 			sequence number is 100:
#
# 				INSERT INTO t1 (c1, c2) VALUES (1, 'a'), (NULL, 'b'), (101, 'c'), (NULL, 'd');
#
# 			With any innodb_autoinc_lock_mode setting, this statement generates a duplicate-key error
# 			23000 (Can't write; duplicate key in table) because 101 is allocated for the row (NULL, 'b'),
# 			and insertion of the row (101, 'c') fails.
#
# 		) Modifying AUTO_INCREMENT column values in the middle of a sequence of INSERT statements
#
# 			In MySQL 5.7 and earlier, modifying an AUTO_INCREMENT column value in the middle of a sequence
# 			of INSERT statements could lead to "Duplicate entry" errors.
#
# 			For example, if you performed an UPDATE operation that changed an AUTO_INCREMENT column value
# 			to a value larger than the current maximum auto-increment value, subsequent INSERT operations
# 			that did not specify an unused auto-increment value could encounter "Duplicate entry" errors.
#
# 			In MySQL 8.0 and later, if you modify an AUTO_INCREMENT column value to a value larger than the
# 			current maximum auto-increment value, the new value is persisted, and subsequent INSERT operations
# 			allocate auto-increment values starting from the new, larger value.
#
# 			This behavior is demonstrated in the following example.
#
# 				CREATE TABLE t1 (
# 					c1 INT NOT NULL AUTO_INCREMENT,
# 					PRIMARY KEY (c1)
# 					) ENGINE = InnoDB;
#
# 				INSERT INTO t1 VALUES(0), (0), (3);
#
# 				SELECT c1 FROM t1;
# 				+-----+
# 				| c1  |
# 				+-----+
# 				| 1   |
# 				| 2   |
# 				| 3   |
# 				+-----+
#
# 				UPDATE t1 SET c1 = 4 WHERE c1 = 1;
#
# 				SELECT c1 FROM t1;
# 				+----+
# 				| c1 |
# 				+----+
# 				| 2  |
# 				| 3  |
# 				| 4  |
# 				+----+
#
# 				INSERT INTO t1 VALUES(0);
#
# 				SELECT c1 FROM t1;
# 				+----+
# 				| c1 |
# 				+----+
# 				| 2  |
# 				| 3  |
# 				| 4  |
# 				| 5  |
# 				+----+
#
# InnoDB AUTO_INCREMENT COUNTER INITIALIZATION
#
# This section describes how InnoDB initializes AUTO_INCREMENT counters.
#
# If you specify an AUTO_INCREMENT column for an InnoDB table, the in-memory table object
# contains a special counter called the auto-increment counter that is used when assigning
# new values for the column.
#
# In MySQl 5.7 and earlier, the auto-increment counter is stored only in main memory, not on disk.
#
# To initialize an auto-increment counter after a server restart, InnoDB would execute the equivalent
# of the following statement on the first insert into a table containing an AUTO_INCREMENT column.
#
# 		SELECT MAX(ai_col) FROM table_name FOR UPDATE;
#
# In MySQL 8.0, this behavior is changed.
#
# The current maximum auto-increment counter value is written to the redo log each time it changes
# and is saved to an engine-private system table on each checkpoint.
#
# These changes make the current maximum auto-increment counter value persistent across server
# restarts.
#
# On a server restart following a normal shutdown, InnoDB initializes the in-memory auto-increment
# counter using the current maximum auto-increment value stored in the data dictionary system table.
#
# On a server restart during crash recovery, InnoDB initializes the in-memory auto-increment counter
# using the current maximum auto-increment value stored in the data dictionary system table and scans
# the redo log for auto-increment counter values written since the last checkpoint.
#
# If a redo-logged value is greater than the in-memory counter value, the redo-logged value is applied.
#
# However, in the case of a server crash, reuse of a previously allocated auto-increment value
# cannot be guaranteed.
#
# Each time the current maximum auto-increment value is changed due to an INSERT or UPDATE operation,
# the new value is written to the redo log, but if the crash occurs before the redo log is flushed
# to disk, the previously allocated value could be reused when the auto-increment counter is initialized
# after the server is restarted.
#
# The only circumstance in which InnoDB uses the equivalent of a SELECT MAX(ai_col) FROM table_name FOR UPDATE
# statement in MySQL 8.0 and later to initialize an auto-increment counter is when importing a tablespace
# without a .cfg metadata file.
#
# Otherwise, the current maximum auto-increment counter value is read from the .cfg metadata file.
#
# In MysQL 5.7 and earlier, a server restart cancels the effect of the AUTO_INCREMENT = N table option,
# which may be used in a CREATE TABLE or ALTER TABLE statement to set an intiial counter value or
# alter the existing counter value, respectively.
#
# In MySQL 8.0, a server restart does not cancel the effect of the AUTO_INCREMENT = N table
# option.
#
# If you initialize the auto-increment counter to a specific value, or if you alter the auto-increment
# counter value to a larger value, the new value is persisted across server restarts.
#
# NOTE:
#
#		ALTER_TABLE_..._AUTO_INCREMENT_=_N can only change the auto-increment counter value to a value
# 		larger than the current maximum.
#
# In MySQL 5.7 and earlier, a server restart immediately following a ROLLBACK operation could
# result in the reuse of auto-increment values that were previously allocated to the rolled-back
# transaction, effectively rolling back the current maximum auto-increment value.
#
# In MySQL 8.0, the current maximum auto-increment value is persisted, preventing the reuse of
# previously allocated values.
#
# If a SHOW_TABLE_STATUS statement examines a table before the auto-increment counter is initialized,
# InnoDB opens the table and initializes the counter value using the current maximum auto-increment
# value that is stored in the data dictionary system table.
#
# The value is stored in memory for use by later inserts or updates. Initialization of the counter-value
# uses a normal exclusive-locking read on the table which lasts to the end of the transaction.

# InnoDB follows the same procedure when intitializing the auto-increment counter for a newly created
# table that has a user-specified auto-increment value that is greater than 0.
#
# After the auto-increment counter is initialized, if you do not explicitly specify an auto-increment
# value when inserting a row, InnoDB implicitly increments the counter and assigns the new value to the
# column.

# If you insert a row that explicitly specifies an auto-increment column value, and the value is greater
# than the current maximum counter value, the counter is set to the specified value.
#
# InnoDB uses the in-memory auto-increment counter as long as the server runs. When the server is stopped
# and restarted, InnoDB reinitializes the auto-increment counter, as described earlier.
#
# The auto_increment_offset configuration option determines the starting point for the AUTO_INCREMENT
# column value.
#
# The default setting is 1.
#
# The auto_increment_increment configuration option controls the interval between successive column values.
# THe default setting is 1.
#
# 15.6.1.5 InnoDB AND FOREIGN KEY CONSTRAINTS
#
# How the InnoDB storage engine handles foreign key constraints is described under the following topics in this section:
#
# 		) Foreign Key Definitions

# 		) Referential Actions
#
# 		) Foreign Key Restrictions for Generated Columns and Virtual Indexes
#
# For foreign key usage information and examples, see Section 13.1.20.6, "Using FOREIGN KEY Constarints"
#
# Foreign Key Definitions
#
# Foreign key definitions for InnoDB tables are subject to the following conditions:
#
# 	) InnoDB permits a foreign key to reference any index column or group of columns.
#
# 		However, in the referenced table, there must be an index where the referenced
# 		columns are the first columns in the same order. Hidden columns that InnoDB adds
# 		to an index are also considered (see Section 15.6.2.1, "Clustered and Secondary Indexes")
#
# 	) InnoDB does not currently support foreign keys for tables with user-defined partitioning.
#
# 		This means that no user-partitioned InnoDB table may contain foreign key references
# 		or columns referenced by foreign keys.
#
# 	) InnoDB allows a foreign key constraint to reference a nonunique key. This is an InnoDB extension to standard SQL.
#
# Referential Actions
#
# 	Referential actions for foreign keys of InnoDB tables are subject to the following conditions:
#
# 		) While SET DEFAULT is allowed by the MySQL server, it is rejected as invalid by InnoDB. CREATE_TABLE and ALTER_TABLE
# 			statements using this clause are not allowed for InnoDB tables.
#
# 		) 	If there are several rows in the parent table that have the same referenced key value, InnoDB acts in foreign key checks
# 			as if the other parent rows with the same key value does not exist.
#
# 			For example, if you have defined a RESTRICT type constraint, and there is a child row with several parent rows, InnoDB
# 			does not permit the deletion of any of those parent rows.
#
# 		) InnoDB performs cascading operations through a depth-first algorithm, based on records in the indexes corresponding to the
# 			foreign key constraints.
#
# 		) If ON UPDATE CASCADE or ON UPDATE SET NULL recurses to update the same table it has previously updated during the cascade, it acts
# 			like RESTRICT.
#
# 			This means that you cannot use self-referential ON UPDATE CASCADE or ON UPDATE SET NULL operations.
#
# 			This is to prevent infinite loops resulting from cascaded updates. A self-referential ON DELETE SET NULL, on the other hand,
# 			is possible, as is a self-referential ON DELETE CASCADE.
#
# 			Cascading operations may not be nested more than 15 levels deep.
#
# 		) Like MySQL in general, in an SQL statement that inserts, deletes, or updates many rows, InnoDB checks UNIQUE and FOREIGN KEY
# 			constraints row-by-row.
#
# 			When performing foreign key checks, InnoDB sets shared row-level locks on child or parent records it has to look at .
#
# 			InnoDB checks foreign key constraints immediately; the check is not deferred to transaction commit. According to the SQL standard,
# 			the default behavior should be deferred checking.
#
# 			That is, constraints are only checked after the entire SQL statement has been processed.

# 			Until InnoDB implements deferred constraint checking, some things are impossible, such as deleting a record that
# 			refers to itself using a foreign key.
#
# Foreign Key Restrictions for Generated Columns and Virtual Indexes
#
# 	) A foreign key constraint on a stored generated column cannot use CASCADE, SET NULL, or SET DEFAULT as ON UPDATE referential
# 		actions, nor can it use SET NULL or SET DEFAULT as ON DELETE referential actions.
#
#  ) A foreign key constraint on the base column of a stored generated column cannot use CASCADE, SET NULL, or SET DEFAULT as ON UPDATE
# 		or ON DELETE referential actions.
#
# 	) A foreign key constraint cannot reference a virtual generated column.
#
# 	) Prior to MySQL 8.0, a foreign key constraint cannot reference a secondary index defined on a virtual generated column.
#
# 15.6.1.6 Limits on InnoDB Tables
#
# Limits on InnoDB tables are described under the following topics in this section:
#
# 		) Maximums and Minimums
#
# 		) Restrictions on InnoDB Tables
#
# 		) Locking and Transactions
#
# 		Warning:
#
# 			Before using NFS with InnoDB, review potential issues outlined in Using NFS with MySQL.
#
# Maximums and Minimums
#
# 	) A table can contain a maximum of 1017 columns. Virtual generated columns are included in this limit.
#
# 	) A table can contain a maximum of 64 secondary indexes.
#
# 	) The index key prefix length limit is 3072 bytes for InnoDB tables that use DYNAMIC or COMPRESSED row format.
#
# 		The index key prefix length limit is 767 bytes for InnoDB tables that use REDUNDANT or COMPACT row format.
#
# 		For example, you might hit this limit with a column prefix index of more than 191 characters on a TEXT
# 		or VARCHAR column, assuming a utf8mb4 character set and the maximum of 4 bytes for each character.
#
# 		Attempting to use an index key prefix length that exceeds the limit returns an error.
#
# 		The limits that apply to index key prefixes also apply to full-column index keys.
#
# 	) If you reduce the InnoDB page size to 8kb or 4kb by specifying the innodb_page_size option when creating
# 		the MySQL instance, the maximum length of the index key is lowered proportionally, based on the limit of
# 		3072 bytes for a 16kb page size.
#
# 		That is, the maximum index key length is 1536 bytes when the page size is 8kb, and 768 bytes when the
# 		page size is 4kb.
#
# 	) A maximum of 16 columns is permitted for multicolumn indexes. Exceeding the limit returns an error.
#
# 		ERROR 1070 (42000): Too many key parts specified; max 16 parts allowed
#
# 	) The maximum row length, except for variable-length columns (VARBINARY, VARCHAR, BLOB and TEXT), is slightly
# 		less than half of a page for 4kb, 8kb, 16kb and 32kb page sizes.
#
# 		For example, the maximum row length for the default innodb_page_size of 16kb is about 8000 bytes.
#
# 		However, for an InnoDB page size of 64kb, the maximum row length is approximately 16k bytes.
#
# 		LONGBLOB and LONGTEXT columns must be less than 4GB, and the total row length, including BLOB and TEXT
# 		columns, must be less than 4GB.
#
# 		If a row is less than half a page long, all of it is stored locally within the page.
#
# 		If it exceeds half a page, variable-length columns are chosen for external off-page storage until
# 		the row fits within half a page, as described in Section 15.11.2, "File Space Management"
#
# 	) Although InnoDB supports row sizes larger than 65,535 bytes internally, MySQL itself imposes a row-size limit
# 		of 65,535 for the combined size of all columns:
#
# 		CREATE TABLE t (a VARCHAR(8000), b VARCHAR(10000),
# 		c VARCHAR(10000), d VARCHAR(10000), e VARCHAR(10000),
# 		f VARCHAR(10000), g VARCHAR(10000)) ENGINE=InnoDB;
# 		ERROR 1118 (42000): Row size too large. The maximum row size for the
# 		used table type, not counting BLOBs, is 65535. You have to change some
# 		columns to TEXT or BLOBs.
#
# 		See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# 	) On some older operating systems, files must be less than 2GB. This is not a limitation
# 		of InnoDB itself, but if you require a large tablespace, configure it using several
# 		smaller data files rather than one large data file.
#
# 	) The combined size of the InnoDB log files can be up to 512GB.
#
# 	) The minimum tablespace size is slightly larger than 10MB. The maximum tablespace size depends
# 		on the InnoDB page size.
#
# 		Table 15.3 InnoDB Maximum Tablespace Size
#
# 			InnoDB Page Size 		Maximum Tablespace Size
#
# 			4kb 						16TB
# 			8kb 						32TB
# 			16kb 						64TB
# 			32kb 						128TB
# 			64kb 						256TB
#
# 		The maximum tablespace size is also the maximum size for a table.
#
# 	) The path of a tablespace file, including the file name, cannot exceed the MAX_PATH limit on Windows.
#
# 		Prior to Windows 10, the MAX_PATH limit is 260 characters. As of Windows 10, version 1607, MAX_PATH
# 		limitations are removed from common Win32 file and directory functions, but you must enable the new
# 		behavior.
#
# 	) The default page size in InnoDB is 16kb. You can increase or decrease the page size by configuring the innodb_page_Size
# 		option when creating the MySQL instance.
#
# 		32kb and 64kb page sizes are supported, but ROW_FORMAT=COMPRESSED is unsupported for page sizes greater than
# 		16kb. For both 32KB and 64KB page sizes, the maximum record size is 16kb.
#
# 		For innodb_page_size = 32kb, extent size is 2MB.
#
# 		For innodb_page_size=64kb, extent size is 4MB.
#
# 		A MySQL instance using a particular InnoDB page size cannot use data files or log files from an instance
# 		that uses a different page size.
#
# Restrictions on InnoDB Tables
#
# 	) ANALYZE_TABLE determines index cardinality (as displayed in the Cardinality column of SHOW_INDEX output)
# 		by performing random dives on each of the index trees and updating index cardinality estimates accordingly.
#
# 		Because these are only estimates, repeated runs of ANALYZE_TABLE could produce different numbers.
#
# 		This makes ANALYZE_TABLE fast on InnoDB tables but not 100% accurate because it does not take all rows
# 		into account.
#
# 		You can make the statistics collected by ANALYZE_TABLE more precise and more stable by turning on the
# 		innodb_stats_persistent configuration option, as explained in Section 15.8.10.1, "Configuring Persistent
# 		Optimizer Statistics Parameters"
#
# 		When that setting is enabled, it is important to run ANALYZE_TABLE after major changes to indexed column
# 		data, because the statistics are not recalculated periodically (such as after a server restart)
#
# 		If the persistent statistics setting is enabled, you can change the number of random dives by modifying
# 		the innodb_stats_persistent_sample_pages system variable.
#
# 		If the persistent statistics setting is disabled; modify the innodb_stats_transient_sample_pages system
# 		variable instead.
#
# 		MySQL uses index cardinality estimates in join optimization. If a join is not optimized in the right way,
# 		try using ANALYZE_TABLE.
#
# 		In the few cases that ANALYZE_TABLE does not produce values good enough for your particular tables, you can
# 		use FORCE INDEX with your queries to force the use of a particular index, or set the max_seeks_for_key
# 		system variable to ensure that MySQL prefers index lookups over table scans.
#
# 		See SECTION B.4.5, "Optimizer-Related Issues"
#
# 	) If statements or transactions are running on a table, and ANALYZE_TABLE is run on the same table followed by a 
# 		second ANALYZE_TABLE operation, the second ANALYZE_TABLE operation is blocked until the statements or transactions
# 		are completed.
#
# 		This behavior occurs because ANALYZE_TABLE marks the currently loaded table definition as obsolete when ANALYZE_TABLE
# 		is finished running.
#
# 		New statements or transactions (including a second ANALYZE_TABLE statement) must load the new table definition into the
# 		table cache, which cannot occur until currently running statements or transactions are completed and the old table
# 		definition is purged.
#
# 		Loading multiple concurrent table definitions is not supported.
#
# ) SHOW_TABLE_STATUS does not give accurate statistics on InnoDB tables except for the physical size reserved by the table.

# 		The row count is only a rough estimate used in SQL optimization.
#
# ) InnoDB does not keep an internal count of rows in a table because concurrent transactions might "see" different number
# 		of rows at the same time.
#
# 		Consequently, SELECT COUNT(*) statements only count rows visible to the current transaction.
#
# 		For information about how InnoDB proceses SELECT COUNT(*) statements, refer to the COUNT() description in 
# 		Section 12.20.1, "Aggregate (GROUP BY) Function Descriptions"
#
# ) On Windows, InnoDB always stores database and table names internally in lowercase. To move database in a binary format
#   from Unix to Windows or from Windows to Unix, create all databases and tables using lowercase names.
#
# ) An AUTO_INCREMENT column ai_col must be defined as part of an index such that it is possible to perform the equivalent
# 	of an indexed SELECT MAX(ai_col) lookup on the table to obtain the maximum column value.
#
#  Typically, this is achieved by making the column the first column of some table index.
#
# ) InnoDB sets an exclusive lock on the end of the index associated with the AUTO_INCREMENT column while initializing a previously
# 	specified AUTO_INCREMENT column on a table.
#
# With innodb_autoinc_lock_mode=0, InnoDB uses a special AUTO-INC table lock mode where the lock is obtained and held to the end
# of the current SQL statement while accessing the auto-increment counter.
#
# Other clients cannot insert into the table while the AUTO-INC table lock is held. The same behavior occurs for "bulk inserts"
# with innodb_autoinc_lock_mode=1.
#
# Table-level AUTO-INC locks are not used with innodb_autoinc_lock_mode=2. For more information, see Section 15.6.1.4, "AUTO_INCREMENT
# Handling in InnoDB"
#
# ) When an AUTO_INCREMENT integer column runs out of values, a subsequent INSERT operation returns a duplicate-key error.
#
# This is general MySQL behavior.
#
# ) DELETE FROM tbl_name does not regenerate the table but instead deletes all rows, one by one.
#
# ) Cascaded foreign key actions do not activate triggers.
#
# ) You cannot create a table with a column name that matches the name of an internal INnoDB column (including DB_ROW_ID, DB_TRX_ID, DB_ROLL_PTR and DB_MIX_ID)
# 		This restriction applies to use of the names in any letter case.
#
# 		CREATE TABLE t1 (c1 INT, db_row_id INT) ENGINE=INNODB;
# 		ERROR 1166 (42000): Incorrect column name 'db_row_id'
#
# Locking and Transactions
#
# ) LOCK_TABLES acquires two locks on each table if innodb_table_locks=1 (the default). In addition to a table lock on the MySQL layer, it also
# 	acquires an InnoDB table lock.
#
#  Versions of MySQL before 4.1.2 did not acquire InnoDB table locks; the old behavior can be selected by setting innodb_table_locks=0.

#  If no InnoDB table lock is acquired, LOCK_TABLES completes even if some records of the tables are being locked by other transactions.
#
# In MySQL 8.0, innodb_table_locks=0 has no effect for tables locked explicitly with LOCK_TABLES_..._WRITE. It does have an effect for tables
# locked for read or write by LOCK_TABLES_..._WRITE implicitly (for example, through triggers) or by LOCK_TABLES_..._READ.
#
# ) All InnoDB locks held by a transaction are released when the transaction is committed or aborted. Thus, it does not make much sense to invoke
# 	LOCK_TABLES on InnoDB tables in autocommit=1 mode because the acquired InnoDB table locks would be released immediately.
#
# ) You cannot lock additional tables in the middle of a transaction because LOCK_TABLES performs an implicit COMMIT and UNLOCK_TABLES
#
# ) For limits associated with concurrent read-write transactions, see SECTION 15.6.6, "Undo logs"
#
# 15.6.2 INDEXES
#
# 15.6.2.1 Clustered and Secondary Indexes
# 15.6.2.2 The Physical Structure of an InnoDB Index
# 15.6.2.3 Sorted Index Builds
# 15.6.2.4 InnoDB FULLTEXT Indexes
#
# This section covers topics related to InnoDB indexes.
#
# 15.6.2.1 Clustered and Secondary Indexes
#
# Every InnoDB table has a special index called the clustered index where the data for the rows is stored.
#
# Typically, the clustered index is synonymous with the primary key. To get hte best performance from queries,
# inserts, and other database operations, you must understand how InnoDB uses the clustered index to optimize the
# most common lookup and DML operations for each table.
#
# 	) When you define a PRIMARY KEY on your table, InnoDB uses it as the clustered index. Define a primary key for each table
# 		that you create.
#
# 		If there is no logical unique and non-null column or set of columns, add a new auto-increment column, whose values
# 		are filled in automatically.
#
# 	) If you do not define a PRIMARY KEY for your table, MySQL locates the first UNIQUE index where all the key columns are NOT NULL
# 		and InnoDB uses it as the clustered index.
#
# 	) If the table has no PRIMARY KEY or suitable UNIQUE index, InnoDB internally generates a hidden clustered index named GEN_CLUST_INDEX
# 		on a synthetic column containing row ID values.
#
# 		The rows are ordered by the ID that InnoDB assigns to the rows in such a table.
#
# 		The row ID is a 6-byte field that increases monotonically as new rows are inserted.
# 		Thus, the rows ordered by the row ID are physically in insertion order.
#
# How the clustered Index speeds up Queries
#
# Accessing a row through the clustered index is fast because the index search leads directly to the page with all the row data.
# If a table is large, the clustered index architechture often saves a disk I/O operation when compared to storage organizations
# that store row data using a different page from the index record.
#
# How Secondary INdexes Relate to the Clustered Index
#
# All indexes other than the clustered index are known as secondary indexes. In InnoDB, each record in a secondary index contains the
# primary key columns for the row, as well as the columns specified for the secondary index.
#
# InnoDB uses this primary key value to search for the row in the clustered index.
#
# If the primary key is long, the secondary indexes use more space, so it is advantageous to have a short primary key.
#
# For guidelines to take advantage of InnoDB clustered and secondary indexes, see Section 8.3, "Optimization and Indexes"
#
# 15.6.2.2 THE PHYSICAL STRUCTURE OF AN INNODB INDEX
#
# With the exception of spatial indexes, InnoDB indexes are B-tree data structures. Spatial indexes use R-trees, which are specialized
# data structures for indexing multi-dimensional data.
#
# Index records are stored in the leaf pages of their B-tree or R-tree data structure. The default size of an index page is 16kb.
#
# When new records are inserted into an InnoDB clustered index, InnoDB tries to leave 1/16 of the page free for future insertions
# and updates of the index records.
#
# If index records are inserted in a sequential order (ascending or descending), the resulting index pages are about 15/16 full.
#
# If records are inserted in a random order, the pages are from 1/2 to 15/16 full.
#
# InnoDB performs a bulk load when creating or rebuilding B-tree indexes. This method of index creation is known as a sorted index build.
#
# The innodb_fill_factor configuration option defines the percentage of space on each B-tree page that is filled during a sorted index build,
# with the remaining space reserved for future index growth.
#
# Sorted index builds are not supported for spatial indexes. For more information, see Section 15.6.2.3, "Sorted Index Builds"
#
# An innodb_fill_factor setting of 100 leaves 1/16 of the space in clustered index pages free for future index growth.
#
# If the fill factor of an InnoDB index page drops below the MERGE_THRESHOLD, which is 50% by default if not specified, InnoDB
# tries to contract the index tree to free the page.
#
# The MERGE_THRESHOLD setting applies to both B-tree and R-tree indexes. For more information, see SECTION 15.8.11, "Configuring the Merge Threshold for Index Pages"
#
# You can define the page size for all InnoDB tablespaces in a MySQL instance by setting the innodb_page_size configuration option prior to initializing the MySQL
# instance.
#
# Once the page size for an instance is defined, you cannot change it without reinitializing the instance. Supported sizes are 64kb, 32kb, 16kb (default), 8kb and 4kb.
#
# A MySQL instance using a particular InnoDB page size cannot use data files or log files from an instance that uses a different page size.
#
# 15.6.2.3 SORTED INDEX BUILDS
#
# InnoDB performs a bulk load instead of inserting one index record at a time when creating or rebuilding indexes. 
#
# This method of index creation is also known as a sorted index build. Sorted index builds are not supported for spatial indexes.
#
# There are three phases to an index build. In the first phase, the clustered index is scanned, and index entries are generated and
# added to the sort buffer.
#
# When the sort buffer becomes full, entries are sorted and written out to a temporary intermediate file.
#
# THis process is also known as a "run". In the second phase, with one or more runs written ot the temporary
# intermediate files, a merge sort is performed on all entries in the file.
#
# In the third and final phase, the sorted entries are inserted into the B-Tree.
#
# Prior to the introduction of sorted index builds, index entries were inserted into the B-tree one record at a time using insert APIs.
#
# This method involved opening a B-tree cursor to find the insert pos and then inserting entries into a B-tree page using an optimistic
# insert.
#
# If an insert failed due to page being full, a pessimistic insert would be performed, which involves opening a B-tree cursor and splitting
# and merging B-tree nodes as necessary to find space for the entry.
#
# The drawbacks of this "top-down" method of building an index are the cost of searching for an insert position and the constant splitting
# and merging of B-tree nodes.
#
# Sorted index builds use a "bottom-up" approach to building an index. With this approach, a reference to the right-most leaf page is held
# at all levels of the B-tree.
#
# The right-most leaf page at the necessary B-tree depth is allocated and entries are inserted according to their sorted order.
#
# Once a leaf page is full, a node pointer is appended to the parent page and a sibling leaf page is allocated for the next insert.
#
# This process continues until all entries are inserted, which may result in inserts up to the root level.
#
# When a sibling page is allocated, the reference to the previously pinned leaf page is released, and the newly allocated leaf page becomes
# the right-most leaf page and new default insert location.
#
# RESERVING B-TREE PAGE SPACE FOR FUTURE INDEX GROWTH
#
# To set aside space for future index growth, you can use the innodb_fill_factor configuration option to reserve a percentage of
# B-tree page space. For example, setting innodb_fill_factor to 80 reserves 20 percent of the space in B-tree pages during a sorted
# index build.
#
# This setting applies to both B-tree leaf and non-leaf pages. It does not apply to external pages used for TEXT or BLOB entries.
#
# The amount of space that is reserved may not be exactly as configured, as the innodb_fill_factor value is interpreted as a hint
# rather than a hard limit.
#
# SORTED INDEX BUILDS AND FULL-TEXT INDEX SUPPORT
#
# Sorted index builds are supported for fulltext indexes. Previously, SQL was used to insert entries into a fulltext index.
#
# SORTED INDEX BUILDS AND COMPRESSED TABLES
#
# For compressed tables, the previous index creation method appended entries to both compressed and uncompressed pages.
# When the modification log (representing free space on the compressed page) became full, the compressed page would be
# recompressed.
#
# If compression failed due to a lack of space, the page would be split.
#
# With sorted index builds, entries are only appended to uncompressed pages. When an uncompressed page becomes full,
# it is compressed.
#
# Adaptive padding is used to ensure that compression succeeds in most cases, but if compression fails, the page is split
# and compression is attempted again.
#
# This process continues until compression is successful.
#
# For more information about compression of B-tree pages, see SECTION 15.9.1.5, "HOW COMPRESSION WORKS FOR INNODB TABLES"
#
# SORTED INDEX BUILDS AND REDO LOGGING
#
# Redo logging is disabled during a sorted index build. Instead, there is a checkpoint to ensure that the index build
# can withstand a crash or failure.
#
# The checkpoint forces a write of all dirty pages to disk. During a sorted index build, the page cleaner thread is signaled
# periodically to flush dirty pages to ensure that the checkpoint operation can be processed quickly.
#
# Normally, the page cleaner thread flushes dirty pages when the number of clean pages falls below a set threshold.
#
# For sorted index builds, dirty pages are flushed promptly to reduce checkpoint overhead and to parallelize I/O and CPU
# activity.
#
# SORTED INDEX BUILDS AND OPTIMIZER STATISTICS
#
# Sorted index builds may result in optimizer statistics that differ from those generated by the previous method of index creation.
# The difference in statistics, which is not expected to affect workload performance, is due to the different algorithm
# used to populate the index.
#
# 15.6.2.4 InnoDB FULLTEXT INDEXES
#
# FULLTEXT indexes are created on text-based columns (CHAR, VARCHAR or TEXT columns) to help speed up queries and DML operations
# on data contained within those columns, omitting any words that are defined as stopwords.
#
# A FULLTEXT index is defined as part of a CREATE_TABLE statement or added to an existing table using ALTER_TABLE or CREATE_INDEX.
#
# Full-text search is performed using MATCH()_..._AGAINST syntax. For usage information, see SECTION 12.9, "FULL-TEXT SEARCH FUNCTIONS".
#
# InnoDB FULLTEXT indexes are described under the following topics in this section:
#
# 		) InnoDB Full-Text Index Design
#
# 		) InnoDB Full-Text Index Tables
#
# 		) InnoDB Full-Text Index Cache
#
# 		) InnoDB Full-Text Index Document ID and FTS_DOC_ID Column
#
# 		) InnoDB Full-Text Index Deletion Handling
#
# 		) InnoDB Full-Text Index Transaction Handling
#
# 		) Monitoring InnoDB Full-Text Indexes
#
# InnoDB Full-Text Index Design
#
# InnoDB FULLTEXT indexes have an inverted index design. Inverted indexes store a list of words, and for each word, a list of
# documents that the word appears in.
#
# To support proximity search, position information for each word is also stored, as a byte offset.
#
# InnoDB Full-Text index Tables
#
# When creating an InnoDB FULLTEXT index, a set of index tables is created, as shown in the following example:
#
# 		CREATE TABLE opening_lines (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			opening_line TEXT(500),
# 			author VARCHAR(200),
# 			title VARCHAR(200),
# 			FULLTEXT idx (opening_line)
# 			) ENGINE=InnoDB;
#
# 		SELECT table_id, name, space from INFORMATION_SCHEMA.INNODB_TABLES WHERE name LIKE 'test/%';
# 		+-----------+---------------------------------------------------------+-------------+
# 		| table_id  | name 																    | space 	   |
# 		+-----------+---------------------------------------------------------+-------------+
# 		| 333 		| test/fts_000000000000000000000147_0000000001c9_index_1  | 289 			|
# 		etc.
#
# The first six tables represent the inverted index and are referred to as auxilliary index tables.
#
# When incoming documents are tokenized, the individual words (also referred to as "tokens") are inserted
# into the index tables along with position information and the associated Document ID (DOC_ID).
#
# The words are fully sorted and partitioned among the six index tables based on the character set sort
# weight of the word's first character.
#
# The inverted index is partitioned into six auxiliary index tables to support parallel index creation.
#
# By default, two threads tokenize, sort, and insert words and associated data into the index tables.
#
# The number of threads is configurable using the innodb_ft_sort_pll_degree option.
#
# Consider increasing the number of threads when creating FULLTEXT indexes on large tables.
#
# Auxiliary index table names are prefixed with fts_ and postfixed with index_*.

# Each index table is associated with the indexed table by a hex value in the index table name
# that matches the table_id of the indexed table.
#
# For example, the table_id of the test/opening_lines table is 327, for which the hex value is
# 0x147.
#
# As shown in the preceding example, the "147" hex value appears in the names of index tables
# that are associated with the test/opening_lines table.
#
# A hex value representing the index_id of the FULLTEXT index also appears in auxiliary index table names.
# For example, in the auxiliary table name test/fts_00000000000147_000000000001c9_index_1, the hex value
# 1c9 has a decimal value of 457.
#
# The index defined on the opening_lines table (idx) can be identified by querying the INFORMATION_SCHEMA.INNODB_INDEXES
# table for this value (457)
#
# SELECT index_id, name, table_id, space FROM INFORMATION_SCHEMA.INNODB_INDEXES
# WHERE index_id=457;
# 	+-----------+----------+--------------+-------------+
#  | index_id  | name 	  | table_id 	  | space 		 |
# 	+-----------+----------+--------------+-------------+
# 	| 457 	   | idx 	  | 327 			  | 283 			 |
# 	+-----------+----------+--------------+-------------+
#
# Index tables are stored in their own tablespace if the primary table is created in a file-per-table tablespace.
#
# The other index tables shown in the preceding example are referred to as common index tables and are used
# for deletion handling and storing the internal state of FULLTEXT indexes.
#
# Unlike the inverted index tables, which are created for each full-text index, this set of tables is common to
# all full-text indexes created on a particular table.
#
# Common auxiliary tables are retained even if full-text indexes are dropped. When a full-text index is dropped,
# the FTS_DOC_ID column that was created for the index is retained, as removing the FTS_DOC_ID column would
# require rebuilding the table.
#
# Common axiliary tables are required to manage the FTS_DOC_ID column.
#
# 	) fts_*_deleted and fts_*_deleted_cache
#
# 		Contain the document IDs (DOC_ID) for documents that are deleted but whose data is not yet removed from the full-text index.
#
# 		The fts_*_deleted_cache is in the in-memory version of the fts_*_deleted table.
#
# 	) fts_*_being_deleted and fts_*_being_deleted_cache
#
# 		Contain the document IDs (DOC_ID) for documents that are deleted and whose data is currently in the process of being
# 		removed from the full-text index.
#
# 		The fts_*_being_deleted_cache table is the in-memory version of the fts_*_being_deleted table.
#
# 	) fts_*_config
#
# 		Stores information about the internal state of the FULLTEXT index. Most importantly, it stores the FTS_SYNCED_DOC_ID,
# 		which identifies documents that have been parsed and flushed to disk.
#
# 		In case of crash recovery, FTS_SYNCED_DOC_ID values are used to identify documents that have not been flushed to disk
# 		so that the documents can be re-parsed and added back to the FULLTEXT index cache.
#
# 		To view the data in this table, query the INFORMATION_SCHEMA.INNODB_FT_CONFIG table.
#
# InnoDB Full-Text Index Cache
#
# When a document is inserted, it is tokenized, and the individual words and associated data are inserted into the
# FULLTEXT index.
#
# This process, even for small documents, could result in numerous small insertions into the auxiliary index tables,
# making concurrent access to these tables a point of contention.
#
# To avoid this problem, InnoDB uses a FULLTEXT index cache to temporarily cache index table insertions for recently
# inserted rows.
#
# This in-memory cache structure holds insertions until the cache is full and then batch flushes them to disk
# (to the auxiliary index tables)
#
# You can query the INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE table to view tokenized data for recently inserted rows.
#
# The caching and batch flushing behavior avoids frequent updates to auxiliary index tables, which could result in 
# concurrent access issues during busy insert and update times.
#
# The batching technique also avoids multiple insertions for the same word, and minimizes duplicate entries.
#
# Instead of flushing each word individually, insertions for the same word are merged and flushed to disk as a 
# single entry, improving insertion efficiency while keeping auxiliary index tables as small as possible.
#
# The innodb_ft_cache_size variable is used to configure the full-text index cache size (on a per-table basis),
# which affects how often the full-text index cache is flushed.
#
# You can also define a global full-text index cache size limit for all tables in a given instance using the
# innodb_ft_total_cache_size option.
#
# THe full-text index cache stores the same information as auxiliary index tables. However, the full-text index
# cache only caches tokenized data for recently inserted rows.
#
# The data that is already flushed to disk (to the full-text auxiliary tables) is not brought back into the full-text
# index cache when queries.
#
# The data in auxiliary index tables is queried directly, and results from the auxiliary index tables are merged with
# results from the full-text index cache before being returned.
#
# InnoDB Full-Text Index Document ID and FTS_DOC_ID Column
#
# InnoDB uses a unique document identifier referred to as a Document ID (DOC_ID) to map words in the full-text index to
# document records where the word appears.
#
# The mapping requires an FTS_DOC_ID column on the indexed table. If an FTS_DOC_ID column is not defined,, InnoDB
# automatically adds a hidden FTS_DOC_ID column when the full-text index is created.
#
# The following example demonstrates this behavior.
#
# The following table definition does not include an FTS_DOC_ID Column:
#
# 		CREATE TABLE opening_lines (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			opening_line TEXT(500),
# 			author VARCHAR(200),
# 			title VARCHAR(200),
# 			) ENGINE=InnoDB;
#
# When you create a full-text index on the table using CREATE FULLTEXT INDEX syntax, a warning is returned which reports
# that InnoDB is rebuilding the table to add the FTS_DOC_ID column.
#
#
# 		CREATE FULLTEXT INDEX idx ON opening_lines(opening_line);
# 		Query OK, 0 rows affected, 1 warning (0.19 sec)
# 		Records: 0 Duplicates: 0 Warnings: 1
#
# 		SHOW WARNINGS;
# 		+------------+-----------+----------------------------------------------------+
# 		| Level 	    | Code 		 | Message 														   |
# 		+------------+-----------+----------------------------------------------------+
# 		| Warning 	 | 124 		 | InnoDB rebuilding table to add column: FTS_DOC_ID  |
# 		+------------+-----------+----------------------------------------------------+
#
# The same warning is returned when using ALTER_TABLE to add a full-text index to a table that does not have an 
# FTS_DOC_ID column.
#
# If you create a full-text index at CREATE_TABLE time and do not specify an FTS_DOC_ID column, InnoDB adds a hidden
# FTS_DOC_ID column, without warning.
#
# Defining an FTS_DOC_ID column at CREATE_TABLE time is less expensive than creating a full-text index on a table
# that is already loaded with data.
#
# If an FTS_DOC_ID column is defined on a table prior to loading data, the table and its indexes do not have to be
# rebuilt to add the new column.
#
# If you are not concerned with CREATE FULLTEXT INDEX performance, leave out the FTS_DOC_ID column to have InnoDB
# create it for you.
#
# InnoDB creates a hidden FTS_DOC_ID column along with a unique index (FTS_DOC_ID_INDEX) on the FTS_DOC_ID column.
#
# If you want to create your own FTS_DOC_ID column, the column must be defined as BIGINT UNSIGNED NOT NULL and
# name FTS_DOC_ID (all upper case), as in the following example:
#
# 		Note:
#
# 			The FTS_DOC_ID column does not need to be defined as an AUTO_INCREMENT column, but AUTO_INCREMENT could make
# 			loading data easier.
#
# CREATE TABLE opening_lines (
# FTS_DOC_ID BIGINT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# opening_line TEXT(500),
# author VARCHAR(200),
# title VARCHAR(200)
# ) ENGINE=InnoDB;
#
# If you choose to define the FTS_DOC_ID column yourself, you are responsible for managing the column to avoid empty
# or duplicate values.
#
# FTS_DOC_ID values cannot be reused, which means FTS_DOC_ID values must be ever increasing.
#
# Optionally, you can create the required unique FTS_DOC_ID_INDEX (all upper case) on the FTS_DOC_ID column.
#
# CREATE UNIQUE INDEX FTS_DOC_ID_INDEX on opening_lines(FTS_DOC_ID);
#
# If you do not create the FTS_DOC_ID_INDEX, InnoDB creates it automatically.
#
# Note:
#
# 		FTS_DOC_ID_INDEX cannot be defined as a descending index because the InnoDB SQL parser does not use descending indexes.
#
# The permitted gap between the largest used FTS_DOC_ID value and new FTS_DOC_ID value is 65535.
#
# To avoid rebuilding the table, the FTS_DOC_ID column is retained when dropping a full-text index.
#
# InnoDB Full-Text Index Deletion Handling
#
# Deleting a record that has a full-text index column could result in numerous small deletions in the auxiliary index tables,
# making concurrent access to these tables a point of contention.
#
# To avoid this problem, the Document ID (DOC_ID) of a deleted document is logged in a special FTS_*_DELETED table whenever
# a record is deleted from an indexed table, and the indexed record remains in the full-text index.
#
# Before returning query results, information in the FTS_*_DELETED table is used to filter out deleted Document IDs.
#
# The benefit of this design is that deletions are fast and inexpensive. The drawback is that the size of the index is not
# immediately reduced after deleting records.
#
# To remove full-text index entries for deleted records, run OPTIMIZE TABLE on the indexed table with innodb_optimize_fulltext_only=ON
# to rebuild the full-text index.
#
# For more information, see Optimizing InnoDB Full-Text indexes.
#
# INNODB FULL-TEXT INDEX TRANSACTION HANDLING
#
# InnoDB FULLTEXT indexes have special transaction handling characteristics due to its caching and batch processing behavior.
#
# Specifically, updates and insertions on a FULLTEXT index are processed at transaction commit time, which means that a FULLTEXT
# search can only see committed data.
#
# The following example demonstrates this behavior.
#
# The FULLTEXT search only returns a result after the inserted lines are committed.
#
# CREATE TABLE opening_lines (
# 		id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 		opening_line TEXT(500),
# 		author VARCHAR(200),
# 		title VARCHAR(200),
# 		FULLTEXT idx (opening_line)
# 		) ENGINE=InnoDB;
#
# BEGIN;
#
# INSERT INTO opening_lines(opening_line,author,title) VALUES
# 		(// String values to insert//);
#
# SELECT COUNT(*) FROM opening_lines WHERE MATCH(opening_line) AGAINST (//STring value//);
# +-----------+
# | COUNT(*)  |
# +-----------+
# | 0 		  |
# +-----------+
#
# COMMIT;
#
# SELECT COUNT(*) FROM opening_lines WHERE MATCH(opening_line) AGAINST('//string value//');
# +-----------+
# | COUNT(*)  |
# +-----------+
# | 1 		  |
# +-----------+
#
# MONITORING INNODB FULL-TEXT INDEXES
#
# You can monitor and examine the special text-processing aspects of InnoDB FULLTEXT indexes by querying the following
# INFORMATION_SCHEMA tables:
#
# 		) INNODB_FT_CONFIG
#
# 		) INNODB_FT_INDEX_TABLE
#
# 		) INNODB_FT_INDEX_CACHE
#
# 		) INNODB_FT_DEFAULT_STOPWORD
#
# 		) INNODB_FT_DELETED
#
# 		) INNODB_FT_BEING_DELETED
#
# You can also view basic information for FULLTEXT indexes and tables by querying INNODB_INDEXES and INNODB_TABLES
#
# For more information, see SECTION 15.14.4, "InnoDB INFORMATION_SCHEMA FULLTEXT INDEX TABLES"
#
# 15.6.3 TABLESPACES
#
# 15.6.3.1 The System Tablespace
# 15.6.3.2 File-Per-Table Tablespaces
# 15.6.3.3 General Tablespaces
# 15.6.3.4 Undo Tablespaces
# 15.6.3.5 Temporary Tablespaces
# 15.6.3.6 Creating a Tablespace Outside of the Data Directory
# 15.6.3.7 Copying Tablespaces to Another Instance
# 15.6.3.8 Moving Tablespace Files While the Server is Offline
# 15.6.3.9 InnoDB Data-at-Rest Encryption
#
# This section covers topics related to InnoDB tablespaces.
#
# 15.6.3.1 The System Tablespace
#
# The InnoDB system tablespace is the storage area for the doublewrite buffer and the change buffer.
#
# The system tablespace also contains table and index data for user-created tables created in the system
# tablespace.
#
# In previous releases, the system tablespace contained the InnoDB data dictionary.
#
# In MySQL 8.0, InnoDB stores metadata in the MySQL data dictionary. See Chapter 14, MySQL Data Dictionary
#
# The system tablespace can have one or more data files. By default, one system tablespace data file, named ibdata1,
# is created in the data directory.
#
# The size and number of system tablespace data files is controlled by the innodb_data_file_path startup option.
#
# For related information, see System Tablespace Data File Configuration.
#
# Resizing the System Tablespace
#
# This section describes how to increase or decrease the size of the InnoDB system tablespace.
#
# Increasing the Size of the InnoDB System Tablespace
#
# The easiest way to increase the size of the InnoDB system tablespace is to configure it from the beginning
# to be auto-extending.
#
# Specify the autoextend attribute for the last data file in the tablespace definition.
#
# Then InnoDB increases the size of that file automatically in 64MB increments when it runs out of space.
#
# The increment size can be changed by setting the value of the innodb_autoextend_increment system variable,
# which is measured in megabytes.
#
# You can expand the system tablespace by a defined amount by adding another data file:
#
# 	1. Shut down the MySQL Server.
#
# 	2. If the previous last data file is defined with the keyword autoextend, change its definition to use a fixed size,
# 		based on how large it has actually grown.
#
# 		Check the size of the data file, round it down to the closest multiple of 1024 x 1024 bytes (= 1MB), and specify this
# 		rounded size explicitly in innodb_data_file_path.
#
# 	3. Add a new data file to the end of innodb_data_file_path, optionally making that file auto-extending. Only the last data file
# 		in the innodb_data_file_path can be specified as auto-extending.
#
# 	4. Start the MySQL server again.
#
# For example, this tablespace has just one auto-extending data file ibdata1:
#
# 		innodb_data_home_dir =
# 		innodb_data_file_path = /ibdata/ibdata1:10M:autoextend
#
# Suppose that this data file, over time, has grown to 988MB. Here is the configuration line after modifying the original data file
# to use a fixed size and adding a new auto-extending data file:
#
# 		innodb_data_home_dir =
# 		innodb_data_file_path = /ibdata/ibdata1:988M;/disk2/ibdata2:50M:autoextend
#
# When you add a new data file to the system tablespace configuration, make sure that the filename does not refer to an existing
# file.
#
# InnoDB creates and initializes the file when you restart the server.
#
# Decreasing The Size of the InnoDB System Tablespace
#
# You cannot remove a data file from the system tablespace. To decrease the system tablespace size, use this procedure:
#
# 		1. Use mysqldump to dump all your InnoDB tables, including InnoDB tables located in the MySQL database.
#
# 			SELECT TABLE_NAME from INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA='mysql' and ENGINE='InnoDB';
# 			+----------------------------------+
# 			| TABLE_NAME 							  |
# 			+----------------------------------+
# 			| columns_priv 						  |
# 			| / etc /
# 	
# 		2. Stop the server
#
# 		3. Remove all the existing tablespace files (*.ibd), including the ibdata and ib_log files. Do not forget to remove *.ibd files
# 			for tables located in the MySQL database.
#
# 		4. Configure a new tablespace.
#
# 		5. Restart the server
#
# 		6. Import the dump files
#
# NOTE:
#
# 		If your databases only use the InnoDB engine, it may be simpler to dump all databases, stop the server, remove all databases and
# 		InnoDB log files, restart the server, and import the dump files.
#
# USING RAW DISK PARTITIONS FOR THE SYSTEM TABLESPACE
#
# You can use raw disk partitions as data files in the InnoDB system tablespace. This technique enables nonbuffered I/O on Windows and
# on some Linux and Unix systems without file system overhead.
#
# Perform tests with and without raw partitions to verify whether this change actually improves performance on your system.
#
# When you use a raw disk partition, ensure that the user ID that runs the MySQL server has read and write privileges for that
# partition.
#
# For example, if you run the server as the mysql user, the partition must be readable and writable by mysql.
#
# If you run the server with the --memlock option, the server must be run as root, so the partition must be readable
# and writable by root.
#
# The procedures described below involve option file modification. For additional information, see Section 4.2.2.2, "Using OPtion Files"
#
# Allocating A Raw Disk Partition on Linux and Unix Systems
#
# 1. When you create a new data file, specify the keyword newraw immediately after the data file size for the innodb_data_file_path option.
#
# 		The partition must be at least as large as the size that you specify.
#
# 		Note that 1MB in InnoDB is 1024 x 1024 bytes, whereas 1MB in Disk specs usually means 1 mil bytes
#
# 			[mysqld]
# 			innodb_data_home_dir=
# 			innodb_data_file_path=/dev/hdd1:3Gnewraw;/dev/hdd2:2Gnewraw
#
# 2. Restart the server.
#
# 		InnoDB notices the newraw keyword and initializes the new partition. However, do not create or change any InnoDB
# 		tables yet.
#
# 		Otherwise, when you next restart the server, InnoDB reinitializes the partition and your changes are lost.
#
# 		(As a safety measure InnoDB prevents users from modifying data when any partition with newraw is specified)
#
# 3. After InnoDB has initialized the new partition, stop the server, change newraw in the data file specification to raw:
#
# 		[mysqld]
# 		innodb_data_home_dir=
# 		innodb_data_file_path=/dev/hdd1:3Graw;/dev/hdd2:2Graw
#
# 4. Restart the server. InnoDB now permits changes to be made.
#
# Allocating a Raw Disk Partition on Windows
#
# On Windows systems, the same steps and accompanying guidelines described for Linux and Unix systems apply except that
# the innodb_data_file_path setting differs slightly on Windows.
#
# 1. When you create a new data file, specify the keyword newraw immediately after the data file size for the innodb_data_file_path option:
#
# 		[mysqld]
# 		innodb_data_home_dir=
# 		innodb_data_file_path=//./D::10Gnewraw
#
# 		The //./ corresponds to the Windows syntax of \\.\ for accessing physical drives. In the example above, D: is the drive letter of the partition.
#
# 2. Restart the server. InnoDB notices the newraw keyword and initializes the new partition.
#
# 3. After InnoDB has initialized the new partition, stop the server, change newraw in the data file specification to raw:
#
# 		[mysqld]
# 		innodb_data_home_dir=
# 		innodb_data_file_path=//./D::10Graw
#
# 4. Restart the server. InnoDB now permits changes to be made.
#
# 15.6.3.2 File-Per-Table Tablespaces
#
# Historically, InnoDB tables were stored in the system tablespace.
#
# This monolithic approach was targeted at machines dedicated to database processing, with carefully
# planned data growth, where any disk storage allocated to MySQL would never be needed for other purposes.
#
# The file-per-table tablespace feature provides a more flexible alternative, where each InnoDB table is stored
# in its own tablespace data file (.ibd file).
#
# This feature is controlled by the innodb_file_per_table configuration option, which is enabled by default.
#
# Advantages 
#
# 	) You can reclaim disk space when truncating or dropping a table stored in a file-per-table tablespace.
#
# 		Truncating or dropping tables stored in the shared system tablespace creates free space internally
# 		in the system tablespace data files (ibdata files) which can only be used for new InnoDB data.
#
# 		Similarly, a table-copying ALTER_TABLE operation on table that resides in a shared tablespace can
# 		increase the amount of space used by the tablespace.
#
# 		Such operations may require as much additional space as the data in the table plus indexes.
#
# 		The additional space required for the table-copying ALTER_TABLE operation is not released
# 		back to the OS as it is for file-per-table tablespaces.
#
# ) The TRUNCATE_TABLE operation is faster when run on tables stored in file-per-table tablespaces.
#
# ) You can store specific tables on separate storage devices, for I/O optimization, space management, or backup
# 		purposes by specifying the location of each table using the syntax:
#
# 			CREATE TABLE ... DATA DIRECTORY = absolute_path_to_directory
#
# 		as explained in SECTION 15.6.3.6, "Creating a Tablespace Outside of the Data Directory"
#
# ) You can run OPTIMIZE_TABLE to compact or recreate a file-per-table tablespace. When you run an OPTIMIZE_TABLE,
# 		InnoDB creates a new .ibd file with a temporary name, using only the space required to store actual data.
#
# 		When the optimization is complete, InnoDB removes the old .ibd file and replaces it with the new one.
#
# 		If the previous .ibd file grew significantly but the actual data only accounted for a portion of its size,
# 		running OPTIMIZE_TABLE can reclaim the unused space.
#
# ) You can move individual InnoDB tables rather than entire databases.
#
# ) You can copy individual InnoDB tables from one MySQL instance to another (known as the transportable tablespace feature)
#
# ) Tables created in file-per-table tablespaces support features associated with compressed and dynamic row formats.
#
# ) You can enable more efficient storage for tables with large BLOB or TEXT columns using the dynamic row format.
#
# ) File-per-table tablespaces may improve chances for a successful recovery and save time when a corruption occurs,
# 		when a server cannot be restarted, or when backup and binary logs are unavailable.
#
# ) You can back up or restore individual tables quickly using the MySQL Enterprise Backup product, without interrupting the
# 		use of other InnoDB tables.
#
# 		This is beneficial if you have tables that require backup less frequently or on a different backup schedule.
#
# 		See Making a Partial Backup for details.
#
# ) File-per-table tablespaces are convenient for per-table status reporting when copying or backing up tables.
#
# ) You can monitor table size at a file system level without accessing MySQL.
#
# ) Common Linux file systems do not permit concurrent writes to a single file when innodb_flush_method is set to O_DIRECT.
# 		As a result, there are possible performance improvements when using file-per-table tablespaces in conjunction
# 		with innodb_flush_method
#
# ) The system tablespace stores the data dictionary and undo logs, and is limited in size by InnoDB tablespace size limits.
#
# 		See Section 15.6.1.6, "Limits on InnoDB Tables"
#
# 		With file-per-table tablespaces, each table has its own tablespace, which provides room for growth.
#
# Potential Disadvantages
#
# 	) With file-per-table tablespaces, each table may have unused space, which can only be utilized by rows of the same table.
#
# 		This could lead to wasted space if not properly managed.
#
# 	) fsync operations must run on each open table rather than on a single file.
#
# 		Because there is a separate fsync operation for each file, write operations on multiple tables cannot be combined
# 		into a single I/O operation.
#
# 		THis may require InnoDB to perform a higher total number of fsync operations.
#
# ) mysqld must keep one open file handle per table, which may impact performance if you have numerous tables in file-per-table tablespaces.
#
# ) More file descriptors are used.
#
# ) innodb_file_per_table is enabled by default in MySQL 5.6 and higher. You may consider disabling it if backward compatibility
# 		with earlier versions of MySQL is a concern.
#
# ) If many tables are growing there is potential for more fragmentation which can impede DROP_TABLE and table scan performance.
#
# 		However, when fragmentation is managed, having files in their own tablespace can improve performance.
#
# ) The buffer pool is scanned when dropping a file-per-table tablespace, which can take several seconds for buffer pools that are
# 		tens of gigabytes in size.
#
# 		The scan is performed with a broad internal lock, which may delay other operations.
#
# 		Tables in the system tablespace are not affected.
#
# ) The innodb_autoextend_increment variable, which defines increment size (in MB) for extending the size of an auto-extending
# 		shared tablespace file when it becomes full, does not apply to file-per-table tablespace files, which are auto-extending
# 		regardless of the innodb_autoextend_increment setting.
#
# 		The initial extensions are by small amounts, after which extensions occur in increments of 4MB.
#
# ENABLING FILE-PER-TABLE TABLESPACES
#
# The innodb_file_per_table option is enabled by default.
#
# To set the innodb_file_per_table option at startup, start the server with the --innodb_file_per_table command-line option,
# or add this line to the [mysqld] section of my.cnf:
#
# 		[mysqld]
# 		innodb_file_per_table=1
#
# You can also set innodb_file_per_table dynamically, while the server is running:
#
# 		SET GLOBAL innodb_file_per_table=1;
#
# With innodb_file_per_table enabled, you can store InnoDB tables in a tbl_name.ibd file.
#
# Unlike the MyISAM storage engine, with its separate tbl_name.MYD and tbl_name.MYI files
# for indexes and data, InnoDB stores the data and the indexes together in a single .ibd file.
#
# If you disable innodb_file_per_table in your startup options and restart the server, or disable it
# with the SET GLOBAL command, InnoDB creates new tables inside the system tablespace unless you have
# explicitly placed the table in file-per-table tablespace or general tablespace using the CREATE_TABLE_..._TABLESPACE
# option.
#
# You can always read and write any InnoDB tables, regardless of the file-per-table setting.
#
# To move a table from the system tablespace to its own tablespace, change the innodb_file_per_table setting and rebuild the table:
#
# 		SET GLOBAL innodb_file_per_table=1;
# 		ALTER TABLE table_name ENGINE=InnoDB;
#
# Tables added to the system tablespace using CREATE_TABLE_..._TABLESPACE or ALTER_TABLE_..._TABLESPACE syntax are not affected
# by the innodb_file_per_table setting.
#
# To move these tables from the system tablespace to a file-per-table tablespace, they must be moved explicitly using ALTER_TABLE_..._TABLESPACE
# syntax.
#
# Note:
#
# 		InnoDB always needs the system tablespace because it puts its internal data dictionary and undo logs there.
# 		The .ibd files are not sufficient for InnoDB to operate.
#
# 		When a table is moved out of the system tablespace into its own .ibd file, the data files that make up the system
# 		tablespace remain the same size.
#
# 		The space formerly occupied by the table can be reused for new InnoDB data, but is not reclaimed for use by the OS.
# 
# 		When moving large InnoDB tables out of the system tablespace, where disk space is limited, you may prefer to enable
# 		innodb_file_per_table and recreate the entire instance using the mysqldump command.
#
# 		As mentioned above, tables added to the system tablespace using CREATE_TABLE_..._TABLESPACE or ALTER_TABLE_..._TABLESPACE
# 		syntax are not affected by the innodb_file_per_table setting.
#
# 		These tables must be moved individually.
#
# 	15.6.3.3 GENERAL TABLESPACES
#
# A general tablespace is a shared InnoDB tablespace that is created using CREATE_TABLESPACE syntax.
#
# General tablespace capabilities and features are described under the following topics in this section:
#
# 		) General Tablespace Capabilities
#
# 		) Creating a General Tablespace
#
# 		) Adding Tables to a General Tablespace
#
# 		) General Tablespace Row Format Support
#
# 		) Moving Tables Between Tablespaces Using ALTER TABLE
#
# 		) Renaming a General Tablespace
#
# 		) Dropping a General Tablespace
#
# 		) General Tablespace Limitations
#
# General Tablespace Capabilities
#
# The general tablespace feature provides the following capabilities:
#
# 		) Similar to the system tablespace, general tablespaces are shared tablespaces that can store data for multiple tables.
#
# 		) General tablespaces have a potential memory advantage over file-per-table tablespaces.
#
# 			The server keeps tablespace metadata in memory for the lifetime of a tablespace.
#
# 			Multiple tables in fewer general tablespaces consume less memory for tablespace metadata than the same number
# 			of tables in separate file-per-table tablespaces.
#
# 		) General tablespace data files may be placed in a directory relative to or independent of the MySQL data directory,
# 			which provides you with many of the data file and storage management capabilities of file-per-table tablespaces.
#
# 			As with file-per-table tablespaces, the ability to place data files outside of the MySQL data directory
# 			allows you to manage performance of critical tables separately, setup RAID or DRBD for specific tables,
# 			or bind tables to particular disks, for example.
#
# 		) General tablespaces support both Antelope and barracuda file formats, and therefore support all table row formats
# 			and associated features.
#
# 			With support for both file formats, general tablespaces have no dependence on innodb_file_format or innodb_file_per_table
# 			settings, nor do these variables have any effect on general tablespaces.
#
# 		) The TABLESPACE option can be used with CREATE_TABLE to create tables in a general tablespaces, file-per-table tablespace,
# 			or in the system tablespace.
#
# 		) The TABLESPACE option can be used with ALTER_TABLE to move tables between general tablespaces, file-per-table tablespaces,
# 			and the system tablespace.
#
# 			Previously, it was not possible to move a table from a file-per-table tablespace to the system tablespace.
#
# 			With the general tablespace feature, you can now do so.
#
# Creating a General Tablespace
#
# General tablespaces are created using CREATE_TABLESPACE syntax.
#
# 		CREATE TABLESPACE tablespace_name
# 			[ADD DATAFILE 'file_name']
# 			[FILE_BLOCK_SIZE = value]
# 				[ENGINE [=] engine_name]
#
# A general tablespace can be created in the data directory or outside of it.
#
# To avoid conflicts with implicitly created file-per-table tablespaces, creating a general tablespace
# in a subdirectory under the data directory is not supported.
#
# When creating a general tablespace outside of the data directory, the directory must exist and must be
# known to InnoDB prior to creating the tablespace.
#
# To make an unknown directory known to InnoDB, add the directory to the innodb_directories argument value.
#
# innodb_directories is a read-only startup option. Configuring it requires restarting the server.
#
# Examples:
#
# 	Creating a general tablespace in the data directory:
#
# 		CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' Engine=InnoDB;
#
#  or
#
# 		CREATE TABLESPACE `ts1` Engine=InnoDB;
#
#
# The ADD DATAFILE clause is optional as of MySQL 8.0.14 and required before that. if the ADD DATAFILE clause is not specified
# when creating a tablespace, a tablespace data file with a unique file name is created implicitly.
#
# The unique file name is a 128 bit UUID formatted into five groups of hexadecimal numbers separated by dashes
# (aaaaaaaa-bbbb-cccc-dddd-eeeeeeee).
#
# General tablespace data files include an .ibd file extension. In a replication environment, the data file name created on the
# master is not the same as the data file name created on the slave.
#
# Creating a general tablespace in a directory outside of the data directory:
#
# 		CREATE TABLESPACE `ts1` ADD DATAFILE '/my/tablespace/directory/ts1.ibd' Engine=InnoDB;
#
# You can specify a path that is relative to the data directory as long as the tablespace directory is not under the data
# directory.
#
# In this example, the my_tablespace directory is at the same level as the data directory:
#
# 		CREATE TABLESPACE `ts1` ADD DATAFILE '../my_tablespace/ts1.ibd' Engine=InnoDB;
#
# Note:
#
# 		The ENGINE = InnoDB clause must be defined as part of the CREATE_TABLESPACE statement, or InnoDB must be defined
# 		as the default storage engine (default_storage_engine=InnoDB).
#
# Adding Tables to a General Tablespace
#
# After creating an InnoDB general tablespace, you can use CREATE_TABLE_tbl_name_..._TABLESPACE_[=]_tablespace_name or
# ALTER_TABLE_tbl_name_TABLESPACE_[=]_tablespace_name to add tables to the tablespace, as shown in the following examples:
#
# 		CREATE_TABLE
#
# 			CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts1;
#
# 		ALTER_TABLE
#
# 			ALTER TABLE t2 TABLESPACE ts1;
#
# NOTE:
#
# 		Support for adding table partitions to shared tablespaces was deprecated in MySQl 5.7.24 and removed in MySQL 8.0.13.
#
# 		Shared tablespaces include the InnoDB system tablespace and general tablespaces.
#
# For detailed syntax information, see CREATE_TABLE and ALTER_TABLE
#
# General Tablespace Row Format Support
#
# General tablespaces support all table row formats (REDUNDANT, COMPACT, DYNAMIC, COMPRESSED) with the caveat that compressed
# and uncompressed tables cannot coexist in the same general tablespace due to different physical page sizes.
#
# For a general tablespace to contain compressed tables (ROW_FORMAT=COMPRESSED), FILE_BLOCK_SIZE must be specified, and the
# FILE_BLOCK_SIZE value must be a valid compressed page size in relation to the innodb_page_size value.
#
# Also, the physical page size of the compressed table (KEY_BLOCK_SIZE) must be equal to FILE_BLOCK_SIZE/1024.
#
# For example, if innodb_page_size=16kb and FILE_BLOCK_SIZE=8k, the KEY_BLOCK_SIZE of the table must be 8.
#
# The following table shows permitted innodb_page_size, FILE_BLOCK_SIZE, and KEY_BLOCK_SIZE combinations. FILE_BLOCK_SIZE
# values may also be specified in bytes.
#
# To determine a valid KEY_BLOCK_SIZE value for a given FILE_BLOCK_SIZE, divide the FILE_BLOCK_SIZE value by 1024.
#
# Table compression is not supported for 32k and 64k InnoDB page sizes.
#
# For more information about KEY_BLOCK_SIZE, see CREATE_TABLE, and Section 15.9.1.2, "Creating Compressed Tables"
#
# Table 15.4 Permitted Page Size, FILE_BLOCK_SIZE, and KEY_BLOCK_SIZE Combinations for Compressed Tables
#
# InnoDB Page Size (innodb_page_size) 			Permitted FILE_BLOCK_SIZE Value 				Permitted KEY_BLOCK_SIZE Value
#
# 		64KB 														64k (65536) 											Compression is not supported
#
# 		32kb 														32k (32768) 											Compression is not supported
#
# 		16kb 														16k (16384) 											N/A: If innodb_page_size is equal to FILE_BLOCK_SIZE,
# 																																the tablespace cannot contain a compressed table.
#
# 		16kb 														8k (8192) 												8
#
# 		16kb 														4k (4096) 												4
#
# 		16kb 														2k (2048) 												2
#
# 		16kb 														1k (1024) 												1
#
# 		8kb 														8K (8192) 												N/A: If innodb_page_size is equal to FILE_BLOCK_SIZE,
# 																																the tablespace cannot contain a compressed table
#
# 		8kb 														4k (4096) 												4
#
# 		8kb 														2k (2048) 												2
#
# 		8kb 														1k (1024) 												1
#
# 		4kb 														4k (4096) 												N/A: If innodb_page_size is equal to FILE_BLOCK_SIZE,
# 																																the tablespace cannot contain a compressed table.
#
# 		4kb 														2k (2048) 												2
#
# 		4kb 														1k (1024) 												1
#
# This example demonstrates creating a general tablespace and adding a compressed table. The example assumes a default innodb_page_size of 16kb.
#
# The FILE_BLOCK_SIZE of 8192 requires that the compressed table have a KEY_BLOCK_SIZE of 8.
#
# 		CREATE TABLESPACE `ts2` ADD DATAFILE 'ts2.ibd' FILE_BLOCK_SIZE = 8192 Engine=InnoDB;
#
# 		CREATE TABLE t4 (c1 INT PRIMARY KEY) TABLESPACE ts2 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8;
#
# If you do not specify FILE_BLOCK_SIZE when creating a general tablespace, FILE_BLOCK_SIZE defaults to innodb_page_size.
#
# When FILE_BLOCK_SIZE is equal to innodb_page_size, the tablespace may only contain tables with an uncompressed row format
# (COMPACT, REDUNDANT, and DYNAMIC row formats)
#
# Moving Tables Between Tablespaces using ALTER TABLE
#
# You can use ALTER_TABLE with the TABLESPACE option to move a table to an existing general tablespace, to a new file-per-table tablespace,
# or to the system tablespace.
#
# Note:
#
# 		Support for placing table partitions in shared tablespaces was deprecated in MySQL 5.7.24 and removed MySQL 8.0.13.
#
# 		Shared tablespaces include the InnoDB system tablespace and general tablespaces.
#
# To move a table from a file-per-table tablespace or from the system tablespace to a general tablespace, specify the name
# of the genral tablespace.
#
# The general tablesapce must exist. See CREATE_TABLESPACE for more information.
#
# 		ALTER TABLE tbl_name TABLESPACE [=] tablespace_name;
#
# To move a table from a general tablespace or file-per-table tablespace to the system tablespace, specify innodb_system as the
# tablespace name.
#
# 		ALTER TABLE tbl_name TABLESPACE [=] innodb_system;
#
# To move a table from the system tablespace or a general tablespace to a file-per-table tablespace, specify innodb_file_per_table
# 	as the tablespace name.
#
# 		ALTER TABLE tbl_name TABLESPACE [=] innodb_file_per_table;
#
# ALTER TABLE ... TABLESPACE operations always cause a full table rebuild, even if the TABLESPACE attribute has not changed from
# its previous value.
#
# ALTER TABLE ... TABLESPACE syntax does not support moving a table from a temporary tablespace to a persistent tablespace.
#
# The DATA DIRECTORY clause is permitted with CREATE TABLE ... TABLESPACE=innodb_file_per_table but is otherwise not supported
# for use in combination with the TABLESPACE option.
#
# Restrictions apply when moving tables from encrypted tablespaces. See Encryption Limitations.
#
# Renaming a General Tablespace
#
# Renaming a general tablespace is supported using ALTER_TABLESPACE_..._RENAME_TO syntax
#
# 		ALTER TABLESPACE s1 RENAME TO s2;
#
# The CREATE_TABLESPACE privilege is required to rename a general tablespace.
#
# RENAME TO operations are implicitly performed in autocommit mode, regardless of the autocommit setting.
#
# A RENAME TO operation cannot be performed while LOCK_TABLES or FLUSH_TABLES_WITH_READ_LOCK is in effect for
# tables that reside in the tablespace.
#
# Exclusive metadata locks are taken on tables within a general tablespace while the tablespace is renamed,
# which prevents concurrent DDL.
#
# Concurrent DML is supported.
#
# Dropping a General Tablespace
#
# the DROP_TABLESPACE statement is used to drop an InnoDB general tablespace.
#
# All tables must be dropped from the tablespace prior to a DROP_TABLESPACE operaiton.
#
# If the tablespace is not empty, DROP_TABLESPACE returns an error.
#
# Use a query similar to the following to identify tables in a general tablespace.
#
# 		SELECT a.NAME AS space_name, b.NAME AS table_name FROM INFORMATION_SCHEMA.INNODB_TABLESPACES a,
# 		INFORMATION_SCHEMA.INNODB_TABLES b WHERE a.SPACE=b.SPACE AND a.NAME LIKE 'ts1';
#
# 		+-------------+-------------+
# 		| space_name  | table_name  |
# 		+-------------+-------------+
# 		| ts1 		  | test/t1 	 |
# 		| ts1 		  | test/t2 	 |
# 		| ts1 		  | test/t3 	 |
# 		+-------------+-------------+
#
# A general InnoDB tablespace is not deleted automatically when the last table in the tablespace is dropped.
#
# The tablespace must be dropped explicitly using DROP_TABLESPACE_tablespace_name
#
# A general tablespace does not belong to any particular database. A DROP_DATABASE operation can drop tables
# that belong to a general tablespace but it cannot drop the tablespace, even if the DROP_DATABASE operation
# drops all tables that belong to the tablespace.
#
# A general tablespace must be dropped explicitly using DROP_TABLESPACE tablespace_name.
#
# SImilar to the system tablespace, truncating or dropping tables stored in a general tablespace creates free
# space internally in the general tablespace .ibd data file which can onl be used for new InnoDB data.
#
# Space is not released back to the OS as it is when a file-per-table tablespace is deleted during a DROP_TABLE
# operation.
#
# This example demonstrates how to drop an InnoDB general tablespace. The general tablespace ts1 is created
# with a single table.
#
# The table must be dropped before dropping the tablespace.
#
# CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' Engine=InnoDB;
#
# CREATE TABLE t1 (c1 INT PRIMARY KEY) TABLESPACE ts10 Engine=InnoDB;
#
# DROP TABLE t1;
#
# DROP TABLESPACE ts1;
#
# NOTE:
#
# 		tablespace_name is a case-sensitive identifier in MySQL
#
# GENERAL TABLESPACE LIMITATIONS
#
# ) A generated or existing tablespace cannot be changed to a general tablespace.
#
# ) Creation of temporary general tablespaces is not supported
#
# ) General tablespaces do not support temporary tables
#
# ) Similar to the system tablespace, truncating or dropping tables stored in a general tablespace creates free space internally
# 		in the general tablespace .ibd data file which can only be used for new InnoDB data.
#
# 		Space is not released back to the OS as it is for file-per-table tablespaces.
#
# 		Additionally, a table-copying ALTER_TABLE operation on table that resides in a shared tablespace (a general tablespace or the system
# 		tablespace) can increase the amount of space used by the tablespace.
#
# 		Such operations require as much additional space as the data in the table plus indexes.
#
# 		The additional space required for the table-copying ALTER_TABLE operation is not released back to the
# 		OS as it is for file-per-table tablespaces.
#
# ) ALTER_TABLE_..._DISCARD_TABLESPACE and ALTER_TABLE_..._IMPORT_TABLESPACE are not supported for tables that belong to a general tablespace.
#
# ) Support for placing table partitions in general tablespaces was deprecated in MySQl 5.7.24 and removed in MySQL 8.0.13
#
# 15.6.3.4 UNDO TABLESPACES
#
# Undo tablespaces contain undo logs, which are collections of undo log records that contain information about how to undo
# the latest change by a transaction to a clustered index record.
#
# Undo logs exist within undo log segments, which are contained within rollback segments.
#
# The innodb_rollback_segments variable defines the number of rollback segments allocated to each undo tablespace.
#
# Two default undo tablespaces are created when the MySQL instance is initialized. Default undo tablespaces are created at initialization
# time to provide a location for rollback segments that must exist before SQL statements can be accepted.
#
# A minimum of two undo tablespaces is required to support automated truncation of undo tablespaces.
#
# See Truncating Undo Tablespaces.
#
# Default undo tablespaces are created in the location defined by the innodb_undo_directory variable.
#
# If the innodb_undo_directory variable is undefined, default undo tablespaces are created in the data directory.
# Default undo tablespace data files are named undo_001 and undo_002.
#
# The corresponding undo tablespace names defined in the data dictionary are innodb_undo_001 and innodb_undo_002
#
# As of MySQL 8.0.14, additional undo tablespaces can be created at runtime using SQL. See Adding Undo Tablespaces.
#
# The initial size of an undo tablespace data file depends on the innodb_page_size value. For the default 16kb page size,
# the initial undo tablespace file size is 10MiB.
#
# For 4kb, 8kb, 32kb, and 64kb page sizes, the initial undo tablespace files sizes are 7MiB, 8MiB, 20MiB, and 40MiB, respectively.
#
# Adding Undo Tablespaces
#
# Because undo logs can become large during long-running transactions, creating additional undo tablespaces can help prevent
# individual undo tablespaces from becoming too large.
#
# As of MySQL 8.0.14, additional undo tablespaces can be created at runtime using CREATE_UNDO_TABLESPACE syntax.
#
# 		CREATE UNDO TABLESPACE tablespace_name ADD DATAFILE 'file_name.ibu'
#
# The undo tablespace file name must have an .ibu extension. It is not permitted to specify a relative path when defining
# the undo tablespace file name.
#
# A fully qualified path is permitted, but the path must be known to InnoDB. Known paths are those defined by the innodb_directories
# variable.
#
# Unique undo tablespace file names are recommended to avoid potential file name conflicts when moving or cloning data.
#
# At startup, directories defined by the innodb_directories variable are scanned for undo tablespace files.
#
# (The scan also traverses subdirectories). Directories defined by the innodb_data_home_dir, innodb_undo_directory, and datadir
# variables are automatically appended to the innodb_directories value, regardless of whether the innodb_directories variable
# is defined explicitly.
#
# An undo tablespace can therefore reside in paths defined by any of those variables.
#
# If the undo tablespace file name does not include a path, the undo tablespace is created in the directory defined by the
# innodb_undo_directory variable.
#
# If that variable is undefined, the undo tablespace is created in the data directory.
#
# NOTE:
#
# 		The InnoDB recovery process requires that undo tablespace files reside in known directories.
# 		Undo tablespace files must be discovered and opened before redo recovery and before other data
# 		files are opened to permit uncommitted transactions and data dictionary changes to be rolled back.
#
# 		An undo tablespace not found before recovery cannot be used, which can cause database inconsistencies.
#
# 		An error message is reported at startup if an undo tablespace known to the data dictionary is not found.
#
# 		The known directory requirement also supports undo tablespace portability. See Moving Undo Tablespaces.
#
# To create undo tablespaces in a path relative to the data directory, set the innodb_undo_directory variable
# to the relative path, and specify the file name only when creating an undo tablespace.
#
# To view undo tablespace names and paths, query INFORMATION_SCHEMA.FILES:
#
# 		SELECT TABLESPACE_NAME, FILE_NAME FROM INFORMATION_SCHEMA.FILES
# 			WHERE FILE_TYPE LIKE 'UNDO LOG';
#
# A MySQL instance supports up to 127 undo tablespaces including the two default undo tablespaces created when the
# MySQL instance is initialized.
#
# 	NOTE:
#
# 		Prior to MySQL 8.0.14, additional undo tablespaces are created by configuring the innodb_undo_tablespaces startup
# 		variable.
#
# 		This variable is deprecated and no longer configurable as of MySQL 8.0.14
#
# 		Prior to MySQL 8.0.14, increasing the innodb_undo_tablespaces setting creates the specified number of undo tablespaces
# 		and adds them to the list of active undo tablespaces.
#
# 		Decreasing the innodb_undo_tablespaces setting removes undo tablespaces from the list of active undo tablespaces.
#
# 		Undo tablespaces that are removed from the active list remain active until they are no longer used by existing transactions.
#
# 		The innodb_undo_tablespaces variable can be configured at runtime using a SET statement or defined in a configuration file.
#
# 		Prior to MySQL 8.0.14, deactivated undo tablespaces cannot be removed. Manual removal of undo tablespaces file is possible
# 		after a slow shutdown but is not recommended, as deactivated undo tablespaces may contain active undo logs for some time
# 		after hte server is restarted if open transactions were present when shutting down the server.
#
# 		As of MySQL 8.0.14, undo tablespaces can be dropped using DROP_UNDO_TABLESPACE syntax.
#
# 		See Dropping Undo Tablespaces.
#
# DROPPING UNDO TABLESPACES
#
# 		As of MySQL 8.0.14, undo tablespaces created using CREATE_UNDO_TABLESPACE syntax can be dropped at runtime using
# 		DROP_UNDO_TABLESPACE syntax.
#
# 		An undo tablespace must be empty before it can be dropped. To empty an undo tablespace, the undo tablespace must first
# 		be marked as inactive using ALTER_UNDO_TABLESPACE syntax so that the tablespace is no longer used for assigning rollback
# 		segments to new transactions.
#
# 			ALTER UNDO TABLESPACE tablespace_name SET INACTIVE;
#
# 		After an undo tablespace is marked as inactive, transactions currently using rollback segments in the undo tablespace are
# 		permitted to finish, as are any transactions started before those transactions are completed.
#
# 		After transactions are completed, the purge system frees the rollback segments in the undo tablespace, and the undo
# 		tablespace is truncated to its initial size.
#
# 		(The same process is used when truncating undo tablespaces. See Truncating Undo Tablespaces)
#
# 		When the undo tablespace is empty, it can be dropped:
#
# 			DROP UNDO TABLESPACE tablespace_name;
#
# 		NOTE:
#
# 			Alternatively, the undo tablespace can be left in an empty state and reactivated later, when needed,
# 			by issuing an ALTER_UNDO_TABLESPACE tablespace_name_SET_ACTIVE statement.
#
# 		The state of an undo tablespace can be monitored by querying the INFORMATION_SCHEMA.INNODB_TABLESPACE table.
#
# 			SELECT NAME, STATE FROM INFORMATION_SCHEMA.INNODB_TABLESPACES
# 				WHERE NAME LIKE tablespace_name;
#
# 		An inactive state indicates that rollback segments in an undo tablespace are no longer used by new transactions.
#
# 		An empty state indicates that an undo tablespace is empty and ready to be dropped, or made active again using an
# 		ALTER_UNDO_TABLESPACE_tablespace_name_SET_ACTIVE statement.
#
# 		Attempting to drop an undo tablespace that is not empty returns an error.
#
# 		The default undo tablespaces (innodb_undo_001 and innodb_undo_002) created when the MySQL instance is initialized
# 		cannot be dropped.
#
# 		They can, however, be made inactive using an ALTER_UNDO_TABLESPACE_tablespace_name_SET_INACTIVE statement.
#
# 		Before a default undo tablespace can be made inactive, there must be an undo tablespace to take its place.
#
# 		A minimum of two active undo tablespaces are required at all times to support automated truncation of undo tablespaces.
#
# MOVING UNDO TABLESPACES
#
# Undo tablespaces created with CREATE_UNDO_TABLESPACE syntax can be moved while the server is offline to any known directory.
#
# Known directories are those defined by the innodb_directories variable. Directories defined by innodb_data_home_dir, innodb_undo_directory,
# and datadir are automatically appended to the innodb_directories values regardless of whether the innodb_directories variable is defined
# explicitly.
#
# Those directories and their sub dirs are scanned at startup for undo tablespace files.
#
# An undo tablespace file moved to any of those directories is discovered at startup and assumed to be the undo tablespace that was moved.
#
# The default undo tablespaces (innodb_undo_001 and innodb_undo_002) created when the MySQL instance is initialized must always reside in the
# directory defined by the innodb_undo_directory variable.
#
# If the innodb_undo_directory variable is undefined, default undo tablespaces reside in the data directory.
#
# If default undo tablespaces are moved while the server is offline, the server must be started with the innodb_undo_directory variable
# configured to the new directory.
#
# The I/O patterns for undo logs make undo tablespaces good candidates for SSD storage.
#
# Configuring the Number of Rollback Segments
#
# The innodb_rollback_segments variable defines the number of rollback segments allocated to each undo tablespace
# and to the global temporary tablespace.
#
# The innodb_rollback_segments variable can be configured at startup or while the server is running.
#
# The default setting for innodb_rollback_segments is 128, which is also the maximum value. For more information
# about the number of transactions that a rollback segment supports, see SECTION 15.6.6, "Undo Logs"
#
# Truncating Undo Tablespaces
#
# There are two methods of truncating undo tablespaces, which can be used individually or in combination to manage
# undo tablespace size. One method is automated, enabled using configuration variables.
#
# The other method is manual, performed using SQL statements.
#
# The automated method does not require monitoring undo tablespace size and, once enabled, it performs deactivation,
# truncation and reactivation of undo tablespaces without manual intervention.
#
# The manual truncation method may be preferable if you want to control when undo tablespaces are taken offline for
# truncation. For example, you may want to avoid truncating undo tablespaces during peak workload times.
#
# Automated Truncation
#
# Automated truncation of undo tablespaces requires a minimum of two active undo tablespaces, which ensures that one
# undo tablespace remains active while the other is taken offline to be truncated.
#
# By default, two undo tablespaces are created when the MySQL instance is initialized.
#
# To have undo tablespaces automatically truncated, enable the innodb_undo_log_truncate variable. For example:
#
# 		SET GLOBAL innodb_undo_log_truncate=ON;
#
# When the innodb_undo_log_truncate variable is enabled, undo tablespaces that exceed the size limit defined by the
# innodb_max_undo_log_size variable are subject to truncation.
#
# The innodb_max_undo_log_size variable is dynamic and has a default value of 1073741824 bytes (1024 MiB)
#
# SELECT @@innodb_max_undo_log_size;
# +--------------------------------+
# | @@innodb_max_undo_log_size 	  |
# +--------------------------------+
# | 				1073741824 			  |
# +--------------------------------+
#
# When the innodb_undo_log_truncate variable is enabled:
#
# 		1. Default and user-defined undo tablespaces that exceed the innodb_max_undo_log_size setting are marked for truncation.
#
# 			Selection of an undo tablespace for truncation is performed in a circular fashion to avoid truncating the same undo tablespace
# 			each time.
#
# 		2. Rollback segments residing in the selected undo tablespace are made inactive so that they are not assigned to new transactions.
#
# 			Existing transactions that are currently using rollback segments are permitted to finish.
#
# 		3. The purge system frees rollback segments that are no longer in use.
#
# 		4. After all rollback segments in the undo tablespace are freed, the truncate operation runs and truncates the undo tablespace to its
# 			initial size.
#
# 			The initial size of an undo tablespace depends on the innodb_page_size value. For the default 16kb page size, the initial undo tablespace
# 			file size is 10MiB.
#
# 			For 4kb, 8kb, 32kb and 64kb page sizes, the initial undo tablespace files sizes are 7MiB, 8MiB, 20MiB, and 40MiB, respectively.
#
# 			The size of an undo tablespace after a truncate operation may be larger than the initial size due to immediate use following the completion
# 			of the operation.
#
# 			The innodb_undo_directory variable defines the location of default undo tablespace files. If the innodb_undo_directory variable is undefined,
# 			default undo tablespaces reside in the data directory.
#
# 			The location of all undo tablespace files including user-defined undo tablespaces created using CREATE_UNDO_TABLESPACE syntax can be determined
# 			by querying the INFORMATION_SCHEMA.FILES table:
#
#
# 				SELECT TABLESPACE_NAME, FILE_NAME FROM INFORMATION_SCHEMA.FILES WHERE FILE_TYPE LIKE 'UNDO LOG';
#
# 		5. Rollback segments are reactivated so that they can be assigned to new transactions.
#
# MANUAL TRUNCATION
#
# Manual truncation of undo tablespaces requires a minimum of three active undo tablespaces. Two active undo tablespaces are required at all times
# to support the possibility that automated truncation is enabled.
#
# A minimum of three undo tablespaces satisfies this requirement while permitting an undo tablespace to be taken offline manually.
#
# To manually initiate truncation of an undo tablespace, deactivate the undo tablespace by issuing the following statement:
#  			
# 		ALTER UNDO TABLESPACE tablespace_name SET INACTIVE;
#
# After the undo tablespace is marked as inactive, transactions currently using rollback segments in the undo tablespace are permitted
# to finish, as are any transactions started before those transactions are completed.
#
# After transactions are completed, the purge system frees the rollback segments in the undo tablespace, the undo tablespace
# is truncated to its initial size, and the undo tablespace state changes from inactive to empty.
#
# NOTE:
#
# 		When an ALTER UNDO TABLESPACE tablespace_name SET INACTIVE statement deactivates an undo tablespace, the purge thread looks for that
# 		undo tablespaces at the next oppurtunity.
#
# 		Once the undo tablespace is found and marked for truncation, the purge thread returns with increased frequency to quickly empty
# 		and truncate the undo tablespace.
#
# To check the state of an undo tablespace, query the INFORMATION_SCHEMA.INNODB_TABLESPACES table.
#
# 		SELECT NAME, STATE FROM INFORMATION_SCHEMA.INNODB_TABLESPACES
# 			WHERE NAME LIKE tablespace_name;
#
# Once the undo tablespace is in an empty state, it can be reactivated by issuing the following statement:
#
# 		ALTER UNDO TABLESPACE tablespace_name SET ACTIVE;
#
# An undo tablespace in an empty state can also be dropped. See Dropping Undo Tablespaces.
#
# Expediting Automated Truncation of Undo Tablespaces
#
# The purge thread is responsible for emptying and truncating undo tablespaces. By default, the purge thread looks for undo tablespaces
# to truncate once every 128 times that purge is invoked.
#
# The frequency with which the purge thread looks for undo tablespaces to truncate is controlled by the innodb_purge_rseg_truncate_frequency
# variable, which has a default setting of 128.
#
# 		SELECT @@innodb_purge_rseg_truncate_frequency;
# 		+------------------------------------------------+
# 		| @@innodb_purge_rseg_truncate_frequency 		    |
# 		+------------------------------------------------+
# 		| 		128 													 |
# 		+------------------------------------------------+
#
# To increase that frequency, decrease the innodb_purge_rseg_truncate_frequency setting. For example, to have the purge thread look for undo
# tablespaces once every 32 times that purge is invoked, set innodb_purge_rseg_truncate_frequency to 32.
#
# SET GLOBAL innodb_purge_rseg_truncate_frequency=32;
#
# When the purge thread finds an undo tablespace that requires truncation, the purge thread returns with increased frequency to quickly empty
# and truncate the undo tablespace.
#
# Performance Impact of Truncating Undo Tablespace Files
#
# When an undo tablespace is truncated, the rollback segments in the undo tablespace are deactivated.
#
# The active rollback segments in other undo tablespaces assume responsibility for the entire system load, which may result
# in a slight performance degradation.
#
# The amount of performance degradation depends on a number of factors:
#
# 		) Number of undo tablespaces
#
# 		) Number of undo logs
#
# 		) Undo tablespace size
#
# 		) Speed of the I/O subsystem
#
# 		) Existing long running transactions
#
# 		) System load
#
# The easiest way to avoid impacting performance when truncating undo tablespaces is to increase the number of undo tablespaces.
#
# Monitoring Undo Tablespace Truncation
#
# As of MySQL 8.0.16, undo and purge subsystem counters are provided for monitoring background activities associated with undo log
# truncation. For counter names and descriptions, query the INFORMATION_SCHEMA.INNODB_METRICS table.
#
# SELECT NAME, SUBSYSTEM, COMMENT FROM INFORMATION_SCHEMA.INNODB_METRICS WHERE NAME LIKE '%truncate%';
#
# For information about enabling counters and querying counter data, see Section 15.14.6, "InnoDB INFORMATION_SCHEMA Metrics Table"
#
# 15.6.3.5 Temporary Tablespaces
#
# InnoDB uses session temporary tablespaces and a global temporary tablespace.
#
# Session Temporary Tablespaces
#
# Session temporary tablespaces store user-created temporary tables and internal temporary tables created by the optimizer
# when InnoDB is configured as the storage engine for on-disk internal temporary tables.
#
# Beginning with MySQL 8.0.16, the storage engine used for on-disk internal temporary tables is always InnoDB.
#
# (Previously, the storage engine was determined by the value of internal_tmp_disk_storage_engine)
#
# Session temporary tablespaces are allocated to a session from a pool of temporary tablespaces on the first request to
# create an on-disk temporary table.
#
# A maximum of two tablespaces is allocated to a session, one for user-created temporary tables and the other for internal
# temporary tables created by the optimizer.
#
# The temporary tablespaces allocated to a session are used for all on-disk temporary tables created by the session.
#
# When a session disconnects, its temporary tablespaces are truncated and released back to the pool.
#
# A pool of 10 temporary tablespaces is created when the server is started. The size of the pool never shrinks and
# tablespaces are added to the pool automatically as necessary.
#
# The pool of temporary tablespaces is removed on normal shutdown or on an aborted initialization.
#
# Session temporary tablespace files are five pages in size when created and have an .ibt file name extension.
#
# A range of 400 thousand space IDs is reserved for session temporary tablespaces. Because the pool of session temporary
# tablespaces is recreated each time the server is started, space IDs for session temporary tablespaces are not persisted
# when the server is shut down and may be reused.
#
# The innodb_temp_tablespaces_dir variable defines the location where session temporary tablespaces are created.
#
# The default location is the #innodb_temp directory in the data directory. Startup is refused if the pool of temporary
# tablespaces cannot be created.
#
# cd BASEDIR/data/#innodb_temp
# ls
# temp_10.ibt temp_2.ibt temp_4.ibt temp_6.ibt temp_8.ibt
# temp_1.ibt  temp_3.ibt temp_5.ibt temp_7.ibt temp_9.ibt
#
# In statement based replication (SBR) mode, temporary tables created on a slave reside in a single session temporary
# tablespace that is truncated only when the MySQL server is shut down.
#
# The INNODB_SESSION_TEMP_TABLESPACES table provides metadata about session temporary tablespaces.
#
# The INFORMATION_SCHEMA.INNODB_TEMP_TABLE_INFO table provides metadata about user-created temporary tables that are active
# in an InnoDB instance.
#
# Global Temporary Tablespace
#
# The global temporary tablespace (ibtmp1) stores rollback segments for changes made to user-created temporary tables.
#
# The innodb_temp_data_file_path variable defines the relative path, name, size and attributes for global temporary tablespace data files.
# If no value is specified for innodb_temp_data_file_path, the default behavior is to create a single auto-extending data file
# named ibtmp1 in the innodb_data_home_dir dir.
#
# The initial file size is slightly larger than 12MB.
#
# The global temporary tablespace is removed on normal shutdown or on an aborted initialization, and recreated each time the server is started.
#
# The global temporary tablespace receives a dynamically generated space ID when it is created.
#
# Startup is refused if the global temporary tablespace cannot be created. The global temporary tablespace is not removed if the server halts
# unexpectedly.
#
# In this case, a database admin can remove the global temp tablespace manually or restart the MySQL server. Restarting the MySQL server removes
# and recreates the global temporary tablespace automatically.
#
# The global temporary tablespace cannot reside on a raw device.
#
# INFORMATION_SCHEMA.FILES provides metadata about the global temporary tablespace. Issue a query similar to this one to view global
# temporary tablespace metadata:
#
# 		SELECT * FROM INFORMATION_SCHEMA.FILES WHERE TABLESPACE_NAME='innodb_temporary'\G
#
# By default, the global temporary tablespace data file is autoextending and increases in size as necessary.
#
# To determine if a global temporary tablespace data file is autoextending, check the innodb_temp_data_file_path setting:
#
# 		SELECT @@innodb_temp_data_file_path;
# 		+--------------------------------------+
# 		| @@innodb_temp_data_file_path 		   |
# 		+--------------------------------------+
# 		| ibtmp1:12M:autoextend 					|
# 		+--------------------------------------+
#
# To check the size of global temporary tablespace data files, query the INFORMATION_SCHEMA.FILES table using a query similar ot this one:
#
# 		SELECT FILE_NAME, TABLESPACE_NAME, ENGINE, INITIAL_SIZE, TOTAL_EXTENTS*EXTENT_SIZE
# 		AS TotalSizeBytes, DATA_FREE, MAXIMUM_SIZE FROM INFORMATION_SCHEMA.FILES
# 		WHERE TABLESPACE_NAME = 'innodb_temporary'\G
# 		****************************** 1. row ***********************************
# 			FILE_NAME: ./ibtmp1
# 			TABLESPACE_NAME: innodb_temporary
# 			ENGINE: InnoDB
# 			INITIAL_SIZE: 12582912
# 			TotalSizeBytes: 12582912
# 			DATA_FREE: 6291456
# 			MAXIMUM_SIZE: NULL
#
# TotalSizeBytes shows the current size of the global temporary tablespace data file. For information about other field values, see 
# SECTION 25.11, "The INFORMATION_SCHEMA FILES Table"
#
# Alternatively, check the global temporary tablespace data file size on your OS.
#
# The global temporary tablespace data file is located in the directory defined by the innodb_temp_data_file_path variable.
#
# To reclaim disk space occupied by a global temporary tablespace data file, restart the MySQL server. Restarting the server removes
# and recreates the global temporary tablespace data file according to the attributes defined by innodb_temp_data_file_path.
#
# To limit the size of the global temporary tablespace data file, configure innodb_temp_data_file_path to specify a maximum file size.
#
# For example:
#
# 		[mysqld]
# 		innodb_temp_data_file_path=ibtmp1:12M:autoextend:max:500M
#
# Configuring innodb_temp_data_file_path requires restarting the server.
#
# 15.6.3.6 Creating a Tablespace Outside of the Data Directory
#
# The CREATE_TABLE_..._DATA_DIRECTORY clause permits creating a file-per-table tablespace outside of the data directory.
#
# For example, you can use the DATA DIRECTORY clause to create a tablespace on a separate storage device with particular
# performance or capacity characteristics, such as a fast SSD or a high-capacity HDD.
#
# Be sure of the location that you choose. The DATA DIRECTORY clause cannot be used with ALTER_TABLE to change the location later.
#
# The tablespace data file is created in the specified directory, within in a subdirectory named for the schema to which the table
# belongs.
#
# The following example demonstrates creating a file-per-table tablespace outside of the data directory. It is assumed that the
# innodb_file_per_table variable is enabled.
#
# USE test;
# Database changed
#
# CREATE TABLE t1 (c1 INT PRIMARY KEY) DATA DIRECTORY = '/remote/directory';
#
# #MySQL creates the tablespace file in a subdirectory that is named 
# # for the schema to which the table belongs
#
# shell> cd /remote/directory/test
# shell> ls
# t1.ibd
#
# When creating a tablespace outside of the data directory, ensure that the directory is known to InnoDB.
#
# Otherwise, if the server halts unexpectedly before tablespace data file pages are fully flushed, startup
# fails when the tablespace is not found during the pre-recovery discovery phase that searches known directories
# for tablespace data files (see Tablespace discovery during Crash Recovery)
#
# To make a directory known, add it to the innodb_directories argument value. innodb_directories is a read-only
# startup option that defines directories to scan at startup for tablespace data files.
#
# Configuring it requires restarting the server.
#
# CREATE_TABLE_..._TABLESPACE syntax can also be used in combination with the DATA DIRECTORY clause to create a
# file-per-table tablespace outside of the data directory.
#
# To do so, specify innodb_file_per_table as the tablespace name.
#
# 		CREATE TABLE t2 (c1 INT PRIMARY KEY) TABLESPACE = innodb_file_per_table
# 		DATA DIRECTORY = '/remote/directory';
#
# The innodb_file_per_table variable does not need to be enabled when using this method.
#
# USAGE NOTES:
#
# 		) MySQL initially holds the tablespace data file open, preventing you from dismounting the device, but might eventually close
# 			the table if hte server is busy.
#
# 			Be careful not to accidentally dismount an external device while MySQL is running, or start MySQL while the device is disconnected.
#
# 			Attempting to access a table when the associated tablespace data file is missing causes a serious error that requires a server restart.
#
# 			A server restart issues errors and warnings if the tablespace data file is not at the expected path. In this case, you can restore the
# 			tablespace data file from a backup or drop the table to remove the information about it from the data dictionary.
#
# 		) Before placing a tablespace on an NFS-mounted volume, review potential issues outlined in Using NFS with MySQL.
#
# 		) If using an LVM snapshot, file copy or other file based mechanisms to back up the tablespace data file, always use the FLUSH_TABLE_..._FOR_EXPORT
# 			statement first to ensure that all changes buffered in memory are flushed to disk before the backup occurs.
#
# 		) Using the DATA DIRECTORY clause is an alternative to using symbolic links, which is not supported.
#
# 15.6.3.7 COPYING TABLESPACES TO ANOTHER INSTANCE
#
# This section describes how to copy a file-per-table tablespaces from one MySQL instance to another, otherwise known as the
# Transportable Tablespaces feature.
#
# This feature also supports partitioned InnoDB tables and individual InnoDB table partitions and subpartitions.
#
# For information about other InnoDB table copying methods, see SECTION 15.6.1.2, "MOVING OR COPYING InnoDB TABLES"
#
# There are many reasons why you might copy an InnoDB file-per-table tablespace to a different instance:
#
# 		) To run reports without putting extra load on a production server.
#
# 		) To set up identical data for a table on a new slave server.
#
# 		) To restore a backed-up version of a table or partition after a problem or mistake.
#
# 		) As a faster way of moving data around than importing the results of a mysqldump command.
#
# 			The data is available immediately, rather than having to be re-inserted and the indexes rebuilt.
#
# 		) To move a file-per-table tablespace to a server with storage medium that better suits system requirements.
#
# 			For example, you may want to have busy tables on an SSD device, or large tables on a high-capacity HDD device.
#
# Limitations and Usage Notes
#
# ) The tablespace copy procedure is only possible when innodb_file_per_table is enabled, which is the default setting.
#
# 		Tables residing in the shared system tablespace cannot be quiesced.
#
# ) When a table is queisced, only read-only transactions are allowed on the affected table.
#
# ) When importing a tablespace, the page size must match the page size of the importing instance.
#
# ) ALTER_TABLE_..._DISCARD_TABLESPACE is supported for partitioned InnoDB tables, and ALTER_TABLE_..._DISCARD_PARTITION_..._TABLESPACE
# 		is supported for InnoDB table partitions.
#
# ) DISCARD TABLESPACE is not supported for tablespaces with a parent-child (primary-key-foreign key) relationship when foreign_key_checks
# 		is set to 1.
#
# 		Before discarding a tablespace for parent-child tables, set foreign_key_checks=0. Partitioned InnoDB tables do not support foreign keys.
#
# ) ALTER_TABLE_..._IMPORT_TABLESPACE does not enforce foreign key constraints on imported data.
#
# 		If there are foreign key constraints between tables, all tables should be exported at the same (logical) point in time.
#
# 		Partitioned InnoDB tables do not support foreign keys.
#
# ) ALTER_TABLE_..._IMPORT_TABLESPACE and ALTER_TABLE_..._IMPORT_PARTITION_..._TABLESPACE do not require a .cfg metadata file to import
# 		a tablespace.
#
# 		However, metadata checks are not performed when importing without a .cfg file, and a warning similar to the following is issued:
#
# 			Message: InnoDB: IO Read error: (2, No such file or Directory) Error opening '.\
# 			test\t.cfg', will attempt to import without schema verification 
# 			1 row in set (0.00 sec)
#
# 		The ability to import without a .cfg file may be more convenient when no schema mismatches are expected.
#
# 		Additionally, the ability to import without a .cfg file could be useful in crash recovery scenarios in which
# 		metadata cannot be collected from an .ibd file
#
# 		If no .cfg file is used, InnoDB uses the equivalent of a SELECT MAX(ai_col) FROM table_name FOR UPDATE statement
# 		to initialize the in-memory auto-increment counter that is used in assigning values for to an AUTO_INCREMENT column.
#
# 		Otherwise, the current maximum auto-increment counter value is read from the .cfg metadata file.
#
# 		For related information, see InnoDB AUTO_INCREMENT Counter Initialization
#
# ) Due to a .cfg metadata file limitation, schema mismatches are not reported for partition type or partition definition
# 		differences when importing tablespace files for partitioned tables.
#
# 		Column differences are reported.
#
# ) When running ALTER_TABLE_..._DISCARD_PARTITION_..._TABLESPACE and ALTER_TABLE_..._IMPORT_PARTITION_..._TABLESPACE on subpartitioned
# 		tables, both partition and subpartition table names are allowed.
#
# 		When a partition name is specified, subpartitions of that partition are included in the operation.
#
# ) Importing a tablespace file from another MySQL server instance works if both instances have GA (General Availability) status
# 		and the server instance into which the file is imported is at the same or higher release level within the same release series.
#
# 		Importing a tablespace file into a server instance running an earlier release of MySQL is not supported.
#
# ) In replication scenarios, innodb_file_per_table must be set to ON on both the master and slave.
#
# ) On Windows, InnoDB stores database, tablespace and table names internally in lowercase.
#
# 		To avoid import problems on case-sensitive OS systems such as Linux and UNIX, create all databases, tablespaces,
# 		and tables using lowercase names.
#
# 		A convenient way to accomplish this is to add the following line to the [mysqld] section of your my.cnf or my.ini
# 		file before creating databases, tablespaces, or tables:
#
# 			[mysqld]
# 			lower_case_table_names=1
#
# 		NOTE:
#
# 			It is prohibited to start the server with a lower_case_table_names setting that is different from the setting
# 			used when the server was initialized.
#
# 	) ALTER_TABLE_..._DISCARD_TABLESPACE and ALTER_TABLE_..._IMPORT_TABLESPACE are not supported with tables that belong to an InnoDB
# 		general tablespace.
#
# 		For more information, see CREATE_TABLESPACE.
#
# ) The default row format for InnoDB tables is configurable using the innodb_default_row_format configuration option.
#
# 		Attempting to import a table that does not explicitly define a row format (ROW_FORMAT), or that uses ROW_FORMAT=DEFAULT,
# 		could result in a schema mismatch error if the innodb_default_row_format setting on the source instance differs from
# 		the setting on the destination instance.
#
# 		For related information, see Defining the Row Format of a Table.
#
# ) When exporting an encrypted tablespace, InnoDB generates a .cfp file in addition to a .cfg metadata file.
#
# 		The .cfp file must be copied to the destination instance together with the .cfg file and tablesapce file before
# 		performing the ALTER_TABLE_..._IMPORT_TABLESPACE operation on the destination instance.
#
# 		The .cfp file contains a transfer key and an encrypted tablespace key. 
#
# 		On import, InnoDB uses the transfer key to decrypt the tablespace key. For related information, see
# 		Section 15.6.3.9, "InnoDB Data-at-Rest Encryption"
#
# ) FLUSH_TABLES_..._FOR_EXPORT is not supported on tables that have a FULLTEXT index.
#
# 		Full-text search auxiliary tables are not flushed. After importing a table with a FULLTEXT index,
# 		run OPTIMIZE_TABLE to rebuild the FULLTEXT indexes.
#
# 		Alternatively, drop FULLTEXT indexes before the export operation and recreate them after importing the
# 		table on the destination instance.
#
# 15.6.3.7.1 Transportable Tablespace Examples
#
# 		Note:
#
# 			If you are transporting tables that are encrypted using the InnoDB tablespace encryption, see Limitations and Usage notes
# 			before you begin for additional procedural information.
#
# Example 1: Copying an InnoDB Table to Another Instance
#
# 		This procedure demonstrates how to copy a regular InnoDB table from a running MySQL server instance to another running instance.
#
# 		The same procedure with minor adjustments can be used to perform a full table restore on the same instance.
#
# 		1. On the source instance, create a table if one does not exist:
#
# 			USE test;
# 			CREATE TABLE t(c1 INT) ENGINE=InnoDB;
#
# 		2. On the destination instance, create a table if one does not exist:
#
# 			USE test;
# 			CREATE TABLE t(c1 INT) ENGINE=InnoDB;
#
# 		3. On the destination instance, discard the existing tablespace. (Before a tablespace can be imported, InnoDB must discard
# 			the tablespace that is attached to the receiving table.)
#
# 				ALTER TABLE t DISCARD TABLESPACE;
#
# 		4. On the source instance, run FLUSH_TABLES_..._FOR_EXPORT to quiesce the table and create the .cfg metadata file:
#
# 			USE test;
#  		FLUSH TABLES t FOR EXPORT;
#
# 			The metadata (.cfg) is created in the InnoDB data directory.
#
# 			NOTE:
#
# 				The FLUSH_TABLES_..._FOR_EXPORT statement ensures that changes to the named table have been flushed to disk
# 				so that a binary table copy can be made while the instance is running.
#
# 				When FLUSH_TABLES_..._FOR_EXPORT is run, InnoDB produces a .cfg file in the same database directory
# 				as the table. The .cfg file contains metadata used for schema verification when importing the tablespace file.
#
# 		5. Copy the .ibd file and .cfg metadata file from the source instance to the destination instance. For example:
#
# 			scp /path/to/datadir/test/t.{ibd,cfg} destination-server:/path/to/datadir/test
#
# 			NOTE:
#
# 				The .ibd file and .cfg file must be copied before releasing the shared locks, as described in the next step.
#
# 		6. On the source instance, use UNLOCK_TABLES to release the locks acquired by FLUSH_TABLES_..._FOR_EXPORT:
#
# 			USE test;
# 			UNLOCK TABLES;
#
# 		7. On the destination instance, import the tablespace:
#
# 			USE test;
# 			ALTER TABLE t IMPORT TABLESPACE;
#
# 			NOTE:
#
# 				The ALTER_TABLE_..._IMPORT_TABLESPACE feature does not enforce foreign key constraints on imported data.
#
# 				If there are foreign key constraints between tables, all tables should be exported at the same (logical)
# 				point in time.
#
# 				In this case you would stop updating the tables, commit all transactions, acquire shared locks on the
# 				tables, and then perform the export operation.
#
# EXAMPLE 2: Copying an InnoDB Partitioned Table to Another Instance
#
# This procedure demonstrates how to copy a partitioned InnoDB table from a running MySQL server instance to another
# running instance.
#
# The same procedure with minor adjustments can be used to perform a full restore of a partitioned InnoDB table on
# the same instance.
#
# 		1. On the source instance, create a partitioned table if one does not exist. In the following example, a table with three
# 			partitions (p0, p1, p2) is created:
#
# 				USE test;
# 				CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 3;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the three partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd t1#P#p1.ibd t1#P#p2.ibd
#
# 		2. On the destination instance, create the same partitioned table:
#
# 			mysql> USE test;
# 			mysql> CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 3;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the three partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd t1#P#p1.ibd t1#P#p2.ibd
#
# 		3. On the destination instance, discard the tablespace for the partitioned table.
#
# 			(Before the tablespace can be imported on the destination instance, the tablespace that is attached
# 			to the receiving table must be discarded.)
#
# 				mysql> ALTER TABLE t1 DISCARD TABLESPACE;
#
# 			The three .ibd files that make up the tablespace for the partitioned table are discarded from the /datadir/test directory.
#
# 		4. On the source instance, run FLUSH_TABLES_..._FOR_EXPORT to quiesce the partitioned table and create the .cfg metadata files:
#
# 			mysql> USE test;
# 			mysql> FLUSH TABLES t1 FOR EXPORT;
#
# 			Metadata (.cfg) files, one for each tablespace (.ibd) file, are created in the /datadir/test directory on the source instance:
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd t1#P#p1.ibd t1#P#p2.ibd
# 				t1#P#p0.cfg t1#P#p1.cfg t1#P#p2.cfg
#
# 			NOTE:
#
# 				FLUSH_TABLES_..._FOR_EXPORT statement ensures that changes to the named table have been flushed to disk so that binary
# 				table copy can be made while the instance is running.
#
# 				When FLUSH_TABLES_..._FOR_EXPORT is run, InnoDB produces a .cfg metadata file for the table's tablespace files in the same
# 				database directory as the table.
#
# 				The .cfg files contain metadata used for schema verification when importing tablespace files.
#
# 				FLUSH_TABLES_..._FOR_EXPORT can only be run on the table, not on individual table partitions.
#
# 		5. Copy the .ibd and .cfg files from the source instance database directory to the destination instance database directory. For example:
#
# 			shell>scp /path/to/datadir/test/t1*.{ibd,cfg} destination-server:/path/to/datadir/test
#
# 			NOTE:
#
# 				The .ibd and .cfg files must be copied before releasing the shared locks, as described in the next step.
#
# 		6. On the source instance, use UNLOCK_TABLES to release the locks acquired by FLUSH_TABLES_..._FOR_EXPORT
#
# 			mysql> USE test;
# 			mysql> UNLOCK TABLES;
#
# 		7. On the destination instance, import the tablespace for the partitioned table:
#
# 			mysql> USE test;
# 			mysql> ALTER TABLE t1 IMPORT TABLESPACE;
#
# Example 3: Copying InnoDB Table Partitions to Another Instance
#
# This procedure demonstrates how to copy InnoDB table partitions from a running MySQL server instance to another
# running instance.
#
# The same procedure with minor adjustments can be used to perform a restore of InnoDB table partitions on the same instance.
#
# In the following example, a partitioned table with four partitions (p0,p1,p2,p3) is created on the source instance.
#
# Two of the partitions (p2 and p3) are copied to the destination instance.
#
# 		1. On the source instance, create a partitioned table if one does not exist. In the following example, a table with
# 			four partitions (p0,p1,p2,p3) is created:
#
# 				mysql> USE test;
# 				mysql> CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 4;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the four partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd t1#P#p1.ibd t1#P#p2.ibd  t1#P#p3.ibd
#
# 		2. On the destination instance, create the same partitioned table:
#
# 			mysql> USE test;
# 			mysql> CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 4;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the four partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd 	t1#P#p1.ibd 	t1#P#p2.ibd 	t1#P#p3.ibd
#
# 		3. On the destination instance, discard the tablespace partitions that you plan to import from the source instance.
#
# 			(Before tablespace partitions can be imported on the destination instance, the corresponding partitions that are attached
# 			to the receiving table must be discarded)
#
# 				mysql> ALTER TABLE t1 DISCARD PARTITION p2, p3 TABLESPACE;
#
# 			The .ibd files for the two discarded partitions are removed from the /datadir/test directory on the destination instance,
# 			leaving the following files:
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd 	t1#P#p1.ibd
#
# 			NOTE:
#
# 				When ALTER_TABLE_..._DISCARD_PARTITION_..._TABLESPACE is run on subpartitioned tables, both partition and subpartition
# 				table names are allowed.
#
# 				When a partition name is specified, subpartitions of that partition are included in the operation.
#
# 		4. On the source instance, run FLUSH_TABLES_..._FOR_EXPORT to quiesce the partitioned table and create the .cfg metadata files.
#
# 			mysql> USE test;
# 			mysql> FLUSH TABLES t1 FOR EXPORT;
#
# 			The metadata files (.cfg files) are created in the /datadir/test directory on the source instance.
#
# 			There is a .cfg file for each tablespace (.ibd) file.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd 	t1#P#p1.ibd 	t1#P#p2.ibd 	t1#P#p3.ibd
# 				t1#P#p0.cfg 	t1#P#p1.cfg 	t1#P#p2.cfg 	t1#P#p3.cfg
#
# 			NOTE:
#
# 				FLUSH_TABLES_..._FOR_EXPORT statements ensure that changes to the named tables have been flushed to disk
# 				so that binary table copy can be made while the instance is running.
#
# 				When FLUSH_TABLES_..._FOR_EXPORT is run, InnoDB produces a .cfg metadata file for the table's tablespace
# 				files in the same database directory as the table.
#
# 				The .cfg files contain metadata used for schema verification when importing tablespace files.
#
# 				FLUSH_TABLES_..._FOR_EXPORT can only be run on the table, not on individual table partitions.
#
# 		5. Copy the .ibd and .cfg files from the source instance database directory to the destination instance
# 			database directory. For example:
#
# 				shell>scp /path/to/datadir/test/t1*.{ibd,cfg} destination-server:/path/to/datadir/test
#
# 			NOTE:
#
# 				The .ibd and .cfg files must be copied before releasing the shared locks, as described in
# 				the next step.
#
# 		6. On the source instance, use UNLOCK_TABLES to release the locks acquired by FLUSH_TABLES_..._FOR_EXPORT:
#
# 			mysql> USE test;
# 			mysql> UNLOCK TABLES;
#
# 		7. On the destination instance, import the tablespace for the partitioned table:
#
# 			mysql> USE test;
# 			mysql> ALTER TABLE t1 IMPORT TABLESPACE;
#
# Example 3: Copying InnoDB Table partitions to Another Instance
#
# This procedure demonstrates how to copy InnoDB table partitions from a running MySQL server instance to another running
# instance.
#
# The same procedure with minor adjustments can be used to perform a restore of InnoDB table partitions on the same instance.
#
# In the following example, a partitioned table with four partitions (p0,p1,p2,p3) is created on the source instance.
#
# Two of the partitions (p2 and p3) are copied to the destination instance.
#
# 		1. On the source instance, create a partitioned table if one does not exist. In the following example, a table with
# 			four partitions (p0,p1,p2,p3) is created:
#
# 				mysql> USE test;
# 				mysql> CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 4;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the four partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd t1#P#p1.ibd t1#P#p2.ibd t1#P#p3.ibd
#
# 		2. On the destination instance, create the same partitioned table:
#
# 				mysql> USE test;
# 				mysql> CREATE TABLE t1 (i int) ENGINE = InnoDB PARTITION BY KEY (i) PARTITIONS 4;
#
# 			In the /datadir/test directory, there is a separate tablespace (.ibd) file for each of the four partitions.
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd  t1#P#p1.ibd 	t1#P#p2.ibd 	t1#P#p3.ibd
#
# 		3. On the destination instance, discard the tablespace partitions that you plan to import from the source instance.
#
# 			(Before tablespace partitions can be imported on the destination instance, the corresponding partitions that are
# 			attached to the receiving table must be discarded)
#
# 				mysql> ALTER TABLE t1 DISCARD PARTITION p2, p3 TABLESPACE;
#
# 			The .ibd files for the two discarded partitions are removed from the /datadir/test directory on the destination instance,
# 			leaving the following files:
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd 	t1#P#p1.ibd
#
# 			NOTE:
#
# 				When ALTER_TABLE_..._DISCARD_PARTITION_..._TABLESPACE is run on subpartitioned tables, both partition and subpartition
# 				table names are allowed.
#
# 				When a partition name is specified, subpartitions of that partition are included in the operation.
#
# 		4. On the source instance, run FLUSH_TABLES_..._FOR_EXPORT to quiesce the partitioned table and create the .cfg metadata files.
#
# 				mysql> USE test;
# 				mysql> FLUSH TABLES t1 FOR EXPORT;
#
# 			The metadata files (.cfg files) are created in the /datadir/test directory on the source instance.
# 			There is a .cfg file for each tablespace (.ibd) file
#
# 				mysql> \! ls /path/to/datadir/test/
# 				t1#P#p0.ibd 	t1#P#p1.ibd 	t1#P#p2.ibd 	t1#P#p3.ibd
# 				t1#P#p0.cfg 	t1#P#p1.cfg 	t1#P#p2.cfg 	t1#P#p3.cfg
#
# 			NOTE:
#
# 				FLUSH_TABLES_..._FOR_EXPORT statement ensures that changes to the named table have been flushed
# 				to disk so that binary table copy can be made while the instance is running.
#
# 				When FLUSH_TABLES_..._FOR_EXPORT is run, InnoDB produces a .cfg metadata file for the table's
# 				tablespace files in the same database directory as the table.
#
# 				The .cfg files contain metadata used for schema verification when importing tablespace files.
#
# 				FLUSH_TABLES_..._FOR_EXPORT can only be run on the table, not on individual table partitions.
#
# 		5. Copy the .ibd and .cfg files from the source instance database directory to the destination instance database directory.
#
# 			In this example, only the .ibd and .cfg files for partition 2 (p2) and partition 3 (p3) are copied to the data directory
# 			on the destination instance.
#
# 			Partition 0 (p0) and partition 1 (p1) remain on the source instance.
#
# 				shell> scp t1#P#p2.ibd 	t1#P#p2.cfg 	t1#P#p3.ibd 	t1#P#p3.cfg 	destination-server:/path/to/datadir/test
#
# 			NOTE:
#
# 				The .ibd files and .cfg files must be copied before releasing the shared locks, as described in the next step.
#
# 		6. On the source instance, use UNLOCK_TABLES to release the locks acquired by FLUSH_TABLES_..._FOR_EXPORT
#
# 				mysql> USE test;
# 				mysql> UNLOCK TABLES;
#
# 		7. ON the destination instance,, import the tablespace partitions (p2 and p3):
#
# 				mysql> USE test;
# 				mysql> ALTER TABLE t1 IMPORT PARTITION p2, p3 TABLESPACE;
#
# 			NOTE:
#
# 				When ALTER_TABLE_..._IMPORT_PARTITION_..._TABLESPACE is run on subpartitioned tables, both partition
# 				and subpartition table names are allowed.
#
# 				When a partition name is specified, subpartitions of that partition are included in the operation.
#
# 15.6.3.7.2 Transportable Tablespace INternals
#
# The following information describes internals and error log messaging for the transportable tablespaces copy procedure
# for a regular InnoDB table.
#
# When ALTER_TABLE_..._DISCARD_TABLESPACE is run on the destination instance:
#
# 		) The table is locked in X mode
#
# 		) The tablespace is detached from the table.
#
# When FLUSH_TABLES_..._FOR_EXPORT is run on the source instance:
#
# 		) The table being flushed for export is locked in shared mode
#
# 		) The purge coordinator thread is stopped
#
# 		) Dirty pages are synchronized to disk
#
# 		) Table metadata is written to the binary .cfg file
#
# Expected error log messages for this operation:
#
# 		2013-09-24T13:10:19.<etc> 2 [Note] InnoDB: Sync to disk of '"test"."t"' started:
# 		2013-09-24T13:10:19.<etc> 2 [Note] InnoDB: Stopping purge
# 		2013-09-24T13:10:19.<etc> 2 [Note] InnoDB: Writing table metadata to './test/t.cfg'
# 		2013-09-24T13.10.19.<etc> 2 [Note] InnoDB: Table '"test"."t"' flushed to disk
#
# When UNLOCK_TABLES is run on the source instance:
#
# 		) The binary .cfg file is deleted.
#
# 		) The shared lock on the table or tables being imported is released and the purge coordinator thread is restarted.
#
# Expected error log messages for this operation:
#
# 		2013-09-24T13:10:21.<etc> 2 [Note] InnoDB: Deleting the meta-data file './test/t.cfg'
# 		2013-09-24T13:10:21.<etc> 2 [Note] InnoDB: Resuming purge
#
# When ALTER_TABLE_..._IMPORT_TABLESPACE is run on the destination instance, the import algorithm performs the following
# operations for each tablespace being imported:
#
# 		) Each tablespace page is checked for corruption
#
# 		) The space ID and log sequence numbers (LSNs) on each page are updated
#
# 		) Flags are validated and LSN updated for the header page.
#
# 		) Btree pages are updated.
#
# 		) The page state is set to dirty so that it is written to disk.
#
# Expected error log messages for this operation:
#
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Importing tablespace for table 'test/t' that was exported from host 'ubuntu'
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Phase I - Update all pages
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Sync to disk
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Sync to disk - done!
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Phase III - Flush changes to disk
# 		2013-07-18 15:15:01 34960 [Note] InnoDB: Phase IV - Flush complete
#
# NOTE:
#
# 		You may also receive a warning that a tablespace is discarded (if you discarded the tablespace for the destination table)
# 		and a message stating that statistics could not be calculated due to a missing .ibd file:
#
# 			2013-07-18 15:14:38 34960 [Warning] InnoDB: Table "test"."t" tablespace is set as discarded.
# 			2013-07-18 15:14:38 7f34d9a37700 InnoDB: cannot calculate statistics for table "test"."t"
# 			because the .ibd file is missing. For help, please refer to 
# 			http://dev.mysql.com/doc/refman/8.0/en/innodb-troubleshooting.html
#
# 15.6.3.8 Moving Tablespace Files While the Server is Offline
#
# The innodb_directories option, which defines directories to scan at startup for tablespace files, supports moving or
# restoring tablespace files to a new location while the server is offline.
#
# During startup, discovered tablespace files are used instead those referenced in the data directory, and the data
# dictionary is updated to reference the relocated files.
#
# If duplicate tablespace files are discovered by the scan, startup fails with an error indicating that multiple files
# were found for the same tablespace ID.
#
# The directories defined by the innodb_data_home_dir, innodb_undo_directory, and datadir configuration options are
# automatically appended to the innodb_directories argument value.
#
# These directories are scanned at startup regardless of whether the innodb_directories option is specified explicitly.
#
# The implicit addition of these directories permits moving system tablespace files, the data directory, or undo tablespace
# files without configuring the innodb_directories setting.
#
# However, settings must be updated when directories change. For example, after relocating the data directory, you must
# update the --datadir setting before restarting the server.
#
# The innodb_directories option may be specified in a startup command or MySQL option file.
#
# Quotes are used around the argument value because otherwise a semicolon (;) is interpreted as a special
# character by some command interpreters. (Unix shells treat it as a command terminator, for example)
#
# Startup command:
#
# 		mysqld --innodb-directories="directory_path_1;directory_path_2"
#
# MySQL option file:
#
# 		[mysqld]
# 		innodb_directories="directory_path_1;directory_path_2"
#
# The following procedure is applicable to moving individual file-per-table and general tablespace files, system tablespace files,
# undo tablespace files, or the data directory.
#
# Before moving files or directories, review the usage notes that follow.
#
# 	1. Stop the server
#
# 	2. Move the tablespace files or directories
#
# 	3. Make the new directory known to InnoDB.
#
# 		) If moving individual file-per-table or general tablespace files, add unknown directories to the innodb_directories value.
#
# 			) The directories defined by the innodb_data_home_dir, innodb_undo_directory, and datadir configuration options are automatically
# 				appended to the innodb_directories argument value, so you need not specify these.
#
# 			) A file-per-table tablespace file can only be moved to a directory with same name as the schema. For example, if the actor
# 				table belongs to the sakila schema, then the actor.ibd data file can only be moved to a directory named sakila.
#
# 			) General tablespace files cannot be moved to the data directory or a subdirectory of the data directory.
#
# 		) If moving system tablespace files, undo tablespaces, or the data directory, update the innodb_data_home_dir, innodb_undo_directory,
# 			and datadir settings, as necessary.
#
# 	4. Restart the server.
#
# USAGE NOTES
#
# ) Wildcard expressions cannot be used in the innodb_directories argument value.
#
# ) The innodb_directories scan also traverses subdirectories of specified directories. Duplicate directories and subdirectories are discarded
# 		from the list of directories to be scanned.
#
# ) The innodb_directories option only supports moving InnoDB tablespace files. Moving files that belong to a storage engine other than InnoDB
# 		is not supported.
#
# 		This restriction also applies when moving the entire data directory.
#
# ) The innodb_directories option supports renaming of tablespace files when moving files to a scanned directory.
#
# 		It also supports moving tablespaces files to other supported OS's.
#
# ) When moving tablespace files to a different OS, ensure that tablespace file names do not include prohibit chars or chars with a special
# 		meaning on the destination OS.
#
# ) When moving a data directory from a Windows OS to a Linux OS, modify the binary log file paths in the binary log index file to use 
# 		backward slashes instead of forward slashes.
#
# 		By default, the binary log index file has the same base name as the binary log file, with the extension '.index'
#
# 		The location of the binary log index file is defined by --log-bin. The default location is the data directory.
#
# ) If moving tablespace files to a different OS introduces cross-platform replication, it is the responisbility of the DB admin to ensure
# 		proper replication of DDL statements that contain platform-specific DIrs.
#
# 		Statements that permit specifying dirs include CREATE_TABLE_..._DATA_DIRECTORY and CREATE_TABLESPACE.
#
# ) The directory of file-per-table and general tablespace files created with an absolute path or in a location outside of the data
# 		directory should be added to the innodb_directories argument value.
#
# 		Otherwise, InnoDB is not able to locate these files during recovery.
#
# 		CREATE_TABLE_..._DATA_DIRECTORY and CREATE_TABLESPACE permit creation of tablespace files with absolute paths.
#
# 		CREATE_TABLESPACE also permits tablespace file directories that are relative to the data directory.
#
# 		To view tablespace file locations, query the INFORMATION_SCHEMA.FILES table:
#
# 			mysql> SELECT TABLESPACE_NAME, FILE_NAME FROM INFORMATION_SCHEMA.FILES \G
#
# ) CREATE_TABLESPACE requires that the target directory exists and is known to InnoDB. Known directories include those implicitly and explicitly
# 		defined by the innodb_directories option.
#
# 15.6.3.9 InnoDB Data-at-Rest Encryption
#
# InnoDB supports data-at-rest encryption for file-per-table tablespaces, general tablespaces, the mysql system tablespace, redo logs, and undo logs.
#
# As of MySQL 8.0.16, setting an encryption default for schemas and general tablespaces is also supported, which permits DBAs to control whether
# tables created in those schemas and tablespaces are encrypted.
#
# InnoDB data-at-rest encryption features and capabilities are described under the following topics in this section.
#
# 		) About Data-at-Rest Encryption
#
# 		) Encryption Prerequisites
#
# 		) Defining an Encryption Default for Schemas and General Tablespaces
#
# 		) File-Per-Table tablespace encryption
#
# 		) General Tablespace Encryption
#
# 		) mysql System Tablespace Encryption
#
# 		) Redo Log Encryption
#
# 		) Undo Log Encryption
#
# 		) Master Key Rotation
#
# 		) Encryption and Recovery
#
# 		) Exporting Encrypted Tablespaces
#
# 		) Encryption and Replication
#
# 		) Identifying Encrypted Tablespaces and Schemas
#
# 		) Monitoring Encryption Progress
#
# 		) Encryption Usage Notes
#
# 		) Encryption Limitations
#
# ABOUT DATA-AT-REST ENCRYPTION
#
# InnoDB uses a two tier encryption key architechture, consisting of a master encryption key and tablespace keys.
#
# When a tablespace is encrypted, a tablespace key is encrypted and stored in the tablespace header.
#
# When an application or authenticated user wants to access encrypted tablespace data, InnoDB uses a master encryption
# key to decrypt the tablespace key. The decrypted version of a tablespace key never changes, but the master encryption
# key can be changed as required.
#
# This action is referred to as master key rotation.
#
# The data-at-rest encryption feature relies on a keyring plugin for master encryption key management.
#
# All MySQL editions provide a keyring_file plugin, which stores keyring data in a file local to the server host.
#
# MySQL Enterprise Edition offers additional keyring plugins:
#
# 		) The keyring_encrypted_file plugin, which stores keyring data in an encrypted file local to the server host.
#
# 		) The keyring_okv plugin, which includes a KMIP client (KMIP 1.1) that uses a KMIP-compatible product as a back end
# 			for keyring storage.
#
# 			Supported KMIP-compatibble products include centralized key management solutions such as Oracle Key Vault,
# 			Gemalto KeySecure, etc.
#
# 		) The keyring_aws plugin, which communicates with the Amazon Web Services Key Management Service (AWS KMS) as
# 			a back end for key generation and uses a local file for key storage.
#
# 			WARNING:
#
# 				The keyring_file and keyring_encrypted file plugins are not intended as regulatory compliance solutions.
#
# 				Security standards such as PCI, FIPS, and others require use of key management systems to secure, manage,
# 				and protect encryption keys in key vaults or hardware security modules (HSMs)
#
# A secure and robust encryption key management solution is critical for security and for compliance with various
# security standards.
#
# When the data-at-rest encryption feature uses a centralized key management solution, the feature is referred to
# as "MySQL Enterprise Transparent Data Encryption (TDE)"
#
# The data-at-rest encryption feature supports the Advanced Encryption Standard (AES) block-based encryption algorithm.
#
# It uses Electronic Codebook (ECB) block encryption mode for tablespace key encryption and Cipher Block Chaining
# (CBC) block encryption mode for data encryption.
#
# For frequently asked questions about the data-at-rest Encryption feature, see SECTION A.16, "MySQL 8.0 FAQ: InnoDB Data-At-Rest Encryption"
#
# Encryption Prerequisites
#
# 		) A keyring plugin must be installed and configured. Keyring plugin installation is performed at startup using the early-plugin-load option.
#
# 			Early loading ensures that the plugin is available prior to initialization of the InnoDB storage engine.
#
# 			For keyring plugin installation and configuration instructions, see SECTION 6.4.4, "The MySQL Keyring"
#
# 			Only one keyring plugin can be enabled at a time. Enabling multiple keyring plugins is not supported.
#
# 			IMPORTANT:
#
# 				Once encrypted tablespaces are created in a MySQL instance, the keyring plugin that was loaded when creating
# 				the encrypted tablespace must continue to be loaded at startup using the early-plugin-load option.
#
# 				Failing to do so results in errors when starting the server and during InnoDB recovery.
#
# To verify that a keyring plugin is active, use the SHOW_PLUGINS statement or query the INFORMATION_SCHEMA.PLUGINS table.
#
# For example:
#
# 		SELECT PLUGIN_NAME, PLUGIN_STATUS
# 		FROM INFORMATION_SCHEMA.PLUGINS
# 		WHERE PLUGIN_NAME LIKE 'keyring%';
# 		+--------------+----------------+
# 		| PLUGIN_NAME  | PLUGIN_STATUS  |
# 		+--------------+----------------+
# 		| keyring_file | ACTIVE 		  |
# 		+--------------+----------------+
#
# 	) When encrypting production data, ensure that you take steps to prevent loss of the master encryption key.
#
# 		If the master encryption key is lost, data stored in encrypted tablespace files is unrecoverable. If you 
# 		use the keyring_file or keyring_encrypte_file plugin, create a backup of the keyring data file immedaitely
# 		after creating the first encrypted tablespace, before master key rotation, and after master key rotation.
#
# 		The keyring_file_data configuration option defines the keyring data file location for the keyring_file plugin.
#
# 		The keyring_encrypted_file_data configuration option defines the keyring data file location for the 
# 		keyring_encrypted_file plugin. If you use the keyring_okv or keyring_aws plugin, ensure that you have
# 		performed the necessary configuration.
#
# 		For instructions, see SECTION 6.4.4, "The MySQL Keyring"
#
# DEFINING AN ENCRYPTION DEFAULT FOR SCHEMAS AND GENERAL TABLESPACES
#
# As of MySQL 8.0.16, the default_table_encryption variable defines the default encryption setting for schemas and general
# tablespaces.
#
# CREATE_TABLESPACE and CREATE_SCHEMA operations apply the default_table_encryption setting when an ENCRYPTION clause is not
# specified explicitly.
#
# ALTER_SCHEMA and ALTER_TABLESPACE operations do not apply the default_table_encryption setting. An ENCRYPTION clause must be
# specified explicitly to alter the encryption of an existing schema or general tablespace.
#
# The default_table_encryption variable can be set for an individual client connection or globally using SET syntax.
#
# For example, the following statement enables default schema and tablespace encryption globally:
#
# 		mysql> SET GLOBAL default_table_encryption=ON;
#
# The default encryption setting for a schema can also be defined using the DEFAULT ENCRYPTION clause when creating
# or altering a schema, as in this example:
#
# 		mysql> CREATE SCHEMA test DEFAULT ENCRYPTION = 'Y';
#
# If the DEFAULT ENCRYPTION clause is not specified when creating a schema, the default_table_encryption setting is applied.
#
# The DEFAULT ENCRYPTION clause must be specified to alter the default encryption of an existing schema.
#
# Otherwise, the schema retains its current encryption setting.
#
# By default, a table inherits the encryption setting of the schema or general tablespace it is created in. For example,
# a table created in an encryption-enabled schema is encrypted by default.
#
# This behavior enables a DBA to control table encryption usage by defining and enforcing schema and general tablesapce
# encryption defaults.
#
# Encryption defaults are enforced by enabling the table_encryption_privilege_check variable. When table_encryption_privilege_check
# is enabled, a privilege check occurs when creating or altering a schema or general tablespace with an encryption setting that
# differs from the default_table_encryption setting, or when creating or altering a table with an encryption setting that differs
# from the default schema encryption.
#
# When table_encryption_privilege_check is disabled (the default), the privilege check does not occur and the previously
# mentioned operations are permitted to proceed with a warning.
#
# The TABLE_ENCRYPTION_ADMIN privilege is required to override default encryption settings when table_encryption_privilege_check
# is enabled.
#
# A DBA can grant this privilege to enable a user to deviate from the default_table_encryption setting when creating or altering
# a schema or general tablespace, or to deviate from the default schema encryption when creating or altering a table.
#
# This privilege does not permit deviating from the encryption of a general tablespace when creating or altering a table.
#
# A table must have the same encryption setting as the general tablespace it resides in.
#
# FILE-PER-TABLE TABLESPACE ENCRYPTION
#
# As of MySQL 8.0.16, a file-per-table tablespace inherits the default encryption of the schema in which the table is created
# unless an ENCRYPTION clause is specified explicitly in the CREATE_TABLE statement.
#
# Prior to MySQL 8.0.16, the ENCRYPTION clause must be specified to enable encryption.
#
# 	mysql> CREATE TABLE t1 (c1 INT) ENCRYPTION = 'Y';
#
# To alter the encryption of an existing file-per-table tablespace, an ENCRYPTION clause must be specified.
#
# 	mysql> ALTER TABLE t1 ENCRYPTION = 'Y';
#
# As of MySQL 8.0.16, if the table_encryption_privilege_check variable is enabled, specifying an ENCRYPTION clause
# with a setting that differs from the default schema encryption requires the TABLE_ENCRYPTION_ADMIN privilege.
#
# See Defining an Encryption Default for Schemas and General Tablespaces
#
# General Tablespace Encryption
#
# 		As of MySQL 8.0.16, the default_table_encryption variable determines the encryption of a newly created tablespace
# 		unless an ENCRYPTION clause is specified explicitly in the CREATE_TABLESPACE statement.
#
# 		Prior to MySQL 8.0.16, an ENCRYPTION clause must be specified to enable encryption.
#
# 			mysql> CREATE TABLESPACE `ts1` ADD DATAFILE 'ts1.ibd' ENCRYPTION = 'Y' Engine=InnoDB;
#
# 		To alter the encryption of an existing general tablespace, an ENCRYPTION clause must be specified.
#
# 			mysql> ALTER TABLESPACE ts1 ENCRYPTION = 'Y';
#
# As of MySQL 8.0.16, if the table_encryption_privilege_check variable is enabled, specifying an ENCRYPTION
# clause with a setting that differs from the default_table_encryption setting requires the TABLE_ENCRYPTION_ADMIN
# privilege.
#
# See Defining an Encryption Default for Schemas and General Tablespaces.
#
# Mysql System Tablespace Encryption
#
# Encryption support for the mysql system tablespace is available as of MySQL 8.0.16
#
# The mysql system tablespace contains the mysql system database and MySQL data dictionary tables. It is unencrypted
# by default.
#
# To enable encryption for the mysql system tablespace, specify the tablespace name and the ENCRYPTION option in an
# ALTER_TABLESPACE statement.
#
# 		mysql> ALTER TABLESPACE mysql ENCRYPTION = 'Y';
#
# To disable encryption for the mysql system tablespace, set ENCRYPTION = 'N' using an ALTER_TABLESPACE statement.
#
# 		mysql> ALTER TABLESPACE mysql ENCRYPTION = 'N';
#
# Enabling or disabling encryption for the mysql system tablespace requires the CREATE_TABLESPACE privilege on all tables
# in the instance (CREATE TABLESPACE on *.*)
#
# Redo Log Encryption
#
# Redo log data encryption is enabled using the innodb_redo_log_encrypt configuration option. Redo log encryption is disabled
# by default.
#
# As with tablespace data, redo log data encryption occurs when redo log data is written to disk, and decryption occurs when redo
# log data is read from disk.
#
# Once redo log data is read into memory, it is in unencrypted form. Redo log data is encrypted and decrypted using the tablespace
# encryption key.
#
# When innodb_redo_log_encrypt is enabled, unencrypted redo log pages that are present on disk remain unencrypted, and new redo log
# pages are written to disk in encrypted form.
#
# Likewise, when innodb_redo_log_encrypt is disabled, encrypted redo log pages that are present on disk remain encrypted, and new redo
# log pages are written to disk in unencrypted form.
#
# Redo log encryption metadata, including the tablespace encryption key, is stored in the header of the first redo log file (ib_logfile0).
#
# if this file is removed, redo log encryption is disabled.
#
# Once redo log encryption is enabled, a normal restart without the keyring plugin or without the encryption key is not possible,
# as InnoDB must be able to scan redo pages during startup, which is not possible if redo log pages are encrypted.
#
# Without the keyring plugin or the encryption key, only a forced startup without the redo logs (SRV_FORCE_NO_LOG_REDO) is possible.
#
# See SECTION 15.20.2, "Forcing InnoDB Recovery"
#
# UNDO LOG ENCRYPTION
#
# Undo log data encryption is enabled using the innodb_undo_log_encrypt configuration option. Undo log encryption applies to undo logs
# that reside in undo tablespaces.
#
# See SECTION 15.6.3.4, "UNDO TABLESPACES". Undo log data encryption is disabled by default.
#
# As with tablespace data, undo log data encryption occurs when undo log data is written to disk, and decryption occurs when undo log
# data is read from disk.
#
# Once undo log data is read into memory, it is in unencrypted form. Undo log data is encrypted and decrypted using the tablespace
# encryption key.
#
# When innodb_undo_log_encrypt is enabled, unencrypted undo log pages that are present on disk remain unencrypted, and new undo log pages
# are writen to disk in encrypted form.
#
# Likewise, when innodb_undo_log_encrypt is disabled, encrypted undo log pages that are present on disk remain encrypted, and new undo
# log pages are written to disk in unencrypted form.
#
# Undo log encryption metadata, including the tablespace encryption key, is stored in the header of the undo log file.
#
# MASTER KEY ROTATION
#
# The master encryption key should be rotated periodically and whenever you suspect that the key has been compromised.
#
# Master key rotation is an atomic, instance-level operation. Each time the master encryption key is rotated, all tablespace keys
# in the MySQL instance are re-encrypted and saved back to their respective tablespace headers.
#
# As an atomic operation, re-encryption must succeed for all tablespace keys once a rotation operation is initiated.
#
# If master key rotation is interrupted by a server failure, InnoDB rolls the operation forward on server restart.
#
# For more information, see Encryption and Recovery.
#
# Rotating the master encryption key only changes the master encryption key and re-encrypts tablespace keys. It does not
# decrypt or re-encrypt associated tablespace data.
#
# Rotating the master encryption key requires the ENCRYPTION_KEY_ADMIN or SUPER privilege.
#
# To rotate the master encryption key, run:
#
# 		mysql> ALTER INSTANCE ROTATE INNODB MASTER KEY;
#
# ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY supports concurrent DML. however, it cannot be run concurrently with tablespace
# encryption operations, and locks are taken to prevent conflicts that could arise from concurrent execution.
#
# If an ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY operation is running, it must finish before a tablespace encryption
# operation can proceed, and vice versa.
#
# ENCRYPTION AND RECOVERY
#
# If a server failure occurs during an encryption operation, the operation is rolled forward when the server is restarted.
#
# For general tablespaces, the encryption operation is resumed in a background thread from the last processed page.
#
# If a server failure occurs during master key rotation, InnoDB continues the operation on server restart.
#
# The keyring plugin must be loaded prior to storage engine initialization so that the information necessary to decrypt
# tablespace data pages can be retrieved from tablespace headers before InnoDB initialization and recovery activities
# access tablespace data.
#
# (See Encryption Prerequisites)
#
# When InnoDB initialization and recovery begin, the master key rotation operation resumes. Due to the server failure,
# some tablespace keys may already be encrypted using the new master encryption key.
#
# InnoDB reads the encryption data from each tablesapce header, and if the data indicates that the tablespace key is
# encrypted using the old master encryption key, InnoDB retrieves the old key from the keyring and uses it to decrypt
# the tablespace key.
#
# InnoDB then re-encrypts the tablespace key using the new master encryption key and saves the re-encrypted tablespace
# key back to the tablespace header.
#
# EXPORTING ENCRYPTED TABLESPACES
#
# Tablespace export is only supported for file-per-table tablespaces.
#
# When an encrypted tablespace is exported, InnoDB generates a transfer key that is used to encrypt the tablespace key.
#
# The encrypted tablespace key and transfer key are stored in a tablespace_name.cfp file.
#
# This file together with the encrypted tablespace file is required to perform an import operation.
#
# On import, InnoDB uses the transfer key to decrypt the tablespace key in the tablespace_name.cfp file.
#
# For related information, see SECTION 15.6.3.7, "COPYING TABLESPACES TO ANOTHER INSTANCE"
#
# ENCRYPTION AND REPLICATION
#
# 		) The ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY statement is only supported in replication environments where the master
# 			and slaves run a version of MySQL that supports tablespace encryption.
#
# 		) Successful ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY statements are written to the binary log for replication on slaves.
#
# 		) If an ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY statement fails, it is not logged to the binary log and is not replicated on slaves.
#
# 		) Replication of an ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY operation fails if the keyring plugin is installed on the master but not on the slave.
#
# 		) If the keyring_file or keyring_encrypted_file plugin is installed on both the master and slave but the slave does not have a keyring data file,
# 			the replicated ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY statement creates the keyring data file on the slave, assuming the keyring file data is
# 			not cached in memory.
#
# 			ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY uses keyring file data that is cached in memory, if available.
#
# IDENTIFYING ENCRYPTED TABLESPACES AND SCHEMAS
#
# The INFORMATION_SCHEMA.INNODB_TABLESPACES table, introduced in MySQL 8.0.13, includes an ENCRYPTION column that can be used to identify encrypted tablespaces.
#
# 		SELECT SPACE, NAME, SPACE_TYPE, ENCRYPTION FROM INFORMATION_SCHEMA.INNODB_TABLESPACES
# 		WHERE ENCRYPTION='Y'\G
# 		************************* 1. row **********************************
# 			SPACE: 4294967294
# 			NAME: mysql
# 			SPACE_TYPE: General
# 			ENCRYPTION: Y
#
# 		************************* 2. row ***********************************
# 			SPACE: 2
# 			NAME:  test/t1
# 			SPACE_TYPE: Single
# 			ENCRYPTION: Y
# 		************************* 3. row ***********************************
# 			SPACE: 3
# 			NAME: ts1
# 			SPACE_TYPE: General
# 			ENCRYPTION: Y
#
# When the ENCRYPTION option is specified in a CREATE_TABLE or ALTER_TABLE statement, it is recorded in the CREATE_OPTIONS
# column of INFORMATION_SCHEMA.TABLES
#
# This column can be queried to identify tables that reside in encrypted file-per-table tablespaces.
#
# 		SELECT TABLE_SCHEMA, TABLE_NAME, CREATE_OPTIONS FROM INFORMATION_SCHEMA.TABLES
# 		WHERE CREATE_OPTIONS LIKE '%ENCRYPTION%';
# 		+--------------------+------------------+-------------------------------+
# 		| TABLE_SCHEMA 	   | TABLE_NAME 	    | CREATE_OPTIONS 					|
# 		+--------------------+------------------+-------------------------------+
# 		| test 					| t1 					 | ENCRYPTION="Y" 					|
# 		+--------------------+------------------+-------------------------------+
#
# Query INFORMATION_SCHEMA.INNODB_TABLESPACES to retrieve information about the tablespace associated with a particular
# schema and table.
#
# 		SELECT SPACE, NAME, SPACE_TYPE FROM INFORMATION_SCHEMA.INNODB_TABLESPACES WHERE NAME='test/t1';
# 		+-----------+------------+----------------+
# 		| SPACE 	   | NAME 		 | SPACE_TYPE 	   |
# 		+-----------+------------+----------------+
# 		| 3 			| test/t1 	 | Single 			|
# 		+-----------+------------+----------------+
#
# You can identify encryption-enabled Schemas by querying the INFORMATION_SCHEMA.SCHEMATA table.
#
# 		SELECT SCHEMA_NAME, DEFAULT_ENCRYPTION FROM INFORMATION_SCHEMA.SCHEMATA
# 		WHERE DEFAULT_ENCRYPTION='YES';
# 		+---------------+---------------------+
# 		| SCHEMA_NAME   | DEFAULT_ENCRYPTION  |
# 		+---------------+---------------------+
# 		| test 			 | YES 					  |
# 		+---------------+---------------------+
#
# SHOW_CREATE_SCHEMA also shows the DEFAULT ENCRYPTION clause.
#
# MONITORING ENCRYPTION PROGRESS
#
# You can monitor general tablespace and mysql system tablespace encryption progress using Performance Schema.
#
# The stage/innodb/alter tablespace (encryption) stage event instrument reports WORK_ESTIMATED and WORK_COMPLETED information
# for general tablespace encryption operations.
#
# The following example demonstrates how to enable the stage/innodb/alter tablespace (encryption) stage event instrument
# and related consumer tables to monitor general tablespace or mysql system tablespace encryption progress.
#
# For information about Performance Schema stage event instruments and related consumers, see SECTION 26.12.5, "PERFORMANCE
# 	SCHEMA STAGE EVENT TABLES"
#
# 		1. Enable the stage/innodb/alter tablespace (encryption) instrument:
#
# 				USE performance_schema;
# 				UPDATE setup_instruments SET ENABLED = 'YES'
# 				WHERE NAME LIKE 'stage/innodb/alter tablespace (encryption)';
#
# 		2. Enable the stage event consumer tables, which include events_stages_current, events_stages_history and events_stages_history_long
#
# 				UPDATE setup_consumers SET ENABLED = 'YES' WHERE NAME LIKE '%stages%';
#
# 		3. Run a tablespace encryption operation. In this example, a general tablespace named ts1 is encrypted.
#
# 				ALTER TABLESPACE ts1 ENCRYPTION = 'Y';
#
# 		4. Check the progress of the encryption operation by querying the Performance Schema events_stages_current table.
#
# 			WORK_ESTIMATED reports the total number of pages in the tablespace. WORK_COMPLETED reports the number of pages processed.
#
# 				SELECT EVENT_NAME, WORK_ESTIMATED, WORK_COMPLETED FROM events_stages_current;
#
# 				+--------------------------------------------+-----------------+------------------------+
# 				| EVENT_NAME 									      | WORK_COMPLETED  | WORK_ESTIMATED 			 |
# 				+--------------------------------------------+-----------------+------------------------+
# 				| stage/innodb/alter tablespace (encryption) | 1056 				| 1407 						 |
# 				+--------------------------------------------+-----------------+------------------------+
#
# 			The events_stages_current table returns an empty set if the encryption operation has completed.
#
# 			In this case, you can check the events_stages_history table to view event data for the completed
# 			operation. For example:
#
# 				SELECT EVENT_NAME, WORK_COMPLETED, WORK_ESTIMATED FROM events_stages_history;
# 				+---------------------------------------------+------------------+--------------------+
# 				| EVENT_NAME 											 | WORK_COMPLETED   | WORK_ESTIMATED 	  |
# 				+---------------------------------------------+------------------+--------------------+
# 				| stage/innodb/alter tablespace (encryption)  | 1407 				  | 1407 				  |
# 				+---------------------------------------------+------------------+--------------------+
#
# ENCRYPTION USAGE NOTES
#
# ) Plan appropriately when altering an existing file-per-table tablespace with the ENCRYPTION option.
#
# 		Tables residing in file-per-table tablespace are rebuilt using the COPY algorithm.
# 		The INPLACE algorithm is used when altering the ENCRYPTION attribute of a general tablespace or the
# 		mysql system tablespace.
#
# 		The INPLACE algorithm permits concurrent DML on tables that reside in the general tablespace.
#
# 		Concurrent DDL is blocked.
#
# ) When a general tablespace or the mysql system tablespace is encrypted, all tables residing in the tablespace
# 		are encrypted.
#
# 		Likewise, a table created in an encrypted tablesapce is encrypted.
#
# ) If the server exits or is stopped during normal operation, it is recommended to restart the server using the same
# 		encryption settings that were configured previously.
#
# ) The first master encryption key is generated when the first new or existing tablespace is encrypted.
#
# ) Master key rotation re-encrypts tablespaces keys but does not change the tablespace key itself. To change a tablespace
# 		key, you must disable and re-enable encryption.
#
# 		For file-per-table tablespaces, re-encrypting the tablespace is an ALGORITHM=COPY operation that rebuilds the table.
#
# 		For general tablespaces and the mysql system tablespace, it is an ALGORITHM=INPLACE operation, which does not require
# 		rebuilding tables that reside in the tablespace.
#
# ) If a table is created with both the COMPRESSION and ENCRYPTION options, compression is performed before tablespace data is encrypted.
#
# ) If a keyring data file (the file named by keyring_file_data or keyring_encrypted_file_data) is empty or missing, the first execution
# 		of ALTER_INSTANCE_ROTATE_INNODB_MASTER_KEY creates a master encryption key.
#
# ) Uninstalling the keyring_file or keyring_encrypted_file plugin does not remove an existing keyring data file.
#
# ) It is recommended that you do not place a keyring data file under the same directory as tablespace data files.
#
# ) Modifying the keyring_file_data or keyring_encrypted_file_data setting at runtime or when restarting the server can cause
# 		previously encrypted tablespaces to become inaccessible, resulting in lost data.
#
# ENCRYPTION LIMITATIONS
#
# ) Advanced Encryption Standard (AES) is the only supported encryption algorithm. InnoDB tablespace encryption uses Electronic Codebook (ECB) block
# 		encryption mode for tablespace key encryption and Cipher Block Chaining (CBC) block encryption mode for data encryption.
#
# ) Encryption is only supported for file-per-table tablespaces, general tablespaces, and the mysql system tablespace.
#
# 		Encryption support for general tablespaces was introduced in MySQL 8.0.13. Encryption support for the mysql system tablespace
# 		is available as of MySQL 8.0.16. Encryption is not supported for other tablespace types including the InnoDB system tablespace.
#
# ) You cannot move or copy a table from an encrypted file-per-table tablespace, general tablespace or the mysql system tablespace to a tablespace
# 		type that does not support encryption.
#
# ) You cannot move or copy a table from an encrypted tablespace to an unencrypted tablespace. However, moving a table from an unencrypted tablespace
# 		to an encrypted one is permitted.
#
# 		For example, you can move or copy a table from a unencrypted file-per-table or general tablespace to an encrypted general tablesapce.
#
# ) By default, tablespace encryption only applies to data in the tablespace. Redo log and undo log data can be encrypted by enablibg innodb_redo_log_encrypt
# 		and innodb_undo_log_encrypt. See Redo Log Encryption, and Undo Log Encryption. Binary log data is not encrypted.
#
# ) It is not permitted to change the storage engine of a table that resides in, or previously resided in, an encrypted tablesapce.
#
# 15.6.4 DOUBLEWRITE BUFFER
#
# The doublewrite buffer is a storage area located in the system tablespace where InnoDB writes pages that are flushed from teh InnoDB
# buffer pool, before the pages are written to their proper positions in the data file.
#
# Only after flushing and writing pages to the doublewrite buffer, does InnoDB write pages to their proper positions.
#
# If there is an OS, storage subsystem or mysqld process crash in the middle of a page write, InnoDB can later find a good copy
# of the page from the doublewrite buffer during crash recovery.
#
# Although data is always written twice, the doublewrite buffer does not require twice as much I/O overhead or twice as many I/O
# operations.
#
# Data is written to the doublewrite buffer itself as a large sequential chunk, with a single fsync() call to the OS.
#
# The doublewrite buffer is enabled by default in most cases. To disable the doublewrite buffer, set innodb_doublewrite to 0.
#
# If system tablespace files ("ibdata files") are located on Fusion-io devices that support atomic writes, doublewrite buffering
# is automatically disabled and Fusion-io atomic writers are used for all data files.
#
# Because the doublewrite buffer setting is global, doublewrite buffering is also disabled for data files residing on non-Fusion-io
# hardware.
#
# This feature is only supported on Fusion-io hardware and is only enabled for Fusion-io NVMFS on Linux.
#
# To take full advantage of this feature, an innodb_flush_method setting of O_DIRECT is recommended.
#
# 15.6.5 REDO LOG
#
# The redo log is a disk-based data structure used during crash recovery to correct data written by incomplete transactions.
#
# During normal operations, the redo log encodes requests to change table data that result from SQL statements or low-level API
# calls.
#
# Modifications that did not finish updating the data files before an unexpected shutdown are replayed automatically during initialization,
# and before the connections are accepted.
#
# For information about the role of the redo log in crash recovery, see SECTION 15.17.2, "InnoDB Recovery"
#
# By default, the redo log is physically represented on disk by two files named ib_logfile0 and ib_logfile1.
#
# MySQL writes to the redo log files in a circular fashion. Data in the redo log is encoded in terms of records affected;
# this data is collectively referred to as redo. The passage of data through the redo log is represented by an ever-increasing
# LSN value.
#
# For related information, see Redo Log File Configuration, and Section 8.5.4, "Optimizing InnoDB Redo Logging"
#
# For information about data-at-rest encryption for redo logs, see Redo Log Encryption.
#
# CHANGING THE NUMBER or SIZE OF REDO LOG FILES
#
# To change the number or the size of redo log files, perform the following steps:
#
# 		1. Stop the MySQL server and make sure that it shuts down without errors.
#
# 		2. Edit my.cnf to change the log file configuration. To change the log file size, configure innodb_log_file_size.
#
# 			To increase the number of log files, configure innodb_log_files_in_group.
#
# 		3. Start the MySQL server again.
#
# If InnoDB detects that the innodb_log_file_size differs from the redo log file size, it writes a log checkpoint, closes
# and removes the old log files, creates new log files at the requested size, and opens the new log files.
#
# GROUP COMMIT FOR REDO LOG FLUSHING
#
# InnoDB, like any other ACID-compliant database engine, flushes the redo log of a transaction before it is committed.
#
# InnoDB uses group commit functionality to group multiple such flush requests together to avoid one flush for each commit.
#
# With group commit, InnoDB issues a single write to the log file to perform the commit action for multiple user transactions
# that commit at about the same time, significantly improving throughput.
#
# For more information about performance of COMMIT and other transactional operations, see SECTION 8.5.2, "Optimizing InnoDB Transaction Management"
#
# 15.6.6 Undo Logs
#
# An undo log is a collection of undo log records associated with a single read-write transaction. An undo log record contains information about how
# to undo the latest change by a transaction to a clustered index record.
#
# If another transaction needs to see the original data as part of a consistent read operation, the unmodified data is retrieved from undo log records.
#
# Undo logs exist within undo log segments, which are contained within rollback segments. Rollback segments reside in undo tablespaces
# and in the global temporary tablespace.
#
# Undo logs that reside in the global temporary tablespace are used for transactions that modify data in user-defined temporary tables.
#
# These undo logs are not redo-logged, as they are not required for crash recovery. They are used only for rollback while the server is
# running.
#
# This type of undo log benefits performance by avoiding redo logging I/O.
#
# For information about data-at-rest encryption for undo logs, see Undo Log Encryption.
#
# Each undo tablespace and the global temporary tablespace individually support a maximum of 128 rollback segments.
#
# The innodb_rollback_segments variable defines the number of rollback segments.
#
# The number of transactions that a rollback segment supports depends on the number of undo slots in the rollback segment
# and the number of undo logs required by each transaction.
#
# The number of undo slots in a rollback segment differs according to InnoDB page size.
#
# 		InnoDB Page Size 					Number of Undo Slots in a Rollback Segment (InnoDB Page Size / 16)
#
# 		4096 (4kb) 							256
#
# 		8192 (8kb) 							512
#
# 		16384 (16kb) 						1024
#
# 		32768 (32kb) 						2048
#
# 		65536 (64kb) 						4096
#
# A transaction is assigned up to four undo logs, one for each of the following operation types:
#
# 		1. INSERT operations on user-defined tables
#
# 		2. UPDATE and DELETE operations on user-defined tables
#
# 		3. INSERT operations on user-defined temporary tables
#
# 		4. UPDATE and DELETE operations on user-defined temporary tables
#
# Undo logs are assigned as needed. For example, a transaction that performs INSERT, UPDATE and DELETE operations on regular
# and temporary tables requires a full assignment of four undo logs.
#
# A transaction that performs only INSERT operations on regular tables requires a single undo log.
#
# A transaction that performs operations on regular tables is assigned undo logs from an assigned undo tablespace rollback segment.
#
# A transaction that performs operations on temporary tables is assigned undo logs from an assigned global temporary tablespace rollback segment.
#
# An undo log assigned to a transaction remains tied to the transaction for its duration. For example, an undo log assigned to a transaction for
# an INSERT operation on a regular table is used for all INSERT operations on regular tables performed by that transaction.
#
# Given the factors described above, the following formulas can be used to estimate the number of concurrent read-write transactions that InnoDB
# is capable of supporting.
#
# 		NOTE:
#
# 			A transaction can encounter a concurrent transaction limit error before reaching the number of concurrent read-write transactions
# 			that InnoDB is capable of supporting.
#
# 			This occurs when a rollback segment assigned to a transaction runs out of undo slots.
#
# 			In such cases, try rerunning the transaction.
#
# 			When transactions perform operations on temporary tables, the number of concurrent read-write transactions that InnoDB is capable
# 			of supporting is constrained by the number of rollback segments allocated to the global temporary tablespace, which is 128 by default.
#
# 		) If each transaction performs either an INSERT or an UPDATE or DELETE operation, the number of concurrent read-write transactions that InnoDB
# 			is capable of supporting is:
#
# 				(innodb_page_size / 16) * innodb_rollback_segments * number of undo tablespaces
#
# 		) If each transaction performs an INSERT and an UPDATE or DELETE operation, the number of concurrent read-write transactions that InnoDB
# 			is capable of supporting is:
#
# 				(innodb_page_size / 16 / 2) * innodb_rollback_segments * number of undo tablespaces
#
# 		) If each transaction performs an INSERT operation on a temporary table, the number of concurrent read-write transactions that InnoDB is capable
# 			of supporting is:
#
# 				(innodb_page_size / 16) * innodb_rollback_segments
#
# 		) If each transaction performs an INSERT and an UPDATE or DELETE operation on a temporary table, the number of concurrent read-write transactions
# 			that InnoDB is capable of supporting is:
#
# 				(innodb_page_size / 16 / 2) * innodb_rollback_segments
#
# 15.7 InnoDB Locking and Transaction Model
#
# 15.7.1 InnoDB Locking
# 15.7.2 InnoDB Transaction Model
# 15.7.3 Locks Set by Different SQL Statements in InnoDB
# 15.7.4 Phantom Rows
# 15.7.5 Deadlocks in InnoDB
#
# To implement a large-scale, busy, or highly reliable database application, to port substantial code from a different database system, or to tune
# MySQL performance, it is important to understand InnoDB locking and the InnoDB transaction model.
#
# This section discusses several topics related to InnoDB locking and the InnoDB transaction model with which you should be familiar.
#
# 		) Section 15.7.1, "InnoDB Locking" describes lock types used by InnoDB
#
# 		) Section 15.7.2, "InnoDB Transaction Model" describes transaction isolation levels and the locking strategies used by each.
#
# 								It also discusses the use of autocommit, consistent non-locking reads, and locking reads.
#
# 		) Section 15.7.3, "Locks Set by Different SQL Statements in InnoDB" discusses specific types of locks set in InnoDB for various statements.
#
# 		) Section 15.7.4, "Phantom Rows" describes how InnoDB uses next-key locking to avoid phantom rows.
#
# 		) Section 15.7.5, "Deadlocks in InnoDB" provides a deadlock example, discusses deadlock detection and rollback, and provides tips for minimizing
# 								and handling deadlocks in InnoDB.
#
# 15.7.1 InnoDB Locking
#
# This section describes lock types used by InnoDB.
#
# 		) Shared and Exclusive Locks
#
# 		) Intention Locks
#
# 		) Record Locks
#
# 		) Gap Locks
#
# 		) Next-Key Locks
#
# 		) Insert Intention Locks
#
# 		) AUTO-INC Locks
#
# 		) Predicate Locks for Spatial Indexes
#
# Shared and Exclusive Locks
#
# InnoDB implements standard row-level locking where there are two types of locks, shared (S) locks and exclusive (X) locks.
#
# 	) A shared (S) lock permits the transaction that holds the lock to read a row.
#
# 	) An exclusive (X) lock permits the transaction that holds the lock to update or delete a row.
#
# If transaction T1 holds a shared (S) lock on row r, then requests from some distinct transaction T2 for a lock on row r are handled
# as follows:
#
# 	) A request by T2 for an S lock can be granted immediately. As a result, both T1 and T2 hold an S lock on r.
#
# 	) A request by T2 for an X lock cannot be granted immediately.
#
# If a transaction T1 holds an exclusive (X) lock on row r, a request from some distinct transaction T2 for a lock of either type
# on r cannot be granted immediately.
#
# Instead, transaction T2 has to wait for transaction T1 to release its lock on row r.
#
# Intention Locks
#
# InnoDB supports multiple granularity locking which permits coexistence of row locks and table locks.
#
# For example, a statement such as LOCK_TABLES_..._WRITE takes an exclusive lock (an X lock) on the specified table.
#
# To make locking at multiple granularity levels practical, InnoDB uses intention locks.
#
# Intention locks are table-level locks that indicate which type of lock (shared or exclusive) a transaction requires
# later for a row in a table.
#
# There are two types of intention locks:
#
# 		) An intention shared lock (IS) indicates that a transaction intends to set a shared lock on individual rows in a table
#
# 		) An intention exclusive lock (IX) indicates that a transaction intends to set an exclusive lock on individual rows in a table.
#
# For example, SELECT_..._FOR_SHARE sets an IS lock, and SELECT_..._FOR_UPDATE sets an IX lock.
#
# The intention locking protocol is as follows:
#
# 		) Before a transaction can acquire a shared lock on a row in a table, it must first acquire an IS lock or stronger on the table.
#
# 		) Before a transaction can acquire an exclusive lock on a row in a table, it must first acquire an IX lock on the table.
#
# Table-level lock type compatibility is summarized in the following matrix.
#
# 		-/- 		X 				IX 			S 				IS
# 	
# 		X 			Conflict 	Conflict 	Conflict 	Conflict
#
# 		IX 		Conflict 	Compatible 	Conflict 	Compatible
# 
# 		S 			Conflict 	Conflict 	Compatible 	Compatible
#
# 		IS  		Conflict 	Compatible 	Compatible 	Compatible
#
# A lock is granted to a requesting transaction if it is compatible with existing locks, but not if it conflicts
# with existing locks.
#
# A transaction waits until the conflicting existing lock is released.
#
# If a lock request conflicts with an existing lock and cannot be granted because it would cause deadlock, an error occurs.
#
# Intention locks do not block anything except full table requests (for example, LOCK_TABLES_..._WRITE). The main purpose of
# intention locks is to show that someone is locking a row, or going to lock a row in the table.
#
# Transaction data for an intention lock appears similar to the following in SHOW_ENGINE_INNODB_STATUS and InnoDB monitor output:
#
# 		TABLE LOCK table `test`.`t` trx id 10080 lock mode IX
#
# Record Locks
#
# A record lock is a lock on an index record. For example, SELECT c1 FROM t WHERE c1 = 10 FOR UPDATE; prevents any other transaction
# from inserting, updating, or deleting rows where the value of t.c1 is 10.
#
# Record locks always lock index records, even if a table is defined with no indexes. For such cases, InnoDB creates a hidden
# clustered index and uses this index for record locking.
#
# See SECTION 15.6.2.1, "Clustered and Secondary Indexes"
#
# Transaction data for a record lock appears similar to the following in SHOW_ENGINE_INNODB_STATUS and InnoDB monitor output:
#
# 		RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t`
# 		trx id 10078 lock_mode X locks rec but not gap
# 		Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0
# 			0: len 4; hex 800000000a; asc 		;;
# 			1: len 6; hex 0000000000274f; asc 			'0;;
# 			2: len 7; hex b600000019d0110;  asc 				;;
#
# GAP LOCKS
#
# A gap lock is a lock on a gap between index records, or a lock on the gap before the first or after the last index record.
#
# For example, SELECT c1 FROM t WHERE c1 BETWEEN 10 and 20 FOR UPDATE; prevents other transactions from inserting a value of
# 15 into column t.c1, whether or not there was already any such value in the column, because the gaps between all existing
# values in the range are locked.
#
# A gap might span a single index value, multiple index values, or even be empty.
#
# Gap locks are part of the tradeoff between performance and concurrency, and are used in some transaction isolation levels
# and not others.
#
# Gap locking is not needed for statements that lock rows using a unique index to search for a unique row.
#
# (This does not include the case that the search condition includes only some columns of a multiple-column unique index;
#	in that case, gap locking does occur).
#
# For example, if the id column has a unique index, the following statement uses only an index-record lock for the row having
# id value 100 and it does not matter whether other sessions insert rows in the preceding gap:
#
# 		SELECT * FROM child WHERE id = 100;
#
# If id is not indexed or has a nonunique index, the statement does lock the preceding gap.
#
# It is also worth noting here that conflicting locks can be held on a gap by different transactions. For example, transaction A
# can hold a shared gap lock (gap S-lock) on a gap while transaction B holds an exclusive gap lock (gap X-lock) on the same gap.
#
# The reason conflicting gap locks are allowed is that if a record is purged from an index, the gap locks held on the record
# by different transactions must be merged.
#
# Gap locks in InnoDB are "purely inhibitive", which means that their only purpose is to prevent other transactions from inserting
# to the gap.
#
# Gap locks can co-exist. 
#
# A gap lock taken by one transaction does not prevent another transaction from taking a gap lock on the same gap.
#
# There is no difference between shared and exclusive gap locks. They do not conflict with each other, and they perform
# the same function.
#
# Gap locking can be disabled explicitly. This occurs if you change the transaction isolation level to READ_COMMITTED. Under these
# circumstances, gap locking is disabled for searches and index scans and is used only for foreign-key constraint checking and
# duplicate-key checking.
#
# There are also other effects of using the READ_COMMITTED isolation level. 
#
# Record locks for nonmatching rows are released after MySQL has evaluated the WHERE condition. For UPDATE statements, InnoDB
# does a "semi-consistent" read, such that it returns the latest committed version to MySQL so that MySQL can determine
# whether the row matches the WHERE condition of the UPDATE.
#
# NEXT-KEY lOCKS
#
# A next-key lock is a combination of a record lock on the index record and a gap lock on the gap before the index record.
#
# InnoDB performs row-level locking in such a way that when it searches or scans a table index, it sets shared or exclusive
# locks on the index records it encounters.
#
# Thus, the row-level locks are actually index-record locks.
#
# A next-key lock on an index record also affects the "gap" before that index record. That is, a next-key lock is an index-record
# lock plus a gap lock on the gap preceding the index record.
#
# If one session has a shared or exclusive lock on record R in an index, another session cannot insert a new index record in the
# gap immediately before R in the index order.
#
# Suppose that an index contains the value 10, 11, 13, and 20. The possible next-key locks for this index cover the following intervals,
# where a round bracket denotes exclusion of the interval endpoint and a square bracket denotes inclusion of the endpoint:
#
#  ( or ) = Exclusion of endpoint
# 	[ or ] = INclusion of endpoint

# 		(negative_infinity, 10]
# 		(10, 11]
# 		(11, 13]
# 		(13, 20]
# 		(20, positive infinity)
#
# For the last interval, the next-key lock locks the gap above the largest value in the index and the "supremum" pseudo-record having
# a value higher than any value actually in the index.
#
# THe supremum is not a real index record, so, in effect, this next-key lock locks only the gap following the largest index value.
#
# By default, InnoDB operates in REPEATABLE_READ transaction isolation level. In this case, InnoDB uses next-key locks for searches
# and index scans, which prevents phantom rows (see SECTION 15.7.4, "Phantom Rows")
#
# Transaction data for a next-key lock appears similar to the following in SHOW_ENGINE_INNODB_STATUS and InnoDB monitor output:
#
# 		RECORD LOCKS space id 58 page no 3 n bits 72 index `PRIMARY` of table `test`.`t`
# 		trx id 10080 lock_mode X
# 		Record lock, heap no 1 PHYSICAL RECORD: n_fields 1; compact format; info bits 0
# 		0: len 8; hex 73757072656d756d; asc supremum;;
#
# 		Record lock, heap no 2 PHYSICAL RECORD: n_fields 3; compact format; info bits 0
# 		0: len 4; hex 80000000a; asc 		;;
# 		1: len 6; hex 000000000274f; asc 		'0;;
# 		2: len 7; hex b600000019d0110; asc 			  ;;
#
# INSERT INTENTION LOCKS
#
# https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html
# 		