#Some Queries are commented out, but every query has been tested.

#SELECT version(), current_date; /* We can access basic functions and date formattings/underlying data with function calls and attribute designations */
/* Casing in terms of the function name etc, is irrelevant. */

/*we can, also - if we wish - use MySQL as a calculator for basic arithmetic operations */


#SELECT SIN(pi()/5), 5*2;

/* A couple of notes on this matter:

** is not allowed as an operator.

Each result of a query is parsed in a seperate windowing. */


/*
SELECT version(); SELECT 5*2;
*/


/* Just showcasing that we can perform several operations on the same line. 

Do denote, that each ; section, is denoted as a individual query each. */

/*
SELECT
USER(),

CURRENT_DATE;

*/

/* The above showcases that we can perform several line long queries, where the termination point of the query
or the "endpoint" of it - is the ; notation. */

/* In terms of if we were to run this by CMD line, we could incorporate a number of other factorials if we so wish:

akin to /c to stop execution or to perform cancellation.

As for the prompt in terms of CMD structure, it would be:

mysql> - is ready for a new query

-> Waiting for the next line of a multiple-line query

'> Waiting for the next line, waiting for completion in terms of string that begins with a '

"> Same as above, except string that begins with a "

`> Same as above, except identifier with backtick as beginning structure

/*> Same as above, except completion of comment section awaited

*/

#SHOW DATABASES;

/* Covering some basics of Syntax interactions

Do note - that if you do not yield the privleges or rights to view a database, it is not shown by this command. */

#USE world; 

/* Use, akin to Quit - does not need a semicolon, as it's a special designation command. 
It must be used on one line. */

#GRANT ALL ON world TO 'root'@'localhost';

/* Whilst granting full rights to the base Root user is not a wise move, this is done here to just illustrate the process */

#CREATE DATABASE illustration; 

/* Keep in mind that DB names are case sensitive. */

/* Where of we can create tables as well, if we so wish */

#USE illustration;

#SET sql_notes = 0;  
/* The above turns off storing and messaging in terms of warning messages 

Meaning, if you run SHOW WARNINGS; - it won't have anything to show, even if any triggered, as it won't
register them or catalog them. */

/*In case of changing attributes, we can utilize ALTER_TABLE statements. */
#CREATE TABLE IF NOT EXISTS example (name VARCHAR(20), x_attribute INTEGER(10), y_attribute INTEGER(10));


/* In terms of the Create if not exists attribute, it mainly applies to checking for table existence. */

#SET sql_notes = 1;

/*If we wish, ,we can denote to find out what the attributes of a Table is, with Describe. */

#DESCRIBE example;

/* Little bit of a note about the Local notation in the following:

LOAD DATA LOCAL INFILE 'D:/loadintodb.txt' INTO TABLE example;

It's a sensetive wording that is based on the installation and setup of the MySQL. This can either
come down to overriding with enabling construction in the underlying installation or overriding akin to
adhering of that MySQL have the full path installed - lest it will resolve to internal handles.

This can also be changed in Config files, akin to setting local-infile=1 in the .cnf file

We can also utilize things akin to exec()

*/

/* In terms of file security, we have the setup of certain privacy adherences to different file formats.

As of such, we can adhere to this, by running the showing of secure_file_priv - to then write to that file or upload,
as it's adhered to being safe. */

#SHOW VARIABLES LIKE "secure_file_priv";

#LOAD DATA INFILE 'D:/loadintodb.txt' INTO TABLE example; NOT ALLOWED BECAUSE OF SAFETY PRIVS OF FOLDERINGS
#Have to save to C:\ProgramData\MySQL\MySQL Server 8.0\Uploads\ \n

/* There is a number of different levels of interactions that are relevant to talk about in terms of Loading Local Data.

This can vary from permissions on Server side to Client siding and compilation settings.

To verifications in terms of SSL and dynamics akin to omitting Local to circumvent permissions needed of File
access, where of Local will be utilize loading up speed.

The major problem here - and sake of omittal in terms of this specific instance, is mostly file configuration
constraint. 

Need be, i will change this for upcoming repeated cases. */


#LOAD LOCAL DATA INFILE 'C:\ProgramData\MySQL\MySQL Server 8.0\Uploads\loadintodb' INTO TABLE example;

/* We can of course, commit to having insertions of tables as well. */

#DELETE FROM example; #Just clear out the Table

#INSERT IGNORE INTO example VALUES ('Example_1', 10, 15);
#Etc. Also, a small difference between Insert and Load Data, is that Load Data represents NULL with /N
#Whilst, if we wish to have NULL in terms of Insert, we can simply state it as NULL.

#The general pattern of Selecting is:
# SELECT <attribute_to_select> 
# FROM <table>
# WHERE <conditions>

#SELECT * FROM example;

#Where of we can of course, specify this and performs updates etc.

#UPDATE example SET x_attribute = 30 WHERE name = 'Example_1';
#We can of course, modify more and update the conditions, involve operators etc.
#We will cover that later.

#SELECT * FROM example;

#INSERT IGNORE INTO example VALUES ('Example_2', 55, NULL);
#INSERT IGNORE INTO example VALUES ('Example_Two', 3, NULL);
#INSERT IGNORE INTO example VALUES ('Testiiiiiiiing', 3, NULL);
#INSERT IGNORE INTO example VALUES ('aaaaaaaaa', 3, NULL);

#INSERT IGNORE INTO example VALUES ('Some_Tricky', NULL, 1003);
#INSERT IGNORE INTO example VALUES ('Some_Thing', NULL, 55);
#INSERT IGNORE INTO example VALUES ('Some_Trick', NULL, 10000);
#INSERT IGNORE INTO example VALUES ('Some_Trick', NULL, 10000);
#INSERT IGNORE INTO example VALUES ('Some_Trick', NULL, 10000);
#INSERT IGNORE INTO example VALUES ('Some_Trick', NULL, 10000); 
#INSERT IGNORE INTO example VALUES ('Some_Trick', NULL, 10000);


#SELECT * FROM example WHERE name LIKE '%xam%';

#We can basically utilize different forms of Regex or pattern recognition applications akin to % denotations to showcase, anything that fits
#along the designation of xam goes into the string.

#And of course, we can commit structured queries and prepared statements - however, we will cover that later.

#We can also select based on numerical samplings or comparisons

#SELECT * FROM example WHERE (y_attribute IS NOT NULL) AND (name LIKE 'Some_T%i__'); #Showcasing wildcard char and regex of 2 chars pattern length
/* The above interplays so that % is wildchar, __ is specific length of pattern, as in, pattern of length 2 */

#We can also utilize regex to locate for beginning and end, with ^ and $, where each is beginning/end respectively
#SELECT * FROM example WHERE REGEXP_LIKE(name, '^E');

#SELECT * FROM example WHERE REGEXP_LIKE(name, 'k$'); #Ends with k

#SELECT * FROM example WHERE REGEXP_LIKE(name, '^.{3,9}$'); #Checks a range of length of the name attribute from beginning to end, length interval of 3 to 9

#SELECT DISTINCT name FROM example WHERE REGEXP_LIKE(name, '^.{3,9}$');

#We could keep compounding different operations to check for values, patterns etc.

#SELECT DISTINCT name, x_attribute FROM example WHERE x_attribute < 100 ORDER BY x_attribute ASC, name ASC;

#The ordering in terms of Descending and Ascending is a matter of a compounded stature where we can just throw on more and more
#orders of operations in terms of integrations of Structure and differentiate how they should be partitioned.

#If we were interested, we could ordane TIMESTAMPDIFF to integrate accessing of Date denotations akin to CURDATE()

#For instance, in the documentation it is showcased as:
#SELECT name, birth, CURDATE(), TIMESTAMPDIFF(YEAR, birth, CURDATE()) AS age FROM pet;
#
# Where the mosti mportant part is just to denote the CURDATE() function and the TIMESTAMPDIFF() which interacts with date stamps
#Computing a differential

#CREATE TABLE IF NOT EXISTS datestuff (name VARCHAR(20), age INTEGER(20), first_date DATE, second_date DATE);

#DELETE FROM datestuff;
#DELETE FROM datestuff;

#INSERT IGNORE INTO datestuff VALUES ('Base_1', 100, '2018-10-10', CURDATE()); #Insert some basic date operations
#INSERT IGNORE INTO datestuff VALUES ('Base_2', 15, '2018-09-11', CURDATE()); 
#INSERT IGNORE INTO datestuff VALUES ('Base_3', NULL, '2018-05-11', CURDATE());
#INSERT IGNORE INTO datestuff VALUES ('Base_4', 5, '2011-01-11', CURDATE());
#INSERT IGNORE INTO datestuff VALUES ('Base_5', 100, NULL, CURDATE());  

#SELECT name AS variable_name, age AS x_variable, TIMESTAMPDIFF(MONTH, first_date, second_date) AS months_differing FROM datestuff 
#WHERE TIMESTAMPDIFF(MONTH, first_date, second_date) IS NOT NULL ORDER BY name; 
#As shown above, we can compute more and more "compounded" statements based on the Query Structure.
#
#The hiearchial principle of subcomposition in the query is based on the complexity of the Query, as we can chain the commands.
#However, we'll get into that later.

#We can subaccess the different dates by virtue of Month, Year, day, and intervals etc.

#In terms of Truth values - we run with binary denotation of truth/false values
#SELECT first_date IS NOT NULL FROM datestuff; #0 denotes a False outcome, 1 is a True outcome

#As far as Operations of Regex goes, we can utilize Grep, vi and sed of which are extensions

#SELECT name, COUNT(*) FROM datestuff GROUP BY age; #Now, if we had different structures and different parts of which we wish to
#integrate - we can do so - by better sub partitioning in the pattern of different structure pieces.
#To which we can perform count across a specific axis etc.

#In case you attempt to ordane selects past the point of Counts, we have to consider the
# ONLY_FULL_GROUP_BY attribute. Of which defines if only full groupings are to be accounted for.

#If the ONLY_FULL_GROUP_BY is not activated, the query is as if all the rows are a single group.
#But the nature of the naming of each column is nondeterministic.

#CREATE TABLE IF NOT EXISTS secondtable (name VARCHAR(20), age INTEGER(20), misc VARCHAR(20) , third_date DATE);

#DELETE FROM secondtable;


#INSERT IGNORE INTO secondtable VALUES ('SecondBase_1', 100, 'Example_1', CURDATE());
#INSERT IGNORE INTO secondtable VALUES ('SecondBase_2', 100, 'Example_2', CURDATE());
#INSERT IGNORE INTO secondtable VALUES ('SecondBase_3', 100, 'Example_3', CURDATE());
#INSERT IGNORE INTO secondtable VALUES ('SecondBase_4', 100, 'Example_4', CURDATE());
#INSERT IGNORE INTO secondtable VALUES ('SecondBase_5', 100, 'Example_5', CURDATE());




#We can access the hierarchy in terms of the databases with the class names and the sub attribute namings etc.

#SELECT illustration.datestuff.name as datestuff_name, illustration.secondtable.name as second_table_name,
#illustration.secondtable.age as cross_over_age
#FROM illustration.datestuff, illustration.secondtable WHERE illustration.datestuff.age = illustration.secondtable.age;

# The above causes the inherent pattern of querying across:
# Cycle from every element on base table -> Cycle through across every element of target Table
# TABLE[0][0-Length of sub-table denoted by element chosen] -> TABLE[1][0-length of sub-table denoted by element chosen]
#
# So, in our case - since both tables are 5 elements, this is 25 operations, as it cycles through 5x5 operations
# 2 of them co-align, so that means we have 5x2 results, 10 results
#

#We could omit the structure referal of doing explicit calls to explicit paths - however, that would fall back to local handle
#designation parameter interpretation - i.e, ambiguity is introduced into the Schematic.

#If we need to, we can run MySQL In batch mode as well, which allows us to integrate so that we are not running in a interactive mode.
#This is needed if we are to run for instance Cron Jobs.

#Run from CMD:
#
# mysql < batch-file , case of special chars being issues - run with -e
#
# The CMD line can also look like:
#
# mysql -h host -u user -p < batch-file
# enter password: --------

#We can also then pipe the output to either page more or have a further outputting file
#
# mysql < batch-file | more
#
# mysql < batch-file > mysql out

#We can also trigger MySQL scripts from CMD prompt of MySQL:
#
# mysql> source filename
# mysql> \ filename

#Showcasing some basic structural composition of base integrations

#CREATE TABLE IF NOT EXISTS Shoes (
#	Size INT(4) UNSIGNED ZEROFILL DEFAULT '0000' NOT NULL, #The base it goes for is 0000, numeral designated will simply inject unto the beginning
#	owner  CHAR(20) 					   DEFAULT '' 		NOT NULL, #The base string appended to, is ''
#	price   DOUBLE(16,2) 				DEFAULT '0.00' NOT NULL, #The default in terms of Pricing is just a 0.00
#	PRIMARY KEY(Size, owner));                            #The primary keys bound to the table

#CREATE TABLE IF NOT EXISTS People (
#	Age INT(4) UNSIGNED ZEROFILL DEFAULT '00' NOT NULL,
#	Name CHAR(20) 					  DEFAULT '' NOT NULL,
#	Last_Name CHAR(20) 			  DEFAULT '' NOT NULL,
#	PRIMARY KEY(Name, Last_Name));

#INSERT IGNORE INTO People VALUES
#	(30, 'Adrian', 'Markovich'), (50, 'Bonny', 'Taylor'), (60, 'Camille', 'Johnsonn'), (10, 'Zoe', 'Quinn'),
#	(15, 'Alexander', 'The Great'), (49, 'Alice', 'Cooper'), (100, 'Daniel', 'Markov'), (18, 'Alexander', 'The Great'),
#	(150, 'Daniel', 'Markov'); #Since Name and Last_Name are primary keys, they are implicitly Unique. I.e, duplications are ignored.


#INSERT IGNORE INTO Shoes VALUES
#	(34, 'Adrian', 3.45), (33, 'Bonny', 5.99), (32, 'Camille', 12.55), (35, 'Quinn', 1.10),
#	(41, 'Alexander', 10.00), (44, 'Alice', 12.33), (43, 'Daniel', 23.31);
	
#SELECT MAX(Size) AS Largest_Shoe_Size FROM Shoes;

#We can, if we so wish - denote to structure sub-queries of selectional structure.

#SELECT illustration.Shoes.Size AS size, illustration.Shoes.Price AS price, illustration.Shoes.owner AS owner_name FROM illustration.people, illustration.Shoes 
#WHERE illustration.people.name = illustration.Shoes.owner ORDER BY price LIMIT 2; #We can impose limits as well 

#SELECT owner AS owner_name, size AS largest_size FROM Shoes ORDER BY size DESC LIMIT 1; #Find the person with the biggest shoe size

#there is ways to circumvent the denotation of selecting the whole set and simply do a more specific Query in terms of Sorting and Grouping
#Albeit, that is a more advanced partition.


#SELECT name, last_name, Age, size FROM People, Shoes WHERE name = illustration.Shoes.owner AND age % 5 = 0;
#We can also involve operators in our selection of AND statements.

#If we wish, we can implement further denotations in terms of assigned variables

#Runs assignment from selected variables
#SELECT @min_size:=MIN(size), @max_size:=MAX(size) FROM Shoes;

#SELECT * FROM Shoes WHERE size=@min_size OR size=@max_size; #Get all the columns that trigger on having the size of assigned variables, in a or fashion

#In terms of creations of Tables - if we denote a References clause - that's a ignored section which only acts a indirecty way of comment or reminder.

#If we were to search based on optimized standardization of Query parsing - We can use an OR, bound to a single key
#Another way, is to do a Union between two Queries of Selects

#SELECT size FROM Shoes WHERE size > 10
#UNION
#SELECT owner FROM Shoes WHERE owner LIKE '%onn%';
#Kind of a poor example, but combines the two queries of performing where Size and owner is checked up on.

#CREATE TABLE IF NOT EXISTS purchased_ice_cream (name CHAR(20), price INT(4) UNSIGNED ZEROFILL, date_of_purchase DATE);

#Omit ignore into, to allow for duplications
#INSERT INTO purchased_ice_cream VALUES("Vanilla", 10, "2018-08-01");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-08-02");
#INSERT INTO purchased_ice_cream VALUES("Strawberry", 20, "2017-07-03");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-08-04");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-08-05");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-08-06");	
							
#INSERT INTO purchased_ice_cream VALUES("Caramell", 30, "2011-09-07");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-02-08");
#INSERT INTO purchased_ice_cream VALUES("Strawberry", 20, "2015-03-09");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2016-04-10");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2018-06-11");
#INSERT INTO purchased_ice_cream VALUES("Chocolate", 15, "2011-08-12");

#SELECT name, price, BIT_COUNT(BIT_OR(1<<DAY(date_of_purchase))) AS Unique_dates_of_purchase, COUNT(DAY(date_of_purchase)) AS amount_of_purchases FROM purchased_ice_cream GROUP BY name, price;
#The above showcases that we can run Queries against amount of purchases, on what amount of different days, unique or not, etc.
#We can of course also designate to be a factor of uniqueness to count in terms of BIT_COUNT, but we could also count by virtue of
#other methods.

#And we can, if we so wish - utilize Auto_Increment - which interplays so that it defaults to what value was designated last
#based on insertion operations

#CREATE TABLE IF NOT EXISTS example_of_auto_increment(id INT(10) NOT NULL AUTO_INCREMENT,
#	name CHAR(30) NOT NULL,
#	x_attribute CHAR(30) DEFAULT '' NOT NULL,
#	y_attribute CHAR(30) DEFAULT '' NOT NULL,
#	PRIMARY KEY (id)
#);
#When something is a Numerical akin to ID and we have auto_increment,
#We do not need to have a default designation - as the handle in terms of defaulting is implicit
#in designation to last numerical call or 0, depending on context.

#INSERT IGNORE INTO example_of_auto_increment (id, name, x_attribute) VALUES
#	(1, 'Shoe', 'Brown'),
#	(2, 'Pasta', 'Tasty'),
#	(3, 'Mug', 'Cheramic'),
#	(1001, 'Sickle', 'Ripping'),
#	(5, 'Frown', 'Sad'),
#	(100, 'Locks', 'Unbreakable'),
#	(10, 'Fox', 'Jumped over the Rice'),
#	(11, 'Box', 'Square');

#INSERT INTO example_of_auto_increment (name) VALUES
#	('Shoe');
#INSERT INTO example_of_auto_increment (name) VALUES
#	('Shoe_box');
#INSERT INTO example_of_auto_increment (id, name) VALUES
#	(NULL,'Glove_box');
#Simply runs auto-increment to reflect of where the last designated default handle was put in terms of Value designation
#We can also designate Null values as auto_increment generation if NOT NULL has been designated.

#If we wish to find out the latest Automatic generated ID, we can access it with LAST_INSERT_ID()

#We can further Enumerate structures by virtue of utilizing the MyISAM Engine designation of Tables.

#CREATE TABLE IF NOT EXISTS isam_example (
#	groupings ENUM('Shoe', 'Sock', 'Pants') NOT NULL,
#	id INT NOT NULL AUTO_INCREMENT,
#	color CHAR(30) NOT NULL,
#	PRIMARY KEY (groupings,id)
#) ENGINE=MyISAM;

#INSERT IGNORE INTO isam_example (groupings, color) VALUES
#	('Shoe', 'Brown'), ('Shoe', 'Green'), ('Shoe', 'Yellow'),
#	('Sock', 'Rainbow'), ('Sock', 'White'),
#	('Pants', 'Black'), ('Pants', 'Grey'),('Pants', 'Red'), ('Pants', 'Green');

#SELECT * FROM isam_example ORDER BY groupings, id;

#If we wish to configure the Apache logging format to adhere to MySQL's structure - we can do so by virtue of
#putting the following into the Apache configuration file:
#
# LogFormat \
# 				"\"%h\",%{%Y%m%d%H%M%S}t,%>s, \"%b\", "%{Content_Type}o\", \
# 				\"%U\", \"%{Referer}i\",\"%{User-Agent}i\""

#Where of the loading of a log file might look as follows:
#
# LOAD DATA INFILE '/local/access_log' INTO TABLE tbl_name
# FIELDS TERMINATED BY ',' OPTIONALLY ENCLOSED BY '"' ESCAPED BY '\\'

#There are a number of programs related to MySQL overall:
#
#mysql - the mysql daemon, i.e, the mysql server.
#
#mysqld_safe - A server startup script. mysqld_safe attempts to start mysqld.
#
#mysql.server - A server startup script. Used on systems that use System V-style run directories containing
#scripts that start system services for particular run levels. It invokes the mysqld_safe to start the MySQL Server.
#
#mysqld_multi - A server startup script that can start or stop multiple servers installed on the system.

#comp_err - Used during the MySQL build/installation process. Compiles error messages files from the error source files.

#mysql_secure_installation - Enables to improve the security of your MySQL installation.

#mysql_ssl_rsa_setup - creates the SSL cert and key files and RSA key-pair files required to support secure connections, if those
#files are missing. Files created by mysql_ssl_rsa_setup can be used for secure connections using SSL or RSA.

#mysql_tzinfo_to_sql - This program loads the time zone tables in the mysql db using the contents of the host system zoneinfo db
# (This is a set of files that describes time zones)

#mysql_upgrade - Used after a MySQL upgrade operation. Checks tables for incompatibilies and repairs them if nessecary, and updates
#the grant tables with any changes relevant in newer versionings of MySQL.

#The following is the client programs that connect to the MySQL server:

#mysql - cmd line tool for interactively entering SQL statements or executing them from a file in batch mode.

#mysqladmin - A client that performs administrative operations, such as creating or dropping DBs, reloading the grant tables,
#flushing tables to disk and reopening log files.
#
#mysqladmin can also be used to retrieve version, process and status information from the server. 

#mysqlcheck - A table-maintenance client that checks, repairs and analyzes and optimizes tables.

#mysqldump - A client that dumps a MySQL db into a file as SQL,text, or XML.

#mysqlimport - A client that imports text files into their respective tables using LOAD DATA INFILE.

#mysqlpump - a client that dumps a MySQL db into a file as SQL.

#mysqlsh - MySQL Shell is a code editor for MySQL server. Allows for scripting of JS and Python.

#mysqlshow - A client that displays information about DBs, tables, columns and indexes.

#mysqlslap - A client made to emulate client load for a MySQL server and report the timing of each stage.
#Works as if multiple clients are accessing the server.

#There are a few MySQL Administrative and utility sectioned programs as well
#
#innochecksum - a offline InnoDB offline checksum utility.

#myisam_ftdump - A utility that displays information about full-text indexes in MyISAM tables.

#myisamchk - A utility to describe, check and optimize/repair MyISAM tables.

#myisamlog - A utility that processes the contents of a MyISAM log file.

#myisampack - A utiliy that compresses MyISAM tables to produce smaller read-only tables.

#mysql_config_editor - A utility that enables you to store authentication credentials in a secure, encrypted login path file
#named .mylogin.cnf

#mysqlbinlog - A utility for reading statements from a binary log. The log of executed statements contained in the binary log files
#can be used to help recover from a crash.

#mysqldumpslow - A utility to read and summarize the contents of a slow query log.

#Past this, there are MySQL program-development utilities.

#mysql_config - A shell script that produces the option values needed when compiling MySQL programs.

#my_print_defaults - A utility that shows which options are present in option groups of option files.

#resolve_stack_dump - A utility program that resolves a numeric stack trace dump to symbols.

#There are some misc. utilities:

#lz4_decompress - A utility that decompresses mysqlpump output that was created using LZ4 compression.

#perror - A utility that displays the meaning of system or MySQL error codes.

#resolveip - A utility program that resolves a host name to an IP address or vice versa.

#zlib_decompress - Utility that decompresses mysqlpump output that was created using ZLIB compression.

#Some of the ENvironment variables used by MySQL are as follows:

#MYSQL_UNIX_PORT - The default Unix socket file, used for connections to localhost

#MYSQL_TCP_PORT - The default port number, used for TCP/IP connections

#MYSQL_PWD - The default PW

#MYSQL_DEBUG - Debug trace options when debugging

#TMPDIR - The dir where temporary tables and files are created.

#Past this, there is the interaction of actually interacting with MySQL from the Commandline

#mysql --user=root test 
#
#Harkening back unto Unix systems, -- denotes commands, - denotes unix options
#test is a DB name, in this instnace

#most common operations shorthand to the first letter of the naming to denote command interaction
#--host/-h - Host
#--user/-u - User
#--password/-p - Password
#
#--port/-P - Port number to connect to
#--socket/-S - Specify a UNIX socket file on Unix (named Pipe name on Windows)

#To circumvent full need of explicit path denotation in parameter accessing, we can include the installation Path
#in the PATH setup.
#
#Meaning, if Mysql is installed to /usr/local/mysql/bin - we can put that into PATH, allowing us to simply denote it as 
#mysql
#
#Generally the runtime path declaration resolves to a local handle in terms of the bin designation path
#as in, just refering to bin with resolve it to a local designation path for MySQL.
#
#This can be important as well in terms of recursive path resolution, as this can come to be bugged.

#The following pertains to connecting to a MySQL Server
#
# There are a number of default parameter handligns to fallback unto, in terms of how MySQL operates.
#This means that if you just write for instance MySQL in the cmd, it will resolve to the default resolution
#of certain program variables:

#default host name: localhost
#
#default user name: ODBC on Windows, Unix login name on UNIX.
#
#if neither -p or --password is given, password is given as empty field
#
#default name of db to access: the first non option parameter found. If none, it does not select one

#Example of showcasing of accessing
#
# mysql --host=localhost --user=myname --password=password mydb
# mysql -h localhost -u myname -ppassword mydb

#note, no space between -p or --password command and actual PW.

#Other users on the system can see the pw entered on cmd line with ps auxw.

#To avoid security risks in that department, simply omit writing the pw on the cmd line
#
# mysql --host=localhost --user=myname --password mydb
# mysql -h localhost -u myname -p mydb

# The above examples has omitted PW on the CMDline.

#Some systems limit the PW to 8 chars. Either have the PW as 8 chars, or put it as a value in a option file

#On Unix systems, localhost attempts to ordane connection through a UNix Socket. 
#To circumvent this, use explicit IP declaration
#
# mysql --host=127.0.0.1
# mysql --protocol=TCP Allows us to denote different connection types, even if it would default ot something else

#If the server is made to accept Ipv6 connections, clients can connect with --host=::1

#On windows, we can force named-pipe connections by specifying the --pipe or --protocol=PIPE option, or by using
#. as the hostname

#If named-pipe connections are not enabled, an error occurs. Use the --socket option to specify the
#name of the pipe, if we do not wish to have the default naming on pipes.

#Default port is 3306
#mysql --host=remote.example.com Defaults to port being 3306

#To specify a port use --port or -P
#mysql --host=remote.example.com --port=13306

#Do note, attempting to ordane localhost on a unix system will use a socket file
#to circumvent this, use more explicit denotation

#mysql --port=13306 --host=localhost Will ignore the port part on a Unix system, as it defaults to a socket file

#mysql --port=13306 --host=127.0.0.1
#mysql --port=13306 --protocol=TCP

#We can utilize things akin to hints to denote what the client-side authentication plugin should be:
#
#--default-auth=plugin

#To utilize pipes, we can use:
#--pipe, -W
#However, the server must be started with the --enable-named-pipe option to enable named-pipe connections.

#We can denote what kind of protocol to use, which relates back unto what kind of a OS is permissible to utilize it
#
# --protocol=TCP - TCP/IP connection to local or remote server, usable by all
#
# --protocol=SOCKET - Unix socket file connection to local server, Unix only

# --protocol=PIPE   - Named-pipe connection to local or remote server, Windows only

# --protocol=MEMORY - Shared-memory connection to local server, Windows only

#Do denote, for most cases - overhead is avoided with Socket default integrations in Unix systems.

#To run with Shared memory:

#--shared-memory-base-name=name , defaults to MYSQL. Server must be started with --shared-memory

#--socket=file_name, -S file_name - On Unix, the Unix socket file to use, for connections made using a named pipe to a local server.
# On Unix, defaults to /tmp/mysql.sock
# 
# On windows, the named pipe name to use. defaults to MySQL.

#Server must be started with --enable-named-pipe to enable this.

#--ssl* to start up connection based on SSL layering

#--tls-version=protocol list
#Denotes the protocols permitted by the client for encrypted connections. The value is a comma-separated list containing one
#or more protocol names.

#The protocols usable for this option depend on the SSL library used to compile MySQL.

#--user=user name, -u user_name - username to be used. default on Windows is ODBC or the Unix login name on Unix.

#We can modify options files akin to the Client section of an option file.

#We can also utilize PATH variables, akin to MYSQL_HOST, USER or MYSQL_PWD.

#The following section showcases the Path parameters in terms of connections
#They are bound to URI type strings or data dictionaries

#scheme:Specifies the connection protocol to use. To account for a specific protocol, use mysqlx, mysql for classic
#MySQL protocol connections. If a protocol is not specified - the server attempts to guess the protocol.

#user: Specifies the MySQL user account to be used for the authentication process.

#password: Specifies the password to be used for the authentication process. Do not store hte PW in the connection path

#host: Specifies the server instance the connection refers to. Can be either an IpV4 address, an IpV6 address or a hostname. If not specified,
#localhost is used by default.

#port: Specifies a network port which the target MySQL server is listening on for connections. If not specified, 33060 is used by default
#for X protocol connections.

#3306 is the default for classic MySQL protocol connections.

#socket: path to a Unix socket or Windows named-pipe. The values are local file paths and must be encoded in URI type strings,
#using % encodings or surrounding the path with ()'s - as full resolution of path is then realized, instead of needing to escape for explicit stature.

#To connect as root@localhost using Unix sockets, we can use /tmp/mysqld.sock we can use % or ()'s:

#()'s:
#root@localhost?socket=(/tmp/mysqld.sock)

#%'s:
#root@localhost?socket=%2Ftmp%2Fmysqld.sock

#Basically in the case of % escaping, we replace the direct symbols with underlying unicode translations
#akin to accessing of typing/other structuring.
#It resolves to /, regardless.

#schema: specifies the database to be set as default when a connection is established.

#?attribute=value: Specifies a data dictionary that contains options.

#The params are case insensitive and can only be defined once.
#If defined more than once, a error is generated.

#When a dictionary is used, the following options are also valid:
#
#ssl-mode: the SSL mode to be used for the connection.
#
#ssl-ca: the path to the X.509 cert authority in PEM format.
#
#ssl-capath: the path to the directory that contains the X.509 certs authorities in PEM format.
#
#ssl-cert:The path to the X.509 certs in PEM format.
#
#ssl-key: The path to the X.509 key in PEM format.
#
#ssl-crl: The path to file that contains certificate revocation lists
#
#ssl-crlpath: The path to the directory that contains certificate revocation list files.
#
#ssl-cipher: the SSL cipher to use.
#
#tls-version: List of protocols permitted for secure connections.
#
#auth-method: Authentication method used for the connection. Defaults to AUTO, meaning that the server attempts to guess.
#Can be one of the following:
#
#AUTO, MYSQL41, SHA256_MEMORY, FROM_CAPABILITIES, FALLBACK, PLAIN

#Whenever we use a X Protocol connection, any configured auth-method is overridden to this sequence of authentication methods:
#MYSQL41, SHA256_MEMORY, PLAIN.

#get-server-public-key. 
#Requests the public key from the server required for RSA key-paired based password exchange.
#
#use this when connecting to the MySQL 8.0 servers over classic MySQL protocol with SSL mode DISABLED.
#You must specify the protocol in this case, for example:
#
#mysql://user@localhost:3306?get-server-key=true

#server-public-key-path: The path name to a file containing a client-side copy of the public key required for RSA key pair-based password exchange.
#Use when connecting to MySQL 8.0 servers over classic MySQL protocol with SSL mode DISABLED.

#The ?attribute=value options data dictionary can contain are the following options:
#
#mycnfPath: the path to the MySQL configuration file of the instance.
#
#outputMycnfPath: alternative output path to write the MySQL configuration file of the instance.
#
#password: the password to be used by the connection.
#
#clusterAdmin: the name of the InnoDB cluster administrator used to be created. The supported format is the standard
#MySQL account name format.
#
#clusterAdminPassword: the password for the innoDB cluster admin account.
#
#clearReadOnly: a boolean value used to confirm that super_read_only must be disabled.
#
#interactive: A boolean of which disables the interactive wizards of assignments of variables/non-assignments etc.

#restart: A boolean of which is used to indicate that a remote restart of the target instance should be performed to finalize operations.

#The following is a covering of how to connect using a URI string

#We can specify a connection using a URI type string format. Such strings can be used with
#the MySQL Shell --uri command option, along with the MySQL Shell \connect command

#This also applies to tools like MySQL Routers and Connectors of whom implement X DevAPI.

#A typical URI type string has the following format:

#[scheme://][user[:[password]]@]target[:port][/schema][?attribute1=value1&attribute2=value2]

#Note, that reserved keywords must be escaped, akin to:
#% - %25
#@ - %40

#Some examples of connections being made with this formatting:
#
#A classical MySQL protocol connection to a local server instance listening at port 3333
#mysql://user@localhost:3333
#
#A X Protocol connection to a local server instance listening at port 33065
#mysqlx://user@localhost:33065
#
#A X protocol connection to a remote server instance, using a host name, an IpV4 address and an IpV6 address.
#
#mysqlx://user@server.example.com/
#mysqlx://user@198.51.100.14:123 IPV4 address
#mysqlx://user@[2001:db8:85a3:8d3:1319:8a2e:370:7348]
#
#We can also specify a optional path which represents a DB schema
#mysqlx://user@198.51.100.1/world%5Fx Basically, the encoding/escaping of chars akin to %5Fx is Hexadecimal and akin.
#mysqlx://user@198.51.100.2:33060/world

#Where of the following example illustrates a connection to a localhost, SSL integration with certs,
#key and cert.
#
#The example is just to illustrate the difference between escaping of characters and paranthesis integration
#
#ssluser@127.0.0.1?ssl-ca=%2Froot%2Fclientcert%2Fca-cert.pem\
#&ssl-cert=%2Froot%2Fclientcert%2Fclient-cert.pem\
#&ssl-key=%2Froot%2Fclientcert%2Fclient-key

#ssluser@127.0.0.1?ssl-ca=(/root/clientcert/ca-cert.pem)\
#&ssl-cert=(/root/clientcert/client-cert.pem)\
#&ssl-key=(/root/clientcert/client-key)

#Denote, the above documentation assumes that the integration does require a Password based on Syntax interaction.
#
#To account for a passwordless structure of where we can access the structure without a explicit PW,
#i.e - pw-less or integrated unto Unix socket connections, we must use the following Syntax:
#
#mysqlx://user:@localhost

#We can also utilize Dictionaries in terms of connection details towards a server, with the
#shell.connect() or dba.createCluster() MySQL Shell commands and with MySQL Connectors that implement the X DevAPI.

#Unlike URI strings, we need not escape characters in a Dictionary structure composition.

#If no PW is specified in the dict, none is promted for.

#Some examples are as follows:

#A X protocol connection to a local server @ port 33065
#{user:'user', host:'localhost', port:33065}

#A classic MySQL protocol X protocol connection, local server @ 3333
#{user:'user', host:'localhost', port:3333}

#An X protocol connection to a remote server instance, using a host name, an IPv4 address and an IPv6 address, is showcased:
#
#{user:'user', host:'server.example.com'}
#{user:'user', host:198.51.100.14:123}
#{user:'user', host:[2001:db8:85a3:8d3:1319:8a2e:370:7348]}
#
#We can also display an optional schema to represent a DB
#
#{user:'user', host:'localhost', schema:'world'}
#
# The above showcasing requires a PW.
# Showcasing case of no PW integration required
#
# {user:'user', password:'', host:'localhost'}

#There are a number of ways that we can specify program options:

#CMD line after the instegated command

#Options file to integrate options before running the program

#List the options in the environment variables

#Since the options are iteratively parsed, on duplications, the last one in the ordering is commited:

#mysql -h example.com -h localhost <- Will resolve to -h Localhost, since repetition of -h command parsing

#In the case of conflicting or related options are given - the later in the ordering is taken, instead of the earlier
#mysql --column-names --skip-column-names

#The ordering of processing is:
#Environment variables
#option files
#command line

#for the server, mysqld-auto.cnf takes highest prio (i.e, last)

#The following designates and showcases the usage of options on the CMD line

#Options are given after the cmd name

#A option argument begins with one or two dashes, depending on the format of the option.
#
#An example is the help command:
#
#-? (short) or --help (long)

#Option namings and designations are case sensitive. Example showcasing this:
#
# -v (verbose) or -V (version)

#Of course, sometimes options need arguments, as is showcased:
#
#-h localhost 
#
#or
#
#--host=localhost

#Delegation of parameters in long formatted PWs are separated with a =
#
#--password=<some value goes here> #Incinuates that we are to connect with said PW
#
#--password #Prompts for PW

#In the case of shortcutting the letter designation of password prompts, the dynamics can be seen as follows:
#
#mysql -ptest #Will attempt to access with a PW value of test, to whatever DB it defaults to
#
#mysql -p test #Will attempt to access the test DB, with no pw defined

#Do denote, that in terms of commands _ and - are synonymous in terms of interpretation
#
#--skip-grant-tables is the same as --skip_grant_tables

#We can also utilize suffixes in terms of utilization of commands.

#The notations are as follows: K, M, G (1024^1, 1024^2, 1024^3)
#
#In 8.0.14 or beyond:
#T,P,E (1024^4, 1024^5, 1024^6)

#For instance, if we wish to ping the server 1024 times intertwined with the power:

#mysqladmin --count=1K --sleep=10 ping 
#Denotes to ping 1024 times, 10 seconds interval

#If using filenames as option values, do not use ~

#When we denote to make queries on the CMD line, we use "" encapsulation, for instance
#
#mysql -u root -p --execute="SELECT User, Host FROM mysql.user" #Connect using the user of root, prompt for pw, execute the escaped Query
#

#Different levels of escaping might be needed, in terms of " or '
#
#Multiple statements can be passed in the option value on the CMD line separated by semicolons:
#
#mysql -u root -p -e "SELECT VERSION();SELECT NOW()"

#If we wish - we can disable/enable certain parts:

#Disabling:
#--disable-column-names
#--skip-column-names
#--column-names=0

#Enabling:
#--column-names
#--enable-column-names
#--column-names=1

#We can also use TRUE, OFF, FALSE - Non-case sensitive

#If we denote the --loose, it is a option of denoting that the program do not exit upon an error or unrecognized command, instead it does so with a warning
#
#mysql --no-such-option #Would cause an error, unrecognized command
#
#mysql --loose-no-such-option #Would exit with a warning, despite unrecognized command

#We can also limit session values, akin to memory allocation - as follows, in mysqld:
#
#--maximum-max_heap_table_size=32M - Prevents a client from making the heap table size limit larger than 32M.
#
#--maximum cannot be applied to system vars that are global in scope:
#
#--maximum-back_log=200 #Gives an error because attempted designation to a global system var

#In case of if we wish to denote what options files are read, we can use --verbose and --help
#
#a MySQL program with --no-defaults reads no option files other than .mylogin.cnf
#
#A server started with the persisted globals load system var disabled does not read mysqld-auto.cnf

#The login path group options allow for the following:
#
#host,user,password,port and socket

#To  define what login path to read from in the .mylogin.cnf - we can use the --login-path option.

# If we wish to specify another login path file name, we can set the MYSQL_TEST_LOGIN_FILE environment variable.
# This variable is used by mysql-test-run.pl and is recognized by other mysql clients.

#There is a second config file, that is auto managed by the server - that is called:
#
#mysqld-auto.cnf file in the data directory. This is a JSON file that contains persisted system var settings.
#
#It is created by the server upon execution of SET PERSIST or PERSIST_ONLY.
#
#One should not manage said fail alone, and leave that to the server.

#On Windows systems, the files are read in the following order:
#
# NAME 																	PURPOSE
#
# %WINDIR%\my.ini, %WINDIR%\my.cnf 							Global options

# C:\my.ini, C:\my.cnf 											Global options

# BASEDIR\my.ini, BASEDIR\my.cnf 							Global options

# defaults-extra-file 											The file specified with --defaults-extra-file (if any)

# %APPDATA%\MySQL\.mylogin.cnf 								Login path options (clients only)

# DATADIR\mysqld-auto.cnf 										System variables persisted with SET PERSIST or PERSIST_ONLY (server only)

#The %WINDIR% and %APPDATA% are basically system path designations that are found by utilization of Regex,
#to find them, we can simply echo their  designation in the cmd line:
#
# C:\> echo %WINDIR% #Showcases where the Windows directory is
#
# C:\> echo %APPDATA% #Showcases where the Appdata dir is

#BASEDIR refers to the MySQL base install dir. usually, it is at C:\PROGRAMDIR\MySQL\MySQL 8.0 Server
#where the Programdir, is the program files dir.

#DATADIR is the MySQL data dir. It is used to find mysqld-auto.cnf - the default being the data dir loc
#built in when MySQL was compiled - but can be changed with --datadir specified as a option-file.

#It can also be changed by virtue of cmd line designation before the mysqld-auto.cnf is processed.

#On Unix, the ordering of the startup is as follows:
#
# FILE NAME 						PURPOSE
# /etc/my.cnf 						Global options
# /etc/mysql/my.cnf 				Global options
# SYSCONFDIR/my.cnf 				Global options
# $MYSQL_HOME/my.cnf 			Server-specific options (server only)
# defaults-extra-file 			The file specified with --defaults-extra-file, if any
# ~/.my.cnf 						User-specific options
# ~/.mylogin.cnf 					User-specific login path options (clients only)
# DATADIR/mysqld-auto.cnf 		System variables persisted with SET PERSIST or PERSIST_ONLY (server only)

#As per usual, the ~ denotes the home dir, the set system var of $HOME
#
# SYSCONFDIR is the dir specified with the SYSCONFDIR option to CMake when MySQL was built.
# By default, this is the etc file dir

# MYSQL_HOME is an env variable containing the path to the dir in which the server-specific my.cnf file
# resides.
#
# If MYSQL_HOME is not set and you start the server using mysqld_safe, mysqld_safe sets it to BASEDIR, the MySQL base install dir.

# DATADIR refers to the MySQL data dir. As used to find mysqld-auto.cnf, its default value is the data dir location built in when
# MySQL was compiled.
#
# can be changed with --datadir specified as an option-file or command-line option processed before mysqld-auto.cnf is processed.

# If multiple instances are given, the latest is taken.
#
# The one exception is mysqld, where the first is taken of the --user option as security precaution.

#The following integration rules adheres to the manually edited files - not standing in terms of the .mylogin.cnf which is
# created using mysql_config_editor and is encrypted. 
#
# This too accounts for mysqld_auto.cnf, which the server creates in JSON.

#In terms of Options files, the following rules are adhered to:

# Any cmd line integrated on CMD line is done with --, in option files we omit thoose.

# Empty lines are ignored. Comments start with ; or #

# [group] denotes a group subsectioning. Holds until end of file or different Group designation.

#Leading and trailing spaces are deleted. We can have spaces around the =

#We are allowed to use the following escape sequences:
#
# \b, \t, \n, \r, \\ and \s
#
# they are in order:
#
# backspace, tab, newline, carriage return, backslash and space

#The chars are only escaped if they are not valid commands. i.e, \s is not escaped - \S is, due to invalid command.

#The above implies that we can write a \ as either: \\ or \

#The escape rules in terms of opton files is denoted as conversion unto "(char)" upon errornous registration of a command.
#As in, if \x is not a command, it's converted to "x"

#Note: In option files, on Windows - \ can be written as / as well

#Examples of usage:

#basedir="C:\\Program Files\MySQL\MySQL Server 8.0"
#basedir="C:\\Program Files\\MySQL\\MySQL Server 8.0"
#basedir="C:/Program Files/MySQL/MySQL/MySQL Server 8.0"
#basedir=C:\\Program\sFiles\\MySQL\\MySQL\sServer\s8.0

#If a option name denotation is the same as a program name, then that group applies specifically to that program.
#Akin to:
#
# [mysqld] and [mysql] applying to mysqld and mysql respectively.

# [client] is read by all client programs provided in MySQL distributions.

# Do note, we have to be careful about level of options that we put in in terms of Client,
# that it is understood by all levels of the clients. If not understood, the client will raise an exception and quit.

#In terms of ordering of hierarchy in terms of options, we go from:
#
#Highest global reach
#
# More specific
#
# Most specific
#
# For instance:
#
# [client]
# port=3306
# socket=/tmp/mysql.sock
#
# [mysqld]
# port=3306
# socket=/tmp/mysql.sock
# key_buffer_size=16M
# max_allowed_packet=128M
#
# [mysqldump]
# quick

#Another example of a option file:

#[client]
# Send out a standardized password for all client level integrations
# password="my password"

#[mysql]
#no-auto-rehash
#connect_timeout=2

#We can target versionings as well:
#
#[mysqld-8.0]
#sql_mode=TRADITIONAL

#To include specific files or even dirs, we can use !include and !includedir
#
# !include /home/mydir/myopt.cnf #reads that specific config file
#
# !include /home/mydir #reads all the option files in mydir

#On Windows, the extensions included are .ini and .cnf
#
#Linux is .cnf
#
#Past that, MySQL does not guarantee ordering of integration

#As far as Grouping goes contra Parsing, as we iterate - we integrate what actually is
#targeted by the respective groupings - akin to that if MySQLD is reading something - it will
#trigger thoose respective groups.

#Past this, we can come to talk about CMD line options that affect option-file handling

#The following commands, to function properly - must be given before other options, except for:
#
# --print-defaults can be used after --defaults-file, --defaults-extra-file or --login-path
#
# On Windows, if the server is started with the --defaults-file and --install options,
# --install must be first.
#

#--defaults-extra-file=file_name - reads this option file after the global option file 
#
# On Unix, this is read before the user option file 

# On all platforms, this is read before the login path file.

# The parameter name in terms of file name, is treated as a relative path towards the CWD.
# To fundamentally assess greater control, we can denote the full explicit path, if we want

# --defaults-file=file_name - reads the given option file.
# 
# Note: even with the above, mysqld refers to mysqld-auto.cnf and client refers to .mylogin.cnf

# --defaults-group-suffix=str
#
# Denotes a default suffix of grouping name to read.
#
# For instance - a parameter name of "dogs" would groups that have a suffix of "dogs",
# like - [options_dogs]

# --login-path=name
#
# Reads options from the named login path in the .mylogin.cnf login path file.
# This specific group denotes which MySQL server to connect to and which account to authenticate as.
#
# To create or modify this login path file - use the mysql_config_editor

#This path is read even if --no-defaults is set.
#
# The given command is appended unto the already list of defaulted programs, as can be showcased:
#
# mysql --login-path=somextra
#
# Would end up with mysql reading [client] and [mysql] from the option files,
# and [client], [mysql], and [mypath] from the login path file.

#To specify an alternate login path file name, set the MYSQL_TEST_LOGIN_FILE env variable

#--no-defaults
#
# Prevents default option files from being read.
# Will still read .mylogin.cnf

#--print-defaults
#
#Prints the program name and all of the options that it gets from the option files.
#PWs are masked.

# --max_allowed_packet=32M #Can be specified in Bytes.
#
# Still power denotation in terms of K, M, G (1024^1, 1024^2, 1024^3) and T,P,E (1024^4, 1024^5, 1024^6)
#
# In option files:
#
# [mysql]
# max_allowed_packet=32M #can be specified in bytes

#- and _ are treated as equals in the context of variable names
#
# example:
#
# [mysqld]
# key_buffer_size=512M
# 
# is identical to
#
# [mysqld]
# key-buffer-size=512M

#In terms of variable naming, we can give ambigious naming that can be autocompleted,
#However, it's just a better idea to denote a option name htat is fully declared.

# mysql --max=1000000 would be interpreted as ambigious as it would not be clear to what it means, in terms of
# meaning max_allowed_packet or max_join_size
# to which we would be warned.

#Server setup denotation of commands do not support arithmetic interpretation in terms of intialization
#
# mysql --max_allowed_packet=16M #Allowed in server startup
# mysql --max_allowed_packet=16*1024*1024 #Not allowed, due to being a operation

# At runtime, when the server is running etc, though:
# SET GLOBAL max_allowed_packet=16M; #Not allowed in a runtime env.
# SET GLOBAL max_allowed_packet=16*1024*1024;

#For options that do not require a value, we can omit the assignment operator in notation (=):
#
# mysql --host=somehost --user=someguy #Usable with default value integrations
#
# mysql --host tonfisk --user jon #Usable with non-default value integrations

# In terms of omitting variables names, can cause errors akin to skipping, as showcased:
#
# mysql --host --user jon #Will give an error in trying to access host --user

#An example of denoting of where to log errors, in terms of a UNIX system
# NOTE: For safety, use = assignment in variable name contexts

# mysqld_safe --log-error=my-errors & #The & is just a background designation operator for UNIX systems
#
#For default isntallation and relative pathing, this gives to:
# '/usr/local/mysql/var/my-errors.err'

#The next section will be about setting ENV Vars

#We can denote environment variables in terms of Usernames, ports, exporting etc:
#
# SET USER=your_name
#
# For unix systems, accounting for sh, ksh, bash, zsh:
#
# MYSQL_TCP_PORT=3306
# export MYSQL_TCP_PORT
#
# For csh and tcsh:
#
# setenv MYSQL_TCP_PORT 3306

#The above are allocated to session. To denote for more permanent startup status:
#
# Windows -> Control panel
#
# Unix (Bash) -> .bashrc or .bash_profile for bash 
# Unix (tcsh) -> .tcshrc

#An example of modifying the path denotation variable in Bash
#
# #Assume /usr/local/mysql/bin is the installation path
# 
# PATH=${PATH}:/usr/local/mysql/bin #put in .bashrc file to allow for easy access to MySQL setup in terms of options

#Note, the .bashrc is for login shells, and .bash_profile is for nonlogin shells

#In the case of tcsh:
# setenv PATH ${PATH}:/usr/local/mysql/bin

#The next section is mysqld_safe

#Some Unix systems involve usage of a MySQL Server startup that is safer,
#i.e - mysqld_safe

#These features include things like restarting the server and logging runtime info to an error log.

#On some specific UNix systems, akin to RPM or Debian, include systemd support for managing MySQl server
#startup/shutdown.

#If we wish to override the default options and specify a explicit name of the server we wish to run
#we can specify --mysqld or --mysqld-version option to mysqld_safe.

#You can also use --ledir to indicate the dir where mysqld_safe should look for the server.

#The options in terms of mysqld_safe is the same as mysqld

#If the option is unknown to mysqld_safe, they are passed to mysqld if it's done on the cmd line
#
#However, if this is done in a option file - specified to [mysqld_safe] as a group
#they are ignored.

#mysqld_safe will read all of the options from the [mysqld], [server] and [mysqld_safe] sections
#in option files.

#Note, for backwards compability cases - mysqld_safe also reads [safe_mysqld] sections

#The following denotes the options for mysqld_safe

# Format 	 					Desc
#	
# --basedir 					path to MySQL installation dir
# --core-file-size 			Size of core file that mysqld should be able to create
# --datadir 					path to the data dir
# --defaults-extra-file 	Read named option file in addition to usual option files
#
# --defaults-file 			Read only named option file
# --help 						display help message and exit
# --ledir 					 	Path to directory where server is located
# --log-error 					Write error log to named file
#
# --malloc-lib 						Alternative malloc library to use for mysqld
# --mysqld 								Name of server program to start (in ledir directory)
# --mysqld-safe-log-timestamps 	Timestamp format for logging
# --mysqld-version 					Suffix for server program name
# --nice 								Use nice program to set server scheduling priority
# --no-defaults 						Read no option files
#
# --open-files-limit 				Number of files that mysqld should be able to open
# --pid-file 							Path name of server process ID file
# --plugin-dir 						Directory where plugins are installed
# --port 								Port number on which to listen for TCP/IP connections

# --skip-kill-mysqld 				Do not try to kill stray mysqld processes
# --skip-syslog 						Do not write error messages to syslog; use error log file
# --socket 								Socket file on which to listen for Unix socket connections

# --syslog 								Write error messages to syslog
# --syslog-tag 						Tag suffix for messages written to syslog
# --timezone 							Set TZ time zone environment variable to named value
# --user 								Run mysqld as user having name user_name or numeric user ID user_id

#Some further covering in terms of different parts
#
#--help - Display a help message and exit
#
#--basedir=dir_name - The path to the MySQL install dir

#--core-file-size=size - The size of the core file that mysqld should be able to create. 
#The value of the option is passed to ulimit -c
#
# If we disable innodb buffer pool in core file, we can reduce the core file size.

#--datadir=dir_name - The path to the data dir

#--defaults-extra-file=file_name - Read this option file in addition to the usual option files.
#
# If the file is not found, does not exist or permissions are not given - the server exists with an error.
#
# file_name is interpreted as relative to the current dir if given as a relative path name rather than
# a full path name. 
#
#This must be the first option on the cmd line if used.

#--defaults-file=file_name
#
#Use only the given option file. If the file does not exist or is otherwise inaccessible, the server exits with an error.
#
#file_name is interpreted as relative to the current dir if given as a relative path name rather than a explicit one.
#
#This must be the first option on the cmd line if used

#--ledir=dir_name - 
#
#If mysqld_safe cannot find the server, use this option to indicate the path name to the dir where the server is located.
#
#This command can only be given on cmdline, not in option files. On platforms that use systemd, the value can be specified
#in the value of MYSQLD_OPTS.

#--log-error=file_name
#
#Write the error log to the given file

#--mysqld-safe-log-timestamps
#
#This option is the one that controls the format of timestamps in the log output produced by mysqld_safe.
#
#If the value does not belong to any of the following, a warning is logged and resorts to UTC formatting.
#
#UTC,utc - ISO 8601 UTC format (this is the same as --log timestamps=UTC for the server) - Defaults to this

#SYSTEM, system - ISO 8601 local time format (same as --log timestamps=SYSTEM for the server)

#HYPHEN, hyphen - YY-MM-DD h:mm:ss format, as in mysqld_safe for MySQL 5.6

#LEGACY, legacy - YYMMDD hh:mm:ss format, as in mysqld_safe prior to MySQL 5.6

#--malloc-lib=[lib name]
#
#The name of the library to use for memory allocation instead of the system malloc() library. 
#
#The option value must be one of the dirs:
# /usr/lib
# /usr/lib64
# /usr/lib/i386-linux-gnu
# /usr/lib/x86_64-linux-gnu

#The --malloc-lib option works by modifying the LD_PRELOAD env value to affect dynamic linking to enable
#the loader to find the memory-allocation library when mysqld runs.

#Some notes on this:

#If the option is not given, or is given without a value (--malloc-lib=), LD_PRELOAD is not modified
#and no attempt is made to use tcmalloc.

#If the option is given as --malloc-lib=tcmalloc, mysqld_safe looks for a tcmalloc library in /usr/lib
#
#If tcmalloc is found, its path name is added to the beginning of the the LD_PRELOAD value for mysqld.
#
#If tcmalloc is not found, mysqld_safe aborts with an error.

#If the option is given as --malloc-lib=/path/to/some/library, that full path is added to the beginning
#of the LD_PRELOAD value.
#
#If said path is not legitimate - as in nonexistent or unreadable, mysqld_safe aborts with an error.

#For the cases of where mysqld_safe adds a path name to LD_PRELOAD - it adds the path to the beginning of any
#existing value the variable already has.

#NOTE: In case that our system manage using systemd, mysqld_safe is not available.
#Thus - we instead specify the allocation lib by setting LD_PRELOAD in /etc/sysconfig/mysql.

#In terms of Linux, we can use the libtcmalloc_minimal.so lib on any platform for which a tcmalloc
#package is installed in /usr/lib by adding the following lines to my.cnf:
#
# [mysqld_safe]
# malloc-lib=tcmalloc

#To use a specific tcmalloc lib, specify its full path name:
#
# [mysqld_safe]
# malloc-lib=/opt/lib/libtcmalloc_minimal.so

#--mysqld=prog_name
#
#The name of the server program (in the ledir directory) that you want to start.
#
#This option is needed if you use the MySQL binary distirbution but have the data
#dir outside of the binary distribution.
#
#If mysqld_safe cannot find the server, use the --ledir option to indicate the path name
#to the dir where the server is located.
#
#This command is only available on cmd line, not in option files. On platforms that use systemd,
#the value can be specified in the value of MYSQLD_OPTS.

#--mysqld-version=suffix
#
#This option is similar to the --mysqld option, but you specify only the suffix for the server program name.
#The base name is assumed to be mysqld.
#
#--nice=priority
#
#Use the nice program to set the server's scheduling prio to the given value.

#--no-defaults
#
#Do not read option files. Can be used to prevent crashing of attempting to access invalid paths/errors raised are simply offset
#as in the failed files are not read.

#--open-files-limit=count
#
#The number of files that mysqld should be able to open. This options value is passed to ulimit -n.
#
#NOTE: This call requires root permissions in terms of level of started the program.

#--pid-file=file_name
#
#The path name that mysqld should use for its process ID file.

#--plugin-dir=dir_name
#
#The path name of the plugin dir

#--port=port_num
#
#The port number that the server should use when listening for TCP/IP connections. The port number
#must be 1024 or higher lest the server is started by root priveleges.

#--skip-kill-mysqld
#
#An option to disallow killings of stray mysqld processes at startup.
#Works only on Linux.

#--socket=path
#The Unix socket file that the server should use when listening for local connections.

#--syslog, --skip-syslog
#
# --syslog: Causes error messages to be sent to syslog on systems that support the logger program.

# --skip-syslog: suppresses the use of syslog; messages are written to a error log file.

#If syslog is used for error logging, daemon.err facility/severity is used for all log messages.

#However, the above is deprecated in terms of controlling mysqld.
#To control the facility, use the server log syslog facility system var.

#--syslog-tag=tag: also deprecated, use the server log syslog tag system var.

#--timezone=timezone - Sets the TZ time zone environment var to the given option value.
#Legal time zone specs is relative to OS doc specs

#--user={<USER> name|<USER> id}
#
#Run the mysqld server as the user having the name user_name or the numeric user ID user_id.
#(<USER> in this context refers to a system login account - not a part of the MySQL users in teh grant tables.)

#Illustration of forced ordering in terms of --defaults-file or --defaults-extra-file:
#
# mysqld_safe --port=port_num --defaults-file=file_name #Will ignore the default file command, due to not first place ordering
#
# mysqld_safe --defaults-file=file_name --port=port_num

#To have a decent run with mysqld_safe - one of the following conditions need to be true:
#
# If we executed mysqld_safe from the MySQL Install dir - the server and DB must be able to be found in terms of
# a relative path to the working dir.
#
# For binary distributions, mysqld_safe looks for bin and data in the CWD

# For source distris, it looks for libexec and var dirs

# If the above fails, it attempts by absolute paths akin to:
#
# /usr/local/libexec
#
# or 
#
# /usr/local/var

#These locations are determined upon config when installing MySQL.

#An example of running MySQL anywhere, based on relative pathing, assuming initial path is done to the MySQL Install dir:
#
# cd mysql_installation_directory
# bin/mysqld_safe & #Delegate to background job

#If this fails, we can delegate with --ledir or --datadir to indicate dirs for the server and DB.

#The default attempts to attempting to start is 5/second, by utility of sleep and date.
#If this is exceeded - it waits 1 full second before going at it again.

#Error messages go to syslog and stdout.
#To direct options - use syslog.

#The following covers server interaction on the CMD line.
#Naming refers to local installation naming, such as mysqld or mysql.
#I will simply refer to it as mysql here.

#This pertains to Linux systems.

#To start/Stop the script:
#
# mysql start #To start
# mysql stop  #To stop

#To run the server as some specific user, we can config the /etc/my.cnf - adding a user option to
# the [mysqld] group.

#To start or stop MySQL Automatically on the server - we can add start and stop commands in /etc/rc*

#If we use the Linux server RPM package (MySQL-server-VERSION.rpm) or a native Linux package, it may be installed
# in the /etc/init.d dir with the name mysqld or mysql.

#If we do not have the server installed, we can copy a version of it
#
#cp mysql.server /etc/init.d/mysql  #Copy the server to the designated folder
#chmod +x /etc/init.d/mysql

#Depending on our system and integration of Unix - we can use chkconfig to activate it to run at system startup
#
# chkconfig --add mysql
#
# Sometimes, we need a different version
#
# chkconfig --level 345 mysql on

#If it is a version of FreeBSD, the scripts should generally go in /usr/local/etc/rc.d/
#
#Install the mysql.server script as /usr/local/etc/rc.d/mysql.server.sh to enable automatic startup

#The base name file pattern must be *.sh to trigger, otherwise it is silently ignored.

#Sometimes, some operative systems use /etc/rc.local or /etc/init.d/boot.local to start additional
#services on startup.
#
#To utilize it, append something akin to the following to a startup file:
#
# /bin/sh -c 'cd /usr/local/mysql; ./bin/mysqld_safe --user=mysql &'

#mysql.server reads from [mysql.server] and [mysqld] sections of option files.
#
#We can add options for mysql.server in a global /etc/my.cnf, it might look as follows:
#
# [mysqld]
# datadir=/usr/local/mysql/var
# socket=/var/tmp/mysql.sock
# port=3306
# user=mysql

# [mysql.server]
# basedir=/usr/local/mysql

#The following are mysql.server option-file options
#
# Option Name 								Desc 														Type
# basedir 						Path to MySQL installation dir 								Directory name
# datadir 						Path to MySQL data directory 									Directory name
# pid-file 						File in which server should write its process ID  		File name
# service-startup-timeout 	How long to wait for server startup 						Integer

#The following is explonations of the different parts:
#
#basedir=<dir name> # The path to the MySQL installation dir
#
#datadir=<dir name> # The path to the MySQL data dir
#
#pid-file=<file name> # The path name of the file in which the server should write its process ID.
#
## if this option is not given, it defaults to <host_name>.pid
# This file value overrides the mysqld_safe specified in [mysqld_safe] option file group
#
# For safety in terms of the server value starting designations, we can specify both
# in [mysqld_safe] and [mysqld] groups.

# service-startup-timeout=<seconds>
#
# How many seconds to wait for confirmation of server startup.
# If the server does not start within said limit, mysql.server exits with an error.
# Defaults to 900.
#
# Negative is forever (no timeout), 0 is to not wait at all.

#The following is related to mysqld_multi - which is to manage multiple MySQL servers

#The mysqld_multi is designed to handle/listen to different connections on different Unix sockets files 
# and TCP/IP ports.

#The mysqld_multi searches for groups that are called [mysqldN] in my.cnf
#
# Or in the file named by the --defaults-file option
#
#N refers to the group number, to which can also be represented as GNR.
#It can be any positive integer.

#Each respective numeral represents a server/connection - they have their own values
#
#To invoke mysqld_multi - we can use the following syntax:
#
# mysqld_multi [options] {start|stop|reload|report} [GNR[, GNR] ...]

#If no list exists - mysqld_multi performs the operation for all servers in the option file.
#
#We can perform more specific numerals in terms of listing of gnr's, operations and listing of options

#Some examples of utilization of starting multiple servers, groupings etc:
#
# mysqld_multi start 17 #Just starts nr 17
#
# mysqld_multi stop 8, 10-13 #8, 10,11,12,13
#
# mysqld_multi --example #more examples

#The search order for option files are as follows:
#
# --no-defaults - no option files read
#
# --defaults-file=<file name> - onl the named file is read

# Beyond this standard prio is taken, incl. --defaults-extra-file=<file name>

#Option files read are searched for [mysqld_multi] and [mysqldN] option groups.
#
# The [mysqld_multi] can be used for options to mysqld_multi itself

# The [mysqldN] groups can be used for options passed to specific mysqld instances.

# The [mysqld] or [mysqld_safe] groups can be used for common options read by all instances of mysqld or
# mysqld_safe.

# We can specify a --defaults-file=<file name> option to use a different config file for that instance
# To which the sourceo f [mysqld] or [mysqld_safe] is redirected to this file.

# The following options are what pertain to mysqld_multi:
#
# --help - Displays a help message and exits
#
# --example - Display a sample option file
#
# --log=<file name> - Specify the name of the log file. If hte file exists, log output is appended to it.
#
# --mysqladmin=<prog name> - the mysqladmin binary to be used to stop servers
#
# --mysqld=<prog name> - The mysqld binary to be used. We can specify mysqld_safe for this option.
# if we do - we can include mysqld or ledir in the corresponding [mysqldN] option group.
#
# These options are to indicate the name of the server that mysqld_safe should start and the path
# name of the dir where the server is located.
#
# For instance:
#
# [mysqld38]
# mysqld = mysqld-debug
# ledir = /opt/local/mysql/libexec

# --no-log - Print log info to stdout rather than the log file. By default, it goes to log.

# --password=<password> - The PW of the MySQL acc to use when invoking mysqladmin. Non-optional, for this program.

# --silent - Silent mode, no warnings

# --tcp-ip - Connect to each MySQL server through the TCP/IP port instead of the Unix socket file.
# (If a socket file is missing, the server might still be running, but accessible only through the TCP/IP port)
#
# By default, the connections are made through the Unix socket file. Affects stop and report operations.

# --user=<user name> - User name of the MySQL acc to use when invoking mysqladmin

# --verbose - Verbose mode

# --version - Version info and exit

#NOTE: Use seperate dirs when splintering with mysqld servers.
#
# Make sure of clearance of reading/writing of each file dir.
#
#Splintering does not give performance increasing in terms of the threading pooling

#We also have to make sure that privs to SHUTDOWN is given, and that we have the same connection params for all
#parts involved. 

#Showcasing of targetting and giving privs to each resp. server:
#
# mysql -u root -S /tmp/mysql sock -p #Will prompt for pw
# CREATE USER 'name_to_be_given_to_multi_admin'@'your_server' IDENTIFIED BY 'multipass'
#
# GRANT SHUTDOWN ON *.* TO 'name_to_be_given_to_multi_admin'@'your_server'
#
# The above, is shorthand for giving shutdown privleges on all fronts in terms of the given user account 
#
# The above must be repeated for every mysqld server.
# We must also have multi_admin rights from where we connect with mysqld_multi

# The respective socket files in terms of Unix and TCP/IP port must be different for every mysqld.
#
# If the host has multiple network addresses, we can use --bind-address to cause different servers
# to listen to different interfaces

# The --pid-file option is important for if we use mysqld_safe to start mysqld (for example, --mysqld=<mysqld_safe>
# We need to have a seperate pid file for every respective mysqld.

# The advantage of using mysqld_safe instead of mysqld is that mysqld_safe monitors its mysqld process,
# allowing us to have restarts in case of kill signals (kill -9) or segmentation faults.

#To be allowed to use --user for mysqld, we have to run the mysqld_multi as root
#Designating options in the option file, does not matter.

# if we try to run mysqld whilst not root, we get a warning and it's run under our own Unix acc

#The following is an example of having a option file to use with mysqld_multi:

# The order of the mysqld programs are started or stopped depends on the order in the opt file
# The sequence need not be unbroken 

# [mysqld_multi] #The base mysqld_multi structure
# mysqld 		= /usr/local/mysql/bin/mysqld_safe
# mysqladmin 	= /usr/local/mysql/bin/mysqladmin
# user 			= multi_admin
# password 		= my_password

# [mysqld2] #The splinters
# socket 		= /tmp/mysql.sock2
# port 			= 3307
# pid-file 		= /usr/local/mysql/data2/hostname.pid2
# datadir 		= /usr/local/mysql/data2
# language 		= /usr/local/mysql/share/mysql/english
# user 			= unix_user1

# [mysqld3]
# mysqld 		= /path/to/mysqld_safe
# ledir 			= /path/to/mysqld-binary/
# mysqladmin 	= /path/to/mysqladmin
# socket 		= /tmp/mysql.sock3
# port 			= 3308
# pid-file 		= /usr/local/mysql/data3/hostname.pid3
# datadir 		= /usr/local/mysql/data3
# language 		= /usr/local/mysql/share/mysql/swedish
# user 			= unix_user2

# [mysqld4]
# socket 		= /tmp/mysql.sock4
# port 			= 3309
# pid-file 		= /usr/local/mysql/data4/hostname.pid4
# datadir 		= /usr/local/mysql/data4
# language 		= /usr/local/mysql/share/mysql/estonia
# user 			= some_user_5

# [mysqld6]
# socket 		= /tmp/mysql.sock6
# port 			= 3311
# pid-file 		= /usr/local/mysql/data6/hostname.pid6
# datadir 		= /usr/local/mysql/data6
# language 		= /usr/local/mysql/share/mysql/japanese
# user 			= unix_user4

#The next section covers MySQL installation related things, akin to:
# comp_err, ssl_rsa, tzinfo_to_sql, mysql_upgrade etc.

#comp_err:

# Creates the errmsg.sys file that is used by mysqld to determine the error message to display
# for different error codes.

# comp_err normally is run automatically when MySQL is built. It compiles the errmsg.sys file
# from the text file located at sql/share/errmsg-utf8.txt in the MySQL source distr.

# It also generates mysqld_error.h, mysqld_ername.h and sql_state.h header files

# To invoke comp_err:

# comp_err [options]

# Supports the following options:

# --help, -? - Displays a help message and exit

# --charset=<dir name>, -C dir_name - The char set directory. The default is ../sql/share/charsets

# --debug=<debug options>, -# <debug options> - Write a debug log. 
# A typical debug_options string is d:t:O, <file name>
# the default is:
# d:t:O, /tmp/comp_err.trace

# --debug-info, -T - Print debug info when the program exits

# --header file=<file name>, -H <file_name> - name of the error header file. 
# defaults to: mysqld_error.h

# --in file=<file name>, -F <file_name> - The name of the input file.
# defaults to: ../sql/share/errmsg-utf8.txt

# --name file=<file name>, -N <file_name> - The name of the error name file.
# Defaults to: mysqld_ername.h

# --out dir=<dir name>, -D <dir name> - Name of output base dir
# Defaults to: ../sql/share/

# --out file=<file name>, -O <file name> - Name of the output file
# Defaults to: errmsg.sys

# --statefile=<file name>, -S <file_name> - Name of the SQLSTATE header file.
# Defaults to: sql_state.h

# --version, -V #Displays version info and exits

# mysql_secure_installation:
#
# Allows us to set pw for root accs, remove root accs outside of localhost, remove anon users, remove the test DB
# (The test DB can be accessed by anon users/all users) - we can also remove permits of dbs with name that starts with
# test_

# Base usage:
# mysql_secure_installation

# Doing this, will prompt for an action.

# We can utilize validate_password to check PW strength.

# Showcasing of using cmd line and options files to connect:
#
# mysql_secure_installation --host::1 --port=3307

#The following options can be defined by cmd line or in option file groups of:
# [mysql_secure_installation] 
# [client]

#The options of the mysql_secure_installation are as follows:
#
# FORMAT 													DESC
#
# --defaults-extra-file 				Read named option file in addition to usual option files
# --defaults-file 						Read only named option file
# --defaults-group-suffix 				Option group suffix value
# --help 									Display help messages n exit
# --host 									Host to connect to (IP address or host name)
# --no-defaults 							Read no option files
# --password 								Accepted but ignored. Prompt occurs regardless
# --port 									TCP/IP port number for connection
# --print-defaults 						Print default options
#
# --protocol 								Connection protocol to use
# --socket 									For connections to localhost, the Unix socket file to use
# --ssl-ca 									File that contains list of trusted SSL Certs Auths
# --ssl-capath 							Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 								File that contains X.509 certificate
# --ssl-cipher 							List of permitted ciphers for connection encryption
#
# --ssl-crl 								File that contains cert revocation list files
# --ssl-crlpath 							Dir that contains cert revocation list files
# --ssl-fips-mode 						Whether to enable FIPS mode on the client side
#
# --ssl-key 								file that contains X.509 key
# --tls-version 							Protocols permitted for encrypted connections
# --use-default 							Execute with no user interactivity
# --user 									MySQL user name to use when connecting to the server

# Further explaining of subsections:
#
# --help, -? - Display a help message and exit
# --defaults-extra-file=<file name> - Reads this option file after the global option file, but before the user option file.
# --defaults-file=<file name> - use only the given option file. If the file does not exist or is inaccessible, errors occur.
# 										  Pathing is: relative (default), full on explicit designation
# --defaults-group-suffix=<str> - Additional groupings to read in terms of suffix regex designation (i.e, all of the defaults + suffix matches)
# --host=<host_name>, -h <host_name> - Connect to the MySQL Server on the given host.
#
# --no-defaults - Do not read any option files. If program startup fails due to reading unknown options from an option file, --no-defaults can be used to
# prevent them from being read.
#
# As per usual, if .mylogin.cnf exists - it is read, regardless of options.

# --password=<password>, -p <password> - The option is accepted but ignored. mysql_secure_installation always prompts for PW.
# --port=<port num>, -P <port_num> - TCP/IP port to use for the connection

# --print-defaults - Print the program name and all options that it gets from option files
# --protocol={TCP|SOCKET|PIPE|MEMORY} - The connection protocol to use for connecting to the server.
# --socket=<path>, -S <path> - What Unix socket/Windows pipe to use when connecting to localhost.
# --ssl* - Connect using SSL, implies need to specify SSL keys and certs.

# --ssl-fips-mode={OFF|ON|STRICT} - Controls whether to enable FIPS mode on the client side.
# Denotes what cryptographic operations are permitted - not actually used to establish encrypted connections.

# OFF - Disables FIPS mode.
# ON - Enables FIPS mode.
# STRICT - Enable "strict" FIPS mode.

# If the OpenSSL FIPS Object Module is not available, the onl permitted value is OFF.
# Attempting to ordane ON or STRICT, causes warning at startup, resorting to non-FIPS mode.

# --tls-version=<protocol list> - Protocols permitted by the client for encrypted connections. The value is a comma-separated list
# containg one or more protocol names.
#
# The protocols used depend on the SSL lib used to compile MySQL.

# --use-default - Execute noninteractively. Can be used for unattended installation operations

# --user=<user name>, -u <user_name> - MySQL user name when connecting to the server.

#Next section covers: mysql_ssl_rsa_setup - Creating SSL/RSA files
#
# creates the SSL certificate and key files and RSA key-pair files required to support secure
# connections using SSL and secure password exchange using RSA over unencrypted connections,
# if those files are missing.
#
# Can also be used to create new SSL files if existing ones have expired.
#
# Note, these forms of certs are self-signed - i.e, not safe. This is more about the principle of creation/usage,
# not the factual gain of security in terms of usage.
#
# To invoke mysql_ssl_rsa_setup:
#
# mysql_ssl_rsa_setup [options]
#
# The typical options are --datadir to specify where to create the files, and --verbose to see the openssl commands
# that mysql_ssl_rsa_setup executes.
#
# mysql_ssl_rsa_setup attempts to create SSL and RSA files using a default set of file names. It works as follows:
#
# > checks for the openssl binary at the locations specified by the PATH env var.
# > If not found - nothing happens.
#
# If openssl is present, mysql_ssl_rsa_setup looks for default SSL and RSA files in the MySQL data dir specified
# by the --datadir option or the compiled-in data dir if the --datadir option is not given.
#
# > Checks the data dir for SSL files with the following names:
# ca.pem
# server-cert.pem
# server-key.pem
#
# > If any of the above exist, no SSL files are created. Otherwise, openssl is invoked to create them, for a total of:
#
# ca.pem 			#Self-signed CA cert
# ca-key.pem 		#CA private key
# server-cert.pem #Server cert
# server-key.pem 	#Server private key
# client-cert.pem #Client cert
# client-key.pem 	#Client private key
#
# > Checks data dir for RSA files with the following names:
#
# private_key.pem 	#Private member of private/public key pair
# public_key.pem 		#Public member of private/public key pair

# If any of the above is present, mysql_ssl_rsa_setup creates no RSA files.
# Otherwise, invokes openSSL to create them.
#
# The files enable secure PW exchange using RSA over unencrypted connections for
# accounts authenticated by the sha256_password or caching_sha2_password plugin

# When starting the MySQL Server, it automatically uses the SSL files created by mysql_ssl_rsa_setup
# to enable SSL if no explicit SSL options are given other than --ssl (possibly also --ssl-cipher)
#
# If we prefer to designate the files explicitly, invoke the clients with the --ssl-ca, --ssl-cert and
# --ssl-key options to name the ca.pem, client-cert.pem and client-key.pem files, respectively
#
# The server also automatically uses the RSA files created by mysql_ssl_rsa_setup to enable RSA, if none are explicitly given
#
# If the server has activated SSL, the client uses SSL by default for the connection.
#
# Also, to circumvent the read/write permission problems in terms of locations of Certs,
# due to that the initialized data dir permissions is restricted to the System account that runs the server.
#
# To make the files available, copy them to a dir that is readable (but not writable) by clients:
#
# For local clients, the MySQL install is assumed, thus, we can use a relative path in terms of implied referal in copying:
#
# cp ca.pem client-cert.pem client-key.pem
#
# For remote clients, we distribute the files using a secure channel to ensure they are not tampered with.
#
# If the SSL files have expired - we can use mysql_ssl_rsa_setup to create new ones:
#
# > Stop the server
# > Rename or remove the existing SSL files. You may wish to make a backup of them first.
# (RSA's do not expire)
# > Run mysql_ssl_rsa_setup with the --datadir option to specify where to create the new files.
# >Restart the server

# mysql_ssl_rsa_setup supports the following CMD line options - can be specified on the CMD line or 
# in the [mysql_ssl_rsa_setup] and [mysqld] groups of an option file.

# Options for mysql_ssl_rsa_setup :
#
# FORMAT 			DESC
# --datadir 		Path to data directory
# --help 			Display help messagee and exit
# --suffix 			Suffix for X.509 cert Common Name attribute
# --uid 				Name of effective user to use for file permissions
# --verbose 		Verbose mode
# --version 		Display version info and exit

# Further explonation of the commands:
#
# --help, ? - Display a help message and exit
# --datadir=<dir name> - The path to the directory that mysql_ssl_rsa_setup should check for default SSL and RSA files and in
# which it should create files if they are missing. 
#
# Defaults to compiled-in data dir
#
# --suffix=<str> - Suffix of the common name attribute in X.509 certs. The suffix value is limit to 17 chars.
# The default is based on the MySQL version number.
#
# --uid=<name>, -v - The name of the user who should be the owner of any created files. The value is a user name,
# not a numeric user ID. 
#
# In case this is absent, files created by mysql_ssl_rsa_setup are owned by the user who executes it. This option is 
# valid only if you execute the program as root on a system that supports the chown() system call.
#
# --verbose, -v - Verbose mode. Tells about if it skipped SSL, RSA file creation and openssl commands being run.
#
# --version, -V - Display version info and exit.

#Next covers mysql_tzinfo_to_sql - The time Zone tables
#
# Loads the time zone tables in the mysql db. It is used on systems that have a zoneinfo DB (set of files that describe time zones)
#
# Examples of such OS's: Linux, FreeBSD, Solaris, and OS X. One likely location for these is the /usr/share/zoneinfo dir
# (/usr/share/lib/zoneinfo on Solaris).
#
# mysql_tzinfo_to_sql can be invoked several ways:
# mysql_tzinfo_to_sql <tz_dir>
# mysql_tzinfo_to_sql <tz_file> <tz_name>
# mysql_tzinfo_to_sql --leap <tz_file>

#Exampel of invocation:
# mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root mysql #Pipe the output to mysql from the zoneinfo dir path name, access mysql with root user

# mysql_tzinfo_to_sql reads the systems time zone files and generates SQL statements from them. mysql processes them to load the time zone tables.
# 
# The second syntax, loads a single time zone file <tz_file> that corresponds to a time zone name tz_name:
#
# mysql_tzinfo_to_sql <tz_file> <tz_name> | mysql -u root mysql
#
# If we need to account for leap seconds, use the third syntax noted in the above ordering.

#To account for the newly initialized data and to circumvent previously cached time zone data 
# we have to restart the server.

#Next up, is mysql_upgrade

#mysql_upgrade is a utility in terms of integrating updates to tables and capacities in terms of between versionings

#If mysql_upgrade finds that a table has a possible incompability - it performs a table check and, if issues are found
#attempts a table repair.

#The mysql_upgrade runs updating in terms of the MySQL tables

#The base initialization of command is:

#mysql_upgrade [options]

#After we have run mysql_upgrade - we need to stop and restart it.

#If we have multiple MySQL servers running - we can invoke mysql_upgrade with connection parameters
#as can be showcased:
#
# mysql_upgrade --protocol=tcp -P 3306 [other_options]
# mysql_upgrade --protocol=tcp -P 3307 [other_options]
# mysql_upgrade --protocol=tcp -P 3308 [other_options]

#In terms of running on localhost on Unix, the --protocol=tcp options forces a connection
#using TCP/IP rather than the Unix socket file

#NOTE: In case of disabled_storage_engines sys var set to disable certain storage engines (for instance, MyISAM)
#mysql_upgrade might fail as follows:
#
# mysql_upgrade: [ERROR] 3161: Storage engine MyISAM is disabled (Table creation is disallowed)
#
# To handle it, restart the server with disabled_storage_engines disabled.
# We can then run mysql_upgrade successfully. 
#
# After that, restart the server with disabled_storage_engines set to its original value

#mysql_upgrade runs a version comparison in terms of a file named mysql_upgrade_info in the data dir.
#
#This is used to quickly check whether all tables have been checked for this release so that
#table-checking is skipped.
#
#To ignore this file, run --force

#Unless we invoked with --skip-sys-schema - then mysql_upgrade installs the sys schema and upgrades it.
#
# However, if there exists one and has no version view - we have to rename it/remove it and then
#run the upgrade.

#If we wish, we can upgrade specific individual tables with ALTER TABLE ... UPGRADE PARTITIONING

#mysql upgrade can fail to upgrade due to expired PWs, which we can reset with the following:

#mysql -u root -p #Then reset the PW with alter user
#ALTER USER USER() IDENTIFIED BY 'root-password';

#Run the mysql_upgrade again after having exited:
#mysql_upgrade [options]

#The following options are the ones that mysql_upgrade supports
#
# They are found in [mysql_upgrade] and [client]groups of an option file.
#
# FORMAT 																		DESC
# --bind-address 					Use specified network interface to connect to MySQL Server
# --character-sets-dir 			Directory where character sets are installed
# --compress 						Compress all information sent between client and server
#
# --debug 							Write debugging log
# --debug-check 					Print debugging information when program exits
# --debug-info 					Print debugging information, memory and CPU statistics when program exits
# --default-auth 					Authentication plugin to use
# --default-character-set 		Specify default character set
# --defaults-extra-file 		Read named option file in addition to usual option files
#
# --defaults-file 				Read only named option file
# --defaults-group-suffix 		Option group suffix value
# --force 							Force execution even if mysql_upgrade has already been executed for current version of MySQL
# --get-server-public-key 		Request RSA public key from server
#
# --help 							display help messages and exit
# --host 							Connect to MySQL server on given host
# --login-path 					Read login path options from .mylogin.cnf
# --max-allowed-packet 			Maximum packet length to send or recieve from server
#
# --net-buffer-length 			Buffer size for TCP/IP and socket communication
# --no-defaults 					Read no option files
# --password 						Password to use when connecting to server
# --pipe 							On Windows, connect to server using named pipe
# --plugin-dir 					Directory where plugins are installed
#
# --port 							TCP/IP port number for connection
# --print-defaults 				Print default options
# --protocol 						Connection protocol to use
# --server-public-key-path 	Path name to file containing RSA public key
#
# --shared-memory-base-name 	The name of shared memory to use for shared-memory connections
# --skip-sys-schema 				Do not install or upgrade the sys schema
# --socket 							For connections to localhost, the Unix socket file to use
# --ssl-ca 							File that contains list of trusted SSL Certificate Authorities
# --ssl-capath 					Directory that contains trusted SSL Certificate Authority certificate files
#
# --ssl-cert 						File that contains X.509 certificate
# --ssl-cipher 					List of permitted ciphers for connection encryption
# --ssl-crl 						File that contains certificate revocation lists
# --ssl-crlpath 					Directory that contains certificate revocation list files
#
# --ssl-fips-mode 				Whether to enable FIPS mode on the client side
# --ssl-key 						File that contains X.509 key
# --ssl-mode 						Security state of connection to server
# --tls-version 					Protocols permitted for encrypted connections
#
# --upgrade-system-tables 		Update only system tables, not data
# --user 							MySQL user name to use when connecting to server
# --verbose 						Verbose mode
# --version-check 				Check for proper server version
# --write-binlog 					Write all statements to binary log

#The showcasing in terms of Options and what they do:
#
# --help - Display a short help message and exit
# --basedir=<dir name> - The path to the MySQL installation dir
# --bind-address=<ip address> - On a computer having multiple network interfaces, use this to decide which one to use for connecting
# --character-sets-dir=<dir name> - The dir where char sets are installed
#
# --compress, -C - Compress all info between client and server, if both support compression.
# --debug[=<debug options>], -# [<debug options>] - Writes a debug log. Typical: d:t:o, <file_name>
# Defaults to: d:t:O,/tmp/mysql_upgrade.trace
# --debug-check - Print some debugging information when the program exits
# --debug-info, -T - Print debugging information and memory and CPU usage stats when the program exits
#
# --default-auth=<plugin> - A hint about the client-side auth plugin to use.
# --default-character-set=<charset name> - Use <charset_name> as the default character set
# --defaults-extra-file=<file name> - Read this option file after the global option file but (on Unix) before the user option file.
# --defaults-file=<file name> - Use only the given option file. If the file does not exist or inaccessible - error is raised. Path is relative if given as such, Full otherwise.
#
# --defaults-group-suffix=<str> - Read not only the usual option groups, but also groups with usual names and suffix of <str>.
#   										 Normally reads [client] and [mysql_upgrade] - treats str input as suffix regex.
# --force - 							 Ignore the mysql_upgrade_info and force run
#
# --get-server-public-key 			 Requests the public key required for the RSA key-pair PW exchange.
# 											 Applies to the clients whom authenticate with caching_sha2_password auth plugin.
# 											 In case of usage of this plugin - the server does not send the public key lest requested.
# 											 The option is ignored for accs that do not authenticate with said plugin.
# 					
# 											 If a secure connection is rendered to the server, RSA exchange is not used - as such, this command is then ignored.
#
# 											 If --server-public-key-path=<file name> is given and specifies a valid public key file, it takes precedence over
# 											 --get-server-public-key
#
# --host=<host name>, 				 Connect to the MySQL on the given host. 
# -h <host name>
# --login-path=<name> 				 Read options from the named login path in the .mylogin.cnf login path file.
# 											 The login path is the group option that specifies which MySQL server to connect to
# 											 and which acc to authenticate as.
#
# --max-allowed-packet=<value> 	 The max size of the buffer for client/server communication. Defaults to 24MB. Min is 2kb, max is 2Gb.
# --net-buffer-length=<value> 	 The initial size of the buffer for client/server comm. Default is 1MB - 1kb. The min 4KB, max 16MB
# --no-defaults 						 Do not read any option files. Prevents exception raising failures
# 							
# 											 Exception is .mylogin.cnf file, if it exists - is read in all cases (reading PW from File)
# --password[=<password>], 		  
# -p [<password>]	  					 PW. -p prevents space after input, --password without value prompts for it
#
# --pipe, -W 							 On Windows, connect to the server using a named pipe. Applies only if the server supports named-pipe connections
# --plugin-dir=<dir name> 			 The dir in which to look for plugins. Use if --default-auth is used for an Auth plugin, but it is not found.
# --port=<port num>, 
# -P <port_num> 						 The TCP/IP port number to use for the connection.
# --print-defaults 					 Print the program name and all options that it gets from option files.
#
# --protocol=
#{TCP|SOCKET|PIPE|MEMORY} 			 The connection protocol to use for connecting to the server. 
# 											 It is useful when the other connection parameters normally would cause
# 											 a protocol to be used other than the one you want.
#
# --server-public-key-path=       The path name to a file containing a client-side copy of the public key required by the server
# <file name> 							 for RSA key pair-based PW exchange. The file must be in PEM format.
#              
# 											 This option applies to clients that authenticate with the sha256_password or caching_sha2_password
# 											 authentication plugin. This is ignored for accounts that do not authenticate with one of those plugins.
#
# 											 It is also ignored if RSA-based pw exchange is not used, as is the case when the client connects to
# 											 the server using safe connections (SSL)
#
# 											 If --server-public-key-path=<file name> is given and specifies a valid public key file, it takes
# 											 precedence over --get-server-public-key.
#
# 											 For Sha256_pw, this applies only if we used SSL to build the MySQL.
#
# --shared-memory-base-name= 		 On Windows, the shared memory name to use, for connections made using shared memory to a local server.
# <name> 								 Defaults to MySQL. Case-sensitive. Must startup with --shared-memory to enable shared-memory connections.
#
# --skip-sys-schema 					 mysql_upgrade installs the sys schema if it is not installed, and upgrades it to the current version otherwise.
#                                 This suppresses that behavior.
#
# --socket=<path>, -S <path> 		 Connections to localhost, Unix socket file to use - Windows, the named pipe to use.
# --ssl* 								 Options that begin with --ssl specify whether to connect the server using SSL and indicate where to 
# 											 find SSL keys and certs.
#
# --ssl-fips-mode={OFF|ON|STRICT} Controls whether to enable FIPS mode on the client side. The --ssl-fips-mode option differs from other
# 										    --ssl-xxx options in that it is not used to establish encrypted connections, but rather to affect which
# 											 cryptographic operations are permitted.
#
# 											 The options are: OFF (Disable FIPS mode), ON (Enable FIPS mode), STRICT (Enable "strict" FIPS mode).
# 											 
# 											 If the OpenSSL FIPS Object Module is not available, the only permitted value is OFF. 
# 											 Going against it, produces a warning and starts in non-FIPS mode.
#
# --tls-version=<protocol list> 	 The protocols permitted by the client for encrypted connections. The value is a comma-separated list 
# 											 containing one or more protocol names. 
# 												
#                                 The protocols that can be named for this option depend on the SSL library used to compile MySQL.
#
# --upgrade-system-tables, -s 	 Upgrade only the system tables, do not upgrade the data.
#
# --user=<user name>,  				 The MySQL user name to use when connecting to the server. defaults to root.
# -u <user_name>
# 
# --verbose 							 Verbose mode
#
# --version-check, -k 				 Check the version of the server to which mysql_upgrade is connecting to verify that it is
# 											 the same as the version for which mysql_upgrade was built.
# 
# 											 This option is enabled by default - to disable it, use --skip-version-check
#
# --write-binlog 						 By default, binary logging by mysql_upgrade is disabled. Invoke the program with 
# 											 --write-binlog if you want its actions to be written to  the binary log.
#
# 											 When the server is running with global transactions identifiers (GTIDs) enabled
# 										    (gtid mode=ON), do not enable binary logging by mysql_upgrade.
#
# The next section covers mysql on the cmd line
#
# If used interactively, query results are presented in an ASCII table format.
# If not, it's in a tab-separated format.
#
# If there is not enough memory, use --quick. Forces usage of one row at a time instead of 
# buffering in memory and retrieving everything. Utilizes mysql_use_result() C api in the client/server lib,
# instead of the mysql_store_result()
#
# Examples of simple usages:
#
# mysql <db_name>
#
# mysql --user=<user_name> --password <db_name> #Causes prompt
#
# Ctrl+C stops current query or partial inputs.
# To finish a query on the cmd line, end with ;, \g or \G and Enter
#
# We can execute SQL statements in a script file (batch file) as follows:
# mysql db_name < script sql > output tab
#
# On Unix, the client logs statements executed interactively to a history file.
#
# The next section covers mysql options for the Cmd line or [client] and [mysql] groups of an option file.
#
# FORMAT 								DESC
# --auto-rehash 						Enable automatic rehashing
# --auto-vertical-output 			Enable automatic vertical result set display
# --batch 								Do not use history file
# --binary-as-hex 					Display binary values in hexadecimal notation
#
# --binary-mode 						Disable \r\n - to - \n translation and treatment of \0 as end-of-query
# --bind-address 						Use specified network interface to connect to the MySQL Server
# --character-sets-dir 				Directory where character sets are installed
# --column-names 						Write column names in results
# --column-type-info 				Display result set metadata
# --comments 							Whether to retain or strip comments in statements sent to the server
#
# --compress 							Compress all information sent between client and server
# --connect-expired-password 		Indicate to server that client can handle expired-password sandbox mode
# --connect_timeout 					Number of seconds before connection timeout
# --database 							The database to use
# --debug 								Write debugging log; supported only if MySQL was built with debugging support
#
# --debug-check 						Print debugging information when program exits
# --debug-info 						Print debugging information, memory and CPU stats when the program exits
# --default-auth 						Authentication plugin to use
# --default-character-set 			Specify default character set
#
# --defaults-extra-file 			Read named option file in addition to usual option files
# --defaults-file 					Read only named option file
# --defaults-group-suffix 			Option group suffix value
# --delimiter 							Set the statement delimiter
# --enable-cleartext-plugin 		Enable cleartext authentication plugin
#
# --execute 							Execute the statement and quit
# --force 								Continue even if an SQL error occurs
# --get-server-public-key 			Request RSA public key from server
# --help 								Display help message and exit
# --histignore 						Patterns specifying which statements to ignore for logging
# --host 								Connect to MySQL server on given host
#
# --html 								Produce HTML output
# --ignore-spaces 					Ignore spaces after function names
# --init-command 						SQL statement to execute after connecting
# --line-numbers 						Write line numbers for errors
# --local-infile 						Enable or disable for LOCAL capability for LOAD DATA INFILE
#
# --login-path 						Read login path options from .mylogin.cnf
# --max_allowed_packet 				Maximum packet length to send to or recieve from the server
# --max_join_size 					The automatic limit for rows in a join when using --safe-updates
# --named-commands 					Enable named mysql commands
# --net_buffer_length 				Buffer size for TCP/IP and socket communication
#
# --no-auto-rehash 					Disable automatic rehashing
# --no-beep 							Do not beep when errors occur
# --no-defaults 						Read no option files
# --one-database 						Ignore statements except those for the default DB named on the cmd line
# --pager 								Use the given command for paging query output
# --password 							Password to use when connecting to server
#
# --pipe 								On Windows, connect to server using named pipe
# --plugin-dir 						Directory where plugins are installed
# --port 								TCP/IP port number for connection
# --print-defaults 					Print default options
# --prompt 								Set the prompt to the specified format
# --protocol 							Connection protocol to use
#
# --quick 								Do not cache each query result
# --raw 									Write column values without escape conversion
# --reconnect 							If the connection to the server is lost, automatically try to reconnect
# --i-am-a-dummy, --safe-updates Allow only UPDATE and DELETE statements that specify key values
#
# --select_limit 						The automatic limit for SELECT statements when using --safe-updates
# --server-public-key-path 		Path name to file containing RSA public key
# --shared-memory-base-name 		The name of shared memory to use for shared-memory connections
# --show-warnings 					Show warnings after each statement if there are any
# --sigint-ignore 					Ignore SIGINT signals (typically the result of typing Ctrl+C)
#
# --silent 								Silent mode
# --skip-auto-rehash 				Disable automatic rehashing
# --skip-column-names 				Do not write column names in results
# --skip-line-numbers 				Skip line numbers for errors
# --skip-named-commands 			Disable named mysql commands
# --skip-pager 						Disable paging
#
# --skip-reconnect 					Disable reconnecting
# --socket 								For connections to localhost, the Unix socket file or Windows named pipe to use
# --ssl-ca 								File that contains list of trusted SSL Cert Auths
# --ssl-capath 						Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 							File that contains X.509 cert
#
# --ssl-cipher 						List of permitted ciphers for connection encryption
# --ssl-crl 							File that contains certificate revocation lists
# --ssl-crlpath 						Directory that contains cert revocation list files
# --ssl-fips-mode 					Whether to enable FIPS mode on the client side
# --ssl-key 							File that contains X.509 key
# --ssl-mode 							Security state of connection to server
#
# --syslog 								Log interactive statements to syslog
# --table 								Display output in tabular format
# --tee 									Append a copy of output to named file
# --tls-version 						Protocols permitted for encrypted connections
# --unbuffered 						Flush the buffer after each query
#
# --user 								MySQL user name to use when connecting to server
# --verbose 							Verbose mode
# --version 							Display version information and exit
# --vertical 							Print query output rows vertically (one line per column value)
# --wait 								If the connection cannot be established, wait and retry instead of aborting
# --xml 									Produce XML output
#

# Further explonation of the interactions:
#
# --help, -? - Display a help message and exit
# --auto-rehash - Enable automatic rehashing. On by default, enables database, table and column name completion.
# 					   Use --disable-auto-rehash to disable rehashing. That causes mysql to start faster, but you must
# 						issue the rehash command or its \# shortcut if you want to use name completion.
#
# 						To cycle through completion of names, write the first part and press Tab to cycle Regex matchings.
# 						Does not trigger unless there is a default DB.
#
# 						The above requires a MySQL client that is compiled with the readline library. Typically, the readline
# 						library is not available on Windows.
#
# --auto-vertical-output - Cause result sets to be displayed vertically if they are too wide for the current window, and using
# 									normal tabular format otherwise. (Applies to statements terminated by ; or \G)
#
# --batch, -B 				 - Print results using tab as the column separator, with each row on a new line. With this option, mysql
# 									does not use the history file.
#
# 									Batch mode results in nontabular output format and escaping of special characters. Escaping may be
# 									disabled by using raw mode; see the description for the --raw option.
#
# --binary-as-hex 			When this option is given, mysql displays binary data using hexadecimal notation (0x value).
# 									This occurs whether the overall output display format is tabular, vertical, HTML or XML.
#
# --binary-mode 				This option helps when processing mysqlbinlog output that may contain BLOB values.
# 									By default, mysql translates \r\n in statement strings to \n and interprets \0 as
# 									the statement terminator.
#
# 									This option disables both features. Also disables all mysql commands except charset and delimiter
# 									in non-interactive mode (for input piped to mysql or loaded using the source command)
#
# --bind-address= 			On a computer having multiple network interfaces, use this option to select which interface to use
#   <ip address> 				for connecting to the MySQL server.
#
# --character-sets-dir= 	The directory where char sets are installed.
#   <dir name>
#
# --column-names 				Write column names in results
#
# --column-type-info 		Display result sets metadata
#
# --comments, -c 				Whether to strip or preserve comments in statements sent to the server. (DEPRECATED)
# 									Defaults to --skip-comments (strip comments), enable with --comments (preserves them)
# 
# 									Note: Commands and queries directed towards the server - are just hints. Server yields final say.
# 														
# --compress, -C 				Compress all information sent between client and the server if both support compression.
#
# --connect-expired- 		Indicate to the server that the client can handle sandbox mode if the account used to connect has an expired PW.
#   password 					Can be useful for noninteractive invocations of mysql because normally the server disconnects noninteractive clients
# 									that attempt to connect using an account with an expired PW.
#
# --database=<db_name>, 	The DB to use. Useful primarily in a option file.
#   -D <db_name>
#
# --debug[=<debug_options>], Write a debugging tool. A typical <debug_options> string is d:t:o, <file_name>. Defaults to d:t:o, /tmp/mysql.trace
#   -# [<debug options>]     Available only if MySQL was built using WITH_DEBUG.
#
# 									  MySQL release binaries are NOT designed for this option.
#
# --debug-check 				Print some debugging information when the program exits.
#
# --debug-info, -T 			Print debugging information and memory and CPU usage stats when the program exits.
#
# --default-auth=<plugin>  A hint about the client-side auth plugin to use
#
# --default-character-set  Use charset_name as the default char set for the client and connection.
# =<charset_name> 			This option can be useful if the OS uses one char set and the mysql client by default
# 									uses another.
#
# 									In this case, output may be formatted incorrectly. You can usually fix such issues by using
# 									this option to force the client to use the system char set instead.
#
# --defaults-extra-file 	Read this option file after the global option file but (On Unix) before user option files.
# =<file name> 				If not found/inaccessible, error raised. Relative if not full path specified, explicit otherwise.
#
# --defaults-file 			Use only the given option file. .mylogin.cnf is still read. If not found/inaccessible, error raised.
# =<file name>
#
# --defaults-group-suffix  Read not only the usual option groups, but also groups with the usual names and a suffix of <str>.
# =<str> 						Regex triggering of suffix sorting, basically.
#
# --delimiter=<str> 			Set the statement delimiter. The default is the semicolon char (;)
#
# --disable-named-commands Disable named commands. Use the \* format only, or use named commands only at the beginning of a line ending with (;)
# 									Starts with this option enabled by default.
#
# 								   Even with this option, long-format commands still work from the first line.
#
#--enable-cleartext-plugin Enables the mysql_clear_password cleartext authentication plugin.
#
# --execute=<statement>, 	Execute the statement and quit. The default output format is like that produced with --batch.
#  -e <statement>
# 									If this option is done, the history file is not used by MySQL.
#
# --force, -f 					Continue even if an error is raised
#
# --get-server-public-key  Request from the server the public key required for RSA key pair-based PW exchange.
# 									This option applies to clients that authenticate with the caching_sha2_password authentication plugin.
#
# 									For that plugin, the server does not send the public key unless requested. This option is
# 									ignored for accounts that do not authenticate with that plugin. 
#
# 									It is also ignored if RSA-based PW exchange is not used, as is the case when the client connects
# 									to the server using a secure connection.
#
# 									If --server-public-key-path=<file name> is given and specifies a valid public key file,
# 									it takes precedence over --get-server-public-key
#
# --histignore 				Colon-seperated list of one or more patterns specifying statements to ignore for logging purposes.
# 									The patterns are added to the default pattern list ("*IDENTIFIED*:*PASSWORD*")
#
# 									The value specified for this option affects logging of statements written to the history file, and
# 									to syslog if the --syslog option is given.
#
# --host=<host name>, 		Connect to the MySQL server on the given host.
# -h <host name>
#
# --html, -H 					Produce HTML Output
#
# --ignore-spaces, -i 		Ignore spaces after function names. The effect of this is described in the discussion
# 									for the IGNORE_SPACE SQL mode
#
# --init-command=<str> 		SQL statements to execute after connecting to the server. If auto-reconnect is enabled, the statement
# 									is executed again after reconnection occurs.
#
# --line-numbers 				Write line numbers for errors. Disable this with --skip-line-numbers.
#
# --local-infile[={0|1}] 	Enable or disable LOCAL capability for LOAD DATA INFILE. For mysql, this capability is disabled by default.
# 									With no value, the option enables LOCAL. This option may be given as --local-infile=0 or --local-infile=1 
# 									to explicitly disable or enable LOCAL.
#
# 									Enabling local data loading also requires that the server permits it.
#
# --login-path=<name> 		Read options from the named login path in the .mylogin.cnf login path file.
# 									A "login path" is an option group containing options that specify which MySQL server
# 									to connect to and which account to authenticate as.
#
# 									To create or modify a login path file, use the mysql_config_editor.
#
# --named-commands, -G 		Enables named mysql commands. Long-format commands are permitted, not just short-format commands.
# 									For example, quit and \q both are recognized. Use --skip-named-commands to disable named commands.
#
# --no-auto-rehash, -A 		This has the same effect as --skip-auto-rehash.
#
# --no-beep, -b 				No beep @ errors
#
# --no-defaults 				Do not read any option files. Prevents error causing files. 
# 									.mylogin.cnf is read regardless.
#
# --one-database, -o 		Ignore statements except those that occur while the default DB is the one named on the CMD line.
# 									This option is rudimentary and should be used with care.
#
# 									Statement filtering is based only on USE statements.
#
# 									Initially, mysql executes statements in the input because specifying a DB <db_name>
# 									on the CMD line is the equivalent to inserting USE <db name> at the beginning of the input.
#
# 									Then, for each USE statement encountered, mysql accepts or rejects following statements depending on
# 									whether the database named is the one on the CMD line.
#
# 									The content of hte statement is irrelevant.
#
# 									Assuming the following Query:
# 									DELETE FROM db2.t2; USE db2; DROP TABLE db1.t1; CREATE TABLE db1.t1 (i INT); USE db1;
# 									INSERT INTO t1 (i) VALUES(1); CREATE TABLE db2.t1 (j INT);
#
# 									If the command to process it, is: 
# 									mysql --force --one-database db1, mysql
#
# 									The DELETE statement is executed because the default database is db1, even though the statement
# 									names a table in a different database.
#
# 									The DROP TABLE and CREATE TABLE statements are not executed because the default database is not db1,
# 									even though the statements named a table in db1
#
# 									The INSERT and CREATE TABLE statements are executed because the default database is db1, even though
# 									the CREATE TABLE statement names a table in a different database.
#
# --pager[=<command>] 		Use the given command for paging query output. If the command is omitted, the default pager is the value of
# 									your PAGER environment variable.
#
# 									Valid pagers are less, more, car [> filename>], and so forth. This option works only on Unix and only
# 									in interactive mode. To disable it - use --skip-pager.
#
# --password=[=<password>] The password to use when connecting to the server. If you use the short option form (-p), you cannot
#   ,-p[<password>]        have a space between the option and the PW.
#
# 									If you omit the PW value following the --password or -p option on the command line, mysql prompts for one.
#
# --pipe, -W 					On Windows, connect to the server using a named pipe. This option applies only if the server supports named-pipe
# 									connections.
#
# --plugin-dir=<dir name> 	The dir in which to look for plugins. Specify this option if the --default-auth option is used to specify an authentication
# 									plugin but mysql does not find it.
#
# --port=<port num>, 		The TCP/IP port number to use for the connection. 
#  -P <port_num>
#
# --print-defaults 			Print the program name and all options that it gets from option files.
#
# --prompt=<format str> 	Set the prompt to the specified format. The default is mysql>. The special sequences
# 									that the prompt can contain are described later.
#
# --protocol={TCP|SOCKET 	The connection protocol to use for connecting to the server. It is useful when the other connection
#   |PIPE|MEMORY} 			parameters normally would cause a protocol to be used other than the one you want.
#
# --quick, -q 					Do not cache each query result, print each row as it is received. This may slow down the server if the output is suspended.
# 									With this option, mysql does not use the history file.
#
# --raw, -r 					For tabular output, the "boxing" around columns enables one column value to be distinguished from another.
# 									For nontabular output (such as is produced in batch mode or when the --batch or --silent option is given),
# 									special chars are escaped in the output so they can be identified easily.
#
# 									Newline, tab, NUL, and backslash are written as \n, \t, \0, and \\. The --raw disables the char escaping.
#
# Showcasing of differences:
# mysql> SELECT CHAR(92); #Select ORD numeral 92 char, which is \
# +-------------------+
# | 		CHAR(92) 	 | 
# +-------------------+
# | 			\ 			 |
# +-------------------+
#
# mysql -s #Silent mode
# mysql> SELECT CHAR(92); #Select ORD numeral 92, silent, escape enabled
# CHAR(92)
# \\
#
# mysql -s -r #Silent raw mode
# mysql> SELECT CHAR(92);
# CHAR(92)
# \
#
# --reconnect
# If the connection to the server is lost, automatically try to reconnect. A single reconnect attempt 
# is made each time the connection is lost.
#
# To surpress the reconnection behavior, use --skip-reconnect.
#
# --safe-updates, --i-am-a-dummy, -U
# Permit only those UPDATE and DELETE statements that specify which rows to modify by using key values.
# If you have set this option in an option file, you can override it by using --safe-updates on
# on the cmd line.
#
# --secure-auth
# This option was removed in MySQL 8.0.3
#
# --server-public-key-path=<file name>
# The path name to a file containing a client-side copy of the public key required by the server for RSA key pair-based password exchange.
# The file must be in PEM format.
# This option applies to clients that authenticate with the sha256_password or caching_sha2_password authentication plugin.
# 
# This option is ignored for accounts that do not authenticate with one of those plugins. It is also ignored for instances of
# RSA-based PW exchange not being used.
#
# If --server-public-key-path=<file name> is defined and is valid, it takes precedence over --get-server-public-key
# It is only available if MySQL was built using OpenSSL.
#
# --shared-memory-base-name=<name>
# On Windows, the shared-memory name to use, for connections made using shared memory to a local server.
# The default is MySQL. Case-sensitive.
# 
# Must start with --shared-memory to enable shared-memory connections.
#
# --show-warnings
# Causes warnings to be shown after each statement if there are any. This option applies to interactive and batch mode.
#
# --sigint-ignore
# Ignore SIGINT signals (typically the result of using CTRL+C)
#
# --silent, -s
# Silent mode. Produces less output. 
# This option can be given multiple times to produce less and less output.
# Results in nontabular output format and escaping of special characters. 
# Escaping may be disabled by using
# raw mode. (--raw)
# 
# --skip-column-names, -N
# Do not write column names in results
#
# --skip-line-numbers, -L
# Do not write line numbers for errors. Useful when you want to compare result files that include error messages.
#
# --socket=<path>, -S <path> 
# For connections to localhost, the Unix socket file to use - or on Windows, the name of the named pipe to use.
#
# --ssl*
# Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find
# SSL keys and certs.
#
# --ssl-fips-mode={OFF|ON|STRICT}
# Controls whether to enable FIPS mode on the client side.
# The --ssl-fips-mode option differs from other --ssl-xxx options in that it is not used to
# establish encrypted connections, but rather to affect which cryptographic ops are permitted.
#
# These --ssl-fips-mode values are permitted:
# 		OFF - disables fips mode
# 		ON  - enables fips mode
#     STRICT - Enable "strict" FIPS mode.
#
# If the OpenSSL FIPS Object Module is not available, the only permitted value for --ssl-fips-mode is OFF.
# In this case, setting --ssl-fips-mode to ON or STRICT - produces a warning, and defaults to OFF.
#
# --syslog, -j
# Causes mysql to send interactive statements to the system logging facility.
# On Unix, this is syslog; on Windows, it is the Windows Event Log.
#
# The destination where logged messages appear is system dependent. 
#
# On Linux, the destination is often the /var/log/messages file.
#
# a sample of output generated on Linux by using --syslog.
# Each line is usually one line:
#
# Mar 	7 12:39:25 myhost MysqlClient[20824]:
# 		SYSTEM_USER:'oscar', MYSQL_USER:'my_oscar', CONNECTION_ID:23,
# 		DB_SERVER:'127.0.0.1', DB:'--', QUERY:'USE test;'
# Mar 	7 12:39:28 myhost MysqlClient[20824]:
# 		SYSTEM_USER:'oscar', MYSQL_USER:'my_oscar', CONNECTION_ID:23,
# 		DB_SERVER:'127.0.0.1', DB:'test', QUERY:'SHOW TABLES;'
#
# --table, -t
# Display output in table format. This is the default for interactive use, but can be used to produce
# table output in batch mode.
#
# --tee=<file name>
# Append a copy of output to the given file. This option works only in interactive mode.
#
# --tls-version=<protocol list>
# The protocols permitted by the client for encrypted connections. 
# The value is a comma-separated list containing one or more protocol names.
# The protocols that can be named for this option depend on the SSL lib used to compile MySQL.
# 
# --unbuffered, -n
# Flush the buffer after each query.
#
# --user=<user name>, -u <user_name>
# The MySQL user name to use when connecting to the server.
#
# --verbose, -v
# Verbose mode. Can be given multiple times.
#
# --version, -V
# Version info and exit
#
# --vertical, -E
# Print query output rows vertically (one line per column value).
# Without this option, you can specify vertical output for individual statements
# by terminating them with \G.
#
# --wait, -w
# If the connection cannot be established, wait and retry insteaed of aborting.
#
# --xml, -X
# Produce XML output
# <field name="column_name">NULL</field>
#
# The output when --xml is used with mysql matches that of mysqldump --xml.
#
# An example of output is as follows:
#
# mysql --xml -uroot -e "SHOW VARIABLES LIKE 'version%'"
# <?xml version="1.0"?>
# 
# <resultset statement="SHOW VARIABLES LIKE 'version%'" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
# <row>
# <field name="Variable_name">version</field>
# <field name="Value">5.0.40-debug</field>
# </row>
#
# <row>
# <field name="Variable_name">version_comment</field>
# <field name="Value">Source distribution</field>
# </row>
#
# <row>
# <field name="Variable_name">version_compile_machine</field>
# <field name="Value">i686</field>
# </row>
#
# <row>
# <field name="Variable_name">version_compile_os</field>
# <field name="Value">suse-linux-gnu</field>
# </row>
# </resultset>
#
# We can also set the following variables by using --<var_name>=<value>
# 
# connect_timeout - Number of seconds before connection timeout (Defaults to 0)
# max_allowed_packet - Maximum size of the buffer for client/server communication. defaults to 16MB, max is 1GB.
# max_join_size - Automatic limit for rows in a join when using --safe-update. Defaults 1 million
# net_buffer_length - The buffer size for TCP/IP and socket communication (default is 16KB)
# select_limit - Automatic limit for SELECT statements when using --safe-updates. (default is 1000)

#The following section covers mysql commands:
#
# Showcasing of the results of writing help on the cmd line
#
# mysql> help
#
# List of all MySQL commands:
# Note that all text commands must be first on line and end with ';'
# ? 			(\?) 	Synonym for 'help'.
# clear 		(\c)  Clear the current input statement.
# connect  	(\r) 	Reconnect to the server. Optional arguments are db and host.
# delimiter (\d) 	Set statement delimiter
# edit 		(\e) 	Edit command with $EDITOR.
# ego 		(\G) 	Send command to mysql server, display result vertically
#
# exit 		(\q) 	Exit mysql. same as quit.
# go 			(\g) 	Send command to mysql server
# help 		(\h) 	Display this help
# nopager 	(\n) 	Disable pager, print to stdout
# notee 		(\t) 	Do not write into outfile
#
# pager 		(\P) 	Set PAGER [to_pager]. Print the query results via PAGER
# print 		(\p) 	Print current command
# prompt 	(\R) 	Change your mysql prompt
# quit 		(\q) 	Quit mysql
# 
# rehash 	(\#) 	Rebuild completion hash
# source 	(\.) 	Execute an SQL script file. Takes a file name as an argument.
# status 	(\s) 	Get status information from the server.
# system 	(\!) 	Execute a system shell command
#
# tee 		(\T) 	Set outfile [to_outfile]. Append everything into given outfile.
# use 		(\u) 	Use another database. Takes database name as argument
# charset 	(\C) 	Switch to another charset. Might be needed for processing binlog with multi-byte charsets.
#
# warnings 	(\W) 	Show warnings after every statement
# nowarning (\w) 	Don't show warnings after every statement.
# resetconnection(\x) 	show warnings after every statement
#
# If MySQL is invoked with the --binary-mode option, all mysql commands are disabled except charset and delimiter
# in non-interactive mode (for input piped to mysql or loaded using the source command)
#
# Each command has both a long and short form. Long is not case-sensitive. Short is.
#
# Long can be followed by an optional semicolon terminator, but short should not.
#
# We are not allowed to use multiple line comments with /* ... */
#
# the following showcases the different commands in terms of long format and short format
#
# help [arg], \h [arg], \? [arg], ? [arg]
# 
# Displays a help message listing the available mysql commands.
# The arg input to help, acts as regex match in server-side help commands.
#
# charset <charset_name>, \C <charset_name>
#
# Changes the default character set and issues a SET_NAMES statement. This enables the character set to remain
# synchronized on the client and server if mysql is run with auto-reconnect enabled (not recommended),
# as the specified char set is used for reconnects.
# 
# clear, \c
# Clear the current input. Use this if you change your mind about executing the statement that you are entering.
#
# connect [<db_name> <host_name>]], \r [<db name> <host name>]]
#
# Reconnect to the server. The optional database name and host name arguments may be given to specify the default
# DB or the host where the server is running.
#
# If omitted, the current values are used.
#
# delimiter <str>, \d <str>
# 
# Change the string that mysql interprets as the separator between SQL statements. The default is the semicolon char (;)
#
# The delimiter string can be specified as an unquoted or quoted argument on the delimiter command line. Quoting can be done
# with either single quote ('), double quote (") or backtick (`) chars.
#
# To include a quote within a quoted string, either quote the string with a different quote character or
# escape the quote with a (\) char.
#
# Backslash should be avoided outside of quoted strings because it is the escape character for MySQL.
# For an unquoted argument, the delimiter is read up to the first space or end of line.
#
# For a quoted argument, the delimiter is read up to the matching quote on the line.
#
# mysql interprets instances of the delimiter string as a statement delimiter anywhere it occurs, except within
# quoted strings.
#
# Be careful about defining a delimiter that might occur within other words. For example, if you define
# the delimiter as X, you will be unable to use the word <INDEX> in statements.
#
# Mysql interprets this as <INDE> followed by the delimiter X.
#
# When the delimiter recognized by mysql is set to something other than the default of ;,
# instances of that character are sent to the server without interpretation.
#
# However, the server itself still interprets ; as a statement delimiter and process statements
# accordingly. This behavior on the server side comes into play for multiple-statement execution,
# for parsing the body of stored procedures and functions, triggers and events.
#
# edit, \e
# Edit the current input statement. mysql checks the values of the EDITOR and VISUAL env variables
# to determine which editor to use.
#
# The default editor is vi if neither variable is set.
#
# The edit command works only in Unix.
#
# ego, \G
# Send the current statement to the server to be executed and display the result using vertical format.
#
# exit, \q
# Exit mysql
#
# go, \g
# Send the current statement to the server to be executed.
#
# nopager, \n
# Disable output paging. See the description for pager.
#
# The nopager command works only in Unix.
#
# notee, \t
# Disable output copying to the tee file. See the description for tee.
#
# nowarning, \w
# Disable display of warnings after each statement.
#
# pager [<command>], \P [<command>]
# Enable output paging. By using the --pager option when you invoke mysql, it is possible to browse or search query
# results in interactive mode with Unix programs such as less, more, or any other similar program.
#
# If you specify no value for the option, mysql checks the value of the PAGER environment variable and sets the
# pager to that. Pager functionality works only in interactive mode.
#
# Output paging can be enabled interactively with the pager command and disabled with nopager.
# The command takes an optional argument; if given, the paging program is set to that.
#
# With no arg, the pager is set to the pager that was set on the command line, or stdout if no pager was specified.
#
# Output paging works only in Unix because it uses the popen() function, which does not exist on Windows.
# For Windows, the tee option can be used instead to save query output, although it is not as convenient
# as pager for browsing output in some situations.
#
# print, \p
# Print the current input statement without executing it
#
# prompt [<str>], \R [<str>]
# Reconfigure the mysql prompt to the given string. The special character sequences that can be used in the
# prompt are described later in this section.
#
# If you specify the prompt command with no argument, mysql resets the prompt to the default of mysql>.
#
# quit, \q
# Exit mysql.
#
# rehash, \#
# Rebuild the completion hash that enables database, table and column name completion while you are entering statements.
# (See the description for the --auto-rehash option)
#
# resetconnection, \x
# Reset the connection to clear the session state.
#
# Resetting a connection has effects similar to mysql_change_user() or an auto-reconnect except that
# the connection is not closed and reopened, and re-authentication is not done.
#
# Showcasing of example:
#
# SELECT LAST_INSERT_ID(3); #gives 3
# SELECT LAST_INSERT_ID(); #gives 3, still set to this
# resetconnection; #Resets defaults
# SELECT LAST_INSERT_ID(); #Gives 0, reset has been done

# source <file_name>, \. <file_name>
# Read the named file and execute the statements contained therein. On Windows, you can specify
# path name separators as / or \\.
#
# Quote characters are taken as part of the file name itself. For best results, the name should not
# include space characters.
#
# status, \s
# Provide status information about the connection and the server you are using.
# If you are running in --safe-updates mode, status also prints the values for the
# mysql variables that affect your queries.
#
# system <command>, \! <command>
# Execute the given command using your default cmd interpreter.
# Works only on Unix.
#
# tee [<file_name>], \T [<file_name>]
# By using the --tee option when you invoke mysql, you can log statements and their output.
# All the data displayed on the screen is appended into a given file.
#
# This can be very useful for debugging purposes also. mysql flushes results to the file
# after each statement, just before it prints its next prompt.
#
# Tee functionality works only in interactive mode.
#
# You can enable this feature interactively with the tee command. Without a parameter,
# the previous file is used. The tee file can be disabled with the notee command.
#
# Executing tee again re-enables logging.
#
# use <db_name>, \u <db_name>
# Use <db_name> as the default DB.
#
# warnings, \W
# Enable display of warnings after each statement (if there are any)
#
# Tips about the pager command:
# 
# Example of writing only to a file:
# pager cat > /tmp/log.txt
#
# We can also pass options with the pager
# pager less -n -i -S
#
# Example of piping to different files mounted on two different systems, still displaying to screen using less:
# pager cat | tee /dr1/tmp/res.txt \
# 			| tee /dr2/tmp/res2.txt | less -n -i -S
#
# We can also combine the tee and pager functions. Have a tee file enabled and pager set to less, and you are
# able to browse the results using the less program and still have everything appended into a file the same time.
#
# The difference between the Unix tee used with the pager command and the mysql built-in tee command is that the
# built-in tee works even if you do not have the Unix tee available.
#
# The built-in tee logs everything that is printed on the screen, where as the Unix tee used with pager
# does not log equal amounts.
#
# Additionally, tee file logging can be turned on and off interactively from within mysql. This is useful
# when you want to log some queries to a file, but not others.
#
# The prompt command reconfigures the default mysql> prompt. The string for defining the prompt can
# contain the following special sequences:
#
# Option 					Desc
# \C 				The current connection identifier
# \c 				A counter that increments for each statement you issue
# \D 				The full current date
# \d 				The default database
# \h 				The server host
#
# \l 				The current delimiter
# \m 				Minutes of the current time
# \n 				A newline char
# \O 				The current month in three letter format (Jan, Feb, etc.)
# 
# \o 				The current month in numeric format
# \P 				am/pm
# \p 				The current TCP/IP port or socket file
# \R 				The current time, in 24-hour military time(0-23)
#
# \r 				The current time, standard 12-hour time (1-12)
# \S 				Semicolon
# \s 				Seconds of the current time
# \t 				A tab char
#
# \U 				Your full user_name@host_name acc name
# \u 				Your user name
# \v 				The server version
# \w 				The current dat of the week in three letter format (Mon, Tue, etc.)
#
# \Y 				The current year, four digits
# \y 				The current year, two digits
# \_ 				A space
# \ 				A space (space after the \)
# \' 				Single quote
# \" 				Double quote
# \\ 				A literal backslash char
#
# \x 				x, for any "x" not listed above

# There is a number of ways we can change the prompt:
#
# An environment variable: 
# export MYSQL_PS1="(\u@\h) [\d]> "
#
# A cmd line option. Can set the prompt with --prompt on the cmd line:
# mysql --prompt="(\u@\h) [\d]> "
# (user@host) [database]>
#
# Using an option file. Prompt option in the [mysql] group, such as /etc/my.cnf or the .my.cnf in the home dir:
# [mysql]
# prompt(\\u@\\h) [\\d]>\\_
#
# \\ is used in the option file for explicit escaping.
#
# We can also set it interactively, by using prompt or \R

# prompt (\u@\h) [\d]>\_
# PROMPT set to '(\u@\h) [\d]>\_'
# (user@host) [database]>
# (user@host) [database]> prompt
# Returning to default PROMPT of mysql>
# mysql>
#
#The next part covers Mysql logging
#
# The mysql client can do these types of logging for statements executed interactively:
#
# Unix -> mysql writes the statements to a history file. By default, the file is named .mysql_history in your home dir.
# To specify a different file, set the value of the MYSQL_HISTFILE env variable.
#
# On all platforms, if the --syslog option is given, mysql writes the statements to the system logging facility.
# Unix -> syslog
# Windows -> Windows Event Log
#
# the destination where logged messages appear is system dependent. On Linux, the destination is often
# the /var/log/messages file.
#
# How Logging Occurs:
#
# For each enabled logging destination - statement logging occurs as is shown:
# 
# Statements are logged only when executed interactively. Statements are noninteractive, for example, when read
# from a file or a pipe. It is also possible to suppress statement logging by using the --batch or --execute option.
#
# Statements are ignored and not logged if they match any pattern in the "ignore" list. Shown later.
#
# mysql logs each nonignored, nonempty statement line individually.
#
# If a nonignored statement spans multiple lines (not including the terminating delimiter), mysql concatenates
# the lines to form the complete statement, maps newlines to spaces and then logs the result + a delimiter.
#
# For instance:
# SELECT
# 	'Today is'
#  ,
#  CURDATE()
#  ;
#Gives:
# SELECT 'Today is' , CURDATE();

# mysql ignores for logging purposes statements that match any pattern in the "ignore" list.
# By default, the pattern list is "*IDENTIFIED*:*PASSWORD*", to ignore statements that identify as PWs.

# Two chars are significant in terms of the regex pattern: ? (Single wildcard char), * any sequence of zero or more chars.
#
# To specify additional patterns, use the --histignore option or set the MYSQL_HISTIGNORE env variable.
# Option value takes precedence.
#
# The value should be a colon separated list, which are appended to the default list.
# An example of a pattern delimiter defined on the cmd line, to ignore UPDATE and DELETE:
#
# mysql --histignore="*UPDATE*:*DELETE*"
#
# If we do not wish to maintain a hist file, cause it can contain PW info, we can remove it and do one of hte following:
#
# Set the MYSQL_HISTFILE env var to /dev/null - put in one of the shell startup files, causing deployment of options at the startup.
# 
# Create .mysql_history as a symbolic link to /dev/null; - only needs to be done once:
#
# ln -s /dev/null $HOME/.mysql_history
#
# syslog Logging Characeristics
#
# If the --syslog option is given, mysql writes interactive statements to the system logging facility.
# Message logging has the following characteristics:
#
# Logging occurs at the "informational" level. 
# This corresponds to the LOG_INFO priority for syslog on Unix/Linux syslog capability and to 
# EVENTLOG_INFORMATION_TYPE for the Windows Event Log.
#
# Message size limit is 1024 bytes.
#
# Messages consists of the identifier MysqlClient followed by these values:
#
# SYSTEM_USER - The system user name (login name) or -- if the user is unknown.
# 
# MYSQL_USER  - The MySQL user name (specified with the --user option) or -- if the user is unknown.
#
# CONNECTION_ID - The client connection identifier. This is the same as the CONNECTION_ID() function value within the session.
#
# DB_SERVER - The server host or -- if the host is unknown
# 
# DB - The default database or -- if no DB has been selected.
#
# QUERY - The text of the logged statement.
#
# Example of output generated on Linux by using --syslog. Formatted for readability, each logged message takes a single line:
#
# Mar 	7 12:39:25 myhost 	MysqlClient[20824]:
# 		SYSTEM_USER:'oscar', MYSQL_USER:'my_oscar', CONNECTION_ID:23,
# 		DB_SERVER:'127.0.0.1', DB:'--', QUERY:'USE test;'
# Mar 	7 12:39:28 myhost 	MysqlClient[20824]:
# 		SYSTEM_USER:'oscar', MYSQL_USER:'my_oscar', CONNECTION_ID:23,
# 		DB_SERVER:'127.0.0.1', DB:'test', QUERY:'SHOW TABLES;'

# The following section covers the mysql Server-Side Help
#
# mysql> help <search_string>
#
# For this operation to work, the help tables in the mysql database must be initialized with the help topic information.
#
# If no value is found, an error is thrown.
#
# To see a list of categories:
# 
# mysql> help contents
# You asked for help about help category: "Contents"
# For more info, type 'help <item>', where <item> is one of the following categories:
#
# Account management
# Administration
# Data Definition
# Data Manipulation
# Data Types
# Functions
# Functions and Modifiers for Use with GROUP BY
# Geographic Features
# Language Structure
# 
# Plugins
# Storage Engines
# Stored Routines
# Table Maintenance
# Transactions
# Triggers
#
# If multiple tags coincide, a list of the topics are shown:
#
# help logs
# Many help items for your request exist
# To make a more specific request, please type 'help <item>'
# where <item> is one of the following topics:
# 		SHOW
# 		SHOW BINARY LOGS
# 		SHOW ENGINE
# 		SHOW LOGS
#
# Use a topic as the search string to see the help entry for that topic:
#
# mysql> help show binary logs
# Name: 'SHOW BINARY LOGS'
# Description:
# Syntax:
# SHOW BINARY LOGS
# SHOW MASTER LOGS
#
# Lists the binary log files on the server. This statement is used as
# part of the procedure described in [purge-binary-logs] - which shows how to determine which logs can be purged.
#
# mysql> SHOW BINARY LOGS;
# +------------------------------+
# | Log_name 	    |   File_size |
# +------------------------------+
# | binlog.000015  |    724935   |
# | binlog.000016  | 	733481 	|
# +------------------------------+

# The search string can contain the wildcard char % and _. These have the same meaning as for pattern-matching,
# such as % as any sequencing following but yields designated part in respective parting before that
#
# EXAMPLE% Finds anything that begins with EXAMPLE
# %EXAMPLE Finds anything that ends with EXAMPLE
#
# mysql> HELP rep%
# Many help items for your request exist
# To make a more specific request, please type 'help <item>'
# where <item> is one of the following topics:
#
# REPAIR TABLE
# REPEAT FUNCTION
# REPEAT LOOP
# REPLACE
# REPLACE FUNCTION
#
# The following showcases of how to execute SQL statements from a Text File
#
# Typically the mysql client is interactively done as:
#
# shell> mysql <db_name>
#
# However - we can run a script from a file, unto a DB - as follows:
#
# shell> mysql <db_name> < <text_file>
#
# If we include a USE <db_name> statement as the first statement in the file, no DB name must be done on the cmd line.
#
# If mysql is already running - we can execute a SQL script file using the source command or \. command:
#
# mysql> source <file_name>
# mysql> \ <file_name>

# mysql ignores Unicode byte order mark (BOM) chars at the beginning of input files.

#MYSQL tips section next

# Input-Line Editing
#
# mysql supports input-line editing, which enables you to modify the current input line in place or recall previous input lines.
# For example, up/down arrows moves between previous entered lines.
#
# To change the set of key sequences permitted by a given input library, define key bindings in the library startup file.
# .editrc for libedit and .inputrc for readline
#
# in Libedit:
# CTRl+W - deletes everything before current cursor pos.
# CTRL+U - the entire line.
#
# in readline:
# Ctrl+W - deletes the word before the cursor
# CTRl+U - deletes everything before the current cursor pos.

# Unicode on Windows:
# provided through UTF-16LE APIs reading from and to the console.
# The mysql client for Windows is able to use these APIs.
# 
# The Windows installer creates an item in the MySQL menu named MySQL command line client - Unicode.
# This item invokes the mysql client with properties set to communicate through the console to
# the MySQL server using Unicode.
#
# Open the console window
# Go to console window properties - select font tab - choose Lucidia Console or some other compatible UNICODE font.
#
# This is called for, due to console windows start by default using a DOS raster font that is uncalled for Unicode.
#
# Execute mysql with --default-character-set=utf8 (or utf8mb4) option.
# It is nessecary because utf16le cannot be used as client char set, amongst others.
#
# With said changes, Windows will use the Windows API to communicate with the console using UTF-16LE,
# and communicate with the server using UTF-8.
#
# To avoid said steps each time we run mysql, we can create a shortcut that invokes mysql.exe
# The shortcut should set the console font to Lucida Console or some other compatible
# Unicode font, and pass the --default-character-set=utf8 to mysql.
#
# Alternatively, we have a shortcut for the console font - with the char set in the [mysql] group in a my.ini file:
# [mysql]
# default-character-set=utf8
#
# The following covers Displaying Query Results Vertically
# 
# Just end the query with \G instead of ;
# mysql> SELECT * FROM mails WHERE LENGTH(txt) < 300 LIMIT 300,1\G
# 
# ******************************* 1. row ****************************
# 
#   msg_nro: 3068
# 		 date: 2000-03-01 23:29:50
# time_zone: +0200
# mail_from: Monty
#     reply: monty@no.spam.com
#   mail_to: "Thimble Smith" <tim@no.spam.com>
# 	 	  sbj: UTF-8
# 		  txt: >>>>> "Thimble" == Thimble Smith Writes:
#
# Thimble> Hi, i think this is a good idea. Is anyone familiar 
# Thimble> with UTF-8 or Unicode? Otherwise, i'll put this on my
# Thimble> TODO list and see what happens.
#
# Yes, please do that
# 
# Regards,
# Monty
# 		 file: inbox-jani-1
# 		 hash: 190402944

# Using the --safe-updates Option
# 
# For beginners, a useful startup option is --safe-updates (or --i-am-a-dummy, which has the same effect).
# It is helpful for cases when you might have issued a DELETE FROM <tbl_name> statement, but if we forgot the Where part.
#
# By --safe-updates, we enforce key referal to commit to delete updates.
#
# The query sent upon startup is the following:
# 
# SET sql_safe_updates=1, sql_select_limit=1000, max_join_size=1mil
#
# The SET statement has the following effects:
#
# You are not permitted to execute an UPDATE or DELETE statement unless you specify a key constraint in the
# WHERE clause or provide a LIMIT clause (or both)
#
# Example:
#
# UPDATE <tbl_name> SET <not_key_column>=<val> WHERE <key_column>=<val>;
#
# UPDATE <tbl_name> SET <not_key_column>=<val> LIMIT 1;
#
# The server limits all large SELECT results to 1,000 rows unless the statement includes a LIMIT clause.
# 
# The server aborts multiple-table SELECT statements that probably need to examine more than 1 mil row combos.
#
# We can override the defaults by using --select_limit and --max_join_size options:
#
# mysql --safe-updates --select_limit=500 --max_join_size=10000
#
# Disabling mysql Auto-Reconnect
#
# If the mysql client loses its connection to the server while sending a statement, it immediately and automatically
# tries to reconnect once to the server and send the statement again.
#
# However, even if mysql succeeds in reconnecting, your first connection has ended and all your previous session objects/settings
# are lost.
#
# Temporary tables, the autocommit mode, user-defined vars and session vars.
#
# Any current transactions roll back. 
#
# An example of loss of designation:
#
# mysql> SET @a=1;
# mysql> INSERT INTO t VALUES(@a); #Gets error
#
# mysql> SELECT * FROM t; #a is now Null

#To terminate with an error, start mysql with --skip-reconnect

# The next section covers mysqladmin - Client to administer a MySQL server
#
# Invoked:
#
# mysqladmin [<options>] <command> [<command-arg>] [<command> [<command-arg>]] ...
#
# mysqladmin supports the following commands. Some of the commands take an argument following the cmd name:
#
# create <db_name> - creates a DB with <db_name>
# debug - Tell the server to write debug information to the error log. Connnected user must have SUPER privs.
# drop <db_name> - Delete the DB named <db_name> and all of its tables.
# extended-status - Display the server status vars and their values.
# flush-hosts - Flush all information in the host cache
#
# flush-logs [<log_type> ...] - Flush all logs. The mysqladmin flush-logs cmd permits optional log types to be given,
# to specify which logs to flush.
#
# Following the flush-logs command, you can provide a space-separated list of one or more of the following log types:
# binary, engine, error, general, relay, slow
#
# These correspond to the log types that can be specified for the <FLUSH LOGS> SQL statement.
#
# flush-privileges - Reload the grant tables (same as reload)
#
# flush-status - Clear status vars
#
# flush-tables - Flush all tables
#
# flush-threads - Flush the thread cache
#
# kill id, id, ... - Kill server threads. If multiple thread ID values are given, there must be no spaces in the list.
# 							To kill threads belonging to other users, the connected user must have the CONNECTION_ADMIN or SUPER privs.
#
# password <new_pw> - Sets a new PW. This changes the PW to <new_pw> for the account that you use with mysqladmin for connecting to the server.
# 							 Thus, the next time you invoke mysqladmin (or any other client program) using the same account, you need to specify the new PW.
#
# NOTE: Setting a pw using mysqladmin should be considered <insecure>. On some systems, your PW becomes visibile to system status programs such as 
# ps that may be invoked by other users to display cmd lines. MySQL clients typically overwrite the cmd-line pw argument with 0's during init seq.
#
# There is still a brief interval during which the value is visible. Also, on some systems this overwriting strategy is ineffective and the PW
# remains visible to ps.
#
# If the <new_pw> contains spaces or other chars that are special to your cmd line, you need to enclose it with ""
# On windows, be sure to use "" rather than '', '' are not stripped from the PW.
#
# Simply use config files for PWs.
#
# ping - Check whether the server is available. The return status from mysqladmin is 0 if the server is running, 1 if it is not.
# Even errors produce 0 - as it does not denote that the server is offline.
#
# processlist - Show a list of active server threads. This is the same as SHOW PROCESSLIST. If Verbose is given, the output is like that
# of SHOW FULL PROCESSLIST.

# reload - Reload the grant tables.
#
# refresh - Flush all tables and close and open log files.
#
# shutdown - Stop the server
#
# start-slave - Start replication on a slave server
#
# status - Display a short server status message
#
# stop-slave - Stop replication on a slave server
#
# variables - Display the server system vars and their values
#
# version - Display version info from the server
#
# All commands can be shortened to any unique prefix:
#
# mysqladmin proc stat #Prints ID, user, host, db, command, Time, State, Info
# #Also prints stats
#
# The mysqladmin status command result displays the following values:
# 
# Uptime - Number of seconds the MySQL server has been running
# Threads - Number of active threads (clients)
# Questions - The number of questions (queries) from clients since the server was started.
# Slow queries - Number of queries that have taken more than long query time seconds.
#
# Opens - The number of tables the server has opened
# Flush tables - The number of flush-*, refresh and reload commands the server has executed
# Open tables - Number of tables that currently are open

# If you execute mysqladmin shutdown when connecting to a local server using a Unix socket file, mysqladmin waits until
# the server's process ID file has been removed, to ensure that the server has stopped properly.
#
# The following options are supported in terms of mysqladmin - of which can be specified on the cmd line or in the [mysqladmin] and [client] groups of a option file.
#
# mysqladmin Options
#
# Format 									Desc
# --bind-address 							Use specified network interface to connect to MySQL Server
# --compress 								Compress all information sent between client and server
# --connect_timeout 						Number of seconds before connection timeout
# --count 									Number of iterations to make for repeated command execution
#
# --debug 									Write debugging log
# --debug-check 							Print debugging information when program exits
# --debug-info 							Print debugging information, memory and CPU stats when the program exits.
#
# --default-auth 							Authentication plugin to use.
# --default-character-set 				Specify default character set
# --defaults-extra-file 				Read named option file in addition to usual option files
# --defaults-file 						Read only named option file
#
# --defaults-group-suffix 				Option group suffix value
# --enable-cleartext-plugin 			Enable cleartext authentication plugin
# --force 									Continue even if an SQL error occurs
# --get-server-public-key 				Request RSA public key from server
# --help 									Display help message and exit
#
# --host 									Connect to MySQL Server on given host
# --login-path 							Read login path options from .mylogin.cnf
# --no-beep 								Do not beep when errors occur
# --no-defaults 							Read no option files
# --password 								Password to use when connecting to server
# --pipe 									On Windows, connect to server using named pipe
# --plugin-dir 							Directory where plugins are installed
#
# --port										TCP/IP port number for connection
# --print-defaults 						Print default options
# --protocol 								Connection protocol to use
# --relative 								Show the difference between the current and previous values when used with the --sleep option
# --secure-auth 							Do not send PWs to server in old formats (REMOVED)
# --server-public-key-path 			Path name to file containing RSA public key
#
# --shared-memory-base-name 			Name of the shared memory to use for shared-memory connections
# --show-warnings 						Show warnings after statement execution.
# --shutdown_timeout 					The maximum number of seconds to wait for server shutdown
# --silent 									Silent mode
# --sleep 									Execute commands repeatedly, sleeping for delay in between
# --socket 									For connections to localhost, the Unix socket file to use
# --ssl-ca 									File that contains list of trusted SSL Cert Auths
#
# --ssl-capath 							Directory that contains trusted SSL cert Auth cert files
# --ssl-cert 								File that contains X.509 cert
# --ssl-cipher 							List of permitted ciphers for connection encryption
# --ssl-crl 								File that contains cert revocation lists
#
# --ssl-crlpath 							Dir that contains cert revocation list files
# --ssl-fips-mode 						Whether to enable FIPS mode on the client side
# --ssl-key 								File that contains X.509 key
# --ssl-mode 								Security state of connection to server
# --tls-version 							Protocols permitted for encrypted connections
# --user 									MySQL user name to use when connecting to server
# --verbose 								Verbose mode
#
# --version 								Display version information and exit
# --vertical 								Print query output rows vertically (one line per column value)
# --wait 									If the connection cannot be established, wait and retry instead of aborting

# The following showcases short commands for some of the above of whom are listed:
#
# --help, -? - Display a help msg and exit
# --bind-address=<ip address> - A computer having multiple network interfaces, use this option to select which interface to use for connecting to the MySQL Server.
# --character-sets-dir=<dir name> - The dir where char sets are installed.
# --compress, -C - Compress all information sent between the client and server if both support compression.
# --count=<N>, -c <N> - The number of iterations to make for repeated command execution if the --sleep option is given.
# --debug[=<debug options>], -# [<debug_options>] - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>.
# 									     Defaults to d:t:o, /tmp/mysqladmin.trace
# --debug-check - Prints some debugging information when the program exits.
# --debug-info - Print debugging info, memory, CPU usage stats when the program exits.
# --default-auth=<plugin> - A hint about the client side auth to use.
#
# --default-character-set=<charset name> - Use <charset_name> as the default char set.
# --defaults-extra-file=<file name> - Read this option file after global, but before user option files on Unix.
# 												  If not found or not permissioned, error raised. Relative if relative, Absolute otherwise.
# --defaults-file=<file name> - Use only the given option file. If the file does not exist or is otherwise inaccessible, an error occurs.
# 										  relative if relative, full otherwise.
#
# 										  The exception is .mylogin.cnf
#
# --defaults-group-suffix=<str> - read also groups with suffix regex match to str.
# --enable-cleartext-plugin - Enables cleartext authentication plugin.
# --force, -f - Do not ask for confirmation for the drop <db_name> command. with several commands, Continue even if an error occurs.
# --get-server-public-key - Request RSA public key from server.
# --help - Display help message and exit
# --host - Connect to MySQL server on given host
# --login-path - Read login path options from .mylogin.cnf
#
# --no-beep - Do not beep when errors occur
# --no-defaults - Read no option files
# --password - Password to use when connecting to server
# --pipe - On Windows, connect to server using named pipe
# --plugin-dir - Directory where plugins are installed
# --port - TCP/IP port number for connection
# --print-defaults - Print default options
#
# --protocol - Connection protocol to use
# --relative - Show the difference between the current and previous values when used with the --sleep option
# --secure-auth - Do not send passwords to server in old format (REMOVED)
# --server-public-key-path - Path name to file containing RSA public key
# --shared-memory-base-name - The name of shared memory to use for shared-memory connections
#
# --show-warnings - Show warnings after statement execution
# --shutdown_timeout - The maximum number of seconds to wait for server shutdown
# --silent - Silent mode
# --sleep - Execute commands repeatedly, sleeping for delay seconds in between
# --socket - For connections to localhost, the Unix socket file to use
# --ssl-ca - File that contains list of trusted SSL Cert Auths
# --ssl-capath - Directory that contains trusted SSL Cert Auth cert files
# --ssl-cert - File that contains X.509 cert
#
# --ssl-cipher - List of permitted ciphers for connection encryption
# --ssl-crl - File that contains certificate revocation lists
# --ssl-crlpath - Dir that contains the cert revocation list files
# --ssl-fips-mode - Whether to enable FIPS modeon the client side
# --ssl-key - File that contains X.509 key
# --ssl-mode - Security state of connection to server
# --tls-version - Protocols permitted for encrypted connections
# --user - MySQL user name to use when connecting to server
#
# --verbose - Verbose mode
# --version - Display version information and exit
# --vertical - Print query output rows vertically (one line per column value)
# --wait - If the connection cannot be established, wait and retry instead of aborting

#Basically, a lot of these options in terms of shorthand are repeats - thus, i will omit them.

#Next up, is mysqlcheck 
#
# The mysqlcheck client performs table maintenance: checks, repairs, optimizes and analyzes tables.
#
# Each table is locked and therefore unavailable to other sessions while it is being processed, although for
# check ops, the table is locked with a READ lock only
#
# mysqlcheck must be used when the mysqld server is running, which means that you do not have to stop the server
# to perform table maintenance.
#
# mysqlcheck uses the SQL statements CHECK TABLE, REPAIR TABLE, ANALYZE TABLE and OPTIMIZE TABLE in a convenient way for
# the user. It determines which statements to use for the operation you want to perform, then sends the statements to 
# the server to be executed.
#
# Not all storage engines do not support all four maintenance operations.
#
# Note: We are wise to make backups in terms of tables - in case of error in file parsing
#
# The three general ways of invoking mysqlchecks:
#
# mysqlcheck [<options>] <db_name> [<tbl_name ...>]
# mysqlcheck [<options>] --databases <db_name> ...
# mysqlcheck [<options>] --all-databases
#
# If the tbl name option is ommitted, or --databases or --all-databases options are used - entire DBs are checked.
#
# mysqlcheck has a special feature compared to other client programs.
# The default behavior of checking tables (--check) can be changed by renaming the binary.
#
# If you want to have a tool that repairs tables by default, you should just make a copy of mysqlcheck 
# named mysqlrepair, or make a symbolic link to mysqlcheck named mysqlrepair.
#
# The following names can be used to change mysqlcheck default behavior
#
# Command 			Meaning
# mysqlrepair 		Default option is --repair
# mysqlanalyze 	Default option is --analyze
# mysqloptimize 	Default option is --optimize

# mysqlcheck supports the following options, which can be specified on the command file or in the
# [mysqlcheck] and [client] groups of an option file.
#
# Format 										Desc
# 
# --all-databases 		Check all tables in all DBs
# --all-in-1 				Execute a single statement for each DB that names all the tables from that DB
# --analyze 				Analyze the tables
# --auto-repair 			If a checked table is corrupted, automatially fix it
# --bind-address 			Use specified network interface to connect to MySQL Server
# --character-sets-dir 	Dir where char sets are installed
# --check 					Check the tables for errors
#
# --check-only-changed 	Check only tables that have changed since the last check
# --check-upgrade 		Invoke CHECK TABLE with the FOR UPGRADE option
# --compress 				Compress all information sent between client and server
# --databases 				Interpret all arguments as DB names
# --debug 					Write debugging log
# --debug-check 			Print debug info when program exits
# --debug-info 			Print debug info, memory and CPU stats @ exit
#
# --default-auth 			Authentication plugin to use
# --default-character-set 			Specify default char set
# --defaults-extra-file Read named option file in addition to usual option files
# --defaults-file 		Read only named option file
# --defaults-group-suffix 		Option group suffix value
# --enable-cleartext-plugin 	Enable cleartext auth plugin
# --extended 						Check and repair tables
# --fast 							Check only tables that have not been closed properly
# --force 							Continue even if an SQL error occurs
#
# --get-server-public-key 		Request RSA public key from server 		
# --help 							Display help message and exit
# --host 							Connect to MySQL server on given host
# --login-path 					Read login path options from .mylogin.cnf
# --medium-check 					Do a check that is faster than an --extended operation
# --no-defaults 					Read no option files
# --optimize 						Optimizes the tables
# --password 						Password to use when connecting to server
#
# --pipe 							On Windows, connect to server using named pipe
# --plugin-dir 					Dir where plugins are installed
# --port 							TCP/IP port number for connection
# --print-defaults 				Print default options
# --protocol 						Connection protocol to use
# --quick 							The fastest method of checking
#
# --repair 							Perform a repair that can fix almost anything except unique keys that are not unique
# --secure-auth 					Do not send PW to server in old format (REMOVED)
# --server-public-key-path 	Path name to file containing RSA public key
# --shared-memory-base-name 	Name of shared memory to use for shared-memory connections
# --silent 							Silent mode
# --skip-database 				Omit this database from performed operations
# --socket 							For connections to localhost, the Unix socket file to use
# --ssl-ca 							File that contains list of trusted SSL Cert Auths
#
# --ssl-capath 					Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 						File that contains X.509 cert
# --ssl-cipher 					List of permitted ciphers for connection encryption
# --ssl-crl 						File that contains cert revocation lists
# --ssl-crlpath 					Dir that contains cert revocation list files
# --ssl-fips-mode 				Whether to enable FIPS mode on the client side
#
# --ssl-key 						File that contains X.509 key
# --ssl-mode 						Security state of connection to server
# --tables 							Overrides the --database or -B option
# --tls-version 					Protocols permitted for encrypted connections
# --use-frm 						For repair operations on MyISAM tables
# --user 							MySQL user name to use when connecting to server
# --verbose 						Verbose mode
# --version 						Display version information and exit
# --write-binlog 					Log ANALYZE, OPTIMIZE, REPAIR statements to binary log, 
# 										--skip-write-binlog adds NO_WRITE_TO_BINLOG to these statements.
# 
# --help, -? - Displays a help message and exits
# --all-databases, -A - Check all tables in all databases. This is the same as using the --databases option and naming all the databases
# 								on the CMD line, except for the INFORMATION_SCHEMA and performance_schema DBs of whom are not checked.
#
# 								To check them, explicitly name them with the --databases option
#
# --all-in-1, -1 - Instead of issuing a statement for each table, execute a single statement for each DB that names all the tables from that DB to be processed.
# --analyze, -a - Analyzes the tables
# --auto-repair - If a checked table is corrupted, automatically fix it. Any necessary repairs are done after all the tables have been checked.
# --bind-address=<ip_address> - On a computer having multiple network interfaces, use this option to select which interface to use for connecting to the MySQL Server.
# --character-sets-dir=<dir name> - The dir where char sets are installed
#
# --check, -c - Check the tables for errors. This is the default operation.
# --check-only-changed, -C - Check only tables that have changed since the last check or that have not been closed properly.
# --check-upgrade, -g - invoke the CHECK_TABLE with the FOR UPGRADE option to check tables for incompabilities with the current version of the server.
# --compress - Compress all information sent between the client and the server if both support it.
# --databases, -B - Process all tables in the named databases. Normally, mysqlcheck treats the first name argument on the cmd line as a DB name
# 						  and any following names as table names. With this option, it treats all name args as DB names.
# --debug[=<debug_options>], -# [<debug_options>] - Write a debugging log. A typical debug_options string is d:t:o, <file_name>. Default is d:t:o
# --debug-check - Print some debug info when the program exits
# 
# --debug-info - Print debugging info, memory and CPU usage stats when the program exits.
# --default-character-set=<charset_name> - Use <charset_name> as default char set
# --defaults-extra-file=<file name> - Read this option file after the global option file, but on Unix, before hte user option file.
# 												  If not found or inaccessible, an error occurs. Interpreted as relative, lest declared full path.
# --defaults-file=<file name> - Use only the given option file. If the file does not exist or is otherwise inaccessible, an error occurs.
# 										  <file_name> is relative, lest explicit. Still reads .mylogin.cnf
#
# --defaults-group-suffix=<str> - Regex pattern against suffix inclusion in addition to default groupings.
#
# --extended, -e - If you are using this option to check tables, it ensures that they are 100% consistent but takes a long time.
# 						 If used in conjunction with repair - it may produce garbage as well.
#
# --default-auth=<plugin> - A hint about the client-side auth plugin to use.
#
# --enable-cleartext-plugin - Enable the <mysql_clear_password> cleartext auth plugin
#
# --fast, -F - Check only tables that have not been closed properly
#
# --force, -f - Continue even if an SQL error occurs.
#
# --get-server-public-key - Request from the server public key required for RSA key pair-based PW exchange.
# 									 Applies to clients that authenticate with the <caching_sha2_password> auth plugin.
# 									 For said plugin, the server does not send the public key unless requested.
#
# 									 Is ignored for accs that do not authenticate with that plugin. 
# 									 Also ignored if RSA-based PW exchange is not used, as is when clients use secure connections.
# 	
# 									 If --server-public-key-path=<file_name> is given and valid - it's > in prio over --get-server-public-key
#
# --host=<host name>,  		 Connect to the MySQL server on the given host.
#  -h <host_name>
# 
# --login-path=<name> 		 Read options from the named login path in the .mylogin.cnf login path file.
# 									 A "login path" is an option group containing options that specify which MySQL
# 									 server to connect to and which account to authenticate as.
#
# 								    To create or modify a login path file, use the mysql_config_editor utility.
#
# --medium-check, -m 		 Do a check that is faster than a --extended operation. This finds only 99.99% of all errors,
# 									 which should be enough in most cases.
#
# --no-defaults 				 Do not read option files. Prevents errors thrown due to errornous parsing.
# 									 .mylogin.cnf is read in all cases.
#
# --optimize, -o 				 Optimize the tables
#
# --password[=<password>],  The PW to use when connecting to the server. Short option (-p) requires no space between option and PW.
#  -p [<password>] 			 If omitted, prompts afterwards for it.
#
# --pipe, -W 					 Connect to the server using a named pipe. Only applies if server supports named-pipes
#
# --plugin-dir=<dir_name> 	 The dir in which to look for plugins. Specify if --default-auth is used for auth plugin but mysqlcheck can't find it
#
# --port=<port num>,        The TCP/IP port number to use for the connection. 
#  -P <port num>
#
# --print-defaults 			 Print the program name and all options that it gets from option files.
#
# --protocol= 					 The connection protocol to use for connecting to the server. It is useful when the other connection params
# {TCP|SOCKET|PIPE|MEMORY}  normally would cause a protocol to be used other than the one you want.
#
# --quick, -q 					 If you are using this option to check tables, it prevents the check from scanning the rows to check
# 								    for incorrect links. The fastest check method.
#
# 									 If attempting to repair tables, it tries only to repair the index tree.
#
# --repair, -r 				 Perform a repair that can fix almost anything except unique keys that are not unique.
#
# --secure-auth 				 REMOVED.
#
# --server-public-key-path= The path name to a file containing a client-side copy of the public key required by the server for RSA
#   <file name> 				 key pair-based PW exchange.
#
# 								    File must be in PEM format. Applies to clients that authenticate with the sha256_password or caching_sha2_password
# 									 auth plugin. Ignored for accounts that do not authenticate with one of those plugins.
#
# 									 Also ignored if RSA based PW exchange is not used, as in secure connection.
# 									 sha256_password only applies with MySQL being built with OpenSSL.
# 									 
# 									 If --server-public-key-path=<file name> is given and specified as a valid public key,
# 									 it takes precedence over --get-server-public-key
#
# --shared-memory-base-name= On Windows, the shared memory name to use - for connections made using shared memory to a local server.
# <name>  						 Defaults to MySQL. Shared name is case-sensitive.
#
# 									 Server must be started with the --shared-memory option to enable shared-memory connections.
#
# --silent, -s 				 Silent mode. Print only error messages.
#
# --skip-database=<db name> Do not include the named DB (case-sensitive) in the operations performed by mysqlcheck.
#
# --socket=<path>,  			 For connections to localhost, the Unix socket file to use, or on Windows, the name of the named pipe to use.
#  -S <path>
#
# --ssl* 						 Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certs.
#
# --ssl-fips-mode= 			 Controls whether to enable FIPS mode on the client side. Defines which Cryptographic ops are permitted.
# {OFF|ON|STRICT} 			 allows:
#
# 									 OFF - Disabled, ON - Enabled, STRICT - "strict" FIPS mode
#
# --tables 						 Overrides the --databases or -B option. All names following are regarded as table names.
#
# --tls-version= 				 The protocols permitted by the client for encrypted connections. Comma separated list containing one or more protocol names.
#  <protocol list> 			 Protocols that can be named, depend on the SSL Lib used to Compile MySQL.
#
# --use-frm 					 For repair operations on MyISAM tables, get the table structure from the data dictionary so that the table can be repaired even
# 									 if the .MYI header is corrupted.
#
# --user=<user name>, 		 The MySQL user name to use when connecting to the server. 
#  -u <user_name>
#
# --verbose, -v 				 Verbose mode. Prints info about various stages of program ops.
#
# --version, -V 				 Display version info and exit.
#
# --write-binlog 				 Enabled by default, so that ANALYZE_TABLE, OPTIMIZE_TABLE, and REPAIR_TABLE statements generated by mysqlcheck are written to 
# 									 the binary log.
#
# 									 Use --skip-write-binlog to cause NO_WRITE_TO_BINLOG to be added to the statements so that they are not logged.
# 									 Use --skip-write-binlog when these statements should not be sent to replication slaves or run when using the binary
# 									 logs for recovery from backup.
#
# The next section covers mysqldump
#
# The mysqldump client utility performs logical backups, producing a set of SQL statements that can be executed
# to reproduce the original database object definitions and table data. 
#
# It dumps one or more MySQL databases for backup or transfer to another SQL server.
#
# mysqldump can also generate output in CSV, text or XML.
#
# mysqldump requires at least the SELECT privlege for dumped tables, SHOW VIEW for dumped views, TRIGGER for dumped triggers
# LOCK TABLES if the --single-transaction option is not used.
#
# Certain options might require other privs as noted in the option desc.
#
# To reload a dump file, you must have the privs required to execute the statements that it contains, such as
# the appropriate CREATE privs for objects created by those statements.
#
# mysqldump output can include ALTER DATABASE statements that change the database collation.
# These may be used when dumping stored programs to preserve their char encodings.
#
# To reload a dump file containing such statements, the ALTER priv for the affected DB is required.

# For instance, a dump made by PowerShell will be in UTF16 - which is not a permitted connection char encoding.
# To account for this - use --result-file to have it written in ASCII:
#
# mysqldump [<options>] --result-file=dump.sql
#
# mysqldump advantages include the convenience and flexibility of viewing or even editing the output before restoring.
# You can clone DBs and create slight variations, kind of like branching, in a way.
#
# The backup step can take a reasonable time - however, restoring the data can be very slow because replaying
# the SQL involves disk I/O for insertion, index creation and so on.
#
# If we have a lot of tables using InnoDB tables or a mix of InnoDB and MyISAM - we can use mysqlbackup from MySQL Enterprise Backup.
#
# It has the best performance for InnoDB.
#
# Otherwise, for large scale backup operations - utilize physical allocation.
#
# mysqldump can retrieve and dump table contents row by row, or it can retrieve the entire content from a table
# and buffer it in memory before dumping it.
#
# Buffering in memory can be a problem if you are dumping large tables. To dump tables row by row, use the --quick
# option (or --opt, which enables --quick).
#
# The --quick (implicitly activated by --opt) is on by default, so to enable memory buffering - use --skip-quick
#
# If you are using a recent version of mysqldump to generate a dump to be reloaded into a very old MySQL server,
# use the --skip-opt option instead of the --opt or --extended-insert option.
#
# There is in general three ways of using mysqldump - one for a set of one or more tables, a set of one or more complete DBs,
# or an entire MySQL server -
#
# mysqldump [<options>] <db_name> [<tbl_name> ...] #Omitting table names infers to dump the entire db
# mysqldump [<options>] --databases <db_name>
# mysqldump [<options>] --all-databases

# mysqldump supports the following options - which can be specified on the cmd line or in the [mysqldump] and [client] groups
# of an option file.
#
# Format 									Description
# --add-drop-database 				Add DROP DATABASE statement before each CREATE DATABASE statement
# --add-drop-table 					Add DROP TABLE statement before each CREATE TABLE statement
# --add-drop-trigger 				Add DROP TRIGGER statement before each CREATE TRIGGER statement
# --add-locks 							Surround each table dump with LOCK TABLES and UNLOCK TABLES statements
#
# --all-databases 					Dump all tables in all databases
# --allow-keywords 					Allow creation of column names that are keywords
# --apply-slave-statements 		Include STOP SLAVE prior to CHANGE MASTER statement and START SLAVE at end of Output
# --bind-address						Use specified network interface to connect to MySQL Server
# --character-sets-dir 				Directory where char sets are installed
# --column-statistics 				Write ANALYZE TABLE statements to generate statistics histograms
#
# --comments 							Add comments to dump file
# --compact 							Produce more compact output
# --compatible 						Produce output that is more compatible with other database systems or with older MySQL servers
# --complete-insert 					Use complete INSERT statements that include column names
# --compress 							Compress all information sent between client and server
# --create-options 					Include all MySQL-specific table options in CREATE TABLE statements
# 
# --databases 							Interpret all name arguments as database names
# --debug 								Write debugging log
# --debug-check 						Print debugging information when program exits
# --debug-info 						Print debugging information, memory, CPU stats when program exits
# --default-auth 						Authentication plugin to use
# --default-character-set 			Specify default character set
# --defaults-extra-file 			Read named option file in addition to usual option files
#
# --defaults-file 					Read only named option file
# --defaults-group-suffix 			Option group suffix value
# --delete-master-logs 				On a master replication server, delete the binary logs after performing the dump operation
# --disable-keys 						For each table, surround INSERT statements with statements to disable and enable keys
# --dump-date 							Include dump date as "Dump completed on" comment, if comments option is given
# --dump-slave 						Include CHANGE MASTER statement that lists binary log coordinates of slave's master
# --enable-cleartext-plugin 		Enable cleartext authentication plugin
#
# --events 								Dump events from dumped databases
# --extended-insert 					Use multiple-row INSERT syntax
# --fields-enclosed-by 				This option is used with the --tab option and has the same meaning as the corresponding clause for LOAD DATA INFILE
# --fields-escaped-by 				This option is used with the --tab option and has the same meaning as the corresponding clause for LOAD DATA INFILE
# --fields-optionally-escaped-by -||- (Denotes "same as above", basically)
# --fields-terminated-by 			-||-
# --flush-logs 						Flush MySQL server log files before starting dump
#
# --flush-privileges 				Emit a FLUSH PRIVILEGES statement after dumping mysql database
# --force 								Continue even if an SQL error occurs during a table dump
# --get-server-public-key 			Request RSA public key from server
# --help 								Display help message and exit
# --hex-blob 							Dump binary columns using hexadecimal notation
# --host 								Host to connect to (IP address or hostname)
# --ignore-error 						Ignore specified errors
#
# --ignore-table 						Do not dump given table
# --include-master-host-port 		Include MASTER_HOST/MASTER_PORT options in CHANGE MASTER statement procured by --dump-slave option enabled
# --insert-ignore 					Write INSERT IGNORE rather than INSERT statements
# --lines-terminated-by 			This option is used with the --tab option and has the same meaning as the corresponding clause for LOAD DATA INFILE
# --lock-all-tables 					Lock all tables across all databases
# --lock-tables 						Lock all tables before dumping them
# --log-error 							Append warnings and errors to named file
# --login-path 						Read login path options from .mylogin.cnf
# --master-data 						Write the binary log file name and position to the output
# --max_allowed_packet 				Maximum packet length to send to or receive from server
#
# --net_buffer_length 				Buffer size for TCP/IP and socket communication
# --network-timeout 					Increase network timeouts to permit larger table dumps
# --no-autocommit 					Enclose the INSERT statements for each dumped table within SET autocommit = 0 and COMMIT statements
# --no-create-db 						Do not write CREATE DATABASE statements
# --no-create-info 					Do not write CREATE TABLE statements that re-create each dumped table
# --no-data 							Do not dump table contents
# --no-defaults 						Read no option files
# --no-set-names 						Same as --skip-set-charset
# --no-tablespaces 					Do not write any CREATE LOGFILE GROUP or CREATE TABLESPACE statements in output
# --opt 									Shorthand for --add-drop-table --add-locks --create-options --disable-keys --extended-insert
# 															  --lock-tables --quick --set-charset
# 
# --order-by-primary 				Dump each table's rows sorted by its primary key, or by its first unique index
# --password 							Password to use when connecting to server
# --pipe 								On Windows, connect to server using named pipe
# --plugin-dir 						Dir where plugins are installed
# --port 								TCP/IP port number for connection
# --print-defaults 					Print default options
# --protocol 							Connection protocol to use
# --quick 								Retrieve rows for a table from the server a row at a time
# --quote-names 						Quote identifiers within backtick characters
#
# --replace 							Write REPLACE statements rather than INSERT statements
# --result-file 						Direct output to a given file
# --routines 							Dump stored routines (procedures and functions) - from dumped databases
# --secure-auth 						Do not send passwords to server in old (REMOVED)
# --server-public-key-path 		Path name to file containing RSA public key 
# --set-charset 						Add SET NAMES default_character_set to output
# --set-gtid-purged 					Whether to add SET @@GLOBAL.GTID_PURGED to output
# --shared-memory-base-name 		The name of shared memory to use for shared-memory connections
# --single-transaction 				Issue a BEGIN SQL statement before dumping data from server
#
# --skip-add-drop-table 			Do not add a DROP TABLE statement before each CREATE TABLE statement
# --skip-add-locks 					Do not add locks
# --skip-comments 					Do not add comments to dump file
# --skip-compact 						Do not produce more compact output
# --skip-disable-keys 				Do not disable keys
# --skip-extended-insert 			Turn off extended-insert
# --skip-opt 							Turn off options set by --opt
# --skip-quick 						Do not retrieve rows for a table from the server a row at a time
# --skip-quote-names 				Do not quote identifiers
# --skip-set-charset 				Do not write SET NAMES statement
# --skip-triggers 					Do not dump triggers
#
# --skip-tz-utc 						Turn off tz-utc
# --socket 								For connections to localhost, the Unix socket file to use
# --ssl-ca 								File that contains list of trusted SSL Cert Auths
# --ssl-capath 						Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 							File that contains X.509 cert
# --ssl-cipher 						List of permitted ciphers for connection encryption
# --ssl-crl 							File that contains certificate revocation lists
# --ssl-crlpath 						Dir that contains cert revocation list files
#
# --ssl-fips-mode 					Whether to enable FIPS mode on the client side
# --ssl-key 							File that contains X.509 key
# --ssl-mode 							Security state of connection to server
# --tab 									Produce tab-separated data files
# --tables 								Override --databases or -B option
# --tls-version 						Protocols permitted for encrypted connections
# --triggers 							Dump triggers for each dumped table
# --tz-utc 								Add SET TIME_ZONE='+00:00' to dump file
#
# --user 								MySQL user name to use when connecting to server
# --verbose 							Verbose mode
# --version 							Display version info and exit
# --where 								Dump only rows selected by given WHERE condition
# --xml 									Produce XML output
#
# The mysqldump command logs into a MySQL server to extract information. 
# The following options relate to how the connection interacts with the MySQL Server, local or remote:
#
# --bind-address=<ip address> - On a computer having multiple network interfaces, use this option to select which interface to use for connecting to the MySQL server.
# --compress, -C - Compress all information sent between the client and the server if both support compression.
# --default-auth=<plugin> - A hint about the client-side authentication plugin to use.
# --enable-cleartext-plugin - Enable the <mysql_clear_password> cleartext authentication plugin
# --get-server-public-key - Request as per before:
#
# 									 Request from the server the public key required for RSA key pair-based PW exchange.
# 									 This option applies to clients that authenticate with the <caching_sha2_password> authentication plugin.
#              
#                           For that plugin, the server does not send the public key unless requested. This option is ignored
# 									 for accounts that do not authenticate with that plugin. Also ignored for non RSA based PWs, i.e secure connections.
#
# 									 If --server-public-key-path=<file name> is given and specifies a valid public key file - it takes precedence over
# 									 --get-server-public-key.
#
# --host=<host_name>, 		 Dump data from the MySQL server on the given host. Defaults localhost 
#  -h <host_name>
#
# --login-path=<name> 		 Read options from the named login path in the .mylogin.cnf login path file.
# 									 A "login path" is an option group containing options that specify which MySQL Server
# 									 to connect to and which account to authenticate as.
#
# 									 To create or modify a login path file, use the mysql_config_editor utility.
# 									 
# --network-timeout, -M 	 Enable large tables to be dumped by setting max_allowed_packet to its maximum value
# 									 and network read and write timeouts to a large value.
#
# 									 This option is enabled by default. To disable, use --skip-network-timeout
#
# --password[=<password>],  The password to use when connecting to the server. If you use the short option form (-p), no space req
#  -p [<password>] 			 Prompt kicks in if no pw - can specify PW in a option file
#
# --pipe, -W 					 On Windows, connect to the server using a named pipe. Applies only if the server supports named-pipe connections
#
# --plugin-dir=<dir_name> 	 The dir of where to look for plugins. Specify if the --default-auth option is used to specify an authentication plugin but mysqldump does not find it.
#
# --port=<port_num>, 		 The TCP/IP port number to use for the connection
# 	-P <port_num>
#
# --protocol= 					 The connection protocol to use for connecting to the server. 
# {TCP|SOCKET|PIPE|MEMORY}
#
# --secure-auth 				 REMOVED
#
# --server-public-key-path  Same as before
#   =<file name>
#
# --socket=<path>, 			 For connections to <localhost>, the Unix socket file to use - or Windows, name of the named pipe to use 
#  -S <path>
#
# --ssl* 						 Options that begin with --ssl specify whether to connect to the server using SSL, indicate where to find SSL keys and Certs.
#
# --ssl-fips-mode= 			 Whether to enable FIPS mode on the client side. Which cryptographic ops are permitted.
#  {OFF|ON|STRICT} 			 OFF: Disable FIPS mode. ON: Enable FIPS mode. STRICT: Enable "strict" FIPS mode.
#
# --tls-version= 				 The protocols permitted by the client for encrypted connections. 
# <protocol list> 			 The value is a comma-separated list containing one or more protocol names. Allowed values depend on the SSL lib used to Compile MySQL.
#
# --user=<user_name>, 		 User name to use for connecting
#  -u <user_name>
#
# --max_allowed_packet= 	 Maximum size of the buffer for client/server comm. Defaults to 24MB, max is 1GB.
#   <value>
#
# --net_buffer_length 		 The initial size of the buffer for client/server communication. When creating multiple-row INSERT
# 									 statements (as with the --extended-insert or --opt option), mysqldump creates rows up to <net_buffer_length>
# 									 bytes long. If we increase this, the MySQL Server in terms of net_buffer_length, must be at least this large.
#
# The following options pertain to option files and which option files to read:
# 
# --defaults-extra-file=<file name> - Same as before, read before user option file on unix but after global, permissions, etc.
# --defaults-file=<file name> - Use only given option. Relative if relative, still use .mylogin.cnf - error if inaccessible.
# --defaults-group-suffix=<str> - Regex match against suffix in grouping 
# --print-defaults - Print the program name and all options that it gets from option files.
#
# Scenarios of where you'd use mysqldump include setting up an entire new MySQL instance (including DB tables), and replacing
# data inside an existing instance with existing DBs and tables.
#
# The following options let you specify which things to tear down and what to set up when restoring a dump - by utilizing
# DDL statements in the dump file.
#
# --add-drop-database - Write a <DROP DATABASE> statement before each <CREATE DATABASE> statement. 
# 							   Usually used with a --all-databases or --databases option
# --add-drop-table 	 - Write a <DROP TABLE> statement before each <CREATE TABLE> statement.
# --add-drop-trigger  - Write a <DROP TRIGGER> statement before each <CREATE TRIGGER> statement.
#
# --all-tablespaces,  - Adds to a table dump all SQL statements needed to create any tablespaces used by an NDB table.
#                       Otherwise not included from mysqldump, only relevant to NDB cluster tables, not supported by MySQL 8.0
# --no-create-db, -n  - Suppress the <CREATE DATABASE> statements that are otherwise included in the output if the --databases
#                       or --all-databases option is given.
#
# --no-create-info,   - Do not write <CREATE TABLE> statements that create each dumped table.
#  -t 						This option does not exclude statements creating log file groups or tablespaces from mysqldump output.
# 								However, you can use the --no-tablespaces option for this.
#
# --replace 				Write REPLACE statements rather than INSERT statements.
# 
# The following options pertain to debuging
#
# --allow-keywords - Permit creation of column names that are keywords. This works by prefixing each column name with the table name.
# --comments, -i 	 - Write additional information in the dump file such as program version,server version and host.
# 							This option is enabled by default. To suppress this additional information, use --skip-comments.
# --debug 				 
# [=<debug_options>], Writes a debugging log. A typical <debug_options> string is d:t:o, <file_name>. Defaults to d:t:o, /tmp/mysqldump.trace
#-# [<debug options>]	
#
# --debug-check 	 - Print some debugging information when the program exits
# --debug-info 	 - Print debugging information, memory and CPU stats when the program exits.
# --dump-date 		 - If the --comments option is given, mysqldump produces a comment at the end of the dump of the following form:
# 							-- Dump completed on <DATE>
# 						
# 						   However, the date causes dump files taken at different times to appear to be different, even if data is identical.
# 							--dump-date and --skip-dump-date control whether the date is added to the comment.
# 							Defaults to --dump-date (include date in comment), --skip-dump-date to suppress
#
# --force, -f 		 - Ignore all errors, continue even if an SQL error occurs during a table dump.
# 							Can for instance ignore view errornous referential addresses - if underlying table has been dropped.
#
# 							Without --force, mysqldump exits with an error message.
# 						   --force causes mysqldump to print the error message - but also writes an SQL comment
# 							containing the view definition to the dump output and continues executing.
#
# 							If --ignore-error is also given, --force takes higher prio
#
# --log-error= 		Log warnings and errors by appending them to the named file. Defaults to no logging.
#	<file_name>
#
# --skip-comments 	See the description for the --comments options
#
# --verbose, -v 		Verbose mode
#
# The following options pertain to some help options
#
# --help, -? - Display a help message and exit
# --version, -V - Display version info and exit
#
# The following options pertain to char sets in relation to national language settings
#
# --character-sets-dir=<dir_name> - The dir where character sets are installed.
# --default-character-set= 		 - Use <charset_name> as default char set. If none specified, defaults to UTF8.
#  <charset_name>
# --no-set-names, -N 				 - Turns off the --set-charset setting, the same as specifying --skip-set-charset
# --set-charset 						 - Write SET NAMES <default character set> to the output. Enabled by default. 
# 												To suppress the SET NAMES, use --skip-set-charset
#
# The following options pertain to Replication and akin
#
# The mysqldump command is frequently used to create an empty instance, or an instance including data, on a slave server
# in a replication configuration.
#
# The following options apply to dumping and restoring data on replication master and slave servers:
#
# --apply-slave-statements - For a slave dump produced with the --dump-slave option, add a STOP SLAVE statement before the
# 									  CHANGE MASTER TO statement and a START SLAVE statement at the end of the output.
#
# --delete-master-logs 		- On a master replication server, delete the binary logs by sending a PURGE BINARY LOGS statement to the server
# 									  after performing the dump operation. Automatically enables --master-data.
#
# --dump-slave[=<value>] 	- Similar to --master-data except that it is used to dump a replication slave server to produce a dump file
# 									  that can be used to set up another server as a slave that has the same master as the dumped server.
#
# 									  It causes the dump output to include a CHANGE MASTER TO statement that indicates the binary log coords
# 									  (file name and pos) of the dumped slave's master.
#
# 									  The CHANGE MASTER TO statement reads the values of Relay_Master_Log_File and Exec_Master_Log_Pos
# 									  from the SHOW SLAVE STATUS output and uses them for MASTER_LOG_FILE and MASTER_LOG_POS respectively.
#
# 									  Thoose are the master server coords to which the slave is to replicate from.
#
# 									  NOTE: Inconsistencies in the sequence of transactions from the relay log which have been executed can
# 									  cause the wrong coords to be used.
#
# 									  This option causes the coords from the master to be used rather than those of the dumped server, as is 
# 									  done by the --master-data option.
#
# 									  In addition - specifying this option causes the --master-data option to be overridden, if used, and ignored.
#
#  								  WARNING: Do not use in conjunction with dumped server coords which yields gtid mode=ON and MASTER_AUTOPOSITION=1
#
#  								  The option value is handled the same way as for --master-data:
#                            no value or 1 - Causes a CHANGE MASTER TO statement to be written to the dump
# 									  2 - Causes the statement to be written but encased in SQL comments (same effect as --master-data 
# 									  in enabling or disabling other options and in how locking is handled)
#
# 									  This option causes mysqldump to stop the slave SQL thread before the dump and restart it again after.
# 									  With --dump-slave - the --apply-slave-statements and --include-master-host-port options can also be used.
#
# --include-master-host-port For the CHANGE MASTER TO statement in a slave dump produced with --dump-slave option, add MASTER_HOST and MASTER_PORT
# 									  options for the host name and TCP/IP port number of the slave's master.
#
# --master-data[=<value>] 	  Use this option to dump a master replication server to produce a dump file that can be used to set up another server
# 									  as a slave of the master.
#
# 									  Causes the dump output to include a CHANGE_MASTER_TO statement that indicates the binary log coords (file name and pos) 
# 									  of the dumped server. Said coords are the master server coords from which the slave should start replicating after the dump
# 									  is loaded into the slave.
# 							
# 									  If the option value is 2 - the CHANGE_MASTER_TO statement is written as an SQL comment, and is informative only.
# 									  Has no effect when the dump file is reloaded.
#
# 									  If the option value is 1 - the statement is not written as a comment and takes effect when the dump file is reloaded.
# 									  If none is specified - it defaults to 1.
#
# 									  Requires the RELOAD privilege and the binary log must be enabled.
#
# 									  The --master-data option automatically turns off --lock-tables. 
# 									  Also turns on --lock-all-tables, unless --single-transaction also is specified.
# 									  If --single-transaction is also specified - a global read lock is acquired only for a short time
# 									  at the beginning of the dump.
#
# 									  Any action on logs happens at the exact moment of the dump.
# 									  We can also set up a slave by dumping an existing slave of the master, using the --dump-slave option
# 									  - overriding the --master-data - causing both to be ignored.
#
# --set-gtid-purged=<value>  Enables control over global transaction ID (GTID) information written to the dump file, by indicating whether
# 									  to add a SET @@global.gtid purged statement to the output.
#
# 									  May also cause a statement to be written to the output that disables binary logging while the dump file is being
# 									  reloaded.
#
# 									  Default: AUTO.
#									  OFF  : Add no SET statement to the output.
# 									  ON   : Add a SET statement to the output. An error occurs if GTIDs are not enabled on the server.
# 								     AUTO : Add a SET statement to the output if GTIDs are enabled on the server.
#
# 									  A partial dump from a server that is using GTID-based replication requires the --set-gtid-purged={ON|OFF} option
# 									  to be specified.

# 									  If we wish to deploy a new replication slave using only some of the data from the dumped server, use ON.

# 									  If we wish to repair the table in terms of copying within a topology or copy between disjoint topologies
# 									  of which remain so - Use OFF.
# 
# 									  The --set-gtid-purged option has the following effect on binary logging when the dump file is reloaded:
#
# 									  --set-gtid-purged=OFF : SET @@SESSION.SQL_LOG_BIN=0; is not added to the output.
# 									  --set-gtid-purged=ON  : SET @@SESSION.SQL_LOG_BIN=0; is added to the output
# 									  --set-gtid-purged=AUTO: SET @@SESSION.SQL_LOG_BIN=0; is added to the output if GTIDs are enabled on the server you are backing up. (If AUTO evalutes to ON)
#
# 									  NOTE: It is not recommended to load a dump file when GTIDs are enabled on the server (gtid mode=ON), if your dump file
# 									  includes system tables.
#
# 								     mysqldump issues DML instructions for the system tables which use the non-transactional MyISAM storage engine,
#								     and this combination is not permitted when GTIDs are enabled.
#
# 									  Also be aware that loading a dump file from a server with GTIDs enabled - into another server with GTIDs enabled -
# 									  causes different transaction identifiers to be generated.
# 
# The following options specify how to represent the entire dump file or certain kinds of data in the dump file.
# They also control whether certain optional info is written to the dump file:
#
# --compact - Produce more compact output. This option enables the --skip-add-drop-table, --skip-add-locks, --skip-comments,
# 																						 --skip-disable-keys, --skip-set-charset options.
# --compatible=<name> - Produce output that is more compatible with other database systems or with older MySQL servers.
# 								Only permitted value for this is ansi - has the same meaning as for the Server SQL mode option.
# --complete-insert, -c Use complete INSERT statements that include column names
#
# --create-options 		Include all MySQL-specific table options in the CREATE TABLE statements.
#
# --fields-terminated-by=<...>, 				Options used with the --tab option and have the same meaning as the corresponding FIELDS
# --fields-enclosed-by=<...>, 				clauses for LOAD DATA INFILE.
# --fields-optionally-enclosed-by=<...>,
# --fields-escaped-by=<...>
#
# --hex-blob 				Dump binary columns using hexadecimal notation ('abc' becomes 0x616263).
# 								Affected data types are BINARY, VARBINARY, BLOB types and BIT.
#
# --lines-terminated-by=<...> 				Used with the --tab option and has the same meaning as the corresponding LINES clause for LOAD DATA INFILE.
#
# --quote-names, -Q 		Quote identifiers, such as DB, table and column names - within ` chars. If the ANSI_QUOTES SQL mode is on, identifiers are quoted with "
# 								Enabled by default. Can be disabled with --skip-quote-names, but this option should be given after any option such as --compatible that may
# 								enable --quote-names. i.e - Order this command after others
#
# --result-file= 		   Direct output to the named file. Result file is created and its previous contents overwritten, even if an error occurs while generating dump.
#  <file_name>, 			Used on Windows to prevent \n from becoming \r\n
#
# --tab=<dir_name>, 	   Produce tab-separated text-format data files. For each dumped table, mysqldump creates a <tbl_name>.sql file that contains 
#  -T <dir_name> 			the CREATE TABLE statements - of which create the table and the server writes a <tbl_name>.txt that contains its data.
# 								The option value is the dir in which to write the files.
#
# 								NOTE: Should only be used when mysqldump is run on the same machine as the mysqld server.
# 										The server creates *.txt files in the dir that we specify - the dir must be writable by the server
# 										and the MySQL acc that we use must have the FILE privs.
#
# 									   Because mysqldump creates *.sql in the same dir, it must be writable by the system login acc.
#
# 								By default - the .txt data files are formatted using tab chars between column values and a newline at the end of each line.
# 								The format can be specified explicitly using the --fields-<xxx> and --lines-terminated-by options.
#
# 								Column values are converted to the character set specified by the --default-character-set option.
#
# --tz-utc 					Enables TIMESTAMP columns to be dumped and reloaded between servers in different time zones.
# 								mysqldump sets its connection time zone to UTC and adds SET TIME_ZONE='+00:00' to the dump file.
# 			
# 								Without this - TIMESTAMP columns are dumped and reloaded in the time zones local to the source and
# 								destination servers - Which causes discrepencies in values if the servers are in different timezones.
#
# 								Also protects against changes due to daylight saving time.
# 								Enabled by default - disable with --skip-tz-utc
#
# --xml, -X 				
#  -r <file_name> 		Write dump output as well-formed XML.
#
# 								The following example showcases the differences:
# 								VALUE: 									XML Representation:
# 								NULL(unknown value) 					<field name="column_name" xsi:nil="true" />
# 								''(empty strting) 					<field name="column_name"></field>
# 								'NULL'(string value) 				<field name="column_name">NULLL</field>
#
# 								An example of mysqldump can be showcased as follows:
#
# 								mysqldump --xml -u root world City
# 								<?xml version="1.0"?>
# 								<mysqldump xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
# 								<database name="world">
#
# 								<table_structure name="City">
# 								<field Field="ID" Type="int(11)" Null="NO" Key="PRI" Extra="auto_increment" />
# 								<field Field="Name" Type="char(35)" Null="NO" Key="" Default="" Extra="" />
# 								<field Field="CountryCode" Type="char(3)" Null="NO" Key="" Default="" Extra="" />
# 
# 								<field Field="District" Type="char(20)" Null="NO" Key="" Default="" Extra="" />
# 								<field Field="Population" Type="int(11)" Null="NO" Key="" Default="0" Extra="" />
# 								<key Table="City" Non_unique="0" Key_name="PRIMARY" Seq_in_index="1" Column_name="ID"
# 								Collation="A" Cardinality="4079" Null="" Index_type="BTREE" Comment="" />
# 								
# 								<options Name="City" Engine="MyISAM" Version="10" Row_format="Fixed" Rows="4079"
# 								Avg_row_length="67" Data_length="273293" Max_data_length="<numbers>"
# 								Index_length="43008" Data_free="0" Auto_increment="4080"
# 								Create_time="2007-03-31 01:47:01" Update_time="2007-03-31 01:47:02"
# 								Collation="latin1_swedish_ci" Create_options="" Comment="" />
# 								</table_structure>
# 								
# 								<table_data name="City">
# 								<row>
# 								<field name="ID">1</field>
# 								<field name="Name">SomeName</field>
# 								<field name="CountryCode">SomeValue</field>
# 								<field name="District">SomeValue</field>
# 								<field name="Population">SomeValue</field>
# 								</row>
#
# 								<row>
# 								<field name="ID">SomeValue</field>
# 								<field name="Name">SomeValue</field>
# 								<field name="CountryCode">SomeValue</field>
# 								<field name="District">SomeValue</field>
# 								<field name="Population">SomeValue</field>
# 								</row>
# 								</table_data>
# 								</database>
# 								</mysqldump>
#
# 
# The following options pertain to filtering in terms of Schema objects being written to dump files, sorted by:
# Category
# triggers/events
# names to be dumped
# Filtering based on WHERE
#
# --all-databases, -A - Dump all the tables in all of the DBs. Same as using --databases on cmd line
# 								To include routines and events in terms of > 8.0, use --routines and --events in addition to the --all-databases
# 								The reason for this - is that the mysql.event and mysql.proc tables are not used.
#
# 								< 8.0, the system DB included the mysql.proc and mysql.event tables with the routines and event defs
#
# --databases, -B 	 - Dump several DBs. Normally - mysqldump treats each name past the first as tables. This treats all names as DBs.
# 								This can be used to dump the performance_schema DB, not normally dumped with --all-databases
# 								(Also use the --skip-lock-tables)
#
# --events, -E 		 - Include Event Scheduler events for the dumped databases in the output. This option requires the EVENT privs for those DBs.
# 								The output generated by using --events contains CREATE EVENT statements to create the events.
#
# --ignore-error= 		Ignore the specified errors. The option value is a comma-separated list of error numbers specifying the errors to ignore
#   <error>[,<error>].. during mysqldump execution.
#
# 								If the --force option is also given to ignore all errors, --force takes precedence.
#
# --ignore-table= 		Do not dump the given table, which must be specified using both the DB and Table names.
#   <db_name>.<tbl_name> To ignore multiple tables, use this option multiple times. Can also be used to ignore views.
#
# --no-data, -d 			Do not write any table row info (that is, do not dump the table contents). This is useful if you want to dump
# 								only the CREATE TABLE statement for the table (For example - to create a empty copy of the table by loading the dump file)
#
# --routines, -R 			Include stored routines (procedures and functions) for the dumped databases in the output. This option requires the global
# 								SELECT priv.
#
# 								The output generated by using --routines contains CREATE_PROCEDURE and CREATE_FUNCTION statements to create the routine.
# 
# --tables 					Override the --databases or -B option. mysqldump regards all name arguments following the option as table names.
#
# --triggers 				Include triggers for each dumped table in the output. This option is enabled by default; disable it with --skip-triggers
#
# 								To be able to dump a table's triggers - you must have the TRIGGER priv for the table.
#
# 								Multiple triggers are permitted. mysqldump dumps triggers in activation order so that when the dump file is reloaded,
# 								triggers are created in the same activation order. 
#
# 								If a mysqldump file contains multiple triggers for a table that have the same trigger event and action time,
# 								an error occurs to load the dump file into a older server that does not support multiple triggers.
#
# --where= 					Dump only rows selected by the given <WHERE> condition. Quotes around the condition are mandatory if it contains
#  <WHERE CONDITION>  	spaces or other chars that are special to your cmd interpreter (Just escape with ""'s)
#  -w <WHERE CONDITION>
#
# The following options pertain to performance options related to restore operations.
# For large data sets - restore operations (processing the INSERT statements in the dump file) takes a lot of time (or most)
# 
# Performance is also influenced by the transactional options, primarily for the dump operation.
#
# --column-statistics - Add <ANALYZE TABLE> statements to the output to generate histogram stats for dumped tables when the dump file is reloaded.
# 								This option is disabled by default because histogram generation for large tables takes a long time.
#
# --disable-keys, -K  - For each table - surround the <INSERT> statements with /*!40000 ALTER TABLE <tbl_name> DISABLE KEYS */;
# 																										 /*!40000 ALTER TABLE <tbl_name> ENABLE KEYS */;
#
# 								This makes loading the dump files faster because the indexes are created after all rows are inserted.
#								Effective only for nonunique indexes of MyISAM tables.
#
# --extended-insert,  - Write <INSERT> statements using multiple-row syntax that includes several VALUES lists.
#  -e  						Results in a smaller dump file and speeds up inserts when the file is reloaded.
#
# --insert-ignore 	 - Write <INSERT IGNORE> statements rather than <INSERT> statements.
#
# --opt 					 - This option, enabled by default - is short hand for: 
# 											--add-drop-table --add-locks --create-options
# 											--disable-keys --extended-insert --lock-tables
# 											--quick --set-charset
#
# 								It's basically a fast dump.
# 								Since --opt is default, running --skip-opt just turns off several defaults.
#
# --quick, -q 			 - Useful for dumping large tables. Forces mysqldump to retrieve rows for a table from the
# 								server a row at a time rather than retrieving the entire row set and buffering it in memory before writing it out.
#
# --skip-opt 			 - Read --opt 
#
# The following options pertain to trade off between speed, reliability and consistency of the exported data.
#
# --add-locks 			- Surround-each table dump with LOCK TABLES and UNLOCK TABLES statements.
# 							  Results in faster inserts when dump file is reloaded.
#
# --flush-logs,  		-  Flush the MySQL server log files before starting the dump. This option requires the RELOAD priv.
#  -F 					 	If you use this option in combo with the --all-databases option - the logs are flushed
# 								for each DB dumped.
#
# 								The exception is when using --lock-all-tables, --master-data or --single-transaction.
# 								In this case, the logs are flushed only once - corresponding to the moment that all tables
# 								are locked by <FLUSH TABLES WITH READ LOCK>.
#
# 								If you want your dump and the log flush to happen at exactly the same moment - you should use
# 								--flush-logs together with --lock-all-tables, --master-data, or --single-transaction.
#
# --flush-privileges 	Adds a FLUSH PRIVILEGES statement to the dump output after dumping the mysql database.
# 								This option should be used any time the dump contains the mysql DB and any other DB that depends
# 								on the data in the mysql db for proper restoration.
#
# 								For > 5.7.2 - do not use --flush-privileges.
#
# --lock-all-tables, 	Lock all tables across all databases. This is achieved by acquiring a global read lock for the
#  -x  						duration of the whole dump.
#
# 								This option automatically turns off --single-transaction and --lock-tables
# 
# --lock-tables, -l 		For each dumped database, lock all tables to be dumped before dumping them.
# 								The tables are locked with READ LOCAL to permit concurrent inserts in the case
# 								of MyISAM tables.
#
# 								For transactional tables such as InnoDB, --single-transaction is a much better option
# 								than --lock-tables because it does not need to lock the tables at all.
#
# 								Because --lock-tables locks tables for each DB separately, this option does not guarantee
# 								that the tables in the dump file are logically consistent between DBs.
#
# 								Tables in different DBs may be dumped in different states.
#
# 								Some options such as --opt automatically enable --lock-tables.
# 								If you want to override this  - use --skip-lock-tables at the end of the options list.
# 								
# --no-autocommit 		Enclose the INSERT statements for each dumped table within SET autocommit = 0 and COMMIT statements.
#
# --order-by-primary 	Dump each table's rows sorted by it's primary key - or by its first unique index - if such an index exists.
# 								This is useful when dumping a MyISAM table to be loaded into an InnoDB table, but makes the dump operation
# 								take a lot more time.
#
# --shared-memory- 		On Windows, the shared-memory name to use - for connections made using shared memory to a local server.
#  base-name=<name> 		The default value is MySQL. The shared-memory name is case-sensitive.
#
# 								Server must be started with the --shared-memory to enable shared-memory connections
#
# --single-transaction 	This option sets the transaction isolation mode to REPEATABLE READ and sends a START TRANSACTION SQL statement
# 								to the server before dumping data. It is useful only with transactional tables such as InnoDB - because it
# 								dumps the consistent state of the DB at the time of when START TRANSACTION was issued without blocking
# 								any apps.
#
# 								When using this option - you should keep in mind that only InnoDB tables are dumped in a consistent state.
# 								For example, any MyISAM or MEMORY tables dumped while using this option may still change state.
#
# 								While a --single-transaction dump is in process, to ensure a valid dump file (correct table contents and binary log coords)
# 								no other connection should use the following statements:
#
# 								ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE
#
# 								A consistent read is not isolated from those statements - so use of them on a table to be dumped
# 								can cause the SELECT that is performed by mysqldump to retrieve the table contents to obtain incorrect contents or fail.
#
# 								The --single-transaction option and the --lock-tables option are mutually exclusive because LOCK TABLES causes any
# 								pending transactions to be committed implicitly.
#
# 								To dump larger tables - combine the --single-transaction option with the --quick option.
#
# The following are some examples:
#
# Backup of an entire DB:
#
# mysqldump <db_name> > backup-file.sql
#
# To load the dump file back into the server:
#
# mysql <db_name> < backup-file.sql
#
# Another way to reload the dump file:
#
# mysql -e "source /path-to-backup/backup-file.sql" <db_name>
#
# mysqldump can also populate other DBs by copying data from one MySQL server to another:
#
# mysqldump --opt <db_name> | mysql --host=<remote_host> -C <db_name>
#
# We can also dump several DBs with one comment:
#
# mysqldump --databases <db_name1> [<db_name2> ...] > <my_databases.sql>
#
# We can also direct flow of output to a sql file :
# mysqldump --all-databases > all_databases.sql
#
# For InnoDB tables, mysqldump provides a way of making a online backup:
#
# mysqldump --all-databases --master-data --single-transaction > all_databases.sql
#
# This backup acquires global read lock on all tables (using the FLUSH TABLES WITH READ LOCK) at the beginning of the dump.
# As soon as the lock has been aquired - the binary log co-ords are read and the lock is released.
#
# If long updating statements are running when the FLUSH statement is issued - the MySQL server may get stalled
# until said statements finish.
#
# After that - the dump becomes lock free and does not disturb reads and writes on the tables. If the update statements
# that the MySQL server receives are short (in terms of execution time) - the initial lock period should not be noticable.
#
# If we are interested in point-in-time recovery (known as "roll-forward" - when we need to restore an old backup and replay the changes that
# 																  happened since that backup) - it is useful to rotate the binary log - or at least know the binary log co-ords
# 																  to which the dump corresponds:
#
# mysqldump --all-databases --master-data=2 > all_databases.sql
#
# OR
#
# mysqldump --all-databases --flush-logs --master-data=2 > all_databases.sql
#
# The --master-data and --single-transaction options can be used at the same time - which provides a convenient way to make a online
# backup suitable for use prior to point-in-time recovery if tables are used with InnoDB as a storage engine.
#
# Mysqldump does not dump the performance_schema or sys schema by default. To dump any of these - name them explicitly  on the cmd line.
# You can also name them with the --databases option. For performance_schema - also use the --skip-lock-tables option.
#
# mysqldump does not dump the INFORMATION_SCHEMA schema
#
# mysqldump does not dump InnoDB CREATE TABLESPACE statements
#
# mysqldump includes statements to recreate the <general_log> and <slow_query_log> tables for dumps of the mysql database.
# Log table contents are not dumped.
#
# The following options section pertains to mysqlimport - which is used for data imports.
#
# The mysqlimport client provides a CMD line interface to the LOAD DATA INFILE SQL statement.
# Most options to mysqlimport correspond directly to clauses of LOAD DATA INFILE syntax.
#
# To invoke mysqlimport, the syntax is generally:
#
# mysqlimport [<options>] <db_name> <textfile1> [<textfile2>]
#
# For each text file named on the cmd line - mysqlimport strips any extension from the file name and uses
# the result to determine the name of the table into which to import the file's contents.
#
# For example - files named patient.txt, patient.text and patient all would be imported into a table called patient.
#
# We can define the following options on the cmd line or the [mysqlimport] and [client] groups of an option file.
#
# 		FORMAT 											Desc
# --bind-address  			Use specified network interface to connect to MySQL Server
# --columns 					This option takes a comma-separated list of column names as its value
# --compress 					Compress all information sent between client and server
# --debug 						Write debug log
# --debug-check 				Print debug info when program exits
# --debug-info 				Print debug info, memory and CPU stats when the program exits
# --default-auth 				Auth plugin to use
#
# --default-character-set 	Specify default character set
# --defaults-extra-file 	Read named option file in addition to usual option files
# --defaults-file 			Read only named option file
# --defaults-group-suffix 	Option group suffix value
# --delete 						Empty the table before importing the text file
#
# --enable-cleartext- 		Enable cleartext auth plugin
#   plugin
# --fields-enclosed-by 		keeps the same for several structures adhering to the following
# --force 						Continue even if an SQL error occurs
# --get-server-public-key 	Request RSA public key from server
# --help 						Displays help message and exits
# --host 						Connect to MySQL server on given host
#
# --ignore 						See the desc file for the --replace option
# --ignore-lines 				Ignore the first N lines of hte data file
# --lines-terminated-by 	Same as other terminated by dynamics
# --local 						Read input files locally from the client host
# --lock-tables 				Lock all tables for writing before processing any text files
#
# --login-path 				Read login path options from .mylogin.cnf
# --low-priority 				Use LOW_PRIORITY when loading the table
# --no-defaults 				Read no option files
# --password 					PW to use when connecting to server
# --pipe 						On Windows, connect to the server using named pipe
#
# --plugin-dir 				Dir where plugins are installed
# --port 						TCP/IP number for connection
# --print-defaults 			Print default options
# --protocol 					Connection protocol to use
# --replace 					The --replace and --ignore options control handling of input rows that duplicate
# 									existing rows on unique key values
# --secure-auth 				REMOVED
#
# --server-public-key-path Path name to file containing RSA public key
# --shared-memory-base- 	Name of the shared memory to use for shared-memory connections
#   name
# --silent 						Produce output only when errors occur
# --socket 						For connections to localhost, the Unix file socket to use
#
# --ssl-ca 						File that contains list of trusted SSL Cert Auths
# --ssl-capath 				Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 					File that contains X.509 cert
# --ssl-cipher 				List of permitted ciphers for connection encryption
# --ssl-crl 					File that contains cert revocation lists
# --ssl-crlpath 				Dir that contains cert revocation list files
#
# --ssl-fips-mode 			Whether to enable FIPS mode on the client side
# --ssl-key 					File that contains X.509 key
# --ssl-mode 					Security state of connection to the server
# --tls-version 				Protocols permitted for encrypted connections
# --use-threads 				Number of threads for parallel file-loading
# --user 						MySQL user name to use when connecting to server
# --verbose 					Verbose mode
# --version 					Display v info and exit

# --help, -? - Display help and exit
# --bind-adress=<ip address> - On a computer having multiple network interfaces, use this option to select which interface to use for connecting to the MySQL serv.
# --character-sets-dir=<dir name> - The dir where char sets are installed
# --columns=<column list>, 		 - This option takes a comma-separated list of column names as its value. The order of the column names indicates how to match
#  -c <column_list> 						data file columns with table columns
# --compress, -C 						 - Compress all information sent between client and the server if both support compression
# --debug[=<debug options>], 		 - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>. Default is d:t:o
#  -# [<debug_options>]
# --debug-check 						 - Print some debugging information when the program exits
# --debug-info 						 - Print debugging info, memory info, CPU usage etc. when the program exits
# 
# --default-character-set= 		 - Use <charset_name> as the default char set
#  <charset_name>
#
# --default-auth=<plugin> 			 - Hint about client-side auth plugin to use
#
# --defaults-extra-file= 			 - Same as previous file ordering partition
#  <file name>
#
# --defaults-file=<file name> 	 - Use only given option file, .mylogin.cnf is still read - path is relative if relative, full otherwise
#
# --defaults-group-suffix= 		 - Suffix regex against group names
# 	 <str>
#
# --delete, -D 						 - Empty the table before importing the text file
#
# --enable-cleartext-plugin 		 - Enable the mysql_clear_password cleartext auth plugin
#
# Ommited a few due to repetition
#
# --host=<host name>, 				 - Import data to mysql server on the given host - defaults to Local
#  -h <host_name>
#
# --ignore, -i 						 - --replace, basically
#
# --ignore-lines=<N> 				 - Ignore the N first lines of hte data file
#
# --lines-terminated-by=<...> 	 - This option has the same meaning as the corresponding clause for LOAD DATA INFILE.
# 												For example - to import Windows files that have lines terminated with carriage return/linefeed pairs,
# 												use --lines-terminated-by="\r\n".
#
# --local, -L 							 - Default, files are read by the server on the server host. With this option, mysqlimport reads input files locally
# 												on the client host. Enabling local data loading also requires that the server permits it.
#
# --lock-tables, -l 					 - Lock all tables for writing before processing any text files. Ensures that all tables are synched on the server.
#
# --login-path=<name> 				 - Read options from the named login path in the .mylogin.cnf login path file.
# 												A "login path" is an option group containing options that specify which MySQL server to connect to
# 												and which acc to auth as. Used with mysql_config_editor
#
# --low-priority 						 - Use LOW_PRIORITY when loading the table. This affects only storage engines that use only table-level locking
# 												(such as MyISAM, MEMORY, and MERGE)
#
# --no-defaults 						 - Same as other no-defaults
#
# SKIP A FEW BECAUSE REPEAT
#
# --replace, -r 						  - The --replace and --ignore options control handling of input rows that duplicate existing rows on unique key values.
# 												 If given - new rows replace existing rows that have the same unique key value.
# 												 --ignore skips - If neither is given, an error occurs when running into a duplication and ignores the rest of the file.
#
# //SKIPPED REPEATAL
#
# --use-threads=<N> 						- Load files in parallel using <N> threads
#
# Example of showcasing of usage:
#
# mysql -e 'CREATE TABLE imptest(id INT, n VARCHAR(30))' test #Create the table
# ed #Linux text editor interaction
# a
# 100 		Max Sydow
# 101 		Count Dracula
#
# w imptest.txt #Write to imptext.txt
# 32
# q
# od -c imptest.txt #Dump octal format unto text file and utilize -c to run the command as this program in terms of interpretation
# <Octal format for String chars> <id value> <String structure> #The first string value of 100 max Sydow
# etc.
#
# mysqlimport --local test imptest.txt #connect to local, select a table called test and insert the imptest info
# test.imptest: Records: 2 Deleted: 0 Skipped: 0 warning: 0 #Imports into table
# mysql -e 'SELECT * FROM imptest' test #Select all from imptext, escape chars with -e
# +----------------------------------+
# | id 	| 	n 								 |
# +------+---------------------------+
# |  100 | Max Sydow 					 |
# |  101 | Count Dracula 				 |
# +------+---------------------------+
#
#
# The following section covers mysqlpump - which breaks down DBs etc. into logical backups, which comes in the form of
# a set of SQL statements that can rebuild the system you broke down.
#
# Can dump one or several DBs.
#
# The features covers things akin to:
#
# Parallel processing of DBs, and of objects within DBs
# Better control over which DB and DB objects (tables, stored programs, user accs) to dump
# Dumping of user accs as account-management statements (CREATE USER, GRANT) - rather than as inserts into the mysql DB
# 
# Capability of creating compressed output
# Progress indicator (estimates)
# In terms of dump file reloading, faster secondary index creation for InnoDB tables by adding indexes after rows are inserted
#
# mysqlpump requires at least the SELECT privilege for dumped tables, SHOW VIEW for dumped views, TRIGGER for dumped triggers
# LOCK TABLES if the --single-transaction option is not used
#
# The SELECT priv on the mysql system db is required to dump user defs. Certain options might require other privs
# as noted in the option desc.
#
# To reload a dump file - you must have the privs reqed to execute the statements that it contains - such as appropiate CREATE privs
# for objects created by said statements.
#
# When dumping, use --result-file to circumvent UTF-16 encoding
#
# mysqlpump [<options>] > dump.sql #UTF-16, not allowed as server conn Char set
#
# mysqlpump [<options>] --result-file=dump.sql
#
# By default, mysqlpump dumps all the DBs, except a few. Can use --all-databases to do all
#
# To dump more specifically - following syntax holds:
#
# mysqlpump <db_name>
# mysqlpump <db_name> <tbl_name1, tbl_name2>
#
# To treat all name args as DB names - use the --databases option:
#
# mysqlpump --databases <db_name1, db_name2>
#
# By default, mysqlpump does not dump user acc defs - even if you dump the mysql system DB that contains the grant tables.
# To dump grant table contents as logical definitions in the form of CREATE USER and GRANT statements - use the --users option
# and suppress all DB dumping
#
# mysqlpump --exclude-databases=% --users
#
# The % above is wildchar regex against any name sequence in the context above
#
# mysql has different options for including/excluding DBs, tables, stored programs and user defs.
#
# To reload a dump file - execute the statements that it contains. For instance:
#
# mysqlpump [<options>] > dump.sql
# mysql < dump.sql
#
# FORMAT 										Desc
# --add-drop-database 				Add DROP DATABASE statement before each CREATE DATABASE statement
# --add-drop-table 					Add DROP TABLE statement before each CREATE TABLE statement
# --add-drop-user 					Add DROP USER statement before each CREATE USER statement
# --add-locks 							Surround each table dump with LOCK TABLES and UNLOCK TABLES statements
# --all-databases 					Dump all DBs
#
# --bind-address 						Use specified network interface to connect to MySQL Server
# --character-sets-dir 				Dir where char sets are installed
# --column- statistics 				Write ANALYZE TABLE statements to generate stats histograms
# --complete-insert 					Use complete INSERT statements that include column names
# --compress 							Compress all information sent between client and server
#
# --compress-output 					Output compress algo
# --databases 							Interpret all name args as DB names
# --debug 								Write debugging log
# --debug-check 						Print debugging info when program exits
# --debug-info 						Print debug info, memory and CPU stats when program exits
# --default-auth 						Auth plugin to use
#
# --default-character-set 			Specify default char set
# --default-parallelism 			Default number of threads for parallel processing
# --defaults-extra-file 			Read named option file in addition to usual option files
# --defaults-file 					Read only named option file
#
# --defaults-group-suffix 			Option group suffix regex
# --defer-table-indexes 			For reloading, defer index creation until after loading table rows
# --events 								Dump events from dumped databases
# --exclude-databases 				Databases to exclude from dump
# --exclude-events 					Events to exclude from dump
#
# --exclude-routines 				Routines to exclude from dump
# --exclude-tables 					Tables to exclude from dump
# --exclude-triggers 				Triggers to exclude from dump
# --exclude-users 					Users to exclude from dump
# --extended-insert 					Use multiple-row INSERT syntax
#
# --get-server-public-key 			Request RSA public key from server
# --help 								Display help and exit
# --hex-blob 							Dump binary columns using hexadecimal notation
# --host 								Host to connect to (IP address or hostname)
# --include-databases 				DBs to include in dump
#
# --include-events 					Events to include in dump
# --include-routines 				Routines to include in dump
# --include-tables 					Tables to include in dump
# --include-triggers 				Triggers to include in dump
# --include-users 					Users to include in dump
#
# --insert-ignore 					Write INSERT IGNORE rather than INSERT statements
# --log-error-file 					Append warnings and errors to named file
# --login-path 						Read login path options from .mylogin.cnf
# --max-allowed-packet 				Maximum packet length to send or recieve from server
# --net-buffer-length 				Buffer size for TCP/IP and socket communication
# --no-create-db 						Do not write CREATE DATABASE statements
# --no-create-info 					Do not write CREATE TABLE statements that re-create each dumped table
#
# --no-defaults 						Read no option files
# --parallel-schemas 				Specify schema-processing parallelism
# --password 							Password to use when connecting to server
# --plugin-dir 						Dir where plugins are installed
# --port 								TCP/IP port number for connection
# --print-defaults 					Print default options
#
# --protocol 							Connection protocol to use
# --replace 							Write REPLACE statements rather than INSERT statements
# --result-file 						Direct output to a given file
# --routines 							Dump stored routines (procedures and functions) from dumped DBs
# --server-public-key-path 		Path name to file containing RSA public key
#
# --set-charset 						Add SET NAMES default_char_set to output
# --set-gtid-purged 					Whether to add SET @@GLOBAL.GTID_PURGED to output
# --single-transaction 				Dump tables within single transaction
# --skip-definer 						Omit DEFINER and SQL SECURITY clauses from view and stored program CREATE statements
# --skip-dump-rows 					Do not dump table rows
# --socket 								For connections to localhost, the Unix socket file to use
# --ssl-ca 								File that contains list of trusted SSL Cert Auths
# --ssl-capath 						Dir that contains trusted SSL Cert Auth cert files
#
# --ssl-cert 							File that contains X.509 cert
# --ssl-cipher 						List of permitted ciphers for connection encryption
# --ssl-crl 							File that contains cert revocation lists
# --ssl-crlpath 						Dir that contains cert revocation list files
# --ssl-fips-mode 					Whether to enable FIPS mode on the client side
# --ssl-key 							File that contains X.509 key
#
# --ssl-mode 							Security state of connection to server
# --tls-version 						Protocols permitted for encrypted connections
# --triggers 							Dump triggers for each dumped table
# --tz-utc 								Add SET TIME_ZONE='+00:00' to dump file
# --user 								MySQL user name to use when connecting to server
# --users 								Dump user accs
#
# --version 							Display version info and exit
# --watch-progress 					Display progress indicator
#
# The following is further designation of options:
#
# --help, -? - Display a help message and exit
# --add-drop-database - Write a DROP DATABASE statement before each CREATE DATABASE statement.
# --add-drop-table - Write a DROP TABLE statement before each CREATE TABLE statement
# --add-drop-user - Write a DROP USER statement before each CREATE USER statement
#
# --add-locks - Surround each table dump with LOCK_TABLES and UNLOCK_TABLES statements. Causes faster inserts when dump is loaded
#
# 					 Does not work with parallelism because INSERT statements from different tables can be interleaved,
# 					 UNLOCK TABLES following the end of the inserts for one table could release locks on tables for which inserts remain.
#
# 					 i.e - --add-locks and --single-transaction are mutually exclusive
#
# --all-databases, - Dump all databases. Exclusive towards --databases. Defaults to dumping all, except few.
#  -A
#
# 							< MySQL 8.0 - includes mysql system db, also mysql.proc and mysql.event tables - with routines and events
# 							>= MySQL 8.0 - mysql.event and mysql.proc tables are not used. To include, use --routines and -events explicitly
#
# --bind-address   - On a computer having multiple network interfaces - use this option to select which interface to use for connecting to the MySQL server 
#  =<ip address>
#
# --character-sets-dir - The dir where char sets are installed
#  =<path>
#
# --column-statistics - Add ANALYZE TABLE statements to the output to generate histogram statistics for dumped tables when the dump file is reloaded.
# 								This option is disabled by default because histogram generation for large tables can take a long time.
#
# --complete-insert 	 - Write complete INSERT statements that include column names
#
# --compress, -C 		 - Compress all information sent between the client and server if both support compression
#
# --compress-output=  - By default, mysqlpump does not compress output. This option specifies output compressiion using the specified algo.
#  <algorithm> 		   Permitted are LZ4 and ZLIB.
#
# 								To uncompress compressed output - you must have an appropiate utility. If the system commands iz4 and openssl zlib are not about,
# 								MySQL includes iz4_decompress and zlib_decompress utilities that can be used to decompress mysqlpump output that was
# 								compressed using the --compress-output=LZ4 and --compress-output=ZLIB.
#
# --databases, -B 	 - Normally, mysqlpump treats the first name arg on the cmd line as a db name and any following names as table names.
# 								With this option - it treats all name args as db names. CREATE DATABASE statements are included in the output before
# 								each new DB.
#
# 								--all-databases and --databases are exclusive.
#
# --debug[=<debug options>] - Write a debugging log. A typical <debug_options> is d:t:o, <file_name>. Defaults to d:t:O, /tmp/mysqlpump.trace
#  -# [<debug_options>
#
# --debug-check - Print some debugging when the program exits
#
# --debug-info, -T - Print debugging info, memory and stats usage when the program exits.
#
# --default-auth - Hint about the client-side auth plugin to use 
#  =<plugin>
#
# --default-character-set= - Use <charset_name> as the default char set - if none specified, defaults to UTF8
#   <charset_name>
#
# --default-parallelism=<N> - The default number of threads for each parallel processing queue. Defaults to 2.
#
# 										--parallel-schemas also affects parallelism - and can be used to override the default numbers of threads.
#
# 										If we use --default-parallelism=0 and no --parallel-schemas - mysqlpump runs a single-threaded process and 
# 										creates no queues.
# 	
#  									With parallelism enabled - it is possible for output from different databases to be interleaved
#
# --defaults-extra-file=    - Read this option file after the global option file but (on Unix) before the user option file.
#   <file name> 					Relative if relative, absolute if absolute - failure to access throws an error
#
# --defaults-file= 			 - Use only the given option file. If it does not exist or cannot be accessed - error is thrown.
#   <file name> 					.mylogin.cnf is still read
#
# 										Relative if relative, absolute if absolute etc.
#
# --defaults-group-suffix=  - Regex match against suffix in groupings
#  <str>
#
# --defer-table-indexes 	 - In the dump output, defer index creation for each table until after its rows have been loaded.
# 										This works for all storage engines - but for InnoDB applies only for secondary indexes.
#
# 										Enabled by default, --skip-defer-tables-indexes to disable.
#
# --events 							Include Event Scheduler events for the dumped databases in the output. 
# 										Event dumping requires the EVENT privs for those DBs.
#
# 										The output generated by using --events contains CREATE EVENT statements to create the events.
# 										On by default - use --skip-events to disable it
#
# --exclude-databases= 		 - Do not dump the DBs in said list. This option stacks.
#  <db_list>
#
# --exclude-events= 			 - Do not dump the DBs in <event list>. Stacks.
#  <event_list>
#
# --exclude-routines/tables/triggers/users - Do not dump events/tables/triggers/users in said list. Stacks.
#
# --extended-insert=<N> 	 - Write INSERT statements using multiple-row syntax that includes several VALUES lists.
# 										Results in smaller dump file and speeds up inserts when the file is reloaded.
#
# 										Option value indicates number of rows to include in each INSERT statement. Defaults to 250.
# 										This means the total of 250 rows are bound to a INSERT statement in terms of list relation.
#
# --hex-blob 					-  Binary colums are converted to hexadecimal. BINARY, VARBINARY, BLOB and BIT are affected.
#
# --host=<host name>,      -  Dump data from the MySQL server on the given host.
#  -h <host name>
#
# --include-databases/events/routines/tables/triggers/user= Dump the databases/events/routines/tables/triggers/users in the respective list. Stacks. 		-  
# 	 <db_list>
#
# --insert-ignore 			- Write INSERT IGNORE instead of INSERT statements.
#
# --log-error-file= 			- Log warnings and errors by appending them to the named file. If this option is not given, mysqlpump writes warnings and 
# 									  errors to the std error output.
#
# --login-path=<name> 		- Read options from the named login path in the .mylogin.cnf login path file.
# 									  A "login path" is an option group containing options that specify which MySQL
# 									  to connect to and which acc to auth as. Create or modify with mysql_config_editor
#
# --max-allowed-packet=<N> - Max size of the buffer for client/server comm. Defaults to 24MB, max to 1gb
#   <file name>
#
# --net-buffer-length=<N>  - The initial size of the buffer for client/server comm. When creating multiple-row INSERT 
# 									  statements (as with the --extended-insert) - mysqlpump creates rows up to <N> bytes long.
#
# 									  If you use this option to increase the value - ensure that the MySQL server <net buffer length>
# 									  system var has a value at least this large.
#
# --no-create-db 				- Suppress any <CREATE DATABASE> statements that might otherwise be included in the output.
#
# --no-create-info, -t 		- Do not write <CREATE TABLE> statements that create each dumped table
#
# --parallel-schemas=[<N:> - Create a queue for processing the DBs in db_list. If N is given, the queue uses N threads.
#  <db list>] 					  If N is not defined - --default-parallelism defines the number of queue threads.
#
# 									  Multiple instances of this option creates multiple queues. Also creates a default queue to use
# 									  for DBs not named in any --parallel-schemas option - and for dumping user definitions if command
# 									  options select them.
#
# --password[=<password>], - The PW to use for connecting to the server. If -p is used - cannot have space between designation.
#  -p [<password>] 			  
#
# --plugin-dir=<dir name>  - The dir where to look for plugins. Specify this option if the --default-auth option is used to specify
# 									  an auth plugin but mysqlpump doesn ot find it.
#
# --port=<port num>, 	   - The TCP/IP port number to use for the connection
#  -P <port_num>
#
# --print-defaults 			- Print the program name and all options that it gets from option files
#
# --protocol= 					- Protocol to use
#  {TCP|SOCKET|PIPE|MEMORY}
#
# --replace 					- Write REPLACE statements rather than INSERT statements
#
# --result-file=<file name>- Direct output to the named file. Result file is created and its previous contents overwritten,
# 									  even if an error occurs while generating the dump.
#
# 									  Should be used on Windows to prevent \n from being converted to \r\n
#
# --routines 					- Include stored routines (procedures and functions) for the dumped DB in the output.
# 									  Requires the global SELECT priv.
#
# 									  output generated by using --routines contains CREATE PROCEDURE and CREATE FUNCTION statements to 
# 									  create the routines.
#
# 									  Enabled by default, use --skip-routines to disable it.
#
# --secure-auth 				- REMOVED
#
# --set-gtid-purged=<value>- Enables control over global transaction ID (GTID) info written to the dump file, by indicating whether
# 									  to add a SET @@global.gtid purged statement to the output.
#
# 									  This option may also cause a statement to be written to the output that disables binary logging
# 									  while the dump file is being reloaded.
#
# 									  Defaults: AUTO
# 									  OFF --> No SET statement in the output
# 									  ON  --> Add a SET statement to the output. Error occurs if GTIDs are not enabled on the server.
# 									  AUTO -> Add a SET statement to the output if GTIDs are enabled on the server.
#
# 									  The --set-gtid-purged option has the following effect on binary logging when the dump file is reloaded:
#
# 									  --set-gtid-purged=OFF:SET @@SESSION.SQL_LOG_BIN=0; is not added to the output
# 									  --set-gtid-purged=ON:SET @@SESSION.SQL_LOG_BIN=0; is added to the output
# 									  --set-gtid-purged=AUTO:SET @@SESSION.SQL_LOG_BIN=0; is added to the output if GTIDs are enabled on the server
# 									  you are backing up (that is - if AUTO is evaluated as ON)
#
# --single-transaction 		- Sets the transaction isolation mode to REPEATABLE READ and sends a START TRANSACTION SQL statement to the server before dumping data.
# 									  It is useful only with transactional tables such as InnoDB, because then it dumps the consistent state of the DB
# 									  at the time when START TRANSACTION was issued without blocking any app.
#
# 									  Only InnoDB tables are dumped in a consistent state. For example - MyISAM or MEMORY tables dumped while using this
# 									  may still change state.
#
# 									  While a --single-transaction dump is in process, to ensure a valid dump file (correct table contents and binary log coords)
# 									  no other connection should use the following statements:
#
# 									  ALTER TABLE, CREATE TABLE, DROP TABLE, RENAME TABLE, TRUNCATE TABLE
#
# 									  a consistent read is not isolated from those statements - so use of them on a table to be dumped
# 									  can cause the SELECT that is performed by mysqlpump to retrieve the table contents to obtain
# 									  incorrect contents or fail.
#
# 								     --add-locks is exclusive against --single-transaction
#
# --skip-definer 				- Omit DEFINER and SQL SECURITY clauses from the CREATE statements for views and stored programs. The dump file,
# 									  when reloaded - creates objects that use the default DEFINER and SQL SECURITY values.
#
# --skip-dump-rows, 			- Do not dump table rows
#  -d
#
# --socket= 						- For connections to localhost, the Unix socket file to use - or on Windows, name of the named pipe to use
# {<file name>|<pipe name>}, 
# -S {<file name>|<pipe name>}
#
# --ssl* 							- Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys/certs
#
# --ssl-fips-mode= 				- Whether to use fips mode on client. 
#  {OFF|ON|STRICT}
#
# --tls-version=<protocol list> - The protocols permitted by the client for encrypted connections.
#
# --triggers 						- Include triggers for each dumped table in the output.
# 										  Enabled by default - use --skip-triggers to disable it
#
# --tz-utc 							- Enables TIMESTAMP columns to be dumped and reloaded between servers in different time zones.
# 										  mysqlpump Sets its connection time zone to UTC and adds SET TIME_ZONE='+00:00' to the dump file.
#
# 										  Without this option - TIMESTAMP columns are dumped and reloaded in the time zones local to the source
# 										  and destination server - which can cause the values to change if servers are in different time zones.
# 
# 										  --tz-utc also protects against changes due to daylight saving time.
#
# 										  Enabled by default, use --skip-tz-utc to disable it
#
# --user=<user name>, 		   - Name of MySQL user to connect with
#  -u <user_name>
#
# --users 							- Dump user accs as logical definitions in the form of CREATE USER and GRANT statements.
# 											
#                               User definitions are stored in the grant tables in the mysql system database. By default, mysqlpump
# 										  does not include the grant tables in mysql database dumps.
#
# 										  To dump the contents of the grant tables as logical definitions - use the --users option and suppress
# 										  all database dumping:
#
# 										  mysqlpump --exclude-databases=% --users
#
# --version, -V 					- Display version info and exit
#
# --watch-progress 				- Periodically display a progress indicator that provides info about the completed and total number of tables, rows, etc.
# 										  On by default - --skip-watch-progress to disable it
#
# The following section covers mysqlpump Object Selection
#
# mysqlpump has a set of inclusion and exclusion options that enable filtering of several object types and control which objects to dump:
#
# --include-databases and --exclude-databases apply to databases and all objects within them
# --include-tables and --exclude-tables apply to tables. These options also affect triggers associated with tables unless the trigger-specific
# 																			options are given.
# --include-triggers and --exclude-triggers - apply to triggers
#
# --include-routines and --exclude-routines - apply to stored procedures and functions. If a routine option matches a stored
# 															 function of the same name.
#
# --include-events and --exclude-events - apply to Event Scheduler events
#
# --include-users and --exclude-users - apply to user accounts
#
# Any inclusion or exclusion option may be given multiple times. Stacks. Order of options does not matter.
# The value of each inclusion and exclusion option is a list of namings
#
# --exclude-databases=test,world
# --include-tables=customer,invoice
#
# Wildcard chars are permitted (% as sequence, _ as regex against singular char)
#
# Example: --include-tables=t%, _____tmp matches all table names that begin with t - and all len(5) table names that end with tmp
#
# For users, a name specified without a host part is interpreted with an implied host of %.
# For example: u1 and u1@% are equivalent.
#
# Inclusion and exclusion options interact as follows:
#
# With no inclusion or exclusion options - mysqlpump dumps all databases (with a few notable exceptions)
#
# If inclusion options are given in the absence of exclusion options - only the objects named as included are dumped.
#
# If exclusion options are given in the absence of inclusion options - all objects are dumped except those named as excluded.
#
# If inclusion and exclusion options are given - all objects named as excluded and not named as inlcuded are not dumped. All others are.
#
# If multiple DBs are being dumped - it is possible to name tables, triggers and routines in a specific database by qualifying 
# the object names with the DB name.
#
# Example:
#
# mysqlpump --include-databases=db1,db2 --exclude-tables=db1.t1,db2.t2 #Dumps db1 and db2, but excludes specific tables
#
# The following options provide alternative ways to specify which DB to dump:
#
# The --all-databases option dumps all DBs (with certain exceptions). Equivalent to specifying no object options at all
#
# --include-databases=% is similar to --all-databases, but selects all databases for dumping, even those that are exceptions for --all-databases
#
# The --databases option causes mysqlpump to treat all name args as names of DBs to dump.
# Equivalent to an --include-databases option that names the same DBs.
#
# mysqlpump Parallel Processing
#
# mysqlpump can use parallelism to achieve concurrent processing. You can select concurrency between DBs (to dump multiple DBs at once)
# and within DBs (to dump multiple objects from a given DB simultaneously)
#
# By default - mysqlpump sets up one queue with two threads. You can create additional queues and control the number of threads assigned
# to each one - including the default queue:
#
# --default-parallelism=<N> specifies the default number of threads used for each queue. In the absence of this Option, N is 2.
#
# 									 The default queue always uses the default number of threads. Additional queues use the default number of threads
# 									 unless you specify otherwise.
#
# --parallel-schemas=[<N:>] sets up a processing queue for dumping the DBs named in <db_list> and optionally specifies how many
#  <db_list> 					 threads the queue uses.
#
# 									 <db_list> is a list of DB names. If the option argument begins with <N:>, the queue uses <N> threads.
# 									 Otherwise, the --default-parallelism option determines the number of queue threads.
#
# 									 Multiple instances of the --parallel-schemas option create multiple queues.
#
# 									 Names in the database list are permitted to contain the same % and _ wildcards as filtering.
#
# mysqlpump uses the default queue for processing any DBs not named explicitly with a --parallel-schemas option, and for dumping 
# user defs if cmd options select them.
#
# In general - with multiple queues, mysqlpump uses parallelism between the sets of DBs processed by the queues, to dump multiple
# DBs at once.
#
# For a queue that uses multiple threads, mysqlpump uses parallelism within DBs - to dump multiple objects from a given DB at once.
# Exceptions can occur; for example, mysqlpump may block queues while it obtains from the server lists of objects in DBs.
#
# With parallelism on - it is possible for output from different DBs to interleave. For example, INSERT statements from multiple
# tables dumped in parallel can be interleaved - they are not written in any specific order.
#
# Does not affect reloading because output statements qualify object names with DB names or are preceded by USE statements as required.
#
# The smallest scope of parallelism - is a single DB.
#
# Example:
#
# mysqlpump --parallel-schemas=db1,db2 --parallel-schemas=db3 #Partition db1 and db2 to a specific queue, another to Db3 - and a default for the rest. All queues use two threads.
#
# mysqlpump --parallel-schemas=db1,db2 --parallel-schemas=db3 --default-parallelism=4 #Same as above, except 4 threads for each queue
#
# We can also further partition thread usage if we wish:
#
# mysqlpump --parallel-schemas=5:db1,db2 --parallel-schemas=3:db3 #Run with 5 threads for queue related to db1 and db2, run with 3 for queue on db3, 2 for default to rest
#
# We can also disable multi-threading and allocate no queues
#
# --default-parallelism=0 and no --parallel-schemas options - runs a single-threaded process and creates no queues.
#
# The following pertains to mysqlpump in terms of restrictions
#
# mysqlpump does not dump the performance_schema, ndbinfo or sys schema by default. To dump any of said ones, name them
# explicitly on cmd line. Can also name them with --databases or --include-databases option
#
# mysqlpump does not dump the INFORMATION_SCHEMA schema
#
# mysqlpump does not dump InnoDB CREATE_TABLESPACE statements
#
# mysqlpump dumps user accounts in logical form using CREATE USER and GRANT statements (for example - when using the --include-users or --users option)
# For this reason, dumps of the mysql system DB do not by default include the grant tables that contain user defs:
#
# user,db,tables_priv, columns_priv, procs_priv or proxies_priv. To dump any of the grant tables, name the mysql DBs by the table names:
#
# mysqlpump mysql user db ...
#
# The following section pertains to mysqlshow.
#
# The mysqlshow client can be used to quickly see which DB exists, their tables or a table's columns or indexes.
#
# mysqlshow provides a cmd-line interface to several SQL SHOW statements. The same info can be obtained by using those statements directly.
# For example - we can issue them from the mysql client program.
#
# mysqlshow [<options>] [<db_name> [<tbl_name> [<col_name>]]]
#
# If no DB is given - a list of DB names is shown.
# If no table is given - all matching tables in the DB are shown.
# If no column is given - all matching columns and column types in the table are shown.
#
# The output displays only the names of those databases, tables or columns for which you have some privs.
# 
# If the last argument contains shell or SQL wildcard chars (*, ?, %, or _) - only those names that are matched
# by the wildcard are shown. If a DB name contains any underscores - those should be escaped with // or /.
#
# * and ? are converted into SQL % and _ wildcard chars. This might cause some confusion when you try to display
# the columns for a table with a _ in the name, because in this case - mysqlshow shows you only the table names
# that match the pattern.
#
# Can be fixed by adding an extra % last on the cmd line as a arg
#
# mysqlshow can utilize the following options:
#
# 		Format 					Desc
# --bind-address 	 Use specified network interface to connect to MySQL server
# --compress 		 Compress all information sent between client and server
# --count 			 Show the number of rows per table
# --debug 			 Write debugging log
#
# --debug-check 	 Print debug info when program exits
# --debug-info 	 Print debug info, memory and CPU stats when exiting
# --default-auth 	 Auth plugin to use
# --default-char-  Specify default charset
#   set
# --defaults-extra- Read named option file in addition to usual option files
#   file
#
# --defaults-file  Read only named option file
# --defaults-group Option group suffix value
#  -suffix
#
# --enable-cleartext Enable cleartext Auth plugin
#  -plugin 			 
# --get-server-      Request RSA public key from server
#   public-key
# --help 				Display help message and exit
# --host 				Connect to MySQL server on given host
# --keys 				Show table indexes
# --login-path 		Read login path options from .mylogin.cnf
# --no-defaults 		Read no option files
#
# --password 			Password to use when when connecting to server
# --pipe 				On Windows, connect to server using named pipe
# --plugin-dir 		Dir where plugins are installed
# --port 				TCP/IP port number for connection
# --print-defaults 	Print default options
#
# --protocol 			Connection protocol to use
# --secure-auth 		REMOVED
# --server-public-   Path name to file containing RSA public key
#   key-path
# --shared-memory    Name of the shared memory to use for shared-memory connections
#  -base-name
# --show-table-type 	Show a column indicating the table type
# --socket 				For connections to localhost, the Unix socket file to use
# --ssl-ca 				File that contains list of trusted SSL Cert Auths
#
# --ssl-capath 		Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 			File that contains X.509 cert
# --ssl-cipher 		List of permitted ciphers for connection encryption
# --ssl-crl 			File that contains cert revocation lists
# --ssl-crlpath 		Dir that contains cert revocation list files
# --ssl-fips-mode 	Whether to enable FIPS mode on the client side
#
# --ssl-key 			File that contains X.509 key
# --ssl-mode 			Security state of connection to server
# --status 				Display extra information about each table
# --tls-version 		Protocols permitted for enc. connections
# --user 				MySQL user name to use
# --verbose 			Verbose
# --version 			Verison info and exit
#
# --help, -? - Display a help message and exit
# --bind-address=<ip address> - On a computer having multiple network interfaces, use this to select which interface to use for connecting to the MySQL server.
# --character-sets-dir=<dir name> - The dir where char sets are installed
#
# --compress, -C - Compress all info sent between client and server if both support it
# --count - Show number of rows per table. Can be slow for non-MyISAM tables.
# --debug[=<debug options>], - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>. Defaults to d:t:o
#  -# [<debug_options>]
# --debug-check - Print some debug info when the program exits
# --debug-info - Print debbug info, memory and CPU usage stats upon exit
# --default-character-set=<charset name> - Use <charset_name> as default char set
#
# --default-auth=<plugin> - Hint about client-side auth plugin to use
# --defaults-extra-file=<file name> - Read this option file after the global option file but (on Unix) before the user option file.
# 											     Relative if relative, absolute if absolute - error raised if inaccessible or lack of perms.
# --defaults-file=<file name> - Use only said file. Still uses .mylogin.cnf - relative if relative, absolute if absolute.
# --defaults-group-suffix=<str> - Regex suffix matching
# 
# //cleartext, get-server-public-key
#
# --keys, -k - Show table indexes
# --host=<host name>, - Connect to MySQL server on the given host 
#  -h <host_name>
# --login-path=<name> - options from the named login path in the .mylogin.cnf - option group for MySQL server to connect to and which acc to auth as
# --no-defaults - Still reads .mylogin.cnf
# --password[=<password>], -p [<password>] - pw to use, normal dynamics in relation to no space 
# --pipe, -W - connect using named pipe. Only applies if named-pipe connections are supported
# --plugin-dir=<dir name> - Where to look for plugins, use if --default-auth can't find
#
# --port=<port num>, -P <port_num> - TCP/IP port to use for connection
# --print-defaults - Print the program name and all options that it gets from option files.
# --protocol={TCP|SOCKET|PIPE|MEMORY} - The protocol to use for the connection
# --secure-auth - REMOVED
# --server-public-key-path=<file name> - Path name to a file containing a client-side copy of the public key required by the server for RSA key pair
# 													  exchange. Must be PEM, applies to sha256_password or caching_sha2_password auth plugin.
#
# 													  Ignored for accounts that do not authenticate with said things. Also ignored if 
# 													  RSA-based PW exchange is not used.
#
# 													  If --server-public-key-path=<file name> is given and specifies a valid public key - it takes precedene over
# 													  --get-server-public-key
#
# 													  For sha256_password, this applies only if MySQL was built using OpenSSL.
#
# --shared-memory-base-name=<name> 		  On Windows, shared-memory name to use for connections made using shared memory to a local server.
# 													  Defaults to MYSQL - case-sensitive. Must be started with --shared-memory to enable shared-memory connections
#
# --show-table-type, -t 					  Show a column indicating the table type - as in SHOW FULL TABLES. The type is BASE TABLE or VIEW.
#
# --socket=<path>, -S <path> 				  For connections to localhost, the Unix socket file to use or on Windows the named pipe to use
#
# --ssl* 										  Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to find SSL keys and certs.
#
# --ssl-fips-mode={OFF|ON|STRICT} 		  etc.
#
# --status, -i 								  Display extra info about each table
# --tls-version=<protocol list> 			  Protocols allowed for secure connections
# --user=<user name>, -u <user_name> 	  The MySQL user name to use when connecting to the server
# --verbose, -v 								  Verbose mode, stacks
# --version, -V 								  Display version info and exit
#
# The following covers mysqlslap , used for diagnostics to emulate client load for a MySQL Server and to report timing of each stage.
#
# The interaction is emulating as if multiple clients are accessing the server.
#
# mysqlslap [<options>]
#
# Some options such as --create or --query enables you to specify a string containing an SQL statement or a file containing statements.
# If it specifies a file - it must contain one statement per line. (Implicit delimiter is \n)
#
# Use the --delimiter to specify a different delimiter - which allows us to span multiple lines or place multiple statements on a single line.
# Comments cannot be included in terms of mysqlslap
#
# It runs in three stages:
#
# Create schema, table and optionally any stored programs or data to use for the test. This stage uses a single client connection
# 
# Run the load test. Can use many client connections
#
# Clean up (disconnect, drop table if specified) - uses a single client connection
#
# An example of 50 clients, 200 selects for each - created query integrated:
#
# mysqlslap --delimiter=";" 
#   --create="CREATE TABLE a (b int);INSERT INTO a VALUES (23)"
#   --query="SELECT * FROM a" --concurrency=50 --iterations=200
#
# Let mysqlslap build the query SQL statements with a table of two INT and Three VARCHAR columns.
# Use five clients querying 20 times each. 
#
# Do not create the table or insert the data (that is - use previous test's schema and data):
#
# mysqlslap --concurrency=5 --iterations=20 #5 clients, 20 times each
#   --number-int-cols=2 --number-char-cols=3 #2 int, 3 char
#   --auto-generate-sql #Auto build the query statements
#
# Tell the program to load the create, insert and query SQL statements from the specified files - where the
# create.sql has multiple table creation statements delimited by ';' and multiple insert statements delimited by
# ';'
#
# In this instance, the Query file has multiple queries delimited by ';'. Run all of em, then run all
# the queries in the query file with five clients (five times each):
#
# mysqlslap --concurrency=5
#   --iterations=5 --query=query.sql --create=create.sql
#   --delimiter=";"
#
# mysqlslap supports the following options - which can be specified on the cmd line or in the [mysqlslap] and [client]
# groups of an option file.
#
# Format 										Desc
# --auto-generate-sql 			Generate SQL statements automatically when they are not supplied in files or using command options
# --auto-generate-sql 			Add AUTO_INCREMENT column to automatically generated tables
#  -add-autoincrement
# --auto-generate-sql-/[execute-number, guild-primary, load-type, secondary-indexes, unique-query-number, unique-write-number, write-number]
# 										
# 										Number of queries/GUID based primary key to auto generate tables/Test load type
# 										Number of secondary indexes to add to automated generated tables/
# 									   Number of unique queries for automated tests/
# 										Number of unique queries for --auto-generate-sql-write-number/
# 										Number of row inserts to perform on each thread
# --commit 							Number of statements to execute before committing
# --compress 						Compression of info between client and server
#
# --concurrency 					Number of clients to simulate when issuing the SELECT statement
# --create 							File or string containing the statement to use for creating the table
# --create-schema 				Schema in which to run the tests
# --csv 								Generate output in comma-separated values format
# --debug 							Write debugging log
#
# --debug-check 					Print debugging information when program exits
# --debug-info 					Print debugging information, memory and CPU stats when exiting
# --default-auth 					Auth plugin to use
# --defaults-extra-file 		Read named option file in addition to usual option files
# --defaults-file 				Read only named option file
#
# --defaults-group-suffix 		Option group suffix value
# --delimiter 						Delimiter to use in SQL statements
# --detach 							Detach (close and reopen) each connection after each <N> statements
# --enable-cleartext-plugin 	Enable cleartext auth plugin
#
# --engine 							Storage engine to use for creating the table
# --get-server-public-key 		Request RSA public key from server
# --help 							Display help msg and exit
# --host 							Connect to MySQL servers or given host
# --iterations 					Number of times to run the tests
# --login-path 					Read login path options from .mylogin.cnf
# --no-defaults 					Read no option files
# --no-drop 						Do not drop any schema created during the test run
#
# --number-char-cols 			Number of VARCHAR columns to use if --auto-generate-sql is specified
# --number-int-cols 				Number of INT columns to use if --auto-generate-sql is specified
# --number-of-queries 			Limit each client to approx this number of queries
# --only-print 					Do not connect to databases, mysqlslap only prints what it would have done
# --password 						Password to use when connecting to server
# --pipe 							On Windows, connect to server using named pipe
#
# --plugin-dir 					Dir where plugins are installed
# --port 							TCP/IP port number for connection
# --post-query 					File or string containing the statement to execute after the tests have completed
# --pre-query 						File or string containing the statements to execute before running the tests
# --pre-system 					String to execute using system() before running the tests
# --print-defaults 				Print default options
# --protocol 						Connection protocol to use
#
# --query 							File or string containing the SELECT statement to use for retrieving data
# --secure-auth 					REMOVED
# --server-public-key-path 	Path name to file containing RSA public key
# --shared-memory-base-name 	The name of shared memory to use for shared-memory connections
# --silent 							Silent mode
# --socket 							For connections to localhost, the Unix socket file to use
#
# --sql-mode 						Set SQL mode for client session
# --ssl-ca 							File that contains list of trusted SSL cert auths
# --ssl-capath 					Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 						File that contains X.509 cert
# --ssl-cipher 					List of permitted ciphers for connection encryption
# --ssl-crl 						File that contains cert revocation lists
# --ssl-fips-mode 				Enabling fips mode on client side
#
# --ssl-key 						File that contains X.509 key
# --ssl-mode 						Security state of connection to server
# --tls-version 					Protocols permitted for encrypted connections
# --user 							MySQL user name to use when connecting to server
# --verbose 						Verbose mode
# --version 						Display version info and exit
#
# --help, -? - Display help and exit
# --auto-generate-sql, -a - Generate SQL statements automatically when they are not supplied in files or using command options
# --auto-generate-sql-add-autoincrement - Add an AUTO_INCREMENT column to automatically generated tables
# --auto-generate-sql-execute-number=<N> - Specifies how many queries to generate automatically
#
# --auto-generate-sql-guid-primary - Add a GUID based primary key to automatically generated tables
# --auto-generate-sql-load-type=<type> - Specify the test load type. The permissible values are:
#
# 													  read - Scans tables
# 													  write - Inserts into tables
# 													  key - Read primary keys
# 													  update - update primary keys
# 													  mixed - half inserts, half scanning selects.
#
# 													  Defaults to mixed.
#
# --auto-generate-sql-secondary-indexes= - Specifies how many secondary indexes to add to automatically generated tables. Defaults to none.
#  <N>
# --auto-generate-sql-unique-query-number= - How many different queries to generate for automatic tests. For example - if you run a key
#  <N> 													test that performs 1000 selects - you can use this option with a value of 1000 to run 1000 unique Queries.
#  													   Defaults to 10.
#
# --auto-generate-sql-unique-write-number= - How many different queries to generate for --auto-generate-sql-write-number. Defaults to 10.
#  <N>
# --auto-generate-sql-write-number=<N> 	 - How many row inserts to perform. Defaults to 100.
# --commit=<N> 									 - How many statements to execute before committing. Defaults to 0.
# --compress, -C 									 - Compress all info sent between client and server, if both support compression.
# --concurrency=<N>, -c <N> 					 - Number of parallel clients to simulate
# --create=<value> 								 - File or string containing statement to use for creating the table
# --create-schema=<value> 						 - The schema in which to run the tests. If --auto-generate-sql is also denoted - mysqlslap drops the schema
# 															at the end of the test run.
#
# 															To avoid - use --no-drop as well.
# --csv[=<file name>] 							 - Generate output in comma separated values format. Output goes to named file - or to STD out if no file
# --debug[=<debug options>], 					 - Write a debug log. A typical <debug_options> is d:t:o, <file_name> - defaults to d:t:o, /tmp/mysqlslap.trace
#  -# [<debug_options>]
# --debug-check 									 - Print some debug info when the program exits
# --debug-info, -T 								 - Print debug info, memory and CPU usage stats when exiting.
# --default-auth=<plugin> 						 - A hint about the client side auth plugin to use
# --defaults-extra-file= 						 - Read this option file after the global option file but (on Unix) before the user option file. 
#   <file name>  										If it does not exist/not found - error is thrown. Relative path is interpreted, absolute as absolute
# --defaults-file= 								 - Use only the given option file. relative if relative, absolute if absolute.
#   <file name> 										Still reads .mylogin.cnf
# --defaults-group-suffix 						 - Read not only the usual option groups - but also the regex suffix
#   =<str>
# --delimiter=<str>, 							 - Delimiter to use in the SQL statement supplied in files or using the CMD options.
#  -F <str>
# --detach=<N> 									 - Detach (close and reopen) each connection afer each <N> statements. Default is 0 (connections are not detached)
#
# --enable-cleartext-plugin 					 - Enable the mysql_clear_password cleartext auth plugin
# --engine=<engine name>, 						 - Storage engine to use for creating tables 
#  -e <engine_name>
# --get-server-public-key 						 - Request from the server the RSA public key that it uses for key pair-based PW exchange.
# 															Applies to clients that connect with caching_sha2_password Auth plugin.
#
# 															etc.
#
# --host=<host name>, 							 - Connect to the MySQL server on the given host.
#  -h <host_name>
# --iterations=<N>, 								 - Number of times to run the tests
#  -i <N>
# --login-path=<name> 							 - Read options from the named login path in the .mylogin.cnf path file.
# --no-drop 										 - Prevent mysqlslap from dropping any schema it creates during the test run.
# --no-defaults 									 - Do not read any option files. Exception is .mylogin.cnf
# --number-char-cols=<N>, 						 - Number of VARCHAR columns to use if --auto-generate-sql is specified
#  -x <N>
# --number-int-cols=<N>, 						 - Number of INT columns to use if --auto-generate-sql is specified
#  -y <N>
# --number-of-queries=<N> 						 - Limit each client to approximately this many queries. Query counting takes into account
# 															the statement delimiter. 
# 															
# 															For example - if you invoke mysqlslap as follows, the ; delimiter
# 															is recognized so that each instance of the query string counts as two queries.
# 					
# 															As a result - 5, in this case - not 10 - are inserted.
#
# 															mysqlslap --delimiter=";" --number-of-queries=10
# 																--query="use test;insert into t values(null)"
#
# --only-print 									 - Do not connect to DBs. Only prints what it would have done.
# --password[=<password>],  					 - Normal dynamics
#  -p [<password>]
# --pipe, -W 										 - Connect to the server using a named pipe. Applies only if the server supports named-pipe connections
# --plugin-dir=<dir name> 						 - The dir in which to look for plugins.
# --port=<port num>, 							 - TCP/IP port number to use for the connection
#  -P <port_num>
# --post-query=<value> 							 - File or string containing the statement to execute after the tests have completed.
# 															Execution is not counted for timing purposes.
# --post-system=<str> 							 - String to execute using system() after the tests have completed.
# 															Not counted for timing purposes.
# --pre-query=<value> 							 - File or string containing the statement to execute before running the tests.
# --pre-system=<str> 							 - The string to execute using system() before running the tests. Not counted for timing purposes
#
# --print-defaults 								 - Print the program name and all options that it gets from option files.
# --protocol={TCP|SOCKET|PIPE|MEMORY} 		 - Connection protocol to use for connecting to the server.
# --query=<value>, 								 - File or string containing the SELECT statements to use for retrieving data
#  -q <value>
# --secure-auth 									 - REMOVED
# --server-public-key-path=<file name> 	 - Path name to file containing client-side copy of the public key etc.
# --shared-memory-base-name=<name> 			 - On Windows, shared-memory name to use for connections made using shared memory to a local server.
#  														Only applies if the server supports shared-memory connections.
# --silent, -s 									 - Silent mode. No output.
# --socket=<path>, -S <path> 					 - For connections to localhost, the Unix socket file to use or on Windows - the named pipe to use.
# --sql-mode=<mode> 								 - Set the SQL mode for the client session
# --ssl* 											 - Indications of where to find certs, keys and wether to connect with SSL
# --ssl-fips-mode={OFF|ON|STRICT} 			 - Wether to enable FIPS mode on the client side.
# --tls-version=<protocol list> 				 - The protocols permitted by the client for encrypted connections.
# --user=<user name>, 							 - The MySQL user name to use when connecting to the server
#  -u <user_name>
#
# --verbose, -v 									 - Verbose mode. Stacks.
# --version, -V 									 - Display version info and exit.
#
# The following section covers Administrative and Utility programs
#
# The following pertains to ibd2sdi - InnoDB Tablespace SDI Extraction Utility
#
# ibd2sdi is a utility for extracting serialized dictionary information (SDI) from InnoDB tablespace files.
# SDI data is present all persistent InnoDB tablespace files.
#
# ----------------------------------------------
# SDI:
#
# Dictionary object metadata in a serialized form. SDI is stored in JSON format.
#
# >= 8.0.3, SDI is present in all InnoDB tablespace files except for temp tablespace and undo tablespace files.
# The presence of SDI in tablespace files provides metadata redundancy. For example - dictionary object metadata
# can be extracted from tablespace files using the ib2sdi utility if the data dictionary becomes unavailable.
#
# For a MyISAM table, SDI is stored in a .sdi metadata file in the schema dir. 
# An SDI metadata file is required to perform an IMPORT TABLE operation.
# 															
# ----------------------------------------------
#
# ibd2sdi can be run on:
# file-per-table tablespace files (*.ibd files), 
# general tablespace files (*.ibd files),
# system tablespace files (ibdata* files),
# data dict tablespace (mysql.ibd) 
#
# It is not supported for use with temp tablespaces or undo tablespaces.
#
# ib2sdi can be used at runtime or while the server is offline. 
# During DDL operations, ROLLBACK operations, and to undo log purge operations related to SDI.  
# There may be a short interval of time when ibd2sdi fails to read SDI data stored in the tablespace.
#
# ibd2sdi performs an uncommitted read of SDI from the specified tablespace. Redo logs and undo logs are not accessed.
# To invoke the ibd2sdi:
#
# ib2sdi [<options>] <file_name1> [<file_name2> <file_name3> ...]
#
# ibd2sdi supports multi-file tablespaces like the InnoDB system tablespace - but it cannot be run on more
# than one tablespace at a time.
#
# For multi-file tablespaces:
#
# ibd2sdi <ibdata1 ibdata2>
#
# The files of a multi-file tablespace must be specified in order of the ascending page number.
# If two successive files have the same space ID - the later file must start with the 
# last page number of the previous file + 1.
#
# ibd2sdi outputs SDI (containing id, type and data fields) in JSON format.
#
# ibd2sdi Options
#
# ibd2sdi supports the following options:
#
# --help, -h
#
# ibd2sdi --help
# USAGE: 	/ibd2sdi [-v] [-c <strict-check>] [-d <dump file name>] [-n] <filename1> [<filenames>]
# See http://dev.mysql.com/doc/refman/8.0/en/ibd2sdi.html for usage hints:
#
# -h, --help - Display help and exit
# -v, --version - Display version info and exit
# -#, --debug[=<name>] - Output debug log. see -> http://dev.mysql.com/doc/refman/8.0/en/dbug-package.html
# -d, --dump-file=<name> - Dump the tablespace SDI into the file passed by user.
# 									Without the filename, it will default to stdout
# -s, --skip-data - Skip retrieving data from SDI records. Retrieve only id and type
# -i, --id=<#> - Retrieve the SDI record matching the id passed by user
# -t, --type=<#> - Retrieve the SDI records matching the type passed by user
# -c, --strict-check=<name>
# 		Specify the strict checksum algo by the user.
# 		Allowed values are innodb, crc32, none
# -n, --no-check - Ignore the checksum verification
# -p, --pretty - Pretty format the SDI output. 
#     If false, SDI would be not human readable but it will be of less size
# 		(Defaults to on;  use --skip-pretty to disable)
#
# Variables (--variable-name=<value>) and boolean options {FALSE|TRUE} 
# debug 			(NO DEFAULT)
# dump-file 	(NO DEFAULT)
# skip-data 	FALSE
# id 				0
# type 			0
# strict-check crc32
# no-check 		FALSE
# pretty 		TRUE
#
# --version, -v - Displays MySQL version info. 
#
#  ibd2sdi --version
#  ibd2sdi Ver 8.0.3-dmr for Linux on x86_64 (Source distri)
#
# --debubg[=<debug options>], - Prints a debug log.
#  -# [<debug_options>]
#  
# 	ibd2sdi --debug=d:t /tmp/ibd2sdi.trace
#
# --dump-file=, -d - Dumps serialized dictionary info (SDI) into the specified dump file. 
#   If a dump file is not specified, the  tablespace SDI is dumped to stdout.
#
#   ibd2sdi --dump-file=<file_name>  ../data/test/t1.ibd
# 
# --skip-data, -s - Skip retrieval of data field values from the serialized dictionary information (SDI) and only
#                   retrieves ID, type field values - which are primary keys for SDI records.
#
# 						  ibd2sdi --skip-data ../data/test/t1.ibd
# 						  ["ibd2sdi"
#
# 						  {
# 								"type": 1,
# 							   "id": 330
# 						  }
# 						  ,
# 						  {
# 								"type": 2,
# 								"id": 7
# 						  }
# 						  ]
#
# --id=#, -i #
# 
# 	Retrieves SDI matching the specified table or tablespace object id. 
#  An object id is unique to the object type.
#
#  Table and tablespace object id's are also found in the id column of the mysql.tables and
#  mysql.tablespace data dir tables.
#
#  ibd2sdi --id=7 ../data/test/t1.ibd
#  ["ibd2sdi"
#  ,
#  {
# 		"type": 2,
# 		"id": 7,
# 		"object":
# 			{
# 		"mysqld_version_id": 80003,
# 		"dd_version": 80003,
# 		"sdi_version": 1,
# 		"dd_object_type": "Tablespace",
# 		"dd_object": {
# 			"name": "test/t1",
# 			"comment": "",
# 			"options": "",
# 			"se_private_data": "flags=16417;id=2;server_version=80003;space_version=1;"
# 			"engine": "InnoDB",
# 			"files": [
# 				{
# 					"ordinal_position": 1,
# 					"filename": "./test/t1.ibd",
# 					"se_private_data": "id=2;"
# 				}
# 			]
# 		}
#  }
#  }
#  ]
#
# --type=#, -t # - Retrieves SDI matching the specified object type. SDI is provided for table (type=1) and tablespace (type=2) objects:
# 
# ibd2sdi --type=2 ../data/test/t1.ibd
# ["ibd2sdi"
# ,
# {
# 		"type": 2,
# 		"id": 7,
# 		"object":
# 			{
# 		"mysqld_version_id": 80003,
# 		"dd_version": 80003,
# 		"sdi_version": 1,
# 		"dd_object_type": "Tablespace",
# 		"dd_object": {
# 			"name": "test/t1",
# 			"comment": "",
# 			"options": "",
# 			"se_private_data": "flags=16417;id=2;server_version=80003;space_version=1;"
# 			"engine": "InnoDB",
# 			"files": [
# 				{
# 					"ordinal_position": 1,
# 					"filename": "./test/t1.ibd",
# 					"se_private_data": "id=2;"
# 				}
# 			]
# 		}
# }
# }
# ]
#
# --strict-check, -c - Specifies a strict checksum algo for validating the checksum of pages that are read.
#   Options include innodb, crc32 and none.
#
# Strict of innodb - ibd2sdi --strict-check=innodb ../data/test/t1.ibd
# 
# Strict of crc32 - ibd2sdi -c crc32 ../data/test/t1.ibd
#
# If --strict-check is not specified, validation is performed against non-strict innodb, crc32 and none.
#
# --no-check, -n - Skip checksum validation for pages that are read - ibd2sdi --no-check ../data/test/t1.ibd
#
# --pretty, -p - Outputs SDI in JSON pretty print format. Enabled by default. 
#   If disabled, SDI is not human readable but is smaller in size. Use --skip-pretty to disable
# 
#   ibd2sdi --skip-pretty ../data/test/t1.ibd
#
# The following covers innochecksum - Offline InnoDB File Checksum Utility
#
# Innochecksum prints checksums for InnoDB files. 
#
# This tool reads an InnoDB tablespace file, calculates the checksum for each page, 
# compares the calculated checksum to the stored checksum and reports mismatches, 
# which indicate damaged pages.
#
# Originally developed to speed up verifying the integrity of tablespace files after power
# outages but can also be used after file copies.
#
# Because checksum mismatches cause InnoDB to deliberately shut down a running server,
# it may be preferable to use this tool rather than waiting for an in-production server to encounter the damaged pages.
#
# Innochecksum cannot be used on tablespace files that the server already has open.
# For such files, you should use CHECK TABLE to check tables within the tablespace.
#
# Attempting to run innochecksum on a tablespace that the server already has open will
# result in an "Unable to lock file" error.
#
# If checksum mismatches are found - you would normally restore the tablespace from backup
# or start the server and attempt to use mysqldump to make a backup of the tables within the tablespace.
#
# innochecksum [<options>] <file_name>
#
# innochecksum supports the following options. For options that refer to page numbers, the numbers are zero-based:
#
# --help, -? 
# innochecksum --help
#
# --info, -I
# Synonym for --help. Displays command line help.
# innochecksum --info
#
# --version, -V
# Displays version info
# innochecksum --version
#
# --verbose, -v
# Verbose mode; prints progress indicator to log file every five seconds. 
# 
# innochecksum --verbose - Verbose mode on
#
# innochecksum --verbose=FALSE - Verbose mode off
#
# --verbose and --log can be specified at the same time:
#
# innochecksum --verbose --log=/var/lib/mysql/test/logtest.txt
#
# To locate the progress indicator info in the log file - you can preform the following search:
#
# cat ./logtest.txt | grep -i "okay"
#
# Prints lines simply put of status, progress, etc.
#
# --count, -c - Prints a count of the number of pages in the file and exit.
# innochecksum --count ../data/test/tab1.ibd
#
# --start-page=<num>, -s <num> - Starts at this page number:
#
#  innochecksum --start-page=600 ../data/test/tab1.ibd
#
#  innochecksum -s 600 ../data/test/tab1.ibd
#
# --end-page=<num>, - End at this page number
#  -e <num>
# 							 --end-page=700 ../data/test/tab1.ibd
#
# 							 --p 700 ../data/test/tab1.ibd
# 
# --page=<num>, -p <num> - Check only this page number.
# 									innochecksum --page=701 ../data/test/tab1.ibd
#
# --strict-check, -C - Specify a strict checksum algo. Options include innodb, crc32 and none.
#
# 							  innochecksum --strict-check=innodb ../data/test/tab1.ibd #use innodb checksum
#
# 							  innochecksum -C crc32 ../data/test/tab1.ibd
#
# 							  The following conditions apply:
#
# 							  If you do not specify --strict-check - innochecksum validates against innodb, crc32 and none.
#
# 							  If none: only checksums generated by none are allowed
# 							  If innodb: only checksums generated by innodb are allowed
# 							  If crc32: only checksums generated by crc32 are allowed
#
# --no-check, -n - Ignore the checksum verification when rewriting a checksum. This option may only be used with the innochecksum
# 						 --write option. If the --write option is not specified - innochecksum will terminate.
#
# 						 Example of innodb checksum rewritten to replace invalid checksum:
#
# 						 innochecksum --no-check --write innodb ../data/test/tab1.ibd
#
# --allow-mismatches, - The max number of checksum mismatches allowed before innochecksum terminates.
#  -a 						Defaults to 0. If --allow-mismatches=<N>, where N>=0 - N mismatches are permitted and innochecksum terminates at N+1.
#
# 								When --allow-mismatches is set to 0, innochecksum terminates on the first checksum mismatch.
#
# 								In this example, an existing innodb checksum is written to set --allow-mismatches to 1.
#
# 								innochecksum --allow-mismatches=1 --write innodb ../data/test/tab1.ibd
#
# 								With --allow-mismatches set to 1, if there is a mismatch at page 600 and another at page 700 out of 1k pages
#
# 								If a mismatch at 600 and 700, it's updated for 0-599 - and 601-699 - terminates at second.
# 								Leaves 600 and 700-999 unchanged
#
# --write=<name>, 	 - Rewrite a checksum. When rewriting an invalid checksum, the --no-check option must be used together with
# 								the --write option.
#
# 								The --no-check option tells innochecksum to ignore verification of the invalid checksum.
# 								You do not have to specify the --no-check option if the current checksum is valid.
#
# 								An Algo must be specified when using the --write option. Possible values are:
#
# 								innodb - Checksum calculated in software, using the original algo from InnoDB
# 								crc32 - Checksum calculated using the crc32, possibly done with a hardware assist
# 								none - A constant number
#
# 								The --write option rewrites entire pages to disk. If the new checksum is identical to the existing
# 								checksum, the new checksum is not written to disk in order to minimize I/O.
#
# 								innochecksum obtains an exclusive lock when the --write option is used.
#
# 								In this example, a crc32 checksum is written for tab1.ibd:
#
# 								innochecksum -w crc32 ../data/test/tab1.ibd
#
# 								Here, we replace the invalid crc32 checksum:
#
# 								innochecksum --no-check --write crc32 ../data/test/tab1.ibd
#
# --page-type-summary, - Display a count of each page type in a tablespace. Example:
#  -S 						 innochecksum --page-type-summary ../data/test/tab1.ibd
#
# 								 Sample output for --page-type-summary:
#
# 								 File::./data/test/tab1.ibd
# 								 ====================PAGE TYPE SUMMARY===================
# 								 #PAGE_COUNT PAGE_TYPE
# 								 ========================================================
# 								 		2 		 Index page
# 										0      Undo log page
# 										1 		 Incode page
# 										0 		 Insert buffer free list page
# 										2 		 Freshly allocated page
# 										1 		 Insert buffer bitmap
# 									   0 		 System page
# 										0 		 Transaction system page
# 										1 		 File Space Header
# 										0 		 Extent descriptor page
# 										0 		 BLOB page
# 										0 		 Compressed BLOB page
# 									   0 		 Other type of page
# 								 =========================================================
# 								 Additional information:
# 								 Undo page type: 0 insert, 0 update, 0 other
# 								 Undo page state: 0 active, 0 cached, 0 to_free, 0 to_purge, 0 prepared, 0 other
#
# --page-type-dump,   - Dump the page type info for each page in a tablespace to stderr or stdout. Example:
#  -D 						innochecksum --page-type-dump=/tmp/a.txt ../data/test/tab1.ibd
#
# --log, -l 			 - Log output for the innochecksum tool. A log file name must be provided.
# 								Log output contains checksum values for each tablespace page.
#
# 								For uncompressed tables, LSN values are also provided. The --log replaces the --debug option,
# 								which was available in earlier releases. Example usage:
#
# 								innochecksum --log=/tmp/log.txt ../data/test/tab1.ibd
#
# 								innochecksum -l /tmp/log.txt ../data/test/tab1.ibd
#
# - Option
# Specify this to read from STD input.
# 								Specify the - option to read from STD input. 
# 								
# 								If the - option is missing when "read from standard in" is expected
# 								innochecksum will output innochecksum usage information indicating that the
# 								"-" option was omitted. Examples of usage:
#
# 								cat t1.ibd | innochecksum -
#
# 								In this example, innochecksum writes the crc32 checksum algorithm to a.ibd without
# 								changing the original t1.ibd file.
#
# 								cat t1.ibd | innochecksum --write=crc32 - > a.ibd
#
# The following section covers the case of running innochecksum on Multiple User-defined Tablespace files
#
# User defined tablespace files are denoted (.ibd)
#
# The following examples demonstrate how to run innochecksum on multiple user-defined tablespace files
#
# innochecksum ./data/test/*.ibd #Run innochecksum for all tablespace (.ibd) files in a DB called "test"
#
# innochecksum ./data/test/t*.ibd #Run innochecksum for all tablespace files (.ibd files) that start with t
#
# innochecksum ./data/*/*.ibd #Run innochecksum for all tablespace files (.ibd files) in the data dir
#
# Running innochecksum on multiple user-defined tablespace files is not supported on Windows OS, as Windows shells
# such as cmd.exe do not support glob pattern expansion.
#
# On Windows systems, innochecksum must be run separately for each user-defined tablespace file.
# 
# cmd> innochecksum.exe t1.ibd
# cmd> innochecksum.exe t2.ibd
# cmd> innochecksum.exe t3.ibd
#
# The following section covers innochecksum on Multiple System Tablespace Files
#
# By default - there is only one InnoDB system tablespace file (ibdata1) but multiple files for the system
# tablespace can be defined using the innodb data file path option.
#
# In the following example, three files for the system tablespace are defined using the innodb data file path option:
# ibdata1, ibdata2 and ibdata3
#
# ./bin/mysqld --no-defaults --innodb-data-file-path="ibdata1:10M;ibdata2:10M;ibdata3:10M:autoextend"
#
# The three above files form a logical system tablespace.
#
# To run innochecksum on multiple files that form one logical system tablespace - innochecksum requires the
# - option to read the tablespace file from Standard input - which equates to concatenating multiples files to creating one.
#
# To run the above, we would use:
#
# cat ibdata* | innochecksum -
#
# Windows CMD shell does not support globbing patterns - thus each file must be run seperately.
#
# The following covers myisam_ftdump - Used to display Full-Text Index information:
#
# myisam_ftdump displays info about FULLTEXT indexes in MyISAM tables.
# It reads MyISAM index files directly - so it must be run on the server host where the table is located.
#
# Before using myisam_ftdump, be sure to issue a FLUSH TABLES statement first if the server is running.
#
# myisam_ftdump scans and dumps the entire index - which is not fast. Does not need to be run often, however.
#
# To invoke the myisam_ftdump:
#
# myisam_ftdump [<options>] <tbl_name> <index_num>
#
# We can also specify the table name by naming its index file (a file with .MYI suffix).
#
# If we do not invoke the myisam_ftdump in the dir where the table files are located - the table
# or index file name must be preceded by the path name to the table's DB dir.
#
# Index numbers begin with 0.
#
# Assume the base of:
#
# CREATE TABLE mytexttable
# (
# 	 id 	INT NOT NULL, #Index 0
#   txt  TEXT NOT NULL, #Index 1
#   PRIMARY KEY (id),
#   FULLTEXT (txt)
# ) ENGINE=MyISAM;
#
# If the cwd is test DB dir, invoke myisam_ftdump:
#
# myisam_ftdump mytexttable 1
#
# If our path name to the test DB dir is /usr/local/mysql/data/test - you can also specify the table
# name arg using that path name.
#
# myisam_ftdump /usr/local/mysql/data/test/mytexttable 1
#
# We can also use myisam_ftdump to generate a list of index entries in order of frequency of occurence
# on Unix systems:
#
# myisam_ftdump -c mytexttable 1 | sort -r #-c is count, pipe the output and sort it - -r here is Recursive calling
#
# On Windows, can use:
#
# myisam_ftdump -c mytexttable 1 | sort /R - same as above, except /R is Recursive interaction on Windows
#
# The following options are supported by myisam_ftdump:
#
# --help, -h -? - Display a help message and exit
#
# --count, -c - Calculate per-word stats (counts and global weights)
#
# --dump, -d - Dump the index, include data offset and word weights
#
# --length, -l - Report length distribution
#
# --stats, -s - Report global index stats. Default operation if not other operation is specified
#
# --verbose, -v - Verbose. 
#
# The following section covers - myisamchk - a MyISAM Table-Maintenance Utility
#
# The myisamchk utility gets information about the DB, checks, repairs or optimizes them.
#
# myisamchk works with MyISAM tables (tables with .MYD and .MYI files for storing data and indexes)
#  
# We can also use the CHECK TABLE and REPAIR TABLE to check and repair MyISAM tables.
#
# NOTE: Not supported for partitioned tables, have backups in case of Errors.
#
# General syntax of myisamchk:
#
# myisamchk [<options>] <tbl_name> ...
#
# myisamchk defaults to checking tables - to get more info or correct tables - specify options.
#
# Path of file is relative if relative, Absolute if Absolute
#
# myisamchk *.MYI #Checks all files in CWD
#
# Absolute path check:
#
# myisamchk /path/to/database_dir/*.MYI
#
# * wildcarding is also allowed for Folders.
#
# An example of running a fast check on all MyISAM tables:
#
# myisamchk --silent --fast /path/to/datadir/*/*.MYI
#
# An example of repairing any corrupt tables and checking:
#
# myisamchk --silent --force --fast --update-state \
# 	  --key_buffer_size=64M --myisam_sort_buffer_size=64M \
# 	  --read_buffer_size=1M --write_buffer_size=1M \
# 	  /path/to/datadir/*/*.MYI
#
# Assumes >= 64M memory allocation
#
# When checking tables - no other operations are to be run on them. I.e - they must be locked - or server completely dead.
#
# Otherwise, we might get:
#
# warning: Clients are using or have not closed table properly
#
# This can occur if the table has not been closed or it has been updated - Iterating over it and modifying it in this state,
# can cause corruption and loss of data in terms of MyISAM tables.
#
# If mysqld is running - you must force it to flush table modifications, to clear buffered memory with FLUSH TABLES.
# 
# We could also just use CHECK TABLE to check tables.
#
# myisamchk supports the following options - can be specified on CMD or in the [myisamchk] group of an option file.
#
# FORMAT 					DESC
# --analyze 				Analyze the distribution of key values
# --backup 					Make a backup of the .MYD file as file_name-time.BAK
# --block-search 			Find the record that a block at the given offset belongs to
# --check 					Check the table for errors
# --check-only-changed 	Check only tables that have changed since the last check
#
# --correct-checksum 	Correct the checksum information for the table
# --data-file-length 	Maximum length of the data file (when re-creating data file when it is full)
# --debug 					Write debugging log
# --decode_bits 			?
#
# --defaults-extra-file Read named option file in addition to usual option files
# --defaults-file 		Read only named option file
# --defaults-group 		Option group suffix value
#  -suffix 
# --description 			Print some descriptive info about the table
# --extend-check 			Do very thorough table check or repair that tries to recover every possible row from the data file
# 
# --fast 					Check only tables that have not been closed properly
# --force 					Do a repair operation automatically if myisamchk finds any errors in the table
# --force 					Overwrite old temporary files. For use with the -r or -o option
# --ft_max_word_len 		Max word length for FULLTEXT indexes
# --ft_min_word_len 		Min word length for FULLTEXT indexes
# --ft_stopword_file 	Use stopwords from this file instead of built-in list
# --HELP/--help 					Display help message and exit
# 
# --information 			Print info stats about the table that is checked
# --key_buffer_size 		Size of buffer used for index blocks for MyISAM tables
# --keys-used 				A bit-value that indicates which indexes to update
# --max-record-length 	Skip rows larger than the given length if myisamchk cannot allocate memory to hold them
# --medium-check 			Do a check that is faster than an --extend-check operation
#
# --myisam_block_size 	Block size to be used for MyISAM index pages
# --myisam_sort_ 			The buffer that is allocated when sorting the index when doing a REPAIR or when creating indexes with CREATE INDEX or ALTER TABLE
#  buffer_size
# --no-defaults 			Read no option files
# --parallel-recover 	Same as -r and -n, but creates all keys in parallel using different threads
# --print-defaults 		Print default options
# --quick 					Achieve a faster repair by not modifying the data file
# --read_buffer_size 	Each thread that does a sequential scan allocates a buffer of this size for each table it scans
#
# --read-only 				Do not mark the table as checked
# --recover 				Do a repair that can fix almost any problem except unique keys that are not unique
# --safe-recover 			Do a repair using a old recovery method that reads through all rows in order and updates all index trees based on the rows found
# --set-auto-increment 	Force AUTO_INCREMENT numbering for new records to start at the given value
# --set-collation 		Specify the collation to use for sorting table indexes
# --silent 					Silent mode
# --sort_buffer_size 	The buffer that is allocated when sorting the index when doing a REPAIR or when creating indexes with CREATE INDEX or ALTER TABLE
# --sort-index 			Sort the index tree blocks in high-low order
# --sort_key_blocks 		?
#
# --sort-records 			Sort records according to a particular index
# --sort-recover 			Force myisamchk to use sorting to resolve the keys even if the temporary files would be very large
# --stats_method 			Specifies how MyISAM index stats collection code should treat NULLs
# --tmpdir 					Dir to be used for storing temp files
# --unpack 					Unpack a table that was packed with myisampack
# --update-state 			Store information in the .MYI file to indicate where the table was checked and whether the table crashed.
# --verbose 				Verbose mode
# --version 				Display version information and exit
# --write_buffer_size 	Write buffer size
#
# The following pertains to myisamchk General Options
#
# --help, -? - Display help and exit. Options are grouped by type of operation
# --HELP, -H - Displays help and exit. Presented in a single list.
# --debug=<debug options>, - Write a debugging log. Typical string is d:t:o, <file_name>. Defaults to d:t:o, /tmp/myisamchk.trace
#  -# <debug_options>
# --defaults-extra-file=<file name> - Read this option file after global option file but (On Unix) before the User option file.
# 												  Relative if relative, absolute if absolute - if cannot access file, error is thrown
# --defaults-file=<file name> - Use only the given option file. Relaive if relative, absolute if absolute - error thrown if inaccessible.
# --defaults-group-suffix - Read not only the usual option groups, but also suffix regex. Normally only reads [myisamchk]
#
# --no-defaults - Do not read any option files. .mylogin.cnf is read if exists 
# --print-defaults - Print the program name and all options that it gets from option files
# --silent, -s - Silent mode. Write output only when errors occur - stacks twice (-ss)
# --verbose, -v - Verbose mode. Prints more info about what the program does. Can be used with -d and -e. Stacks.
# --wait, -w - Instead of terminating with an error if the table is locked - wait until the table is unlocked before continuing.
# 					If you are running mysqld with external locking disabled - the table can be locked only by another myisamchk cmd
#
# We can also define the following variables with the general syntax of --var_name=value:
#
# 		Var 					 Default
# decode_bits 				 9
# ft_max_word_len 		 version-dependent
# ft_min_word_len 		 4
# ft_stopword_file 		 built-in-list
# key_buffer_size 		 523264
# myisam_block_size 		 1024
# myisam_sort_key_blocks 16
# read_buffer_size 		 262136
# sort_buffer_size 		 2097144
# sort_key_blocks 		 16
# stats_method 			 nulls_unequal
# write_buffer_size 		 262136
#
# The possible myisamchk vars and their default values can be examined with myisamchk --help:
#
# myisam_sort_buffer_size is used when the keys are repaired by sorting keys, which is the normal case when you use
# --recover. 
#
# sort_buffer_size is a deprecated synonym for myisam_sort_buffer_size
#
# key_buffer_size is used when you are checking the table with --extend-check or when the keys are repaired by inserting
# keys row by row into the table 
#
# Repairing through the key buffer is used in the following cases:
#
# You use --safe-recover
#
# The temp files needed to sort the keys would be more than twice as big as when creating the key file directly.
# This is usually the case when you have large key values for CHAR, VARCHAR or TEXT columns - because the sort operation
# needs to store the complete key values as it proceeds.
#
# If we have  a lot of tmp space and we can force myisamchk to repair by sorting - we can use the --sort-recover option.
#
# Repairing through the key buffer takes much less disk space than using sorting, but is also much slower.
#
# If we wish to have fast repairs - we can set the key_buffer_size and myisam_sort_buffer_size var to about 25%
# of our available memory.
#
# Only one of em is used at a time.
#
# myisam_block_size is the size used for index blocks.
#
# stats_method influences how NULL values are treated for index stats collection when the --analyze option is given.
# It acts like the myisam_stats_method system var.
#
# ft_min_word_len and ft_max_word_len indicate the min and max word length for FULLTEXT indexes on MyISAM tables.
# ft_stopword_file names the stopword file. 
#
# If we use myisamchk to perform an operation that modifies table indexes (such as repair or analyze), the FULLTEXT
# indexes are rebuilt using the default full-text param values for min and max word length and the stopword file unless specified otherwise.
# This can cause Queries to fail.
# 
# This can occur due to that said params are known only by the server.
# They are not stored in MyISAM index files. 
#
# To avoid the problem if you have modified the min or max word length or the stopward file in the server, specify
# the same ft_min_word_len, ft_max_word_len and ft_stopword_file values to myisamchk that we use for mysqld.
#
# For example - if we have set the min word length to 3 - we can repair a table with myisamchk as follows:
#
# myisamchk --recover --ft_min_word_len=3 <tbl_name.MYI>
#
# To ensure that myisamchk and the server uses the same values for full-text params - we can place each one in both the
# [mysqld] and [myisamchk] sections of a option file:
#
# [mysqld]
# ft_min_word_len=3
#
# [myisamchk]
# ft_min_word_len=3
#
# An alternative to using myisamchk is to use the REPAIR TABLE, ANALYZE TABLE, OPTIMIZE TABLE or ALTER TABLE.
#
# The above statements are executed by the server.
#
# The following section covers myisamchk Check options
#
# myisamchk supports the following options for table checking ops:
#
# --check, -c - Check the table for errors. Default operation if you specify no option that selects an operation type explicitly
# --check-only-changed, -C - Check only tables that have changed since the last check
# --extend-check, -e - Check the table extensively. Very slow. Extreme case usage. Can raise key_buffer_Size to help speed.
# --fast, -F - Check only tables that have not been closed properly
# --force, -f - Do a repair operation automatically if myisamchk finds any errors in the table. Same as --recover or -r
# --information, -i - Print info stats about the table that is being checked
# --medium-check, -m - Faster than --extend-check.
# --read-only, -T - Do not mark the table as checked - useful if you use myisamchk to check a table that is in use by some other app that does not use locking 
# 						  - such as mysqld when run with external locking disabled
# --update-state, -U - Store info in the .MYI file to indicate when the table was checked and whether the table crashed. Should be used to get full benefit
# 							  of the --check-only-changed option - but you should not use this option if the mysqld server is using the table and you run it with external locking off.
#
#
# The following section covers myisamchk Repair Options
#
# myisamchk supports the following options for table repair operations (operations performed when an option such as --recover or --safe-recover is given):
#
# --back, -B - Make a backup of the .MYD file as <file_name-time.BAK>
# --character-sets-dir=<dir name> - The dir where char sets are installed
# --correct-checksum - Correct the checksum info for the table
# --data-file-length=<len>, -D <len> - The max length of the data file (when re-creating data file when it is "full")
# --extend-check, -e - Do a repair that tries to recover every possible row from the data file.
# 							  Normally - this also finds a lot of garbage rows.  Extreme case usage.
# --force, -f - Overwrite old intermediate files (files with names like <tbl_name.TMD>) instead of aborting
#
# --keys-used=<val>, - For myisamchk - the option value is a bit value that indicates which indexes to update.
#  -k <val> 			  Each binary bit of the option value corresponds to a table index - where the first index is bit 0.
# 							  
# 							  An option value of 0 disables updates to all indexes, which can be used to get faster inserts.
#							  Deactivated indexes can be reactivated by using myisamchk -r.
#
# --no-symlinks, -l  - Do not follow symbolic links. Normally myisamchk repairs the table that a symlink points to. 
# 							  Deprecated past 4.0 because symlinks are not removed during repair operations.
#
# --max-record-length= - Skip rows larger than the given length if myisamchk cannot allocate memory to hold them.
#  <len>  							  
#
# --parallel-recover,  - Use the same technique as -r and -n, but create all the keys in parallel - using different threads. (beta)
#  -p 
#
# --quick, -r 			  - Achieve a faster repair by modifying only the index file - not the data file.
# 								 You can specify this option twice to force myisamchk to modify the original data file in case of duplicate keys.
#
# --recover, -r 		  - Do a repair that can fix almost any problem except unique keys that are not unique.
# 								 Use this to recover tables.
#
# 								 Data remains intact if this fails. If it fails, use --safe-recover instead.
#
# --safe-recover,  	  - Do a repair using an old recovery method that reads through all rows in order and updates all index trees
#  -o 						 based on the rows found.
#
# 								 Slower than --recover, uses less memory though.
#
# --set-collation=     - Specify the collation to use for sorting table indexes. The char set is implied by the first part of the collation name.
#  <name> 
#
# --sort-recover, 	  - Force myisamchk to use sorting to resolve the keys even if temp files would be v large
#  -n
#
# --tmpdir=<dir name>, - The path of the dir to be used for storing temp files. If not set - myisamchk uses the value of the TMPDIR env var.
#  -t <dir name> 			 --tmpdir can be set to a list of dir paths that are used successivly on rotation for creating temp files.
#								 Separation char is : on Unix, ; on Windows.
#
# --unpack, -u - Unpack a table that was packed with myisampack.
#
# The following covers myisamchk options for actions other than table checks and repairs:
#
# --analyze, -a - Analyze the distribution of key values. This improves join performance by enabling the join optimizer to better choose the order
# 						in which to join the tables and which indexes it should use.
#
# 						To obtain information about the key distribution - use a myisamchk --description --verbose <tbl name> command or
# 						the SHOW INDEX FROM <tbl_name> statement.
#
# --block-search=<offset> - Find the record that a block at the given offset belongs to.
#  -b <offset>
#
# --description, -d - Print some descriptive info about the table. Specifying the --verbose option once or twice produces more info.
#
# --set-auto-increment [=<value>], - Force AUTO_INCREMENT numbering for new records to start at the given value (or higher - if there exists
#  -A [<value>] 							 records with AUTO_INCREMENT values this large).
#
# 												 If <value> is not specified, <AUTO_INCREMENT> numbers for new records begin with the largest value in the table + 1.
#
# --sort-index, -S 	- 	Sort the index tree blocks in high-low order. Optimizes seeks and makes table scans that use indexes faster.
#
# --sort-records=<N>, - Sort records according to a particular index. This makes your data much more localized and may speed up range-based
#  -R <N> 					SELECT and ORDER BY operations that use this index.
#
# 								May be very slow at first use.
#
# 								To determine table index number - use SHOW INDEX, which displays a table's indexes in the same order
# 								that myisamchk sees them. Indexes are numbered beginning with 1.
#
# 								If keys are not packed (PACK_KEYS=0) - they have the same length - so when myisamchk sorts and moves records,
# 								it just overwrites record offsets in the index.
#
# 								If keys are packed (PACK_KEYS=1), myisamchk must unpack key blocks first - then re-create indexes and pack
# 								the key blocks again. (re-creating indexes is faster than updating offsets for each index - in this case)
#
# The following covers how to obtain table info with myisamchk:
#
# To obtain a desc of a MyISAM table or stats about it - use the commands shown here. The output from these commands is explained later in this section.
#
# myisamchk -d <tbl name> - Runs myisamchk in "describe mode" to produce a description of your table. 
# 									 If you start the MySQL server with external locking disabled - myisamchk may report an
# 									 error for a table that is updated while it runs.
#
# 									 However - because myisamchk does not change the table in describe mode - there is no risk of destroying data.
#
# myisamchk -dv <tbl name> - Adding -v runs myisamchk in verbose mode so that it produces more info about the table. Stacks.
# myisamchk -eis <tbl name> - Shows only the most important information from a table. This operation is slow because it must read the entire table.
# myisamchk -eiv <tbl name> - This is like -eis, but tells you what is being done.
#
# The <tbl_name> arg can be either the name of a MyISAM table or the name of its index file. Multiple args can be given.
# 
# Assume following table Structure:
#
# CREATE TABLE person
# (
#   id 			INT NOT NULL AUTO_INCREMENT,
# 	 last_name 	VARCHAR(20) NOT NULL,
#   first_name VARCHAR(20) NOT NULL,
#   birth 		DATE,
#   death 		DATE,
#   PRIMARY KEY  (id),
#   INDEX (last_name, first_name),
#   INDEX (birth)
# ) MAX_ROWS = 10000000 ENGINE=MYISAM;
#
# Suppose also that the table has these data and index file sizes:
# -rw-rw---- 	1 mysql 	mysql 	9347072 Aug 19 11:47 person.MYD
# -rw-rw---- 	1 mysql 	mysql 	6066176 Aug 19 11:47 person.MYI
#
# An example of myisamchk -dvv would then output:
# 
# MyISAM file: 	person
# Record format: 	Packed
# Character set: 	utf8mb4_0900_ai_ci (255)
# File-version: 	1
# Creation time: 	2017-03-30 21:21:30
# Status: 			checked, analyzed, optimized, keys, sorted index pages
# Auto increment key: 				1 	Last value: 			306688
# Data records: 				 306688 	Deleted blocks: 			  0
# Datafile parts: 			 306688 	Deleted data: 				  0
# Datafile pointer (bytes): 		4 	Keyfile pointer (bytes):  3
# Datafile length: 			9347072  Keyfile length: 	  6066176
# Max datafile length:  4294967294  Max keyfile length: 17179867159
# Recordlength: 					  54  
#
# table description:
# Key Start Len Index 	Type 					Rec/key 			Root Blocksize
# 1 	2 		4 	 unique 	long 					1 								 1024
# 2 	6 		80  multip. varchar prefix 	0 								 1024
# 		87 	80 			varchar 				0
# 3 	168 	3 	 multip. uint24 NULL 		0 								 1024
#
# Field Start Length 	Nullpos 	Nullbit 	Type
# 1 	  1 	  1 
# 2 	  2 	  4 									no zeros
# 3 	  6 	  81 									varchar
# 4 	  87 	  81 									varchar
# 5 	  168   3 				1 			1 		no zeros
# 6 	  171   3 				1 			2 		no zeros
#
# Explanations for the types of information myisamchk produces are given here. "Keyfile" refers to the index file.
# "Record" and "row" are synonymous - as are "field" and "column"
#
# The initial part of the table desc contains these values:
#
# MyISAM file - Name of the MyISAM (index) file
# Record format - The format used to store table rows. The preceding examples use Fixed length.
# 						Other possible values are Compressed and Packed. (Packed corresponds to what SHOW TABLE STATUS reports as Dynamic)
# Character set - The table default char set
# File-version  - Version of MyISAM format. Always 1.
# Creation time - When the data file was created
# Recover time  - When the index/data file was last reconstructed
# Status 		 - Table status flags. Possible values are crashed, open, changed, analyzed, optimized keys and sorted index pages.
# Auto increment key, Last value - The key number associated the table's AUTO_INCREMENT column, and most recently generated value. Does not appear if none found.
# Data records  - Number of rows in the table
# Deleted blocks - How many deleted blocks still have reserved space. can optimize tables to minimize this space.
# Datafile parts - For dynamic-row format, this indicates how many data blocks there are. For an optimized table without fragmented rows, this is the same as Data records.
# 
# Deleted data - How many bytes of unreclaimed deleted data there are. You can optimize your table to minimize this space.
# Datafile pointer - The size of the data file pointer, in bytes. Usually is 2,3,4 or 5. Most manage with 2 - cannot be controlled with MySQL.
# 							For fixed tables - this is row address. For dynamic tables, this is byte address.
# Keyfile pointer - Size of the index file pointer, in bytes. Usually 1,2 or 3. Most manage with 2 - auto calculated by MySQL. is always a block address.
# Max datafile length - How long the table data file can become, in bytes.
# Max keyfile length - How long the table index can become, in bytes.
# Recordlength - How much space each row takes, in bytes.
#
# The table desc part of the output includes a list of all keys in the table. For each key, myisamchk displays some low-level info:
#
# Key - This key's number. This value is shown only for the first column of the key. If this value is missing, the line corresponds to the
# second or later column of a multiple-column key.
#
# For the table shown in the example, there are two table description lines for the second index.
# This indicates that it is a multiple-part index with two parts.
#
# Start - Where in the row this portion of the index starts.
# Len - How long this portion of the index is. For packed numbers, this should always be the full length of the column.
# 		  For strings - it may be shorter than the full length of the indexed column - because you can index a prefix of a string column.
#
# 		  The total length of a multiple-part key is the sum of the Len values for all key parts.
# Index - Whether a key value can exist multiple times in the index. Possible values are unique or multip. (multiple)
# Type - What data type this portion of the index has. This is a MyISAM data type with the possible values packed, stripped or empty.
# Root - Address of the root index block.
# Blocksize - The size of each index block. By default is 1024, but the value may be changed at compile time when MySQL is built from source.
# Rec/key - This is a statistical value used by the optimizer. It tells how many rows there are per value for this index.
# 				A unique index always has a value of 1. This may be updated after a table is loaded (or greatly changed) with myisamchk -a.
#
# 				If this is not updated at all,a default value os 30 is given.
#
# The last part of the output provides info about each column:
#
# Field - The column number.
# Start - The byte position of the column named within table rows.
# Length - The length of the column in bytes.
# Nullpos, Nullbit - For columns that can be NULL, MyISAM stores NULL values as a flag in a byte.
# 							Depending on how many nullable columns there are, there can be one or more bytes used for this purpose.
# 							The Nullpos and Nullbit values - if nonempty, indicate which byte and bit contains that flag indicating whether the column is NULL.
#
# 							The position and number of bytes used to store NULL flags is shown in the line for field 1. This is why there are
# 							six Field lines for the person table even though it has only five columns.
#
# Type - The data type. The value may contain any of the following descriptors:
# 			constant - all rows have the same value.
# 			no endspace - Do not store endspace.
# 			no endspace, not_always - Do not store endspace and do not do endspace compression for all values
# 			no endspace, no empty - Do not store endspace. Do not store empty values
# 			table-lookup - The column was converted to an ENUM.
# 			zerofill(N) - The most significant N bytes in the value are always 0 and are not stored.
#
# 			no zeros - Do not store zeros.
# 			always zero - Zero values are stored using one bit.
#
# Huff tree - The number of the Huffman tree associated with the column.
# Bits - The number of bits used in the Huffman tree.
#
# The Huff tree and Bits fields are displayed if the table has been compressed with myisampack.
#
# an example of a myisamchk -eiv output:
#
# Checking MyISAM file: person
# Data records: 	306688 		Deleted blocks: 				0
# - check file-size
# - check record delete-chain
# No recordlinks
# - check key delete-chain
# block_size 1024:
# - check index reference
# - check data record references index: 1
# Key: 	1: 	Keyblocks used: 98% Packed: 	0% 	Max levels: 3
# - check data record references index: 2
# Key: 	2: 	Keyblocks used: 99% Packed: 	97% 	Max levels: 3
# - check data record references index: 3
# Key: 	3: 	Keyblocks used: 98% Packed: 	-14%  Max levels: 3
# Total: 		Keyblocks used: 98% Packed: 	89%
#
# - check records and index references
# *** LOTS OF ROW NUMBERS DELETED ***
#
# Records: 		  306688 	M.recordlength: 		25 Packed: 			83%
# Recordspace used: 97% 	Empty space: 			2% Blocks/Record: 1.00
# Record blocks: 306688 	Delete blocks: 		0
# Record data:  7934464 	Deleted data: 			0
# Lost space: 	  256512 	Linkdata: 		1156096
# 
# User time 43.08, System time 1.68
# Maximum resident set size 0, Integral resident set size 0
# Non-physical pagefaults 0, Physical pagefaults 0, Swaps 0
# Blocks in 0 out 7, Messages in 0 out 0, Signals 0
# Voluntary context switches 0, Involuntary context switches 0
# Maximum memory usage: 1046926 bytes (1023k)
#
# myisamchk -eiv output includes the following info:
#
# data records - Number of rows in the table
# Deleted blocks - How many deleted blocks still have reserved space. You can optimize your table to minimize this space.
# Key - The key number
# Keyblocks used - What percentage of the keyblocks are used. When a table has just been reorganized with myisamchk, the values
# 						 are very high (very near theoretical maximum)
# Packed - MySQL tries to pack key values that have a common suffix. This can only be used for indexes on CHAR and VARCHAR columns.
# 			  For long indexed strings that have similar leftmost parts - this can significantly reduce the space used.
#
# 			  In the preceeding example - the second key is 40 bytes long and a 97% reduction in space is achieved.
#
# Max levels - How deep the B-tree for this key is. Large tables with long key values get high values
# Records - How many rows are in the table.
# M.recordlength - The average row length. This is the exact row length for tables with fixed-length rows, because all rows have the same length.
# Packed - MySQL strips spaces from the end of strings. The Packed value indicates the percentage of savings achieved by doing this.
# Recordspace used - What percentage of the data file is used.
# Empty space - What percentage of the data file is unused.
# Blocks/Record - Average number of blocks per row (that is - how many links a fragmented row is compsoed of). This is always 1.0 for fixed-format tables.
#						This value should stay as close to 1.0 as possible. If it gets too large - you can reorganize the table.
# Recordblocks - How many blocks (links) are used. For fixed-format tables, this is the same as the number of rows.
# Deleteblocks - How many blocks (links) are deleted
#
# Recorddata - How many bytes in the data file are used
# Deleted data - How many bytes in the data file are deleted (unused)
# Lost space - If a row is updated to a shorter length - some space is lost. This is the sum of all such losses - in bytes.
# Linkdata - When the dynamic table format is used, row fragments are linked with pointers (4 to 7 bytes each).
# 				 Linkdata is the sum of the amount of storage used by all such pointers.
#
# The following section covers myisamchk Memory Usage:
#
# Memory allocation is important when you run myisamchk. myisamchk uses no more memory than its memory-related vars are set to.
# If you are going to use myisamchk on very large tables - you should first decide how much memory you want it to use.
#
# The default is to use about 3MB to perform repairs. By using larger values, you can get myisamchk to operate faster.
# For example, if you have more than 512MB RAM available - you could use options such as these (in addition to any other options you might specify):
#
# myisamchk --myisam_sort_buffer_size=256M \
# 						--key_buffer_size=512M   \
# 						--read_buffer_size=64M 	 \
# 						--write_buffer_size=64M ...
#
# Using --myisam_sort_buffer_size=16M is probably enough for most cases.
#
# Be aware that myisamchk uses temp files in TMPDIR. If TMPDIR points to a memory file system - out of memory
# errors can easily occur. If this happens - run myisamchk with the --tmpdir=<dir name> option to specify
# a dir located on a file system that has more space.
#
# When performing repair operations, myisamchk also needs a lot of disk space:
#
# Twice the size of the data file (the original file and copy). This space is not needed if you do a repair
# with --quick; in this case, only the index file is re-created. (This space must be available on the same file system as the original data file)
# as the copy is created in the same dir as the original.
# 
# Space for the new index file that replaces the old one. The old index file is truncated at the start of the repair operation, so you usually
# ignore this space. This space must be available on the same file system as the original data file.
#
# When using --recover or --sort-recover (but not when using --safe-recover) - you need space on disk for sorting.
# This space is allocated in the temp dir (specified by TMPDIR or --tmpdir=<dir name>). 
#
# The following formula yields the amount of space required:
#
# (largest_key + row_pointer_length) * number_of_rows * 2
#
# You can check the length of the keys and the row_pointer_length with myisamchk -dv <table name>
# The <row_pointer_length> and <number_of_rows> values are the <Datafile pointer> and <Data records> values
# in the table desc.
#
# To determine the <largest_key> value - check the Key lines in the table desc.
# The Len column indicates the number of bytes for each key part.
# For a multiple-column index, the key size is the sum of the Len values for all key parts.
#
# If disk space is an issue in relation to repairs, use --safe-recover instead of --recover
#
# The following part pertains to myisamlog - Interactions of displaying MyISAM Log File Contents
#
# myisamlog processes the contents of a MyISAM log file. To create such a file, start the server with
# a --log-isam=<log file> option.
#
# Invoke myisamlog as follows:
#
# myisamlog [<options>] [<file_name> [<tbl_name>] ...]
#
# The default operation is to update (-u).
# If a recovery is done (-r) - all writes and possibly updates and deletes are done and errors are only counted.
# The default log file name is myisam.log if no <log_file> arg is given.
#
# If tables are named on the cmd line - only those tables are updated.
#
# myisamlog supports the following options:
#
# -?, -I - display a help message and exit
# -c <N> - Execute only N amount of commands
# -f <N> - Specify the max number of open files
# -F <filepath/> - Specify the file path with a trailing slash
# -i - Display extra info before exiting
# -o <offset> - Specify the starting offset
#
# -p <N> - Removes <N> components from path
# -r - Performs a recovery operation
# -R <record_pos_file record_pos> - Specify record pos file and record pos
# -u - Perform an update operation
# -v - Verbose mode. Print more output. Stacks.
# -w <write_file> - Specify the write file
# -V - version info
#
# myisampack - Generate compressed, Read-Only MyISAM Tables
#
# The myisampack utility compresses MyISAM tables. myisampack works by compressing each column in the table separately.
# Usually, myisampack packs the data file 40% to 70%
#
# When the table is used later - the server reads into memory the info needed to decompress columns.
# This results in much better performance when accessing individual rows, because you only have to uncompress exactly one row.
#
# MySQL uses mmap() when possible to perform memory mapping on compressed tables.
# If mmap() does not work - MySQL falls back to normal read/write file operations.
#
# NOTE: 
#
# If the mysqld server was invoked with external locking disabled - it is not a good idea to invoke myisampack if the 
# table might be updated by the server during the packing process. It is better to compress tables with the server turned off.
#
# After packing a table - it becomes read only. 
#
# myisampack does not support partitioned tables.
#
# To invoke:
#
# myisampack [<options>] <file_name> ...
#
# Each file name argument should be the name of an index (.MYI) file. 
# If you are not in the DB dir, you should specify the path name to the file. 
# It is permissible to omit the .MYI extension
#
# After we compress a table with myisampack - we can use myisamchk -rq to rebuild its indexes.
# 
# 
# It also reads option files and supports the options for processing them.
#
# myisampack supports the following options: 
#
# --help, -?
# --backup, -b - Make a backup of each table's data file using the name <tbl_name>.OLD
# --character-sets-dir=<dir name> - The dir where char sets are installed.
# --debug[=<debug_options>], - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>. Defaults to d:t:o
#  -# [<debug_options>]
# --force, -f - Produce a packed table even if it becomes larger than the original or if the intermediate file from an earlier invocation
# 					 of myisampack exists.
#
# 					 myisampack creates an intermediate file named <tbl_name>.TMD in the database dir while it compresses the table.
# 					 If you kill myisampack, the .TMD file might not be deleted.
# 					 Normally, myisampack exits with an error if it finds that <tbl_name>.TMD exists.
#
# 					 With --force, myisampack packs the table anyway.
#
# --join=<big tbl name>, - Join all tables named on the cmd line into a single packed table <big_tbl_name>.
#  -j <big_tbl_name> 		All tables that are to be combined must have identical structure (same column names and types, same indexes, etc.)
# 	
# 									<big_tbl_name> must not exist prior to the join operation. All source tables named on the cmd line
# 									to be merged into <big_tbl_name> must exist. The source tables are read for the join operation but not modified.
# --silent, -s 			 - Silent mode. Writes only error outputs.
# --test, -t 				 - Do not actually pack the table, just test packing it.
# --tmpdir=<dir name>,   - Use the named dir as the location where myisampack creates temp files.
#  -T <dir_name>
# --verbose, -v 			 - Verbose. Write info about the progress of the packing ops and its result.
# --version, -V 			 - Display version info and exit
# --wait, -w 				 - Wait and retry if the table is in use. If the mysqld server was invoked with external locking disabled, it is not a good idea
# 									to invoke myisampack if the table might be updated by the server during the packing process.
#
# The following sequence of commands illustrates a typical table compression session:
#
# ls -l station
# -rw-rw-r-- 	1 monty 	my 		994128 Apr 17 19:00 station.MYD
# -rw-rw-r-- 	1 monty  my 		 53248 Apr 17 19:00 station.MYI
#
# myisamchk - dvv station
#
# MyISAM file: 		station
# Isam-version: 	2
# Creation time: 	1996-03-13 10:08:58
# Recover time:   1997-02-02 3:06:43
# Data records: 				  1192  Deleted blocks: 			  0
# Datafile parts: 			  1192  Deleted data: 			     0
# Datafile pointer (bytes): 	  2  Keyfile pointer (bytes):   2
# Max datafile length: 	 54657023  Max keyfile length: 33554431
# Recordlength: 					834
# Record format: Fixed length
#
# table description:
# Key  Start  Len  Index   Type 				Root Blocksize 	Rec/key
# 1 	 2 	  4 	 unique 	unsigned long 	1024 1024 					1
# 2 	 32 	  30 	 multip. text 			  10240 1024 					1
# 
# Field Start Length Type
# 1 	  1 	  1
# 2 	  2 	  4
# 3 	  6 	  4
# 4 	  10 	  1
# 5 	  11 	  20
# 6 	  31 	  1
# etc.
#
# myisampack station.MYI
# Compressing station.MYI: (1192 records)
# - Calculating statistics
#
# normal: 		20  empty-space: 		16 empty-zero: 		12 empty-fill:  11
# pre-space: 	 0  end-space: 		12	table-lookups: 	 5 zero: 		  7
# Original trees:  57 	After join: 17
# - Compressing file
# 87.14%
# Remember to run myisamchk -rq on compressed tables
# 
# myisamchk -rq station
# - check record delete-chain
# - recovering (with sort) MyISAM-table 'station'
# Data records: 1192
# - Fixing index 1
# - Fixing index 2
#
# mysqladmin -uroot flush-tables
#
# ls -l station
# -rw-rw-r-- 	1 monty 	my 		127874 Apr 17 19:00 station.MYD
# -rw-rw-r-- 	1 monty 	my 		 55296 Apr 17 19:04 station.MYI
#
# myisamchk -dvv station
# 
# MyISAM file: 		station
# Isam-version: 		2
# Creation time: 		1996-03-13 10:08:58
# Recover time: 		1997-04-17 19:04:26
# Data records: 					  1192 	Deleted blocks: 		    0
# Datafile parts: 				  1192 	Deleted data: 		       0
# Datafile pointer (bytes): 		  3 	Keyfile pointer (bytes): 1
#
# Max datafile length:      16777215 	Max keyfile length: 131071
# Recordlength: 						834
# Record format: Compressed
#
# table description:
# Key Start Len 	Index 	Type 			   Root 		Blocksize 	Rec/key
# 1 	2 		4 		unique 	unsigned long  10240 		1024 				1
# 2 	32 	30 	multip.  text 				54272 		1024 				1
# 
# Field Start Length Type 										Huff tree Bits
# 1 	  1 	  1 		constant 								 		  1    0
# 2 	  2 	  4 		zerofill(1) 									  2 	 9
# etc.
#
# myisampack displays the following kinds of info:
#
# normal - Number of cols for which no extra packing is used
# empty-spaces - Number of cols containing values that are only spaces. Occupies one bit.
# empty-zero - Number of cols containing values that are only binary zeros. Occupies one bit
# empty-fill - Number of integer cols that do not occupy the full byte range of their type. These are 
# 					changed to a smaller type. For example - a BIGINT column (eight bytes) can be stored
# 					as a TINYINT col (one byte) if all the values are in the range of a TINYINT (-128 to 127)
# pre-space  - Number of decimal cols that are stored with leading spaces. In this case - each value contains a count for the number of leading spaces.
# end-space  - Number of columns that have a lot of trailing space. In this case - each value contains a count for the number of trailing spaces
# table-lookup - The column had only a small number of different values, which are converted to ENUM before Huffman compression.
# zero 		 - Number of cols in which all values are zero
# Original trees - Initial number of Huffman trees.
# 
# After join - Number of distinct Huffman trees left after joining trees to save some header space.
#
# After a table has been compressed, the Field lines displayed by myisamchk -dvv include additional informaton about each col:
#
# Type - The data type. Can be one of the following:
#
# constant - Same values across all rows
# no endspace - Do not store endspace
# no endspace, not_always - Do not store endspace and do not do endspace compression for all values
# no endspace, no empty - Do not store endspace. Do not store empty values
# table-lookup - The column was converted to an ENUM.
# zerofill(<N>) - The most significant <N BYTES> in the value are always 0 and are not stored.
# no zeros - Do not store zeros
# always zero - Zero values are stored using one bit.
#
# Huff tree - Number of the Huffman tree associated with the column.
# Bits - Number of bits used in the huffman tree
#
# After you run myisampack, use myisamchk to re-create any indexes. 
# At this time, you can also sort the index blocks and create stats needed for the MySQL optimizer to work better:
#
# myisamchk -rq --sort-index --analyze <tbl_name.MYI>
#
# After you have installed the packed table into the MySQL DB dir, you should execute mysqladmin flush-tables to force
# mysqld to start using the new table.
#
# To unpack a packed table, use the --unpack option to myisamchk.
#
# The following covers mysql_config_editor - a MySQL Configuration Utility
#
# The mysql_config_editor utility enables you to store authentication creds in a obfuscated login path file named .mylogin.cnf
# 
# The file location is the %APPDATA%\MySQL directory on Windows and the current user's home dir on non-Windows systems.
# The file can be read later by MySQL client programs to obtain authentication credentials for connecting to MySQL server. 
#
# The unobfuscated format of the .mylogin.cnf login path consists of option groups, similar to other option files.
# Each option group in .mylogin.cnf is called a "login path" which is a group that permits only certain options:
#
# host, user, password, port and socket
#
# Think of a login path option group as a set of options that specify which MySQL server to connect to and which
# account to authenticate as.
#
# An unobfuscated example:
#
# [client]
# user = mydefaultname
# password = mydefaultpass
# host = 127.0.0.1
# [mypath]
# user = myothername
# password = myotherpass
# host = localhost
#
# Order of prio is: Cmd > mylogin.cnf > other option files
#
# To specify a alternative login path file name, set the MYSQL_TEST_LOGIN_FILE environment variable.
# This variable is recognized by mysql_config_editor, by standard MySQL clients and the mysql-test-run.pl testing utility.
#
# Programs use groups in the login path file as follows:
#
# mysql_config_editor operates on the client login path by default if you specify no --login-path=<name> option
# to indicate explicit pathing.
#
# Without a --login-path option - it reads the same groups from other option files as well as the loginpath file.
# i.e default groups pertaining to said command.
#
# With a --login-path option, client programs read the named login path from the login path file.
# The option groups read from other option files remain the same.
#
# mysql --login-path=<mypath>
#
# The mysql client then reads [client] and [mysql] from other option files - whilst reading [client], [mysql] and [mypath] from the login path file.
#
# Client programs read the login path file even when the --no-defaults option is used.
# 
# mysql_config_editor obfuscates the .mylogin.cnf file so it cannot be read as cleartext - and it's contents when obfuscated by client programs
# are used only in memory.
#
# In said way - a PW can be stored in a file in non-cleartext format and used later, without exposing in a Env var or cmd.
# 
# mysql_config_editor does come with a print command as to show login path file contents - but this still omits PWs.
#
# Note: .mylogin.cnf files can be unobfuscated with root privs
#
# The login path file must be readable and writable to the current user - and inaccessible to other users.
# Otherwise, mysql_config_editor ignores it and client programs do not use it either.
#
# To invoke mysql_config_editor:
#
# mysql_config_editor [<program options>] <command> [<command_options>]
#
# If the login path files does not exist - mysql_config_editor creates it.
#
# <program options> : Pertains to general mysql_config_editor options
# <command> : Pertains to what action to perform on the .mylogin.cnf login path file. 
# 				  For example - set writes a login path to the file, remove removes a login path, and print displays login path contents.
# <command_options> : Indicates any additional options specific to the command, such as the login path name and the values to use in the login path.
#
# The position of the command name within the set of program arguments is explicit.
# 
# mysql_config_editor --help set #Interprets it as "--help", ignores the set part
# mysql_config_editor set --help #Interprets it as "set --help" - as in, help command regarding set
#
# Assuming that you wish to have a client login path that defines default connection params - and a separate one for remote,,
# an example:
#
# The following will modify your .mylogin.cnf using set commands:
#
# mysql_config_editor set --login-path=client
# 		--host=localhost --user=localuser --password
# >Prompt for PW to localhost
#
# mysql_config_editor set --login-path=remote
# 		--host=remote.example.com --user=remoteuser --password
# >Prompt for PW to Remote 
#
# We can showcase groupings from the .mylogin.cnf with print --all:
#
# mysql_config_editor print --all
# [client]
# user = localuser
# password = *******
# host = localhost
# [remote]
# user = remoteuser
# password = *******
# host = remote.example.com
#
# If we omit names or --all, it prints client path by default - if there is one.
#
# The login path file can contain multiple login paths.
# A quick example of how to access remote in addition to the stnadard config ones:
#
# mysql --login-path=remote #Reads [client], [mysql] and [remote] groups form login path file
#
# Note: Groups read from later appearances - take precedence over earlier ones appearing.
#
# mysql_config_editor adds login paths to the login path file in the order we create them,
# Thus, more general ones first - more specific ones later on
#
# Ommited values can be appended in terms of specification:
# mysql --login-path=remote --host=remote2.example.com #Assuming that remote yields same login details as the remote2.example.com host, we can just redirect to that specific host
#
# The following are mysql_config_editor General options
#
# mysql_config_editor supports the following general options 
#
# --debug - Write debugging log
# --help - Display help message and exit
# --verbose - Verbose mode
# --version - Display version info and exit
#
# --help, -? - Display a general help message and exit. 
# Example: mysql_config_editor <command> --help
#
# --debug[=<debug options>], - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>.
#  -# <debug_options> 			 Defaults to d:t:o, /tmp/mysql_config_editor.trace
#
# --verbose, -v - Verbose mode.
#
# --version, -V - Display version info and exit
#
# The following covers:
# mysql_config_editor Commands and Command-Specific Options
#
# This section describes the permitted mysql_config_editor commands, and for each one - the command-specific options
# permitted following the command name on the cmd line.
#
# In addition - mysql_config_editor supports general options that can be used preceding any command.
#
# The following options are supported:
#
# help - Display a general help message and exit. This command takes no following options.
# 		
# 			To see a command-specific help message, invoke mysql_config_editor as follows, where <command> is a command other than help:
#
# 			mysql_config_editor <command> --help
# 
# print [<options>] - Print the contents of the login path file in unobfuscated form, with the exception that passwords are displayed as ****.
# 
# 							 The default login path name is <client> if no login path is named.
# 							 If both --all and --login-path are given, --all takes precedence.
#
# 							 The <print> command permits these options following the command name:
#
# 							 --help, -? - Display a help message for the <print> command and exit.
# 							 To see a general help message - use mysql_config_editor --help
# 		
# 							 --all - Print the contents of all login paths in the login path file.
# 
# 							 --login-path=<name>, -G <name> - Print the contents of the named login path.
#
# remove [<options>] - Remove a login path from the login path file - or modify a login path by removing options from it.
#
# 							  This command removes from the login path only such options as are specified with the --host, --password, --port, --socket
# 							  and --user options.
# 
# 							  	If none of the above are given - remove removes the entire login path.
#
#								mysql_config_editor remove --login-path=mypath --user #Removes the user option from login path option 
#
# 								mysql_config_editor remove --login-path=mypath #Removes the entire mypath login path
#
# 								The remove command permits these options following the cmd name:
#
# 								--help, -? - Displays a help message for the remove command and exit.
# 								
# 												 To see a general help message - use mysql_config_editor --help
#
# 								--host, -h - Remove the host name from the login path.
#
# 								--login-path=<name>, -G <name> - The login path to remove or modify. 
# 																			Default login path name is client if this option is not given.
#
#
#  							--password, -p - Removes the PW from the login path
#
# 								--port, -P - Remove the TCP/IP port number from the login path
#
# 								--socket, -S - Remove the Unix socket file name from the login path
#
# 								--user, -u - Remove the user name from the login path
#
# 								--warn, -w - Warn and prompt the user for confirmation if the command attempts to remove the default login
# 												 path (client) and --login-path=client was not specified. On by default, turn off with --skip-warn
#
# reset [<options>] - Empty the contents of the login path file.
#
# 							 The reset command permits these options following the command name:
#
# 							 --help, -? - Display a help message for the reset command and exit.
# 											  To see a general help message, use mysql_config_editor --help
#
# set [<options>] - Write a login path to the login path file.
#
# 						  This command writes to the login path only such options as are specified with the --host,
# 						  --password, --port, --socket and --user options.
#
# 						  If none of those options are given - mysql_config_editor writes the login path as an empty group.
#
# 						  The set command permits these options following the command name:
#
# 						  --help, -? - Display a help message for the set command and exit.
# 
# 											To see a general help message, use mysql_config_editor --help
#
# 						  --host=<host_name>, -h <host_name> - The host name to write to the login path.
#
# 						  --login-path=<name>, -G <name> - The login path to create. The default login path is <client> if this option is not given.
#
# 						  --password, -p - Prompt for a password to write to the login path. After mysql_config_editor displays the prompt,
# 												 type the password and press Enter. mysql_config_editor does not echo it.
#
# 												 To specify a empty password - just press Enter, and it generates:
#
# 												 password =
#
# 						  --port=<port_num>, -P <port_num> - The TCP/IP port number to write to the login path.
#
# 						  --socket=<file_name>, -S <file_name> - The Unix socket file name to write to the login path.
#
# 						  --user=<user_name>, -u <user_name> - User name to write to the login path.
#
# 						  --warn, -w - Warn and prompt the user for confirmation if the command attempts to overwrite an existing login path.
# 											On by default - turn off with --skip-warn
#
# The following section pertains to mysqlbinlog - A utility for Processing Binary Log Files
#
# The server's binary log consists of files containing "events" that describe modifications to the DB contents.
# The server writes these files in binary formatting. To display said contents in text - use the mysqlbinlog utility.
#
# You can also use mysqlbinlog to display the contents of relay log files written by a slave server in a replication setup
# because relay logs have the same format as binary logs.
#
# The binary log and relay log are covered later.
#
# Invoke mysqlbinlog as follows:
#
# mysqlbinlog [<options>] <log_file>
#
# To display contents of binary log file binlog.000003:
#
# mysqlbinlog binlog.000003
#
# The output includes events contained in binlog.000003.
# For statement-based logging, event information includes the SQL statement, the ID of the server on which it
# was executed, timestamp of execution, time taken, etc.
#
# For row-based logging, the event indicates a row change rather than an SQL statement.
#
# Events are preceded by header comments that provide additional information:
#
# # at 141 #Line start or offset in the bin log file
#
# #100309 9:28:36 server id 123 end_log_pos 245 #date, time, server, id, end_log_pos + 1 is where next event will start - timestamp is propagated to slave servers. 
#
#  Query thread_id=3350 exec_time=11 error_code=0 #id of thread, time spent executing the event on the master server. 
#  
#  #On a slave, it is the replication lag behind the master the slave is having. error_code is the raised error - 0 means no error.
#
# When using event groups - the file offset of events may be grouped together and the comments of events may be grouped together.
# Do not mistake these grouped events for blank file offsets.
#
# The output from mysqlbinlog can be re-executed (For example - by using it as input to mysql) - to redo the statements in the log.
# This is useful for recovery operations after a server crash.
#
# Normally - we use mysqlbinlog to read binary log files directly and apply them to the local MySQL server.
# It is also possible to read binary logs from a remote server by using the --read-from-remote-server option.
#
# To read remote binary logs - the connection param options can be given to indicate how to connect to the server.
# These options are --host, --password, --port, --protocol, --socket and --user.
# They are ignored except when you also use the --read-from-remote-server option.
#
# When running mysqlbinlog against a large binary log - be careful that the filesystem has enough space for the
# resulting files.
#
# To configure the directory that mysqlbinlog uses for temp files - use the TMPDIR environment variable.
#
# mysqlbinlog supports the following options, which can be specified on cmd line or in [mysqlbinlog] and [client] groups.
#
# Format 										Desc
# --base64-output 			Print binary log entries using base-64 encoding
# --bind-address 				Use specified network interface to connect to MySQL Server
# --binlog-row-event-max   Binary log max event size
#  -size
# --character-sets-dir 		Directory where char sets are installed
# --connection-server-id 	Used for testing and debugging.
# 
# --database 					List entries for just this db
# --debug 						Write debugging log
# --debug-check 				Print debug info when program exits
# --debug-info 				Print debug info, memory and CPU stats when the program exits
# --default-auth 				Auth plugin to use
# --defaults-extra-file 	Read named option file in addition to usual option files
# --defaults-file 			Read only named option file
#
# --defaults-group-suffix 	Option group suffix value
# --disable-log-bin 			Disable binary logging
# --exclude-gtids 			Do not show any of the groups in the GTID set provided
# --force-if-open 			Read binary log files even if open or not closed properly
# --force-read 				If mysqlbinlog reads a binary log event that it does not recognize - it prints a warning
#
# --get-server-public-key 	Request RSA public key from server
# --help 						Display help message and exit
# --hexdump 					Display a hex dump of the log in comments
# --host 						Connect to MySQL on the given host
# --idempotent 				Cause the server to use idempotent mode while processing binary log updates from this session only
# --include-gtids 			Show only the groups in the GTID set provided
# --local-load 				Prepare local temporary files for LOAD DATA INFILE in the specified dir
# --login-path 				Read login path options from .mylogin.cnf
#
# --no-defaults 				Read no option files
# --offset 						Skip the first N entries in the log
# --password 					Password to use when connecting to server
# --plugin-dir 				Dir where plugins are installed
# --port 						TCP/IP port number for connection
# --print-defaults 			Print default options
# --print-table-metadata 	Print table metadata
# --protocol 					Connection protocol to use
#
# --raw 							Write events in raw (binary) format to output files
# --read-from-remote 		Read the binary log from a MySQL master rather than reading a local log file
#  -master
# --read-from-remote 		Read binary log from MySQL server rather than local log file
#  -server
# --result-file 				Direct output to named file
# --rewrite-db 				Create rewrite rules for databases when playing back from logs written in row-based format. Stacks.
# --secure-auth 				REMOVED
#
# --server-id 					Extract only those events created by the server having the given server ID
# --server-id-bits 			Tell mysqlbinlog how to interpret server IDs in binary log when log was written by a
# 									mysqld having its server-id-bits-set to less than the maximum.
#
# 									Supported only by MySQL Cluster version of mysqlbinlog.
# --server-public-key-path Path name to file containing RSA public key
# --set-charset 				Add a SET NAMES charset_name statement to the output
# --shared-memory-base 		The name of shared memory to use for shared-memory connections
#  -name 
# --short-form 				Display only the statements contained in the log
# --skip-gtids 				Do not print any GTIDs; use this when writing a dump file from bin logs containing GTIDs.
# --socket 						For connections to localhost, the Unix socket file to use
# --ssl-ca 						File that contains list of trusted SSL Cert Auths
# --ssl-capath 				Dir that contains trusted SSL Cert Auth cert files
# --ssl-cert 					File that contains X.509 Cert
#
# --ssl-cipher 				List of permitted ciphers for connection encryption
# --ssl-crl 					File that  contains cert revocation lists
# --ssl-crlpath 				Dir that contains cert revocation list files
# --ssl-fips-mode 			Whether to enable FIPS mode on the client side
# --ssl-key 					File that contains X.509 key
# --ssl-mode 					Security state of connection to server
# --start-datetime 			Read binary log from first event with timestamp equal to or later than datetime argument
# --start-position 			Read binary log from first event with position equal to or greater than argument
# --stop-datetime 			Stop reading binary log at first event with timestmap equal to or greater than datetime arg
#
# --stop-never 				Stay connected to server after reading last binary log file
# --stop-never-slave- 		Slave server ID to report when connecting to server
#  server-id
# --stop-position 			Stop reading binary log at first event when position equal to or greater than arg
# --tls-version 				Protocols permitted for enc. connections
# --to-last-log 				Do not stop at the end of requested binary log from a MySQL server, but rather continue
# 									printing to end of last binary log
# --user 						MySQL user name to use when connecting to server
# --verbose 					Reconstruct row events as SQL statements
# --verify-binlog-checksum Verify checksums in binary log
# --version 					Display version info and exit
#
# The following maps the further attributes of some of the above commands:
#
# --help, -? - Display a help message and exit
# --base64-output=<value> - This option determines when events should be displayed encoded as base-64 strings using BINLOG statements.
# 									 The option has these permissible values (not case-sensitive):
#
# 									 AUTO/UNSPEC - displays BINLOG statements automatically when necessary (that is - for format desc. events and row events).
# 														If no --base64-output option is given, the effect is the same as --base64-output=AUTO
#
# 														NOTE: Automatic BINLOG display is the only safe behavior if you intend to use the output of mysqlbinlog 
# 														to re-execute binary log file contents.
#
# 														The other option values are intended only for debugging or testing purposes because they may produce output
# 														that does not include all events in executable form.
#
# 									 NEVER - Causes BINLOG statements not to be displayed. mysqlbinlog exits with an error if a row event is found that must
# 												be displayed using BINLOG.
#
# 									 DECODE-ROWS - Specifies to mysqlbinlog that you intend for row events to be decoded and displayed as commented SQL statements
# 														by also specifying the --verbose option.
#
# 														Like NEVER, DECODE-ROWS suppresses display of BINLOG statements, but unlike NEVER - it does not exit with an error
# 														if a row event is found.
#
# 									 For examples that show the effect of --base64-output and --verbose on row event output.
#
# --bind-address=<ip address> - On a computer having multiple network interfaces, use this option to select which interface to use for connecting to the MySQL server.
# --binlog-row-event-max-size=<N> - General syntax formatting and values:
#
# 												Command-Line format - --binlog-row-event-max-size=#
# 												Type 						 Numeric
# 												Default Value 			 4294967040
# 												Minimum Value 			 256
# 												Maximum Value 			 18446744073709547520
# 											
# 												The above values are in bytes. Refers to row-based binary log events size.
# 												Rows are grouped into events smaller than this size if possible.
#
# 												Value should be a multiple of 256 - Defaults to 4GB
#
# --character-sets-dir=<dir name> - The dir where char sets are installed.
#
# --connection-server-id=<server id> - specifies the server ID that mysqlbinlog reports when it connects to the server. 
# 													Can be used to avoid a conflict with the ID of a slave server or another mysqlbinlog process.
#
# 													If the --read-from-remote-server option is specified, mysqlbinlog reports a server ID of 0,
# 													which tells the server to disconnect after sending the last log file (nonblocking behavior)
#
# 													If the --stop-never option is also specified to maintain the connection to the server, mysqlbinlog
# 													reports a server ID of 1 by default instead of 0 - and --connection-server-id can be used to
# 													replace that server ID if required.
#
# --database=<db name>, -d <db_name> - This option causes mysqlbinlog to output entries from the binary log (local log only) that occur
# 													while <db_name> has been selected as the default DB by <USE>.
#
# 													The --database option for mysqlbinlog is similar to the --binlog-do-db option for mysqld, but
# 													can be used to specify only one DB. If --database is given several times, the last one is taken.
#
# 													The effects of this option depend on whether the statement-based or row-based logging format is
# 													in use, in the same way that the effects of --binlog-do-db depend on whether statement-based
# 													or row-based logging is used.
#
# 													Statement-based logging:
#
# 													The --database option works as follows:
#
# 														While <db_name> is the default DB, statements are output whether they modify tables in
# 														<db_name> or a different database.
#
# 														Unless <db_name> is selected as the default DB, statements are not output - even if they modify tables in <db_name>.
#
# 														There is an exception for CREATE DATABASE, ALTER DATABASE and DROP DATABASE. 
# 														The database being created, altered or dropped is considered to be the default database
# 														when determining whether to output the statement.
#
#													Assuming the following base of implementation:
#
# 														INSERT INTO test.t1 (i)  VALUES(100);
# 														INSERT INTO db2.t2 (j) 	 VALUES(200);
# 														USE test;
# 														INSERT INTO test.t1 (i)  VALUES(101);
# 														INSERT INTO t1 (i) 		 VALUES(102);
# 														INSERT INTO db2.t2 (j) 	 VALUES(201);
# 														USE db2;
# 														INSERT INTO test.t1 (i)  VALUES(103);
# 														INSERT INTO db2.t2 (j) 	 VALUES(202);
# 														INSERT INTO t2 (j) 		 VALUES(203);
#
# 													mysqlbinlog --database=test does not output the first two INSERT statements because there is no default DB.
# 													It outputs the three INSERT statements following USE test, but not the three INSERT statements following USE db2.
#
# 													mysqlbinlog --database=db2 does not output the first two INSERT statements because there is no default DB.
# 													It does not output the three INSERT statements after USE.test - but it does output the three after USE db2. (because default usage db2)
#
# 													Row-based logging. mysqlbinlog outputs only entires that change tables belonging to <db_name>.
# 													The default DB has no effect on this. Suppose that the binary log just described was created using
# 													row-based logging rather than statement-based logging.
#
# 													mysqlbinlog --database=test outputs only those entries that modify t1 in the test database, regardless of
# 													whether USE was issued or what the default DB is.
#
# 													If a server is running with binlog format set to MIXED - and we want to use mysqlbinlog with --database option,
# 													the modified tables must be selected by USE. (In particular, no cross-database updates should be used)
#
# 													When used together with the --rewrite-db option, the --rewrite-db option is applied first;
# 													Then the --database option is applied - using the rewritten database name.
#
# 													The order in which the options are provided makes no difference in this regard.
#
# --debug[=<debug options>], 			 	Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>. Defaults to d:t:o, /tmp/mysqlbinlog.trace
#  -# [<debug options>]
#
# --debug-check 								Print debug info when the program exits
#
# --debug-info 								Print debug info, memory and CPU usage stats when exiting
#
# --default-auth=<plugin> 					A hint about the client-side auth plugin to use.
#
# --defaults-extra-file=<file name> 	Read this option file after the global option file, but (on Unix) before the user option file.
# 													Relative if relative, absolute if absolute - error if permissions denied or not found.
#
# --defaults-file=<file name> 			Use only the given option file. Relative if relative, error if non permissible or found. Still reads .mylogin.cnf
#
# --defaults-group-suffix=<str> 			Regex suffix matching in grouping 
#
# --disable-log-bin, -D 					Disable binary logging. Useful for avoiding an endless loop if we use --to-last-log option and we are sending the output
# 													to the same MySQL server.
#
# 													Useful when restoring after a crash to avoid duplication of the statements we logged.
#
# 													Causes mysqlbinlog to include a <SET sql log bin = 0> statement in its output to disable binary
# 													logging of the remaining output.
#
# 													Manipulating the session value of the sql log bin system var is a restricted operation - so 
# 													this requires permissions to set restricted session vars.
#
# --exclude-gtids=<gtid set> 				Do not display any of the groups listed in the <gtid_set>
#
# --force-if-open, -F 						Read binary log files even if they are open or were not closed properly.
#
# --force-read, -f 							With this option, if mysqlbinlog reads a binary log event that it does not recognize
# 													- it prints a warning, ignores the event and continues. Without this option - mysqlbinlog stops reading in such an event.
#
# --get-server-public-key 					Same as otherwise with RSA public key request, applies to clients authenticating caching_sha2_password auth plugin.
#
# --hexdump, -H 								Display a hex dump of the log in comments - can be useful for replicating debugging
#
# --host=<host name>, 						Get the binary log from the MySQL server on the given host.
#  -h <host name>
#
# --idempotent 								Tell the MySQL server to use idempotent mode while processing updates.
# 													Causes suppression of any duplicate-key or key-not-found errors that the server
# 													encounters in the current session while processing updates.
#
# 													May prove useful whenever it is desirable or nessecary to replay one or more binary logs
# 													to a MySQL server which may not contain all of the data to which the logs refer.
#
# 													The scope of effect for this option includes the current mysqlbinlog client and session only.
#
# --include-gtids=<gtid set> 		 		Display only the groups listed in the gtid_set
#
# --local-load=<dir name>,  				Prepare local temporary files for LOAD DATA INFILE in the specified dir.
#  -l <dir_name> 								(These are not automatically removed by any MySQL program)
#
# --login-path=<name> 						Read options from the named login path in the .mylogin.cnf login path file.
# 													This specific option group pertains to connection details to server and account to auth as.
#
# --no-defaults 								Do not read any option files. If program startup fails due to reading unknown options from an option file
# 													--no-defaults can be used to prevent them from being read.
#
# 													The exception is that the .mylogin.cnf file, it's always read.
#
# --offset=<N>, -o <N> 						Skip the first N entries in the log.
#
# --password[=<password>], 				The PW to use when connecting to the server. If you use the short option (-p) - cannot have space.
#  -p [<password>]  							If value omitted, prompted for one
#
# --plugin-dir=<dir name> 					The dir in which to look for plugins. Specify if --default-auth option is used to specify a auth plugin 
# 													but mysqlbinlog can't find it
#
# --port=<port num>, 						The TCP/IP port number to use for connecting to a remote server
#  -P <port_num>
#
# --print-defaults 							Print the program name and all the options that it gets from option files.
#
# --print-table-metadata 					Print table related metadata from the binary log. 
# 													Configure the amount of table related metadata binary logged using binlog-row-metadata
#
# --protocol={TCP|SOCKET|PIPE|MEMORY}  The connection protocol to use for connecting to the server.
# 													
# --raw 											By default, mysqlbinlog reads binary log files and writes events in text format.
# 													The --raw option tells mysqlbinlog to write them in their original binary format.
#
# 													Its use requires that --read-from-remote-server also be used because the files are requested from a server.
#
# 													mysqlbinlog writes one output file for each file read from the server.
# 													The --raw option can be used to make a backup of the Server's binary log.
#
# 													With --stop-never, the backup acts as "live" - because connection is not interuppted.
# 													Defaults to writing to a output file in the CWD with the same name as the original log files.
#
# 													Output file names can be modified using the --result-file 
#
# --read-from-remote-master=<type> 		Read binary logs from a MySQL server with the COM_BINLOG_DUMP or COM_BINLOG_DUMP_GTID commands
# 													by setting the option value to either BINLOG-DUMP-NON-GTIDS or BINLOG-DUMP-GTIDS, respectively.
#
# 													If --read-from-remote-master=<BINLOG-DUMP-GTIDS> is combined with --exclude-gtids - transactions
# 													can be filtered out on the master - avoiding unessecary network traffic.
#
# --read-from-remote-server, -R 			Read the binary log from a MySQL server rather than reading a local log file.
# 													Any connection parameter options are ignored unless this option is given as well.
#
# 													These options are --host, --password, --port, --protocol, --socket and --user.
#
# 													Requires that the remote server is running. Works only for binary log files on the remote server,
# 													not relay log files.
#
# 													This option is equivalent to --read-from-remote-master=BINLOG-DUMP-NON-GTIDS
#
# --result-file=<name>, -r <name> 		Without the --raw option, this option indicates the file to which mysqlbinlog writes text output.
#
# 													With -raw, mysqlbinlog writes one binary output file for each log file transferred from the server,
# 													writing them by default in the CWD using the same name as the original log file.
#
# 													In this case, the --result-file option value is treated as a prefix that modifies output file names.
#
# --rewrite-db='<from name->to name>' 	When reading from a row-based or statement-based log, rewrite all occurrences of <from_name> to <to_name>.
# 													Rewriting is done on the rows, for row-based logs - as well as on the USE clauses, for statement based logs.
#
# 													NOTE: Statements in which table names are qualified with DB names are not rewritten to use the new name when using this option.
#
# 													The rewrite rule employed as a value for this option is a string having the form '<from_name>-><to_name>' as shown previously,
# 													and it must be enclosed ''
#
# 													To employ it multiple times, an example:
#
# 													mysqlbinlog --rewrite-db='dbcurrent->dbold' --rewrite-db='dbtest->dbcurrent' \
# 																	binlog.00001 > /tmp/statements.sql
#
# 													When used together with the --database option, the --rewrite-db option is applied first -
# 													then --database is applied, using the rewritten DB name.
#
# 													In this case, ordering makes no difference.
#
# 													For instance, if mysqlbinlog is started with --rewrite-db='mydb->yourdb' --database=yourdb, then all
# 													updates to any tables in databases mydb and yourdb are included in said output.
#
# 													On the other hand, if it is started with --rewrite-db='mydb->yourdb' --database=mydb, then no outputs are given,
# 													because all updates to mydb are first rewritten as updates to yourdb before applying the --database option
#
# 													Thus no updates are left matching --database=mydb
#
# --server-id=<id> 							Display only events created by the server having the given server ID
#
# --set-charset=<charset name> 			Add a SET NAMES <charset name> statement to the output to specify the char set to be used for processing log files.
#
# --shared-memory-base-name=<name> 		On Windows, the shared-memory name to use for connections made using shared memory to a local server.
# 													Defaults to MySQL. Case-sensitive
#
# 													Server must be started with --shared-memory to enable shared-memory connections
#
# --short-form, -s 							Display only the statements contained in the log, without any extra information or row-based events.
# 													DEPRECATED, DO NOT USE.
#
# --skip-gtids[=(true|false)] 			Do not display any GTIDs in the output. Needed when writing to a dump file from one or more binary logs
# 													containing GTIDs, as shown:
#
# 													mysqlbinlog --skip-gtids binlog.000001 >  /tmp/dump.sql
# 													mysqlbinlog --skip-gtids binlog.000002 >> /tmp/dump.sql
# 													mysql -u root -p -e "source /tmp/dump.sql"
#
# 													Not recommended for production
#
# --socket=<path>, -S <path> 				For connections to localhost, Unix socket file to use or Windows - named pipe to use.
#
# --ssl* 										Options that begin with --ssl specify whether to connect to the server using SSL and indicate where to
# 													find SSL keys and certs.
#
# --ssl-fips-mode={OFF|ON|STRICT} 		Controlling FIPS mode on the client side.
#
# --start-datetime=<datetime> 			Start reading the binary log at the first event having a timestamp equal to or later than the <datetime> argument.
# 													The <datetime> value is relative to the local time zone on the machine where you run mysqlbinlog.
#
# 													The value should be in a format accepted for the DATETIME or TIMESTAMP data types.
#
# 													mysqlbinlog --start-datetime="2005-12-25 11:25:56" binlog.000003
#
# 													Useful for point-in-time recovery.
#
# --start-position=<N>, -j <N> 			Start reading the binary log at the first event having a position equal to or greater than <N>.
# 													This option applies to the first log file named on the cmd line.
#
# 													Useful for point-in-time recovery.
#
# --stop-datetime=<datetime> 				Stop reading the binary log at the first event having a timestamp equal to or later than the <datetime> argument.
# 													This option is useful for point-in-time recovery.
#
# --stop-never 								This option is used with --read-from-remote-server. It tells mysqlbinlog to remain connected to the server.
# 													Otherwise mysqlbinlog exits when the last log file has been transferred from the server.
#
# 													--stop-never implies --to-last-log - so only the first log file to transfer needs to be named on the cmd line.
#
# 													--stop-never is commonly used with --raw to make a live binary log backup, but can also be used without --raw
# 													to maintain a continous text display of log events as the server generates them.
#
# 													With --stop-never, by default, mysqlbinlog reports a server ID of 1 when it connects to the server.
# 													Use --connection-server-id to explicitly specify an alternative ID to report. Can be used to
# 													avoid a conflict with the ID of a slave server or another mysqlbinlog.
#
# --stop-never-slave-server-id=<id> 	DEPRECATED, use --connection-server-id instead to specify a server ID for mysqlbinlog to report.
#
# --stop-position=<N> 						Stop reading the binary log at teh first event having a position equal to or greater than <N>.
# 													Applies to the last log file named on the cmd line.
#
# 													Useful for point-in-time recovery.
#
# --tls-version=<protocol list> 			The protocols permitted by the client for encrypted connections. Depends on compilated SSL libs relative to MySQL.
#
# --to-last-log, -t 							Do not stop at the end of requested binary log from a MySQL server, but rather continue printing
# 													until the end of the last binary log.
#
# 													If this is sent to the same MySQL server, it causes an endless loop.
#
# 													Requires --read-from-remote-server.
#
# --user=<user name>, -u <user_name> 	The MySQL user name to use when connecting to a remote server
#
# --verbose, -v 								Reconstruct row events and display them as commented SQL statements.
# 													If given twice - output includes comments to indicate column data types, some metadata and row query log events.
#
# --verify-binlog-checksum, -c 			Verify checksums in binary log files.
#
# --version, -V 								Display version info and exit
#
# --open_files_limit=<value> 				Specifies number of open file descriptors to reserve
#
# We can pipe the output of mysqlbinlog into the mysql client to execute the events contained in the binary log.
# This can be done to recover from a crash with a old backup:
#
# mysqlbinlog binlog.000001 | mysql -u root -p
#
# or
#
# mysqlbinlog binlog.[0-9]* | mysql -u root -p
#
# If the statements produced by mysqlbinlog may contain BLOB values, these may cause problems when mysql processes them.
# In such a case - use mysql with --binary-mode then.
#
# We can also redirect the output of mysqlbinlog to a text file instead - if we need to modify the statement log first
# (for example - to remove statements that we do not want to execute)
#
# Example of redirection:
#
# mysqlbinlog binlog.000001 > tmpfile #Redirect unto tmpfile
# <Interlude>
# mysql -u root -p < tmpfile #Redirect from tmpfile to the DB
#
# When mysqlbinlog is invoked with the --start-position option - it displays only those events
# with an offset in the binary log greater than or equal to the given pos. (The pos must align with start of an event)
#
# Thus we can do rollbacks or rollfowards to specific time points - such as roll forward to how the DB was @ a specific time point (in tandem with --stop-datetime)
#
# The following covers how to approaching multiple file integrations: 
#
#
# mysqlbinlog binlog.000001 | mysql -u root -p  #Problematic if contains CREATE TEMPORARY TABLE statement and second uses said table
# mysqlbinlog binlog.000002 | mysql -u root -p  #The reason why it's an isssue, is that the connection is terminated between the two commands, so tmp table is dropped - have to specify them as 1 command
#
# Example:
#
# mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p
#
# Another way is to route log files to a file and then read the file:
#
# mysqlbinlog binlog.000001 > /tmp/statements.sql
# mysqlbinlog binlog.000002 >> /tmp/statements.sql
# mysql -u root -p -e "source /tmp/statements.sql"
#
# As of 8.0.12, you can also supply multiple binary log files to mysqlbinlog as streamed input using a shell pipe.
# An archive of compressed binary log files can be decompressed and provided directly to mysqlbinlog.
#
# In this example, binlog-files_1.gz contains multiple binary log files for processing.
#
# The pipeline extracts the contents of binlog-files_1.gz - pipes the binary log files to mysqlbinlog as standard input,
# and pipes the output of mysqlbinlog into mysql for execution:
#
# gzip -cd binlog-files_1.gz | ./mysqlbinlog - | ./mysql -uroot -p
#
# We can chain more than one archive file:
#
# gzip -cd binlog-files_1.gz binlog-files_2.gz | ./mysqlbinlog - | ./mysql -uroot -p
#
# For streamed input, do not use --stop-position, because mysqlbinlog cannot identify the last log file to apply this option.
#
# LOAD DATA INFILE operations: mysqlbinlog can produce output that reproduces a LOAD DATA INFILE operation without
# the original data file.
#
# mysqlbinlog copies the data to a temp file and writes a LOAD DATA LOCAL INFILE statement that refers to the file.
# The default location of the dir where said files are written is system-specific.
#
# To specify a dir explicitly, use the --local-load option
#
# Because mysqlbinlog converts LOAD DATA INFILE statements to LOAD DATA LOCAL INFILE statements (i.e, it adds LOCAL) - both the client
# and server that you use to process the statements must be configured with the LOCAL capability enabled.
#
# WARNING: The temporary files created for LOAD DATA LOCAL statements are NOT automatically deleted because they are
# 			  needed until you actually execute those statements. You should delete the temporary files yourself after
#  		  you no longer need the statement log. The files can be found in the temporary file dir and have names like:
# 			  <original_file_name-#-#>
#
# The following covers mysqlbinlog Hex Dump Format
#
# The --hexdump option causes mysqlbinlog to produce a hex dump of the binary log contents:
#
# 	mysqlbinlog --hexdump master-bin.000001
#
# The hex output consists of comment lines beginning with #, it might look as follows:
#
# /* !40019 SET @@session.max_insert_delayed_threads=0*/;
# /* !50003 SET @@OLD_COMPLETION_TYPE=@@COMPLETION_TYPE, COMPLETION_TYPE=0*/;
# at 4
# 051024 17:24:13 server id 1 end_log_pos 98
# Position 	Timestamp 	Type 		Master ID 		Size 		Master Pos 	  Flags
# <                    Hexadecimal outputs           >   62 00 00 00   00 00
# < 						  Hexadecimal outputs 			  >   |..5.0.15.debug.l|
# etc.
# 		Start: binlog v 4, server v 5.0.15-debug-log created 051024 17:24:13
# 		at startup
# ROLLBACK;
#
# The hex dump output contains the elements in the following list: (This might change)
#
# Position: The byte pos within the log file
# Timestamp: The event timestamp. In the example shown, '9d fc 5c 43' is the representation of '051024 17:24:13' in hexadecimal
# Type: The event type code
# Master ID: The server ID of the master that created the event
# Size: The size in bytes of the event
# Master Pos: The position of the next event in the original master log file.
# Flags: Event flag values.
#
# The following covers mysqlbinlog Row Event Displays:
#
# The following examples illustrate how mysqlbinlog displays row events that specify data modifications.
# These correspond to events with the WRITE_ROWS_EVENT, UPDATE_ROWS_EVENT and DELETE_ROWS_EVENT type codes.
#
# The --base64-output=DECODE-ROWS and --verbose options may be used to affect row event output.
#
# Suppose that the server is using row-based binary logging and that you execute the following sequence of statements:
#
# CREATE TABLE t
# (
# 	 id 	INT NOT NULL,
# 	 name VARCHAR(20) NOT NULL,
#   date DATE NULL,
# ) ENGINE = InnoDB;
#
# START TRANSACTION;
# INSERT INTO t VALUES(1, 'apple', NULL);
# UPDATE t SET name = 'pear', date = '2009-01-01' WHERE id = 1;
# DELETE FROM t WHERE id = 1;
# COMMIT;
#
# By default, mysqlbinlog displays row events encoded as base-64 strings using BINLOG statements.
# Omitting extraneous lines, the output for the row events produced by the preceding statement sequences might look as follows:
#
# mysqlbinlog <log_file>
#
# # at 218
# #080828 15:03:08 server id 1 end_log_pos 258 		Write_rows: 	table id 17 flags: 	STMT_END_F
# 
# BINLOG '
# <string>
# '/*!*/;
# ...
# # at 302
# #080828 15:03:08 server id 1 end_log_pos 356 		Update_rows: 	table id 17 flags: 	 STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/;
# ...
# # at 400
# #080828 15:03:08 server id 1 end_log_pos 442 		Delete_rows: table id 17 flags: STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/;
#
# We can convert said binary strings to closer to SQL, with --verbose or -v. Said lines pertain to the lines starting with ###
# 
# mysqlbinlog -v <log_file>
# ...
# # at 218
# #080828 15:03:08 server id 1 	end_log_pos 258 		Write_rows: table id 17 flags: STMT_END_F
# 
# BINLOG '
# <string>
# '/*!*/;
# ### INSERT INTO test.t
# ### SET
# ###   @1=1
# ###   @2='apple'
# ###   @3=NULL
# ...
# # at 302
# #080828 15:03:08 server id 1 	end_log_pos 356 		Update_rows: table id 17 	flags: STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/
# ### UPDATE test.t
# ### WHERE
# ###   @1=1
# ###   @2='apple'
# ###   @3=NULL
# ### SET
# ###   @1=1
# ###   @2='pear'
# ###   @3='2009:01:01'
# ...
# # at 400
# #080828 15:03:08 server id 1 end_log_pos 442 		Delete_rows: table id 17 flags : STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/
# ### DELETE FROM test.t
# ### WHERE
# ###   @1=1
# ###   @2='pear'
# ###   @3='2009:01:01'
#
# Where of, if we do it twice:
#
# mysqlbinlog -vv <log_file>
# ...
# # at 218
# #080828 15:03:08 server id 1  end_log_pos 258 	Write_rows: table id 17 flags: STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/;
# ### INSERT INTO test.t
# ### SET
# ###   @1=1 /* INT meta=0 nullable=0 is_null=0 */
# ###   @2='apple' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
# ###   @3=NULL /* VARSTRING(20) meta=0 nullable=1 is_null=1 */
# ...
# # at 302
# #080828 15:03:08 server id 1 end_log_pos 356 	Update_rows: table id 17 flags: STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/;
# ### UPDATE test.t
# ### WHERE
# ###   @1=1 /*  INT meta=0 nullable=0 is_null=0 */
# ###   @2='apple' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
# ###   @3=NULL /* VARSTRING(20) meta=0 nullable=1 is_null=1 */
# ### SET
# ###   @1=1 /*  INT meta=0 nullable=0 is_null=0 */
# ###   @2='pear' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
# ###   @3='2009:01:01' /* DATE meta=0 nullable=1 is_null=0 */
# ...
# at 400
#080828 15:03:08 server id 1 	end_log_pos 442 	Delete_rows: table id 17 flags: STMT_END_F
#
# BINLOG '
# <string>
# '/*!*/;						
# ### DELETE FROM test.t
# ### WHERE
# ###   @1=1 /* INT meta=0 nullable=0 is_null=0 */
# ###   @2='pear' /* VARSTRING(20) meta=20 nullable=0 is_null=0 */
# ###   @3='2009:01:01' /* DATE meta=0 nullable=1 is_null=0 */
#
# You can tell mysqlbinlog to suppress the BINLOG statements for row events by using the --base64-output=<DECODE-ROWS> option.
# This is similar to --base64-output=NEVER but it does not exit with an error if a row event is found.
# The combination of --base64-output=<DECODE-ROWS> and --verbose provides a convenient way to see row events
# only as SQL statements:
#
# mysqlbinlog -v --base64-output=DECODE-ROWS log_file
# # at 218
# #080828 15:03:08 server id 1 end_log_pos 258 		Write_rows: table id 17 flags: STMT_END_F
# ### INSERT INTO test.t
# ### SET
# ###   @1=1
# ###   @2='apple'
# ###   @3=NULL
# ...
# # at 302
# #080828 15:03:08 server id 1 end_log_pos 356 		Update_rows: table id 17 flags: STMT_END_F
# ### UPDATE test.t
# ### WHERE
# ###   @1=1
# ###   @2='apple'
# ###   @3=NULL
# ### SET
# ###   @1=1
# ###   @2='pear'
# ###   @3='2009:01:01'
# ...
# # at 400
# #080828 15:03:08 server id 1 	end_log_pos 442 		Delete_rows: table id 17 flags: STMT_END_F
# ### DELETE FROM test.t
# ### WHERE
# ###   @1=1
# ###   @2='pear'
# ###   @3='2009:01:01'
#
# NOTE: You should not suppress BINLOG statements if you intend to re-execute mysqlbinlog output
#
# The SQL statements produced by --verbose for row events are much more readable than the corresponding BINLOG statements.
# However, they do not correspond exactly to the original SQL statements that generated the events.
#
# The following limitations apply:
#
# The original column names are lost and replaced by @N where N is the column number
# 
# Character set information is not available in the binary log, which affects string column display:
# 		
# 		There is no distinction made between corresponding binary and nonbinary string types (BINARY and CHAR, VARBINARY and VARCHAR, BLOB and TEXT)
#     The output uses a data type of STRING for fixed-length strings and VARSTRING for variable-length strings.
#
# 		For multibyte char sets, the max number of bytes per character is not present in the binary log, so the length for string
# 		types is displayed in bytes rather than in characters. For example, STRING(4) will be used as the data type for values from either
#     of these column types:
#
# 		CHAR(4) 	CHARACTER SET latin1
# 		CHAR(2) 	CHARACTER SET ucs2
#
# 		Due to the storage format for events of type UPDATE_ROWS_EVENT, UPDATE statements are displayed with the WHERE clause preceding the SET clause.
# 
# Proper interpretation of row events requires the information from the format description event at the beginning of the binary log.
#
# Because mysqlbinlog does not know in advance whether the rest of the log contain rows row events, by default it displays the format
# description event using a BINLOG statement in the initial part of the output.
#
# If the binary log is known not to contain any events requiring a BINLOG statement (that is, no row events) - the --base64-output=NEVER option can be 
# used to prevent this header from being written.
#
# The following covers using mysqlbinlog to Back Up Binary Log Files
#
# By default, mysqlbinlog reads binary log files and displays their contents in text format. This enables you
# to examine events within the files more easily and to re-execute them (For example - by using the output as input to mysql)
#
# mysqlbinlog can read log files directly from the local file system, or, with the --read-from-remote-server option
# - it can connect to a server and request binary log contents from that server.
#
# mysqlbinlog writes text output to its standard output - or to the file named as the value of the --result-file=<file name> option
# if that option is given.
#
# mysqlbinlog can read binary log files and write new files containing the same content - that is, in binary
# format rather than text format.
#
# This capability enables you to easily back up a binary log in its original format. mysqlbinlog can make a static
# backup, backing up a set of log files and stopping when the end of the last file is reached.
#
# It can also make a continuous ("live") backup - staying connected to the server when it reaches the end of the last log
# file and continuing to copy new events as they are generated.
#
# In continuous-backup operation, mysqlbinlog runs until the connection ends (for example - when the server exits) or mysqlbinlog
# is forcibly terminated. When the connection ends, mysqlbinlog does not wait and retry the connection - unlike a slave replication server.
#
# To continue a live backup after the server has been restarted - you must also restart mysqlbinlog.
#
# Binary log backup requires that you invoke mysqlbinlog with two options at minimum:
#
# 		The --read-from-remote-server (or -R) option tells mysqlbinlog to connect to a server and request its binary log.
# 				(This is similar to a slave replication server connecting to its master server)
#
# 		The --raw option tells mysqlbinlog to write raw (binary) output, not text output
#
# Along with --read-from-remote-server - it is common to specify other options: --host indicates where the server
# is running and you may also need to specify connection options such as --user and --password
#
# Several other options are useful in conjunction with --raw:
#
# 		--stop-never: Stay connected to the server after reaching the end of the last log file and continue to read new events
#
# 		--connection-server-id=<id>: The server ID that mysqlbinlog reports when it connects to a server. 
# 											  When --stop-never is used, the default reported server ID is 1.
# 											  If this causes a conflict with the ID of a slave server or another mysqlbinlog process,
# 											  use --connection-server-id to specify an alternative server ID.
#
# 		--result-file: A prefix for output file names, as described later.
#
# To back up a server's binary log files with mysqlbinlog, you must specify file names that actually exist on the server.
# If you do not know the names, connect to the server and use the SHOW BINARY LOGS statement to see the current names.
#
# Suppose that the statement produces this output:
#
# 	SHOW BINARY LOGS;
# 	
# 		Log_name 			File_size
# 	 binlog.000130 		27459
#   binlog.000131 		13719
# 	 binlog.000132 		43268
#
# With that information, you can use mysqlbinlog to back up the binary log to the current dir as follows (enter each command on a single line):
#
# 		To make a static backup of binlog.000130 through binlog.000132, use either of the following commands:
#
# 			mysqlbinlog --read-from-remote-server --host=host_name --raw
# 				binlog.000130 binlog.000131 binlog.000132
#
# 			mysqlbinlog --read-from-remote-server --host=host_name --raw
# 				--to-last-log binlog.000130
#
# 		The first command specifies every file name explicitly. The second names only the first file and uses --to-last-log
# 		to read through the last.
#
# 		A difference between these commands is that if the server happens to open binlog.000130 before mysqlbinlog reaches the
# 		end of binlog.000132, the first command will not read it - but the second will.
#
# 		To make a live backup in which mysqlbinlog starts with binlog.000130 to copy existing log files - then stays
# 		connected to copy new events as the server generates them:
#
# 			mysqlbinlog --read-from-remote-server --host=host_name --raw --stop-never binlog.000130
#
# 		With --stop-never, it is not nessecary to specify --to-last-log to read to the last log file because that option is implied.
#
# The following pertains to Output File Naming
#
# Without --raw, mysqlbinlog produces text output and the --result-file option, if given - specifies the name of the single file
# to which all output is written.
#
# With --raw, mysqlbinlog writes one binary output file for each log file transferred from the server.
# By default, mysqlbinlog writes the files in the current directory with the same name as the original log files.
#
# To modify the output file names, use the --result-file option. In conjunction with --raw, the --result-file option
# value is treated as a prefix that modifies the output file names.
#
# Suppose that a server currently has binary log files named binlog.000999 and up.
# If you use mysqlbinlog --raw to back up the files, the --result-file option produces
# output file names as shown soon.
#
# You can write the files to a specific directory by beginning the --result-file value with the directory path.
# If the --result-file value consists only of a directory name - the value must end with the pathname separator char.
#
# Output files are overwritten if they exist:
#
# 	--result-file OPTION 		OUTPUT FILE NAMES
# --result-file=x 				xbinlog.000999 and up
# --result-file=/tmp/ 			/tmp/binlog.000999 and up
# --result-file=/tmp/x 			/tmp/xbinlog.000999 and up
#
# The following is an example of using mysqldump + mysqlbinlog for Backup and Restore
#
# The following example describes a simple scenario that shows how to use mysqldump and mysqlbinlog together to back
# up a server's data and binary log - and how to use the backup to restore the server if data loss happens.
#
# The example assumes that the server is running on host <host_name> and its first binary log file is named
# binlog.000999. 
#
# Make a continous backup of the bin log:
#
# mysqlbinlog --read-from-remote-server --host=host_name --raw
# 	--stop-never binlog.000999
#
# We can also use mysqldump to make a dump file which acts as a snapshot of the server's data.
#
# Use --all-databases, --events, and --routines to back up all data and --master-data=2 to include the
# current bin log co-ords in the dump file.
#
# mysqldump --host=host_name --all-databases --events --routines --master-data=2> <dump_file> #Select all the data, include binary log co-ords in the dump
#
# We can execute above to make snaphots. 
#
# To restore by usage of a dump file:
#
# mysql --host=host_name -u root -p < <dump_file>
#
# Assuming the binlog file looks as follows:
#
# -- CHANGE MASTER TO MASTER_LOG_FILE='binlog.001002', MASTER_LOG_POS=27284;
#
# If the most recent is binlog.001004, you can re-execute log events as follows:
#
# mysqlbinlog --start-position=27284 binlog.001002 binlog.001003 binlog.001004 | mysql --host=host_name -u root -p
#
# We may also copy the backup files to the server, if we do not have root access.
#
# The following covers how to Specify mysqlbinlog Server ID
#
# When invoked with the --read-from-remote-server option, mysqlbinlog connects to a MySQL server,
# specifies a server ID to identify itself - requests binary log files.
#
# We can use mysqlbinlog to request log files from a server in several ways:
#
# Specify an explicit named set of files: For each file, mysqlbinlog connects and issues a Binlog dump command.
# The server sends the file and disconnects. There is one connection per file.
#
# Specify the beginning file and --to-last-log: mysqlbinlog connects and issues a Binlog dump command for all files.
# The server sends all the files and disconnects.
#
# Specify the beginning file and --stop-never (implies --to-last-log): mysqlbinlog connects and issues a Binlog dump
# command for all files. The server sends all files - but does not disconnect after sending the last one.
#
# If we use --read-from-remote-server only - mysqlbinlog connects using a server ID of 0 - which tells the server to disconnect
# after sending the last requested log file.
#
# With --read-from-remote-server and --stop-never, mysqlbinlog connects using a nonzero server ID, so the server does not
# disconnect after sending the last log file. The server ID is 1 by default, but can be changed with --connection-server-id.
#
# Thus, for the first two ways of requesting files, the server disconnects because mysqlbinlog specifies a server ID of 0.
# Does not disconnect if --stop-never is given because mysqlbinlog specifies a nonzero server ID.
#
# The following covers mysqldumpslow - Summarizing Slow Query Log Files
#
# The MySQL slow query log contains info about queries that take a long time to execute.
# mysqldumpslow parses MySQL slow query log files and prints a summary of their contents.
#
# Normally - mysqldumpslow groups queries that are similar except for the particular values of number and
# string data values. It "abstracts" these values to N and 'S' when displaying summary output.
#
# The -a and -n options can be used to modify value abstracting behavior.
#
# Invoke as follows:
#
# mysqldumpslow [<options>] [<log_file> ...]
#
# The following options pertain to mysqldumpslow:
#
# -a 		   Do not abstract all numbers to N and strings to S
# -n 		   Abstract numbers with at least the specified digits
# --debug   Write debug information
# -g 		   Only consider statements that match the pattern
# --help    Display help message and exit
# -h 		   Host name of the server in the log file name
# -i 		   Name of the server instance
# -l 		   Do not subtract lock time from total time
# -r 		   Reverse the sort order
# -s 		   How to sort output
# -t 		   Display only first num queries
# --verbose Verbose mode
#
# The following covers dynamics in more detail:
#
# --help - Display help message and exit
# -a - Do not abstract all numbers to N and strings to 'S'
# --debug, -d - Run in debug mode
# -g <pattern> - Consider only queries that match the (grep-style) pattern
# -host, <host_name> - Host name of the MySQL server for *-slow.log file name.
# 							  Can contain wildcard. Default wildcard is *
# -i <name> - Name of server instance (if using mysql.server startup script)
# -l - Do not subtract lock time from total time
# -n <N> - Abstract numbers with at least <N> digits within names
# -r - Reverse the sort order
# -s <sort_Type> - How to sort the output. The value of <sort_type> should be chosen from the following list:
# 						
# 						 		t, at: Sort by query time or average query time
# 								l, al: Sort by lock time or average lock time
# 								r, ar: Sort by rows sent or average rows sent
# 								c: Sort by count
#
# 								By default, it sorts by average query time (same as -s at)
#
# -t <N> - Display only the first <N> queries in the output.
# --verbose, -v - Verbose mode. 
#
# Example output:
#
# mysqldumpslow
#
# Reading mysql slow query log from /usr/local/mysql/data/mysqld51-apple-slow.log
# Count: 1 	Time=4.32s (4s) 	Lock=0.00s 	(0s) 		Rows=0.0 (0), 	root[root]@localhost
# 	insert into t2 select * from t1
#
# Count: 3 Time=2.53s (7s) Lock=0.00s (0s) 		Rows=0.0 (0), root[root]@localhost
# 	insert into t2 select * from t1 limit N
#
# Count: 3 Time=2.13s (6s) Lock=0.00s (0s) 		Rows=0.0 (0), root[root]@localhost
# 	insert into t1 select * from t1
#
# The following covers MySQL Program Development Utilities
#
# In shell scripts, you can use the my_print_defaults program to parse option files and 
# see what options would be used by a given program.
#
# The following example shows the output that my_print_defaults might produce when asked to show
# the options found in the [client] and [mysql] groups:
#
# my_print_defaults client mysql
# --port=3306
# --socket=/tmp/mysql.sock
# --no-auto-rehash
#
# Option file handling is implemented in the C client lib simply by processing all options in the
# appropiate group or groups before any CMDline args.
#
# The following pertains to mysql_config - A utility to display options for Compiling Clients
#
# mysql_config provides you with useful information for compiling your MySQL client and connecting it to MySQL.
# It's a shell script.
#
# Note: pkg-config can be used as an alternative to mysql_config for obtaining info such as compiler flags
# or link libraries required to compile MySQL apps.
#
# mysql_config supports the following:
#
# --cflags - C compiler flags to find include files and critical compiler flags - defines used when compiling the libmysqlclient lib.
# 				 The options returned are tied to the specific compiler that was used when the library was created and might 
# 				 clash with the settings for your own compiler.
#
# 				 Using --include is more integratable in relation to portable options that contain only include paths.
#
# --cxxflags - Like -cflags, but for C++ compiler flags
#
# --include - Compiler options to find MySQL include files
#
# --libs - Libs and options required to link with the MySQL client lib.
#
# --libs r - Libs and options required to link with the thread-safe MySQL client lib.
# 				 In MySQL 8.0, all client libs are thread-safe. --libs can be used in all cases.
#
# --plugindir - Default plugin dir path name, defined when configuring MySQL
#
# --port - Default TCP/IP port number, defined when configuring MySQL
#
# --socket - Default Unix socket file, defined when configuring MySQL
#
# --variable=<var_name> - Display the value of the named config variable. 
# 								  Permitted <var_name> values are pkgincludedir (header file dir),
# 						        pkglibdir (the lib dir),
# 								  plugindir (the plugin dir)
#
# --version - Version number for MySQL distri
#
# If you invoke mysql_config with no options, it displays a list of all options that it supports and their values:
#
# mysql_config
# Usage: 	/usr/local/mysql/bin/mysql_config [options]
# Options:
# 	--cflags 		[-I/usr/local/mysql/include/mysql -mcpu=pentiumpro]
#  --cxxflags 		[-I/usr/local/mysql/include/mysql -mcpu=pentiumpro]
#  --include 		[-I/usr/local/mysql/include/mysql]
# 	--libs 			[-L/usr/local/mysql/lib/mysql -lmysqlclient
# 						 -lpthread -lm -lrt -lssl -lcrypto -ldl]
#  --libs_r 		[-L/usr/local/mysql/lib/mysql -lmysqlclient_r
# 						 -lpthread -lm -lrt -lssl -lcrypto -ldl]
#  --plugindir 	[/usr/local/mysql/lib/plugin]
# 	--socket 		[/tmp/mysql.sock]
# 	--port 			[3306]
#  --version 		 [5.8.0-m17]
#  --variable=<VAR> VAR is one of :
# 			pkgincludedir 	[/usr/local/mysql/include]
# 			pkglibdir 		[/usr/local/mysql/lib]
# 			plugindir 		[/usr/local/mysql/lib/plugin]
#
# We can use mysql_config within a CMD line using backticks to include output for particular options.
# For example, we can compile and link a MySQL client program as follows:
#
# gcc -c `mysql_config --cflags` progname.c
# gcc -o progname progname.o `mysql_config --libs`
#
# The following pertains to my_print_defaults - Used for Display Options from Option Files
#
# my_print_defaults displays the options that are present in option groups of option files. 
# The output indicates what options will be used by programs that read the specified option
# groups.
#
# For example, the mysqlcheck program reads the [mysqlcheck] and [client] option groups.
# To see what options are present in thoose groups in the standard option files, invoke the
# my_print_defaults as follows:
#
# my_print_defaults mysqlcheck client
# --user=myusername
# --password=password
# --host=localhost
#
# The output consists of options - one a line.
#
# The following options are supported in terms of my_print_defaults:
#
# --help, -? - Display a help message and exit
#
# --config-file=<file name>, - Read only the given option file
# --defaults-file=<file name>,
#  -c <file_name>
#
# --debug=<debug options>, - Write a debugging log. A typical <debug_options> string is d:t:o, <file_name>.
#  -# <debug_options> 		  Defaults to d:t:o, /tmp/my_print_defaults.trace
#
# --defaults-extra-file=<file name>, - Read this option file after global option file (but on Unix) before the user option file.
# --extra-file=<file name>,
#  -e <file_name>
#
# --defaults-group-suffix=<suffix>, - Suffix regex match option groups
#  -g <suffix>
# --login-path=<name>, - Read options from the named login path in the .mylogin.cnf login path file.
#  -L <name>
# --no-defaults, -n - Return an empty string
# --show, -s - my_print_defaults masks PWs by default. Use this to display in cleartext.
# --verbose, -v - Verbose mode.
# --version, -V - Version info and exit
#
# The following pertains to resolve_stack_dump - Used to resolve Numeric Stack Trace Dump to Symbols
#
# resolve_stack_dump resolves a numeric stack dump to symbols.
#
# Invoke:
#
# resolve_stack_dump [<options>] <symbols_file> [<numeric_dump_file>]
#
# The symbols file should include the output from the nm --numeric-sort mysqld command.
# The numeric dump file should contain a numeric stack track from mysqld.
# If no numeric dump file is named on the command line, the stack trace is read from the standard input.
#
# resolve_stack_dump supports the following options:
#
# --help, -h - Display a help message and exit.
# --numeric-dump-file=<file name>, -n <file_name> - Read the stack trace from the given file.
# --symbols-file=<file name>, -s <file_name> - Use the given symbols file.
# --version, -V - Display version info and exit.
#
# The following covers lz4_decompress - Decompress mysqlpump LZ4-Compressed Output
#
# The lz4_decompress utility decompresses mysqlpump output that was created using LZ4 compression.
#
# NOTE: If MySQL was configured with the -DWITH LZ4=system option, lz4_decompress is not built.
# 	     In this case, the system lz4 command can be used instead.
#
# Invoke lz4_decompress like this:
# lz4_decompress <input_file> <output_file>
#
# Example of usage:
#
# mysqlpump --compress-output=LZ4 > dump.lz4
# lz4_decompress dump.lz4 dump.txt
#
# To see help messages in relation to lz4_decompress, run it with no args.
# To decompress mysqlpump ZLIB-compressed output, use zlib_decompress.
#
# The following pertains to perror - Which displays error messages:
#
# perror displays the error message for MySQL or operating system error codes.
#
# perror [<options>] <errorcode> ...
#
# perror attempts to be flexible in understanding args. For example - 
#
# ER WRONG VALUE FOR VAR - can be translated as 1231, 001231, MY-1231 or MY-001231 or ER WRONG VALUE FOR VAR
#
# shell>perror 1231
# MySQL error code MY-001231 (ER_WRONG_VALUE_FOR_VAR): Variable '%-.64s' can't be set to the value of '%-.200s'
#
# If a error number is in the range where MySQL and OS sys errors overlap, perror displays both error messages:
# 
# perror 1 13
# OS error code 1: Operation not permitted
# MySQL error code MY-000001: Can't create/write to file '%s' (OS errno %d - %s)
# OS error code 13: Permission denied
# MySQL error code MY-000013: Can't get stat of '%s' (OS errno %d - %s)
#
# To obtain the error message for a MySQL Cluster error code, invoke perror with the --ndb option:
#
# perror --ndb <errorcode>
#
# The meaning of system error messages may be dependent on the OS. 
#
# perror supports the following options:
#
# --help, --info, -I, -? - Display a help message and exit
# --ndb - print the error message for a MySQL Cluster error code
# --silent, -s - Silent mode. Print only the error message
# --verbose, -v - Verbose mode
# --version, -V - Version info and exit
#
# The following covers the dynamics of resolveip - Resolve Host name to IP Address or Vice Versa
#
# The resolveip utility resolves host names to IP addresses and vice versa.
#
# Invoke as follows:
#
# resolveip [<options>] {<host_name>|<ip-addr>} ...
#
# Supports the following options:
#
# --help, --info, -?, -I - Display a help message and exit
# --silent, -s - Silent mode.
# --version, -V - Display version info and exit.
#
# The following options cover zlib_decompress - Decompress mysqlpump ZLIB-Compressed Output
#
# The zlib_decompress utility decompresses mysqlpump output that was created using ZLIB compression.
#
# Note: If we configured MySQL with the -DWITH ZLIB=system option, zlib_decompress is not built.
# 		  Then we can use openssl zlib instead.
#
# To use zlib_decompress:
#
# zlib_decompress <input_file> <output_file>
#
# Example:
#
# mysqlpump --compress-output=ZLIB > dump.zlib
# zlib_decompress dump.zlib dump.txt
#
# To see a help message, just run zlib_decompress with no args.
#
# To decompress mysqlpump LZ4-compressed output, use lz4_decompress.
#
# The following pertains to MySQL Program Env Variables:
#
# VARIABLE 										Desc
# AUTHENTICATION_PAM_LOG 				PAM authentication plugin debug logging settings
# CC 											The name of your C compiler (for running CMake)
# CXX 										Name of your C++ compiler (for running CMake)
# CC 											Name of your C compiler (for running CMake)
# DBI_USER 									Default user name for Perl DBI
# DBI_TRACE 								Trace options for Perl DBI
# HOME 										The default path for the mysql history file is $HOME/.mysql_history
# LD_RUN_PATH 								Used to specify the location of libmysqlclient.so
# LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN  Enable mysql_clear_password auth plugin
#
# LIBMYSQL_PLUGIN_DIR 					Dir in which to look for client plugins
# LIBMYSQL_PLUGINS 						Client plugins to preload
# MYSQL_DEBUG 								Debug trace options when debugging
# MYSQL_GROUP_SUFFIX 					Option group suffix value (like specifying --defaults-group-suffix)
# MYSQL_HISTFILE 							The path to the mysql history file. If this var is set, its value overrides the default for $HOME/.mysql_history
# MYSQL_HISTIGNORE 						Patterns specifying statements that mysql should not log to $HOME/.mysql_history or syslog if --syslog is given
#
# MYSQL_HOME 								The path to the dir in which the server-specific my.cnf file resides
# MYSQL_HOST 								Default host name used by the mysql cmd line client
# MYSQL_OPENSSL_UDF_DH_BITS 			Maximum key length for CREATE DH PARAMETERS()
#                _THRESHOLD
# MYSQL_OPENSSL_UDF_DSA_BITS 			Maximum DSA key length for CREATE ASYMMETRIC PRIV KEY()
# 					  _THRESHOLD 
# MYSQL_OPENSSL_UDF_RSA_BITS 			Maximum RSA key length for CREATE ASYMMETRIC PRIV KEY()
# 					  _THRESHOLD
# MYSQL_PS1 								The cmd prompt to use use in the mysql cmd line 
# MYSQL_PWD 								The default PW when connecting to mysqld. Insecure.
# MYSQL_TCP_PORT 							Default TCP/IP port number
# MYSQL_TEST_LOGIN_FILE 				The name of the .mylogin.cnf login path file
# MYSQL_TEST_TRACE_CRASH 				Whether the test protocol trace plugin crashes clients.
# MYSQL_TEST_TRACE_DEBUG 				Whether the test protocol trace plugin produces output.
# MYSQL_UNIX_PORT 						The default Unix socket file name, used for connections to localhost
# MYSQLX_TCP_PORT 						The X plugin default TCP/IP port number
#
# MYSQLX_UNIX_PORT 						The X Plugin default Unix socket file name; used for connections to localhost
# NOTIFY_SOCKET 							Socket used by mysqld to communicate with systemd
# PATH 										Used by the shell to find MySQL programs.
# PKG_CONFIG_PATH 						Location of mysqlclient.pc pkg-config file.
# TMPDIR 									The dir in which temp files are created.
# TZ 											Should be set to your local time zone
# UMASK 										The user-file creation mode when creating files
# UMASK_DIR 								The user-directory creation mode when creating dirs
# USER 										The default user name on Windows when connecting to Mysqld
#
# MYSQL_TEST_LOGIN_FILE is the path name of the login path file (the file created by mysql_config_editor).
#
# If not set, the default value is %APPDATA%\MySQL\.mylogin.cnf dir on Windows and $HOME/.mylogin.cnf on non Windows OS's
#
# The MYSQL_TEST_TRACE_DEBUG and MYSQL_TEST_TRACE_CRASH vars control the test protocol trace client plugin,
# if MySQL is built with that plugin enabled.
#
# The default UMASK and UMASK_DIR values are 0640 and 0750, respectively.
#
# MySQL assumes that the value for UMASK or UMASK_DIR is in octal if it starts with a zero.
# For example, setting UMASK=0600 is equivalent to UMASK=384 because 0600 Octal is 384 decimal.
#
# UMASK and UMASK_DIR, are not masks, they are modes.
#
# If UMASK is set, mysqld uses ($UMASK | 0600) as the mode for file creation, so that newly created files have a mode in the range
# from 0600 to 0666 (octal values)
#
# If UMASK_DIR is set, mysqld uses ($UMASK_DIR | 0700) as the base mode for dir creation, which is AND supplemented with ~(~$UMASK & 0666)
# so that newly created dirs have a mode in the range from 0700 to 0777.
#
# The AND may remove read and write permissions from the dir mode, but not execute permissions.
#
# We might need to set PKG_CONFIG_PATH if we use pkg-config in terms of MySQL programs
#
# The following covers MySQL Server Administration
#
# MySQL Server (mysqld) is the main program that does most of the work in a MySQL installation.
# The following will cover:
#
# Server configuration
# The dara dir, particularly the mysql system db
# The server log files
# Management of multiple servers on a single machine
#
# The following covers The MySQL Server
#
# mysqld is the MySQL server. The following will cover:
#
# Startup options that the server supports. You can specify these options on the cmd line, through config files or both.
#
# Server system vars. These vars reflect the current state and values of the startup options, some of which can be modified while the server is running
#
# Server status vars. These vars contain counters and stats about runtime operations
#
# How to set the server SQL mode. Modifies certain aspects of SQL syntax and semantics, for example for compability
# with code from other DBs or to control the error handling for specific situations
#
# Configuring and using IPv6 support
#
# Configuring and using time zone support
#
# Server-side help capabilities
#
# The server shutdown process. Performance and reliability considerations depending on type of table (transactional or nontransactional) and whether to use replication.
#
# NOTE: Not all storage engines are supported by all MySQL server bins and configs.
#
# The following section covers how to configure the Server.
#
# The MySQL server, mysqld has many command options and system vars that can be set at startup to configure its operation.
# To determine the default command option and system var values used by the server:
#
# mysqld --verbose --help
#
# The command produces a list of all mysqld options and config system vars. 
# Its output includes the default option and var values, might look like:
#
# abort-slave-event-count 			0
# allow-suspicious-udfs 			FALSE
# archive 								ON
# auto-increment-increment 		1
# auto-increment-offset 			1
# autocommit 							TRUE
# automatic-sp-privileges 			TRUE
# avoid-temporal-upgrade 			FALSE
# back-log 								80
# basedir 								/home/jon/bin/mysql-8.0/
# ...
# tmpdir 								/tmp
# transaction-alloc-block-size 	8192
# transaction-isolation 			REPEATABLE-READ
# transaction-prealloc-size 		4096
# transaction-read-only 			FALSE
# transaction-write-set-extraction OFF
# updatable-views-with-limit 		YES
# validate-user-plugins 			TRUE
# verbose 								TRUE
# wait-timeout 						28800
#
# To see the system vars in use on the server:
#
# SHOW VARIABLES;
#
# To see some stats and status indicators for a running server:
#
# SHOW STATUS;
#
# We can also see system vars and status through mysqladmin:
#
# mysqladmin variables
# mysqladmin extended-status
#
# Options set on cmd line are only in effect for that session, for permanance use OPtion files.
#
# The following pertains to Server Configuration Defaults:
#
# The MySQL server has many operating params, which you can change at server startup using cmd line options or config files.
# We can also change params at runtime.
#
# On Windows, the MySQL installer interacts with the user and creates a file named my.ini in the base install dir as the default option file
#
# NOTE: The extension on Windows might not be displayed (in terms of .ini or .cnf)
#
# After completing the installation process, you can edit the default option file at any time to modify the params.
#
# On non Windows, no default option file is made in terms of installation. Without a option file, it just runs with defaults.
# 
# The following pertains to Server Options, System vars and Status Vars
#
# The following contains all cmd line options, system vars, and status vars within mysqld.
#
# Cmd line options, System vars, Status vars:
#
# Name 													CMD-line 					Option file 				System Var 				Status Var 			Var Scope 		Dynamic
# abort-slave-event-count 							Yes 							Yes 							
# Aborted_clients 																																Yes 					Global 			No
# Aborted_connects 																																Yes 					Global 			No
# Acl_cache_items_count 																														Yes 					Global 			No
# activate_all_roles_on_login 					Yes 							Yes 							Yes 												Global 			Yes
# allow-suspicious-udfs 							Yes 							Yes 							
# ansi 													Yes 							Yes
# audit-log 											Yes 							Yes
# audit_log_buffer_size 							Yes 							Yes 							Yes 												Global 			No
# audit_log_compression 							Yes 							Yes 							Yes 												Global 			No
# audit_log_connection_policy 					Yes 							Yes 							Yes 												Global 			Yes
# audit_log_current_session 																						Yes						   					Both 				No
#
# audit_log_current_size 																														Yes 					Global 			No
# audit_log_encryption 								Yes 							Yes 							Yes 												Global 			No
# Audit_log_event_max_drop_size 																												Yes 					Global 			No
# Audit_log_events 																																Yes 					Global 			No
# Audit_log_events_filtered 																													Yes 					Global 			No
# Audit_log_events_lost 																														Yes 					Global 			No
# Audit_log_events_written 																													Yes 					Global 			No
#
# audit_log_exclude_accounts 						Yes 							Yes 							Yes 												Global 			Yes
# audit_log_file 										Yes 							Yes 							Yes 												Global 			No
# audit_log_filter_id 																								Yes												Both 				No
# audit_log_flush 																									Yes 												Global 			Yes
# audit_log_format 									Yes 							Yes 							Yes 												Global 			No
# audit_log_include_accounts 						Yes 							Yes 							Yes 												Global 			Yes
# audit_log_policy 									Yes 							Yes 							Yes 												Global 			No
# audit_log_read_buffer_size 						Yes 							Yes 							Yes 												Varies 			Varies
# audit_log_rotate_on_size 						Yes 							Yes 							Yes 												Global 			Yes
#
# audit_log_statement_policy 						Yes 							Yes 							Yes 												Global 			Yes
# audit_log_strategy 								Yes 							Yes 							Yes 												Global 			No
# Audit_log_total_size 																															Yes 					Global 			No
# Audit_log_write_waits 																														Yes 					Global 			No
# authentication_ldap_sasl_auth_method_name 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_bind_base_dn 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_bind_root_dn 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_bind_root_pwd 		Yes 							Yes 							Yes 												Global 			Yes
#
# authentication_ldap_sasl_ca_path 				Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_group_search_attr Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_group_search_ 		Yes 							Yes 							Yes 												Global 			Yes
# filter
# authentication_ldap_sasl_init_pool_size 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_log_status 			Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_max_pool_size 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_server_host 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_server_port 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_tls 					Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_sasl_user_search_attr 	Yes 							Yes 							Yes 												Global 			Yes
#
# authentication_ldap_simple_auth_method_ 	Yes 							Yes 							Yes 												Global 			Yes
# name
# authentication_ldap_simple_bind_base_dn 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_bind_root_dn 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_bind_root_pwd 	Yes 							Yes 							Yes 												Global 			yes
# authentication_ldap_simple_ca_path 			Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_group_ 			Yes 							Yes 							Yes 												Global 			Yes
# search_attr
# authentication_ldap_simple_int_pool_size 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_log_status 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_max_pool_size 	Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_server_host 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_server_port 		Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_tls 				Yes 							Yes 							Yes 												Global 			Yes
# authentication_ldap_simple_user_ 				Yes 							Yes 							Yes 												Global 			Yes
# search_attr
# 
# authentication_windows_log_level 				Yes 							Yes 							Yes 												Global 			No
# authentication_windows_use_principal_name 	Yes 							Yes 							Yes 												Global 			No
# auto_generate_certs 								Yes 							Yes 							Yes 												Global 			No
# auto_increment_increment 																						Yes 												Both 				Yes
# auto_increment_offset 																							Yes 												Both 				Yes
# autocommit 											Yes 							Yes 							Yes 												Both 				Yes
# automatic_sp_privileges 																							Yes 												Global 			Yes
# avoid_temporal_upgrade 							Yes 							Yes 							Yes 												Global 			Yes
# back_log																												Yes 												Global 			No
# basedir 												Yes 							Yes 							Yes 												Global 			No
# 
# big-tables 											Yes 							Yes 																				Both 				Yes
# - Variable: big_tables 																							Yes 												Both 				Yes
# bind-address 										Yes 							Yes 																				Global 			No
# - Variable: bind_address 																						Yes 												Global 			No
# Binlog_cache_disk_use 																														Yes 					Global 			No
# binlog_cache_size 							 		Yes 							Yes 							Yes 												Global 			Yes
#
# Binlog_cache_use 																																Yes 					Global 			No
# binlog-checksum 									Yes 							Yes 							
# binlog_checksum 																									Yes 												Global 			Yes
# binlog_direct_non_transactional_updates 	Yes 							Yes 							Yes												Both 				Yes
# binlog-do-db 										Yes 							Yes 
# binlog_error_action 								Yes 							Yes 							Yes 												Global 			Yes
# binlog_expire_logs_seconds 						Yes 							Yes 							Yes 												Global 			Yes
# binlog-format 										Yes 							Yes 																				Both 				Yes
# - Variable: binlog_format 																						Yes 												Both 				Yes
# binlog_group_commit_sync_delay 				Yes 							Yes 							Yes 												Global 			Yes
# binlog_group_commit_sync_no_delay_count 	Yes 							Yes 							Yes 												Global 			Yes
# binlog_gtid_simple_recovery 					Yes 							Yes 							Yes 												Global 			No
# binlog-ignore-db									Yes 							Yes 
# binlog_max_flush_queue_time 																					Yes 												Global 			Yes
# binlog_order_commits 																								Yes 												Global 			Yes
# binlog-row-event-max-size 						Yes 							Yes 	
# binlog_row_image 									Yes 							Yes 							Yes 												Both 				Yes
# binlog_row_metadata 								Yes 							Yes 							Yes 												Global 			Yes
# binlog_row_value_options 						Yes 							Yes 							Yes 												Both 				Yes
# 
# binlog-rows-query-log-events 					Yes 							Yes 
# -Variable: binlog_rows_query_log_events 	
# binlog_rows_query_log_events 					Yes 							Yes 							Yes 												Both 				Yes
# Binlog_stmt_cache_disk_use 																														Yes 				Global 			No
# binlog_stmt_cache_size 							Yes 							Yes 							Yes 												Global 			Yes
# Binlog_stmt_cache_use 																															Yes 				Global 			No
# binlog_transaction_dependency_history_size Yes 							Yes 							Yes 												Global 			Yes
# binlog_transaction_dependency_tracking 		Yes 							Yes 							Yes 												Global 			Yes
# block_encryption_mode 							Yes 							Yes 							Yes 												Both 				Yes
# bulk_insert_buffer_size 							Yes 							Yes 							Yes 												Both 				Yes
# Bytes_received 																																		Yes 				Both 				No
# Bytes_sent 																																			Yes 				Both 				No
# caching_sha2_password_auto_ 					Yes 							Yes 							Yes 												Global 			No
# generate_rsa_keys
# caching_sha2_password_private_key_path 		Yes 							Yes 							Yes 												Global 			No
# caching_sha2_password_public_key_path 		Yes 							Yes 							Yes 												Global 			No
# Caching_sha2_password_rsa_public_key 																										Yes 				Global 			No
# character_set_client 																								Yes 												Both 				Yes
# character-set-client-handshake 				Yes 							Yes 
# character_set_connection 																						Yes 												Both 				Yes
# character_set_database (note 1) 																				Yes 												Both 				Yes
# character-set-filesystem 						Yes 							Yes 																				Both 				Yes
# -Variable: character_set_filesystem 																			Yes 												Both 				Yes
# character_set_results 																							Yes 												Both 				Yes
# character-set-server 								Yes 							Yes 																				Both 				Yes
# -Variable: character_set_server 																				Yes 												Both 				Yes
# character_set_system 																								Yes 												Global 			No
# character-sets-dir 								Yes 							Yes 																				Global 			No
#
# -Variable: character_sets_dir 																					Yes 												Global 			No
# check_proxy_users 									Yes 							Yes 							Yes 												Global 			Yes
# chroot 												Yes 							Yes 	
# collation_connection 																								Yes 												Both 				Yes
# collation_database (note 1) 																					Yes 												Both 				Yes
# collation-server 									Yes 							Yes 																				Both 				Yes
# -Variable: collation_server 																					Yes 												Both 				Yes
# Com_admin_commands 																																Yes 				Both 				No
# Com_alter_db 																																		Yes 				Both 				No
# Com_alter_event 																																	Yes 				Both 				No
# Com_alter_function 																																Yes 				Both 				No
# Com_alter_procedure 																																Yes 				Both 				No
# Com_alter_resource_group 																														Yes 				Global 			No
# Com_alter_server 																																	Yes 				Both 				No
# Com_alter_table 																																	Yes 				Both 				No
# Com_alter_tablespace 																																Yes 				Both 				No
# Com_alter_user 																																		Yes 				Both 				No
# Com_alter_user_default_role 																													Yes 				Global 			No
#
# Com_analyze 																																			Yes 				Both 				No
# Com_assign_to_keycache 																															Yes 				Both 				No
# Com_begin 																																			Yes 				Both 				No
# Com_binlog 																																			Yes 				Both 				No
# Com_call_procedure 																																Yes 				Both 				No
# Com_change_db 																																		Yes 				Both 				No
# Com_change_master 																																	Yes 				Both 				No
# Com_change_repl_filter 																															Yes 				Both 				No
# Com_check 																																			Yes 				Both 				No
# Com_checksum 																																		Yes 				Both 				No
# Com_commit 																																			Yes 				Both 				No
# Com_create_db																																		Yes 				Both 				No
# Com_create_event 																																	Yes 				Both 				No
# Com_create_function 																																Yes 				Both 				No
#
# Com_create_index 																																	Yes 				Both 				No
# Com_create_procedure 																																Yes 				Both 				No
# Com_create_resource_group 																														Yes 				Global 			No
# Com_create_role 																																	Yes 				Global 			No
# Com_create_server 																																	Yes 				Both 				No
# Com_create_table 																																	Yes 				Both 				No
# Com_create_trigger 																																Yes 				Both 				No
# Com_create_udf 																																		Yes 				Both 				No
# Com_create_user 																																	Yes 				Both 				No
# Com_create_view 																																	Yes 				Both 				No
#
# Com_dealloc_sql 																																	Yes 				Both 				No
# Com_delete 																																			Yes 				Both 				No
# Com_delete_multi 																																	Yes 				Both 				No
# Com_do 																																				Yes 				Both 				No
# Com_drop_db 																																			Yes 				Both 				No
# Com_drop_event 																																		Yes 				Both 				No
# Com_drop_function 																																	Yes 				Both 				No
# Com_drop_index 																																		Yes 				Both 				No
# Com_drop_procedure 																																Yes 				Both 				No
# Com_drop_resource_group 																															Yes 				Global 			No
# Com_drop_role 																																		Yes 				Global 			No
# Com_drop_server 																																	Yes 				Both 				No
# Com_drop_table 																																		Yes 				Both 				No
# Com_drop_trigger 																																	Yes 				Both 				No
# Com_drop_user 																																		Yes 				Both 				No
# Com_drop_view 																																		Yes 				Both 				No
# Com_empty_query 																																	Yes 				Both 				No
# Com_execute_sql 																																	Yes 				Both 				No
#
# Com_explain_other 																																	Yes 				Both 				No
# Com_flush 																																			Yes 				Both 				No
# Com_get_diagnostics 																																Yes 				Both 				No
# Com_grant  																																			Yes 				Both 				No
# Com_grant_roles																																		Yes 				Global 			No
# Com_group_replication_start 																													Yes 				Global 			No
# Com_group_replication_stop 																														Yes 				Global 			No
# Com_ha_close 																																		Yes 				Both 				No
# Com_ha_open 																																			Yes 				Both 				No
# Com_ha_read 																																			Yes 				Both 				No
# Com_help 																																				Yes 				Both 				No
#
# Com_insert 																																			Yes 				Both 				No
# Com_insert_select 																																	Yes 				Both 				No
# Com_install_component 																															Yes 				Global 			No
# Com_install_plugin 																																Yes 				Both 				No
# Com_kill 																																				Yes 				Both 				No
# Com_load 																																				Yes 				Both 				No
# Com_lock_tables 																																	Yes 				Both 				No
# Com_optimize 																																		Yes 				Both 				No
# Com_preload_keys 																																	Yes 				Both 				No
# Com_prepare_sql 																																	Yes 				Both 				No
# Com_purge 																																			Yes 				Both 				No
# Com_purge_before_date 																															Yes 				Both 				No
# Com_release_savepoint 																															Yes 				Both 				No
# Com_rename_table 																																	Yes 				Both 				No
#
# Com_rename_user 																																	Yes 				Both 				No
# Com_repair 																																			Yes 				Both 				No
# Com_replace 																																			Yes 				Both 				No
# Com_replace_select 																																Yes 				Both 				No
# Com_reset 																																			Yes 				Both 				No
# Com_resignal 																																		Yes 				Both 				No
# Com_revoke 																																			Yes 				Both 				No
# Com_revoke_all 																																		Yes 				Both 				No
# Com_revoke_roles 																																	Yes 				Global 			No
# Com_rollback 																																		Yes 				Both 				No
# Com_rollback_to_savepoint 																														Yes 				Both 				No
# Com_savepoint 																																		Yes 				Both 				No
# Com_select 																																			Yes 				Both 				No
# Com_set_option 																																		Yes 				Both 				No
# Com_set_resource_group 																															Yes 				Global 			No
# Com_set_role 																																		Yes 				Global 			No
#
# Com_show_authors 																																	Yes 				Both 				No
# Com_show_binlog_events 																															Yes 				Both 				No
# Com_show_binlogs 																																	Yes 				Both 				No
# Com_show_charsets 																																	Yes 				Both 				No
# Com_show_collations 																																Yes 				Both 				No
# Com_show_contributors 																															Yes 				Both 				No
# Com_show_create_db 																																Yes 				Both 				No
# Com_show_create_event 																															Yes 				Both 				No
# Com_show_create_func 																																Yes 				Both 				No
# Com_show_create_proc 																																Yes 				Both 				No
# Com_show_create_table 																															Yes 				Both 				No
# Com_show_create_trigger 																															Yes 				Both 				No
# Com_show_create_user 																																Yes 				Both 				No
# Com_show_databases 																																Yes 				Both 				No
# Com_show_engine_logs 																																Yes				Both 				No
# Com_show_engine_mutex 																															Yes 				Both 				No
# Com_show_engine_status 																															Yes 				Both 				No
# Com_show_errors 																																	Yes 				Both 				No
#
# Com_show_events 																																	Yes 				Both 				No
# Com_show_fields 																																	Yes 				Both 				No
# Com_show_function_code 																															Yes 				Both 				No
# Com_show_function_status 																														Yes 				Both 				No
# Com_show_grants 																																	Yes 				Both 				No
# Com_show_keys 																																		Yes 				Both 				No
# Com_show_master_status 																															Yes 				Both 				No
# Com_show_ndb_status 																																Yes 				Both 				No
# Com_show_new_master 																																Yes 				Both 				No
# Com_show_open_tables																																Yes 				Both 				No
# Com_show_plugins 																																	Yes 				Both 				No
# Com_show_privileges 																																Yes 				Both 				No
# Com_show_procedure_code 																															Yes 				Both 				No
# Com_show_procedure_status 																														Yes 				Both 				No
# Com_show_processlist 																																Yes 				Both 				No
# Com_show_profile 																																	Yes 				Both 				No
# Com_show_profiles 																																	Yes 				Both 				No
# Com_show_relaylog_events 																														Yes 				Both 				No
# Com_show_slave_hosts 																																Yes 				Both 				No
# 
# Com_show_slave_status 																															Yes 				Both 				No
# Com_show_slave_status_nonblocking 																											Yes 				Both 				No
# Com_show_status 																																	Yes 				Both 				No
# Com_show_storage_engines 																														Yes 				Both 				No
# Com_show_table_status 																															Yes 				Both 				No
# Com_show_tables 																																	Yes 				Both 				No
# Com_show_triggers 																																	Yes 				Both 				No
# Com_show_variables 																																Yes 				Both 				No
# Com_show_warnings 																																	Yes 				Both 				No
# Com_shutdown 																																		Yes 				Both 				No
# Com_signal 																																			Yes 				Both 				No
# Com_slave_start 																																	Yes 				Both 				No
# Com_slave_stop 																																		Yes 				Both 				No
# Com_stmt_close 																																		Yes 				Both 				No
# Com_stmt_execute 																																	Yes 				Both 				No
#
# Com_stmt_fetch 																																		Yes 				Both 				No
# Com_stmt_prepare 																																	Yes 				Both 				No
# Com_stmt_reprepare 																																Yes 				Both 				No
# Com_stmt_reset 																																		Yes 				Both 				No
# Com_stmt_send_long_data 																															Yes 				Both 				No
# Com_truncate 																																		Yes 				Both 				No
# Com_uninstall_component 																															Yes 				Global 			No
# Com_uninstall_plugin 																																Yes 				Both 				No
# Com_unlock_tables 																																	Yes 				Both 				No
# Com_update 																																			Yes 				Both 				No
# Com_update_multi 																																	Yes 				Both 				No
# Com_xa_commit 																																		Yes 				Both 				No
# Com_xa_end 																																			Yes 				Both 				No
# Com_xa_prepare 																																		Yes 				Both 				No
# Com_xa_recover 																																		Yes 				Both 				No
# Com_xa_rollback 																																	Yes 				Both 				No
# Com_xa_start 									- 																									Yes 				Both 				No
# completion_type 								Yes 					Yes 									Yes 													Both 				Yes
# Compression 																																			Yes 				Session 			No
# concurrent_insert 								Yes 					Yes 									Yes 													Global 			Yes
# connect_timeout 								Yes 					Yes 									Yes 													Global 			Yes
# 
# Connection_control_delay_generated 																											Yes 				Global 			No
# connection_control_failed_ 					Yes 					Yes 									Yes 													Global 			Yes
# connections_threshold
# connection_control_max_connection_delay Yes 					Yes 									Yes 													Global 			Yes
# connection_control_min_connection_delay Yes 					Yes 									Yes 													Global 			Yes
# Connection_errors_accept 																														Yes 				Global 			No
# Connection_errors_internal 																														Yes 				Global 			No
# Connection_errors_max_connections 																											Yes 				Global 			No
# Connection_errors_peer_address 																												Yes 				Global 			No
# Connection_errors_select 																														Yes 				Global 			No
# Connection_errors_tcpwrap 																														Yes 				Global 			No
# Connections 																																			Yes 				Global 			No
# console 											Yes 					Yes 
# core-file 										Yes 					Yes
# core_file 																										Yes 													Global 			No
# Created_tmp_disk_tables 																															Yes 				Both 				No
# Created_tmp_files 																																	Yes 				Global 		 	No
# Created_tmp_tables 																																Yes 				Both 				No
# cte_max_recursion_depth 						Yes 					Yes 									Yes 													Both 				Yes
# daemon_memcached_enable_binlog 			Yes 					Yes 									Yes 													Global 			No
# daemon_memcached_engine_lib_name 			Yes 					Yes 									Yes 													Global 			No
# daemon_memcached_engine_lib_path 			Yes 					Yes 									Yes 													Global 			No
# daemon_memcached_option 						Yes 					Yes 									Yes 													Global 			No
#
# daemon_memcached_r_batch_size 				Yes 					Yes 									Yes 													Global 			No
# daemon_memcached_w_batch_size 				Yes 					Yes 
# daemonize 										Yes 					Yes
# datadir 											Yes 					Yes 									Yes 													Global 			No
# date_format 																										Yes 													Global 			No
# datetime_format 																								Yes 													Global 			No
# debug 												Yes 					Yes 									Yes 													Both 				Yes
# debug_sync 																										Yes 													Session 			Yes
# debug-sync-timeout 							Yes 					Yes 	
# default_authentication_plugin 				Yes 					Yes 									Yes 													Globla 			No
# default_collation_for_utf8mb4 										Yes 									Yes 													Both 				Yes
# default_password_lifetime 					Yes 					Yes 									Yes 													Global 			Yes
# default-storage-engine 						Yes 					Yes 																							Both 				Yes
# -Variable: default_storage_engine 																		Yes 													Both 				Yes
# default-time-zone 								Yes 					Yes 
# default_tmp_storage_engine 					Yes 					Yes 									Yes 													Both 				Yes
# default_week_format 							Yes 					Yes 									Yes 													Both 				Yes
# defaults-extra-file 							Yes
# defaults-file 									Yes
# defaults-group-suffix 						Yes
# delay-key-write 								Yes 					Yes 																							Global 			Yes
# - Variable: delay_key_write 																				Yes 													Global 			Yes
# Delayed_errors 																																			Yes 			Global 			No
# 
# delayed_insert_limit 							Yes 					Yes 									Yes 													Global 			Yes
# Delayed_insert_threads 																																Yes 			Global 			No
# delayed_insert_timeout 						Yes 					Yes 									Yes 													Global 			Yes
# delayed_queue_size 							Yes 					Yes 									Yes 													Global 			Yes
# Delayed_writes 																																			Yes 			Global 			No
# des-key-file 									Yes 					Yes 
# disabled_storage_engines 					Yes 					Yes 									Yes 													Global 			No
# disconnect_on_expired_password 			Yes 					Yes 									Yes 													Global 			No
# disconnect-slave-event-count 				Yes 					Yes 
# div_precision_increment 						Yes 					Yes 									Yes 													Both 				Yes
# dragnet.log_error_filter_rules 			Yes 					Yes 									Yes 													Global 			Yes
# dragnet.Status 																																			Yes 			Global 			No
# early-plugin-load 								Yes 					Yes 
# enable-named-pipe 								Yes 					Yes
# - Variable: named_pipe 
# end_markers_in_json 																							Yes 													Both 				Yes
# enforce-gtid-consistency 					Yes 					Yes 									Yes 													Global 			Yes
# enforce_gtid_consistency 					Yes 					Yes 									Yes 													Global 			Yes
# eq_range_index_dive_limit 																					Yes 													Both 				Yes
# 
# error_count 																										Yes 													Session 			No
# event-scheduler 								Yes 					Yes 																							Global 			Yes
# - Variable: event_scheduler 																				Yes													Global 			Yes
# executed-gtids-compression-period 		Yes 					Yes 
# - Variable: executed_gtids_ 																				Yes 													Global 			Yes
#   compression_period
# executed_gtids_compression_period 																		Yes 													Global 			Yes 					
# exit-info 										Yes 					Yes 
# expire_logs_days 								Yes 					Yes 									Yes 													Global 			Yes
# explicit_defaults_for_timestamp 			Yes 					Yes 									Yes 													Both 				Yes
# external-locking 								Yes 					Yes 									
# - Variable: skip_external_locking 
# external_user 																									Yes 													Session			No
# federated											Yes 					Yes 
# Firewall_access_denied 																																	Yes 		Global 			No
# Firewall_access_granted 																																	Yes 		Global 			No
# Firewall_cached_entries 																																	Yes 		Global 			No
# flush 												Yes 					Yes 									Yes 													Global 			Yes
# Flush_commands 																																				Yes 		Global 			No
# flush_time 										Yes 					Yes 									Yes 													Global 			Yes
# foreign_key_checks 																							Yes 													Both 				Yes
# ft_boolean_syntax 								Yes 					Yes 									Yes 													Global 			Yes
# ft_max_word_len 								Yes 					Yes 									Yes 													Global 			No
# ft_min_word_len 								Yes 					Yes 									Yes 													Global 			No
# ft_query_expansion_limit 					Yes 					Yes 									Yes 													Global 			No
# ft_stopword_file 								Yes 					Yes 									Yes 													Global 			No
# gdb 												Yes 					Yes 
# general-log 										Yes 					Yes 																							Global 			Yes
# -Variable: general_log 																						Yes 													Global 			Yes
# 
# general_log_file 								Yes 					Yes 									Yes 													Global			Yes
# group_concat_max_len 							Yes 					Yes 									Yes 													Both 				Yes
# group_replication_allow_local_disjoint 	Yes 					Yes 									Yes 													Global 			Yes
# _gtids_join
# group_replication_allow_local_lower 		Yes 					Yes 									Yes 													Global 			Yes
# _version_join
# group_replication_auto_ 						Yes 					Yes 									Yes 													Global 			Yes
# increment_increment
# group_replication_bootstrap_ 				Yes 					Yes 									Yes 													Global 			Yes
# group
# group_replication_communication_debug_ 	Yes 					Yes 									Yes 													Global 			Yes
# options
#
# group_replication_components 				Yes 					Yes 									Yes 													Global 			Yes
# group_replication_compression_threshold Yes 					Yes 									Yes 													Global 			Yes
# group_replication_enforce 					Yes 					Yes 									Yes 													Global 			Yes
# _update_everywhere_checks
# group_replication_exit_state_action 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_flow 						Yes 					Yes 									Yes 													Global 			Yes
# _control_applier_threshold
# group_replication_flow 						Yes 					Yes 									Yes 													Global 			Yes
# _control_certifier_threshold 				
#
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _hold_percent
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _max_commit_quota
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _member_quota_percent 
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _min_quota 	
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _min_recovery_quota
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _control_mode
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _control_period 
# group_replication_flow_control 			Yes 					Yes 									Yes 													Global 			Yes
# _control_release_percent
#
# group_replication_force_members 			Yes 					Yes 									Yes 													Global 			Yes
# group_replication_group_name 				Yes 					Yes 									Yes 													Global 			Yes
# group_replication_group_seeds 				Yes 					Yes 									Yes 													Global 			Yes
# group_replication_gtid_assignment  		Yes 					Yes 									Yes 													Global 			Yes
# _block_size
# group_replication_ip_whitelist 			Yes 					Yes 									Yes 													Global 			Yes
# group_replication_local_address 			Yes 					Yes 									Yes 													Global 			Yes
# group_replication_member_expel_timeout 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_member_weight 			Yes 					Yes 									Yes 													Global 			Yes
# group_replication_poll_spin_loops 		Yes 					Yes 									Yes 													Global 			Yes
#
# group_replication_primary_member 																										Yes 						Global 			No
# group_replication_recovery_complete_at 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ 				Yes 					Yes 									Yes 													Global 			Yes
# get_public_key
# group_replication_recovery_ 				Yes 					Yes 									Yes 													Global 			Yes
# public_key_path
# group_replication_recovery_ 				Yes 					Yes 									Yes 													Global 			Yes
# reconnect_interval
# group_replication_recovery_retry_count 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_ca 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_capath 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_cert 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_cipher 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_crl 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery_ssl_crlpath 	Yes 					Yes 									Yes 													Global 			Yes
# 
# group_replication_recovery_ssl_key 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_recovery 					Yes 					Yes 									Yes 													Global 			Yes
# _ssl_verify_server_cert
# group_replication_recovery_use_ssl 		Yes 					Yes 									Yes 													Global 			Yes
# group_replication_single_primary_mode 	Yes 					Yes 									Yes 													Global 			Yes
# group_replication_ssl_mode 					Yes 					Yes 									Yes 													Global 			Yes
# group_replication_start_on_boot 			Yes 					Yes 									Yes 													Global 			Yes
# group_replication_transaction 				Yes 					Yes 									Yes 													Global 			Yes
# _size_limit
# group_replication_unreachable_ 			Yes 					Yes 									Yes 													Global 			Yes
# majority_timeout
#
# gtid_executed 																									Yes 													Varies 			No
# gtid-executed-compression-period 			Yes 					Yes 	
# - Variable: gtid_executed 					
# _compression_period
# gtid_executed_compression_period 																			Yes 													Global 			Yes
# gtid-mode 										Yes 					Yes 																							Global 			Yes
# - Variable: gtid_mode 																						Yes 													Global 			Yes
# gtid_mode 																										Yes 													Global 			Yes
# gtid_next 																										Yes 													Session 			Yes
# gtid_owned 																										Yes 													Both 				No
# gtid_purged 																										Yes 													Global 			Yes
# Handler_commit 																																Yes 						Both 				No
# Handler_delete 																																Yes 						Both 				No
# Handler_external_lock 																													Yes 						Both 				No
# Handler_mrr_init 																															Yes 						Both 				No
# Handler_prepare 																															Yes 						Both 				No
# Handler_read_first 																														Yes 						Both 				No
# Handler_read_key 																															Yes 						Both 				No
# Handler_read_last 																															Yes 						Both 				No
# Handler_read_next 																															Yes 						Both 				No
# Handler_read_prev 																															Yes 						Both 				No
# Handler_read_rnd 																															Yes 						Both 				No
# Handler_read_rnd_next 																													Yes 						Both 				No
#
# Handler_rollback 																															Yes 						Both 				No
# Handler_savepoint 																															Yes 						Both 				No
# Handler_savepoint_rollback 																												Yes 						Both 				No
# Handler_update 																																Yes 						Both 				No
# Handler_write 																																Yes 						Both 				No
# have_compress 																									Yes 													Global 			No
# have_crypt 																										Yes 													Global 			No
# have_dynamic_loading 																							Yes 													Global 			No
# have_geometry 																									Yes 													Global 			No
# have_openssl 																									Yes 													Global 			No
# have_profiling 																									Yes 													Global 			No
# have_query_cache 																								Yes 													Global 			No
# have_rtree_keys 																								Yes 													Global 			No
# have_ssl 																											Yes 													Global 			No
# have_statement_timeout 																						Yes 													Global 			No
#
# have_symlink 									-						-										Yes 													Global 			No
# help 												Yes  					Yes 
#
# histogram_generation_max_mem_size 		Yes 					Yes 									Yes 													Both 				Yes
# host_cache_size 																								Yes 													Global 			Yes
# hostname 																											Yes 													Global 			No
# identity 																											Yes 													Session 			Yes
# ignore-builtin-innodb 						Yes 					Yes 																							Global 			No
# - Variable: ignore_builtin_innodb 																		Yes 													Global 			No
# information_schema_stats_expiry 			Yes 					Yes 									Yes 													Both 				Yes
# init_connect 									Yes 					Yes 									Yes 													Global 			Yes
# init-file 										Yes 					Yes 																							Global 			No
# - Variable: init_file 																						Yes 													Global 			No
# init_slave 										Yes 					Yes 									Yes 													Global 			Yes
# initialize 										Yes 					Yes 
# initialize-insecure 							Yes 					Yes 
# innodb 											Yes 					Yes
# innodb_adaptive_flushing 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_adaptive_flushing_lwm 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_adaptive_hash_index 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_adaptive_hash_index_parts 			Yes 					Yes 									Yes 													Global 			No
# innodb_adaptive_max_sleep_delay 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_api_bk_commit_interval 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_api_disable_rowlock 					Yes 					Yes 									Yes 													Global 			No
# innodb_api_enable_binlog 					Yes 					Yes 									Yes 													Global 			No
# innodb_api_enable_mdl 						Yes 					Yes 									Yes 													Global 			No
# innodb_api_trx_level 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_autoextend_increment 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_autoinc_lock_mode 					Yes 					Yes 									Yes 													Global 			No
# innodb_available_undo_logs 																											Yes 							Global 			No
# innodb_background_drop_list_empty 		Yes 					Yes 									Yes 													Global 			Yes
#
# innodb_buffer_pool_bytes_data 																										Yes 							Global 			No
# innodb_buffer_pool_bytes_dirty 																									Yes 							Global 			No
# innodb_buffer_pool_chunk_size 				Yes 					Yes 									Yes 													Global 			No
# innodb_buffer_pool_debug 					Yes 					Yes 									Yes 													Global 			No
# innodb_buffer_pool_dump_at_shutdown 		Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_dump_now 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_dump_pct 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_dump_status 																									Yes 							Global 			No
# innodb_buffer_pool_filename 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_in_core_file 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_instances 				Yes 					Yes 									Yes 													Global 			No
#
# innodb_buffer_pool_load_abort 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_load_at_startup 		Yes 					Yes 									Yes 													Global 			No
# innodb_buffer_pool_load_now 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_load_status 																									Yes 							Global 			No
# innodb_buffer_pool_pages_data 																										Yes 							Global 			No
# innodb_buffer_pool_pages_dirty 																									Yes 							Global 			No
# innodb_buffer_pool_pages_flushed 																									Yes 							Global 			No
# innodb_buffer_pool_pages_free 																										Yes 							Global 			No
# innodb_buffer_pool_pages_latched 																									Yes 							Global 			No
# innodb_buffer_pool_pages_misc 																										Yes 							Global 			No
# innodb_buffer_pool_pages_total 																									Yes 							Global 			No
# innodb_buffer_pool_read_ahead 																										Yes 							Global 			No
#
# innodb_buffer_pool_read_ahead_evicted 																							Yes 							Global 			No
# innodb_buffer_pool_read_ahead_rnd 																								Yes 							Global 			No
# innodb_buffer_pool_read_requests 																									Yes 							Global 			No
# innodb_buffer_pool_reads 																											Yes 							Global 			No
# innodb_buffer_pool_resize_status 																									Yes 							Global 			No
# innodb_buffer_pool_size 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_buffer_pool_wait_free 																										Yes 							Global 			No
# innodb_buffer_pool_write_requests 																								Yes 							Global 			No
# innodb_change_buffer_max_size 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_change_buffering  					Yes 					Yes 									Yes 													Global 			yes
# innodb_change_buffering_debug 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_checkpoint_disabled 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_checksum_algorithm 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_cmp_per_index_enabled 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_commit_concurrency 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_compress_debug 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_compression_ 							Yes 					Yes 									Yes 													Global 			Yes
# failure_threshold_pct
#
# innodb_compression_level 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_compression_pad_pct_max 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_concurrency_tickets 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_data_file_path 						Yes 					Yes 									Yes 													Global 			No
# innodb_data_fsyncs 																													Yes 							Global 			No
# innodb_data_home_dir 							Yes 					Yes 									Yes 													Global 			No
# innodb_data_pending_fsyncs 																											Yes 							Global 			No
# innodb_data_pending_reads 																											Yes 							Global 			No
# innodb_data_pending_writes 																											Yes 							Global 			No
# innodb_data_read 																														Yes 							Global 			No
# innodb_data_reads 																														Yes 							Global 			No
# innodb_data_writes 																													Yes 							Global 			No
# innodb_data_written 																													Yes 							Global 			No
# innodb_dblwr_pages_written 																											Yes 							Global 			No
# innodb_dblwr_writes 																													Yes 							Global 			No
# innodb_ddl_log_crash_reset_debug 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_deadlock_detect 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_dedicated_server 						Yes 					Yes 									Yes 													Global 			No
# innodb_default_row_format 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_directories 							Yes 					Yes 									Yes 													Global 			No
# 
# innodb_disable_sort_file_cache 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_doublewrite 							Yes 					Yes 									Yes 													Global 			No
# innodb_fast_shutdown 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_fil_make_page_dirty_debug 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_file_per_table 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_fill_factor 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_flush_log_at_timeout 																				Yes 													Global 			Yes
# innodb_flush_log_at_trx_commit 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_flush_method 							Yes 					Yes 									Yes 													Global 			No
# innodb_flush_neighbors 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_flush_sync 								Yes 					Yes 									Yes 													Global 			Yes
# innodb_flushing_avg_loops 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_force_load_corrupted 				Yes 					Yes 									Yes 													Global 			No
# innodb_force_recovery 						Yes 					Yes 									Yes 													Global 			No
# innodb_fsync_threshold 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_aux_table 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_cache_size 							Yes 					Yes 									Yes 													Global 			No
# innodb_ft_enable_diag_print 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_enable_stopword 					Yes 					Yes 									Yes 													Both 				Yes
# innodb_ft_max_token_size 					Yes 					Yes 									Yes 													Global 			No
#
# innodb_ft_min_token_size 					Yes 					Yes 									Yes 													Global 			No
# innodb_ft_num_word_optimize 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_result_cache_limit 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_server_stopword_table 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_ft_sort_pll_degree 					Yes 					Yes 									Yes 													Global 			No
# innodb_ft_total_cache_size 					Yes 					Yes 									Yes 													Global 			No
# innodb_ft_user_stopword_table 				Yes 					Yes 									Yes 													Both 				Yes
# innodb_have_atomic_builtins 																											Yes 						Global 			No
# innodb_io_capacity 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_io_capacity_max 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_limit_optimistic_insert_debug 	Yes 					Yes 									Yes 													Global 			Yes
# innodb_lock_wait_timeout 					Yes 					Yes 									Yes 													Both  			Yes
# innodb_log_buffer_size 						Yes 					Yes 									Yes 													Global 			Varies
# innodb_log_checkpoint_fuzzy_now 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_checkpoint_now 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_checksums 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_compressed_pages 				Yes 					Yes 									Yes 													Global 			Yes
#
# innodb_log_file_size 							Yes 					Yes 									Yes 													Global 			No
# innodb_log_files_in_group 					Yes 					Yes 									Yes 													Global 			No
# innodb_log_group_home_dir 					Yes 					Yes 									Yes 													Global 			No
# innodb_log_spin_cpu_abs_lwm 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_spin_cpu_pct_hwm 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_wait_for_flush_spin_hwm 		Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_waits 																															Yes 						Global 			No
# innodb_log_write_ahead_size 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_log_write_requests 																												Yes 						Global 			No
# innodb_log_writes 																															Yes 						Global 			No
# innodb_lru_scan_depth 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_max_dirty_pages_pct 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_max_dirty_pages_pct_lwm 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_max_purge_lag 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_max_purge_lag_delay 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_max_undo_log_size 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_merge_threshold_set_all_debug 	Yes 					Yes 									Yes 													Global 			Yes
# innodb_monitor_disable 						Yes 					Yes 									Yes 													Global 			Yes
#
# innodb_monitor_enable 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_monitor_reset 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_monitor_reset_all 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_num_open_files 																													Yes 						Global 			No
# innodb_numa_interleave 						Yes 					Yes 									Yes 													Global 			No
# innodb_old_blocks_pct 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_old_blocks_time 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_online_alter_log_max_size 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_open_files 								Yes 					Yes 									Yes 													Global 			No
# innodb_optimize_fulltext_only 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_os_log_fsyncs 																														Yes 						Global 			No
# innodb_os_log_pending_fsyncs 																											Yes 						Global 			No
# innodb_os_log_pending_writes 																											Yes 						Global 			No
# innodb_os_log_written 																													Yes 						Global 			No
# innodb_page_cleaners 							Yes 					Yes 									Yes 													Global 			No
# innodb_page_size 																															Yes 						Global 			No
# innodb_page_size 								Yes 					Yes 									Yes 													Global 			No
#
# innodb_pages_created 																							 							Yes						Global 			No
# innodb_pages_read 																															Yes 						Global 			No
# innodb_pages_written 																														Yes 						Global 			No
# innodb_parallel_read_threads 				Yes 					Yes 									Yes 													Session 			Yes
# innodb_print_all_deadlocks 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_print_ddl_logs 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_purge_batch_size 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_purge_rseg_truncate_frequency 	Yes 					Yes 									Yes 													Global 			Yes
# innodb_purge_threads 							Yes 					Yes 									Yes 													Global 			No
# innodb_random_read_ahead 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_read_ahead_threshold 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_read_io_threads 						Yes 					Yes 									Yes 													Global 			No
# innodb_read_only 								Yes 					Yes 									Yes 													Global 			No
# innodb_redo_log_encrypt 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_replication_delay 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_rollback_on_timeout 					Yes 					Yes 									Yes 													Global 			No
# innodb_rollback_segments 					Yes 					Yes 									Yes 													Global 			Yes
# 
# innodb_row_lock_current_waits 																											Yes 						Global 			No
# innodb_row_lock_time 																														Yes 						Global 			No
# innodb_row_lock_time_avg 																												Yes 						Global 			No
# innodb_row_lock_time_max 																												Yes 						Global 			No
# innodb_row_lock_waits 																													Yes 						Global 			No
# innodb_rows_deleted 																														Yes 						Global 			No
# innodb_rows_inserted 																														Yes 						Global 			No
# innodb_rows_read 																															Yes 						Global 			No
# innodb_rows_updated 																														Yes 						Global 			No
# innodb_saved_page_number_debug 			Yes 					Yes 									Yes 													Global 			Yes
# innodb_scan_directories 						Yes 					Yes 									Yes 													Global 			No
# innodb_sort_buffer_size 						Yes 					Yes 									Yes 													Global 			No
# innodb_spin_wait_delay 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_auto_recalc 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_include_delete_marked 		Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_method 							Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_on_metadata 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_persistent 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_persistent_sample_pages 	Yes 					Yes 									Yes 													Global 			Yes
# innodb_stats_transient_sample_pages 		Yes 					Yes 									Yes 													Global 			Yes
# innodb-status-file 							Yes 					Yes 
# innodb_status_output 							Yes 					Yes 									Yes 													Global 			Yes
#
# innodb_status_output_locks 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_strict_mode 							Yes 					Yes 									Yes 													Both 				Yes
# innodb_sync_array_size 						Yes 					Yes 									Yes 													Global 			No
# innodb_sync_debug 								Yes 					Yes 									Yes 													Global 			No
# innodb_sync_spin_loops 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_table_locks 							Yes 					Yes 									Yes 													Both 				Yes
# innodb_temp_data_file_path 					Yes 					Yes 									Yes 													Global 			No
# innodb_temp_tablespaces_dir 				Yes 					Yes 									Yes 													Global 			No
# innodb_thread_concurrency 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_temp_sleep_delay 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_tmpdir 									Yes 					Yes 									Yes 													Both 				Yes
# innodb_truncated_status_writes 																											Yes 					Global 			No
#
# innodb_trx_purge_view_update_only_debug Yes 					Yes 									Yes 													Global 			Yes
# innodb_trx_rseg_n_slots_debug 				Yes 					Yes 									Yes 													Global 			Yes
# innodb_undo_directory 						Yes 					Yes 									Yes 													Global 			No
# innodb_undo_log_encrypt 						Yes 					Yes 									Yes 													Global 			Yes
# innodb_undo_log_truncate 					Yes 					Yes 									Yes 													Global 			Yes
# innodb_undo_logs 								Yes 					Yes 									Yes 													Global 			Yes
# innodb_undo_tablespaces 						Yes 					Yes 									Yes 													Global 			Varies
# innodb_use_native_aio 						Yes 					Yes 									Yes 													Global 			No
# innodb_version 																									Yes 													Global 			No
# innodb_write_io_threads 						Yes 					Yes 									Yes 													Global 			No
# insert_id 																										Yes 													Session 			Yes
# install 											Yes 
# install-manual 									Yes 
# interactive_timeout 							Yes 					Yes 									Yes 													Both 				Yes
# internal_tmp_disk_storage_engine 			Yes 					Yes 									Yes 													Global 			Yes
# internal_tmp_mem_storage_engine 			Yes 					Yes 									Yes 													Both 				Yes
# join_buffer_size 								Yes 					Yes 									Yes 													Both 				Yes
# keep_files_on_create  						Yes 					Yes 									Yes 													Both 				Yes
#
# Key_blocks_not_flushed 																														Yes					Global 			No
# Key_blocks_unused 																																Yes 					Global 			No
# Key_blocks_used 																																Yes 					Global 			No
# key_buffer_size 								Yes 					Yes 									Yes 													Global 			Yes
# key_cache_age_threshold 						Yes 					Yes 									Yes 													Global 			Yes
# key_cache_block_size 							Yes 					Yes 									Yes 													Global 			Yes
# key_cache_division_limit 					Yes 					Yes 									Yes 													Global 			Yes
# Key_read_requests 																																Yes 					Global 			No
# Key_reads 																																		Yes 					Global 			No
# Key_write_requests 																															Yes 					Global 			No
# Key_writes 																																		Yes 					Global 			No
# keyring_aws_cmk_id 							Yes 					Yes 									Yes 													Global 			Yes
# keyring_aws_conf_file 						Yes 					Yes 									Yes 													Global 			No
# keyring_aws_data_file 						Yes 					Yes 									Yes 													Global 			No
#
# keyring_aws_region 							Yes 					Yes 									Yes 													Global 			Yes
# keyring_encrypted_file_data 				Yes 					Yes 									Yes 													Global 			Yes
# keyring_encrypted_file_password 			Yes 					Yes 									Yes 													Global 			Yes
# keyring_file_data 								Yes 					Yes 									Yes 													Global 			Yes
# keyring-migration-destination 				Yes 					Yes
# keyring-migration-host 						Yes 					Yes
# keyring-migration-password 					Yes 					Yes
# keyring-migration-port 						Yes 					Yes
# keyring-migration-socket 					Yes 					Yes
# keyring-migration-source 					Yes 					Yes
# keyring-migration-user 						Yes 					Yes
# keyring_okv_conf_dir 							Yes 					Yes 									Yes 													Global 			Yes
# keyring_operations 																							Yes 													Global 			Yes
# language 											Yes 					Yes 									Yes 													Global 			No
# large_files_support 																							Yes 													Global 			No
# large_page_size 																								Yes 													Global 			No
# large-pages 										Yes 					Yes 																							Global 			No
# - Variable: large_pages 																						Yes 													Global 			No
# last_insert_id 																									Yes 													Session 			Yes
# Last_query_cost 																																Yes 					Session 			No
# Last_query_partial_plans 																													Yes 					Session 			No
# lc-messages 										Yes 					Yes 																							Both 				Yes
# - Variable: lc_messages 																						Yes 													Both 				Yes
# lc-messages-dir 								Yes 					Yes 																							Global 			No
# - Variable: lc_messages_dir 																				Yes 													Global 			No
# lc_time_names 																									Yes 													Both 				Yes
# license 																											Yes 													Global 			No
# local_infile 																									Yes 													Global 			Yes
#
# local-service 									Yes 															
# lock_wait_timeout 								Yes 					Yes 									Yes 													Both 				Yes
# Locked_connects 																								 								 Yes 					Global 			No
# locked_in_memory 																								Yes 													Global 			No
# log-bin 											Yes 					Yes 									Yes 													Global 			No
# log_bin 																											Yes 							 						Global 			No
# log_bin_basename 																								Yes 													Global 			No
# log-bin-index 									Yes 					Yes 
# log_bin_index 																									Yes 													Global 			No
# log-bin-trust-function-creators 			Yes 					Yes 																							Global 			Yes
# - Variable: log_bin_trust_function_creators 															Yes 													Global 			Yes
# log-bin-use-v1-row-events 					Yes 					Yes 																							Global 			No
# - Variable: log_bin_use_v1_row_events 																	Yes 													Global 			No
# log_bin_use_v1_row_events 					Yes 					Yes 									Yes 													Global 			No
# log_builtin_as_identified_by_password 	Yes 					Yes 									Yes 													Global 			Yes
# log-error 										Yes 					Yes 																							Global 			No
# - Variable: log_error 																						Yes 													Global 			No
# log_error_filter_rules 						Yes 					Yes 									Yes 													Global 			Yes
#
# log_error_services 							Yes 					Yes 									Yes 													Global 			Yes
# log_error_suppression_list 					Yes 					Yes 									Yes 													Global 			Yes
# log_error_verbosity 							Yes 					Yes 									Yes 													Global 			Yes
# log-isam 											Yes 					Yes 
# log-output 										Yes 					Yes 																							Global 			Yes
# - Variable: log_output 																						Yes 													Global 			Yes
# log-queries-not-using-indexes 				Yes 					Yes 																							Global 			Yes
# - Variable: log_queries_not_ 																				Yes 													Global 			Yes
# using_indexes
# log-raw 											Yes 					Yes 
# log-short-format 								Yes 					Yes
# log-slave-updates 								Yes 					Yes 																							Global  			No
# Variable: log_slave_updates 																				Yes 													Global 			No
# log_slave_updates 								Yes 					Yes 									Yes 													Global 			No
# log_slow_admin_statements 																					Yes 													Global 			Yes
# log_slow_slave_statements 																					Yes 													Global 			Yes
# log_statements_unsafe_for_binlog 																			Yes 													Global 			Yes
# log_syslog 										Yes 					Yes 									Yes 													Global 			Yes
# log_syslog_facility 							Yes 					Yes 									Yes 													Global 			Yes
# log_syslog_include_pid 						Yes 					Yes 									Yes 													Global 			Yes
# log_syslog_tag 									Yes 					Yes 									Yes 													Global 			Yes
# log-tc 											Yes 					Yes
#
# log-tc-size 										Yes 					Yes
# log_throttle_queries_not_using_indexes 																	Yes 													Global 			Yes
# log_timestamps 									Yes 					Yes 									Yes 													Global 			Yes
# log-warnings 									Yes 					Yes 																							Global 			Yes
# - Variable: log_warnings 																					Yes 													Global 			Yes
# long_query_time 								Yes 					Yes 									Yes 													Both 				Yes
# low-priority-updates 							Yes 					Yes 																							Both 				Yes
# - Variable: low_priority_updates 																			Yes 													Both 				Yes
# lower_case_file_system 																						Yes 													Global 			No
# lower_case_table_names 						Yes 					Yes 									Yes 													Global 			No
# mandatory_roles 								Yes 					Yes 									Yes 													Global 			Yes
# master-info-file 								Yes 					Yes 
# master-info-repository 						Yes 					Yes 
# - Variable: master_info_repository 
# master_info_repository 						Yes 					Yes 									Yes 													Global 			Yes
# master-retry-count 							Yes 					Yes 
# master-verify-checksum 						Yes 					Yes
# - Variable: master_verify_checksum
#
# master_verify_checksum 																						Yes 													Global 			Yes
# max_allowed_packet 							Yes 					Yes 									Yes 													Both 				Yes
# max_binlog_cache_size 						Yes 					Yes 									Yes 													Global 			Yes
# max-binlog-dump-events 						Yes 					Yes 
# max_binlog_size 								Yes 					Yes 									Yes 													Global 			Yes
# max_binlog_stmt_cache_size 					Yes 					Yes 									Yes 													Global 			Yes
# max_connect_errors 							Yes 					Yes 									Yes 													Global 			Yes
# max_connections 								Yes 					Yes 									Yes 													Global 			Yes
# max_delayed_threads 							Yes 					Yes 									Yes 													Both 				Yes
# max_digest_length 								Yes 					Yes 									Yes 													Global 			No
# max_error_count 								Yes 					Yes 									Yes 													Both 				Yes
# max_execution_time 																														Yes 						Both 				Yes
# Max_execution_time_exceeded 																											Yes 						Both 				No
# Max_execution_time_set 																													Yes 						Both 				No
# Max_execution_time_set_failed 																											Yes 						Both 				No
# max_heap_table_size 							Yes 					Yes 									Yes 													Both 				Yes
# max_insert_delayed_threads 																					Yes 													Both 				Yes
# max_join_size 									Yes 					Yes 									Yes 													Both 				Yes
# max_length_for_sort_data 					Yes 					Yes 									Yes 													Both 				Yes
#
# max_points_in_geometry 						Yes 					Yes 									Yes 													Both 				Yes
# max_prepared_stmt_count 						Yes 					Yes 									Yes 													Global 			Yes
# max_relay_log_size 							Yes 					Yes 									Yes 													Global 			Yes
# max_seeks_for_key 								Yes 					Yes 									Yes 													Both 				Yes
# max_sort_length 								Yes					Yes 									Yes 													Both  			Yes
# max_sp_recursion_depth 						Yes 					Yes 									Yes 													Both 				Yes
# max_tmp_tables 																									Yes 													Both 				Yes
# Max_used_connections 																														Yes 						Global 			No
# Max_used_connections_time 																												Yes 						Global 			No
# max_user_connections 							Yes 					Yes 									Yes 													Both 				Yes
# max_write_lock_count 							Yes 					Yes 									Yes 													Global 			Yes
# mecab_charset 																																Yes 						Global 			No
# mecab_rc_file 									Yes 					Yes 									Yes 													Global 			No
# memlock 											yes 					Yes 
# - variable: locked_in_memory 				
# metadata_locks_cache_size 																					Yes 													Global 			No
# metadata_locks_hash_instances 																				Yes 													Global 			No
# min-examined-row-limit 						Yes 					Yes 									Yes 													Both 				Yes
# multi_range_count 								Yes 					Yes 									Yes 													Both 				Yes
# myisam-block-size 								Yes 					Yes 
# myisam_data_pointer_size 					Yes 					Yes 									Yes 													Global 			Yes
# myisam_max_sort_file_size 					Yes 					Yes 									Yes 													Global 			Yes
# myisam_mmap_size 								Yes 					Yes 									Yes 													Global 			No
# myisam-recover-options 						Yes 					Yes 
# - Variable: myisam_recover_options
# myisam_recover_options 																						Yes 													Global 			No
# myisam_repair_threads 						Yes 					Yes 									Yes 													Both 				Yes
# myisam_sort_buffer_size 						Yes 					Yes 									Yes 													Both 				Yes
# myisam_stats_method 							Yes 					Yes 									Yes 													Both 				Yes
# myisam_use_mmap 								Yes 					Yes 									Yes 													Global 			Yes
# 
# mysql_firewall_mode 							Yes 					Yes 									Yes 													Global 			Yes
# mysql_firewall_trace 							Yes 					Yes 									Yes 													Global 			Yes
# mysql_native_password_proxy_users 		Yes 					Yes 									Yes 													Global 			Yes
# mysqlx 											Yes 					Yes 									Yes 													Global 			No
# Mysqlx_aborted_clients 																														Yes 					Global 			No
# Mysqlx_address 																																	Yes 					Global 			No
# mysqlx-bind-address 							Yes 					Yes 									Yes 													Global 			No
# mysqlx_bind_address 							Yes 					Yes 									Yes 													Global 			No
# Mysqlx_bytes_received 																														Yes 					Both 				No
# Mysqlx_bytes_sent 																																Yes 					Both 				No
# mysqlx-connect-timeout 						Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_connect_timeout 						Yes 					Yes 									Yes 													Global 			Yes
# Mysqlx_connection_accept_errors 																											Yes 					Both 				No
# Mysqlx_connection_errors 																													Yes 					Both 				No
# Mysqlx_connections_accepted 																												Yes 					Global 			No
# Mysqlx_connections_closed 																													Yes 					Global 			No
# Mysqlx_connections_rejected 																												Yes 					Global 			No
# Mysqlx_crud_create_view 																														Yes 					Both 				No
# Mysqlx_crud_delete 																															Yes 					Both 				No
# Mysqlx_crud_drop_view 																														Yes 					Both 				No
# Mysqlx_crud_find 																																Yes 					Both 				No
# Mysqlx_crud_insert 																															Yes 					Both 				No
#
# Mysqlx_crud_modify_view 																														Yes 					Both 				No
# Mysqlx_crud_update 																															Yes 					Both 				No
# mysqlx_document_id_unique_prefix 			Yes 					Yes 									Yes 													Global 			Yes
# Mysqlx_errors_sent 																															Yes 					Both 				No
# Mysqlx_errors_unknown_message_type 																										Yes 					Both 				No
# Mysqlx_expect_close 																															Yes 					Both 				No
# Mysqlx_expect_open 																															Yes 					Both 				No
# mysqlx-idle-worker-thread-timeout 		Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_idle_worker_thread_timeout 		Yes 					Yes 									Yes 													Global 			Yes
# Mysqlx_init_error 																																Yes 					Both 				No
# mysqlx-interactive-timeout 					Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_interactive_timeout 					Yes 					Yes 									Yes 													Global 			Yes
# mysqlx-max-allowed-packet 					Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_max_allowed_packet 					Yes 					Yes 									Yes 													Global 			Yes
#
# mysqlx-max-connections 						Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_max_connections 						Yes 					Yes 									Yes 													Global 			Yes
# mysqlx-min-worker-threads 					Yes 					Yes 									Yes 													Global 			Yes
# mysqlx_min_worker_threads 					Yes 					Yes 									Yes 													Global 			Yes
# Mysqlx_notice_other_sent 																													Yes 					Both 				No
# Mysqlx_notice_warning_sent 																													Yes 					Both 				No
# Mysqlx_port 																																		Yes 					Global 			No
# mysqlx-port 										Yes 					Yes 									Yes 													Global 			No
# mysqlx_port 										Yes 					Yes 									Yes 													Global 			No
# mysqlx-port-open-timeout 					Yes 					Yes 									Yes 													Global 			No
# mysqlx_port_open_timeout 					Yes 					Yes 									Yes 													Global 			No
# mysqlx-read-timeout 							Yes 					Yes 									Yes 													Session 			Yes
# mysqlx_read_timeout 							Yes 					Yes 									Yes 													Session 			Yes
# Mysqlx_rows_sent 																																Yes 					Both 				No
# Mysqlx_sessions 																																Yes 					Global 			No
# Mysqlx_sessions_accepted 																													Yes 					Global 			No
# Mysqlx_sessions_closed 																														Yes 					Global 			No
# Mysqlx_sessions_fatal_error 																												Yes 					Global 			No
# Mysqlx_sessions_killed 																														Yes 					Global 			No
# Mysqlx_sessions_rejected 																													Yes 					Global 			No
# Mysqlx_socket 																																	Yes 					Global 			No
# mysqlx-socket 									Yes 					Yes 									Yes 													Global 			No
# mysqlx_socket 									Yes 					Yes 									Yes 													Global 			No
# Mysqlx_ssl_accept_renegotiates 																											Yes 					Global 			No
#
# Mysqlx_ssl_accepts 																															Yes 					Global 			No
# Mysqlx_ssl_active 																																Yes 					Both 				No
# mysqlx-ssl-ca 									Yes 					Yes  									Yes 													Global 			No
# mysqlx-ssl-capath 								Yes 					Yes 									Yes 													Global 			No
# mysqlx-ssl-cert 								Yes 					Yes 									Yes 													Global 			No
# Mysqlx_ssl_cipher 																																Yes 					Both 				No
# mysqlx-ssl-cipher 								Yes 					Yes 
# Mysqlx_ssl_cipher_list 																														Yes 					Both 				No
# mysqlx-ssl-crl 									Yes 					Yes 									Yes 													Global 			No
# mysqlx-ssl-crlpath 							Yes 					Yes 									Yes 													Global 			No
# Mysqlx_ssl_ctx_verify_depth 																												Yes 					Both 				No
# Mysqlx_ssl_ctx_verify_mode 																													Yes 					Both 				No
# Mysqlx_ssl_finished_accepts 																												Yes 					Global 			No
# mysqlx-ssl-key 									Yes 					Yes 									Yes 													Global 			No
# Mysqlx_ssl_server_not_after 																												Yes 					Global 			No
# Mysqlx_ssl_server_not_before 																												Yes 					Global 			No
# Mysqlx_ssl_verify_depth 																														Yes 					Global 			No
# Mysqlx_ssl_verify_mode 																														Yes 					Global 			No
# Mysqlx_ssl_version 																															Yes 					Both 				No
# Mysqlx_stmt_create_collection 																												Yes 					Both 				No
# Mysqlx_stmt_create_collection_index 																										Yes 					Both 				No
# Mysqlx_stmt_disable_notices 																												Yes 					Both 				No
# Mysqlx_stmt_drop_collection 																												Yes 					Both 				No
# Mysqlx_stmt_drop_collection_index 																										Yes 					Both 				No
# Mysqlx_stmt_enable_notices 																													Yes 					Both 				No
# Mysqlx_stmt_ensure_collection 																												Yes 					Both 				No
# Mysqlx_stmt_execute_mysqlx 																													Yes 					Both 				No
# Mysqlx_stmt_execute_sql 																														Yes 					Both 				No
# Mysqlx_stmt_execute_xplugin 																												Yes 					Both 				No
# Mysqlx_stmt_kill_client 																														Yes 					Both 				No
# Mysqlx_stmt_list_clients 																													Yes 					Both 				No
# Mysqlx_stmt_list_notices 																													Yes 					Both 				No
# 
# Mysqlx_stmt_list_objects 																													Yes 					Both 				No
# Mysqlx_stmt_ping 																																Yes 					Both 				No
# mysqlx-wait-timeout 							Yes 					Yes 									Yes 													Session 			Yes
# mysqlx_wait_timeout 							Yes 					Yes 									Yes 													Session 			Yes
# Mysqlx_worker_threads 																														Yes 					Global 			No
# Mysqlx_worker_threads_active 																												Yes 					Global 			No
# mysqlx-write-timeout 							Yes 					Yes 									Yes 													Session 			Yes
# mysqlx_write_timeout 							Yes 					Yes 									Yes 													Session 			Yes
# named_pipe 																										Yes 													Global 			No
# Ndb_api_bytes_received_count 																												Yes 					Global 			No
# Ndb_api_bytes_received_count_session 																									Yes 					Session 			No
# Ndb_api_bytes_received_count_slave 																										Yes 					Global 			No
# Ndb_api_bytes_sent_count 																													Yes 					Global 			No
# Ndb_api_bytes_sent_count_slave 																											Yes 					Global 			No
# Ndb_api_event_bytes_count_injector 																										Yes 					Global 			No
# Ndb_api_event_data_count_injector 																										Yes 					Global 			No
#
# Ndb_api_event_nondata_count_injector 																									Yes 					Global 			No
# Ndb_api_pk_op_count 																															Yes 					Global 			No
# Ndb_api_pk_op_count_session 																												Yes 					Session 			No
# Ndb_api_pk_op_count_slave 																													Yes 					Global 			No
# Ndb_api_pruned_scan_count  																													Yes 					Global 			No
# Ndb_api_pruned_scan_count_session 																										Yes 					Session 			No
# Ndb_api_range_scan_count_slave 																											Yes 					Global 			No
# Ndb_api_read_row_count 																														Yes 					Global 			No
# Ndb_api_read_row_count_session 																											Yes 					Session 			No
# Ndb_api_scan_batch_count_slave 																											Yes 					Global 			No
# Ndb_api_table_scan_count 																													Yes 					Global 			No
# Ndb_api_table_scan_count_session 																											Yes 					Session 			No
#
# Ndb_api_trans_abort_count 																													Yes 					Global 			No
# Ndb_api_trans_abort_count_session 																										Yes 					Session 			No
# Ndb_api_trans_abort_count_slave 																											Yes 					Global 			No
# Ndb_api_trans_close_count 																													Yes 					Global 			No
# Ndb_api_trans_close_count_session 																										Yes 					Session 			No
# Ndb_api_trans_close_count_slave 																											Yes 					Global 			No
# Ndb_api_trans_commit_count 																													Yes 					Global 			No
# Ndb_api_trans_commit_count_session 																										Yes 					Session 			No
# Ndb_api_trans_commit_count_slave 																											Yes 					Global 			No
# Ndb_api_trans_local_read_row_count_slave 																								Yes 					Global 			No
# Ndb_api_trans_start_count 																													Yes 					Global 			No
# Ndb_api_trans_start_count_session 																										Yes 					Session 			No
# Ndb_api_trans_start_count_slave 																											Yes 					Global 			No
# Ndb_api_uk_op_count 																															Yes 					Global 			No
# Ndb_api_uk_op_count_slave 																													Yes 					Global 			No
# Ndb_api_wait_exec_complete_count 																											Yes 					Global 			No
# Ndb_api_wait_exec_complete_count_session 																								Yes 					Session 			No
# Ndb_api_wait_exec_complete_count_slave 																									Yes 					Global 			No
# Ndb_api_wait_meta_request_count 																											Yes 					Global 			No
# Ndb_api_wait_meta_request_count_session 																								Yes 					Session 			No
# Ndb_api_wait_nanos_count 																													Yes 					Global 			No
# Ndb_api_wait_nanos_count_session 																											Yes 					Session 			No
#
# Ndb_api_wait_nanos_count_slave 																											Yes 					Global 			No
# Ndb_api_wait_scan_result_count 																											Yes 					Global 			No
# Ndb_api_wait_scan_result_count_session 																									Yes 					Session 			No
# Ndb_api_wait_scan_result_count_slave 																									Yes 					Global 			No
# ndb-batch-size 									Yes 					Yes 									Yes 													Global 			No		
# ndb-blob-write-batch-bytes 					Yes 					Yes 									Yes 													Both 				Yes
# ndb-cluster-connection-pool 				Yes 					Yes 									Yes 													Global 			No
# ndb-cluster-connection-pool-nodeids 		Yes 					Yes 									Yes 													Global 			No
# Ndb_cluster_node_id 																															Yes 					Both 				No
# Ndb_config_from_host 																															Yes 					Both 				No
# Ndb_config_from_port 																															Yes 					Both 				No
# Ndb_conflict_fn_epoch_trans 																												Yes 					Both 				No
# Ndb_conflict_fn_max 																															Yes 					Global 			No
# Ndb_conflict_fn_old 																															Yes 					Global 			No
# Ndb_conflict_trans_detect_iter_count 																									Yes 					Global 			No
# Ndb_conflict_trans_row_reject_count 																										Yes 					Global 			No
# ndb-connectstring 								Yes 					Yes 
# ndb-deferred-constraints 					Yes 					Yes 																							Both 				Yes
# - Variable: ndb_deferred_constraints 																	Yes 													Both 				Yes
# ndb_deferred_constraints 					Yes 					Yes 									Yes 													Both 				Yes
# ndb-distribution 								Yes 					Yes 																							Global 			Yes
# - Variable: ndb_distribution 																				Yes 													Global 			Yes
# ndb_distribution 								Yes 					Yes 									Yes 													Global 			Yes
# ndb_eventbuffer_free_percent 				Yes 					Yes 									Yes 													Global 			Yes
# ndb_eventbuffer_max_alloc 					Yes 					Yes 									Yes 													Global 			Yes
# ndb_force_send 									Yes 					Yes 									Yes 													Both 				Yes
# ndb_index_stat_enable 						Yes 					Yes 									Yes 													Both 				Yes
# ndb_index_stat_option 						Yes 					Yes 									Yes 													Both 				Yes
# ndb_join_pushdown 																								Yes 													Both 				Yes
# Ndb_last_commit_epoch_server 																												Yes 					Global 			No
# Ndb_last_commit_epoch_session 																												Yes 					Session 			No
# ndb-log-apply-status 							Yes 					Yes 																							Global 			No
# 
# - Variable: ndb_log_apply_status 																			Yes 													Global 			No
# ndb_log_apply_status 							Yes 					Yes 									Yes 													Global 			No
# ndb_log_binlog_index 							Yes 															Yes 													Global 			Yes
# ndb-log-empty-epochs 							Yes 					Yes 									Yes 													Global 			Yes
# ndb-log-empty-update 							Yes 					Yes 									Yes 													Global 			Yes
# ndb-log-transaction-id 						Yes 					Yes 																							Global 			No
# - Variable: ndb_log_transaction_id 																		Yes 													Global 			No
# ndb_log_updated_only 							Yes 					Yes 									Yes 													Global 			Yes
# ndb-mgmd-host 									Yes 					Yes 
# Ndb_number_of_data_nodes 																													Yes  					Global 			No
# ndb_optimization_delay 																						Yes 													Global 			Yes
# ndb_optimized_node_selection 				Yes 					Yes 									Yes 													Global 			No
# Ndb_pushed_queries_defined 																													Yes 					Global 			No
# Ndb_pushed_queries_executed 																												Yes 					Global 			No
# ndb_recv_thread_activation_threshold 																	Yes 													Global 			Yes
# ndb_recv_thread_cpu_mask 																					Yes  													Global 			Yes
# ndb_report_thresh_binlog_epoch_slip 		Yes 					Yes 									Yes 													Global 			Yes
# ndb_report_thresh_binlog_mem_usage 		Yes 					Yes 									Yes 													Global 			Yes
# Ndb_scan_count 																																	Yes 					Global 			No
# 
# ndb_show_foreign_key_mock_tables 			Yes 					Yes 									Yes 													Global 			Yes
# Ndb_slave_max_replicated_epoch 																			Yes 													Global 			No
# ndb_table_no_logging 																							Yes 													Session 			Yes
# ndb-transid-mysql-connection-map 			Yes 
# ndb_use_transactions 							Yes 					Yes 									Yes 													Both 				Yes
# ndb_version 																										Yes 													Global 			No
# ndb_version_string 																							Yes 													Global 			No
# ndb-wait-setup 									Yes 					Yes 									Yes 													Global 			No
# ndbinfo_database 																								Yes 													Global 			No
# ndbinfo_max_rows 								Yes 															Yes 													Both 				Yes
# ndbinfo_show_hidden 							Yes 															Yes 													Both 				Yes
# ndbinfo_version 																								Yes 													Global 			No
# net_buffer_length 								Yes 					Yes 									Yes 													Both 				Yes
# net_read_timeout 								Yes 					Yes 									Yes 													Both 				Yes
# net_retry_count 								Yes 					Yes 									Yes 													Both 				Yes
# net_write_timeout 								Yes 					Yes 									Yes 													Both 				Yes
# new 												Yes 					Yes 									Yes 													Both 				Yes
# ngram_token_size 								Yes 					Yes 									Yes 													Global 			No
#
# no-dd-upgrade 									Yes 					Yes 
# no-defaults 										Yes 
# no-monitor 										Yes 					Yes
# Not_flushed_delayed_rows 																														Yes 				Global 			No
# offline_mode 									Yes 					Yes 									Yes 													Global 			Yes
# old 												Yes 					Yes 									Yes 													Global 			No
# old-alter-table 								Yes 					Yes 																							Both 				Yes
# - Variable: old_alter_table 																				Yes 													Both 				Yes
# old_passwords 																									Yes 													Both 				Yes
# old-style-user-limits 						Yes 					Yes 
# Ongoing_anonymous_gtid_violating_transaction_count 																						Yes 				Global 			No
# Ongoing_anonymous_transaction_count 																											Yes 				Global 			No
# Ongoing_automatic_gtid_violating_transaction_count 																						Yes 				Global 			No
# Open_files 																																			Yes 				Global 			No
# open-files-limit 								Yes 					Yes 																							Global 			No
# - Variable: open_files_limit 																				Yes 													Global 			No
# Open_streams 																																		Yes 				Global 			No
# Open_table_definitions 																															Yes 				Global 			No
# Open_tables 																																			Yes 				Both 				No
# Opened_files 																																		Yes 				Global 			No
# Opened_table_definitions 																														Yes 				Both 				No
# Opened_tables 																																		Yes 				Both 				No
# optimizer_prune_level 						Yes 					Yes 									Yes 													Both 				Yes
# optimizer_search_depth 						Yes 					Yes 									Yes 													Both 				Yes
# 
# optimizer_switch 								Yes 					Yes 									Yes 													Both 				Yes
# optimizer_trace 																								Yes 													Both 				Yes
# optimizer_trace_features 																					Yes  													Both 				Yes
# optimizer_trace_limit 																						Yes 													Both 				Yes
# optimizer_trace_max_mem_size 																				Yes 													Both 				Yes
# optimizer_trace_offset 																						Yes 													Both 				Yes
# original_commit_timestamp 																					Yes 													Session 			Yes
# parser_max_mem_size 							Yes 					Yes 									Yes 													Both 				Yes
# password_history 								Yes 					Yes 									Yes 													Global 			Yes
# password_require_current 					Yes 					Yes 									Yes 													Global 			Yes
# password_reuse_interval 						Yes 					Yes  									Yes 													Global 			Yes
# performance_schema 							Yes 					Yes  									Yes 													Global 			No
# Performance_schema_accounts_lost 																												Yes 				Global 			No
# performance_schema_accounts_size 			Yes 					Yes 									Yes 													Global 			No
# Performance_schema_cond_classes_lost 																										Yes 				Global 			No
# Performance_schema_cond_instances_lost 																										Yes 				Global 			No
#
# performance-schema-consumer 				Yes 					Yes
# -events-stages-current 
#
# performance-schema-consumer 				Yes 					Yes
# -events-stages-history 
#
# performance-schema-consumer 				Yes 					Yes
# -events-stages-history-long 				
#
# performance-schema-consumer 				Yes 					Yes
# -events-statements-current
#
# performance-schema-consumer 				Yes 					Yes
# -events-statements-history
#
# performance-schema-consumer 				Yes 					Yes
# -events-statements-history-long 		
#
# performance-schema-consumer 				Yes 					Yes
# -events-transactions-current 
#
# performance-schema-consumer 				Yes 					Yes
# -events-transactions-history 
#
# performance-schema-consumer 				Yes 					Yes
# -events-transactions-history-long 	
#
# performance-schema-consumer 				Yes 					Yes
# -events-waits-current 
#
# performance-schema-consumer 				Yes 					Yes
# -events-waits-history
# 
# performance-schema-consumer 				Yes 					Yes
# -events-waits-history-long 
#
# performance-schema-consumer 				Yes 					Yes
# -global-instrumentation 
#
# performance-schema-consumer 				Yes 					Yes
# -statements-digest 
#
# performance-schema-consumer 				Yes 					Yes
# -thread-instrumentation 
#
# Performance_schema_digest_lost 																												Yes 				Global 			No
# performance_schema_digests_size 			Yes 					Yes 									Yes 													Global 			No	
# performance_schema_error_size 				Yes 					Yes 									Yes 													Global 			No
# performance_schema_ 							Yes 					Yes 									Yes 													Global 			No
# events_stages_history_long_size
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# stages_history_size 
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# statements_history_long_size 
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# statements_history_size 
# 
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# transactions_history_long_size
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# transactions_history_size 
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# waits_history_long_size 
#
# performance_schema_events_ 					Yes 					Yes 									Yes 													Global 			No
# waits_history_size 
#
# Performance_schema_file_ 																														Yes 				Global 			No
# classes_lost
#
# Performance_schema_file_ 																														Yes 				Global 			No
# handles_lost
#
# Performance_schema_file_ 																														Yes 				Global 			No
# instances_lost
#
# Performance_schema_hosts_lost 																													Yes 				Global 			No
#
# performance_hosts_size  						Yes 					Yes 									Yes 													Global 			No
# Performance_schema_index_stat_lost 																											Yes 				Global 			No
# performance_schema-instrument 				Yes 					Yes 																		
# Performance_schema_locker_lost 																												Yes 				Global 			No
# performance_schema_max_cond_classes 		Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_cond_instances 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_digest_length 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_ 							Yes 					Yes 									Yes 													Global 			Yes
# max_digest_sample_age
# performance_schema_max_file_classes 		Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_file_handles 		Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_file_instances 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_index_stat 		Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_memory_classes 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_metadata_locks 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_mutex_classes 	Yes 					Yes 									Yes 													Global 			No
#
# performance_schema_max_mutex_instances 	Yes 					Yes 									Yes 													Global 			No
#
# performance_schema_max_ 						Yes 					Yes 									Yes 													Global 			No
# prepared_statements_instances
#
# performance_schema_ 							Yes 					Yes 									Yes 													Global 			No
# max_program_instances
#
# performance_schema_ 							Yes 					Yes 									Yes 													Global 			No
# max_rwlock_classes 
#
# performance_schema_max_socket_classes 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_socket_instances Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_sql_text_length 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_stage_classes 	Yes 					Yes 									Yes 													Global 			No
# performance_schema 							Yes 					Yes 									Yes 													Global 			No
# _max_statement_classes 
# performance_schema 							Yes 					Yes 									Yes 													Global 			No
# _max_statement_stack 
#
# performance_schema_max_table_handles 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_table_instances 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_table_lock_stat 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_thread_classes 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_max_thread_instances Yes 					Yes 									Yes 													Global 			No
# Performance_schema_memory_classes_lost 																								Yes 						Global 			No
# Performance_schema_metadata_lock_lost 																								Yes 						Global 			No
# Performance_schema_mutex_classes_lost 																								Yes 						Global 			No
# Performance_schema_mutex_instances_lost 																							Yes 						Global 			No
# Performance_schema_nested_statement_lost 																							Yes 						Global 			No
# Performance_schema_prepared_statements_lost 																						Yes 						Global 			No
# Performance_schema_program_lost 																										Yes 						Global 			No
# Performance_schema_rwlock_classes_lost 																								Yes 						Global 			No
# Performance_schema_rwlock_instances_lost 																							Yes 						Global 			No
# Performance_schema_session_connect_attrs_longest_seen 																			Yes 						Global 			No
# Performance_schema_session_connect_attrs_lost 																					Yes 						Global 			No
#
# performance_schema_ 							Yes 					Yes 									Yes 													Global 			No
# session_connect_attrs_size 
#
# performance_schema_setup_actors_size 	Yes 					Yes 									Yes 													Global 			No
# performance_schema_setup_objects_size 	Yes 					Yes 									Yes 													Global 			No
# Performance_schema_socket_classes_lost 																								Yes 						Global 			No
#
# Performance_schema_ 																														Yes 						Global 			No
# socket_instnaces_lost 
#
# Performance_schema_stage_classes_lost 																								Yes 						Global 			No
# Performance_schema_statement_classes_lost 																							Yes 						Global 			No
# Performance_schema_table_handles_lost 																								Yes 						Global 			No
# Performance_schema_table_instances_lost 																							Yes 						Global 			No
# Performance_schema_table_lock_stat_lost 																							Yes 						Global 			No
# Performance_schema_thread_classes_lost 																								Yes 						Global 			No
# Performance_schema_thread_instances_lost 																							Yes 						Global 			No
# Performance_schema_users_lost 																											Yes 						Global 			No
# performance_schema_users_size 				Yes 					Yes 									Yes 													Global 			No
# persisted_globals_load 						Yes 					Yes 									Yes 													Global 			No
# pid-file 											Yes 					Yes 																							Global 			No
# - Variable: pid_file 																							Yes 													Global 			No
# plugin 											Yes 					Yes 	
# plugin_dir 										Yes 					Yes  									Yes 													Global 			No
# plugin-load 										Yes 					Yes 
# plugin-load-add 								Yes 					Yes
# port 												Yes 					Yes  									Yes 													Global 			No
# port-open-timeout 								Yes 					Yes 									
# 
# preload_buffer_size 							Yes 					Yes 									Yes 													Both 				Yes
# Prepared_stmt_count 																														Yes 						Global 			No
# print-defaults 									Yes 
# profiling 																										Yes 													Both 				Yes
# profiling_history_size 						Yes 					Yes 									Yes 													Both 				Yes
# protocol_version 																								Yes 													Global 			No
# proxy_user 																										Yes 													Session 			No
# pseudo_slave_mode 																								Yes 													Session 			Yes
# psuedo_thread_id 																								Yes 													Session 			Yes
# Qcache_free_blocks 																														Yes 						Global 			No
# Qcache_free_memory 																														Yes 						Global 			No
# Qcache_hits 																																	Yes 						Global 			No
# Qcache_inserts     																														Yes 						Global 			No
# Qcache_lowmem_prunes 																														Yes 						Global 			No
# Qcache_not_cached 																															Yes 						Global 			No
# Qcache_queries_in_cache 																													Yes 						Global 			No
# Qcache_total_blocks 																														Yes 						Global 			No
# Queries 																																		Yes 						Both 				No
# 
# query_alloc_block_size 						Yes 					Yes 									Yes 													Both 				Yes
# query_cache_limit 								Yes 					Yes 									Yes 													Global 			Yes
# query_cache_min_res_unit 					Yes 					Yes 									Yes 													Global 			Yes
# query_cache_size 								Yes 					Yes 									Yes 													Global 			Yes
# query_cache_type 								Yes 					Yes 									Yes 													Both 				Yes
# query_cache_wlock_invalidate 				Yes 					Yes 									Yes 													Both 				Yes
# query_prealloc_size 							Yes 					Yes 									Yes 													Both 				Yes
# Questions 																																	Yes 						Both 				No
# rand_seed1 																										Yes 													Session 			Yes
# rand_seed2 																										Yes 													Session 			Yes
# range_alloc_block_size 						Yes 					Yes 									Yes 													Both 				Yes
# range_optimizer_max_mem_size 				Yes 					Yes 									Yes 													Both 				Yes
# rbr_exec_mode 																									Yes 													Both 				Yes
#
# read_buffer_size 								Yes 					Yes 									Yes 													Both 				Yes
# read_only 										Yes 					Yes 									Yes 													Global 			Yes
# read_rnd_buffer_size 							Yes 					Yes 									Yes 													Both 				Yes
# regexp_stack_limit 							Yes 					Yes 									Yes 													Global 			Yes
# regexp_time_limit 								Yes 					Yes 									Yes 													Global 			Yes
# relay-log 										Yes 					Yes 																							Global 			No
# - Variable: relay_log 																						Yes 													Global 			No
# relay_log_basename 																							Yes 													Global 			No
# relay-log-index 								Yes 					Yes 									 														Global 			No
# - Variable: relay_log_index 																				Yes 													Global 			No
# relay_log_index 								Yes 					Yes 									Yes 													Global 			No
# relay-log-info-file 							Yes 					Yes 																							
# - Variable: relay_log_info_file 
# relay_log_info_file 							Yes 					Yes 									Yes 													Global 			No
# relay-log-info-repository 					Yes 					Yes 	
# - Variable: relay_log_info_repository 	
# relay_log_info_repository 																					Yes 													Global 			Yes
# relay_log_purge 								Yes 					Yes 									Yes 													Global 			Yes
# relay-log-recovery 							Yes 					Yes 
# - Variable: relay_log_recovery 
# relay_log_recovery 							Yes 					Yes 									Yes 													Global 			No
# relay_log_space_limit 						Yes 					Yes 									Yes 													Global 			No
# remove 											Yes
# replicate-do-db 								Yes 					Yes
# replicate-do-table 							Yes 					Yes
# replicate-ignore-db 							Yes 					Yes
# replicate-ignore-table 						Yes 					Yes
# replicate-rewrite-db 							Yes 					Yes
# replicate-same-server-id 					Yes 					Yes
# replicate-wild-do-table 						Yes 					Yes
# replicate-wild-ignore-table 				Yes 					Yes
# report-host 										Yes 					Yes 																							Global 			No
# - Variable: report_host 																						Yes 													Global 			No
# report-password 								Yes 					Yes 																							Global 			No
# - Variable: report_password 																				Yes 													Global 			No
# report-port 										Yes 					Yes 																							Global 			No
# - Variable: report_port 																						Yes 													Global 			No
# report-user 										Yes 					Yes 																							Global 			No
# - Variable: report_user 																						Yes 													Global 			No
# require_secure_transport 					Yes 					Yes 									Yes 													Global 			Yes
# resultset_metadata 																							Yes 													Session 			Yes
# 
# rewriter_enabled 																								Yes 													Global 			Yes
# Rewriter_number_loaded_rules 																												Yes 					Global 			No
# Rewriter_number_reloads 																														Yes 					Global 			No
# Rewriter_number_rewritten_queries 																										Yes 					Global 			No
# Rewriter_reload_error 																														Yes 					Global 			No
# rewriter_verbose 																								Yes 													Global 			Yes
# rpl_read_size 									Yes 					Yes 									Yes 													Global 			Yes
# Rpl_semi_sync_master_clients 																												Yes 					Global 			No
# rpl_semi_sync_master_enabled 																				Yes 													Global 			Yes
# Rpl_semi_sync_master_net_avg_wait_time 																									Yes 					Global 			No
# Rpl_semi_sync_master_net_wait_time 																										Yes 					Global 			No
# Rpl_semi_sync_master_net_waits 																											Yes 					Global 			No
# Rpl_semi_sync_master_no_times 																												Yes 					Global 			No
# Rpl_semi_sync_master_no_tx 																													Yes 					Global 			No
# Rpl_semi_sync_master_status 																												Yes 					Global 			No
# Rpl_semi_sync_master_timefunc_failures 																									Yes 					Global 			No
# rpl_semi_sync_master_timeout 																				Yes 													Global 			Yes
# rpl_semi_sync_master_trace_level 																			Yes 													Global 			Yes
# Rpl_semi_sync_master_tx_avg_wait_time 																									Yes 					Global 			No
# Rpl_semi_sync_master_tx_wait_time 																										Yes 					Global 			No
# Rpl_semi_sync_master_tx_waits 																												Yes 					Global 			No
# rpl_semi_sync_master_wait_for_slave_count 																Yes 													Global 			Yes
#
# rpl_semi_sync_master_wait_no_slave 																		Yes 													Global 			Yes
# rpl_semi_sync_master_wait_point 																			Yes 													Global 			Yes
# Rpl_semi_sync_master_wait_pos_backtraverse 																							Yes 					Global 			No
# Rpl_semi_sync_master_wait_sessions 																										Yes 					Global 			No
# Rpl_semi_sync_master_yes_tx 																												Yes 					Global 			No
# rpl_semi_sync_slave_enabled 																				Yes 													Global 			Yes
# Rpl_semi_sync_slave_status 																													Yes 					Global 			No
# rpl_semi_sync_slave_trace_level 																			Yes 													Global 			Yes
# rpl_stop_slave_timeout 						Yes 					Yes 									Yes 													Global 			Yes
# Rsa_public_key 																																	Yes 					Global 			No
#
# safe-user-create 								Yes 					Yes 
# schema_definition_cache 						Yes 					Yes 									Yes 													Global 			Yes
# Secondary_engine_execution_count 																											Yes 					Both 				No
# secure-auth 										Yes 					Yes 																							Global 			Yes
# - Variable: secure_auth 																						Yes 													Global 			Yes
# secure-file-priv 								Yes 					Yes 																							Global 			No
# - Variable: secure_file_priv 																				Yes 													Global 			No
#
# Select_full_join 																																Yes 					Both 				No
# Select_full_range_join 																														Yes 					Both 				No
# Select_range 																																	Yes 					Both 				No
# Select_range_check 																															Yes 					Both 				No
# Select_scan 																																		Yes 					Both 				No
# server-id 										Yes 					Yes 																							Global 			Yes
# - Variable: server_id 																						Yes 													Global 			Yes
# server_uuid 																										Yes 													Global 			No
# session_track_gtids 							Yes 					Yes 									Yes 													Both 				Yes
# session_track_schema 							Yes 					Yes 									Yes 													Both 				Yes
# session_track_stat_change 					Yes 					Yes 									Yes 													Both 				Yes
# session_track_system_variables 			Yes 					Yes 									Yes 													Both 				Yes
# 
# session_track_transaction_info 			Yes 					Yes 									Yes 													Both 				Yes
# sha256_password_auto_generate_rsa_keys 	Yes 					Yes 									Yes 													Global			No
# sha256_password_private_key_path 			Yes 					Yes 									Yes 													Global 			No
# sha256_password_proxy_users 				Yes 					Yes 									Yes 													Global 			Yes
# sha256_password_public_key_path 			Yes 					Yes 									Yes 													Global 			No
# shared_memory 									Yes 					Yes 									Yes 													Global 			No
# shared_memory_base_name 						Yes 					Yes 									Yes 													Global 			No
# show_compability_56 							Yes 					Yes 									Yes 													Global 			Yes
# show_create_table_verbosity 				Yes 					Yes 									Yes 													Both 				Yes
# show_old_temporals 							Yes 					Yes 									Yes 													Both 				Yes
# show-slave-auth-info 							Yes 					Yes 
# simplified_binlog_gtid_recovery 			Yes 					Yes 									Yes 													Global 			No
# skip-character-set-client-handshake 		Yes 					Yes 
# skip-concurrent-insert 						Yes 					Yes
# - Variable: concurrent_insert 
# skip-event-scheduler 							Yes 					Yes 									
# skip_external_locking 						Yes 					Yes 									Yes 													Global 			No
# skip-grant-tables 								Yes 					Yes 
# skip-host-cache 								Yes 					Yes
# skip-name-resolve 								Yes 					Yes 																							Global 			No
# - Variable: skip_name_resolve 																				Yes 													Global 			No
# skip-ndbcluster 								Yes 					Yes 																							
# skip-networking 								Yes 					Yes 																							Global 			No
# - Variable: skip_networking 																				Yes 													Global 			No
# skip-new 											Yes 					Yes 
# skip-show-database 							Yes 					Yes 																							Global 			No
# - Variable: skip_show_database 																			Yes 													Global 			No
# skip-slave-start 								Yes 					Yes 
# skip-ssl 											Yes 					Yes
# skip-stack-trace 								Yes 					Yes
# slave_allow_batching 							Yes 					Yes 									Yes 													Global 			Yes
# slave-checkpoint-group 						Yes 					Yes 
# - Variable: slave_checkpoint_group 
# slave_checkpoint_period 						Yes 					Yes 									Yes 													Global 			Yes
# slave_compressed_protocol 					Yes 					Yes 									Yes 													Global 			Yes
# slave_exec_mode 								Yes 					Yes 									Yes 													Global 			Yes
#
# Slave_heartbeat_period 																												Yes 							Global 			No
# Slave_last_heartbeat 																													Yes 							Global 			No
# slave-load-tmpdir 								Yes 					Yes 																							Global 			No
# - Variable: slave_load_tmpdir 																				Yes 													Global 			No
# slave-max-allowed-packet 					Yes 					Yes 
# - Variable: slave_max_allowed_packet 	
# slave_max_allowed_packet 																					Yes 													Global 			Yes
# slave-net-timeout 								Yes 					Yes 																							Global 			Yes
# - Variable: slave_net_timeout 																				Yes 													Global 			Yes
# Slave_open_temp_tables 																												Yes 							Global 			No
# slave-parallel-type 							Yes 					Yes 
# - variable: slave_parallel_type 
# slave_parallel_type 																							Yes 													Global 			Yes
# slave-parallel-workers 						Yes 					Yes 
# - Variable: slave_parallel_workers 		
# slave_parallel_workers 						Yes 															Yes 													Global 			Yes
# slave-pending-jobs-size-max 				Yes 
# - Variable: slave_pending_jobs_size_max 
# slave_pending_jobs_size_max 				Yes 															Yes 													Global 			Yes
# 
# slave_preserve_commit_order 				Yes 															Yes 													Global 			Yes
# Slave_received_heartbeats 																											Yes 							Global 			No
# Slave_retried_transactions 																											Yes 							Global 			No
# Slave_rows_last_search_algorithm_used 																							Yes 							Global 			No
# slave-rows-search-algorithms 				Yes 					Yes 
# - Variable: slave_rows_search_algorithms
# slave_rows_search_algorithms 																				Yes 													Global 			Yes
# Slave_running 																															Yes 							Global 			No
# slave-skip-errors 								Yes 					Yes 																							Global 			No
# - Variable: slave_skip_errors 																				Yes 													Global 			No
# slave-sql-verify-checksum 					Yes 					Yes 
# slave_sql_verify_checksum 																					Yes 													Global 			Yes
# slave_transaction_retries 					Yes 					Yes 									Yes 													Global 			Yes
# slave_type_conversions 						Yes 					Yes 									Yes 													Global 			No
# Slow_launch_threads 																													Yes 							Both 				No
# slow_launch_time 								Yes 					Yes 									Yes 													Global 			Yes
# Slow_queries 																															Yes 							Both 				No
# slow-query-log 									Yes 					Yes 																							Global 			Yes
# - Variable: slow_query_log 																					Yes 													Global 			Yes
# slow_query_log_file 							Yes 					Yes 									Yes 													Global 			Yes
#
# slow-start-timeout 							Yes 					Yes 
# socket 											Yes 					Yes 									Yes 													Global 			No
# sort_buffer_size 								Yes 					Yes 									Yes 													Both 				Yes
# Sort_merge_passes 																														Yes 							Both 				No
# Sort_range 																																Yes 							Both 				No
# Sort_rows 																																Yes 							Both 				No
# Sort_scan 																																Yes 							Both 				No
# sporadic-binlog-dump-fail 					Yes 					Yes 
# sql_auto_is_null 																								Yes 													Both 				Yes
# sql_big_selects 																								Yes 													Both 				Yes
# sql_buffer_result 																								Yes 													Both 				Yes
# sql_log_bin 																										Yes 													Session 			Yes
# sql_log_off 																										Yes 													Both 				Yes
# sql-mode 											Yes 					Yes 																							Both 				Yes
# - Variable: sql_mode 																							Yes 													Both 				Yes
# sql_notes 																										Yes 													Both 				Yes
# sql_quote_show_create 																						Yes 													Both 				Yes
# sql_require_primary_key 						Yes 					Yes 									Yes 													Both 				Yes
# sql_safe_updates 																								Yes 													Both 				Yes
# sql_select_limit 																								Yes 													Both 				Yes
# sql_slave_skip_counter 																						Yes 													Global 			Yes
# sql_warnings 																									Yes 													Both 				Yes
# ssl 												Yes 					Yes 												
# 
# Ssl_accept_renegotiates 																												Yes 							Global 			No
# Ssl_accepts 																																Yes 							Global 			No
# ssl-ca 											Yes 					Yes 																							Global 			No
# - Variable: ssl_ca 																							Yes 													Global 			No
# Ssl_callback_cache_hits 																												Yes 							Global 			No
# ssl-capath 										Yes 					Yes 																							Global 			No
# - Variable: ssl_capath 																						Yes 													Global 			No
# ssl-cert 											Yes 					Yes 																							Global 			No
# - Variable: ssl_cert 																							Yes 													Global 			No
# Ssl_cipher 																																Yes 							Both 				No
# ssl-cipher 										Yes 					Yes 																							Global 			No
# - Variable: ssl_cipher 																						Yes 													Global 			No
# Ssl_cipher_list 																														Yes 							Both 				No
# Ssl_client_connects 																													Yes 							Global 			No
# Ssl_connect_renegotiates 																											Yes 							Global 			No
# ssl-crl 											Yes 					Yes 																							Global 			No
# - Variable: ssl_crl 																							Yes 													Global 			No
# ssl-crlpath 										Yes 					Yes 																							Global 			No
# - Variable: ssl_crlpath 																						Yes 													Global 			No
# Ssl_ctx_verify_depth 																													Yes 							Global 			No
# Ssl_ctx_verify_mode 																													Yes 							Global 			No
# Ssl_default_timeout 																													Yes 							Both 				No
# Ssl_finished_accepts 																													Yes 							Global 			No
#
# Ssl_finished_connects 																												Yes 							Global 			No
# ssl_fips_mode 									Yes 					Yes 									Yes 													Global 			Yes
# ssl-key 											Yes 					Yes 																							Global 			No
# - Variable: ssl_key 																							Yes 													Global 			No
# Ssl_server_not_after 																													Yes 							Both 				No
# Ssl_server_not_before 																												Yes 							Both 				No
# Ssl_session_cache_hits 																												Yes 							Global 			No
# Ssl_session_cache_misses 																											Yes 							Global 			No
# Ssl_session_cache_mode 																												Yes 							Global 			No
# Ssl_session_cache_overflows 																										Yes 							Global 			No
# Ssl_session_cache_size 																												Yes 							Global 			No
# Ssl_session_cache_timeouts 																											Yes 							Global 			No
# Ssl_sessions_reused 																													Yes 							Both 				No
# Ssl_used_session_cache_entries 																									Yes 							Global 			No
# Ssl_verify_depth 																														Yes 							Both 				No
# Ssl_verify_mode 																														Yes 							Both 				No
# Ssl_version 																																Yes 							Both 				No
# standalone 										Yes 					Yes 
# stored_program_cache 							Yes 					Yes 									Yes 													Global 			Yes
# stored_program_definition_cache 			Yes 					Yes 									Yes 													Global 			Yes
# super-large-pages 								Yes 					Yes 
# super_read_only 								Yes 					Yes 									Yes 													Global 			Yes
# symbolic-links 									Yes 					Yes 
# sync_binlog 										Yes 					Yes 									Yes 													Global 			Yes
# sync_master_info 								Yes 					Yes 									Yes 													Global 			Yes
# 
# sync_relay_log 									Yes 					Yes 									Yes 													Global 			Yes
# sync_relay_log_info 							Yes 					Yes 									Yes 													Global 			Yes
# sysdate-is-now 									Yes 					Yes 
# syseventlog.facility 							Yes 					Yes 									Yes 													Global 			Yes
# syseventlog.include_pid 						Yes 					Yes 									Yes 													Global 			Yes
# syseventlog.tag 								Yes 					Yes 									Yes 													Global 			Yes
# system_time_zone 																								Yes 													Global 			No
# table_definition_cache 																						Yes 													Global 			Yes
# Table_locks_immediate 																												Yes 							Global 			No
# Table_locks_waited 																													Yes 							Global 			No
# table_open_cache 																								Yes 													Global 			Yes
# Table_open_cache_hits 																												Yes 							Both 				No
# table_open_cache_instances 																					Yes 													Global 			No
# Table_open_cache_misses 																												Yes 							Both 				No
# Table_open_cache_overflows 																											Yes 							Both 				No
# tablespace_definition_cache 				Yes 					Yes 									Yes 													Global 			Yes
# tc-heuristic-recover 							Yes 					Yes 
# Tc_log_max_pages_used 																												Yes 							Global 			No
# Tc_log_page_size 																														Yes 							Global 			No
# Tc_log_page_waits 																														Yes 							Global 			No
# temp-pool 										Yes 					Yes 
# 
# temptable_max_ram 								Yes 					Yes 									Yes 													Global 			Yes
# thread_cache_size 								Yes 					Yes 									Yes 													Global 			Yes
# thread_handling 								Yes 					Yes 									Yes 													Global 			No
# thread_pool_algorithm 						Yes 					Yes 									Yes 													Global 			No
# thread_pool_high_priority_connection 	Yes 					Yes 									Yes 													Both 				Yes
# thread_pool_max_unused_threads 			Yes 					Yes 									Yes 													Global 			Yes
# thread_pool_prio_kickup_timer 				Yes 					Yes 									Yes 													Both 				Yes
# thread_pool_size 								Yes 					Yes 									Yes 													Global 			No
# thread_pool_stall_limit 						Yes 					Yes 									Yes 													Global 			Yes
#
# thread_stack 									Yes 					Yes 									Yes 													Global 			No
# Threads_cached 																															Yes 							Global 			No
# Threads_connected 																														Yes 							Global 			No
# Threads_created 																														Yes 							Global 			No
# Threads_running 																														Yes 							Global 			No
# time_format 																										Yes 													Global 			No
# time_zone 																										Yes 													Both 				Yes
# timestamp 																										Yes 													Session 			Yes
# tls_version 										Yes 					Yes 									Yes 													Global 			No
# tmp_table_size 									Yes 					Yes 									Yes 													Both 				Yes
# tmpdir 											Yes 					Yes 									Yes 													Global 			No
# transaction_alloc_block_size 				Yes 					Yes 									Yes 													Both 				Yes
# transaction_allow_batching 																					Yes 													Session 			Yes
# transaction-isolation 						Yes 					Yes  																							Both 				Yes
# - Variable: transaction_isolation 																		Yes 													Both 				Yes
# transaction_prealloc_size 					Yes 					Yes 									Yes 													Both 				Yes
# transaction-read-only 						Yes 					Yes 																							Both 				Yes
# - Variable: transaction_read_only 																		Yes 													Both 				Yes
# 
# transaction_write_set_extraction 			Yes 															Yes 													Both 				Yes
# tx_isolation 																									Yes 													Both 				Yes
# tx_read_only 																									Yes 													Both 				Yes
# unique_checks 																									Yes 													Both 				Yes
# updatable_views_with_limit 					Yes 					Yes 									Yes 													Both 				Yes
# Uptime 																																	Yes 							Global 			No
# Uptime_since_flush_status 																											Yes 							Global 			No
# use_secondary_engine 																							Yes 													Session 			Yes
# user 												Yes 					Yes 
# validate-password 								Yes 					Yes
# validate_password_check_user_name 		Yes 					Yes 									Yes 													Global 			Yes
# validate_password_dictionary_file 																		Yes 													Global 			Yes
# validate_password_dictionary_file_last_parsed 																				Yes 							Global 			No
# validate_password_dictionary_file_words_count 																				Yes 							Global 			No
# validate_password_length 																					Yes 													Global 			Yes
# validate_password_mixed_case_count 																		Yes 													Global 			Yes
# validate_password_number_count 																			Yes 													Global 			Yes
# validate_password_policy 																					Yes 													Global 			Yes
# validate_password_special_char_count 																	Yes 													Global 			Yes
# validate_password.check_user_name 		Yes 					Yes 									Yes 													Global 			Yes
# validate_password.dictionary_file 																		Yes 													Global 			Yes
# validate_password.dictionary_file_last_parsed 																				Yes 							Global 			No
# validate_password.dictionary_file_words_count 																				Yes 							Global 			No
# validate_password.length 																					Yes 													Global 			Yes
# validate_password.mixed_case_count 																		Yes 													Global 			Yes
# validate_password.number_count 																			Yes 													Global 			Yes
# validate_password.policy 																					Yes 													Global 			Yes
# validate_password.special_char_count 																	Yes 													Global 			Yes
# validate_user_plugins 																						Yes 													Global 			No
# verbose 											Yes 					Yes 
# version 																											Yes 													Global 			No
# version_comment 																								Yes 													Global 			No
# version_compile_machine 																						Yes 													Global 			No
# version_compile_os 																							Yes 													Global 			No
# version_compile_zlib 																							Yes 													Global 			No
# version_tokens_session 						Yes 					Yes 									Yes 													Both 				Yes
# version_tokens_session_number 				Yes 					Yes 									Yes 													Both 				No
# wait_timeout 									Yes 					Yes 									Yes 													Both 				Yes
# warning_count 																									Yes 													Session 			No
# windowing_use_high_precision 				Yes 					Yes 									Yes 													Both 				Yes
#
# The following pertain to the Server Command Options of mysqld:
#
# mysqld reads options from the [mysqld] and [server] groups.
# mysqld_safe reads options from the [mysqld], [server], [mysqld_safe] and [safe_mysqld] groups.
#
# mysql.server reads options from the [mysqld] and [mysql.server] groups
#
# Memory allocations in size and defaulting is dependant upon platform.
#
# Values default to bytes in memory allocations in terms of buffer sizes, lengths, and stack sizes - unless specified otherwise.
#
# Note: Values are hints - MySQL retains freedom in assignments.
#
# 		Property 					 
# --allow-suspicious-udfs 		 					 						  
# 
#   cmd-line format - --allow-suspicious-udfs 
# 	 Type 				 Boolean
#   Default Value 	 FALSE
#
# 	 Controls whether user-defined functions that have only an xxx symbol for the main function can be loaded.
#   By default - is off and only UDFs that have at least one auxilliary symbol can be loaded; prevents attempts at loading
# 	 functions from shared object files other than those containing legit UDFs.
#
# --ansi
# 
# 	 cmd-line format 	--ansi
#
# 	 Use standard (ANSI) SQL Syntax instead of MySQL syntax. 
#   For more precise control over the server SQL mode - use --sql-mode instead.
#
# --basedir=<dir name>, -b <dir name>
#
# 	 cmd-line format 			--basedir=dir_name
# 	 System Var 				basedir
# 	 Scope 						Global
# 	 Dynamic 				 	No
# 	 SET_VAR Hint Applies  	No
#   Type 						Dir name
#   Default (>= 8.0.2) 		parent of mysqld installation dir
#   Default (<= 8.0.1) 		configuration-dependent default
#
# 	 The path to the MySQL installation dir. This option sets the basedir system var.
#
# 	 The server executable determines its own full path name at startup and uses the parent of the dir in which
# 	 it is located as the default basedir value.
#
# 	 This in turn enables the server to use that basedir when searching for server-related info such as the share dir containing error messages.
#
# --big-tables
#
# 	cmd-line format 			--big-tables
# 	System var 					big_tables
# 	Scope 						Global, Session
# 	Dynamic 						Yes
# 	SET_VAR Hint: 				No
# 	Type 							Boolean
# 	Default 						OFF
#
# 	Enable large result sets by saving all temp sets in files. This option prevents most 
# 	"table full" errors, but also slows down queries for which in-memory tables would suffice.
#
# 	The server is able to handle large result sets automatically by using memory for smaller temp tables and
#  switching to disk tables where necessary.
#
# --bind-address=<addr>
#
# cmd-line format 			--bind-address=addr
# System var 					bind_address
# Scope 							Global
# Dynamic 						No
# SET_VAR Hint Applies 		No
# Type 							String
# Default to 					*
#
# The MySQL server listens on one or more network sockets for TCP/IP connections.
# Each socket is bound to one address - but it is possible for an address to map onto
# multiple network interfaces.
#
# To specify how the server should listen for TCP/IP connections, use the --bind-address option at server startup
#
# < 8.0.13 - Accepts a single address value, which may specify a single non-wildcard IP address or host name, or one of the
#  			 wildcard address formats that permit listening on multiple network interfaces (*, 0.0.0.0 or ::)
#
# >= 8.0.13 - accepts a single value as just described, or a list of comma-separated values. When the opption names a list of
#  			  multiple values, each value must specify a single non-wildcard IP address or host name - i.e NONE may have (*, 0.0.0.0, or ::)
#
# IPs can be specified as IPv4 or IPv6. For any option that is a host name - the server resolves the name to an IP and binds to that address.
# If a host name resolves to multiple IP addresses, the server uses the first IPv4 address if there are any, or the first IPv6 address otherwise.
#
# The server treats different types of addresses as follows:
#
# 		If the address is *, the server accepts TCP/IP connections on all server host IPv4 interfaces - and IPv6 if supported.
# 		This is the default behavior.  - If multiple values are specified, this is not allowed as a value.
#
# 		If the address is 0.0.0.0, the server accepts TCP/IP connections on all server host IPv4 interfaces. Not permitted with a list of several values.
#
# 		If the address is ::, the server accepts TCP/IP connections on all server host IPv4 and IPv6 interfaces. Not permitted with a list of several values.
#
# 		If the address is an IPv4-mapped address, the server accepts TCP/IP connections for that address - in either IPv4 or IPv6.
#	 	Example: If server is bound to ::ffff:127.0.0.1 - Clients can connect using --host=127.0.0.1 or --host=::ffff:127.0.0.1
#
# 		If the address is a regular IPv4 or IPv6 address - such as 127.0.0.1 or ::1, the server accepts TCP/IP only for that IPv4 or IPv6.
#
# 		If binding to any address fails, server procedure fails and does not start.
#
# 		Some examples:
#
# 		--bind-address=* - Listens on all IPv4 or IPv6 - specified by *
#
# 		--bind-address=198.51.100.20 - Listens only on the 198.51.100.20 IPv4 address.
#
# 		--bind-address=198.51.100.20, 2001:db8:0:f101::1 - The server listens on the 198.51.100.20 IPv4 and 2001:db8:0:f101::1 IPv6
#
# 		--bind-address=198.51.100.20,* - Produces an error, Can't use wildcards with multiple designated values.
#
# 		When --bind-address names a single value (wildcard or non-wildcard) - the server listens on a single socket, which for a wildcard
# 		address may be bound to multiple network interfaces. 
#
# 		When it lists multiple values - the server listens on one socket per value - with each socket bound to a single network
# 		interface. This scaling is linear, i.e 1:1. Can come to affect connection-acceptance efficiency depending on the OS - long lists can cause overhead.
#
# 		If we intend to bind the server to a specific address - the mysql.user grant table must contain an account with admin privs that can connect to that 
# 		address.
#
# 		Otherwise - we cannot shut down the server. For example - if we bind the server to * - we can connect to it using all existing accounts.
# 		But if we bind to ::1, we'd need admin privs on root in terms of ::1 - as in 'root'@'::1' exists in the mysql.user table.
#
# --binlog-format={ROW|STATEMENT|MIXED}
#
# 		cmd line format: 		--binlog-format=format
# 		System var: 			binlog_format
# 		Scope 					Global, Session
# 		Dynamic 					Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Defaults: 				ROW
# 		Can take: 				ROW, STATEMENT, MIXED
#
# 		Specify wether to use row-based, statement-based or mixed replication. Statement is default in >= 8.0
#
# 	 	Sometimes the var cannot be changed during runtime - or causes replication to fail.
#
# 		Setting the binary logging format without enabling binary logging sets the binlog format global sys var and logs a warning.
# 
# --character-sets-dir=<dir name>
#
# 		cmd line format: 		--character-sets-dir=dir_name
# 		Sys Var: 				character_sets_dir
# 		Scope: 					Global
# 		Dynamic 					No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name
#
# 		The dir where char sets are installed
#
# --character-set-client-handshake
# 
# 		cmd line format: 		--character-set-client-handshake
# 		Type: 					Boolean
# 		Defaults: 				TRUE
#
# 		Do not ignore char set info sent by the client. 
# 		To ignore client info and use the default server char set, use --skip-character-set-client-handshake.
# 		(Causes behavior akin to MySQL 4.0)
#
# --character-set-filesystem=<charset name>
# 		
# 		cmd line format: 		--character-set-filesystem=name
# 		System Var: 			character_set_filesystem
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Defaults: 				Binary
#
# 		The filesystem char set. Sets the char set filesystem System var.
#
# --character-set-server=<charset name>, -C <charset_name>
#
# 		cmd line format: 		--character-set-server
# 		System var: 			character_set_server
# 		Scope: 					global, session
#		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1): 	utf8mb4
# 		Default (8.0.0): 		latin1
#
# 		Use <charset_name> as the default server char set. To specify a nondefault char set - use --collation-server to specify the collation.
#
# --chroot=<dir name>, -r <dir_name>
#
# 	 	cmd line format: 		--chroot=dir_name
# 		Type: 					Dir name
#
# 		Put the mysqld server in a closed env during startup by using the chroot() system call.
# 		Recommended security measure - limits interaction of LOAD_DATA_INFILE and SELECT ... INTO OUTFILE
#
# --collation-server=<collation_name>
#
# 		cmd line format: 		--collation-server
# 		System var: 			collation_server
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4_0900_ai_ci
# 		Default (8.0.0) 		latin1_swedish_ci
#
# 		Use collation_name as the default server collation.
#
# --console
#
# 		cmd line format: 		--console 
# 		OS: 						Windows
#
# 		Cause the default error log destination to be the console. This affects log writers that base
# 		their own output destination on the default destination.
#
# 		Takes precedence over --log-error if both are given
#
# --core-file
# 
# 		cmd line format: 		--core-file
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Write a core file if mysqld dies. Name and location of the core file is system dependent.
# 		On Linux, a core file named core.pid is written to the current working dir of the process, which for
# 		mysqld is the data dir.
#
# 		pid is the process ID of the server process. On macOS, a core file named core.pid is written
# 		to the /cores dir. On Solaris, use the coreadm cmd to specify where to write the core file and how to name it.
#
# 		For some systems, to get a core file you must also specify the --core-file-size option to mysqld_safe.
# 		On some systems, such as Solaris, you do not get a core file if you are also using the --user option.
# 		
# 		This may cause the need to write ulimit -c unlimited before starting the server.
#
# 		To reduce the size of core files - the innodb buffer pool in core file options can be disabled to prevent
# 		InnoDB buffer pool pages from being written to core files.
# 
# --daemonize, -D
# 		
#
# 		cmd line format: 			--daemonize[={OFF|ON}]
# 		Type 							Boolean
# 		Default: 					OFF
#
# 		Causes the server to run as a traditional, forking daemon, permitting it to work with OS systems that use
# 		systemd for process control.
#
# 		Mutually exclusive with --initialize and --initialize-secure
#
# 		If the server is started using the --daemonize option and is not connected to a tty device - a default log error option
# 		of --log-error="" is used in absence of explicit log file, to direct the error output to the default log file.
#
# 		-D is shorthand for this command.
#
# --datadir=<dir name>, -h <dir_name>
#
# 		cmd line format: 		--datadir=<dir_name>
# 		System var: 			datadir
# 		Scope:					Global
# 		Dynamic: 				No
# 		SET_VAR hint 			No
# 		Type: 					Dir name
#
# 		Path to the MySQL server data dir. This option sets the datadir sys var.
#
# --debug[=<debug options>], -# [<debug_options>]
#
# 		cmd line format: 		--debug[=<debug_options>]
# 		Sys var: 				debug
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR hint 			No
# 		Type: 					String
# 		default (Windows): 	d:t:i:O, \mysqld.trace
# 		default (Unix): 		d:t:i:o, /tmp/mysqld.trace
#
# 		If MySQL is configured with the -DWITH_DEBUG=1 CMake option, you can use this option to get a trace
# 		file of what mysqld is doing.
#
# 		A typical <debug_options> string is d:t:o, <file_name>.
# 		
# 		Using -DWITH_DEBUG=1 to configure MySQL with debug support enables you to use the --debug="d,parser_debug" option
# 		when you start the server.
#
# 		This causes the Bison parser that is used to process SQL statements to dump a parser trace to the server's STD error output.
# 		Typically, this output is written to the error log.
#
# 		Stacks. Values that begin with + or - are subtracted from the previous value. For example:
# 		--debug=T --debug=+P sets the value to P:T
#
# --debug-sync-timeout[=N]
# 		
# 		cmd line format: 			--debug-sync-timeout[=#]
# 		Type: 						Integer
#
# 		Controls whether the Debug Sync facility for testing and debugging is enabled. Use of Debug Sync
# 		requires that MySQL be configured with the -DENABLE_DEBUG_SYNC=1 CMake option.
#
# 		If not compiled-in, this option is not available. The option value is timeout in seconds.
# 		Defaults to 0, which disables Debug Sync.
#
# 		To enable it, specify a value greater than 0; this value also becomes the default timeout for
# 		individual synchronization points.
#
# 		If the option is given without a value - the timeout is set to 300 seconds.
#
# --default-storage-engine=<type>
#
# 		cmd line format: 			--default-storage-engine=name
# 		System var: 				default_storage_engine
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Enumeration
# 		Defaults to: 				InnoDB
#
# 		Set the default storage engine for tables. Sets the storage engine for permanent tables only.
# 		To set for temp tables - set the default_tmp_storage_engine sys Var.
#
# 		If you disable the default storage engine at server startup, you must set the default engine for both
# 		permanent and temp tables to a different engine or the server won't start
#
# --default-time-zone=<timezone>
#
# 		cmd line format: 			--default-time-zone=name
# 		Type: 						String
#
# 		Set the default server time zone. This option sets the global time zone Sys var.
# 		If not given, defaults to sys time zone - same as sys time zone sys var
#
# --defaults-extra-file=<file name>
#
# 		Read this option file after the global option file but (on Unix) before the user option file.
# 		If the file does not exist or is otherwise inaccessible, an error occurs.
# 		Relative if relative, Absolute if Absolute.
#
# 		Must be the first option given if used on the cmd line.
#
# --defaults-file=<file name>
# 
#		Read only the given option file. If the file does not exist or is otherwise inaccessible, an error occurs.
# 		Relative if relative, absolute if absolute.
#
# 		Still reads mysqld-auto.cnf
#
# 		Must be first option on cmd, except if server is started with --defaults-file and --install (or --install-manual) options.
# 		(Then --install/--install-manual must be first)
#
# --defaults-group-suffix=<str>
#
# 		Read not only the usual option groups - but also the groups with usual names and suffix of <str>.
# 		Regex onm suffix of groups to read.
#
# --delay-key-write[={OFF|ON|ALL}]
#
# 		cmd line format: 		--delay-key-write[=name]
# 		Sys var: 				delay_key_write
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR hint: 			No
# 		Type: 					Enumeration
# 		Default: 				ON
# 		ACCEPTS: 				ON/OFF/ALL
#
# 		Specify how to use delayed key writes. Delayed key writing causes key buffers not to be flushed between
# 		writes for MyISAM tables.
#
# 		OFF disables delayed key writes.
# 		ON enables delayed key writes for those tables that were created with the DELAY_KEY_WRITE option.
# 		ALL delay key writes for all MyISAM tables.
#
# 		NOTE: If set to ALL, one should not use MyISAM tables from within another program (such as another MySQL server or
# 				myisamchk) when the tables are in use. Causes index corruption if you do.
#
# --des-key-file=<file name>
#
# 	 	cmd line format: 		--des-key-file=<file_name>
# 		Deprecated: 			Yes
#
# --early-plugin-load=<plugin list>
#
# 		cmd line format: 		--early-plugin-load=<plugin_list>
# 		Type: 					String
# 		Defaults: 				Empty string
#
# 		This option tells the server which plugins to load before loading mandatory built-in plugins and before storage engine initialization.
# 		If multiple --early-plugin-load options are given, only the last one is used.
#
# 		The option value is a semicolon-separated list of <name>=<plugin_library> and <plugin_library> values.
#
# 		Each <name> is the name of a plugin to load, and <plugin_library> is the name of the library file that contains the plugin code.
# 		If a plugin library is named without any preceding plugin name - the server loads all plugins in the library.
#
# 		The server looks for plugin lib files in the dir named by the <plugin dir> Sys var.
#
# 		For example, if plugins named myplug1 and myplug2 have lib files myplug1.so and myplug2.so, use this option to perform an early plugin load:
#
# 			mysqld --early-plugin-load="myplug1=myplug1.so;myplug2=myplug2.so"
#
# 		Quotes are used around the arg value because otherwise a ; is treated as command eliminator in terms of for instance Unix systems.
#
# 		Each named plugin is loaded early for a single invocation of mysqld only.
# 		After a restart, the plugin is not loaded early unless --early-plugin-load is used again.
#
# 		If the server uses --initialize or --initialize-secure, plugins specified by --early-plugin-load are not loaded.
#
# 		If the server is run with --help, plugins specified by --early-plugin-load are loaded but not initialized. Ensures that
# 		plugin options are displayed in the help messages.
#
# 		Default of --early-plugin-load value is empty. To load the keyring_file plugin, you must use an explicit --early-plugin-load option with
# 		a nonempty value.
#
# 		The InnoDB tablespace encryption feature relies on the keyring_file plugin for encryption key management,
# 		and the keyring_file plugin must be loaded prior to storage engine initialization to facilitate InnoDB recovery for encrypted tables.
#
# 		Admins who want the keyring_file plugin loaded at startup should use the appropiate nonempty option value.
# 		For example - keyring_file.so on Unix and keyring_file.dll on Windows.
#
# --enable-named-pipe
#
# 		cmd line format: 			--enable-named-pipe
# 		Platform specific: 		Windows
#
# 		Enable support for named pipes. Applies only on Windows.
#
# --event-scheduler[=<value>]
# 		
# 		cmd line format: 			--event-scheduler[=<value>]
# 		Sys var: 					event_scheduler
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR hint: 				No
# 		Type: 						Enumeration
# 		Default (>= 8.0.3) 		On
# 		Default (<= 8.0.2) 		OFF
# 		Valid: 						ON/OFF/DISABLED
#
# 		For more info on this, see --event-scheduler.
# 		Enable, disable - start or stop the event scheduler.
#
# --exit-info[=<flags>], -T [<flags>]
#
# 		cmd line format: 			--exit-info[=<flags>]
# 		Type: 						Integer
#
# 		This is a bitmask of different flags that you can use for debugging the mysqld server.
# 		
# --external-locking
#
# 		cmd line format: 			--external-locking
# 		Type: 						Boolean
# 		Defaults: 					FALSE
#
# 		Enable external locking (system locking), which is disabled by default.
#
# 		If you use this option on a system on which lockd does not fully work (such as Linux),
# 		mysqld can easily deadlock.
#
# 		To disable external locking explicitly, use --skip-external-locking.
#
# 		External locking affects only MyISAM table access. 
#
# --flush
#
# 		cmd line format: 			--flush
# 		Sys Var 						flush
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Boolean
# 		Defaults: 					OFF
#
# 		Flush (synchronize) all changes to disk after each SQL statement. 
#
# 		Normally, MySQL does a write of all changes to disk only after each SQL statement
# 		and lets the OS handle the synch to disk.
#
# 		Note: If activated, flush time is ignored.
#
# --gdb 
#
# 		cmd line format: 			--gdb
# 		Type: 						Boolean
# 		default: 					FALSE
#
# 		Install an interrupt handler for SIGINT (needed to stop mysqld with ^C to set breakpoints) and disable stack tracking
# 		and core file handling.
#
# 		On Windows, this option also suppresses the forking that is used to implement the RESTART statement:
#
# 			Forking enables one process to act as a monitor to the other, which acts as the server.
#
# 			However, forking makes determining the server process to attach to for debugging more difficult,
# 			so starting the server with --gdb suppresses forking.
# 
# 			For a server started with this, RESTART simply exits and does not restart.
#
# 			In non-debug settings, --no-monitor may be used to suppress forking the monitor process.
#
# --general-log[={0|1}]
#
# 		cmd line format: 			--general-log
# 		Sys var: 					general_log
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR hint: 				No
# 		Type: 						Boolean
# 		Defaults: 					OFF
#
# 		Specify the initial general query log state. With no argument or an argument of 1, the --general-log option enables the log.
# 		If omitted or given with an arg of 0 - the option disables the log.
#
# --initialize, -I
#
# 		cmd line format: 			--initialize
# 		Type: 						Boolean
# 		Defaults: 					OFF
#
# 		Initializes a mysql installation by creating the data dir and populating the tables in the mysql system DB.
# 		
# 		When the server is started with --initialize, some functionality is unavailable that limits the statements permitted
# 		in any file named by the --init-file option.
#
# 		In addition, disabled_storage_engine sys var has no effect.
#
# 		--initialize is mutually exclusive with --daemonize 
#
# 		-I is a synonym for --initialize
#
# --initialize-insecure
#
# 		cmd line format: 			--initialize-insecure
# 		Type: 						Boolean
# 		Default: 					OFF
#
# 		This option is used to initialize a MySQL installation by creating the data dir and populating the tables
# 		in the mysql system DB. This option implies --initialize.
#
# 		--initialize-insecure is mutually exclusive with --daemonize.
#
# --init-file=<file name>
#
# 		cmd line format: 			--init-file=file_name
# 		Sys var: 					init_file
# 		Scope: 						Global 
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						File name
#
# 		Read the SQL statements from this file at the startup. Each statement must be on a single line and should not include comments.
#
# 		If the server is started with the --initialize or --initialize-insecure option, it operates in bootstrap mode and some
# 		functionality is unavailable that limits the statements permitted in the file.
#
# 		These include statements that are related to account management (such as CREATE USER or GRANT), replication and global transaction identifiers.
#
# --innodb-<xxx>
#
# 		Set an option for the InnoDB storage engine. The InnoDB options are listed later.
#
# --install [<service name>]
# 
# 		cmd line format: 			--install [service_name]
# 		Platform: 					Windows
#
# 		Install the server as a Windows Service that starts automatically when Windows does as well.
# 		Defaults to MySQL if no Service_name value is given.
#
# 		If server is started with --defaults-file and --install, --install must be first.
#
# --install-manual [<service name>]
# 		
# 		cmd line format: 			--install-manual [<service_name>]
# 		Platform: 					Windows
#
# 		Install the server as a Windows service that must be started manually. Does not start automatically during Windows boot cycle.
# 		Default service name is MySQL if no service_name is given.
#
# 		--install-manual first if --defaults-file and --install-manual given.
#
# --language=<lang name>, -L <lang name>
#
# 		cmd line format: 			--language=name
# 		Deprecated: 				Yes; use lc-messages-dir
# 		Sys Var: 					language
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						Dir name
# 		Default value: 			/usr/local/mysql/share/mysql/english/
#
# 		The language to use for error messages. <lang_name> can be given as the language name or as the full path name to the dir
# 		where the language files are installed.
#
# 		--lc-messages-dir and --lc-messages should be used rather than --language, which is deprecated (and handeled as an alias for --lc-messages-dir).
# 		--language will be removed in a future MySQL release.
#
# --large-pages
# 
# 		cmd line format: 			--large-pages
# 		Sys var: 					large_pages
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR hint: 				No
# 		Platform specific: 		Linux
# 		Type: 						Boolean
# 		Default: 					FALSE
#
# 		Some hardware/OS architechtures support memory pages greater than the default (4kb normally)
# 		The actual implementation of this support depends on the underlying hardware and OS.
#
# 		Applications that perform a lot of memory accesses may obtain performance improvements by using
# 		large pages due to reduced Translation Lookaside Buffer (TLB) Misses.
#
# 		Disabled by default.
#
# 		MySQL supports the Linux implementation of large page support (which is called HugeTLB) in Linux.
#
# 		For solaris, this pertains to --super-large-pages.
#
# --lc-messages=<locale name>
#
# 		cmd line format: 			--lc-messages=name
# 		Sys var: 					lc_messages
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						String
# 		Default: 					en_US
#
# 		The locale to use for error messages. Defaults to en_US. The server converts
# 		the args to a language name and combines it with the value of --lc-messages-dir to produce the location
# 		for the error message file.
#
# --lc-messages-dir=<dir name>
#
# 		cmd line format: 			--lc-messages-dir=dir_name
# 		Sys var: 					lc_messages_dir
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						Dir name
#
# 		The dir where error messages are located. The server uses the value together with the value
# 		of --lc-messages to produce the location for the error message file.
#
# --local-service
#
# 		cmd line format: 			--local-service
# 		
# 		Windows based: A --local-service option following the service name causes the server to run using the
# 							LocalService Windows acc that has limited sys privs.
#
# 							If both --defaults-file and --local-service are given following the service name, they can be in any order.
#
# --log-error[=<file name>]
#
# 		cmd line format: 			--log-error[=file_name]
# 		Sys var: 					log_error
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						File name
#
# 		Set the default error log dest. to the named file. This affects log writers that base their own
# 		output dest on the default dest.
#
# 		If the option names no file, the default error log dest on Unix and Unix-like systems is a file named <host_name.err> in the data Dir.
# 		The default destination on Windows is the same, unless the --pid-file option is specified.
#
# 		In that case, the file name is the PID file base name with a suffix of .err in the data dir.
#
# 		If the option names a file, the default destination is that file (with an .err suffix added if the name has no suffix),
# 		located under the data dir unless an absolute path name is given to specify a different location.
#
# 		If error log output cannot be redirected to the error log file, an error occurs and startup fails.
#
# 		On Windows, --console takes precedence over --log-error if both are given. In this case, the default error log destination is
# 		the console rather than a file.
#
# --log-isam[=<file name>]
#
# 		cmd line format: 		--log-isam[=file_name]
# 		Type: 					File name
#
# 		Log all MyISAM changes to this file (used only when debugging MyISAM)
#
# --log-output=<value>, ...
#
# 		cmd line format: 		--log-output=name
# 		Sys var: 				log_output
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Set
# 		Defaults: 				FILE
# 		Valid: 					TABLE, FILE, NONE
#
# 		This option determines the destination for general query log and slow query log output.
# 		The option value can be given as one or more of the words TABLE, FILE or NONE.
#
# 		TABLE select logging to the general log and slow_log tables in the mysql database as a destination.
# 		FILE selects logging to log files as a destination.
# 		NONE disables logging.
#
# 		If NONE is present in the option value, it takes precedence over any other words that are present.
# 		TABLE and FILE can both be given to select to both log output destinations.
#
# 		This option selects log output destinations, but does not enable log output.
# 		To do that, use the --general_log and --slow_query_log options.
#
# 		For FILE logging, the --general_log_file and -slow_query_log_file options determine the log file location.
#
# --log-queries-not-using-indexes
# 
# 		cmd line format: 		--log-queries-not-using-indexes
# 		System variable: 		log_queries_not_using_indexes
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		If you are using this option with the slow query log enabled, queries that are expected to retrieve all rows are logged.
#
# 		This option does not necessarily mean that no index is used. For example - a query that uses a full index scan uses an index
# 		but would be logged because the index would not limit the number of rows.
#
# --log-raw 
#
# 		cmd line format: 		--log-raw[=<value>]
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Passwords in certain statements written to the general query log, slow query log and binary log are rewritten by the server
# 		not to occur literally in plain text.
#
# 		Password rewriting can be suppressed for the general query log by starting the server with the --log-raw option.
# 		This option may be useful for diagnostic purposes, to see the exact text of statements as received by the server,
# 		but for security reasons is not recommended for production use.
#
# 		If a query rewrite plugin is installed, the --log-raw option affects statement logging as follows:
#
# 			Without --log-raw, the server logs the statement returned by the query rewrite plugin. This may differ from the statement as received.
#
# 			With --log-raw, the server logs the original statement as received.
#
# --log-short-format
#
# 		cmd line format: 		--log-short-format
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Log less information to the slow query log, if it has been activated.
#
# --log-tc=<file name>
#
# 		cmd line format: 		--log-tc=file_name
# 		Type: 					File name
# 		Default: 				tc.log
#
# 		The name of the memory-mapped transaction coordinator log file (for XA transactions that affect multiple storage engines
# 		when the binary log is disabled).
#
# 		The default name is tc.log. The file is created under the data dir if not given as a full path name. Unused.
#
# --log-tc-size=<size>
#
# 		cmd line format: 		--log-tc-size=#
# 		Type: 					integer
# 		Default: 				6 * page * size
# 		Minimum value: 		6 * page * size
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		The size in bytes of the memory-mapped transaction coordinator log. 
# 		Defaul and min values are 6 times the page size, and the value must be a multiple of the page size.
#
# --log-warnings[=<level>], -W [<level>]
#
# 		cmd line format: 		--log-warnings[=#]
# 		Deprecated: 			YES (removed in 8.0.3)
#     Sys var: 				log_warnings
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Int
# 		Default value: 		2
# 		Min val: 				0
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<a lot>
#
# 		DEPRECATED - Use log error verbosity sys var instead.
#
# --low-priority-updates
#
# 		cmd line format: 		--low-priority-updates
# 		Sys var: 				low_priority_updates
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Give table-modifying operations (INSERT, REPLACE, DELETE, UPDATE) lower prio than selects..
# 		This can also be done using { INSERT | REPLACE | DELETE | UPDATE } LOW PRIORITY ... to lower the prio of only one query,
# 		or by SET LOW_PRIORITY_UPDATES=1 to change the priority in one thread.
#
# 		This affects only storage engines that use only table-level locking (MyISAM, MEMORY, MERGE)
#
# --min-examined-row-limit=<number>
#
# 		cmd line format: 		--min-examined-row-limit=#
# 		Sys var: 				min_examined_row_limit
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min value: 				0
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		When this option is set - queries which examine fewer than <number> rows are not written to the slow query log. Default is 0.
#
# --memlock
#
# 		cmd line format: 		--memlock
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Lock the mysqld process in memory. This option might help if you have a problem where the OS is causing mysqld to swap to disk.
#
# 		--memlock works on systems that support the mlockall() system call; this includes Solaris, most Linux distributions that use a 2.4 or higher kernel,
# 		and perhaps other Unix systems.
#
# 		On Linux systems, you can tell whether or not mlockall() (and thus this option) is supported by checking to see whether or not it is defined
# 		in the system mman.h file, as follows:
#
# 		grep mlockall /usr/include/sys/mman.h
#
# 		If mlockall() is supported, you should see in the output of the previous command something as follows:
#
# 		extern int mlockall (int __flags) __THROW;
#
# 		NOTE: Do not use on a system that does not support mlockall(). Will crash, if you do.
#
# 		Might need to run as root, but can be circumvented with limits.conf changing as well.
#
# --myisam-block-size=<N>
#
# 		cmd line format: 		--myisam-block-size=#
# 		Type: 					integer
# 		Default: 				1024
# 		Min value: 				1024
# 		Max value: 				16384
#
# 		Block size used for MyISAM index pages.
#
# --myisam-recover-options[=<option>[, <option>] ...]]
# 	
# 		cmd line format: 		--myisam-recover-options[=<name>]
# 		Type: 					Enumeration
# 		Default: 				Off
# 		Valid values: 			OFF/DEFAULT/BACKUP/FORCE/QUICK
#
# 		Set the MyISAM storage engine recovery mode. The option value is any combination of the values of
# 		OFF, DEFAULT, BACKUP, FORCE or QUICK.
#
# 		If you specify multiple values, separate them by commas. Specifying the option with no argument is the same
# 		as specifying DEFAULT, and specifying with an explicit value of "" disables recovery (same as OFF).
#
# 		If recovery is enabled, each time mysqld opens a MyISAM table, it checks whether the table is marked as crashed
# 		or was not closed properly. (The last option works only if you are running with external locking disabled).
#
# 		If this is the case, mysqld runs a check on the table. If the table was corrupted, mysqld attempts to repair it.
#
# 		The following options pertain to how the repair works:
#
# 		OFF 		No recovery
# 		DEFAULT 	Recovery without backup, forcing or quick checking
# 		BACKUP 	If hte data file was changed during recovery, save a backup of the <tbl_name>.MYD file as <tbl_name-datetime>.BAK
# 		FORCE 	Run recovery even if we would lose more than one row from the .MYD file
# 		QUICK 	Do not check the rows in the table if there are not any delete blocks.
#
# 		Before the server automatically repairs a table, it writes a note about the repair to the error log.
#
# 		If you want to be able to recover from most problems without user intervention - you should use the options
# 		BACKUP, FORCE. This forces a repair of a table even if some rows would be deleted, but it keeps the old data file
# 		as a backup so that you can later examine what occured.
#
#
# --no-defaults
#
# 		Do not read any option files. If program startup fails due to reading unknown options from an option file, --no-defaults
# 		prevents crashing in relation to reading.
#
# --no-dd-upgrade
#
# 		cmd line format: 				--no-dd-upgrade
# 		Introduced: 					8.0.4
# 		Type: 							Boolean
# 		Default: 						FALSE
#
# 		Prevents the automatic upgrade of data dictionary tables when starting the MySQL server. This option would typically be used
# 		when starting the MySQL server following an in-place upgrade of the MySQL server to a new version, which may include changes to
# 		data dictionary table defs.
#
# 		When --no-dd-upgrade is specified, and the server finds that the data dictionary version of the server is different from the 
# 		version stored in the data dictionary, startup fails with an error stating that data dictionary upgrade is prohibited.
#
# 		During a normal startup, the data dictionary version of the server is compared to the version stored in the data dictionary
# 		to determine if data dictionary table defs should be upgraded.
#
# 		If an upgrade is necessary and supported, the server creates data dictionary tables with updated definitions, copies persisted
# 		metadata to the new tables, automatically replaces the old tables with new ones, and reinitializes the data dir.
#
# 		If an upgrade is not necessary, startup continues without updating data dir tables.
#
# --no-monitor
#
# 	   cmd line format: 				--no-monitor
# 		Introduced: 					8.0.12
# 		Platform based: 				Windows
# 		Type: 							Boolean
# 		Default: 						FALSE
#
# 		Suppresses the forking that is used to implement the RESTART statement.
# 		Forking enables one process to act as a monitor to the other, which acts as the server.
#
# 		For a server started with this option, RESTART simply exits and does not restart.
#
# 		Case of < 8.0.12 - can use --gdb for workaround.
#
# --old-alter-table
#
# 		cmd line format: 				--old-alter-table
# 		Sys Var: 						old_alter_table
# 		Scope: 							Global, Session
# 		Dynamic: 						Yes
# 		SET_VAR Hint: 					No
# 		Type: 							Boolean
# 		Default: 						OFF
#
# 		When this option is given, the server does not use the optimized method of processing an ALTER TABLE operation.
# 		It reverts to using a temp table, copying over the data - and then renames the temp table to the original - as per MySQL <= 5.0
#
# --old-style-user-limits
#
# 		cmd line format: 				--old-style-user-limits
# 		Type: 							Boolean
# 		Default: 						FALSE
#
# 		Enable old-style user limits. (Causes account resource limits to be counted seperately for each host from which a user connected rather than per acc row in the user table)
#
# --open-files-limit=<count>
#
# 		cmd line format: 				--open-files-limit=#
# 		Sys Var: 						open_files_limit
# 		Scope: 							Global
# 		Dynamic: 						No
# 		SET_VAR Hint: 					No
# 		Type: 							Int
# 		Default: 						5000, can be adjusted
# 		min: 								0
# 		max: 								OS dependant
#
# 		Changes the number of file descriptors available to mysqld. You should try increasing the value of this option if
# 		mysqld gives you the error "Too many open files".
#
# 		mysqld uses the option value to reserve desc with setrlimit().
# 		Internally, the maximum value for this option is the max unsigned integer value,
# 		but the actual max is OS dependant.
#
# 		If the requested number of file desc cannot be allocated, mysqld writes a warning to the error log.
#
# 		mysqld may attempt to allocate more than the requested number of desc (if they are available) using the values of max_connections
# 		and table_open_cache to estimate whether more descriptors will be needed.
#
# 		On Unix, the value cannot be set greater than ulimit -n
#
# --performance-schema-xxx
# 
# 		Configure a Performance Schema Option.
#
# --pid-file=<file name>
#
# 		cmd line format: 	--pid-file=<file_name>
# 		Sys Var: 			pid_file
# 		Scope: 				Global
# 		Dynamic: 			No
# 		SET_VAR Hint: 		No
# 		Type: 				File name
#
# 		Path name of the process ID file. The server creates the file in teh data dir unless an absolute path name is given to specify
# 		a different dir.
#
# 		If specified - must specify a value.
#
# 		If not specified, defaults to <host_name>.pid - where host name is name of the host machine.
#
# 		The process ID file is used by other programs such as mysqld_safe to determine the servers process ID.
# 		On Windows, this variable also affects the default error log file name.
#
# --plugin-xxx
#
# 		Specifies an option that pertains to a server plugin. 
#
# 		For example, many storage engines can be built as plugins, and for such engines, options for them
# 		can be specified with a --plugin prefix.
#
# 		Thus, the --innodb_file_per_table option for InnoDB can be specified as --plugin-innodb_file_per_table
#
# 		For boolean options, that can be enabled or disabled, the --skip prefix and other alternatives are supported.
#
# 		For example - --skip-plugin-innodb_file_per_table disables innodb_file_per_table.
#
# 		The rationale for the --plugin prefix is that it enables plugin options to be specified unambiguously if there is a 
# 		name conflict with a built-in server option.
#
# 		For example, if named --sql-mode - it would conflict with built in systems. To circumvent, specify with --plugin first.
#
# --plugin-load=<plugin list>
#
# 		cmd line format: 			--plugin-load=<plugin_list>
# 		Type: 						String
#
# 		This option tells the server to load the named plugins at startup.
#
# 		If multiple --plugin-load options are given, only last one is used. Additional may be loaded using --plugin-load-add.
#
# 		The option value is a semicolon listed of <name>=<plugin_library> and <plugin_library> values.
#
# 		Each <name> is the name of a plugin to load - and <plugin_library> is the name of the library file that contains 
# 		the plugin code.
#
# 		If a plugin library is named without any preceding plugin name, the server loads all plugins in the library.
# 		The server looks for plugin lib files in the dir named by the <plugin dir> sys var.
#
# 		For example - if plugins named myplug1 and myplug2 have lib files - myplug1.so and myplug2.so, use this to perform an early plugin load:
#
# 		mysqld --plugin-load="myplug1=myplug1.so;myplug2=myplug2.so"
#
# 		This differs from INSTALL PLUGIN in that it's localized to one invocation of mysqld - Which adds one entry to the mysql.plugins table to cause
# 		the plugin to be loaded for every normal server startup.
#
# 		Under normal startup, the server determines which plugins to load by reading the mysql.plguins system table.
#
# 		If the server is started with the --skip-grant-tables option - it does not consult the mysql.plugins table and does not load plugins
# 		listed there.
#
# 		--plugin-load allows for plugins to be loaded even when --skip-grant-tables is given.
# 		--plugin-load also enables plugins to be loaded at startup that cannot be loaded at runtime.
#
# --plugin-load-add=<plugin list>
#
# 		cmd line format: 			--plugin-load-add=plugin_list
# 		Type: 						String
#
# 		This option complements the --plugin-load option. 
# 		--plugin-load-add adds a plugin or plugins to the set of plugins to be loaded at startup.
#
# 		The argument format is the same as for --plugin-load. --plugin-load-add can be used to avoid specifying a large
# 		set of plugins as a single long unwieldy --plugin-load argument.
#
# 		--plugin-load-add can be used instead of --plugin-load, but any ones that precedes --plugin-load, resets the set to load.
#
# 		i.e: 	--plugin-load=x --plugin-load-add=y   		--> 		--plugin-load="x;y"
#
# 				--plugin-load-add=y 	--plugin-load=x 		--> 		--plugin-load=x
#
# --port=<port_num>, -P <port_num>
#
# 		cmd line format: 		--port=#
# 		Sys var: 				port
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				3306
# 		Min value: 				0
# 		Max value: 				65535
#
# 		Port number to use for listening on to TCP/IP connections. On Unix/akin, >= 1024 if not started by root
#
# --port-open-timeout=<num>
#
# 		cmd line format: 		--port-open-timeout=#
# 		Type: 					int
# 		Default: 				0
#
# 		On some systems, when the server is stopped, the TCP/IP port might not become available immediately.
# 		If the server is restarted quickly afterwards, its attempt to reopen the port can fail.
#
# 		This indicates how many seconds the server should wait for the TCP/IP port to become free if it cannot be opened.
# 		Defaults to not wait.
#
# --print-defaults
#
# 		Print the program name and all options that it gets from option files.
# 		PWs are masked. Must be first - except in relaiton to --defaults-file or --defaults-extra-file.
#
# --remove [<service_name>]
#
# 		cmd line format: 		--remove [service_name]
# 		platform: 				Windows
#
# 		Removes a MySQL Windows service. Default service name is MySQL if no <service_name> value is given.
#
# --safe-user-create
#
# 		cmd line format: 		--safe-user-create
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		If this option is enabled, a user cannot create new MySQL users by using the GRANT statement unless the user has the INSERT privs
# 		for the mysql.user table or any column in the table.
#
# 		If you want a user to have the ability to create new users that have those privs that the user has the right to grant,
# 		grant the user the following privs:
#
# 		GRANT INSERT(user) 	ON mysql.user 	TO 'user_name'@'host_name';
#
# 		Ensures that the user cannot change any priv columns directly - but has to use the GRANT statement to give privs to other users.
#
# --secure-auth
#
# 		cmd line format: 		--secure-auth
# 		DEPRECATED: 			8.0.3
# 		Sys var: 				secure_auth
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					BOOLEAN
# 		Default: 				ON
# 		VALID: 					ON
#
# --secure-file-priv=<dir name>
#
# 		cmd line format: 		--secure-file-priv=dir_name
# 		Sys var: 				secure_file_priv
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				platform specific
# 		Valid: 					empty string, dirname, NULL
#
# 		Sets the secure file priv sys var - which is used to limit the effect of data import and export operations,
# 		such as those performed by the LOAD DATA and SELECT ... INTO OUTFILE statements and the LOAD FILE() function.
#
# --shared-memory
#
# 		cmd line format: 		--shared-memory[={0,1}]
# 		Sys var: 				shared_memory
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Platform: 				Windows
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Enables shared-memory connections by local clients. Can only be done on Windows.
#
# --shared-memory-base-name=<name>
#
# 		cmd line format: 		--shared-memory-base-name=name
# 		System var: 			shared_memory_base_name
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Platform: 				Windows
# 		Type: 					String
# 		Default: 				MYSQL
#
# 		Name of the shared memory to use for shared-memory connections. Case sensitive.
#
# --skip-concurrent-insert
#
# 		Turns off the ability to select and insert at the same time on MyISAM tables. 
#
# --skip-event-scheduler
#
# 		cmd line format: 		--skip-event-scheduler
# 									--disable-event-scheduler
#
# 		Turns the Event Scheduler OFF. Not the same as disabling the event scheduler - that would require --event-scheduler=DISABLED;
#
# --skip-grant-tables
#
# 		cmd line format: 		--skip-grant-tables
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Causes the server to start without using the privilege system at all, which gives
# 		anyone with access to the server unrestricted access to all DBs.
#
# 		Can cause a running server to start using the grant tables again by executing mysqladmin flush-privileges
# 		or mysqladmin reload cmd from a sys shell or by issuing a MySQL FLUSH PRIVILEGES statement after connecting to the server.
#
# 		If the server is started with the --skip-grant-tables option to disable authentication checks, the server enables
# 		--skip-networking automatically to prevent remote connections.
#
# 		Also causes the server to suppress during its startup sequence the loading of user-defined functions (UDFs),
# 		scheduled events and plugins that were installed with the INSTALL PLUGIN statement.
#
# 		To cause plugins to be loaded anyway, use the --plugin-load option: --skip-grant-tables also causes the 
# 		disabled_storage_engines sys var to have no effect.
#
# 		Does not cause loading of server components to be suppressed during server startup.
#
# 		FLUSH PRIVILEGES might be executed implicitly by other actions performed after startup.
# 		For example, mysql_upgrade flushes the priv during the upgrade procedure.
#
# --skip-host-cache
#
# 		cmd line format: 		--skip-host-cache
#
# 		Disable use of the internal host cache for faster name-to-IP resolution.
# 		In this case, the server performs a DNS lookup every time a client connects.
#
# 		Use of --skip-host-cache is similar to setting the host_cache_size sys var to 0,
# 		but host_cache_size is more flexible - due to ability of integration of resizing, enabling or disabling,
# 		host cache at runtime, not just at server startup.
#
# 		If you start the server with --skip-host-cache - that does not prevent changes to the value of host_cache_size,
# 		but such changes have no effect and the cache is not re-enabled even if host_cache_size is set larger than 0.
#
# --skip-innodb
#
# 		Disable the InnoDB storage engine. In this case, because the default storage engine is InnoDB, the server will not
# 		start unless you also use --default-storage-engine and --default-tmp-storage-engine to set the default to some other
# 		engine for both permanent and TEMPORARY tables.
#
# 		The InnoDB storage engine cannot be disabled, and the --skip-innodb option is deprecated and has no effect.
# 		Results in a warning.
#
# --skip-name-resolve
#
# 		cmd line format: 		--skip-name-resolve
# 		Sys Var: 				skip_name_resolve
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Do not resolve host names when checking client connections. Use only IP addresses.
# 		If used - all Host column values in the grant table must be IP addresses.
#
# 		Depending on the network configuration of your system and the Host values for your accounts,
# 		clients may need to connect using an explicit --host option - such as --host=127.0.0.1 or --host=::1
#
# 		Example: If on, 127.0.0.1 does not resolve to localhost. Must be designated with:
#
# 		CREATE USER 'root'@'127.0.0.1' IDENTIFIED BY 'root-password';
# 		CREATE USER 'root'@'::1' IDENTIFIED BY 'root-password';
#
# --skip-networking
#
# 		cmd line format: 		--skip-networking
# 		Sys Var: 				skip_networking
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
#
# 		Do not listen for TCP/IP connections at all. All interactions with mysqld must be done through named pipes or shared memory or Unix sockets.
# 		Recommended for systems with only local clients permitted.
#
# 		If the server is started with the --skip-grant-tables option to disable authentication checks, the server enables --skip-networking to prevent remote connections.
#
# --ssl*
#
# 		Specify whether to permit clients to connect using SSL and indicate where to find SSL keys/Certs.
#
# --standalone
#
# 		cmd line format: 		--standalone
# 		Platform: 				Windows
#
# 		Instructs MySQL server to not run as a service.
#
# --super-large-pages
#
# 		cmd line format: 		--super-large-pages
# 		Platform: 				Solaris
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Standard use of large pages in MySQL attempts to use the largest size supported, up to 4MB.
# 		Under Solaris, super large pages is up to 256MB of pages.
#
# 		Can be turned on/off with: --super-large-pages or --skip-super-large-pages option.
#
# --symbolic-links, --skip-symbolic-links
#
# 		cmd line format: 		--symbolic-links
# 		Deprecated: 			8.0.2
# 		Type: 					Boolean
# 		Default (8.0.2 >=) 	OFF
# 		Default (8.0.1 <=) 	ON
#
# 		Enable or disable symbolic link support. On Unix, enabling symbolic links means that you can link a MyISAM index file or
# 		data file to another dir with the INDEX DIR or DATA DIR option of the CREATE TABLE statement.
#
# 		If deleting or renaming the table - the files that its symbolic links point to also are deleted or renamed.
#
# 		Symbolic link support, --symbolic-links - is deprecated. Disabled by default. have_symlink sys var is also deprecated
# 		Does not pertain to Windows.
#
# --skip-show-database
#
# 		cmd line format: 		--skip-show-database
# 		Sys Var: 				skip_show_database
# 		Scope: 					Global
#		Dynamic: 				No
# 		SET_VAR Hint: 			No
#
# 		This option sets the skip_show_database sys var that controls who is permitted to use the SHOW DATABASE.
#
# --skip-stack-trace
#
# 		cmd line format: 		--skip-stack-trace
#
# 		Do not write stack traces. Useful when running mysqld under a debugger.
# 		On some systems, you also must use this option to get a core file.
#
# --slow-query-log[={0|1}]
#
# 		cmd line format: 		--slow-query-log
# 		Sys Var: 				slow_query_log
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Specify the initial slow query log state. With no argument or an argument of 1, the --slow-query-log
# 		option enables the log. If omitted or given 0 - disables the log.
#
# --slow-start-timeout=<timeout>
#
# 		cmd line format: 		--slow-start-timeout=#
# 		Type: 					Integer
# 		Default: 				15000
#
# 		Controls the Windows service control manager's service start timeout.
# 		Max number of milliseconds that the service control manager waits before trying to kill the Windows service during startup.
# 		Default value is 15000 (15 seconds).
#
# 		0 is no timeout. 
#
# --socket=<path>
#
# 		cmd line format: 		--socket={file_name|pipe_name}
# 		Sys Var: 				socket
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (Other)  		/tmp/mysql.sock
# 		Default (Windows) 	MySQL
#
# 		On Unix, specifies the Unix socket file to use when listening for local connections.
# 		The default value is /tmp/mysql.sock.
#
# 		If this option is given, the server creates the file in the data dir unless an absolute path name is given
# 		to specify a different dir.
#
# 		On Windows, the option specifies the pipe name to use when listening for local connections that used a named pipe.
# 		Default is MySQL (not case sensitive)
#
# --sql-mode=<value>[,<value>[,<value> ...]]
#
# 		Cmd line format: 		--sql-mode=name
# 		Sys Var: 				sql_mode
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Set
# 		Default (>= 8.0.11) 	ONLY_FULL_GROUP_BY STRICT_TRANS_TABLES NO_ZERO_IN_DATE NO_ZERO_DATE
# 									ERROR_FOR_DIVISION_BY_ZERO NO_ENGINE_SUBSTITUTION
#
# 		Default (<= 8.0.4) 	ONLY_FULL_GROUP_BY STRICT_TRANS_TABLES NO_ZERO_IN_DATE
# 									NO_ZERO_DATE ERROR_FOR_DIVISION_BY_ZERO NO_AUTO_CREATE_USER
# 									NO_ENGINE_SUBSTITUTION
# 		
# 		Valid (>= 8.0.11) 	ALLOW_INVALID_DATES
# 									ANSI_QUOTES
# 									ERROR_FOR_DIVISION_BY_ZERO
# 									HIGH_NOT_PRECEDENCE
# 									IGNORE_SPACE
# 									NO_AUTO_VALUE_ON_ZERO
#
# 									NO_BACKSLASH_ESCAPES
# 									NO_DIR_IN_CREATE
# 									NO_ENGINE_SUBSTITUTION
# 									NO_UNSIGNED_SUBTRACTION
# 									NO_ZERO_DATE
#
# 									NO_ZERO_IN_DATE
# 									ONLY_FULL_GROUP_BY
# 									PAD_CHAR_TO_FULL_LENGTH
# 									PIPES_AS_CONCAT
# 									REAL_AS_FLOAT
#
# 									STRICT_ALL_TABLES
# 									STRICT_TRANS_TABLES
# 									TIME_TRUNCATE_FRACTIONAL
#
# 		Valid Values (>= 8.0.1, <= 8.0.4)
# 	
# 									ALLOW_INVALID_DATES
# 									ANSI_QUOTES
# 									ERROR_FOR_DIVISION_BY_ZERO
# 									HIGH_NOT_PRECEDENCE
# 									IGNORE_SPACE
# 									NO_AUTO_CREATE_USER
# 									NO_AUTO_VALUE_ON_ZERO
# 									NO_BACKSLASH_ESCAPES
# 									NO_DIR_IN_CREATE
# 									NO_ENGINE_SUBSTITUTION
# 									NO_FIELD_OPTIONS
# 									NO_KEY_OPTIONS
#
# 									NO_TABLE_OPTIONS
# 									NO_UNSIGNED_SUBTRACTION
# 									NO_ZERO_DATE
# 									NO_ZERO_IN_DATE
# 									ONLY_FULL_GROUP_BY
# 									
# 									PAD_CHAR_TO_FULL_LENGTH
# 									PIPES_AS_CONCAT
# 									REAL_AS_FLOAT
# 									STRICT_ALL_TABLES
# 									STRICT_TRANS_TABLES
# 									TIME_TRUNCATE_FRACTIONAL
#
# 		Valid (8.0) 			ALLOW_INVALID_DATES
# 									ANSI_QUOTES
# 									ERROR_FOR_DIVISION_BY_ZERO
# 									HIGH_NOT_PRECEDENCE
# 									IGNORE_SPACE
# 									NO_AUTO_CREATE_USER
# 									NO_AUTO_VALUE_ON_ZERO
# 									NO_BACKSLASH_ESCAPES
#
# 									NO_DIR_IN_CREATE
# 									NO_ENGINE_SUBSTITUTION
# 									NO_FIELD_OPTIONS
# 									NO_KEY_OPTIONS
# 									NO_TABLE_OPTIONS
#
# 									NO_UNSIGNED_SUBTRACTION
# 									NO_ZERO_DATE
# 									NO_ZERO_IN_DATE
# 									ONLY_FULL_GROUP_BY
# 									PAD_CHAR_TO_FULL_LENGTH
# 									
# 									PIPES_AS_CONCAT
# 									REAL_AS_FLOAT
# 									STRICT_ALL_TABLES
# 									STRICT_TRANS_TABLES
#
# The above refers to setting of the SQL mode.
#
# The startup can configure these during install process, or option files that the server reads at startup.
#
# --sysdate-is-now
#
# 	cmd line format: 			--sysdate-is-now
# 	Type: 						Boolean
# 	Default: 					FALSE
#
# 	SYSDATE() by default returns the time at which it executes, not the time at which the statement in which
# 	it occurs begins executing.
#
# 	This differs from the behavior of NOW().
#
# 	Causes the SYSDATE() to be an alias for NOW().
#
# --tc-heuristic-recover={COMMIT|ROLLBACK}
#
# 	cmd line format: 			--tc-heuristic-recover=name
# 	Type: 						Enumeration
# 	Default: 					COMMIT
# 	Valid: 						COMMIT, ROLLBACK
#
# 	Type of decision to use in the heuristic recovery process. 
# 	To use this option, two or more storage engines that support XA transactions must be installed.
#
# --temp-pool
#
# 	cmd line format: 			--temp-pool
# 	Deprecated: 				Yes (Removed in 8.0.1)
# 	Type: 						Boolean
# 	Default (other): 			FALSE
# 	Default (Linux): 			TRUE
# 
# 	Removed in 8.0.1
#
# --transaction-isolation=<level>
#
# 	cmd line format: 			--transaction-isolation=name
# 	Sys Var: 					transaction_isolation
# 	Scope: 						Global, Session
# 	Dynamic: 					Yes
# 	SET_VAR Hint: 				No
# 	Type: 						Enumeration
# 	Default: 					REPEATABLE-READ
# 	Valid: 						READ-UNCOMMITTED
# 									READ-COMMITTED
# 									REPEATABLE-READ
# 									SERIALIZABLE
#
# 	Sets the default transaction isolation level. The <level> value can be:
# 	READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ or SERIALIZABLE.
#
# 	The default transaction isolation level can also be set at runtime using the SET TRANSACTION
# 	statement or by setting the transaction_isolation SYS VAR.
#
# --transaction-read-only
#
# 	cmd line format: 			--transaction-read-only
# 	Sys Var: 					transaction_read_only
# 	Scope: 						Global, Session
# 	Dynamic: 					Yes
# 	SET_VAR Hint: 				No
# 	Type: 						Boolean
# 	Default: 					OFF
#
# 	Sets the default transaction access mode. By default, read-only mode is disabled, so the mode is read/write.
#
# 	To set the default transaction access mode at runtime, use the SET TRANSACTION statement or set the
# 	transaction read only SYS VAR.
#
# --tmpdir=<dir name>, -t <dir_name>
#
# 	cmd line format: 			--tmpdir=dir_name
# 	Sys Var: 					tmpdir
# 	Scope: 						Global
# 	Dynamic: 					No
# 	SET_VAR Hint: 				No
# 	Type: 						Dir name
#
# 	Path of the dir to use for creating temp files. Might be useful if your default /tmp dir resides on a platform that is too small to hold temp tables.
# 	Accepts several paths that are used in round-robin typing.
#
# 	Separation char: : on Unix, ; on Windows.
#
# 	If the MySQL server is acting as a replication slave - you should not set --tmpdir to point to a dir on a memory-based file system or to a dir
# 	that is cleared when the server host restarts.
#
# 	A replication slave needs some of its temp files to survive a machine restart so that it can replicate temp tables or LOAD DATA INFILE operations.
# 	If files in the temp file dir are lost when the server restarts, replication fails.
#
# --user={<user name>|<user id>}, -u {<user_name>|<user_id>}
#
# 	cmd line format: 			--user=name
# 	Type: 						String
#
# 	Run the mysqld server as the user having the name <user_name> or the numeric user ID <user_id>.
# 	"User" here is sys acc, not MySQL users in grant tables.
#
# 	Mandatory when starting mysqld as root. Server changes its ID during its startup sequence, causing it to run
# 	as that particular user rather than as root.
#
# 	To avoid a possible security hole where a user adds a --user=root option to my.cnf file,
# 	mysqld only runs with the first --user - attempting several causes a warning.
#
# 	/etc/my.cnf and $MYSQL_HOME/my.cnf run before CMD line. Thus, put another user than root in /etc/my.cnf (found before any other)
#
# --verbose, -v - Use this option with the --help option for detailed help.
#
# --version, -V - Display version info and exit.
#
# The following pertains to Server System Variables and more coverage about their inner workings.
#
# Sys vars can be set at server startup using options on the cmd line or in an option file.
#
# Most of them can be changed dynamically at runtime using the SET statement, which enables you to modify
# operation of the server without having to stop and restart it.
#
# We can also use Sys var values in expressions.
#
# At runtime, setting a global sys var value normally requires the SYSTEM VARIABLES ADMIN or SUPER privilege.
# Setting a session sys var normally reqs no privs - can be done by any user, there are exceptions though.
#
# based on current versioning (option files, compiled in defaults): mysqld --verbose --help
#
# Based on compiled in defaults, ignoring option files: mysqld --no-defaults --verbose --help
# 
# Current values run on server can also be seen with SHOW VARIABLES or the Performance Schema sys var tables.
#
# In terms of options, 1 and 0 act as logical booleans (TRUE and FALSE, respectively)
#
# Relative paths pertain to the data dir - such as /var/mysql/data
#
# activate_all_roles_on_login
#
# 		cmd line format: 		--activate-all-roles-on-login
# 		Introduced: 			8.0.2
# 		Sys Var: 				activate_all_roles_on_login
# 		Scope: 					Global
# 		Dynamic: 				yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Whether to enable automatic activation of all granted roles when users log in to the server:
#
# 			If activate_all_roles_on_login is enabled, the server activates all roles granted to each account at login time.
# 			This takes precedence over default roles specified with SET DEFAULT ROLE.
#
# 			If activate_all_roles_on_login is disabled, the server activates the default roles specified with SET DEFAULT ROLE, if any, at login time.
#
# 			Granted roles include those granted explicitly to the user and those named in the mandatory_roles SYS VAR.
#
# 			activate_all_roles_on_login applies only at login time, and at the beginning of execution for stored programs and views that execute
# 			in definer context.
#
# 			To change the active roles within a session, use SET_ROLE. 
#        To change the active roles for a stored program, the program body should execute SET ROLE.
#
# authentication_windows_log_level
#
# 		cmd line format: 		--authentication-windows-log-level
# 		Introduced: 			8.0.11
# 		Sys var: 				authentication_windows_log_level
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				2
# 		Min value: 				0
# 		Max value: 				4
#
# 		Available only if the authentication_windows Windows auth plugin is enabled and debugging code is enabled.
#
# 		Sets the log level for Windows auth Plugin:
#
# 		0 		No logging
# 		1 		Log only error messages
# 		2 		Log level 1 messages and warning messages
# 		3 		Log level 2 messages and information notes
# 		4 		log level 3 messages and debug messages
#
# authentication_windows_use_principal_name
# 		
# 		cmd line format: 		--authentication-windows-use-principal-name
# 		Introduced: 			8.0.11
# 		Sys Var: 				authentication_windows_use_principal_name
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		Is available only if the authentication_windows Windows auth plugin is enabled.
#
# 		A client that authenticates using the InitSecurityContext() function should provide a string identifying
# 		the service to which it connects.
#
# 		MySQL uses the principal name (UPN) of the account under which the server is running. 
# 		The UPN has the form <user_id@computer_name> and need not be registered anywhere to be used.
#
# 		The UPN is sent by the server at the beginning of authentication handshake.
#
# 		This variable controls whether the server sends the UPN in the initial challenge.
# 		By default, the variable is enabled.
#
# 		For security reasons, it can be disabled to avoid sending the server's account name to a client in clear text.
# 		If the variable is disabled, the server always sends a 0x00 byte in the first challenge, the client does not
# 		specify <targetName>, and as a result - NTLM authentication is used.
#
# 		If the server fails to obtain its UPN (which will happen primarily in environments that do not support Kerberos authentication),
# 		the UPN is not sent by the server and NTLM authentication is used.
#
# autocommit
#
# 		cmd line format: 	--autocommit[=#]
# 		Sys Var: 			autocommit
# 		Scope: 				Global, Session
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Boolean
# 		Default: 			ON
#
# 		The autocommit mode. If set to 1, all changes to a table take effect immediately. 
# 		If set to 0 - you must use COMMIT to accept a transaction or ROLLBACK to cancel it.
#
# 		If autocommit is 0 and you change it to 1, MySQL performs an automatic COMMIT of any open transaction.
# 		Another way to begin a transaction is to use a START TRANSACTION or BEGIN statement.
#
# 		By default, client connections begin with autocommit set to 1. To cause clients to begin with a default of 0,
# 		set the global autocommit value by starting the server with the --autocommit=0 option.
#
# 		Option file usage:
#
# 		[mysqld]
# 		autocommit=0
#
# automatic_sp_privileges
#
# 		Sys Var: 			automatic_sp_privileges
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Boolean
# 		Default: 			TRUE
#
# 		When set to 1 (Default), the server automatically grants the EXECUTE and ALTER ROUTINE privs to the
# 		creator of a stored routine - if the user cannot already execute and alter or drop the routine.
#
# 		(The ALTER ROUTINE priv is required to drop the routine). The server also automatically drops those 
# 		privs from the creator when the routine is dropped. If automatic_sp_privileges is 0, the server does
# 		not automatically add or drop these privs.
#
# 		The creator of a routine is the account used to execute the CREATE statement for it.
# 		This might not be the same as the account named as the DEFINER in the routine def.
#
# auto_generate_certs
#
# 		cmd line format: 		--auto-generate-certs[={OFF|ON}]
# 		System Var: 			auto_generate_certs
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		This variable is available if the server was compiled using OpenSSL. Controls whether 
# 		the server autogenerates SSL key and certificate files in the data dir, if they do not already exist.
#
# 		At startup, the server automatically generates server-side and client-side SSL cert and key files in the data dir
# 		if the auto_generate_certs SYS Var is enabled, no SSL options other than --ssl is on and the server-side SSL files are 
# 		missing from the data dir.
#
# 		These files enable secure client connections using SSL.
#
# 		The sha256_password_auto_generate_rsa_keys and caching_sha2_password_auto_generate_rsa_keys SYS vars are related,
# 		but control autogeneration of RSA key-pair files for secure PWs using RSA over unencrypted connections.
#
# avoid_temporal_upgrade
#
# 		cmd line format: 		--avoid-temporal-upgrade={OFF|ON}
# 		Deprecated: 			Yes
# 		Sys var. 				avoid_temporal_upgrade
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		This variable controls whether ALTER TABLE implicitly upgrades temporal columns found to be in pre-5.6.4 format
# 		(TIME, DATETIME and TIMESTAMP columns without support for fractional seconds precision)
#
# 		Upgrading such columns require a table rebuild, which prevents any use of fast alternations that might otherwise
# 		apply to the operation to be performed.
#
# 		This variable is disabled by default - Enabling it causes ALTER TABLE not to rebuild temporal columns and thereby be able to
# 		take advantage of fast alterations.
#
# 		DEPRECATED, will be removed.
#
# back log
#
# 		Sys var: 				back_log
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				-1 (autosizing)
# 		min: 						1
# 		max: 						65535
#
#		Number of oustanding connection requests MySQL can have.
# 		This comes into play when the main MySQL thread gets very many connection requests in a very short time.
# 		It takes a small gap of time for the main thread to then check the connection and start a new thread.
#
# 		The back_log indicates how many requests can be stacked during this short time before MySQL momentarily stops answering new requests.
#
# 		Only increase this if you expect a large number of connections in a short amount of time.
#
# 		Basically the size of the listen queue for incoming TCP/IP connections.
#
# 		OS has it's own limitations. Cannot be set higher than this limit.
#
# 		defaults to max connections, adjusts max permitted number of connections.
#
# 		the Unix call of listen() system call has more details.
#
# basedir
#
# 		cmd line format: 		--basedir=dir_name
# 		Sys Var: 				basedir
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name
# 		Default (8.0.2 >=) 	parent of mysqld install dir
# 		default (8.0.1 <=) 	configuration-dependant default
#
# 		Path of the MySQL install base dir
#
# big_tables
#
# 		Cmd line format: 		--big-tables
# 		Sys Var: 				big_tables
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		If set to 1 - all temp tables are stored on disk rather than in memory.
# 		This is a little slower, but the error "The table <tbl_name> is full" does not occur for SELECT operations that require
# 		a large temp table.
#
# 		Default value for a new connection is 0 (use in-memory temp tables).
# 		Normally, you should never need to set this Var.
#
# 		When in-memory internal temporary tables are managed by the TempTable storage engine 
# 		(the default), and max amount of memory that can be occupied by the TempTable storage engine is exceeded,
# 		the TempTable storage engine starts storing data to temp files on Disk.
#
# 		When in-memory temporary tables are managed by the MEMORY storage engine,
# 		in-memory tables are automatically converted to disk-based tables as required.
#
# bind_address
#
# 		cmd line format: 		--bind-address=addr
# 		Sys Var: 				bind_address
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Defaults: 				*
#
# 		Value of the --bind-address option
#
# block_encryption_mode
#
# 		cmd line format: 		--block-encryption-mode=#
# 		Sys Var: 				block_encryption_mode
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				aes-128-ecb
#
# 		This controls the block encryption mode for block-based algorithms such as AES.
# 		It affects encryption for AES_ENCRYPT() and AES_DECRYPT().
#
# 		block_encryption_mode takes a value in aes-<keylen>-<mode> format, where <keylen> is the key length
# 		in bits and <mode> is the encryption mode.
#
# 		The value is not case-sensitive. Permitted <keylen> values are 128, 192 and 256.
#
# 		Permitted encryption depend on whether MySQL was compiled using OpenSSL or wolfSSL:
#
# 			For OpenSSL, permitted <mode> values are: ECB, CBC, CFB1, CFB8, CFB128, OFB
#
# 			For wolfSSL, permitted <mode> values are: ECB, CBC
#
# 		For example - the following is 256 bits key length with AES encryption with the CBC mode:
#
# 			SET block_encryption_mode = 'aes-256-cbc';
#
# 		An error occurs for attempts to set block_encryption_mode to a value containing an unsupported key length
# 		or a mode that the SSL lib does not support.
#
# bulk_insert_buffer_size
#
# 		cmd line format: 		--bulk-insert-buffer-size=#
# 		Sys Var: 				bulk_insert_buffer_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				8388608
# 		Min value: 				0
# 		Max value (64-bit) 	a lot
# 		Max value (32-bit) 	less
#
# 		MyISAM uses a special tree-like cache to make bulk inserts faster for INSERT ... SELECT, INSERT ... VALUES (...),
# 		(...), ... and LOAD DATA INFILE when adding data to nonempty tables.
#
# 		This variable limits the size of the cache tree in bytes per thread. 
# 		Setting it to 0 disables this optimization. Defaults to 8MB.
#
# 		(MySQL 8.0.14 >=) : Setting the session value of this SYS var is a restricted operation.
# 								  The session user must have privs sufficient to set restricted session vars.
#
# caching_sha2_password_auto_generate_rsa_keys
#
# 		cmd line format: 		--caching-sha2-password-auto-generate-rsa-keys[={OFF|ON}]
# 		Introduced: 			8.0.4
# 		Sys Var: 				caching_sha2_password_auto_generate_rsa_keys
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		Available if the server was compiled using OpenSSL. The server uses it to determine whether to autogenerate
# 		RSA private/public key-pair files in the data dir if they do not already exist.
#
# 		At startup, the server automatically generates RSA private/public key-pair files in the data dir if all of the following is true:
#
# 			The sha256_password_auto_generate_rsa_keys or caching_sha2_password_auto_generate_rsa_keys sys var is Enabled
#
# 			No RSA options are specified
#
# 			No RSA files are in the data dir.
#
# 			The key-pair files enable secure password exchange using RSA over unencrypted connections for accounts authenticated
# 			by the sha256_password or caching_sha2_password plugin
#
# 			auto_generate_certs SYS var is related but controls autogeneration of SSL cert and key files needed for Secure connections using SSL.
#
# caching_sha2_password_private_key_path
#
# 		cmd line format: 			--caching-sha2-password-private-key-path=file_name
# 		introduced: 				8.0.3
# 		Sys Var: 					caching_sha2_password_private_key_path
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						File Name
# 		Default: 					private_key.pem
#
# 		This variable specifies the path name of the RSA private key file for the caching_sha2_password auth plugin.
# 		If relative, it's relative to server data dir. File must be in PEM format.
#
# 		Because a private key is stored within - access should be restricted to MySQL.
#
# caching_sha2_password_public_key_path
#
# 		Cmd line format: 			--caching-sha2-password-public-key-path=file_name
# 		Introduced: 				8.0.3
# 		Sys Var: 					caching_sha2_password_public_key_path
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						File name
# 		Default: 					public_key.pem
#
# 		Same as above, except for a public key.
#
# character_set_client
#
# 		Sys var: 					character_set_client
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						String
# 		Default (>= 8.0.1) 		utf8mb4
# 		Default (8.0.0) 			utf8
#
# 		Char set for statements that arrive from the client.
#
# 		The session value of this var is set using the char set requested by the client when the client
# 		connects to the server.
#
# 		Many clients support a --default-character-set option to enable this char set to be specified explicitly.
#
# 		The global value of the variable is used to set the session value in cases when the client-requested value is unknown
# 		or not available - or the server is configured to ignore client requests
#
# 		examples:
#
# 		The client requests a char set not known to the server. For example, a japanese-enabled client requests sjis when connecting
# 		to a server not configured with sjis support.
#
# 		The client is from a version of MySQL older than MySQL 4.1 - i.e, does not require a char set
#
# 		mysqld started with the --skip-character-set-client-handshake option - ignores client char set configs.
#
# 		Some char sets are invalid for client char sets. Trying to use them as the character_set_client value produces an error.
#
# character_set_connection
#
# 		Sys var: 				character_set_connection
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4
# 		Default (8.0.0) 		utf8
# 
# 		The char set used for literals specified without a char set introducer and for number-to-string conversion.
#
# character_set_database
#
# 		Sys var: 				character_set_database
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4
# 		Default (8.0.0) 		latin1
# 		Footnote: 				Dynamic - but server should be designating this value by itself.
# 		
# 		The char set used by the default DB. The server sets this var whenever the default DB changes.
# 		If there is no default DB, the var has the same value as character_set_server.
#
# 		(8.0.14 >=) setting the session value of this system variable is a restricted operation.
# 		The session user must have privileges sufficient to set restricted session variables.
#
# 		The global character_set_database and collation_database SYS vars are deprecated, will be removed.
#
# 		Since they are deprecated - attempting to assign them causes a warning.
#
# 		The session vars is read only in the future.
#
# 		Can still access for reading purposes in relation to DB charset and collation.
#
# character_set_filesystem
#
# 		cmd line format: 			--character-set-filesystem=name
# 		Sys var: 					character_set_filesystem
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						String
# 		Default: 					binary
#
# 		The file system char set. Used to interpret string literals that refers to file names, such as 
# 		in the LOAD_DATA_INFILE and SELECT_..._INTO_OUTFILE statements and the LOAD_FILE() function.
#
# 		Such file names are converted from character_set_client to character_set_filesystem before the file opening
# 		attempt occurs.
#
# 		Default is binary, which means no conversion occurs. 
# 		For systems on which multibyte file names are permitted, a different value may be used.
#
# 		For example, if using UTF-8 in the system - we can set this to 'utf8mb4'
#
# 		(MySQL 8.0.14)	- This is a restricted operation - session user must have privs sufficient to set restricted session vars.
#
# character_set_results
#
# 		Sys Var: 				character_set_results
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4
# 		Default (8.0.0) 		utf8
#
# 		The char set used for returning query results to the client.
# 		This includes result data such as column values, result metadata such as column names and error messages.
#
# character_set_server
#
# 		cmd line format: 		--character-set-server
# 		Sys Var: 				character_set_server
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4
# 		Default (8.0.0) 		latin1
#
# 		The servers default char set
#
# character_set_system
#
# 		Sys var: 				character_set_system
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				utf8
#
# 		The char set used by the server for storing identifiers. Value is always utf8.
#
# character_sets_dir
#
# 		cmd line format: 		--character-sets-dir=dir_name
# 		Sys Var: 				character_sets_dir
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name
#
# 		The dir where char sets are installed.
#
# check_proxy_users
#
# 		cmd line format: 		--check-proxy-users=[={OFF|ON}]
# 		Sys var: 				check_proxy_users
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Some authentication plugins implement proxy user mapping for themselves (for example, the PAM and Windows auth plugins)
# 		Other authentication plugins do not support proxy users by default.
#
# 		Of these, some can request that the MySQL server itself map proxy users according to granted proxy privs:
#
# 		mysql_native_password_sha256_password
#
# 		If the check_proxy_users SYS Var is enabled, the server performs proxy user mapping for any authentication plugins that make
# 		such a request.
#
# 		However, it may also be necessary to enable plugin-specific system variables to take advantage of server proxy user mapping support:
#
# 			For the mysql_native_password plugin, enable mysql_native_password_proxy_users
#
# 			For the sha256_password plugin, enable sha256_password_proxy_users
#
# collation_connection
#
# 		Sys var: 				collation_connection
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
#
# 		The collation of the connection char set. 
#
# 		collation_connection is important for comparisons of literal strings.
#
# 		For comparisons of strings with column values, collation_connection does not matter because columns
# 		have their own collation, which has a higher collation precedence.
#
# collation_database
#
# 		Sys var: 				collation_database
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4_0900_ai_ci
# 		Default (8.0.0) 		latin1_swedish_ci
# 		Footnote: 				Dynamic - leave interaction to server.
#
# 		Collation used by the default DB. The server sets this var whenever the default DB changes.
#
# 		If there is no default DB, the var has the same value as collation server.
#
# 		(MySQL 8.0.14 >=) Setting the session value of this system variable is a restricted operation.
# 								The session user must have privs sufficient to set restricted session vars.
#
# 		The global character_set_database and collation_database SYS var is deprecated and assignment causes a warning.
# 		
# 		Read only in the future.
#
# collation_server
#
# 		cmd line format: 		--collation-server
# 		Sys Var: 				collation_server
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (>= 8.0.1) 	utf8mb4_0900_ai_ci
# 		Default (8.0.0) 		latin1_swedish_ci
#
# 		Servers default collation
#
# completion_type
#
# 		cmd line format: 		--completion-type=#
# 		Sys Var: 				completion_type
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				NO_CHAIN
# 		Valid values: 			NO_CHAIN, CHAIN, RELEASE, 0, 1, 2
#
# 		The transaction completion type. This variable can take the values shown in the following:
#
# 		Name 						DESC
# 	
# 		NO_CHAIN/0  			COMMIT and ROLLBACK are unaffected. Default value.
#
# 		CHAIN/1 					COMMIT and ROLLBACK are equivalent to COMMIT AND CHAIN and ROLLBACK AND CHAIN respectively.
# 									(A new transaction starts immediately with the same isolation level as the just-terminated transaction)
#
# 		RELEASE/2 				COMMIT and ROLLBACK are equivalent to COMMIT RELEASE and ROLLBACK RELEASE, respectively.
# 									(The server disconnects after terminating the transaction)
#
# 		completion_type affects transactions that begin with START_TRANSACTION or BEGIN and end with COMMIT or ROLLBACK.
#
# 		Does not apply to implicit commits. Does not apply to XA_COMMIT, XA_ROLLBACK or autocommit=1.
#
# concurrent_insert
#
# 		cmd line format: 		--concurrent-insert[=#]
# 		Sys Var: 				concurrent_insert
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				AUTO
# 		VALID: 					NEVER, AUTO, ALWAYS, 0, 1, 2
#
# 		If AUTO - MySQL permits INSERT and SELECT statements to run concurrently for MyISAM tables that have no free blocks in
# 		the middle of the data file.
#
# 		If you start mysqld with --skip-new, this variable is set to NEVER.
#
# 		Values:
#
# 		Name 				DESC
# 		
# 		NEVER/0 			Disables concurrent inserts
#
# 		AUTO/1 			Enables concurrent insert for MyISAM tables that do not have holes.
#
# 		ALWAYS/2 		Enables concurrent inserts for all MyISAM tables - even those that have holes.
# 							For a table with a hole - new rows are inserted at the end of the table if it is in
# 							use by another thread. 
#
# 							Otherwise - MySQL aquires a normal write lock and inserts the row into the hole.
#
# connect_timeout
#
# 		cmd line format: 		--connect-timeout=#
# 		Sys var: 				connect_timeout
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				10
# 		Min: 						2
# 		Max: 						31536000
#
# 		Number of seconds mysqld waits for a connection packet before responding with Bad handshake.
# 		Defaults 10 seconds.
#
# 		Increasing the connect_timeout value might help if clients frequently encounters errors of the form:
# 		
# 		Lost connection to MySQL server at 'XXX', system error: <errno>
#
# core_file
#
# 		Sys var: 				core_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Whether to write a core file if the server crashes. Is set by the --core-file option.
#
# 		Under some circumstances, disabling innodb_buffer_pool_in_core_file can cause core_file to be disabled.
#
# cte_max_recursion_depth
#
# 		cmd line format: 		--cte-max-recursion-depth=#
# 		Introduced: 			8.0.3
# 		Sys Var: 				cte_max_recursion_depth
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1000
# 		Min: 						0
# 		Max: 						<a lot>
#
# 		The common table expression (CTE) maxium recursion depth.
# 		The server terminates execution of any CTE that recurses more levels than the values of this var.
#
# datadir
#
# 		cmd line format: 		--datadir=dir_name
# 		Sys Var: 				datadir
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name
#
# 		The path to the MySQL server data dir. Relative paths are resolved with respect to the CWD.
# 		If the server will be started automatically (Where you can't assume the CWD) - specify datadir as absolute
#
# debug
# 		
# 		cmd line format: 		--debug[=debug_options]
# 		Sys Var: 				debug
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default (Windows) 	d:t:i:O, \mysqld.trace
# 		Default (Unix) 		d:t:i:o, /tmp/mysqld.trace
#
# 		Indicates the current debugging settings. 
# 		Available only for servers built with debugging support.
#
# 		Initial value comes from the value of instances of the --debug option given at server startup.
# 		Global and Session values may be set at runtime.
#
# 		Setting the session value of this Sys var is a restricted operation.
# 		Must have permission to set restricted session vars.
#
# 		Example of modifying debugging status:
#
# 		SET debug = 'T'; #base declaration
# 		SELECT @@debug; #Select the attribute
#
# 		@@debug
# 		
# 		T
#
# 		SET debug = '+P'; #Add P as part of operations
# 		SELECT @@debug;
# 
# 		@@debug
#
# 		P:T
#
# 		SET debug = '-P'; #Remove P as part of operations
# 		SELECT @@debug;
#
# 		T
#
# debug_sync
#
# 		Sys var: 		debug_sync
# 		Scope: 			Session
# 		Dynamic: 		Yes
#	 	SET_VAR Hint: 	No
# 		Type: 			String
#
# 		The variable is the user interface to the Debug Sync facility.
# 		Use of Debug Sync requires that MySQL be configured with the -DENABLE_DEBUG_SYNC=1 CMake option.
#
# 		If Debug Sync is not compiled in, this sys var is not available.
#
# 		The global var value is read only and indicates whether the facility is enabled.
# 		By default, Debug Sync is disabled and the value of debug_sync is OFF.
#
# 		If the server is started with --debug-sync-timeout=<N>, where <N> is a timeout value greater than 0,
# 		Debug Sync is enabled and the value of debug_sync is ON - <current signal> (the signal name)
#
# 		<N> becomes the default timeout for individual synchronization points.
#
# 		The session value can be read by any user and will have the same value as the global variable.
# 		The session value can be set to control synchronization points.
#
# 		Setting the session value of this Sys Var is a restricted operation.
#
# 		Covered more in terms of MySQL internals: Test Synchronization
#
# default_authentication_plugin
#
# 		cmd line format: 				--default-authentication_plugin=plugin_name
# 		Sys Var: 						default_authentication_plugin
# 		Scope: 							Global
# 		Dynamic: 						No
# 		SET_VAR Hint: 					No
# 		Type: 							Enumeration
#
# 		Default (>= 8.0.4) 			caching_sha2_password
#
# 		Default (<= 8.0.3) 			mysql_native_password
#
# 		Valid (>= 8.0.3) 				mysql_native_password
# 											sha256_password
# 											caching_sha2_password
#
# 		Valid (<= 8.0.2) 				mysql_native_password
# 											sha256_password
#
# 		The default auth plugin. Permitted values are:
#
# 			mysql_native_password: Use MySQL native PWs.
# 
# 			sha256_password: Use SHA-256 PWs.
#
# 			caching_sha2_password: Use SHA-256 passwords. (Default auth plugin rather than mysql_native_password)
#
# 		This value affects these aspects of server operations:
#
# 			Determines which authentication plugin the server assigns to new accounts created by CREATE USER and GRANT statements that 
# 			do not explicitly specify an authentication plugin.
#
# 			For an account created with the following statement, the server associates the account with the default auth plugin and assigns
# 			the account the given PW - hashed as required by that plugin:
#
# 				CREATE USER ... IDENTIFIED BY 'cleartext password';
#
# default_collation_for_utf8mb4
#
# 		Introduced: 		8.0.11
# 		Sys Var: 			default_collation_for_utf8mb4
# 		Scope: 				Global, Session
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Enumeration
# 		Valid: 				utf8mb4_0900_ai_ci 
# 								utf8mb4_general_ci
#
# 		For interal use by replication. This SYS VAR is set to the default collation for the utf8mb4 char set.
#
# 		The value of the Var is replicated from a master to a slave so that the slave can correctly process data
# 		originating from a master with a different default collation for utf8mb4.
#
# 		Primarily intended to support replication from MySQL 5.7 or older master servers to MySQL 8.0 slave server,
# 		or group replication with a MySQL 5.7 primary node and one or more MySQL 8.0 secondaries.
#
# 		The default collation for utf8mb4 in MySQL 5.7 is utf8mb4_general_ci, but utf8mb4_0900_ai_ci in MySQL 8.0
#
# 		If the slave does not recieve a value for the Var, it assumes the master is from an earlier release and sets
# 		the value to the previous default collation utf8mb4_general_ci.
#
# 		Is a restircted operation, requires privs to set.
#
# 		The default utf8mb4 collation is used in the following statements:
#
# 			SHOW COLLATION and SHOW CHARACTER SET.
#
# 			CREATE TABLE and ALTER TABLE having a CHARACTER SET utf8mb4 clause without a COLLATION clause, either for 
# 			the table char set or for a column char set.
#
# 			CREATE DATABASE and ALTER DATABASE having a CHARACTER SET utf8mb4 clause without a COLLATION clause.
#
# 			Any statement containing a string literal of the form _utf8mb4'<some text>' without a COLLATION clause.
#
# default_password_lifetime
#
# 		cmd line format: 		--default-password-lifetime=#
# 		Sys Var: 				default_password_lifetime
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min value: 				0
# 		Max: 						65535
#
# 		Defines the global automatic password expiration policy. The default_password_lifetime value is 0,
# 		which disables automatic password expiration.
#
# 		If the value of default_password_lifetime is a positive int <N>, it indicates the permitted password lifetime; PWs must be changed every <N> days.
#
# 		The global PW expiration policy can be overwritten with individual accounts using the PW expiration option of CREATE USER and ALTER USER statements.
#
# default_storage_engine
#
# 		cmd line format: 		--default-storage-engine=name
# 		Sys var: 				default_storage_engine
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				InnoDB
#
# 		The default storage engine. This variable sets the storage engine for permanent tables only. To set the storage engine
# 		for TEMPORARY tables, set the default_tmp_storage_engine SYS var.
#
# 		To see which storage engines are available and on - we can use SHOW ENGINES or query the INFORMATION_SCHEMA ENGINES table.
#
# 		If you disable the default storage engine at server startup, you must set the default engine for both permanent and TEMPORARY
# 		tables to a different engine or the server won't start.
#
# default_tmp_storage_engine
#
# 		Cmd line format: 		--default-tmp-storage-engine=name
# 		Sys Var: 				default_tmp_storage_engine
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Enumerator
# 		Default: 				InnoDB
#
# 		The default storage engine for TEMPORARY tables (created with CREATE TEMPORARY TABLE)
# 		To set the storage engine for permanent tables - set the default_storage_Engine SYS VAR.
#
# 		If you disable the default storage engine at server startup, you must set the default engine for both
# 		permanent and TEMPORARY tables to a different engine or the server won't start.
#
# default_week_format
#
# 		cmd line format: 		--default-week-format=#
# 		Sys Var: 				default_week_format
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max: 						7
#
# 		Default mode value to use for the WEEK() function
#
# delay_key_write
#
# 		cmd line format: 		--delay-key-write[=name]
# 		Sys Var: 				delay_key_write
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				ON
# 		Valid: 					ON, OFF, ALL
#
# 		This option applies only to MyISAM tables. 
#     It can have one of the following values to affect handling of the DELAY_KEY_WRITE table option that can be used in CREATE TABLE statements.
#
# 		OFF - 	DELAY_KEY_WRITE is ignored.
# 		ON  - 	MySQL honors any DELAY_KEY_WRITE option specified in CREATE_TABLE statements. DEFAULT.
# 		ALL - 	All new opened tables are treated as if they were created with the DELAY_KEY_WRITE option on.
#
# 		If this option is on, the key buffer is not flushed for the table on every index update - but only when the table is closed.
# 		This speeds up writes on keys a lot - but if you use this feature, you should add automatic checking of all MyISAM tables by
# 		starting with --myisam-recover-options , example:
#
# 		--myisam-recover-options=BACKUP, FORCE
#
# 		If external locking is on with --external-locking, there is no protection against index corruption for tables that use
# 		delayed key writes.
#
# delayed_insert_limit
#
# 		cmd line format: 			--delayed-insert-limit=#
# 		Deprecated: 				Yes
# 		Sys var: 					delayed_insert_limit
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Integer
# 		Default: 					100
# 		Min: 							1
# 		Max (64-bit) 				<a lot>
# 		Max (32-bit) 				<less>
#
# 		This Sys var is deprecated (DELAYED inserts are not supported), will be removed.
#
# delayed_insert_timeout
#
# 		cmd line format: 			--delayed-insert-timeout=#
# 		Deprecated: 				Yes
# 		Sys Var: 					delayed_insert_timeout
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Integer
# 		Default: 					300
#
# 		Deprecated, same as above.
#
# delayed_queue_size
#
# 		cmd line format: 			--delayed-queue-size=#
# 		Deprecated: 				Yes
# 		Sys Var: 					delayed_queue_size
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Integer
# 		Default: 					1000
# 		Min: 							1
# 		Max (64-bit) 				<a lot>
# 		Max (32-bit) 				<less>
#
# 		Deprecated
#
# disabled_storage_engines
#
# 		cmd line format: 			--disabled-storage-engines=engine[, engine]...
# 		Sys Var: 					disabled_storage_engines
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						String
# 		Default: 					empty string
#
# 		indicates which storage engines cannot be used to create tables or tablespaces.
# 		For example,to prevent new MyISAM or FEDERATED tables from being created - start with the lines as follows:
#
# 			[mysqld]
# 			disabled_storage_engines="MyISAM,FEDERATED"
#
# 		By default - disabled_storage_engines is empty (no engines disabled) - but can be defined with a comma-listed list.
# 
# 		Values included cause said values to not be able to be used to create tables or tablespaces with CREATE_TABLE or CREATE_TABLESPACE,
# 		and cannot be used with ALTER_TABLE_..._ENGINE or ALTER_TABLESPACE_..._ENGINE to change existing storage engines of tables or tablespaces.
#
# 		Doing so causes a ER_DISABLED_STORAGE_ENGINE error
#
# 		disabled_storage_engines does not restrict other DDL statements for existing tables, such as CREATE_INDEX,
# 		TRUNCATE_TABLE, ANALYZE_TABLE, DROP_TABLE or DROP_TABLESPACE.
#
# 		This permits a smooth transition so that existing tables or tablespaces that use a disabled engine can be migrated to a 
# 		permitted engine by means such as ALTER_TABLE_..._ENGINE_<permitted_engine>
#
# 		It is permitted to set the default_storage_engine or default_tmp_storage_engine SYS var to a storage engine that is disabled.
#
# 		However, it does make the database crash upon attempting to be utilized if used in tandem with this stature. (Can be used for debugging)
#
# 		disabled_storage_engines is disabled and has no effect if the server is started with any of these options:
#
# 			--initialize, --initialize-insecure, --skip-grant-tables
#
# 		Setting this can cause a error with mysqld_upgrade
#
# disconnect_on_expired_password
#
# 		Cmd line format: 		--disconnect-on-expired-password[=#]
# 		Sys Var: 				disconnect_on_expired_password
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		This var controls how the server handles clients with expired passwords:
#
# 			If the client indicates that it can handle expires passwords, the value of disconnect_on_expired_password
# 			is irrelevant. The server permits the client to connect but puts it in sandbox mode.
#
# 			If the client does not indicate that it can handle expires passwords, it handles it according to disconnect_on_expired_password:
#
# 				Enabled -> Disconnects the client
#
# 				Disabled -> permits, but keeps in Sandbox mode
#
# div_precision_increment
#
# 		cmd line format: 			--div-precision-increment=#
# 		Sys Var: 					div_precision_increment
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				Yes
# 		Type: 						Integer
# 		Default: 					4
# 		Min: 							0
# 		Max: 							30
#
# 		This variable indicates the number of digits by which to increase the scale of the result of division operations performed with
# 		the / operator.
#
# dragnet.log_error_filter_rules
#
# 		cmd line format: 			--dragnet.log-error-filter-rules
# 		Introduced: 				8.0.4
# 		Sys Var: 					dragnet.log_error_filter_rules
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						String
# 		Default: 					IF prio>=INFORMATION THEN drop. IF EXISTS source_line THEN unset source_line.
#
# 		The filter rules that control operation of the log_filter_dragnet error log filter component.
# 		If log_filter_dragnet is not installed, dragnet.log_error_filter_rules is N/A.
#
# 		If log_filter_dragnet is installed but off, dragnet.log_error_filter_rules have no effect.
#
# 		(MySQL 8.0.12 >=) - the dragnet.Status variable can be consulted to determine the result of the most
# 		recent assignment to dragnet.log_error_filter_rules
#
# 		(MySQL 8.0.12 <)  - the dragnet.Status assignment upon success, spawned a warning:
#
# 			mysql> SET GLOBAL dragnet.log_error_filter_rules = 'IF prio <> 0 THEN unset prio.';
# 			Query OK, 0 rows affected, 1 warning (0.00 sec)
#
# 			mysql> SHOW WARNINGS\G
# 			******************************** 1. row *******************************************
# 			Level: Note
# 			Code:  4569
# 			Message: filter configuration accepted:
# 						SET @@global.dragnet.log_error_filter_rules='IF prio!=ERROR THEN unset prio.';
#
# 		The value displayed by SHOW_WARNINGS indicates the "decompiled" canonical rep. after the rule set has been
# 		successfully parsed and compiled into internal form.
#
# 		Semantically, this canonical form is identical to the value assigned to dragnet.log_error_filter_rules,
# 		but there may be some differences between the assigned and canonical values, as illustrated:
#
# 			<> goes to !=
#
# 			Numeric prio of 0 is changed to SEVERITY level ERROR
#
# 			Optional spaces are gone
#
# end_markers_in_json
#
# 		Sys var: 		end_markers_in_json
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	Yes
# 		Type: 			Boolean
# 		Default: 		OFF
#
# 		Whether optimizer JSON output should add end markers.
#
# eq_range_index_dive_limit
#
# 		Sys var: 		eq_range_index_dive_limit
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	Yes
# 		Type: 			Integer
# 		Default: 		200
# 		Min: 				0
# 		Max: 				<a lot>
#
# 		This variable indicates the number of equality ranges in an equality comparison condition when the optimizer
# 		should switch from using index drives to index statistics in estimating the number of qualifying rows.
#
# 		It applies to evaluation of expressions that have either of these equivalent forms, where the optimizer uses
# 		a nonunique index to look up <col_name> values:
#
# 			col_name IN(val1, ..., valN)
# 			col_name = val1 OR ... OR col_name = valN
#
# 		In both cases, the expression contains N equality ranges.
#
# 		The optimizer can make row estimates using index dives or index statistics.
#
# 		If eq_range_index_dive_limit is greater than 0, the optimizer uses existing index
# 		statistics instead of index dives if there are eq_range_index_dive_limit or more equality ranges.
#
# 		Thus, to permit use of index dives for up to <N> equality ranges, set eq_range_index_dive_limit to N + 1.
# 		To disable use of index statistics and always use index dives regardless of <N>, set this to 0.
#
# 		To update the table index stats for best estimates, use ANALYZE_TABLE.
#
# error_count
#
# 		Number of errors that resulted from the last statement that generated messages. is Read only.
#
# event_scheduler
#
# 		cmd line format: 		--event-scheduler[=value]
# 		Sys Var: 				event_scheduler
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default (>= 8.0.3) 	ON
# 		Default (<= 8.0.2) 	OFF
# 		Valid: 					ON, OFF, DISABLED
#
# 		This variable indicates the status of the Event Scheduler.
#
# explicit_defaults_for_timestamp
#
# 		cmd line format: 		--explicit-defaults-for-timestamp=#
# 		Deprecated: 			Yes
# 		Sys Var: 				explicit_defaults_for_timestamp
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default (>= 8.0.2) 	ON
# 		Default (<= 8.0.1) 	OFF
#
# 		This sys var determines whether the server enables certain nonstandard behaviors for default values and NULL value
# 		handling in TIMESTAMP columns.
#
# 		By default, explicit_defaults_for_timestamp is enabled, which disables the nonstandard behaviors.
# 		Disabling explicit_defaults_for_timestamp results in a warning.
#
# 		Setting this in scope of session is a restricted operation. Requires privs to allow for setting.
#
# 		If explicit_defaults_for_timestamp is disabled - the server enables the nonstandard behaviors and handles TIMESTAMP cols as follows:
#
# 			TIMESTAMP columns not explicitly declared with the NULL attribute are automatically declared with the NOT NULL attribute.
# 			Assigning such a column value of NULL is permitted and sets the column to the current timestamp.
#
# 			The first TIMESTAMP column in a table, if not explicitly declared with the NULL attribute or an explicit DEFAULT 
# 			or ON UPDATE attribute, is automatically declared with the DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP attributes.
#
# 			TIMESTAMP columns following the first one, if not explicitly declared with the NULL attribute or an explicit DEFAULT,
# 			are automatically declared as DEFAULT '0000-00-00 00:00:00'. For inserted rows that specify no explicit value for such
# 			a column, it defaults to the above with no warnings.
#
# 			Strict SQL mode or the NO ZERO DATE SQL mode being on - can cause invalidation of defaulting to 0000-00-00 00:00:00 may be invalid.
# 			Be aware that the TRADITIONAL SQL mode includes strict mode and NO ZERO DATE.
#
# 		The above is deprecated and will be removed.
#
# 		If explicit_defaults_for_timestamp is on, the server disables the above and handles instead with:
#
# 			It is not possible to assign a TIMESTAMP column a value of NULL to set it to the current timestamp.
# 			To do such, you must use NOW() or CURRENT_TIMESTAMP.
#
# 			TIMESTAMP columns not explicitly declared with the NOT NULL attribute are automatically declared with the
# 			NULL attribute and permit NULL values. (i.e - Assigning it NULL, causes it to be NULL)
#
# 			TIMESTAMP columns declared with the NOT NULL attribute do not permit NULL values.
# 			For inserts that specify NULL for such a column, the result is an error, regardless of mode.
#
# 			TIMESTAMP cols explicitly declared with the NOT NULL attribute and without an explicit DEFAULT attribute
# 			are treated as having no default value. (if Strict is not on, the implicit default is '0000-00-00 00:00:00' and a Warning.
#
# 			No TIMESTAMP cols are automatically declared with the DEFAULT CURRENT_TIMESTAMP or ON UPDATE CURRENT_TIMESTAMP attribs.
# 			(Must be explicitly declared)
#
# 			The first TIMESTAMP col in a table is not handled differently from TIMESTAMP cols following the first one.
#
# 		If explicit_defaults_for_timestamp is disabled at start, this warning crops up:
#
# 			[Warning] TIMESTAMP with implicit DEFAULT value is deprecated.
# 			Please use --explicit_defaults_for_timestamp server option
#
# 		NOTE: --explicit_defaults_for_timestamp is deprecated as well. Will be removed.
#
# external_user
#
# 		Sys var: 		external_user
# 		Scope: 			Session
# 		Dynamic: 		No
# 		SET_VAR Hint: 	No
# 		Type: 			String
#
# 		External user name used during the authentication process, as set by the plugin used to authenticate the client.
# 		With native MySQL auth or if the plugin does not set the value - this is NULL. (Relates to Poxy users)
#
# flush
#
# 		cmd line format: 	--flush
# 		Sys Var: 			flush
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Boolean
# 		Default: 			OFF
#
# 		If ON, the server flushes (synchs) all changes to disk after each SQL statement.
# 		Normally, MySQL does a write of all changes to disk only after each SQL statement
# 		and lets the OS handle the Sync to disk.
#
# 		Starts with ON if we start mysqld with --flush.
#
# 		NOTE: if enabled, flush_time does nothing, and changing it does nothing.
#
# flush_time
#
# 		cmd line format: 	--flush-time=#
# 		Sys var: 			flush_time
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Integer
# 		Default: 			0
# 		Min: 					0
#
# 		If set to a nonzero value, all tables are closed every flush_time seconds to free up resources and synch unflushed data to disk.
# 		Only use for systems with small amounts of resources.
#
# foreign_key_checks
#
# 		Sys Var: 			foreign_key_checks
# 		Scope: 				Global, Session
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		Yes
# 		Type: 				Boolean
# 		Default: 			ON
#
# 		If set to 1 (the default), foreign key constraints for InnoDB tables are checked.
# 		If set to 0, foreign key constraints are ignored, with a couple of exceptions.
#
# 		When re-creating a table that was dropped, an error is returned if the table definition
# 		does not conform to the foreign key constraints referencing the table.
#
# 		Likewise, an ALTER_TABLE operation returns an error if a foreign key definition is incorrectly formed.
#
# 		Typically, you leave this enabled during normal ops. Disabling can be used for reloading InnoDB tables
# 		in a order different from that required by their parent/child relationships.
#
# 		Setting foreign_key_checks to 0 also affects data definition statements: 
#
# 		DROP_SCHEMA drops a schema even if it contains tables that have foreign keys 
# 		that are referred to by tables outside the schema, and DROP_TABLE drops tables 
# 		that have foreign keys that are reffered by other tables.
#
# 		NOTE: Setting this to 1, does not trigger a scan of the existing table data. Therefore,
# 				rows added to the table while foreign_key_checks = 0 will not be verified for consistency.
#
# 				Dropping an index required by a foreign key constraint is not permitted, even with foreign_key_checks=0
# 				The foreign key constraint must be removed before dropping the index.
#
# ft_boolean_syntax
#
# 		cmd line format: 	--ft-boolean-syntax=name
# 		Sys Var: 			ft_boolean_syntax
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				String
# 		Default: 			+ -><()~*:""&|
#
# 		The list of operators supported by boolean full-text searches performed using IN BOOLEAN MODE.
#
# 		The rules for changing the default of this is:
#
# 			Operator function is defined by pos in string
#
# 			Replacement must be 14 chars
#
# 			Each char must be an ASCII nonalphanumeric char
#
# 			Either the first or second char must be a space.
#
# 			No duplicates are permitted except the phrase quoting operators in pos 11 and 12.
# 			These two chars are not required to be the same, but they are the only two that may be.
#
# 			Pos 10, 13 and 14 (defaults to :, &, |) are reserved for future extensions.
#
# ft_max_word_len
#
# 		cmd line format: 		--ft-max-word-len=#
# 		Sys Var: 				ft_max_word_len
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Min: 						10
#
# 		Max length of word in a MyISAM FULLTEXT index.
#
# 		NOTE: FULLTEXT indexes on MyISAM tables must be rebuilt after changing this var. Use REPAIR TABLE <tbl_name> QUICK.
#
# ft_min_word_len
#
# 		cmd line format: 		--ft-min-word-len=#
# 		Sys Var: 				ft_min_word_len
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				4
# 		Min: 						1
#
# 		The min length of the word to be included in a MyISAM FULLTEXT index.
#
# 		NOTE: FULLTEXT indexes on MyISAM tables must be rebuilt after changing this var. Use REPAIR TABLE <tbl_name> QUICK.
#
# ft_query_expansion_limit
#
# 		Cmd line format: 		--ft-query-expansion-limit=#
# 		Sys Var: 				ft_query_expansion_limit
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				20
# 		Min: 						0
# 		Max: 						1000
#
# 		number of top matches to use for full-text searches performed using WITH QUERY EXPANSION.
#
# ft_stopword_file
#
# 		cmd line format: 		--ft-stopword-file=file_name
# 		Sys Var: 				ft_stopword_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					File name
#
# 		The file from which to read the list of stopwords for full-text searches on MyISAM tables.
# 		The server looks for the file in the data directory unless an absolute path name is given to specify a different dir.
#
# 		All the words from the file are used;, comments are not.
#
# 		By default, a list of stopwords is used (defined in storage/myisam/ft_static.c file)
#
# 		Setting this to '' disables stopword filtering.
#
# 		FULLTEXT indexes on MyISAM tables must be rebuilt after changing this var or the contents of the stopword file.
# 		Use REPAIR TABLE <tbl_name> QUICK.
#
# general_log
#
# 		cmd line format: 		--general-log
# 		Sys Var: 				genral_log
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Whether the general query log is enabled. Can be 0/OFF to disable the log or 1/ON to enable.
#
# 		Default depends on whether the --general_log option is given.
#
# 		The destination for log output is controlled by the log_output SYS_VAR; if that value is NONE, no log entries
# 		are written even if the log is enabled.
#
# general_log_file
#
# 		cmd line format: 		--general-log-file=file_name
# 		Sys Var: 				general_log_file
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					File name
# 		Default: 				host_name.log
#
# 		Name of the general query log file. Defaults to <host_name.log> but the initial value can be changed with --general_log_file option.
#
# group_concat_max_len
#
# 		Cmd line format: 		--group-concat-max-len=#
# 		Sys Var: 				group_concat_max_len
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Int
# 		Default: 				1024
# 		Min: 						4
# 		Max (64-bit) 			<a lot>
# 		Min (32-bit) 			<less>
#
# 		Max permitted result length in bytes for the GROUP_CONCAT() function. Defaults to 1024.
#
# have_compress
#
# 		Yes if the zlib compression lib is available to the server, NO if not.
# 		If not, the COMPRESS() and UNCOMPRESS() functions cannot be used.
#
# have_crypt
# 		
# 		REMOVED
#
# have_dynamic_loading
#
#		Yes if mysqld supports dynamic loading of plugins, NO if not.
# 		If NO, cannot use options such as --plugin-load to load plugins at server startup, or the
# 		INSTALL_PLUGIN statement to load plugins at runtime.
#
# have_geometry
#
# 		YES if the server supports spatial data types, NO if not.
#
# have_openssl
#
# 		This variable is an alias for have_ssl
#
# have_profiling
#
# 		YES if statement profiling capability is present, NO if not.
# 		If present, the profiling system variable controls whether this capability is enabled or disabled.
#
# 		DEPRECATED.
#
# have_query_cache
#
# 		Query cache was removed in 8.0.3, have_query_cache is deprecated, always NO.
#
# have_rtree_keys
#
# 		YES if RTREE indexes are available, NO if not. (Used for Spatial indexes in MyISAM tables)
#
# have_ssl
#
# 		Yes if mysqld supports SSL connections, NO if not. DISABLED if server was compiled with SSL, but not activated with the respective --ssl-xxx option
#
# have_statement_timeout
#
# 		Sys_Var: 		have_statement_timeout
# 		Scope: 			Global
# 		Dynamic: 		No
# 		SET_VAR Hint: 	No
# 		Type: 			Boolean
#
# 		Whether the statement execution timeout feature is available. 
# 		Can be NO if the background thread used by this feature, could not be initialized.
# 		
# have_symlink
#
# 		YES if symbolic link support is enabled, NO if not.
# 		Required on UNIX for support of the DATA DIRECTORY and INDEX DIRECTORY table options.
#
# 		If the server is started with --skip-symbolic-links - this value is Disabled.
#
# 		Means nothing on Windows.
#
# 		NOTE: Symbolic links are deprecated in support and stature.
#
# histogram_generation_max_mem_size
#
# 		cmd line format: 		--histogram-generation-max-mem-size=#
# 		Introduced: 			8.0.2
# 		Sys Var: 				histogram_generation_max_mem_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		DEFAULT: 				20000000
# 		min value: 				1000000
# 		max (64-bit) 			<a lot>
# 		max (32-bit) 			<less>
#
# 		Max amount of memory for generating histogram stats.
#
# 		Setting this is a restricted ops, reqs privs.
#
# host_cache_size
#
# 		Sys Var: 				host_cache_size
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				-1 (Autosizing, do not assign)
#		Min: 						0
# 		Max: 						65536
#
# 		Size of the internal host cache. Setting it to 0 disables the host cache.
#
# 		Changing the cache size at runtime implicitly causes a FLUSH HOSTS ops to clear the host cache
# 		and truncate the host_cache table.
#
# 		Defaults to 128 + 1 for a value of max_connections up to 500, plus 1 for every 20 above 500, up to 2k.
#
# 		Using --skip-host-cache is similar to setting the host_cache_size SYS_VAR to 0, but host_cache_size can be set during
# 		runtime - not just startup.
#
# 		If started with --skip-host-cache, modification attempts are simply ignored.
#
# hostname
#
# 		Sys var: 				hostname
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
#
# 		The server sets this var to the server host name at startup.
#
# identity
#
# 		Synonym for the last_insert_id var. Exists for compability with other DB systems.
# 		can be read with SELECT @@identity, and set it using SET identity.
#
# init_connect
#
# 		cmd line format: 		--init-connect=name
# 		Sys Var: 				init_connect
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
#
# 		A string to be executed by the server for each client that connects. 
# 		The string consists of one or more SQL statements, separated by ; chars.
#
# 		For example, each client session begins by default with autocommit mode enabled.
# 		For older servers (< 5.5.8) - there is no global autocommit SYS_VAR to specify that autocommit
# 		should be off by default - but can be circumvented with:
#
# 		SET GLOBAL init_connect='SET autocommit=0';
#
# 		Can also beb set on cmd or in a option file:
#
# 		[mysqld]
# 		init_connect='SET autocommit=0'
#
# 		For users with SUPER priv or CONNECTION_ADMIN - the content of init_connect is not executed.
#
# 		(MySQL 8.0.5 >=) 	init_connect is skipped for any client with an expired PW.
#
# 		Allows for connection and changing of PW.
#
# information_schema_stats_expiry
#
# 		cmd line format: 		--information-schema-stats-expiry=value
# 		Introduced: 			8.0.3
# 		Sys Var: 				information_schema_stats_expiry
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				86400
# 		min: 						0
# 		Max: 						<a lot>
#
# 		Some of the information_schema tables that contain columns that provide table stats:
#
# 		STATISTICS.CARDINALITY
# 		TABLES.AUTO_INCREMENT
# 		TABLES.AVG_ROW_LENGTH
# 		TABLES.CHECKSUM
# 		TABLES.CHECK_TIME
# 		TABLES.CREATE_TIME
# 		TABLES.DATA_FREE
# 		TABLES.DATA_LENGTH
# 		TABLES.INDEX_LENGTH
# 		TABLES.MAX_DATA_LENGTH
# 		TABLES.TABLE_ROWS
# 		TABLES.UPDATE_TIME
#
#		Said columns represent the dynamic table metadata - information that changes as table contents change.
#
# 		By default, MySQL retrieves cached values for those columns from the mysql.index_stats and mysql.table_stats dictionary tables
# 		when the columns are queried, which is more efficient than retrieving stats directly from the storage engine.
#
# 		If cached stats are not available or have expired, MySQL retrieves the latest stats from the storage engine
# 		and caches them in the mysql.index_stats and mysql.table_stats dictionary tables.
#
# 		Subsequent queries retrieve the cachhed stats until the cached stats expire.
#
# 		The information_schema_stats_expiry session var defines the period of time before cached stats expire.
# 		The default is 24 hours (86400 secs), but the time period can be extended to as much as one year.
#
# 		To update cached values at any time for a given table, use ANALYZE TABLE.
#
# 		To always retrieve the latest directly from the storage engine and bybpass cached values, set information_schema_stats_expiry to 0.
#
# 		Querying stats columns does not store or update stats in the mysql.index_stats and mysql.table_stats dictionary tables under said circumstnaces:
#
# 			When cached stats have not expired
#
# 			When information_schema_stats_expiry is set to 0
#
# 			When the server is started in read_only, super_read_only, transaction_read_only or innodb_read_only
#
# 			When the query also fetches Performance Schema Data
#
# 		information_schema_stats_expiry is a session var, and each client session can define its own expiration value.
# 		Stats that are retrieved from the storage engine and cached by one session are available to other sessions.
#
# init_file
#
# 		Cmd line format: 		--init-file=file_name
# 		Sys Var: 				init_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					File name
#
# 		The name of the file specified with the --init-file option when you start the server.
#
# 		This should be a file containing SQL statements that you want the server to execute when it starts.
#
# 		Each statement must be on a single line and no comments. 
#
# innodb_xxx
#
# 		InnoDB sys vars are listed later.
#
# 		Said Vars control many aspects of storage, memory use and I/O patterns for InnoDB tables, and are called for in relation to InnoDB default storage engines.
#
# insert_id
# 
# 		The value to be used by the following INSERT or ALTER_TABLE statement when inserting an AUTO_INCREMENT value.
# 		Mainly used with the binary log.
#
# interactive_timeout
#
# 		cmd line format: 		--interactive-timeout=#
# 		Sys Var: 				interactive_timeout
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				28800
# 		Min: 						1
#
# 		The number of seconds the server waits for acitvity on an interactive connection before closing it.
# 		An interactive client is defined as a client that uses the CLIENT_INTERACTIVE option to mysql_real_connect()
#
# internal_tmp_disk_storage_engine
#
# 		cmd line format: 		--internal-tmp-disk-storage-engine=#
# 		Sys Var: 				internal_tmp_disk_storage_engine
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				INNODB
# 		Valid: 					MYISAM
# 									INNODB
#
# 		The storage engine for on-disk internal temp tables. Permitted values are MYISAM and INNODB (Default)
#
# 		The optimizer uses the storage engine defined by internal_tmp_disk_storage_engine for on-disk internal temporary tables.
#
# 		When using internal_tmp_disk_storage_engine=INNODB (the default), queries that generate on-disk internal temp tables that exceed
# 		InnoDB row or column limits will return Row size too large or Too many columns errors.
#
# 		The workaround is to set internal_tmp_disk_storage_engine to MYISAM.
#
# internal_tmp_mem_storage_engine
#
# 		cmd line format: 		--internal-tmp-mem-storage-engine=#
# 		introduced: 			8.0.2
# 		SYS Var: 				internal_tmp_mem_storage_engine
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Enumeration
# 		Default: 				TempTable
# 		Valid: 					TempTable, MEMORY
#
# 		The storage engine for in-memory internal temporary tables.
#
# 		The optimizer uses the storage engine defined by internal_tmp_mem_storage_engine for in-memory internal temp tables.
#
# join_buffer_size
#
# 		cmd line format: 		--join-buffer-size=#
# 		Sys Var: 				join_buffer_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				262144
# 		Min value: 				128
# 		Max (Other, 64-bit) 	<most>
# 		Max (Other, 32-bit) 	<less>
# 		Max (Windows) 			<less>
#
# 		The min size of the buffer that is used for plain index scans, range index scans, and joins that do not 
# 		use indexes and thus perform full table scans.
#
# 		Normally - the best way to get fast joins is to add indexes. Increase the value of join_buffer_size to get a faster
# 		full join when adding indexes is not possible.
#
# 		One join buffer is allocated for each full join between two tables. For a complex join between several tables for which 
# 		indexes are not used, multiple join buffers might be nessecary.
#
# 		Unless Batched Key Access (BKA) is used, there is no gain from setting the buffer larger than required to hold each
# 		matching row - and all joins allocate at least the min size, thus, careful with global min designation.
#
# 		It is better to have the global be small, and allow for session values that are larger - when thye perform large joins.
# 		Memory allocation time can cause large performance drops if the global size is larger than needed by most queries that use it.
#
# 		When BKA is used, the value of join_buffer_size defines how large the batch of keys is in each request to the storage engine.
# 		The larger the buffer, the more sequential access will be to the right hand table of a join operation, which can significantly 
# 		improve performance.
#
# 		Defaults to 256kb, max is 4gb-1. Larger is allowed for 64-bit (Windows throws a warning and sets to max)
#
# keep_files_on_create
#
# 		cmd line format: 		--keep-files-on-create=#
# 		Sys Var: 				keep_files_on_create
# 		Scope: 					Global ,Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		if a MyISAM table is created with no DATA DIR option, the .MYD file is created in the DB directory.
# 		By default, if MyISAM finds an existing .MYD file in this case, it overwrites it.
#
# 		The same applies to .MYI files for tables created with no INDEX DIRECTORY option.
# 		To suppress this behavior, set the keep_files_on_create var to ON(1), which causes MyISAM to not overwrite
# 		existing files and returns an error instead. 
#
# 		If a MyISAM table is created with a DATA DIRECTORY or INDEX DIRECTORY option and an existing .MYD or .MYI file is found,
# 		MyISAM always returns an error. It will not overwrite a file in the specified dir.
#
#
# key_buffer_size
#
# 		cmd line format: 		--key-buffer-size=#
# 		Sys Var: 				key_buffer_size
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				8388608
# 		Min value: 				8
# 		Max value(64-bit) 	OS_PER_PROCESS_LIMIT
# 		Max (32-bit) 			4294967295
#
# 		Index blocks for MyISAM tables are buffered and are shared by all threads. key_buffer_size is the size of the buffer used
# 		for index blocks. The key buffer is also known as the key cache.
#
# 		The max permissible setting for key_buffer_size is 4gb-1 on 32-bit platforms.
#
# 		Larger are allowed on 64-bit - Realistic size might be less. 
#
# 		The above is akin to a "hint" of request of setting to - value can be overwritten by underlying OS or Hardware etc.
#
# 		You can increase the value to get better index handling for all reads and multiple writes; on a System whose primary
# 		function is to run MySQL using the MyISAM storage engine, 25% of the total machine memory is fine.
#
# 		If assigned too large of a value, the underlying OS which handles file system caching for data reads will start to lag
#
# 		For even more speed when writing many rows at the same time, use LOCK_TABLES.
#
# 		You can check the performance of the key buffer by issuing a SHOW_STATUS statement and examining the Key_read_requests,
# 		Key_reads, Key_write_requests and Key_writes status.
#
# 		The Key_reads/Key_read_requests ratio should normally be less than 0.01.
#
# 		The Key_writes/Key_write_requests ratio is usually near 1 if you use mostly updates and deletes,
# 		but can be smaller in case of updating many rows at the same time or using the DELAY_KEY_WRITE table option.
#
# 		The fraction of the key buffer in use can be determined using key_buffer_size in conjunction with the Key_blocks_unused
# 		status variable and buffer block size, which is available from the key_cache_block_size Sys_var:
#
# 		- ((Key_blocks_unused * key_cache_block_size) / key_buffer_size)
#
# 		This value is an approximation because some space in the key buffer is allocated internally for admin structs.
# 		Factors that influence the amount of overhead for these structures include block size and pointer size.
#
# 		As block size increases, the percentage of the key buffer lost to overhead tends to decrease.
#
# 		larger blocks result in a smaller number of read ops (because more keys are obtained per read),
# 		but an increase in reads of keys that are not examined (if not all keys in a block are relevant to a query)
#
# 		It is possible to create Multiple MyISAM key caches. The size limit of 4gb applies to each cache individually, not as a group.
#
# key_cache_age_threshold
#
# 		Cmd line format: 		--key-cache-age-threshold=#
# 		Sys var: 				key_cache_age_threshold
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				300
# 		Min: 						100
# 		Max value (64-bit): 	<a lot>
# 		Max value (32-bit): 	<less>
#
# 		Controls the demotion of buffers from hot sublist of a key cache to the warm sublist.
# 		Lower values causes demotion to happen more quickly.
#
# 		Min 100. default 300.
#
# key_cache_block_size
#
# 		cmd line format: 		--key-cache-block-size=#
# 		Sys var: 				key_cache_block_size
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1024
# 		Min: 						512
# 		Max: 						16384
#
# 		Size in bytes of blocks in the key cache. Defaults to 1024.
#
# key_cache_division_limit
#
# 		cmd line format: 		--key-cache-division-limit=#
# 		Sys var: 				key_cache_division_limit
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				100
# 		Min: 						1
# 		mx: 						100
#
# 		The division point between the hot and warm sublist of the key cache buffer list.
# 		The value is the % of the buffer list to use for the warm sublist.
#
# large_files_support
#
# 		Sys var: 				large_files_support
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
#
# 		Whether mysqld was compiled with options for large file support.
#
# large_pages
#
# 		cmd line format: 		--large-pages
# 		Sys var: 				large_pages
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Platform: 				Linux
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Whether large page support is enabled (via the --large-pages option)
#
# large_page_size
#
# 		Sys var: 				large_page_size
# 		scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
#
# 		If large page support is enabled, this shows the size of memory pages.
# 		Large memory pages are supported only on Linux, on other OS's - this is always 0.
#
# last_insert_id
#
# 		The values to be returned from LAST_INSERT_ID(). This is stored in the binary log when you use
# 		LAST_INSERT_ID() in a statement that updates a table.
#
# 		Setting this var does not update the value returned by the mysql_insert_id() C API Function
#
# lc_messages
#
# 		cmd line format: 		--lc-messages=name
# 		Sys Var: 				lc_messages
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				en_US
#
# 		The locale to use for error messages. The default is en_US. THe server converts the argument
# 		to a language name and combines it with the value of lc_messages_dir to produce the location
# 		for the error message file.
#
# lc_messages_dir
#
# 		cmd line format: 		--lc-messages-dir=dir_name
# 		Sys var: 				lc_messages_dir
# 		Scope: 					global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name:
#
# 		The dir where error messages are located. The server uses the value together with the values of lc_messages
# 		to produce the location for the error message file.
#
# lc_time_names
#
# 		Sys var: 				lc_time_names
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
#
# 		This var specifies the locale that contorls the language used to display day and month names and abbreviations.
# 		This var affects the output from the DATE_FORMAT(), DAYNAME() and MONTHNAME() functions.
#
# 		Locale names are POSIX-style values such as 'ja_JP' or 'pt_BR'. Default is 'en_US' regardless of your system locale setting.
#
# license
#
# 		Sys var: 				license
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				GPL
#
# 		Type of license the server has
#
# local_infile
#
# 		Sys var: 				local_infile
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			no
# 		Type: 					Boolean
# 		Default (>= 8.0.2) 	OFF
# 		Default (<= 8.0.1) 	oN
#
# 		This variable controls server-side LOCAL capability for LOAD_DATA statements. 
#
# 		Depending on the local_infile setting, the server refuses or permits local data loading 
# 		by clients that have LOCAL enables on the client side.
#
#		To explicitly cause the server to refuse or permit LOAD_DATA_LOCAL statements (regardless of how client programs and libs are configed at build time
# 		or runtime) - start mysqld with local_infile disabled or enabled, respectively.
#
# 		local_infile can also be set at runtime.
#
# lock_wait_timeout
#
# 		Cmd line format: 		--lock-wait-timeout=#
# 		Sys var: 				lock_wait_timeout
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				31536000
# 		Min: 						1
# 		Max: 						31536000
#
# 		Specifies the timeout in seconds for attempts to aquire metadata locks. The permissible value ranges from
# 		1 to 1 year. Default is 1 year.
#
# 		This timeout applies to all statements that use metadata locks. These include DML and DDL operations on tables, views, stored
# 		procedures and stored functions, as well as LOCK_TABLES, FLUSH_TABLES_WITH_READ_LOCK and HANDLER statements.
#
# 		This timeout does not apply to implicit accesses to System tables in the mysql DB, such as grant tables modified by GRANT or REVOKE
# 		statements or table logging statements.
#
# 		This timeout does apply to Sys tables accessed directly, such as with SELECT or UPDATE.
#
# 		The timeout value applies separately for each metadata lock attempt. A given statement can require more than one lock, so it is possible
# 		for the statement to block for longer than the lock_wait_timeout value before reporting a timeout error. When lock timeout occurs, ER_LOCK_WAIT_TIMEOUT
# 		is reported.
#
# 		lock_wait_timeout also defines the amount of time that a LOCK_INSTANCE_FOR_BACKUP statement waits for a lock before giving up.
#
# locked_in_memory
#
# 		sys var: 				locked_in_memory
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 
# 		Whether mysqld was locked in memory with --memlock.
#
# log_error
#
# 		cmd line format: 		--log-error[=file_name]
# 		Sys var: 				log_error
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					File name
#
# 		The default error log destination. If the destination is the console, the value is stderr.
# 		Otherwise, the destination is a file and the log error value is the file name.
#
# log_error_filter_rules
#
# 		cmd line format: 		--log-error-filter-rules
# 		Introduced: 			8.0.2
# 		Removed: 				8.0.4
# 		SYS VAR: 				log_error_filter_rules
# 		Scope: 					Global
#  	Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default value: 		set by server
#
# 		The filter rules for error logging. This variable is unused. Removed.
#
# log_error_services
#
# 		cmd line format: 		--log-error-services
# 		Introduced: 			8.0.2
# 		Sys var: 				log_error_services
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				log_filter_internal; log_sink_internal
#
# 		The components to enable for error logging. This variable may contain a list with 0,1 or many elements.
#
# 		In the latter case, elements may be delimited by ; or (MySQL >= 8.0.12) , + SPACE.
#
# 		A given setting cannot use both ; and , +SPACE separators.
#
# 		Components order is significant because the server executes components in the order listed.
# 		Any loadable (not built in) component named in the log_error_services value must first be installed
# 		with INSTALL_COMPONENT.
#
# log_error_suppression_list
#
# 		Cmd line format: 		--log-error-suppression-list=value
# 		Introduced: 			8.0.13
# 		Sys var: 				log_error_suppression_list
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				''
#
# 		This enables specifying which diagnostics should not be written to the error log when they occur
# 		with a severity of WARNING or INFORMATION.
#
# 		For example, if a particular type of warning occurs frequently but is not of interest (and thus may be
# 		considered undesirable "noise" in the error log) you can suppress that.
#
# 		The variable value may be empty string for no suppression, or a list of one or more comma separated values indicating
# 		the error codes to suppress.
#
# 		The numeric value of each code to be suppressed must be in a permitted range:
#
# 			1 up to (but less than) 1000: Global error codes that are shared by the server and clients
#
# 			10000 and higher: Server error codes intended to be written ot the error log (not sent to clients)
#
# 		Attempts to assign an error code not in a permitted range produces an error and the var value remains unchanged.
#
# 		Error codes may be specified in a numeric or symbolic form. A numeric code may be specified with or without the MY- prefix.
#
# 		Leading 0's in the numeric part are not significant. Examples of permitted code format:
#
# 			31
# 			00031
# 			MY-31
# 			MY-00031
# 			ER_SERVER_SHUTDOWN_COMPLETE
#
# 		List of error codes comes later.
#
# 		The server can generate messages for a given error code at different severities, so suppression for a message
# 		associated with an error code listed in log_error_suppression_list depends on its severity.
#
# 		Suppose that hte variable has a value of '10000, 10001, MY-10002'
#
# 		Messages for those codes are not written to the error log if generated with a SEVERITY of WARNING or INFORMATION.
#
# 		Messages generated with a severity of ERROR or SYSTEM are not suppressed and are written to the error log.
#
# 		The effect of log_error_suppression_list combines with that of log_error_verbosity.
#
# 		Consider a server started with these settings:
#
# 		[mysqld]
# 		log_error_verbosity=2 			# error and warning messages only
# 		log_error_suppression_list='10000,10001,MY-10002'
#
# 		In this case, log_error_verbosity discards all messages with INFORMATION severity.
#
# 		Of the remaining messages, log_error_suppression_list discards messages with WARNING severityy
# 		and any of the named error codes.
#
#
# 		NOTE: log_error_verbosity defaults to 2, so its effect on suppression of all INFORMATION messages is by
# 		default as above. You must set it to 3, if you want log_error_suppression_list to affect messages with INFORMATION severity.
#
# 		Example:
#
# 		[mysqld]
#		log_error_verbosity=1 #Error messages only
#
# 		Discards all messages with WARNING and INFORMATION severity.
#
# 		Setting log_error_suppression_list has no effect because all error codes it might suppress
# 		are already discarded due to the log_error_verbosity setting. 	
#
# 		log_error_suppression_list (like log_error_verbosity) affects the log_filter_internal error log filter,
# 		which is on by default.
#
# 		If that filter is turned off, error code suppression does not occur and must be modeled using whatever
# 		filter service is used instead where desired (for example, with individual filter rules when using
# 		log_filter_dragnet).
#
# log_error_verbosity
#
# 		cmd line format: 		--log-error-verbosity=#
# 		Sys var: 				log_error_verbosity
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default (>= 8.0.4) 	2
# 		Default (<= 8.0.3) 	3
# 		Min: 						1
# 		Max: 						#
# 
# 		The verbosity for handling events intended for the error log, as filtered by the log_filter_internal
# 		error log filter component, which is enabled by default.
#
# 		If log_filter_internal is disabled, log_error_verbosity has no effect
#
# 		The following is the verbosity levels:
#
# 		Error messages: 		1
# 		Error and Warnings: 	2
# 		Error, Warning,Info: 3
#
# 		Selected important sys messages about non-error situations are printed to the error log regardless
# 		of the log_error_verbosity value.
#
# 		These messages include startup and shutdown messages, and some significant changes to settings.
#
# 		The effect of log_error_verbosity combines with that of log_error_suppression_list.
#
# log_output
#
# 		Cmd line format: 		--log-output=name
# 		Sys var: 				log_output
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Set
# 		Default: 				File
# 		Valid: 					TABLE, FILE, NONE
#
# 		The destination for general query log and slow query log output.
# 		The value can be a comma-separated list of one or more of the words TABLE (log of tables),
# 		FILE (log to files), or NONE (do not log to tables or files).
#
# 		The default value is FILE. NONE, if present takes precedence over any other specifiers.
#
# 		If the value is NONE log entries are not written even if the logs are enabled.
# 		If the logs are not enabled, no logging occurs even if the value of log_output is not NONE.
#
# log_queries_not_using_indexes
#
# 		cmd line format: 	--log-queries-not-using-indexes
# 		Sys var: 			log_queries_not_using_indexes
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type:    			Boolean
# 		default: 			OFF
#
# 		Whether queries that do not use indexes are logged to the slow query log.
#
# log_slow_admin_statements
#
# 		Sys var: 			log_slow_admin_statements
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Boolean
# 		Default: 			OFF
#
# 		Include slow administrative statements in the statements written to the slow query log.
#
# 		Administrative statements include ALTER_TABLE, ANALYZE_TABLE, CHECK_TABLE, CREATE_INDEX,
# 		DROP_INDEX, OPTIMIZE_TABLE and REPAIR_TABLE
#
# log_syslog
#
# 		cmd line format: 		--log-syslog[={0|1}]
# 		Deprecated: 			8.0.2 (removed in 8.0.13)
# 		Sys var: 				log_syslog
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default (Windows, <= 8.0.1) 	ON
# 		Default (Unix, <= 8.0.1) 		OFF
# 		Default (>= 8.0.2) 				ON (when error logging to system log is enabled)
#
# 		Prior to (8.0) this var controlled whether to perform error logging to the system log (the Event log on Windows, Syslog on Unix/UNIX based systems)
#
# 		In MySQL 8.0, the log_sink_syseventlog log component implements error logging to the system log.
# 		Thus this type of logging can be enabled by adding that component to the log_error_services SYS var.
#
# 		log_syslog is removed. (just deprecated before 8.0.13)
#
# log_syslog_facility
#
# 		cmd line format: 		--log-syslog-facility=value
# 		Removed: 				8.0.13
# 		Sys var: 				log_syslog_facility
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				daemon
#
# 		This var was removed in 8.0.13 and replaced by syseventlog.facility
#
# log_syslog_include_pid
#
# 		cmd line format: 		--log-syslog-include-pid[={0|1}]
# 		removed: 				8.0.13
# 		Sys var: 				log_syslog_include_pid
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		This was removed in 8.0.13 and replaced by syseventlog.include_pid
#
# log_syslog_tag
#
# 		cmd line format: 		--log-syslog-tag=tag
# 		Removed: 				8.0.13
# 		Sys var: 				log_syslog_tag
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				empty string
#
# 		Removed in 8.0.13 and replaced by syseventlog.tag
#
# log_timestamps
#
# 		cmd line format: 		--log-timestamps=#
# 		Sys var: 				log_timestamps
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				UTC
# 		Valid: 					UTC, SYSTEM
#
# 		Controls the time zone of timestamps in messages written to the error log and in general query log and slow query
# 		log messages written to files.
#
# 		Does not affect the time zone of general query log and slow query log messages written to tables (mysql.general_log, mysql.slow_log).
#
# 		Rows retrieved from those tables can be converted from the local system time zone to any desired time zone with CONVERT_TZ() or by
# 		setting the session time_zone sys var.
#
# 		Permitted log_timestamps values are UTC (default) and SYSTEM (local system time zone)
#
# 		Timestamps are written using ISO 8601 / RFC 3339 format: YYYY-MM-DDThh:mm:ss.uuuuu plus a tail value of Z signifying
# 		Zulu time (UTC) or +hh:mm (offset from UTC)
#
# log_throttle_queries_not_using_indexes
#
# 		Sys var: 			log_throttle_queries_not_using_indexes
# 		Scope: 				Global
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Integer
# 		Default: 			0
#
# 		If log_queries_not_using_indexes is enabled, the log_throttle_queries_not_using_indexes variable
# 		limits the number of such queries per minute that can be written to the slow query log.
#
# 		A value of 0 (default) means "No limit".
#
# log_warnings
#
# 		cmd line format: 		--log-warnings[=#]
# 		Deprecated: 			Yes (removed in 8.0.3)
# 		Sys var: 				log_warnings
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				2
# 		Min: 						0
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		Removed in 8.0.3 - use the log_error_verbosity sys_var instead.
#
# long_query_time
#
# 		cmd line format: 		--long-query-time=#
# 		Sys var: 				long_query_time
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Numeric
# 		Default: 				10
# 		Min: 						0
#
# 		If a query takes longer than this many seconds, the server increments the Slow_queries status var.
# 		If the slow query log is enabled, the query is logged to the slow query log file.
#
# 		This value is measured in real time, not CPU time - so a query that is under Threshold on a lightly loaded
# 		system may be above Threshold on a heavy loaded one.
#
# 		The value of this var can be specified to a resolution of microseconds.
#
# 		For logging to tables, only integer times are written; the microseconds part is ignored.
#
# low_priority_updates
#
# 		cmd line format: 		--low-priority-updates
# 		Sys var: 				low_priority_updates
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		If set to 1, all INSERT, UPDATE, DELETE and LOCK TABLE WRITE statements wait until there is no pending
# 		SELECT or LOCK TABLE READ on the affected table.
#
# 		This affects only storage engines that use only table-level locking (such as MyISAM, MEMORY and MERGE)
#
# lower_case_file_system
#
# 		Sys var: 				lower_case_file_system
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
#
# 		This var describes the case sensitivity of file names on the file system where the data dir
# 		is located.
#
# 		OFF means file names are case-sensitive, ON means they are not case-sensitive.
#
# 		This var is read only because it reflects a file system attribute and setting it would have
# 		no effect on the file system.
#
# lower_case_table_names
#
# 		cmd line format: 		--lower-case-table-names[=#]
# 		Sys var: 				lower_case_table_names
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max: 						2
#
# 		If set to 0, table names are stored as specified and comparisons are case-sensitive.
#
# 		If set to 1, table names are stored in lowercase on disk and comparisons are not case sensitive.
#
# 		If set to 2, table names are stored as given but compared in lowercase.
#
# 		This option also applies to DB names and table aliases. 
#
# 		On Windows the default is 1. On macOS, default is 2. On Linux, 2 is not supported - enforced 0.
#
# 		You should NOT set lower_case_table_names to 0 if you are running MySQL on a system where the data dir
# 		resides on a case-insensitive file system (such as on Windows or macOS).
#
# 		Is an unsupported combination that could result in a hang condition when running an INSERT INTO ... SELECT ... FROM <tbl_name>
# 		operation with the wrong <tbl_name> letter case.
#
# 		With MyISAM - accessing table names using different letter cases could cause index corruption.
#
# 		An error message is printed and the server exits if you attempt to start the server with --lower_case_table_names=0 on
# 		a case-insensitive file system.
#
# 		If you are using InnoDB tables, you should set this variable to 1 on all platforms to force names to be converted
# 		to lowercase.
#
# 		The setting of this variable in MySQL 8.0 affects the behavior of replication filtering options with regard
# 		to case sensitivity. (Bug #51639)
#
# 		It is prohibited to start the server with a lower_case_table_names setting that is different from the setting used
# 		when the server was initialized.
#
# 		The restriction is necessary because collations used by various data dictionary table fields are based on the
#	 	setting defined when the server is initialized and restarting the server with a different setting would
# 		introduce inconsistencies with respect to how identifiers are ordered and compared.
#
# mandatory_roles
#
# 		cmd line format: 				--mandatory-roles=value
# 		introduced: 					8.0.2
# 		Sys var: 						mandatory_roles
# 		Scope: 							Global
# 		Dynamic: 						Yes
# 		SET_VAR Hint: 					No
# 		Type: 							String
# 		Default: 						empty string
#
# 		Roles the server should treat as mandatory. In effect, these roles are automatically
# 		granted to every user, although setting mandatory_roles does not actually change any
# 		user accounts, and the granted roles are not visible in the mysql.role_edges system table.
#
# 		The var value is a comma separated name:
#
# 		SET PERSIST mandatory_roles = '`role1`@`%`, `role2`,role3,role4@localhost';
#
# 		Setting mandatory_roles requires the ROLE_ADMIN priv, in addition to the SYSTEM_VARIABLES_ADMIN or SUPER
# 		priv normally required to set a global system var.
#
# 		Role names consist of a user part and host part in user_name@host_name format.
# 		The host part, if omitted, defaults to %
#
# 		User names and host names, if quoted, must be written in a fashion permitted for quoting within quoted strings.
#
# 		Roles named in the value of mandatory_roles cannot be revoked with REVOKE or dropped with DROP_ROLE or DROP_USER.
#
# 		Mandatory roles, like explicitly granted roles, do not take effect until activated.
#
# 		At login time, role activation occurs for all granted roles if the activate_all_roles_on_login sys_var is enabled,
# 		or only for roles that are set as default roles otherwise.
#
# 		At runtime, SET_ROLE activates roles.
#
# 		Roles that do not exist when assigned to mandatory_roles but are created later may require special treatment
# 		to be considered mandatory.
#
# 		SHOW_GRANTS displays mandatory roles according to the rules showcased later.
#
# max_allowed_packet
#
# 		cmd line format: 		--max-allowed-packet=#
# 		Sys var: 				max_allowed_packet
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default (>= 8.0.3) 	67108864
# 		Default (<= 8.0.2) 	4194304
# 		Min: 						1024
# 		Max: 						1073741824
#
# 		Max size of one packet or any generated/intermediate string or any parameter sent by the mysql_stmt_send_long_data() C API function.
# 		The default is 64MB.
#
# 		The packet message buffer is initialized to net_buffer_length bytes, but can grow up to max_allowed_packet bytes when needed.
# 		This value by default is small, to catch large (possibly incorrect) packets.
#
# 		You must increase this value if you are using large BLOB columns or long strings.
# 		It should be as big as the largest BLOB you want to use.
#
# 		The protocol limit for max_allowed_packet is 1GB. The value should be a multiple of 1024: nonmultiples are rounded down to the nearest
# 		multiple.
#
# 		When you change the message buffer size by changing the value of the max_allowed_packet variable, you should also change
# 		the buffer size on the client side if your client program permits it.
#
# 		The default max_allowed_packet value built in to the client library is 1GB, but individual client programs
# 		might override this.
#
# 		For example, mysql and mysqldump have defaults of 16MB and 24MB, respectively.
#
# 		They also enable you to change the client-side value by setting max_allowed_packet on the cmd line or in an option file.
#
# 		The session value of this var is read only. The client can receive up to as many bytes as the session value.
# 		However, the server will not send to the client more bytes than the current global max_allowed_packet value.
# 		(The global value could be less than the session value if the global value is changed after the client connects.)
#
# max_connect_errors
#
# 		cmd line format: 		--max-connect-errors=#
# 		Sys var: 				max_connect_errors
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				100
# 		Min: 						1
# 		Max (64-bit) 			<a lot>
# 		max (32-bit) 			<less>
#
# 		If more than this many successive connection requests from a host are interuppted without a successful
# 		connection, the server blocks that host from further connections.
#
# 		You can unblock blocked hosts by flushing the host cache. To do so, issue a FLUSH_HOSTS statement or execute
# 		a mysqladmin flush-hosts command.
#
# 		If a connection is established successfully within fewer than max_connect_errors attempts after a previous connection
# 		was interrupted, the error count for the host is cleared to 0.
#
# 		However, once a host is blocked, flushing the host cache is the only way to unblock it. Default is 100.
#
# max_connections
#
# 		Cmd line format: 		--max-connections=#
# 		Sys var: 				max_connections
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				151
# 		Min: 						1
# 		Max: 						100000
#
# 		max permitted number of simultaneous client conns.
#
# max_delayed_threads
#
# 		cmd line format: 		--max-delayed-threads=#
# 		deprecated: 			Yes
# 		Sys var: 				max_delayed_threads
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				20
# 		Min: 						0
# 		Max: 						16384
#
# 		This sys var is deprecated (because DELAYED inserts are not supported), will be removed.
#
# max_digest_length
#
# 		cmd line format: 		--max-digest-length=#
# 		Sys var: 				max_digest_length
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1024
# 		Min: 						0
# 		Max: 						1048576
#
# 		max number of bytes available for computing normalized statement digests.
#
# 		Once said amount of space is used during digest computation, truncation occurs:
# 		No further tokens from a parsed statement are collected or figure into its digest value.
#
# 		Statements that differ only after that many bytes of parsed tokens produce the same 
# 		normalized statement digest and are considered identical if compared or if aggregated for digest stats.
#
# 		Decreasing the max_digest_length value reduces memory use but causes the digest value of more statements
# 		to become indistinguishable if they differ only at the end.
#
# 		Increasing the value permits longer statements to be distinguished but increases memory use, particularly
# 		for workloads that involve large number of simultaneous sessions (the server allocates max_digest_length bytes per session)
#
# 		The parser uses this system var as a limit on the max length of normalized statement digests that it computes.
# 		The Performance Schema, if it tracks statement digests, makes a copy of the digest value, using the performance_schema_max_digest_length,
# 		sys var as a limit on the max length of digests that it stores.
#
# 		Consequently, if performance_schema_max_digest_length is less than max_digest_length digest values stored in the Performance
# 		Schema are truncated relative to the original digest values.
#
# max_error_count
#
# 		cmd line format: 		--max-error-count=#
# 		Sys var: 				max_error_count
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default (>= 8.0.3) 	1024
# 		Default (<= 8.0.2) 	64
# 		Min: 						0
# 		Max: 						65535
#
# 		Max number of error, warning and info messages to be stored for display by the SHOW_ERRORS and SHOW_WARNINGS statements.
# 		This is the same as the number of condition areas in the diagnostics area, and thus the number of conditions that can be
# 		inspected by GET_DIAGNOSTICS.
#
# max_execution_time
#
# 		cmd line format: 		--max-execution-time=#
# 		Sys var: 				max_execution_time
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				0
#
# 		The execution timeout for SELECT statements, in milliseconds.
# 		If the value is 0, timeouts are not enabled.
#
# 		max_execution_time applies as follows:
#
# 			The global max_execution_time value provides the default for the session value for new connections.
# 			The session value applies to SELECT executions executed within the session that include no MAX_EXECUTION_TIME(N)
# 			optimizer hint or for which N is 0.
#
# 			max_execution_time applies to read-only SELECT statements. Statements that are not read only are those that 
# 			invoke a stored function that modifies data as a side effect.
#
# 			max_execution_time is ignored for SELECT statements in stored programs.
#
# max_heap_table_size
#
# 		cmd line format: 		--max-heap-table-size=#
# 		Sys var: 				max_heap_table_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					16777216
# 		Min value: 				16384
# 		Max value (64-bit) 	<a lot>
# 		Max value (32-bit) 	<less>
#
# 		Sets the maximum size to which user-created MEMORY tables are permitted to grow.
# 		The value of the variable is used to calculate MEMORY table MAX_ROWS values.
#
# 		Setting this variable has no effect on any existing MEMORY table, unless the table is
# 		re-created with a statement such as CREATE_TABLE or altered with ALTER_TABLE or TRUNCATE_TABLE
#
# 		A server restart also sets the maximum size of existing MEMORY tables to the global max_heap_table_size 
#
# 		This var is also used in conjunction with tmp_table_size to limit the size of internal in-memory tables.
#
# 		max_heap_table_size is not replicated.
#
# max_insert_delayed_threads
#
# 		deprecated: 			Yes
# 		Sys var: 				max_insert_delayed_threads
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
#
# 		Synonym to max_delayed_threads
#
# 		Deprecated because DELAYED inserts are not supported.
#
# max_join_size
#
# 		cmd line format: 		--max-join-size=#
# 		Sys var: 				max_join_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				<a lot>
# 		Min: 						1
# 		Max: 						<a lot>
# 
# 		Do not permit statements that probably need to exaime more than max_join_size rows (for single-table statements)
# 		or row combinations (for multiple-table statements) or that are likely to do more than max_join_size disk seeks.
#
# 		By setting this value, you can catch statements where keys are not used properly and that would probably take a long time.
# 		Set this if you use to perform joins that lack a WHERE clause, that take a long time or return more than millions of rows.
#
# 		Setting this var to other than DEFAULT resets the value of sql_big_selects to 0.
#
# 		If you set the sql_big_selects value again, the max_join_size var is ignored.
#
# max_length_for_sort_data
#
# 		Cmd line format: 		--max-length-for-sort-data=#
# 		Sys var: 				max_length_for_sort_data
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		DEFAULT (>= 8.0.1) 	4096
# 		Default (8.0.0) 		1024
# 		Min: 						4
# 		Max: 						<max>
#
# 		The cutoff on the size of index values that determines which filesort algo to use.
#
# max_points_in_geometry
#
# 		cmd line format: 		--max-points-in-geometry=integer
# 		Sys var: 				max_points_in_geometry
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				65536
# 		Min: 						3
# 		Max: 						1048576
#
# 		Max value of the points_per_circle argument to the ST_BUFFER_Strategy() function
#
# max_prepared_stmt_count
#
# 		cmd line format: 		--max-prepared-stmt-count=#
# 		Sys var: 				max_prepared_stmt_count
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				16382
# 		Min: 						0
# 		Max: 						1048576
#
# 		This variable limits the total number of prepared statements in the server.
#
# 		It can be used in environments where there is the potentional for denial-of-service attacks
# 		based on running the server out of memory by preparing huge number of statements.
#
# 		If the value is set lower than the current number of prepared statements, existing statements are not
# 		affected and can be used, but no new statements can be prepared until the current number drops below the limit.
#
# 		
# max_seeks_for_key
#
# 		cmd line format: 		--max-seeks-for-key=#
# 		Sys Var: 				max_seeks_for_key
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default (64-bit) 		<a lot>
# 		Default (32-bit) 		<less>
# 		min: 						1
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		Limit the assumed max number of seeks when looking up rows based on a key.
# 		The MySQL optimizer assumes that no more than this number of key seeks are
# 		required when searching for matching rows in a table by scanning an index, regardless
# 		of the actual cardinality of the index.
#
# 		By setting it to a low value, for instance 100 - you can force MySQL to prefer indexes
# 		instead of table scans.
#
# max_sort_length
#
# 		cmd line format: 		--max-sort-length=#
# 		Sys var: 				max_sort_length
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				1024
# 		Min: 						4
# 		Max: 						<a lot>
#
# 		The number of bytes to use when sorting data values. The server uses only the first max_sort_length
# 		bytes of each value and ignore the rest.
#
# 		Consequently, values that differ only after the first max_sort_length bytes compare as equal for
# 		GROUP BY, ORDER BY and DISTINCT operations.
#
# 		Increasing this may require increasing the value of sort_buffer_size as well.
#
# max_sp_recursion_depth
#
# 		cmd line format: 		--max-sp-recursion-depth[=#]
# 		Sys var: 				max_sp_recursion_depth
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Max: 						255
#
# 		The number of times that any given stored procedure may be called recursively.
# 		The default value for this option is 0, which completely disables recursion in stored
# 		procedures.
#
# 		Max is 255.
#
# 		Stored procedure recursion increases the demand on thread stack space.
#
# 		If you increase the value of max_sp_recursion_depth, it may be necessary 
# 		to increase thread stack size by increasing the value of thread_stack at server startup.
#
# max_tmp_tables
#
# 		REMOVED 
#
# max_user_connections
#
# 		cmd line format: 		--max-user-connections=#
# 		Sys var: 				max_user_connections
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max: 						4294967295
#
# 		The max number of simultaneous connections permitted to any given MySQL user account.
# 		A value of 0 (the default) means "No limit".
#
# 		This variable has a global value that can be set at server startup or runtime.
#
# 		It also has a read-only session value that indicates the effective simultaneous-connection
# 		limit that applies to the account associated with the current session. The session value is initalized as
# 		follows: 				
#
# 		If the user account has a nonzero MAX_USER_CONNECTIONS resource limit, the session max_user_connections is set to that limit.
#
# 		Otherwise, the session max_user_connections session value is set to the global value.
#
# 		Account resource limits are specified, using the CREATE_USER or ALTER_USER statement.
#
# max_write_lock_count
#
# 		cmd line format: 		--max-write-lock-count=#
#  	Sys var: 				max_write_lock_count
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default (64-bit) 		<a lot>
# 		Default (32-bit) 		<less>
# 		Min: 						1
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		After this many write locks, permit some pending read lock requests
# 		to be processed in between.
#
# mecab_rc_file
#
# 		cmd line format: 		--mecab-rc-file
# 		Sys var: 				mecab_rc_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Dir name
#
# 		The mecab_rc_file option is used when setting up the MeCab full-text parser.
#
# 		The mecab_rc_file option defines the path to the mecabrc configuration file, which is the configuration
# 		file for MeCab. The option is read-only and can only be set at startup.
#
# 		The mecabrc configuration file is required to initialize MeCab.
#
# metadata_locks_cache_size
#
# 		deprecated: 			Yes (removed in 8.0.13)
# 		Sys var: 				metadata_locks_cache_size
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1024
# 		Min: 						1
# 		Max: 						A LOT
#
# 		REMOVED in 8.0.13
#
# metadata_locks_hash_instances
#
# 		DeprecateD: 			Yes (removed in 8.0.13)
# 		Sys var: 				metadata_locks_hash_instances
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				8
# 		Min: 						1
# 		Max: 						1024
#
# 		Removed in 8.0.13
#
# min_examined_row_limit
#
# 		cmd line format: 		--min-examined-row-limit=#
# 		Sys Var: 				min_examined_row_limit
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max (64-bit): 			<a lot>
# 		Max (32-bit): 			<less>
#
# 		Queries that examine fewer than this number of rows are not logged to the slow query log.
#
# multi_range_count
#
# 		cmd line format: 		--multi-range-count=#
# 		Deprecated: 			Yes (Removed in 8.0.3)
# 		Sys var: 				multi_range_count
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				256
# 		Min: 						1
# 		Max: 						<a lot>
#
# 		Removed in 8.0.3
#
# myisam_data_pointer_size
#
# 		cmd line format: 		--myisam-data-pointer-size=#
# 		Sys var: 				myisam_data_pointer_size
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				6
# 		Min: 						2
# 		Max: 						7
#
# 		Default point size in bytes, to be used by CREATE TABLE for MyISAM tables when no MAX_ROWS
# 		option is specified.
#
# 		This variable cannot be less than 2 or larger than 7. Default to 6.
#
# myisam_max_sort_file_size
#
# 		cmd line formT: 		--myisam-max-sort-file-size=#
# 		SYS var: 				myisam_max_sort_file_size
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					integer
# 		Default (64-bit) 		<a lot>
# 		Default (32-bit) 		<less>
#
# 		The max size of the temp file that MySQL is permitted to use while re-creating a MyISAM index
# 		(during REPAIR_TABLE, ALTER_TABLE, or LOAD_DATA_INFILE)
#
# 		If the file size would be larger than this value, the index is created using the key cache instead
# 		, which is slower. Given in bytes.
#
# 		If MyISAM index files exceed the size and disk space available, increasing the value may help performance.
# 		The space must be available in the file system containing the dir where the original index file is located.
#
# myisam_mmap_size
#
# 		cmd line format: 		--myisam-mmap-size=#
# 		Sys var: 				myisam_mmap_size
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default (64-bit) 		<a lot>
# 		Default (32-bit) 		<less>
# 		Min: 						7
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		The max amount of memory to use for memory mapping compressed MyISAM files.
# 		If many compressed MyISAM tables are used, the value can be decreased to reduce
# 		the likelihood of memory-swapping problems.
#
# myisam_recover_options
#
# 		Sys_var: 				myisam_recover_options
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
#
# 		The value of the --myisam-recover-options option
#
# myisam_repair_threads
#
# 		Cmd line format: 		--myisam-repair-threads=#
# 		Sys var: 				myisam_repair_threads
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1
# 		Min: 						1
# 		Max value (64-bit) 	<a lot>
# 		Max value (32-bit) 	<less>
#
# 		If greater than 1, MyISAM table indexes are created in parallel (each index in its own thread)
# 		during the Repair by sorting process.
#
# 		Multithread repair is still in beta.
#
# myisam_sort_buffer_size
#
# 		cmd line format: 		--myisam-sort-buffer-size=#
# 		Sys Var: 				myisam_sort_buffer_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				8388608
# 		Min: 						4096
# 		Max (other, 64-bit) 	<a lot>
# 		Max (other, 32-bit) 	<less>
# 		Max (windows, 64-bit)<a lot>
# 		Max (Windows, 32-bit)<less>
#
# 		The size of the buffer that is allocated when sorting MyISAM indexes during a REPAIR_TABLE
# 		or when creating indexes with CREATE_INDEX or ALTER_TABLE
#
# myisam_stats_method
#
# 		Cmd line format: 		--myisam-stats-method=name
# 		Sys var: 				myisam_stats_method
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				nulls_unequal
# 		Valid: 					nulls_equal, nulls_unequal, nulls_ignored
#
# 		How the server treats NULL values when collecting statistics about the distribution of index values for MyISAM tables.
# 		
# 		nulls_equal - All NULL index values are considered equal and form a single value group that has a size equal to number of NULL values.
# 		nulls_unequal - NULL values are considered unequal, and each NULL forms a distinct group value of size 1.
# 		nulls_ignored - NULL values are ignored.
#
# 		The method that is used for generating table stats influences how the optimizer chooses indexes for query execution
#
# myisam_use_mmap
#
# 		cmd line format: 		--myisam-use-mmap
# 		Sys var: 				myisam_use_mmap
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Use memory mapping for reading and writing MyISAM tables.
#
# mysql_native_password_proxy_users
#
# 		cmd line format: 		--mysql-native-password-proxy-users=[={OFF|ON}]
# 		Sys var: 				mysql_native_password_proxy_users
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Controls whether the mysql_native_password built-in authentication plugin supports
# 		proxy users. It has no effect unless the check_proxy_users SYS_VAR is on.
#
# named_pipe
#
# 		Sys var: 			named_pipe
# 		Scope: 				global
# 		Dynamic: 			No
# 		SET_VAR Hint: 		No
# 		Platform: 			Windows
# 		Type: 				Boolean
# 		Default: 			OFF
#
# 		Indicates whether the server supports connections over named pipes.
#
# net_buffer_length
#
# 		cmd line format: 		--net-buffer-length=#
# 		Sys var: 				net_buffer_length
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				16384
# 		Min: 						1024
# 		Max: 						1048576
#
# 		Each client thread is associated with a connection buffer and a result buffer.
#
# 		Both begin with a size given by net_buffer_length but are dynamically enlarged up to
# 		max_allowed_packet bytes as needed.
#
# 		The result buffer shrinks to net_buffer_length after each SQL statement.
#
# 		This var should not normally be changed, but in case of having very small amounts of memory,
# 		you can set it to the expected length of statements sent by clients.
#
# 		If statements exceed this length, the connection buffer is automatically enlarged.
# 		The max value to which net_buffer_length can be set is 1MB.
#
# 		Session value of this is read only.
#
# net_read_timeout
#
# 		Cmd line format: 		--net-read-timeout=#
# 		Sys var: 				net_read_timeout
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				30
# 		Min: 						1
#
# 		The number of seconds to wait for more data from a connection before aborting the read.
#
# 		When the server is reading from the client, net_read_timeout is the timeout value controlling
# 		when to abort.
#
# 		When the server is writing to the client, net_write_timeout is the timeout value controlling when to
# 		abort.
#
# 		See also slave_net_timeout
#
# net_retry_count
#
# 		cmd line format: 		--net-retry-count=#
# 		Sys var: 				net_retry_count
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				10
# 		Min: 						1
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		If a read or write on a communication port is interuppted, retry this many times before giving up.
#
# 		This should be set pretty high on FreeBSD because internal interuppts are sent to all threads.
#
# net_write_timeout
#
# 		cmd line format: 		--net-write-timeout=#
# 		Sys var: 				net_write_timeout
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				60
# 		Min: 						1
#
# 		Number of seconds to wait for a block to be written to a connection before aborting the write.
# 		(See also net_read_timeout)
# 
# new
#
# 		cmd line format: 		--new
# 		Sys var: 				new
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Disabled by: 			skip-new
# 		Type: 					Boolean
# 		Default: 				FALSE
#
# 		Used in 4.0 to turn on some 4.1 behaviors, retained for backwards comp. always off.
#
# ngram_token_size
#
# 		cmd line format: 		--ngram-token-size
# 		Sys var: 				ngram_token_size
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				2
# 		Min: 						1
# 		Max: 						10
#
# 		Defines the n-gram token size for the n-gram full-text parser.
# 		The ngram_token_size option is read-only and can only be modified at startup.
#
# offline_mode
#
# 		cmd line format: 		--offline-mode=val
# 		Sys Var: 				offline_mode
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Whether the server is in "offline mode", which has these characteristics:
#
# 			Connected client users who do not have the CONNECTION_ADMIN or SUPER privs are disconnected on the next request,
# 			with an appropiate error.
#
# 			Disconnection includes terminating running statements and releasing locks. Such clients also cannot initiate new connections,
# 			and receive an appropiate error.
#
# 			Connected client users who have the CONNECTION_ADMIN or SUPER privs are not disconnected, and can initiate new connections to
# 			manage the server.
#
# 			Replication slave threads are permitted to keep applying data to the server.
#
# 		Only users who have the SYSTEM_VARIABLES_ADMIN or SUPER priv can control offline mode.
#
# 		To put a server in offline mode, change the value of the offline_mode SYS_VAR from OFF to ON.
#
# 		To resume normal ops, change offline_mode from ON to OFF. In offline mode, clients that are 
# 		refused access receive an ER_SERVER_OFFLINE_MODE error.
#
# old
#
# 		cmd line format: 		--old
# 		Sys_var: 				old_alter_table
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		old is a compability var. Disabled by default, but can be enabled at startup to revert the server to behaviors present in older verisons.
#
# 		When old is enabled, it changes the default scope of index hints to that used prior to MySQL 5.1.17.
#
# 		That is, index hints with no FOR clause apply only to how indexes are used for retrieval and not to resolution
# 		of ORDER BY or GROUP BY clauses.
#
# 		Take care about enabling this in a replication setup.
#
# 		With statement-based binary logging, having different modes for master and slave - might lead to replication errors.
#
# old_alter_table
#
# 		Cmd line format: 		--old-alter-table
# 		Sys var: 				old_alter_table
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		When this variable is enabled, the server does not use optimized method of processing an ALTER_TABLE operation.
# 		It reverts to using a temporary table, copying over the data and then renaming the temporary table to the original,
# 		as used by MySQL 5.0 and earlier.
#
# 		ALTER TABLE ... DROP PARTITION with old_alter_table=ON rebuilds the partitioned table and attempts to move data
# 		from the dropped partition to another partition with a compatible PARTITION ... VALUES def.
#
# 		Data that cannot be moved to another partition is deleted. In earlier releases, ALTER TABLE ... DROP PARTITION 
# 		with old_alter_table=ON deletes data stored in the partition and drops the partition.
#
# old_passwords
#
# 		Deprecated: 		Yes (removed in 8.0.11)
# 		Sys var: 			old_passwords
# 		Scope: 				Global, Session
# 		Dynamic: 			Yes
# 		SET_VAR Hint: 		No
# 		Type: 				Enumeration
# 		Default: 			0
# 		Valid: 				0, 2
#
# 		REMOVED in 8.0.11
#
# open_files_limit
#
# 		Cmd line format: 		--open-files-limit=#
# 		Sys var: 				open_files_limit
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				5000, with possible adjustment
# 		Min: 						0
# 		Max: 						platform dependent
#
# 		The number of files that the OS permits mysqld to open.
#
# 		The value of this variable at runtime is the real value permitted by the system and might
# 		be different from the value you specify at server startup.
#
# 		The value is 0 on systems where MySQL cannot change the number of open files.
#
# 		The effective open_files_limit value is based on the value specified at system startup (if any) and the values
# 		of max_connections and table_open_cache using the following:
#
# 		1) 10 + max_connections + (table_open_cache * 2)
# 		2) max_connections + 5
# 		3) OS limit if +
# 		4) if OS limit is INF 
# 			open_files_limit value specified at startup, 5000 if None
#
# 		The server bases it's max on the max of the above three - If that many cannot be obtained,
# 		the server attempts to obtain as many as the system will permit.
#
# optimizer_prune_level
#
# 		cmd line format: 		--optimizer-prune-level[=#]
# 		Sys var: 				optimizer_prune_level
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Boolean
# 		Default: 				1
#
# 		Controls the heuristic applied during query optimization to prune less-promising
# 		partial plans from the optimizer search space.
#
# 		A value of 0 disables heuristics so that the optimizer performs an exhaustive search.
# 		A value of 1 causes the optimizer to prune plans based on the number of rows retrieved by intermediate plans.
#
# optimizer_search_depth
#
# 		cmd line format: 		--optimizer-search-depth[=#]
# 		Sys_var: 				optimizer_search_depth
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				62
# 		Min: 						0
# 		Max: 						62
#
# 		The max depth of search performed by the query optimizer. Values larger than
# 		the number of relations in a query result in better query plans, but take longer
# 		to generate an execution plan for a query.
#
# 		Values smaller than the number of relations in a query return an execution plan
# 		quicker, but the resulting plan may be far from being optimal.
#
# 		If set to 0, the system automatically picks a reasonable value.
#
# optimizer_switch
#
# 		cmd line format: 		--optimizer-switch=value
# 		Sys_var: 				optimizer_switch
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Set
# 		Valid (>= 8.0.13) 	batched_key_access={on|off}
# 									block_nested_loop={on|off}
# 									condition_fanout_filter={on|off}
#									derived_merge={on|off}
# 									duplicateweedout={on|off}
#
# 									engine_condition_pushdown={on|off}
# 									firstmatch={on|off}
# 									index_condition_pushdown{on|off}
# 									index_merge={on|off}
# 									index_merge_intersection={on|off}
# 									index_merge_union={on|off}
# 									loosescan={on|off}
# 									materialization={on|off}
#
# 									mrr={on|off}
# 									mrr_cost_based={on|off}
# 									semijoin={on|off}
# 									skip_scan={on|off}
# 									subquery_materialization_cost_based={on|off}
# 									use_index_extensions={on|off}
# 									use_invisible_indexes={on|off}
#
# 		Valid (>= 8.0.3, <= 8.0.12)
#
# 									batched_key_access={on|off}
# 									block_nested_loop={on|off}
# 									condition_fanout_filter={on|off}
# 									derived_merge={on|off}
# 									duplicateweedout={on|off}
# 									engine_condition_pushdown={on|off}
# 									firstmatch={on|off}
# 									index_condition_pushdown={on|off}
# 									index_merge={on|off}
# 									index_merge_intersection={on|off}
# 									index_merge_sort_union={on|off}
#
# 									index_merge_union={on|off}
# 									loosescan={on|off}
# 									materialization={on|off}
# 									mrr={on|off}
# 									mrr_cost_based={on|off}
# 									semijoin={on|off}
# 									subquery_materialization_cost_based={on|off}
# 									use_index_extensions={on|off}
# 									use_invisible_indexes={on|off}
#
# 		Valid (<= 8.0.2) 		batched_key_access={on|off}
# 									block_nested_loop={on|off}
# 									condition_fanout_filter={on|off}
# 									derived_merge={on|off}
# 									duplicateweedout={on|off}
# 									engine_condition_pushdown={on|off}
#
# 									firstmatch={on|off}
# 									index_condition_pushdown={on|off}
# 									index_merge={on|off}
# 									index_merge_intersection={on|off}
# 									index_merge_sort_union={on|off}
# 									index_merge_union={on|off}
# 									loosescan={on|off}
# 									materialization={on|off}
# 									mrr={on|off}
# 									mrr_cost_based={on|off}
# 
# 									semijoin={on|off}
# 									subquery_materialization_cost_based={on|off}
# 									use_index_extensions={on|off}
#
# 		The optimizer_switch SYS_VAR enables control over optimizer behavior.
#
# 		The value of this var is a set of flags, each of which has a value of on
# 		or off to indicate whether the corresponding optimizer behavior is enabled or disabled.
#
# 		This variable has global and session values and can be changed at runtime.
#
# 		The global default can be set at server startup.
#
# 		To see the current set of optimizer flags, select the variable value:
#
# 		SELECT @@optimizer_switch\G
# 		***************************** 1. row **********************************
# 		@@optimizer_switch: 	index_merge=on,index_merge_union=on (off if it's off), etc.
#
# optimizer_trace
#
# 		Sys var: 		optimizer_trace
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			String
#
# 		Controls the optimizer tracing.
#
# optimizer_trace_features
#
# 		Sys var: 		optimizer_trace_features
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	no
# 		Type: 			String
#
# 		Enables or disabled selected optimizer tracing features.
#
# optimizer_trace_limit
#
# 		Sys var: 		optimizer_trace_limit
# 		Scope. 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			Integer
# 		Default: 		1
#
# 		Max number of optimizer traces to display.
#
# optimizer_trace_max_mem_size
#
# 		Sys var: 		optimizer_trace_max_mem_size
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	Yes
# 		Type: 			Integer
# 		Default (>= 8.0.4) 1048576
# 		Default (<= 8.0.3) 16384
#
# 		The max cumulative size of stored optimizer traces.
#
# optimizer_trace_offset
#
# 		Sys var: 		optimizer_trace_offset
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			Integer
# 		Default: 		-1
#
# 		The offset of optimizer traces to display.
#
# performance_schema_xxx
#
# 		Performance Schema sys vars, listed later.
# 		Can be used to configure performance schema ops.
#
# parser_max_mem_size
#
# 		cmd line format: 		--parser-max-mem-size=N
# 		Sys var: 				parser_max_mem_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default (64-bit) 		<a lot>
# 		Default (32-bit) 		<less>
# 		Min: 						10000000
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		The max amount of memory available to the parser. 
# 		The default value places no limit on memory available.
# 		
# 		The value can be reduced to protect against out-of-memory situations caused by
# 		parsing long or complex SQL statements.
#
# password_history
#
# 		cmd line format: 		--password-history=#
# 		Introduced: 			8.0.3
# 		Sys var: 				password_history
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max: 						4294967295
#
# 		This variable defines the global policy for controlling reuse of previous passwords based on
# 		required minimum number of password changes.
#
# 		For an account password used previously, this variable indicates the number of subsequent account password
# 		changes that must occur before the password can be used.
#
# 		If the value is 0 (default), there is no reuse restriction based on number of PW changes.
#
# 		Changes to this variable apply immediately to all accounts defined with the PASSWORD HISTORY DEFAULT option.
#
# 		The global number-of-changes password reuse policy can be overridden as desired for individual accounts using
# 		the PASSWORD HISTORY option of the CREATE USER and ALTER USER statements.
#
# password_require_current
#
# 		cmd line format: 		--password-require-current[={OFF|ON}]
# 		Introduced: 			8.0.13
# 		Sys var: 				password_require_current
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		Defines the global policy for controlling whether attempts to change an acc PW must specify the current PW to be replaced.
#
# 		Changes to this var apply immediately to all accounts defined with the PASSWORD REQUIRE CURRENT DEFAULT option.
#
# 		The global verification-required policy can be overriden as desired for individual accounts using the
# 		PASSWORD REQUIRE option of the CREATE_USER and ALTER_USER statements.
#
# password_reuse_interval
#
# 		cmd line format: 		--password-reuse-interval=#
# 		Introduced: 			8.0.3
# 		Sys var: 				password_reuse_interval
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				0
# 		Min: 						0
# 		Max: 						<a lot>
#
# 		This variable defines the global policy for controlling reuse of previous PWs based on time elapsed.
# 		For an account PW used previously, this var indicates the number of days that must pass before the PW can be reused.
#
# 		If the value is 0 (default), there is no reuse restriction based on time elapsed.
#
# 		Changes to this var apply instantly to all accounts defined with the PASSWORD REUSE INTERVAL DEFAULT option.
#
# 		The global time-elapsed PW reuse policy can be overridden as desired for individual accounts using the PASSWORD REUSE INTERVAL
# 		option of the CREATE_USER and ALTER_USER statements.
#
# persisted_globals_load
#
# 		cmd line format: 		--persisted-globals-load[=ON|OFF]
# 		Sys var: 				persisted_globals_load
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				ON
#
# 		Whether to load persisted configuration settings from the mysqld-auto.cnf file in the data dir.
# 		The server normally processes this file at startup after all other option files.
#
# 		Disabling this causes the server startup sequence to skip mysqld-auto.cnf
#
# 		To modify the contents of mysqld-auto.cnf, use the SET_PERSIST, SET_PERSIST_ONLY and
# 		RESET_PERSIST statements.
#
# pid_file
#
# 		cmd line format: 		--pid-file=file_name
# 		Sys var: 				pid_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					File name
#
# 		The path name of the process ID file. This var can be set with the --pid-file option.
#
# 		The server creates the file in the data dir unless an absolute path name is given
# 		to specify a different dir.
#
# 		If you specify the --pid-file option, you must specify a value.
#
# 		If you do not specify the --pid-file option, MySQL uses a default
# 		value of <host_name>.pid where <host_name> is the name of the host machine.
#
# 		The process ID file is used by other programs such as mysqld_safe to determine 
# 		the server's process ID.
#
# 		On Windows, this var also affects the default error log file name.
#
# plugin_dir
#
# 		cmd line format: 		--plugin-dir=dir_name
# 		Sys var: 				plugin-dir
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
#  	Type: 					Dir name
# 		Default: 				BASEDIR/lib/plugin
#
# 		Path name of the plugin dir.
#
# 		If the plugin dir is writable by server, it may be possible for a user to write
# 		executable code to a file in the dir using SELECT ... INTO DUMPFILE
#
# 		This can be prevented by making plugin_dir read only to the server or by setting
# 		--secure-file-priv to a dir where SELECT writes can be made safely.
#
# port
#
# 		cmd line format: 		--port=#
# 		Sys var: 				port
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				3306
# 		Min: 						0
# 		Max: 						65535
#
# 		Number of port on which the server listens for TPC/IP conns.
# 		Can be set with --port
#
# preload_buffer_size
#
# 		cmd line format: 		--preload-buffer-size=#
# 		Sys var: 				preload_buffer_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				32768
# 		Min: 						1024
# 		Max: 						<a lot>
#
# 		Size of the buffer that is allocated when preloading indexes.
#
# profiling
#
# 		If set to 0 or OFF (the default), statement profiling is disabled.
#
# 		If set to 1 or ON, statement profiling is enabled and the SHOW PROFILE
#  	and SHOW PROFILES statements provide access to profiling information.
#
# 		Deprecated.
#
# profiling_history_size
#
# 		Number of statements for which to maintain profiling information if profiling is enabled.
# 		Default is 15.
#
# 		max is 100. Setting this 0 disables profiling.
#
# 		Deprecated.
#
# protocol_version
#
# 		Sys var: 		protocol_version
# 		Scope: 			Global
# 		Dynamic: 		No
# 		SET_VAR Hint: 	No
# 		Type: 			Integer
#
# 		The version of the client/server protocol used by the MySQL server.
#
# proxy_user
#
# 		Sys var: 		proxy_user
# 		scope: 			Session
# 		Dynamic: 		No
# 		SET_VAR Hint: 	No
# 		Type: 			String
#
# 		If the current client is a proxy for another user, this var is the proxy user account name.
# 		Otherwise, this var is NULL.
#
# pseudo_slave_mode
#
# 		Sys var: 		pseudo_slave_mode
# 		Scope: 			Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			Integer
#
# 		This var is used for internal server use.
#
# 		AS of MySQL 8.0.14, setting the session value of this sys var is a restricted ops.
#
# 		The session user must have the privs to set it.
#
# 		In MysQL >= 8.0.14 - pseudo_slave_mode has the following effects on the handling of a statement that
# 		sets one or more unsupported or unknown SQL modes:
#
# 			If true - the server ignores the unsupported mode and raises a warning
#
# 			If false - the server rejects the statement with ER_UNSUPPORTED_SQL_MODE
#
# 		mysqlbinlog sets this var to true prior to executing any other SQL.
#
# pseudo_thread_id
#
# 		Sys var: 		pseudo_thread_id
# 		Scope: 			Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			Integer
#
# 		Used for internal server use
#
# 		Setting this is a restricted ops, must have privs
#
# query_alloc_block_size
#
# 		Cmd line format: 		--query-alloc-block-size=#
# 		Sys var: 				query_alloc_block_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				8192
# 		Min: 						1024
# 		Max: 						<a lot>
# 		Block size: 			1024
#
# 		The allocation size of memory blocks that are allocated for objects created during statement parsing
# 		and execution. 
#
# 		If you have problems with memory fragmentation, it might help to increase this param.
# 		
# query_cache_limit
#
# 		Cmd line format: 		--query-cache-limit=#
# 		DeprecateD: 			Yes (removed in 8.0.3)
# 		Sys var: 				query_cache_limit
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				1048576
# 		Min: 						0
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		REMOVED in 8.0.3
#
# query_cache_min_res_unit
#
# 		Cmd line format: 		--query-cache-min-res-unit=#
# 		Deprecated: 			Yes (Removed in 8.0.3)
# 		Sys var: 				query_cache_min_res_unit
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					integer
# 		Default: 				4096
# 		Min: 						512
# 		Max (64-bit) 			<a lot>
# 		Max (32-bit) 			<less>
#
# 		REMOVED in 8.0.3
#
# query_cache_size
#
# 		cmd line format: 				--query-cache-size=#
# 		Deprecated: 					Yes (removed in 8.0.3)
# 		Sys var: 						query_cache_size
# 		Scope: 							Global
# 		Dynamic: 						Yes
# 		SET_VAR Hint: 					No
# 		Type: 							Integer
# 		Default (64-bit, >= 8.0.1) 0
#  	Default (64-bit, 8.0.0) 	1048576
#
# 		Default (32-bit, >= 8.0.1) 0
# 		Default (32-bit, 8.0.0) 	1048576
# 
# 		Min: 								0
#
# 		Max (64-bit) 					<a lot>
# 		Max (32-bit) 					<less>
#
# 		REMOVED in 8.0.3
#
# query_cache_type
#
# 		Cmd line format: 			--query-cache-type=#
# 		Deprecated: 				Yes (Removed in 8.0.3)
# 		Sys var: 					query_cache_type
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Enumeration
# 		Default: 					0
# 		Valid: 						0, 1, 2
#
# 		Removed in 8.0.3
#
# query_cache_wlock_invalidate
#
# 		cmd line format: 			--query-cache-wlock-invalidate
# 		Deprecated: 				Yes (Removed in 8.0.3)
# 		Sys var: 					query_cache_wlock_invalidate
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Boolean
# 		Default: 					FALSE
#
# 		Removed in 8.0.3
#
# query_prealloc_size
#
# 		cmd line format: 			--query-prealloc-size=#
# 		Sys var: 					query_prealloc_size
# 		Scope: 						Global, Session
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Integer
# 		Default: 					8192
# 		Min: 							8192
# 		Max (64-bit) 				<a lot>
# 		Max (32-bit) 				<less>
# 		Block size: 				1024
#
# 		The size of the persistent buffer used for statement parsing and execution.
# 		This buffer is not freed between statements.
#
# 		If you are running complex queries, a larger query_prealloc_size value might
# 		be helpful in improving performance, because it can reduce the need for the server
# 		to perform memory allocation during query execution operations.
#
# rand_seed1
#
# 		sys var: 				rand_seed1
# 		Scope: 					Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
#
# 		The rand_seed1 and rand_seed2 vars exist as session vars only, and can be set but not read.
# 		The variable - but not their values - are shown in the output of SHOW_VARIABLES.
#
# 		The purpose of these vars is to support replication of the RAND() function.
# 		For statements that invoke RAND(), the master passes two values to the slave -
# 		where they are used to seed the RNG.
#
# 		The slave uses these values to set the session vars rand_seed1 and rand_seed2 so that RAND()
# 		on the slave generates the same value as on the master.
#
# rand_seed2
# 
# 		Same as rand_seed1
#
# range_alloc_block_size
#
# 		Cmd line format: 		--range-alloc-block-size=#
# 		Sys var: 				range_alloc_block_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				4096
# 		Min: 						4096
# 		Max (64-bit) 			<a lot>
# 		Max: 						<less>
# 		Block size: 			1024
#
# 		Size of blocks that are allocated when doing range optimization.
#
# range_optimizer_max_mem_size
#
# 		cmd line ormat: 		--range-optimizer-max-mem-size=N
# 		Sys var: 				range_optimizer_max_mem_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Integer
# 		Default: 				8388608
# 		Min: 						0
# 		Max: 						<a lot>
#
# 		The limit on memory consumption for the range optimizer.
# 		A value of 0 means "no limit".
#
# 		If an execution plan considered by the optimizer uses the range access
# 		method but the optimizer estimates that the amount of memory needed for this
# 		method would exceed the limit - it abandons the plan and considers other plans.
#
# rbr_exec_mode
#
# 		sys var: 		rbr_exec_mode
# 		Scope: 			Global, Session
# 		Dynamic: 		Yes
# 		SET_VAR Hint: 	No
# 		Type: 			Enumeration
# 		Default: 		STRICT
# 		Valid: 			IDEMPOTENT, STRICT
#
# 		For internal use by mysqlbinlog.
# 		The variable switches the server between IDEMPOTENT mode and STRICT mode.
#
# 		IDEMPOTENT mode causes suppression of duplicate-key and no-key found errors
# 		in BINLOG statements generated by mysqlbinlog.		
#
# 		This mode is useful when replaying a row-based binary log on a server that causes
# 		conflicts with existing data. 
#
# 		mysqlbinlog sets this mode when you specify the --idempotent option by writing the following:
#
# 		SET SESSION RBR_EXEC_MODE=IDEMPOTENT;
#
# 		As of MySQL 8.0.14 - setting the session value of this sys var is a restricted ops.
# 		Reqs privs.
#
# read_buffer_size
#
# 		cmd line format: 		--read-buffer-size=#
# 		Sys var: 				read_buffer_size
# 		Scope: 					Global, Session
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			Yes
# 		Type: 					Integer
# 		Default: 				131072
# 		Min: 						8200
# 		Max: 						<a lot>
#
# 		Each thread that does a sequential scan for a MyISAM table allocates a buffer of this size (in bytes)
# 		for each table it scans.
#
# 		If you do many sequential scans, you might want to increase this value.
#
# 		Value of this var should be % 4kb. If it set to a value which is not, it's rounded down to closest % 4kb value.
#
# 		Is also used in the following context for all storage engines:
#
# 			For caching the indexes in a temporary file (not a temp table), when sorting rows for ORDER BY.
#
# 			For bulk insert into partitions.
#
# 			For caching results of nested queries.
#
# 		read_buffer_size is also used in one other storage engine-specific way: To determine the memory block size
# 		for MEMORY tables.
#
# read_only
#
# 		cmd line format: 		--read-only
# 		Sys var: 				read_only
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		When the read_only sys var is enabled, the server permits no client updates except
# 		from users who have the CONNECTION_ADMIN or SUPER privs.
#
# 		This var is disabled by default.
#
# 		The server also supports a super_read_only sys var (disabled by default), which has these effects:
#
# 			If super_read_only is enabled, the server prohibits client updates, even from users who have the SUPER priv.
#
# 			Setting super_read_only to ON implicitly forces read_only to ON.
#
# 			Setting read_only to OFF implicitly forces super_read_only to OFF.
#
# 		Even with read_only enabled, the server permits these operations:
#
# 			Updates performed by slave threads, if the server is a replication slave. 
#
# 			In replication setups, it can be useful to enable read_only on slave servers
# 			to ensure that slaves accept updates only from the master server and not from clients.
#
# 			Use of ANALYZE_TABLE or OPTIMIZE_TABLE statements. The purpose of read-only mode is to prevent
# 			changes to table structure or contents.
#
# 			Analysis and optimization do not qualify as such changes. 
#
# 			This means for example, that consistency checks on read-only replication slaves can be performed with
# 			mysqlcheck --all-databases --analyze
#
# 			Operations on TEMPORARY tables
#
# 			Inserts into the log tables (mysql.general_log and mysql.slow_log)
#
# 			Updates to Performance Schema tables, such as UPDATE or TRUNCATE TABLE operations.
#
# 		Changes to read_only on a master server are not replicated to slave servers. 
# 		The value can be set on a slave server independent of the setting on the master.
#
# 		The following conditions apply to attempts to enable read_only (including implicit attempts resulting from enabling super_read_only):
# 
# 			The attempt fails and an error occurs if you have any explicit locks (acquired with LOCK_TABLES) or have a pending transaction.
#
# 			The attempt blocks while other clients hold explicit table locks or have pending transactions, until the locks are released and
# 			the trans ends. 
# 			
# 			While the attempt to enable read_only is pending, requests by other clients for table locks or to begin trans also block until read_only has been set.
#
# 			The attempt blocks if there are active transactions that hold metadata locks, until those transactions end.
#
# 			read_only can be enabled while you hold a global read lock (acquired with FLUSH_TABLES_WITH_READ_LOCK) because that does
# 			not involve table locks.
#
# read_rnd_buffer_size
#
# 			cmd line format: 		--read-rnd-buffer-size=#
# 			Sys var: 				read_rnd_buffer_size
# 			Scope: 					Global, Session
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			Yes
# 			Type: 					Integer
# 			Default: 				262144
# 			Min: 						1
# 			Max: 						<less>
#
# 			This var is used for reads from MyISAM tables and for any storage engine, for multi-range read optimization.
#
# 			When reading rows from a MyISAM table in sorted order following a key-sorting operation, the rows
# 			are read through this buffer to avoid disk seeks.
#
# 			Setting this variable to a large value can improve ORDER BY performance by a lot.
# 			However, this is a buffer allocated for each client - so you should not set the global variable to a large value.
#
# 			Instead, the session value can be large for where you need to run large queries.
#
# regexp_stack_limit
#
# 			cmd line format: 		--regexp-stack-limit=#
# 			introduced: 			8.0.4
# 			Sys var: 				regexp_stack_limit
# 			Scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Integer
# 			Default: 				8 000 000
# 			Min: 						0
# 			Max: 						<a lot>
#
# 			Max value available memory in bytes for the internal stack used for regex matching ops
# 			performed by REGEXP_LIKE() and similar functions.
#
# regexp_time_limit
#
# 			cmd line format: 		--regexp-time-limit=#
# 			Introduced: 			8.0.4
# 			Sys var: 				regexp_time_limit
# 			Scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Integer
# 			Default: 				32
# 			min: 						0
# 			Max: 						<a lot>
#
# 			The time limit for regexp matching ops performed by REGEXP_LIKE() and similar functions.
# 			This limit is expressed as the max permitted number of steps performed by the match engine,
# 			and thus affects execution time only indirectly.
#
# 			Typically on the order of milliseconds.
#
# require_secure_transport
#
# 			cmd line format: 		--require-secure-transport[={OFF|ON}]
# 			Sys var: 				require_secure_transport
# 			Scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Boolean
# 			Default: 				OFF
# 			
#
# 			Whether client connections to the server are required to use some form of secure transport.
# 			When this variable is enabled, the server permits only TCP/IP connections that use SSL,
# 			or connections that use a socket file (on Unix) or shared memory (on Windows).
#
# 			The server rejects nonsecure connection attempts, which fail with an ER_SECURE_TRANSPORT_REQUIRED error.
#
# 			This capability supplements per-account SSL reqs, which takes precedence.
#
# 			For example,if an acc is defined with REQUIRE SSL - enabling require_secure_transport
# 			does not make it possible to use the account to connect using a Unix socket file.
#
# 			It is possible for a server to have no secure transports available. For example, a server on Windows
# 			supports no secure transports if started without specifying any SSL cert or key files and with
# 			the shared_memory SYS_VAR disabled.
#
# 			Under said conditions, attempts to enable require_secure_transport at startup cause the server to write
# 			a message to the error log and exit. Attempts to enable the variable at runtime fail with an ER_NO_SECURE_TRANSPORTS_CONFIGURED
# 			error.
#
# resultset_metadata
#
# 			Introduced: 		8.0.3
# 			Sys var: 			resultset_metadata
# 			Scope: 				Session
# 			Dynamic: 			Yes
# 			SET_VAR Hint: 		No
# 			Type: 				Enumeration
# 			Default: 			FULL
# 			Valid: 				FULL, NONE
#
# 			For connections for which metadata transfer is optional, the client sets the resultset_metadata
# 			SYS var to control whether the server returns result set metadata.
#
# 			Permitted values are FULL (return all metadata; this is the default) and NONE (return no metadata)
#
# 			For connections that are not metadata-optional, setting resultset_metadata to NONE produces an error.
#
# schema_definition_cache
#
# 			cmd line format: 		--schema-definition-cache=N
# 			Sys var: 				schema_definition_cache
# 			scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Integer
# 			Default: 				256
# 			Min: 						256
# 			Max: 						524288
#
# 			Defines a limit for the number of schema def objects, both used and unused, that can be kept
# 			in the dictionary object cache.
#
# 			Unused schema definition objects are only kept in the dictionary object cache when the number in use is
# 			less than the capacity defined by schema_definition_cache.
#
# 			A setting of 0 means that schema definition objects are only kept in the dictionary object cache
# 			while they are in use.
#
# secure_auth
#
# 			cmd line format: 		--secure-auth
# 			Deprecated: 			Yes (removed in 8.0.3)
# 			Sys var: 				secure_auth
# 			Scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Boolean
# 			Default: 				On
# 			Valid: 					On
#
# 			Removed in 8.0.3
#
# secure_file_priv
#
# 			cmd line format: 		--secure-file-priv=dir_name
# 			Sys var: 				secure_file_priv
# 			Scope: 					Global
# 			Dynamic: 				No
# 			SET_VAR Hint: 			No
# 			Type: 					String
# 			Default: 				platform specific
# 			Valid: 					empty string, dirname, NULL
#
# 			Used to limit the effect of data import and export operations, such as those performed
# 			by the LOAD_DATA and SELECT_..._INTO_OUTFILE statements and the LOAD_FILE() function.
#
# 			Permitted only to users with FILE priv.
#
# 			secure_file_priv can be set as follows:
#
# 				If empty - var has no effect. Not a secure setting.
#
# 				If name of a dir, the server limits import and export ops to work only with files in that dir.
# 				The dir must exist, the server will not create it.
#
# 				If set to NULL, the server disables import and export ops.
#
# 			The default value is platform specific and depends on the value of the INSTALL_LAYOUT CMake option,
# 			as shown as follows:
#
# 			(To specify the default secure_file_priv value explicitly if you are building from source, use the 
# 			INSTALL_SECURE_FILE_PRIVDIR CMake option.)
#
# 				INSTALL_LAYOUT Value 		Default secure_file_priv Value
# 				STANDALONE, WIN 				empty
# 				DEB, RPM, SLES, SVR4 		/var/lib/mysql-files
# 				Otherwise 						mysql-files under the CMAKE_INSTALL_PREFIX value
#
# 			The server checks the value of secure_file_priv at startup and writes a warning to the error log
# 			if the value is insecure.
#
# 			A non-NULL value is considered insecure if it is empty, or the value is the dara dir or a subdir of it,
# 			or a sub-dir that is accessible by all users.
#
# 			If secure_file_priv is set to a nonexistent path, the server writes an error message to the error log and exits.
#
# server_id
#
# 			cmd line format: 		--server-id=#
# 			Sys var: 				server_id
# 			Scope: 					Global
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Integer
# 			Default (>= 8.0.3) 	1
# 			Default (<= 8.0.2) 	0
# 			Min: 						0
# 			Max: 						<a lot>
#
# 			Specifies the server ID. This variable is set by the --server-id option.
# 			The server_id sys var is set to 1 by default.
#
# 			The server can be started with this default ID, but when bin log is enabled,
# 			an informational message is issued if you did not specify a server ID explicitly using the --server-id option.
#
# 			For servers that are used in a replication topology, you must specify a unique server ID for each replication
# 			server, in the range from 1 to 2^32 - 1. "Unique" means that each ID must be different from other IDs in use by 
# 			any other replication master or slave.
#
# 			If the server ID is set to 0, binary logging takes place - but a master server with a server ID of 0
# 			refuses any connections from slaves and a slave with a server ID of 0 refuses to connect to a master.
#
# 			Note that although you can change the server ID dynamically to a nonzero value, doing so does not
# 			enable replication to start immediately.
#
# 			You must change the server ID and then restart the server to initialize the replication slave.
#
# session_track_gtids
#
# 			cmd line format: 			--session-track-gtids=[value]
# 			Sys var: 					session_track_gtids
# 			Scope: 						Global, Session
# 			Dynamic: 					Yes
# 			SET_VAR Hint: 				No
# 			Type: 						Enumeration
# 			Default: 					OFF
# 			Valid: 						OFF, OWN_GTID, ALL_GTIDS
#
# 			Controls whether the server tracks GTIDs within the current session and returns them to the client.
# 			Depending on the variable value, at the end of executing each transaction, the server GTIDs are captured
# 			by the tracker and returned to the client.
#
# 			These session_track_gtids values are permitted:
#
# 				OFF: Track collects no GTIDs. Default.
#
# 				OWN_GTID: The track collects GTIDs generated by successfully committed read/write transactions.
#
# 				ALL_GTIDS: The track collects all GTIDs in the gtid_executed SYS_VAR at the time the current transaction commits,
# 				regardless of whether the transaction is read/write or read only.
#
# 			session_track_gtids cannot be set within transactional context.
#
# session_track_schema
#
# 			cmd line format: 		--session-track-schema=#
# 			Sys var: 				session_track_schema
# 			Scope: 					Global, Session
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Boolean
# 			Default: 				ON
#
# 			Controls whether the server tracks when the default schema (database) is set within the current session
# 			and notifies the client to make the schema name available.
#
# 			If the schema name tracked is enabled, name notification occurs each time the default schema is set,
# 			even if the new schema name is the same as the old.
#
# session_track_state_change
#
# 			Cmd line format: 		--session-track-state-change=#
# 			Sys var: 				session_track_state_change
# 			Scope: 					Global, Session
# 			Dynamic: 				Yes
# 			SER_VAR Hint: 			No
# 			Type: 					Boolean
# 			Default: 				OFF
#
# 			Controls whether the server tracks changes to the state of the current session and notifies
# 			the client when state changes occur.
#
# 			Changes can be reported for these attributes of client session state:
#
# 				Default schema (db)
#
# 				Session-specific values for sys vars.
#
# 				User-defined vars
#
# 				Temp tables
#
# 				Prepared statements
#
# 			If the session state tracker is enabled, notification occurs for each change that involves tracked session attributes,
# 			even if the new attribute values are the same as the old.
#
# 			For example, setting a user-defined variable to its current value results in a notification.
#
# 			The session_track_state_change variable controls only notification of when changes occur, not what the changes are.
#
# 			For example, state-change notifications occur when the default schema is set or tracked session SYS vars are assigned,
# 			but the notification does not include the schema name or variable values.
#
# 			To receive notification of the schema name or session sys var values - use the session_track_schema or session_track_system_variables
# 			SYS_Vars respectively.
#
# 			NOTE: Assigning a value to session_track_state_change itself is not considered a state change and is not reported as such.
# 					However, if its name is listed in the value of session_track_system_variables, any assignments to it do result in notification of the new value.
#
# session_track_system_variables
#
# 			cmd line format: 		--session-track-system-variables=#
# 			Sys var: 				session_track_system_variables
# 			Scope: 					Global, Session
# 			Dynamic: 				Yes
# 			SET_Var Hint: 			No
# 			Type: 					String
# 			Default: 				time_zone, autocommit, character_set_client, character_set_results,
# 										character_set_connection
#
# 			Controls whether the server tracks assignments to session system vars and notifies the client of the name
# 			and value of each assigned variable.
#
# 			The variable value is a comma-separated list of variables for which to track assignments.
#
# 			By default, notification is enabled for time_zone, autocommit, character_set_client,
# 			character_set_results and character_set_connection.
#
# 			(The latter three vars are those affacted by SET_NAMES)
#
# 			Wildcard * all denotation can be given.
#
# 			To disable notification session vars assignments, set session_track_system_variables to the
# 			empty string.
#
# 			If session system variable tracking is enabled, notification occurs for all assignments to tracked
# 			session variables, even if the new values are the same as the old.
#
# session_track_transaction_info
#
# 			cmd line format: 		--session-track-transaction-info=value
# 			Sys var: 				session_track_transaction_info
# 			Scope: 					Global, Session
# 			Dynamic: 				Yes
# 			SET_VAR Hint: 			No
# 			Type: 					Enumeration
# 			Default: 				OFF
# 			Valid: 					OFF, STATE, CHARACTERISTICS
#
# 			Controls whether the server tracks the state and characteristics of transactions within the current session
# 			and notifies the client to make this information available.
#
# 			These session_track_transaction_info values are permitted:
#
# 				OFF: Disable transaction state tracking. Default.
#
# 				STATE: Enable transaction state tracking without characteristics tracking.
# 						 State tracking enables the client to determine whether a transaction is in progress
# 						 and whether it could be moved to a different session without being rolled back.
#
# 				CHARACTERISTICS: Enable transaction state tracking, including chars tracking. Characteristics tracking enables
# 						 the client to determine how to restart a transaction in another session so that it has the same
# 						 characteristics as in the original session.
#
# 						The following chars are relevant:
#
# 						READ ONLY
# 						READ WRITE
# 						ISOLATION LEVEL
# 						WITH CONSISTENT SNAPSHOT
#
# 				For a client to safely relocate a transaction to another session, it must track not only transaction
# 				state but also transaction characteristics. 
#
# 				In addition, the client must track the transaction_read_only and transaction_isolation SYS_VAR to correctly determine the session defaults.
#
# 				(To track these, list them in the value of the session_track_system_variables SYS_VAR)
#
# sha256_password_auto_generate_rsa_keys
#
# 				Cmd line format: 		--sha256-password-auto-generate-rsa-keys[={OFF|ON}]
# 				Sys var: 				sha256_password_auto_generate_rsa_keys
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				ON
#
# 				Available if the server was compiled using OpenSSL. The server uses it to determine whether to
# 				autogenerate RSA private/public key-pair files in the data dir if they do not already exist.
#
# 				At startup, the server automatically generates RSA private/public key-pair files in the data dir
# 				if all of these conditions are true:
#
# 					The sha256_password_auto_generate_rsa_keys or caching_sha2_password_auto_generate_rsa_keys SYS_VAR is on.
#
# 					No RSA options are specified
#
# 					The RSA files are missing from the data dir.
#
# 				These key-pair files enable secure PW exchange using RSA over unencrypted connections for accounts
# 				authenticated by the sha256_password or caching_sha2_password plugin.
#
# 				The auto_generate_certs SYS_VAR is related but controls autogeneration of SSL certs and keys needed for secure connections.
#
# sha256_password_private_key_path
#
# 				cmd line format: 		--sha256-password-private-key-path=file_name
# 				Sys var: 				sha256_password_private_key_path
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					File name
# 				Default: 				private_key.pem
#
# 				This var is available if MySQL was compiled using OpenSSL.
# 				Its value is the path name of the RSA priv key file for the sha256_password
# 				auth plugin.
#
# 				Relative to server data dir. Must be in PEM.
#
# 				Permissions should be constrained to MySQL reading it.
#
# sha256_password_proxy_users
#
# 				cmd line format: 		--sha256-password-proxy-users=[={OFF|ON}]
# 				Sys var: 				sha256_password_proxy_users
# 				Scope: 					Global
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				OFF
#
# 				Controls whether the sha256_password built-in auth plugin supports proxy users.
# 				Has no effect unless the check_proxy_users SYS_VAR is on.
#
# sha256_password_public_key_path
#
# 				cmd line format: 		--sha256-password-public-key-path=file_name
# 				Sys var: 				sha256_password_public_key_path
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					File name
# 				Default: 				public_key.pem
#
# 				Available if MYSQL was compiled using OpenSSL. 
# 				Its value is the path name of the RSA public key file for the sha256_password auth plugin.
# 			 			
# 				If the file is named as a relative path, it is interpreted relative to the server Data dir.
# 				File must be in PEM format.
#
# 				The key is a public key, thus copies can be distirbued to client users.
# 				(Clients that explicitly specify a public key when connecting to the server using RSA
# 				PW encryption must use the same public key as that used by the server.)
#
# shared_memory
#
# 				cmd line format: 		--shared-memory[={0,1}]
# 				Sys var: 				shared_memory
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Platform: 				Windows
# 				Type: 					Boolean
# 				Default: 				FALSE
#
# 				Whether hte server permits shared-memory connections.
#
# shared_memory_base_name
#
# 				cmd line format: 		--shared-memory-base-name=name
# 				Sys var: 				shared_memory_base_name
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Platform: 				Windows
# 				Type: 					String
# 				Default: 				MYSQL
#
# 				Name of the shared memory to use for shared-memory connections.
# 				Useful when running multiple MySQL instances on a single physical machine.
# 				Defaults to MySQL. Case sensitive.
#
# show_compatibility_56
#
# 				cmd line format: 		--show-compatibility-56[={OFF|ON}]
# 				Deprecated: 			Yes (Removed in 8.0.1)
# 				Sys var: 				show_compatibility_56
# 				Scope: 					Global
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				OFF
#
# 				Was used in the transition period during which system and status variable info in
# 				INFORMATION_SCHEMA tables was moved to Performance Schema tables.
#
# 				That transition period ended in MySQL 8.0.1, at which time this variable was removed.
#
# show_create_table_verbosity
#
# 				Cmd line format: 		--show-create-table-verbosity
# 				Introduced: 			8.0.11
# 				Sys var: 				show_create_table_verbosity
# 				Scope: 					Global, Session
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
#
# 				SHOW_CREATE_TABLE normally does not show the ROW_FORMAT table option if the
# 				row format is the default format.
#
# 				Enabling this variable causes SHOW_CREATE_TABLE to display ROW_FORMAT
# 				regardless of whether it is the default format.
#
# show_old_temporals
#
# 				cmd line format: 			--show-old-temporals={OFF|ON}
# 				Deprecated: 				Yes
# 				Sys var: 					show_old_temporals
# 				Scope: 						Global, Session
# 				Dynamic: 					Yes
# 				SET_VAR Hint: 				No
# 				Type: 						Boolean
# 				Default: 					OFF
#
# 				Whether SHOW_CREATE_TABLE output includes comments to flag temporal columns found to be in
# 				pre-5.6.4 format (TIME, DATETIME, and TIMESTAMP columns without support for fractional seconds precision)
#
# 				Disabled by default. If enabled, SHOW_CREATE_TABLE output looks as follows:
#
# 				CREATE TABLE `mytbl` (
# 					`ts` timestamp /* 5.5 binary format */ NOT NULL DEFAULT CURRENT_TIMESTAMP,
# 					`dt` datetime /* 5.5 binary format */ DEFAULT NULL,
# 					`t` time /* 5.5 binary format */ DEFAULT NULL
# 				) DEFAULT CHARSET=utf8mb4
#
# 				Output for the COLUMN_TYPE column of the INFORMATION_SCHEMA.COLUMNS table is affected similarly.
#
# 				Deprecated.
#
# skip_external_locking
#
# 				cmd line format: 		--skip-external-locking
# 				Sys var: 				skip_external_locking
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				ON
#
# 				This is OFF if mysqld uses external locking (system locking), ON if external locking is disabled.
#  			This affects only MyISAM table access.
#
# 				This variable is set by the --external-locking or --skip-external-locking option.
#
# 				External locking is disabled by default.
#
# 				External locking affects only MyISAM table access.
# 
# skip_name_resolve
#
# 				Cmd line format: 		--skip-name-resolve
# 				Sys var: 				skip_name_resolve
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				OFF
#
# 				This variable is set from the value of the --skip-name-resolve option.
# 				If OFF, mysqld resolves host names when checking client connections.
#
# 				If it is ON, mysqld uses only IP numbers; in this case, all Host column values
# 				in the grant tables must be IP addresses or localhost.
#
# skip_networking
#
# 				cmd line format: 		--skip-networking
# 				Sys var: 				skip_networking
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
#
# 				This is ON if the server permits only local (non-TCP/IP) connections.
# 				On Unix, local connections use a Unix socket file.
#
# 				On Windows, local connections use a named pipe or shared memory.
# 				Can be set to ON with the --skip-networking option.
#
# skip_show_database
#
# 				cmd line format: 		--skip-show-database
# 				Sys var: 				skip_show_database
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
#
# 				Prevents people from using the SHOW_DATABASE statement if they do not have the SHOW_DATABASE priv.
#
# 				This can improve security if you have concerns about users being able to see databases belonging to other users.
# 				Its effect depends on the SHOW_DATABASE priv: 
#
# 				If ON - the SHOW_DATABASES statement is permitted only to users who have the SHOW_DATABASES priv, and the statement displays all DB names.
#
# 				If OFF - SHOW_DATABASES is permitted to all users, but displays the names of only those databases for which the user has the SHOW_DATABASE or other privs.
#
# 				(ANY global priv includes privs for all DBs)
#
# slow_launch_time
#
# 				cmd line format: 		--slow-launch-time=#
# 				Sys var: 				slow_launch_time
# 				Scope: 					Global
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					Integer
# 				Default: 				2
#
# 				If creating a thread takes longer than this many seconds, the server increments the Slow_launch_threads status var.
#
# slow_query_log
#
# 				Cmd line format: 		--slow-query-log
# 				Sys var: 				slow_query_log
# 				Scope: 					Global
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					Boolean
# 				Default: 				OFF
#
# 				Whether the slow query log is enabled. 
#
# 				0/OFF - disables the log
#
# 				1/ON  - enables the log
#
# 				The default value depends on whether the --slow_query_log option is given.
# 				The destination for log output is controlled by the log_output SYS VAR.
#
# 				If log_output is NONE, no log entries are written - even if the log is on.
#
# 				"Slow" is defined by the long_query_time var.
#
# slow_query_log_file
#
# 				Cmd line format: 		--slow-query-log-file=file_name
# 				Sys var: 				slow_query_log_file
# 				Scope: 					Global
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					File name
# 				Default: 				host_name-slow.log
#
# 				The name of the slow query log file. 
# 				Default is <host_name>-slow.log - but the intiial value can be changed with the
# 				--slow_query_log_file option.
#
# socket
#
# 				cmd line format: 		--socket={file_name|pipe_name}
# 				Sys var: 				socket
# 				Scope: 					Global
# 				Dynamic: 				No
# 				SET_VAR Hint: 			No
# 				Type: 					String
# 				Default (Other) 		/tmp/mysql.sock
# 				Default (Windows) 	MySQL
#
# 				On Unix platforms, this var is the name of the socket file that is used for local client connections.
# 				The default is /tmp/mysql.sock (might be /var/lib/mysql for RPMs)
#
# 				On Windows, this var is the name of the named pipe that is used for local client connections. Default is MySQL. (non-case sensitive)
#
# sort_buffer_size
#
# 				cmd line format: 		--sort-buffer-size=#
# 				Sys var: 				sort_buffer_size
# 				Scope: 					Global, Session
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			Yes
# 				Type: 					Integer
# 				Default: 				262144
# 				Min: 						32768
#
# 				Max (64-bit other) 	<a lot>
# 				Max (32-bit other) 	<less>
# 				Max (Windows) 			<same>
#
# 				Each session that must perform a sort allocates a buffer of this size.
# 				sort_buffer_size is not specific to any storage engine and applies in a general manner for
# 				optimization.
#
# 				At minimum the sort_buffer_size value must be large enough to accomodate fifteen tuples in the sort buffer.
# 				Also, increasing the value of max_sort_length may require increasing the value of sort_buffer_size.
#
# 				If you see many Sort_merge_passes per second in SHOW_GLOBAL_STATUS output, you can consider increasing the
# 				sort_buffer_size value to speed up ORDER BY or GROUP BY operations that cannot be improved with query
# 				optimization or improved indexing.
#
# 				The optimizer tries to work out how much space is needed but can allocate more, up to said limit.
# 				Setting it larger than required globally will slow down most queries that sort.
#
# 				Best ot increase as session setting, and only for sessions that need a larger size.
#
# 				On Linux, there are thresholds of 256kb and 2MB where larger values may significantly
# 				slow down memory allocation - so you should consider staying below one of said sizes.
#
# 				The max permissible setting for sort_buffer_size is 4GB-1. Larger values are allowed for 64-bit platforms.
# 				(Except 64-bit Windows, restraints to 4GB-1)
#
# sql_auto_is_null
#
# 				Sys var: 		sql_auto_is_null
# 				Scope: 			Global, Session
# 				Dynamic: 		Yes
# 				SET_VAR Hint: 	Yes
# 				Type: 			Boolean
# 				Default: 		OFF
#
# 				If this is enabled, then after a statement that successfully inserts an automatically generated AUTO_INCREMENT value,
# 				you can find said value with a query of:
#
# 				SELECT * FROM <tbl_name> WHERE <auto_col> IS NULL
#
# 				If the statement returns a row, the value returned is the same as if you invoked the LAST_INSERT_ID() function.
#
# 				If no AUTO_INCREMENT value was successfully inserted, the SELECT statement returns no row.
#
# 				The beavior of retrieving an AUTO_INCREMENT value by using an IS_NULL comparison is used by some
# 				ODBC programs, such as Access.
#
# 				This beavior can be disabled by setting sql_auto_is_null to OFF.
#
# sql_big_selects
#
# 				Sys var: 		sql_big_selects
# 				Scope: 			Global, Session
# 				Dynamic: 		Yes
# 				SET_VAR Hint: 	Yes
# 				Type: 			Boolean
# 				Default: 		ON
#
# 				If set to OFF, MySQL aborts SELECT statements that are likely to take a long time to execute (statements that estimate > rows cmp. to max_join_size)
#
# 				Useful when an inadivsable WHERE statement has been issued.
# 				The default value for a new connection is ON, which permits all SELECT statements.
#
# 				If you set the max_join_size SYS_VAR to a value other than DEFAULT, sql_big_selects is set to OFF.
#
# sql_buffer_result
#
# 				Sys var: 		sql_buffer_result
# 				Scope: 			Global, Session
# 				Dynamic: 		Yes
# 				SET_VAR Hint: 	Yes
# 				Type: 			Boolean
# 				Default: 		OFF
#
# 				If enabled, sql_buffer_result forces results from SELECT statements to be put into temporary tables.
#
# 				This helps MySQL free the table locks early and can be beneficial in cases where it takes a long time
# 				to send results to the client. The default value is OFF.
#
# sql_log_off
#
# 				Sys var: 		sql_log_off
# 				Scope: 			Global, Session
# 				Dynamic: 		Yes
# 				SET_VAR Hint: 	No
# 				Type: 			Boolean
# 				Default: 		OFF
# 				Valid: 			OFF (enable logging), ON (disable logging)
#
# 				Controls whether logging to the general query log is disabled for the current session
# 				(assuming that the general query log itself is enabled)
#
# 				The default value is OFF (that is, enable logging).
#
# 				To disable or enable general query logging for the current session, set the session sql_log_off variable
# 				to ON or OFF.
#
# 				Restricted ops. Reqs privs enough for restricted session vars.
#
# sql_mode
#
# 				cmd line format: 		--sql-mode=name
# 				Sys var: 				sql_mode
# 				Scope: 					Global, Session
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			Yes
# 				Type: 					Set
# 				Default (>= 8.0.11) 	ONLY_FULL_GROUP_BY
# 											STRICT_TRANS_TABLES
# 											NO_ZERO_IN_DATE
# 											NO_ZERO_DATE
# 											ERROR_FOR_DIVISION_BY_ZERO
# 											NO_ENGINE_SUBSTITUTION
#
# 				Default (<= 8.0.4) 	ONLY_FULL_GROUP_BY 
# 											STRICT_TRANS_TABLES
# 											NO_ZERO_IN_DATE
# 											NO_ZERO_DATE
# 											ERROR_FOR_DIVISION_BY_ZERO
# 											NO_AUTO_CREATE_USER
# 											NO_ENGINE_SUBSTITUTION
#
# 				Valid (>= 8.0.11) 	ALLOW_INVALID_DATES
# 											ANSI_QUOTES
# 											ERROR_FOR_DIVISION_BY_ZERO
# 											HIGH_NOT_PRECEDENCE
# 											IGNORE_SPACE
# 											NO_AUTO_VALUE_ON_ZERO
# 											NO_BACKSLASH_ESCAPES
# 											NO_DIR_IN_CREATE
# 											NO_ENGINE_SUBSTITUTION
# 											NO_UNSIGNED_SUBTRACTION
# 											NO_ZERO_DATE
# 											NO_ZERO_IN_DATE
# 											ONLY_FULL_GROUP_BY
# 											PAD_CHAR_TO_FULL_LENGTH
# 											PIPES_AS_CONCAT
# 											REAL_AS_FLOAT
# 											STRICT_ALL_TABLES
# 											STRICT_TRANS_TABLES
# 											TIME_TRUNCATE_FRACTIONAL
#
# 				Valid (>= 8.0.1, 		ALLOW_INVALID_DATES 
# 						 <= 8.0.4) 		ANSI_QUOTES
# 											ERROR_FOR_DIVISION_BY_ZERO
# 											HIGH_NOT_PRECEDENCE
# 											IGNORE_SPACE
# 											NO_AUTO_CREATE_USER
# 											NO_AUTO_VALUE_ON_ZERO
# 											NO_BACKSLASH_ESCAPES
# 											NO_DIR_IN_CREATE
# 											NO_ENGINE_SUBSTITUION
# 											NO_FIELD_OPTIONS
# 											NO_KEY_OPTIONS
# 											NO_TABLE_OPTIONS
# 											NO_UNSIGNED_SUBTRACTION
# 											NO_ZERO_DATE
# 											NO_ZERO_IN_DATE
# 											ONLY_FULL_GROUP_BY
# 											PAD_CHAR_TO_FULL_LENGTH
# 											PIPES_AS_CONCAT
# 											REAL_AS_FLOAT
# 											STRICT_ALL_TABLES
# 											STRICT_TRANS_TABLES
# 											TIME_TRUNCATE_FRACTIONAL
#
# 				Valid (8.0.0) 			ALLOW_INVALID_DATES
# 											ANSI_QUOTES
# 											ERROR_FOR_DIVISION_BY_ZERO
# 											HIGH_NOT_PRECEDENCE
# 											IGNORE_SPACE
# 											NO_AUTO_CREATE_USER
# 											NO_AUTO_VALUE_ON_ZERO
# 											NO_BACKSLASH_ESCAPES
# 											NO_DIR_IN_CREATE
# 											NO_ENGINE_SUBSTITUTION
# 											NO_FIELD_OPTIONS
# 											NO_KEY_OPTIONS
# 											NO_TABLE_OPTIONS
# 											NO_UNSIGNED_SUBTRACTION
# 											NO_ZERO_DATE
# 											NO_ZERO_IN_DATE
# 											ONLY_FULL_GROUP_BY
# 											PAD_CHAR_TO_FULL_LENGTH
# 											PIPES_AS_CONCAT
# 											REAL_AS_FLOAT
# 											STRICT_ALL_TABLES
# 											STRICT_TRANS_TABLES
#
# 				The current SQL mode, can be set dynamically.
#
# 				Can be configured during install/Options.
#
#  											
# sql_notes
#
# 				Sys var: 		sql_notes
# 				Scope: 			Global, Session
# 				Dynamic: 		yes
# 				SET_VAR Hint: 	No
# 				Type: 			Boolean
# 				Default: 		ON
#
# 				If enabled (by default), warnings of Note level increment warning_count and the server records them.
# 				If disabled, Note warnings do not increment warning_count and the server does not record them.
#
# 				mysqldump includes output to disable this variable so that reloading the dump file does not produce
# 				warnings for events that do not affect the integrity of the reload ops.
#
# sql_quote_show_create
#
# 				Sys var: 		sql_quote_show_create
# 				Scope: 			Global, Session
# 				Dynamic: 		Yes
# 				SET_VAR Hint: 	No
# 				Type: 			Boolean
# 				Default: 		ON
#
# 				If enabled (the default), the server quotes identifiers for SHOW_CREATE_TABLE and SHOW_CREATE_DATABASE statements.
#
# 				If disabled, quoting is disabled.
# 				Enabled by default so that replication works for identifiers that require quoting.
#
# sql_require_primary_key
#
# 				Cmd line format: 		--sql-require-primary-key[={OFF|ON}]
# 				Introduced: 			8.0.13
# 				Sys var: 				sql_require_primary_key
# 				Scope: 					Global, Session
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			Yes
# 				Type: 					Boolean
# 				Default: 				OFF
#
# 				Whether statements that create new tables or alter the structure of existing tables enforce the requirement that tables have a primary key.
#
# 				Setting this is a restricted ops.
#
# 				Enabling this variable helps avoid performance probblems in row-based replication that can occur when tables
# 				have no primary key.
#
# 				Suppose that a table has no primary key and an update or delete modifies multiple rows.
#
# 				On the master server, this ops can be performed using a single table scan but, when replicate
# 				using row-based replication, results in a table scan for each row to be modified on the slave.
#
# 				With a primary key, these table scans do not occur.
#
# 				sql_require_primary_key applies to both base tables and TEMPORARY tables, and changes to its
# 				value are replicated to slave servers.
#
# 				When enabled, sql_require_primary_key has these effects:
#
# 					Attempts to create a new table with no primary key fail with an error.
#
# 					This includes CREATE TABLE ... LIKE. It also includes CREATE TABLE ... SELECT,
# 					unless the CREATE TABLE includes a primary key def.
#
# 					Attempts to drop the primary key from an existing table fail with an error, with the exception
# 					that dropping the primary key and adding a primary key in the same ALTER TABLE statement is permitted.
#
# 					Dropping the primary key fails even if the table also contains a UNIQUE NOT NULL index.
# 
# 					Attempts to import a table with no primary key fail with an error.
#
# sql_safe_updates
#
# 					Sys var: 		sql_safe_updates
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Boolean
# 					Default: 		OFF
#
# 					If this variable is enabled, UPDATE and DELETE statements that do not use a key in the WHERE clause or a LIMIT clause
# 					produce an error.
#
# 					This makes it possible to catch UPDATE and DELETE statements where keys are not used properly and that would
# 					probably change or delete a large number of rows.
#
# 					For the mysql client, sql_safe_updates can be enabled by using the --safe-updates option.
#
# sql_select_limit
#
# 					Sys var: 		sql_select_limit
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Integer
#
# 					Max number of rows to return from SELECT statements.
#
# 					Default value for a new connection is the max number of rows that the server
# 					permits per table.
#
# 					Typical default values are (2^32)-1 or (2^64)-1.
#
# 					If you have changed the limit, the default value can be restored by assigning a value of DEFAULT.
#
# 					If a SELECT has a LIMIT clause, the LIMIT takes precedence over the value of sql_select_limit.
#
# sql_warnings
#
# 					Sys var: 		sql_warnings
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Boolean
# 					Default: 		OFF
#
# 					Controls whether single-row INSERT statements produce an information string if warnings occur.
# 					Default is OFF.
#
# 					Turn to ON for info strings.
#
# ssl_ca
#
# 					cmd line: 		--ssl-capath=dir_name
# 					Sys var: 		ssl_capath
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			Dir name
#
# 					Path to a dir that contains trusted SSL CA certs in PEM format.
#
# ssl_cert
#
# 					Cmd line: 		--ssl-cert=file_name
# 					Sys var: 		ssl_cert
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			File name
#
# 					Name of the SSL cert to use for establishing a secure connection.
#
# ssl_cipher
#
# 					Cmd line: 		--ssl-cipher=name
# 					Sys var: 		ssl_cipher
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			String
# 					
# 					List of permitted ciphers for SSL encryption.
#
# ssl_crl
#
# 					cmd line: 		--ssl-crl=file_name
# 					Sys var: 		ssl_crl
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			File name
#
# 					Path to a file containing cert revocation lists in PEM format.
# 					Revocation lists work for MySQL distributions compiled using OpenSSL. (but not wolfSSL)
#
# ssl_crlpath
#
# 					cmd line: 		--ssl-crlpath=dir_name
# 					Sys var: 		ssl_crlpath
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			Dir name
#
# 					The path to a dir that contains files containing cert revocation lists in PEM format.
# 					Revocation lists work for MySQL distributions compiled using OpenSSL (but not wolfSS)
#
# ssl_fips_mode
#
# 					cmd line format: 		--ssl-fips-mode={OFF|ON|STRICT}
# 					Introduced: 			8.0.11
# 					Sys var: 				ssl_fips_mode
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Enumeration
# 					Default: 				OFF
# 					Valid: 					OFF (or 0), ON (or 1), STRICT (or 2)
#
# 					Controls whether to enable FIPS mode on the server side. 
#
# 					The ssl_fips_mode system variable differs from other --ssl-xxx options
# 					in that it is not used to control whether the server permits encrypted connections,
# 					but rather to affect which cryptographic ops are permitted.
#
# 					These ssl_fips_mode values are permitted:
#
# 						OFF (or 0): Disable FIPS mode.
#
# 						ON (or 1): Enable FIPS mode.
# 
# 						STRICT (or 2): Enable "strict" FIPS mode.
#
# 					Note: If the OpenSSL FIPS Object Module is N/A, the only permitted value for ssl_fips_mode is OFF.
# 							In this case, setting ssl_fips_mode to ON or STRICT at startup causes the server to produce
# 							an error message and exit.
#
# ssl_key
#
# 					cmd line format: 		--ssl-key=file_name
# 					Sys var: 				ssl_key
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					File name
#
# 					The name of the SSL key file to use for establishing a secure connection.
#
# stored_program_cache
#
# 					cmd line format: 		--stored-program-cache=#
# 					Sys var: 				stored_program_cache
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				256
# 					Min: 						16
# 					Max: 						524288
#
# 					Sets a soft upper limit for the number of cached stored routines per connection.
#
# 					The value of this variable if specified in terms of the number of stored routines held
# 					in each of the two caches maintained by the MySQL Server for, respectively, stored procedures
# 					and stored functions. 				
#
# 					Whenever a stored routine is executed this cache size is checked before the first or top-level
# 					statement in the routine is parsed; if the number of routines of the same type (stored procedures or
#  				stored functions according to which is being executed) exceeds the limit specified by this var,
# 					the corresponding cache is flushed and memory previously allocated for cached objects is freed.
#
# 					This allows for the cache to be flushed safely, even when there are dependencies between stored
# 					routines.
#
# 					The stored procedure and stored function cache exists in parallel with the stored program definition
# 					cache partition of the dictionary object cache.
#
# 					The stored procedure and stored function caches are per connection, while the stored program
# 					definition cache is shared. The existence of objects in the stored procedure and stored function
# 					caches have no dependence on the existence of objects in the stored program definition cache and vice
# 					versa.
#
# 		
# stored_program_definition_cache
#
# 					Cmd line format: 		--stored-program-definition-cache=N
# 					Sys var: 				stored_program_definition_cache
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				256
# 					Min: 						256
# 					Max: 						524288
#
# 					Defines a limit for the number of stored program definition objects, both used
# 					and unused, that can be kept in the dictionary object cache.
#
# 					Unused stored program definition objects are only kept in the dictionary object cache
# 					when the number in use is less than the capacity defined by stored_program_definition_cache
#
# 					A setting of 0 means that stored program definition objects are only kept in the dictionary object
# 					cache while they are in use.
#
# 					The stored program definition cache partition exists in parallel with the stored procedure and
# 					stored function caches that are configured using the stored_program_cache option.
#
# 					The stored_program_cache option sets a soft upper limit for the number of cached stored procedures
# 					or functions per connection, and the limits is checked each time a connection executes a stored
# 					procedure or function.
#
# 					The stored program definition cache partition, on the other hand, is a shared cache that stores
# 					stored program definition objects for other purposes.
#
# 					The existence of objects in the stored program definition cache partition has no dependence
# 					on the existence of objects in the stored procedure cache or stored function cache, and vice versa.
#
# super_read_only
#
# 					cmd line format: 		--super-read-only[={OFF|ON}]
# 					Sys var: 				super_read_only
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Boolean
# 					Default: 				OFF
#
# 					If the read_only SYS_VAR is enabled, the server permits client updates only from users who have
# 					the SUPER priv.
#
# 					If the super_read_only SYS_VAR is also enabled, the server prohibits client updates even from
# 					users who have SUPER privs.
#
# 					Changes to super_read_only on a master server are not replicated to slave servers.
# 					The value can be set on a slave server independent of the setting on the master.
#
# syseventlog.facility
#
# 					Cmd line format: 		--syseventlog.facility=value
# 					Introduced: 			8.0.13
# 					Sys var: 				syseventlog.facility
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					String
# 					Default: 				daemon
#
# 					The facility for error log output written to syslog (what type of program is sending the message)
# 					This variable is unavailable unless the log_sink_syseventlog error log component is installed.
#
# 					Permitted values can vary per OS, consult your syslog documentation.
#
# 					Does not exist on Windows.
#
# syseventlog.include_pid
#
# 					Cmd line format: 		--syseventlog.include-pid[={0|1}]
# 					Introduced: 			8.0.13
# 					Sys var: 				syseventlog.include_pid
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Boolean
# 					Default: 				ON
#
# 					Whether to include the server process ID in each line of error log output written to syslog.
# 					This var is unavailable unless the log_sink_syseventlog error log component is installed.
#
# 					Does not exist on Windows.
#
# syseventlog.tag
#
# 					Cmd line format: 		--syseventlog.tag=tag
# 					Introduced: 			8.0.13
# 					Sys Var: 				syseventlog.tag
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					String
# 					Default: 				empty string
#
# 					The tag to be added to the server identifier in error log output written to syslog or 
# 					the Windows Event Log.
#
# 					This var is unavailable unless the log_sink_syseventlog error log component is installed.
#
# 					By default, no tag is set - so the server identifier is simply MySQL on Windows,
# 					and mysqld on other platforms.
#
# 					If a tag value of <tag> is specified, it is appended to the server identifier with
# 					a leading hyphen, resulting in a syslog identifier of mysqld-<tag> (or MySQL-<tag> on Windows)
# 					
# 					On Windows, to use a tag that does not already exist, the server must be run from an account
# 					with Administrator privs, to permit creation of a registry entry for the tag.
#
# 					Elevated privs are not required if the tag already exists.
#
# system_time_zone
#
# 					Sys var: 			system_time_zone
# 					Scope: 				Global
# 					Dynamic: 			No
# 					SET_VAR Hint: 		No
# 					Type: 				String
#
# 					The server system time zone. When the server begins executing, it inherits a time zone
# 					setting from the machine defaults, possibly modified by the environment of the account
# 					used for running the server or the startup script.
#
# 					The value is used to set system_time_zone. Typically the time zone is specified by the
# 					TZ environment variable.
#
# 					It also can be specified using the --timezone option of the mysqld_safe script.
#
# 					The system_time_zone variable differs from time_zone. Although they might have the same value,
# 					the latter variable is used to initialize the time zone for each client that connects.
#
# table_definition_cache
#
# 					Sys var: 			table_definition_cache
# 					Scope: 				Global
# 					Dynamic: 			Yes
# 					SET_VAR Hint: 		No
# 					Type: 				Integer
# 					Default: 			-1 (Autosizing;do not assign this literal value)
# 					Min: 					400
# 					Max: 					524288
#
# 					The number of table defs that can be stored in the def cache. 
#
# 					If you use a large number of tables, you can create a large table def cache to speed up opening of tables.
# 
#  				The table definition cache takes less space and does not use file descriptors, unlike the normal table cache.
# 					The minimum value is 400.
#
# 					The default value is based on the following formula, capped to a limit of 2000:
#
# 						MIN(400 + table_open_cache / 2, 2000)
#
# 					For InnoDB, table_definition_cache acts as a soft limit for the number of open table instances in the InnoDB
# 					data dir cache.
#
# 					If the number of open table instances exceed the table_definition_cache setting, the LRU mechanism begins to mark
# 					table instances for eviction and eventually removes them from the data dictionary cache.
#
#					The limit helps address situations in which significant amounts of memory would be used to cache
# 					rarely used table instances until the next server restart.
#
# 					The number of table instances with cached metadata could be higher than the limit defined by 
# 					table_definition_cache, because parent and child table instances with foreign key relationships
# 					are not placed on the LRU list and are not subject to eviction from memory.
#
# 					Additionally, table_definition_cache defines a soft limit for the number of InnoDB file-per-table tablespaces
# 					that can be open at one time, which is also controlled by innodb_open_files.
#
# 					If both table_definition_cache and innodb_open_files are set, the highest setting is used.
# 					If neither variable is set, table_definition_cache, which has a higher default value is used.
#
# 					If the number of open tablespace file handles exceeds the limit defined by table_definition_cache
# 					or innodb_open_files, the LRU mechanism searches the tablespace file LRU list for files that are
# 					fully flushed and are not currently being extended.
#
# 					The process is performed each time a new tablespace is opened. If there are no "inactive" tablespaces,
# 					no tablespace files are closed.
#
# 					The table definition cache exists in parallel with the table definition cache partition of the dictionary
# 					object cache.
#
# 					Both caches store table definitions but serve different parts of the MySQL server.
# 					Objects in one cache have no dependence on the existence of objects in the other.
#
# 	
# table_open_cache
#
# 					Sys var: 		table_open_cache
# 					Scope: 			Global
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Integer
# 					Default (>= 8.0.4) 4000
# 					Default (<= 8.0.3) 2000
# 					Min: 				1
# 					Max: 				524288
#
# 					Number of open tables for all threads. Increasing this value increases the number of file descriptors
# 					that mysqld requires. You can check whether you need to increase the table cache by checking
# 					the Opened_tables STATUS_VAR.
#
# 					If the value of Opened_tables is large and you do not use FLUSH_TABLES often (which just forces all tables
# 					to be closed and reopened), then you should increase the value of the table_open_cache variable.
#
# table_open_cache_instances
#
# 					Sys var: 			table_open_cache_instances
# 					Scope: 				Global
# 					Dynamic: 			No
# 					SET_VAR Hint: 		No
# 					Type: 				Integer
# 					Default: 			16
# 					Min: 					1
# 					Max: 					64
#
# 					Number of open tables cache instances. 
#
# 					To improve scalability by reducing contention among sessions, the open tables cache 
# 					can be partitioned into several smaller cache instances of size table_open_cache/table_open_cache_instances.
#
# 					A session needs to lock only one instance to access it for DML statements.
#
# 					This segments cache access among instances, permitting higher performance for
# 					operations that use the cache when there are many sessions accessing tables.
#
# 					(DDL statements still require a lock on the entire cache, but such statements are much less
# 					frequent than DML statements.)
#
# 					A value of 8 or 16 is recommended on systems that routinely use 16 or more cores.
#
# temptable_max_ram
#
# 					cmd line format: 		--temptable-max-ram=#
# 					Introduced: 			8.0.2
# 					Sys Var: 				temptable_max_ram
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				1073741824
# 					Minimum: 				2097152
# 					Max: 						2^64-1
#
# 					Defines the max amount of memory that can be occupied by the TempTable
# 					storage engine before it starts storing data on disk.
#
# 					Default is 1 GiB.
#
# thread_cache_size
#
# 					cmd line format: 		--thread-cache-size=#
# 					Sys Var: 				thread_cache_size
# 					scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				-1 (autosizing)
# 					Min: 						0
# 					Max: 						16384
#
# 					How many threads the server should cache for reuse. When a client disconnects,
# 					the client's threads are put in the cache if there are fewer than thread_cache_size
# 					threads there.
#
# 					Requests for threads are satisfied by reusing threads taken from the cache if possible,
# 					and only when the cache is empty is a new thread created.
#
# 					This variable can be increased to improve performance if you have a lot of new connections.
# 					Normally, this does not provide a notable performance improvement if you have a good
# 					thread implementation.
#
# 					However, if your server sees hundreds of connections per second you should normally
# 					set thread_cache_size high enough so that most new connections use cached threads.
#
# 					By examining the difference between the Connections and Threads created status variables,
# 					you can see how efficient the thread cache is.
#
# 					The default value is based on the following formula, capped to a limit of 100:
#
# 						8 + (max_connections / 100)
#
# thread_handling
#
# 					cmd line format: 		--thread-handling=name
# 					Sys var: 				thread_handling
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					Enumeration
# 					Default: 				one-thread-per-connection
# 					Valid: 					no-threads, one-thread-per-connection, loaded-dynamically
#
# 					The thread-handling model used by the server for connection threads.
# 					The permissible values are:
#
# 					 no-threads (the server uses a single thread to handle one connection) (useful for debugging under Linux)
# 					
# 					 one-thread-per-connection (the server uses one thread to handle each client connection)
# 					 
# thread_pool_algorithm
#
# 					cmd line format: 		--thread-pool-algorithm=#
# 					introduced: 			8.0.11
# 					Sys var: 				thread_pool_algorithm
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				0
# 					Min: 						0
# 					Max: 						1
#
# 					This var controls which algorithm the thread pool plugin uses:
#
# 						A value of 0 (the default) uses a conservative low-concurrency algorithm which is most well tested and stable.
#
# 						A value of 1 increases the concurrency and uses a more aggressive algo which at times can perform 5-10% better,
# 						on optimal thread counts, but has degrading performance as the number of connections increases. (Experimental, not supported)
#
# 					Available only if the thread pool plugin is enabled.
# 
# thread_pool_high_priority_connection
#
# 					cmd line format: 		--thread-pool-high-priority-connection=#
# 					Introduced: 			8.0.11
# 					Sys var: 				thread_pool_high_priority_connection
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				0
# 					Min: 						0
# 					Max: 						1
#
# 					Affects queuing of new statements prior to execution.
#
# 					If the value is 0 (false, default) - statement queuing uses both the low-prio
# 					and high-prio queues.
#
# 					If the value is 1 (true), queued statements always go to the high prio queue.
#
# 					Only available if the thread pool plugin is enabled.
#
# thread_pool_max_unused_threads
#
# 					cmd line format: 		--thread-pool-max-unused-threads=#
# 					introduced: 			8.0.11
# 					Sys Var: 				thread_pool_max_unused_threads
# 					Scope: 					Global
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				0
# 					Min: 						0
# 					Max: 						4096
#
# 					Max permitted number of unused threads in the thread pool.
# 					This variable makes it possible to limit the amount of memory used by sleeping threads.
#
# 					A value of 0 (default) means no limit on the number of sleeping threads.
#
# 					A value of N where N is greater than 0, means 1 consumer thread and N-1 reserve threads.
#
# 					In this case, if a thread is ready to sleep but the number of sleeping threads is already at maximum,
# 					the thread exits rather than going to sleep.
#
# 					A sleeping thread is either sleeping as a consumer thread or a reserve thread.
# 					The thread pool permits one thread to be the consumer thread when sleeping.
#
# 					if a thread goes to sleep and there is no existing consumer thread, it will sleep as a consumer thread.
#
# 					When a thread must be woken up, a consumer thread is selected if there is one.
# 					A reserve thread is selected only when there is no consumer thread to wake up.
#
# 					Only available if the thread pool plugin is enabled.
#
# thread_pool_prio_kickup_timer
#
# 					cmd line format: 		--thread-pool-prio-kickup-timer=#
# 					Introduced: 			8.0.11
# 					Sys var: 				thread_pool_prio_kickup_timer
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				1000
# 					Min: 						0
# 					Max: 						<a lot>
#
# 					Affects statements waiting for execution in the low-prio queue.
# 					The value is the number of MS before a waiting statement is moved to the high-prio queue.
#
# 					Default is 1000 ms (1 sec). Range is 0 to 2^32-2
#
# 					Only available if thread plugin is enabled.
#
# thread_pool_size
#
# 					cmd line format: 		--thread-pool-size=#
# 					Introduced: 			8.0.11
# 					Sys var: 				thread_pool_size
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				16
# 					Min: 						1
# 					Max: 						64
#
# 					Number of thread groups in the thread pool. 
# 					This is the most important parameter controlling thread pool performance.
#
# 					It affects how many statements can execute simultaneously.
#
# 					Defaults to 16, with a range from 1 to 64. Must be within range, plugin won't load and a error is written to the log.
#
# 					Only available if the thread pool plugin is enabled.
#
# thread_pool_stall_limit
#
# 					cmd line format: 		--thread-pool-stall-limit=#
# 					Introduced: 			8.0.11
# 					Sys var: 				thread_pool_stall_limit
# 					Scope: 					Global
# 					Dynamic: 				Yes
## 				SET_VAR Hint: 			No
# 					Type: 					Integer
## 				Default: 				6
# 					Min: 						4
# 					Max: 						600
#
# 					Affects executing statements. 
#
# 					The value is the amount of time a statement has to finish after starting to execute before it becomes
# 					defined as stalled, at which point the thread pool permits the thread group to begin
# 					executing another statement.
#
# 					The value is measured in 10 milliseconds units, so a value of 6 (default),
# 					means 60ms.
#
# 					The range of values is 4 to 600 (40ms to 6s).
#
# 					Short wait values permits threads to start more quickly.
# 					Short values are also better for avoiding deadlock situations.
#
# 					Long wait values are useful for workloads that include long-running statements,
# 					to avoid starting too many new statements while the current ones execute.
#
# 					Only available if thread pool plugin is enabled.
#
# thread_stack
#
# 					cmd line: 			--thread-stack=#
# 					Sys var: 			thread_stack
# 					Scope: 				Global
# 					Dynamic: 			No
# 					SET_VAR Hint: 		No
# 					Type: 				Integer
# 					Default (64-bit)  262144
# 					Default (32-bit) 	196608
# 					Min: 					131072
# 					Max (64-bit) 		<a lot>
# 					Max (32-bit) 		<less>
#
# 					Block Size: 		1024
#
# 					The stack size for each thread. Default is 192KB (256KB for 64-bit Systems) is large enough for most ops.
#
# 					If the thread stack size is too small, it limits the complexity of the SQL statements that the server can handle,
# 					the recursion depth of stored procedures and other memory-consuming actions.
#
# time_format - Removed in 8.0.3
#
# time_zone 
#
# 					Sys var: 		time_zone
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			String
#
# 					The current time zone. 
#
# 					This variable is used to initialize the time zone for each client that connects.
# 					By default, the initial value of this is 'SYSTEM' (basically use the system_time_zone)
#
# 					Can be specified explicitly at server startup with the --default-time-zone option.
#
# 					NOTE: If set to SYSTEM, every MySQL function call that requires a timezone calc, makes a system lib call to find out the
# 							current system timezone. May be protected by a global mutex, resulting on contention.
#
# timestamp
#
# 					Sys var: 		timestamp
# 					Scope: 			Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Numeric
#
# 					Set the time for this client. 
#
# 					This is used to get the original timestamp if you use the binary log to restore rows.
# 					<timestamp_value> should be a Unix epoch timestamp (a value like that returned by UNIX_TIMESTAMP() - not a 'YYYY-MM-DD hh:mm:ss'),
# 					or DEFAULT.
#
# 					Setting timestamp to a constant value causes it to retain that value until it is changed again.
# 					Setting timestamp to DEFAULT causes its value to be the current date and time as of the time it is accessed.
#
# 					In MySQL 8.0, timestamp is a DOUBLE rather than BIGINT because its value includes a microseconds part.
#
# 					SET timestamp affects the value returned by NOW() but not by SYSDATE().
#					This means that timestamp settings in the binary log have no effect on invocations of
# 					SYSDATE().
#
# 					The server can be started with the --sysdate-is-now option to cause SYSDATE() to be an alias for NOW(),
# 					in which case SET timestamp affects both functions.
#
# tls_version
#
# 					cmd line format: 		--tls-version=protocol_list
# 					Sys_var: 				tls_version
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					String
# 					Default (>= 8.0.11) 	TLSv1, TLSv1.1, TLSv1.2
# 					Default (<= 8.0.4) 	TLSv1, TLSv1.1, TLSv1.2 (OpenSSL), TLSv1, TLSv1.1 (yaSSL)
#
# 					The protocols permitted by the server for encrypted connections.
# 					The value is a comma-separated list containing one or more protocol names.
#
# 					The protocols that can be named for this variable depends on the SSL library used to compile
# 					MySQL.
#
# tmp_table_size
#
# 					cmd line format: 		--tmp-table-size=#
# 					Sys_Var: 				tmp_table_size
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			Yes
# 					Type: 					Integer
# 					Default: 				16777216
# 					Min: 						1024
# 					Max: 						<a lot>
#
# 					Max size of internal in-memory temporary tables. Does not apply to user-created MEMORY tables.
#
# 					The actual limit is determined from whichever of the values of tmp_table_size and max_heap_table_size
# 					is smaller.
#
# 					If an in-memory temporary table exceeds the limit, MySQL automatically converts it to an on-disk
# 					temporary table.
#
# 					The internal_tmp_disk_storage_engine option defines the storage engine used for on-disk temporary tables.
#
# 					Increase the value of tmp_table_size (and max_heap_table_size if necessary) if you do many advanced
# 					GROUP BY queries and you have lots of memory.
#
# 					You can compare the number of internal on-disk temporary tables created to the total number of internal
# 					temp tables created by comparing the values of the Created_tmp_disk_tables and Created_tmp_tables Vars.
#
# tmpdir
#
# 					cmd line format: 		--tmpdir=dir_name
# 					Sys_var: 				tmpdir
# 					Scope: 					Global
# 					Dynamic: 				No
# 					SET_VAR Hint: 			No
# 					Type: 					Dir name
#
# 					The dir used for temp files and temp tables.
#
# 					This var can be set to a list of several paths that are used in round-robin regards.
#
# 					Paths should be separated by : on Unix and ; on Windows.
#
# 					The multiple-directory feature can be used to spread the load between several physical disks.
# 
#	 				If the MySQL server is acting as a replication slave, you should not set tmpdir to point to a dir
# 					on a memory-based file system or to a dir that is cleared when the server host restarts.
# 
# 					A replication slave needs some of its temp files to survive a machine restart so that it can replicate
# 					temporary tables or LOAD_DATA_INFILE operations.
#
# 					If files in the temporary file dir are lost when the server restarts, replication fails.
#
# 					You can set the slave's temp dir using the slave_load_tmpdir variable.
#
# 					In that case, the slave will not use the general tmpdir value and you can set tmpdir to a nonpermanent location.
#
# transaction_alloc_block_size
#
# 					cmd line: 		--transaction-alloc-block-size=#
# 					Sys_var: 		transaction_alloc_block_size
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Integer
# 					Default: 		8192
# 					Min: 				1024
# 					Max: 				131072
# 					Block Size: 	1024
#
# 					Amount in bytes by which to increase a per-transaction memory pool which needs memory.
#
# transaction_isolation
#
# 					cmd line format: 	--transaction-isolation=name
# 					Sys_Var: 			transaction_isolation
# 					Scope: 				Global, Session
# 					Dynamic: 			Yes
# 					SET_VAR Hint: 		No
# 					Type: 				Enumeration
# 					Default: 			REPEATABLE-READ
# 					Valid: 				READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE
#
# 					Default transaction isolation level.
# 					Defaults to REPEATABLE-READ.
#
# 					Can be set directly, or indirectly using the SET_TRANSACTION statement.
#
# 					If you set transaction_isolation directly to an isolation level name that contains a space,
# 					the name should be enclosed with '' and spaces replaced with -
#
# 					SET transaction_isolation = 'READ-COMMITTED';
#
# 					Any unique prefix of a valid value may be used to set the value of this var.
#
# 					The default transaction isolation level can also be set at startup using the --transaction-isolation server option.
#
# 					This var has nonstandard semantics for runtime changes to the session value made using the SET statement.
# 					For most session sys_vars - these statements are the same:
#
# 					SET @@var_name = value;
# 					SET @@session.var_name = value;
#
# 					For transaction_isolation, these semantics apply instead:
#
# 						SET @@transaction_isolation = <value>
#
# 							Not permitted within transactions.
#
# 							Set the value only for the next single transaction within the session.
#
# 						SET @@session.transaction_isolation = <value>
#
# 							Permitted within transactions, but does not affect the current ongoing transaction.
#
# 							Sets the value for all subsequent transactions within the session.
#
# 							If executed between transactions, overrides any preceding SET @@transaction_isolation
# 							statement to set the value for the next transaction.
# 			
# transaction_prealloc_size
#
# 					Cmd line format: 		--transaction-prealloc-size=#
# 					Sys_var: 				transaction_prealloc_size
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Integer
# 					Default: 				4096
# 					Min: 						1024
# 					Max: 						131072
# 					Block size: 			1024
#
# 					There is a per-transaction memory pool from which various transaction-related allocations take memory.
# 					The initial size of the pool in bytes is transaction_prealloc_size.
#
# 					For every allocation that cannot be satisfied from the pool because it has insufficient memory available,
# 					the pool is increased by transaction_alloc_block_size bytes.
#
# 					When the transaction ends, the pool is truncated to transaction_prealloc_size bytes.
#
# 					By making transaction_prealloc_size sufficiently large to contain all statements within a single transaction,
# 					you can avoid many malloc() calls.
#
# transaction_read_only
#
# 					cmd line: 				--transaction-read-only
# 					Sys var: 				transaction_read_only
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			No
# 					Type: 					Boolean
# 					Default: 				OFF
#
# 					Default transaction access mode. The value can be OFF (read/write, default) or ON (read only).
#
# 					Can be set directly, or indirectly using the SET_TRANSACTION statement.
#
# 					To set the default transaction access mode at startup, use the --transaction-read-only server option.
#
# 					This var has nonstandard semantics for runtime changes to the session value made using the SET statement.
# 					For most session sys variables, these statements are equivalent:
#
# 						SET @@var_name = <value>;
# 						SET @@session.var_name = <value>;
#
# 					For transaction_read_only, these semantics apply instead:
#
# 						SET @@transaction_read_only = <value>
#
# 							Not permitted within transactions
#
# 							Sets the value only for the next single transaction within the session.
#
# 						SET @@session.transaction_read_only = <value>
#
# 							Permitted within transactions, but does not affect the current ongoing transaction.
#
# 							Sets the value for all subsequent transactions within the session.
#
# 							If executed between transactions, overrides any preceding SET @@transaction_read_only statement
# 							to set the value for the next transaction.
# tx_isolation
#
# 					DEPRECATED -> 8.0.3
# 					Sys_var: 		tx_isolation
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Enumeration
# 					Default: 		REPEATABLE-READ
# 					Valid: 			READ-UNCOMMITTED, READ-COMMITTED, REPEATABLE-READ, SERIALIZABLE
#
# 					Removed in 8.0.3 -> use transaction_isolation instead.
# 
# tx_read_only
#
# 					Deprecated ->  8.0.3
# 					Sys_var: 	   tx_read_only
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Boolean
# 					default: 		OFF
#
# 					Removed in 8.0.3 -> use transaction_read_only instead.
#
# unique_checks
#
# 					Sys var: 		unique_checks
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Boolean
# 					Default: 		ON
#
# 					If set to 1 (default), uniqueness checks for secondary indexes in InnoDB tables are performed.
# 					If set to 0, storage engines are permitted to assume that duplicate keys are not present in input data.
#
# 					If you know for certain that your data does not contain uniqueness violations, you can set this 
# 					to 0 to speed up large table imports to InnoDB.
#
# 					Setting this variable to 0 does not <require> storage engines to ignore duplicate keys.
# 					An engine is still permitted to check for them and issue duplicate-key errors if it 
# 					detects them.
#
# updatable_views_with_limit
#
# 					Cmd line: 		--updatable-views-with-limit=#
# 					Sys var: 		updatable_views_with_limit
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Boolean
# 					Default: 		1
#
# 					This var controls whether updates to a view can be made when the view does not contain
# 					all columns of the primary key defined in the underlying table, if the update statement
# 					contains a LIMIT clause.
#
# 					(Such updates often are generated by GUI tools). An update is an UPDATE or DELETE statement.
#
# 					Primary key here means a PRIMARY KEY, or a UNIQUE index in which no column can contain NULL.
#
# 					The variable can have two values:
#
# 						1 or YES: Issue a warning only (not an error message). Default.
#
# 						0 or NO:  Prohibit the update.
#
# use_secondary_engine
#
# 					Introduced: 	8.0.13
# 					Sys_var: 		use_secondary_engine
# 					Scope: 			Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	Yes
# 					Type: 			Enumeration
# 					Default: 		OFF
# 					Valid: 			OFF, ON, FORCE
#
# 					For future use.
#
# validate_password.<xxx>
#
# 					The validate_password components implements a set of system variables having names of the form
# 					validate_password.<xxx>
#
# 					Affect password testing by that component.
#
# validate_user_plugins
#
# 					Sys_var: 		validate_user_plugins
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			Boolean
# 					Default: 		ON
#
# 					If this var is enabled (default), the server checks each user account and produces a warning if conditions are
# 					found that would make the account unusable:
#
# 						The account requires an authentication plugin that is not loaded.
#
# 						The account requires the sha256_password or caching_sha2_password authentication plugin
# 						but the server was started with neither SSL nor RSA enabled as required by the plugin.
#
# 					Enabling validate_user_plugins slows down server initialization and FLUSH PRIVILEGES.
#
# 					If you do not require the additional checking, you can disable this variable at startup
#  				to avoid the performance decrement.
#
# version
#
# 					The version number for the server. The value might also include a suffix indicating server build or
# 					configuration information.
#
# 					-debug indicates that the server was built with debugging support enabled.
#
# version_comment
#
# 					Sys_var: 		version_comment
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			String
#
# 					The CMake configuration program has a COMPILATION_COMMENT option that permits a
# 					comment to be specified when building MySQL.
#
# 					This var contains the value of that comment.
#
# version_compile_machine
#
# 					Sys_var: 		version_compile_machine
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			String
#
# 					Type of the server binary.
#
# version_compile_os
#
# 					Sys_var: 		version_compile_os
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			String
#
# 					The type of OS on which MySQL was built.
#
# version_compile_zlib
#
# 					Introduced: 	8.0.11
# 					Sys_var: 		version_compile_zlib
# 					Scope: 			Global
# 					Dynamic: 		No
# 					SET_VAR Hint: 	No
# 					Type: 			String
#
# 					The version of the compiled-in zlib library.
#
# wait_timeout
#
# 					cmd line: 		--wait-timeout=#
# 					Sys_var: 		wait_timeout
# 					Scope: 			Global, Session
# 					Dynamic: 		Yes
# 					SET_VAR Hint: 	No
# 					Type: 			Integer
# 					Default: 		28800
# 					Min: 				1
# 					Max (Other): 	31536000
# 					Max (Windows): 2147483
#
# 					Number of seconds the server waits for activity on a noninteractive connection before closing it.
#
# 					On thread startup, the session wait_timeout value is initialized from the global wait_timeout value
# 					or from the global interactive_timeout value, depending on the type of client (as defined by the
#  				CLIENT_INTERACTIVE connection option to mysql_real_connect())
#
# 					See also interactive_timeout.
#
# warning_count
#
# 					Number of errors, warnings and notes that resulted from the last statement that generated messages.
# 					Read only.
#
# windowing_use_high_precision
#
# 					Cmd line format: 		--windowing-use-high-precision=#
# 					Introduced: 			8.0.2
# 					Sys_Var: 				windowing_use_high_precision
# 					Scope: 					Global, Session
# 					Dynamic: 				Yes
# 					SET_VAR Hint: 			Yes
# 					Type: 					Boolean
# 					Default: 				ON
#
# 					Whether to compute window ops without loss of precision.
#
# The following section pertains to Using System Variables:
#
# The MySQL server maintains many system variables that configure its operation.
#
# Each sys var has a default. Can be set at server startup using options on the cmd line or in a option file.
#
# Most of them can be changed dynamically while the server is running by means of the SET statement,
# which enables you to modify operation of the server without having to stop and restart it.
#
# Can also use them in expressions.
#
# Many of the sys vars are built in, but can be installed by server plugins or components:
#
# 		System vars implemented by a server plugin are exposed when the plugin is installed and have
# 		names taht begin with the plugin name.
#
# 		For example - audit_log implements a sys_var named audit_log_policy
#
# 		System vars implemented by a server component are exposed when the component is installed and have
# 		names that begin with a component-specific prefix.
#
# 		For instance - log_filter_dragment is a error log filter component that puts in a sys_var of log_error_filter_rules,
# 		full name is dragnet.log_error_filter_rules. Use full name for this.
#
# There are two scopes for sys vars -> global and session.
#
# Global is for overall, systemwide
#
# Session is for individual client conns. A sys var can have both.
#
# 		When the server starts, it initializes each global variable to its default value.
# 		These defaults can be changed by options specified on the cmd line or in an option file.
#
# 		The server also maintains a set of session variables for each client that connects.
#
# 		The client's session variables are initialized at connect time using the current values of 
# 		the corresponding global vars.
#
# 		For example, a client's SQL mode is controlled by the session sql_mode value - initialized when
# 		the client connects to the value of the global sql_mode value.
#
# 		For some system variables, the session value is not intialized from the corresponding global value;
# 		if so, that is indicated in the variable desc.
#
# System var values can be set globally at server startup by using options on the cmd line or in an option file.
# When you use a startup option to set a variable that takes numerical, it can have suffix of one of the following:
#
# 		K - 1024  (kb)
# 		M - 1024^2 (mb)
# 		G - 1024^3 (gb)
# 		T - 1024^4 (tb)
# 		P - 1024^5
# 		E - 1024^6
#
# The following commands starts the server with an InnoDB log file size of 16 MB and a max pack size of 1 GB:
#
# 		mysqld --innodb_log_file_size=16M --max_allowed_packet=1G
#
# Within an option file, they are set as:
#
# 		[mysqld]
# 		innodb_log_file_size=16M
# 		max_allowed_packet=1G
#
# Case insensitive.
#
# To restrict the maximum value to which a system variable can be set at runtime with the SET
# statement, specify this maximum by using an option of the form --maximum-<var_name>=<value> at server startup.
#
# For example, to prevent the value of innodb_log_file_size from being increased to more than 32MB
# at runtime, use the option --maximum-innodb_log_file_size=32M.
#
# Many sys vars are dynamic and can be changed at runtime by using the SET statement.
# To change a sys var with SET, refer to it by name, optionally preceded by a modifier.
#
# A global sys_var:
#
# 		SET GLOBAL max_connections = 1000;
# 		SET @@global.max_connections = 1000;
#
# Persist a global sys var to the mysqld-auto.cnf file (and set the runtime value):
#
# 		SET PERSIST max_connections = 1000;
# 		SET @@persist.max_connections = 1000;
#
# Persist a global system variable to the mysqld-auto.cnf file (without setting the runtime value):
#
# 		SET PERSIST_ONLY back_log = 1000;
# 		SET @@persist_only.back_log = 1000;
#
# Set a session system variable:
#
# 		SET SESSION sql_mode = 'TRADITIONAL';
# 		SET @@session.sql_mode = 'TRADITIONAL';
# 		SET @@sql_mode = 'TRADITIONAL';
#
# Later on, a full showcasing of SET syntax is showcased.
#
# Suffixes for specifying a value multiplier can be used when setting a variable at server startup,
# but not to set the value with SET at runtime.
#
# On the other hand, with SET you can assign a variable's value using an expression, which is not true
# when you set a variable at server startup.
#
# For example, the first of the following line is legal at server startup - but the second is not:
#
# mysql --max_allowed_packet=16M #Legal at server startup
# mysql --max_allowed_packet=16*1024*1024 #Illegal at server startup
#
# Conversely, for SET, second is legal at runtime - first is not:
#
# SET GLOBAL max_allowed_packet=16M;#
# SET GLOBAL max_allowed_packet=16*1024*1024;
#
# NOTE: Some system vars can be enabled with SET by setting them to ON/1 or OFF/0.
# 		  To set it on the cmd line or in an option file - Must be set to 1 or 0.
#
# To display system variable names and values; use the SHOW_VARIABLES statement:
#
# mysql> SHOW VARIABLES;
#
# +-----------------------------------------------------------------------------+
# | Variable_name 					| 			Value 										  |
# +-----------------------------------------------------------------------------+
# | 										| 															  |
# | auto_increment_increment 		| 			1 												  |
# | auto_increment_offset 		   | 		   1 												  |
# | automatic_sp_privileges 		| 			ON 											  |
# | back_log 							| 			151 											  |
# | basedir 							| 			/home/mysql/ 								  |
# | binlog_cache_size 				| 			32768 										  |
# | bulk_insert_buffer_size 		| 			8388608 										  |
# | character_set_client 			| 			utf8 											  |
# | character_set_connection 		| 			utf8 											  |
# | character_set_database 		| 			utf8mb4 										  |
# | character_set_filesystem 		| 			binary 										  |
# | character_set_results 			| 			utf8 											  |
# | character_set_server 			| 			utf8mb4 										  |
# | character_set_system 			| 			utf8 											  |
# | character_sets_dir 				| 			/home/mysql/share/mysql/charsets/ 	  |
# | collation_connection 			| 			utf8_general_ci 							  |
# | collation_database 				| 			utf8mb4_0900_ai_ci 						  |
# | collation_server 				| 			utf8mb4_0900_ai_ci 						  |
# ...
# | innodb_autoextend_increment 	| 			8 												  |
# | innodb_buffer_pool_size 		| 			8388608 										  |
# | innodb_commit_concurrency 	| 			0 												  |
# | innodb_concurrency_tickets 	| 			500  											  |
# | innodb_data_file_path 		   | 			ibdata1:10M:autoextend 					  |
# | innodb_data_home_dir 			| 															  |
# ...
# | version 							| 			8.0.1-dmr-log 								  |
# | version_comment 					| 			Source distribution 						  |
# | version_compile_machine 		| 			i686 											  |
# | version_compile_os 				| 			suse-linux 									  |
# | wait_timeout 						| 			28800 										  |
# +-----------------------------------------------------------------------------+
#
# With a LIKE clause, the statement displays only those variables that match the pattern.
# To obtain a specific variable name, use a LIKE clause as follows:
#
# 		SHOW VARIABLES LIKE 'max_join_size';
# 		SHOW SESSION VARIABLES LIKE 'max_join_size';
#
# To get a list of variables whose name match a pattern, use % Wildchar regex matching in a LIKE clause:
#
# 		SHOW VARIABLES LIKE '%size%';
# 		SHOW GLOBAL VARIABLES LIKE '%size%';
#
# Wildcard chars can be used in any pos within the pattern to be matched.
# Stricly speaking, because _ is a wildcard char - you ought to escape it as \_
#
# For SHOW_VARIABLES, if you specify neither GLOBAL nor SESSION, MYSQL returns SESSION values.
#
# The reason for requiring the GLOBAL keyword when setting GLOBAL only vars but not when retrieving them
# is to prevent problems in the future:
#
# 		Were a SESSION var to be removed that has the same name as a GLOBAL var, a client with privs sufficient
# 		to modify global vars might accidentally change the GLOBAL variable rather than just the SESSION var for its own session.
#
# 		Were a SESSION variable to be added with the same name as a GLOBAL variable, a client that intends to change
# 		the GLOBAL variable might find only its own SESSION var changed.
#
# The following covers System Variable Privs:
#
# A system variable can have a global value that affects server operations as a whole, a session value that affects the
# the current session or both.
#
# Many SYS_VAR are dynamic and can be changed at runtime using the SET statement to affect operation of the current
# server instance.
#
# SET can also be used to persist certain global SYS_VAR to the mysqld-auto.cnf file in the data dir,
# to affect server operation for subsequent startups.
#
# RESET_PERSIST removes persisted settings from mysqld-auto.cnf
#
# This section pertains to setting privs required to assign values to SYS_VARs at runtime.
#
# This includes persistence-related privs because some statements that modify sys_var values
# persist those settings to the mysqld-auto.cnf file.
#
# These privs apply to setting global SYS_VAR values:
#
# 		To set a global SYS_VAR at runtime, use the SET_GLOBAL statement, which requires the SYSTEM_VARIABLES_ADMIN or SUPER priv.
#
# 		To persist a global system var to the mysqld-auto.cnf (and set the runtime value), use the SET_PERSIST statement,
# 		which requires the SYSTEM_VARIABLES_ADMIN or SUPER privilege.
#
# 		To persist a global system var to the mysqld-auto.cnf (WITHOUT setting runtime), use the SET_PERSIST_ONLY statement,
# 		which requires the SYSTEM_VARIABLES_ADMIN and PERSIST_RO_VARIABLES_ADMIN privs.
#
# 		To remove a persisted global sys_var from the mysqld-auto.cnf file, use the RESET_PERSIST statement:
# 
# 			For dynamic sys_vars, this statement requires the SYSTEM_VARIABLES_ADMIN or SUPER privilege.
#
# 			For read-only sys_vars, this statement requires the SYSTEM_VARIABLES_ADMIN and PERSIST_RO_VARIABLES_ADMIN privs.
#
# The descriptions for individual SYS_VARs indicate any exceptions to the preceding priv requirements. An example is mandatory_roles.
#
# To set a session sys_var at runtime, use the SET_SESSION statement. In contrast to global sys_vars, setting session sys_vars at runtime
# normally requires no special privs and can be done by any user to affect the current session.
#
# However, for some sys_vars, setting the session values can have effects outside the current session and thus is a restricted
# ops, requiring privs:
#
# (MySQL 8.0.14 >=) - the priv required is SESSION_VARIABLES_ADMIN. However, any user who has SYSTEM_VARIABLES_ADMIN or SUPER effectively
# 							 has SESSION_VARIABLES_ADMIN by implication and need not be granted SESSION_VARIABLES_ADMIN explicitly.
#
# (< 8.0.14 MysQL)  - The priv is SYSTEM_VARIABLES_ADMIN or SUPER.
#
# If a session sys_var is restricted, the var desc. indicates that restriction. Examples include binlog_format, sql_log_bin and sql_log_off
#
# The reason for restricting certain session sys_vars is that changing them can have effects beyond the current session.
#
# For example, setting the session binlog_format or sql_log_bin values affects binary logging for the current session,
# but that may have implications for the integrity of server replication and backups.
#
# SESSION_VARIABLES_ADMIN enables admins to minimize the priv footprint of users who may previously have been granted
# SYSTEM_VARIABLES_ADMIN or SUPER for the purpose of enabling them to modify restricted session sys_vars.
#
# Assume that a admin has created the following role to confer the ability to set restricted session Sys_var:
#
# 		CREATE ROLE set_session_sysvars;
# 		GRANT SYSTEM_VARIABLES_ADMIN ON *.* TO set_session_sysvars;
#
# Any user granted the set_session_sysvars role (and who has that role active) is able to set restricted session sys_vars.
# However, that user is also able to set global sys_vars - which may be undesirable.
#
# By modifying the role to have SESSION_VARIABLES_ADMIN instead of SYSTEM_VARIABLES_ADMIN, the role privs can be
# reduced to the ability to set restricted session sys_vars and nothing else.
#
# i.e:
#
# GRANT SESSION_VARIABLES_ADMIN ON *.* TO set_session_sysvars;
# REVOKE SYSTEM_VARIABLES_ADMIN ON *.* FROM set_session_sysvars;
#
# Modifying the role has an immediate effect. 
#
# Any account granted the set_session_sysvars role no longer has SYSTEM_VARIABLES_ADMIN and is not able to set
# global sys_vars without explicit grants.
#
# A similar GRANT/REVOKE sequence can be applied to any account that was granted SYSTEM_VARIABLES_ADMIN
# directly rather than by means of a role.
#
# The following pertains to Dynamic Sys_Vars:
#
# Many server vars are dynamic and can be set at runtime.
#
# The following pertains to Mysqld in relation to dynamic sys_vars.
#
# Var name 																Var type 						Var scope
# activate_all_roles_on_login 								Boolean 								Global
# audit_log_connection_policy 								Enumeration 						Global
# audit_log_exclude_accounts 									String 								Global
# audit_log_flush 												Boolean 								Global
# audit_log_include_accounts 									String 								Global
# audit_log_read_buffer_size 									Integer 								Varies
#
# audit_log_rotate_on_size 									Integer 								Global
# audit_log_statement_policy 									Enumeration 						Global
# authentication_ldap_sasl_auth_method_name 				String 								Global
# authentication_ldap_sasl_bind_base_dn 					String 								Global
# authentication_ldap_sasl_bind_root_dn 					String 								Global
# authentication_ldap_sasl_bind_root_pwd 					String 								Global
#
# authentication_ldap_sasl_ca_path 							String 								Global
# authentication_ldap_sasl_group_search_attr 			String 								Global
# authentication_ldap_sasl_group_search_filter 			String 								Global
# authentication_ldap_sasl_init_pool_size 				Integer 								Global
# authentication_ldap_sasl_log_status 						Integer 								Global
#
# authentication_ldap_sasl_max_pool_size 					Integer 								Global
# authentication_ldap_sasl_server_host 					String 								Global
# authentication_ldap_sasl_server_port 					Integer 								Global
# authentication_ldap_sasl_tls 								Boolean 								Global
# authentication_ldap_sasl_user_search_attr 				String 								Global
# authentication_ldap_simple_auth_method_name 			String 								Global
# authentication_ldap_simple_bind_base_dn 				String 								Global
# authentication_ldap_simple_bind_root_dn 				String 								Global
#
# authentication_ldap_simple_bind_root_pwd 				String 								Global
# authentication_ldap_simple_ca_path 						String 								Global
# authentication_ldap_simple_group_search_attr 			String 								Global
# authentication_ldap_simple_group_search_filter 		String 								Global
# authentication_ldap_simple_init_pool_size 				Integer 								Global
# authentication_ldap_simple_log_status 					Integer 								Global
#
# authentication_ldap_simple_max_pool_size 				Integer 								Global
# authentication_ldap_simple_server_host 					String 								Global
# authentication_ldap_simple_server_port 					Integer 								Global
# authentication_ldap_simple_tls 							Boolean 								Global
# authentication_ldap_simple_user_search_attr 			String 								Global
# auto_increment_increment 									Integer 								Both
# auto_increment_offset 										Integer 								Both
# autocommit 														Boolean 								Both
# automatic_sp_privileges 										Boolean 								Global
# avoid_temporal_upgrade 										Boolean 								Global
# big_tables 														Boolean 								Both
# binlog_cache_size 												Integer 								Global
# binlog_checksum 												String 								Global
#
# binlog_direct_non_transactional_updates 				Boolean 								Both
# binlog_error_action 											Enumeration 						Global
# binlog_expire_logs_seconds 									Integer 								Global
# binlog_format 													Enumeration 						Both
# binlog_group_commit_sync_delay 							Integer 								Global
# binlog_group_commit_sync_no_delay_count 				Integer 								Global
# binlog_max_flush_queue_time 								Integer 								Global
# binlog_order_commits 											Boolean 								Global
# binlog_row_image=image_type 								Enumeration 						Both
# binlog_row_metadata=metadata_type 						Enumeration 						Global
# binlog_row_value_options 									Set 									Both
# binlog_rows_query_log_events 								Boolean 								Both
# binlog_stmt_cache_size 										Integer 								Global
#
# binlog_transaction_dependency_history_size 			Integer 								Global
# binlog_transaction_dependency_tracking 					Enumeration 						Global
# block_encryption_mode 										String 								Both
# bulk_insert_buffer_size 										Integer 								Both
# character_set_client 											String 								Both
# character_set_connection 									String 								Both
# character_set_database 										String 								Both
# character_set_filesystem 									String 								Both
# character_set_results 										String 								Both
#
# character_set_server 											String 								Both
# check_proxy_users 												Boolean 								Global
# collation_connection 											String 								Both
# collation_database 											String 								Both
# collation_server 												String 								Both
# completion_type 												Enumeration 						Both
# concurrent_insert 												Enumeration 						Global
# connect_timeout 												Integer 								Global
# connection_control_failed_connections_threshold 		Integer 								Global
# connection_control_max_connection_delay 				Integer 								Global
#
# connection_control_min_connection_delay 				Integer 								Global
# cte_max_recursion_depth 										Integer 								Both
# debug 																String 								Both
# debug_sync 														String 								Session
# default_collation_for_utf8mb4 								Enumeration 						Both
# default_password_lifetime 									Integer 								Global
# default_storage_engine 										Enumeration 						Both
# default_tmp_storage_engine 									Enumeration 						Both
# default_week_format 											Integer 								Both
# delay_key_write 												Enumeration 						Global
# delayed_insert_limit 											Integer 								Global
# delayed_insert_timeout 										Integer 								Global
# delayed_queue_size 											Integer 								Global
#
# div_precision_increment 										Integer 								Both
# dragnet.log_error_filter_rules 							String 								Global
# end_markers_in_json 											Boolean 								Both
# enforce_gtid_consistency 									Enumeration 						Global
# eq_range_index_dive_limit 									Integer 								Both
# event_scheduler 												Enumeration 						Global
# executed_gtids_compression_period 						Integer 								Global
# expire_logs_days 												Integer 								Global
# explicit_defaults_for_timestamp 							Boolean 								Both
# flush 																Boolean 								Global
#
# flush_time 														Integer 								Global
# foreign_key_checks 											Boolean 								Both
# ft_boolean_syntax 												String 								Global
# general_log 														Boolean 								Global
# general_log_file 												File name 							Global
# group_concat_max_len 											Integer 								Both
# group_replication_allow_local_disjoint_gtids_join 	Boolean 								Global
# group_replication_allow_local_lower_version_join 	Boolean 								Global
# group_replication_auto_increment_increment 			Integer 								Global
# group_replication_bootstrap_group 						Boolean 								Global
# group_replication_communication_debug_options 		String 								Global
# group_replication_components_stop_timeout 				Integer 								Global
# group_replication_compression_threshold 				Integer 								Global
# group_replication_enforce_update_everywhere_checks 	Boolean 								Global
# group_replication_exit_state_action 						Enumeration 						Global
#
# group_replication_flow_control_applier_threshold 	Integer 								Global
# group_replication_flow_control_certifier_threshold 	Integer 								Global
# group_replication_flow_control_hold_percent 			Integer 								Global
# group_replication_flow_control_max_commit_quota 		Integer 								Global
# group_replication_flow_control_member_quota_percent Integer 								Global
# group_replication_flow_control_min_quota 				Integer 								Global
# group_replication_flow_control_min_recovery_quota 	Integer 								Global
# group_replication_flow_control_mode 						Enumeration 						Global
# group_replication_flow_control_period 					Integer 								Global
# group_replication_flow_control_release_percent 		Integer 								Global
# group_replication_force_members 							String 								Global
# group_replication_group_name 								String 								Global
# group_replication_group_seeds 								String 								Global
#
# group_replication_gtid_assignment_block_size 			Integer 								Global
# group_replication_ip_whitelist 							String 								Global
# group_replication_local_address 							String 								Global
# group_replication_member_expel_timeout 					Integer 								Global
# group_replication_member_weight 							Integer 								Global
# group_replication_poll_spin_loops 						Integer 								Global
# group_replication_recovery_complete_at 					Enumeration 						Global
# group_replication_recovery_get_public_key 				Boolean 								Global
# group_replication_recovery_public_key_path 			File name 							Global
# group_replication_recovery_reconnect_interval 		Integer 								Global
# group_replication_recovery_retry_count 					Integer 								Global
# group_replication_recovery_ssl_ca 						String 								global
# group_replication_recovery_ssl_capath 					String 								Global
#
# group_replication_recovery_ssl_cert 						String 								Global
# group_replication_recovery_ssl_cipher 					String 								Global
# group_replication_recovery_ssl_crl 						String 								Global
# group_replication_recovery_ssl_crlpath 					String 								Global
# group_replication_recovery_ssl_key 						String 								Global
# group_replication_recovery_ssl_verify_server_cert 	Boolean 								Global
# group_replication_recovery_use_ssl 						Boolean 								Global
# group_replication_single_primary_mode 					Boolean 								Global
# group_replication_ssl_mode 									Enumeration 						Global
# group_replication_start_on_boot 							Boolean 								Global
# group_replication_transaction_size_limit 				Integer 								Global
# group_replication_unreachable_majority_timeout 		Integer 								Global
# gtid_executed_compression_period 							Integer 								Global
# gtid_mode 														Enumeration 						Global
# gtid_mode 														Enumeration 						Global
# gtid_next 														Enumeration 						Session
#
# gtid_purged 														String 								Global
# histogram_generation_max_mem_size 						Integer 								Both
# host_cache_size 												Integer 								Global
# identity 															Integer 								Session
# information_schema_stats_expiry 							Integer 								Both
# init_connect 													String 								Global
# init_slave 														String 								Global
# innodb_adaptive_flushing 									Boolean 								Global
# innodb_adaptive_flushing_lwm 								Integer 								Global
# innodb_adaptive_hash_index 									Boolean 								Global
# innodb_adaptive_max_sleep_delay 							Integer 								Global
# innodb_api_bk_commit_interval 								Integer 								Global
# innodb_api_trx_level 											Integer 								Global
# innodb_autoextend_increment 								Integer 								Global
# innodb_background_drop_list_empty 						Boolean 								Global
# innodb_buffer_pool_dump_at_shutdown 						Boolean 								Global
# innodb_buffer_pool_dump_now 								Boolean 								Global
# innodb_buffer_pool_dump_pct 								Integer 								Global
#
# innodb_buffer_pool_filename 								File name 							Global
# innodb_buffer_pool_in_core_file 							Boolean 								Global
# innodb_buffer_pool_load_abort 								Boolean 								Global
# innodb_buffer_pool_load_now 								Boolean 								Global
# innodb_buffer_pool_size 										Integer 								Global
# innodb_change_buffer_max_size 								Integer 								Global
# innodb_change_buffering 										Enumeration 						Global
# innodb_change_buffering_debug 								Integer 								Global
# innodb_checkpoint_disabled 									Boolean 								Global
# innodb_checksum_algorithm 									Enumeration 						Global
# innodb_cmp_per_index_enabled 								Boolean 								Global
# innodb_commit_concurrency 									Integer 								Global
# innodb_compress_debug 										Enumeration 						Global
# innodb_compression_failure_threshold_pct 				Integer 								Global
# innodb_compression_level 									Integer 								Global
# innodb_compression_pad_pct_max 							Integer 								Global
# innodb_concurrency_tickets 									Integer 								Global
# innodb_ddl_log_crash_reset_debug 							Boolean 								Global
#
# innodb_deadlock_detect 										Boolean 								Global
# innodb_default_row_format 									Enumeration 						Global
# innodb_disable_sort_file_cache 							Boolean 								Global
# innodb_fast_shutdown 											Integer 								Global
# innodb_fil_make_page_dirty_debug 							Integer 								Global
# innodb_file_per_table 										Boolean 								Global
# innodb_fill_factor 											Integer 								Global
# innodb_flush_log_at_timeout 								Integer 								Global
# innodb_flush_log_at_trx_commit 							Enumeration 						Global
# innodb_flush_neighbors 										Enumeration 						Global
# innodb_flush_sync 												Boolean 								Global
# innodb_flushing_avg_loops 									Integer 								Global
# innodb_fsync_threshold 										Integer 								Global
# innodb_ft_aux_table 											String 								Global
# innodb_ft_enable_diag_print 								Boolean 								Global
# innodb_ft_enable_stopword 									Boolean 								Both
#
# innodb_ft_num_word_optimize 								Integer 								Global
# innodb_ft_result_cache_limit 								Integer 								Global
# innodb_ft_server_stopword_table 							String 								Global
# innodb_ft_user_stopword_table 								String 								Both
# innodb_io_capacity 											Integer 								Global
# innodb_io_capacity_max 										Integer 								Global
# innodb_limit_optimistic_insert_debug 					Integer 								Global
# innodb_lock_wait_timeout 									Integer 								Both
# innodb_log_buffer_size 										Integer 								Global
# innodb_log_checkpoint_fuzzy_now 							Boolean 								Global
# innodb_log_checkpoint_now 									Boolean 								Global
# innodb_log_checksums 											Boolean 								Global
# innodb_log_compressed_pages 								Boolean 								Global
# innodb_log_spin_cpu_abs_lwm 								Boolean 								Global
#
# innodb_log_spin_cpu_pct_hwm 								Integer 								Global
# innodb_log_wait_for_flush_spin_hwm 						Integer 								Global
# innodb_log_write_ahead_size 								Integer 								Global
# innodb_lru_scan_depth 										Integer 								Global
# innodb_max_dirty_pages_pct 									Numeric 								Global
# innodb_max_dirty_pages_pct_lwm 							Numeric 								Global
# innodb_max_purge_lag 											Integer 								Global
# innodb_max_purge_lag_delay 									Integer 								Global
# innodb_max_undo_log_size 									Integer 								Global
# innodb_merge_threshold_set_all_debug 					Integer 								Global
# innodb_monitor_disable 										String 								Global
#
# innodb_monitor_enable 										String 								Global
# innodb_monitor_reset 											String 								Global
# innodb_monitor_reset_all 									String 								Global
# innodb_old_blocks_pct 										Integer 								Global
# innodb_old_blocks_time 										Integer 								Global
# innodb_online_alter_log_max_size 							Integer 								Global
# innodb_optimize_fulltext_only 								Boolean 								Global
# innodb_parallel_read_threads 								Integer 								Session
# innodb_print_all_deadlocks 									Boolean 								Global
# innodb_print_ddl_logs 										Boolean 								Global
# innodb_purge_batch_size 										Integer 								Global
# innodb_purge_rseg_truncate_frequency 					Integer 								Global
# innodb_random_read_ahead 									Boolean 								Global
# innodb_read_ahead_threshold 								Integer 								Global
# innodb_redo_log_encrypt 										Boolean 								Global
# innodb_replication_delay 									Integer 								Global
# innodb_rollback_segments 									Integer 								Global
#
# innodb_saved_page_number_debug 							Integer 								Global
# innodb_spin_wait_delay 										Integer 								Global
# innodb_stats_auto_recalc 									Boolean 								Global
# innodb_stats_include_delete_marked 						Boolean 								Global
# innodb_stats_method 											Enumeration 						Global
# innodb_stats_on_metadata 									Boolean 								Global
# innodb_stats_persistent 										Boolean 								Global
# innodb_stats_persistent_sample_pages 					Integer 								Global
# innodb_stats_transient_sample_pages 						Integer 								Global
# innodb_status_output 											Boolean 								Global
# innodb_status_output_locks 									Boolean 								Global
# innodb_strict_mode 											Boolean 								Both
# innodb_sync_spin_loops 										Integer 								Global
# innodb_table_locks 											Boolean 								Both
# innodb_thread_concurrency 									Integer 								Global
# innodb_thread_sleep_delay 									Integer 								Global
# innodb_tmpdir 													Dir name 							Both
#
# innodb_trx_purge_view_update_only_debug 				Boolean 								Global
# innodb_trx_rseg_n_slots_debug 								Integer 								Global
# innodb_undo_log_encrypt 										Boolean 								Global
# innodb_undo_log_truncate 									Boolean 								Global
# innodb_undo_logs 												Integer 								Global
# innodb_undo_tablespaces 										Integer 								Global
# insert_id 														Integer 								Session
# interactive_timeout 											Integer 								Both
# internal_tmp_disk_storage_engine 							Enumeration 						Global
# internal_tmp_mem_storage_engine 							Enumeration 						Both
# join_buffer_size 												Integer 								Both
# keep_files_on_create 											Boolean 								Both
# key_buffer_size 												Integer 								Global
# key_cache_age_threshold 										Integer 								Global
# key_cache_block_size 											Integer 								Global
# key_cache_division_limit 									Integer 								Global
# keyring_aws_cmk_id 											String 								Global
# keyring_aws_region 											Enumeration 						Global
# keyring_encrypted_file_data 								File name 							Global
# keyring_encrypted_file_password 							String 								Global
# keyring_file_data 												File name 							Global
# keyring_okv_conf_dir 											Dir name 							Global
# keyring_operations 											Boolean 								Global
# last_insert_id 													Integer 								Session
# lc_messages 														String 								Both
# lc_time_names 													String 								Both
# local_infile 													Boolean 								Global
#
# lock_wait_timeout 												Integer 								Both
# log_bin_trust_function_creators 							Boolean 								Global
# log_builtin_as_identified_by_password 					Boolean 								Global
# log_error_filter_rules 										String 								Global
# log_error_services 											String 								Global
# log_error_suppression_list 									String 								Global
# log_error_verbosity 											Integer 								Global
# log_output 														Set 									Global
# log_queries_not_using_indexes 								Boolean 								Global
# log_slow_admin_statements 									Boolean 								Global
# log_slow_extra 													Boolean 								Global
# log_slow_slave_statements 									Boolean 								Global
# log_statements_unsafe_for_binlog 							Boolean 								Global
# log_syslog 														Boolean 								Global
# log_syslog_facility 											String 								Global
# log_syslog_include_pid 										Boolean 								Global
# log_syslog_tag 													String 								Global
# log_throttle_queries_not_using_indexes 					Integer 								Global
# log_timestamps 													Enumeration 						Global
# log_warnings 													Integer 								Global
# long_query_time 												Numeric 								Both
#
# low_priority_updates 											Boolean 								Both
# mandatory_roles 												String 								Global
# master_info_repository 										String 								Global
# master_verify_checksum 										Boolean 								Global
# max_allowed_packet 											Integer 								Both
# max_binlog_cache_size 										Integer 								Global
# max_binlog_size 												Integer 								Global
# max_binlog_stmt_cache_size 									Integer 								Global
# max_connect_errors 											Integer 								Global
# max_connections 												Integer 								Global
# max_delayed_threads 											Integer 								Both
# max_error_count 												Integer 								Both
# max_execution_time 											Integer 								Both
# max_heap_table_size 											Integer 								Both
# max_insert_delayed_threads 									Integer 								Both
# max_join_size 													Integer 								Both
# max_length_for_sort_data 									Integer 								Both
# max_points_in_geometry 										Integer 								Both
# max_prepared_stmt_count 										Integer 								Global
# max_relay_log_size 											Integer 								Global
# max_seeks_for_key 												Integer 								Both
# max_sort_length 												Integer 								Both
# max_sp_recursion_depth 										Integer 								Both
# max_tmp_tables 													Integer 								Both
#
# max_user_connections 											Integer 								Both
# max_write_lock_count 											Integer 								Global
# min_examined_row_limit 										Integer 								Both
# multi_range_count 												Integer 								Both
# myisam_data_pointer_size 									Integer 								Global
# myisam_max_sort_file_size 									Integer 								Global
# myisam_repair_threads 										Integer 								Both
# myisam_sort_buffer_size 										Integer 								Both
# myisam_stats_method 											Enumeration 						Both
# myisam_use_mmap 												Boolean 								Global
# mysql_firewall_mode 											Boolean 								Global
# mysql_firewall_trace 											Boolean 								Global
# mysql_native_password_proxy_users 						Boolean 								Global
# mysqlx-connect-timeout 										Integer 								Global
#
# mysqlx_connect_timeout 										Integer 								Global
# mysqlx_document_id_unique_prefix 							Integer 								Global
# mysqlx-idle-worker-thread-timeout 						Integer 								Global
# mysqlx_idle_worker_thread_timeout 						Integer 								Global
# mysqlx-interactive-timeout 									Integer 								Global
# mysqlx_interactive_timeout 									Integer 								Global
# mysqlx-max-allowed-packet 									Integer 								Global
# mysqlx_max_allowed_packet 									Integer 								Global
# mysqlx-max-connections 										Integer 								Global
# mysqlx_max_connections 										Integer 								Global
#
# mysqlx-min-worker-threads 									Integer 								Global
# mysqlx_min_worker_threads 									Integer 								Global
# mysqlx-read-timeout 											Integer 								Session
# mysqlx_read_timeout 											Integer 								Session
# mysqlx_wait_timeout 											integer 								Session
# mysqlx_wait_timeout 											integer 								Session
# mysqlx_write_timeout 											Integer 								Session
# mysqlx_write_timeout 											Integer 								Session
#
# ndb_blob_write_batch_bytes 									integer 								Both
# ndb_deferred_constraints 									Integer 								Both
# ndb_deferred_constraints 									Integer 								Both
# ndb_distribution 												Enumeration 						Global
# ndb_distribution={KEYHASH|LINHASH} 						Enumeration 						Global
# ndb_eventbuffer_free_percent 								Integer 								Global
# ndb_eventbuffer_max_alloc 									Integer 								Global
# ndb_force_send 													Boolean 								Both
# ndb_index_stat_enable 										Boolean 								Both
# ndb_index_stat_option 										String 								Both
# ndb_join_pushdown 												Boolean 								Both
# ndb_log_binlog_index 											Boolean 								Global
# ndb_log_empty_epochs 											Boolean 								Global
# ndb_log_empty_update 											Boolean 								Global
# ndb_log_updated_only 											Boolean 								Global
# ndb_optimization_delay 										Integer 								Global
# ndb_recv_thread_activation_threshold 					Integer 								Global
# ndb_recv_thread_cpu_mask 									Bitmap 								Global
# ndb_report_thresh_binlog_epoch_slip 						Integer 								Global
# ndb_report_thresh_binlog_mem_usage 						Integer 								Global
# ndb_show_foreign_key_mock_tables 							Boolean 								Global
# ndb_table_no_logging 											Boolean 								Session
#
# ndb_use_transactions 											Boolean 								Both
# ndbinfo_max_rows 												Integer 								Both
# ndbinfo_show_hidden 											Boolean 								Both
# net_buffer_length 												Integer 								Both
# net_read_timeout 												Integer 								Both
# net_retry_count 												Integer 								Both
# net_write_timeout 												Integer 								Both
# new 																Boolean 								Both
# offline_mode 													Boolean 								Global
# old_alter_table 												Boolean 								Both
# old_passwords 													Enumeration 						Both
# optimizer_prune_level 										Boolean 								Both
# optimizer_search_depth 										Integer 								Both
#
# optimizer_switch 												Set 									Both
# optimizer_trace 												String 								Both
# optimizer_trace_features 									String 								Both
# optimizer_trace_limit 										Integer 								Both
# optimizer_trace_max_mem_size 								Integer 								Both
# optimizer_trace_offset 										Integer 								Both
# original_commit_timestamp 									Numeric 								Session
#
# parser_max_mem_size 											Integer 								Both
# password_history 												Integer 								Global
# password_require_current 									Boolean 								Global
# password_reuse_interal 										Integer 								Global
# performance_schema_max_digest_sample_age 				Integer 								Global
# preload_buffer_size 											Integer 								Both
# profiling 														Boolean 								Both
# profiling_history_size 										Integer 								Both
# pseudo_slave_mode 												Integer 								Session
# pseudo_thread_id 												Integer 								Session
# query_alloc_block_size 										Integer 								Both
# query_cache_limit 												Integer 								Global
# query_cache_min_res_unit 									Integer 								Global
# query_cache_size 												Integer 								Global
# query_cache_type 												Enumeration 						Both
# query_cache_wlock_invalidate 								Boolean 								Both
# query_prealloc_size 											Integer 								Both
# rand_seed1 														Integer 								Session
# rand_seed2 														Integer 								Session
#
# range_alloc_block_size 										Integer 								Both
# range_optimizer_max_mem_size 								Integer 								Both
# rbr_exec_mode 													Enumeration 						Both
# read_buffer_size 												Integer 								Both
# read_only 														Boolean 								Global
# read_rnd_buffer_size 											Integer 								Both
# regexp_stack_limit 											Integer 								Global
# regexp_time_limit 												Integer 								Global
# relay_log_info_repository 									String 								Global
# relay_log_purge 												Boolean 								Global
# require_secure_transport 									Boolean 								Global
# resultset_metadata 											Enumeration 						Session
# rewriter_enabled 												Boolean 								Global
# rewriter_verbose 												Integer 								Global
# rpl_read_size 													Integer 								Global
# rpl_semi_sync_master_enabled 								Boolean 								Global
# rpl_semi_sync_master_timeout 								Integer 								Global
# rpl_semi_sync_master_trace_level 							Integer 								Global
# rpl_semi_sync_master_wait_for_slave_count 				Integer 								Global
# rpl_semi_sync_master_wait_no_slave 						Boolean 								Global
# rpl_semi_sync_master_wait_point 							Enumeration 						Global
# rpl_semi_sync_slave_enabled 								Boolean 								Global
# rpl_semi_sync_slave_trace_level 							Integer 								Global
#
# rpl_stop_slave_timeout 										Integer 								Global
# schema_definition_cache 										Integer 								Global
# secure_auth 														Boolean 								Global
# server_id 														Integer 								Global
# session_track_gtids 											Enumeration 						Both
# session_track_schema 											Boolean 								Both
# session_track_state_change 									Boolean 								Both
# session_track_system_variables 							String 								Both
# session_track_transaction_info 							Enumeration 						Both
# sha256_password_proxy_users 								Boolean 								Global
# show_compatibility_56 										Boolean 								Global
# show_create_table_verbosity 								Boolean 								Both
# show_old_temporals 											Boolean 								Both
# slave_allow_batching 											Boolean 								Global
# slave_checkpoint_group=# 									Integer 								Global
# slave_checkpoint_period=# 									Integer 								Global
# slave_compressed_protocol 									boolean 								Global
# slave_exec_mode 												Enumeration 						Global
#
# slave_max_allowed_packet 									Integer 								Global
# slave_net_timeout 												Integer 								Global
# slave_parallel_type 											Enumeration 						Global
# slave_parallel_workers 										Integer 								Global
# slave_pending_jobs_size_max 								Integer 								Global
# slave_preserve_commit_order 								Boolean 								Global
# slave_rows_search_algorithms=list 						Set 									Global
# slave_sql_verify_checksum 									Boolean 								Global
# slave_transaction_retries 									Integer 								Global
# slow_launch_time 												Integer 								Global
# slow_query_log 													Boolean 								Glboal
# slow_query_log_file 											File name 							Global
# sort_buffer_size 												Integer 								Both
# sql_auto_is_null 												Boolean 								Both
# sql_big_selects 												Boolean 								Both
# sql_buffer_result 												Boolean 								Both
# sql_log_bin 														Boolean 								Session
# sql_log_off 														Boolean 								Both
# sql_mode 															Set 									Both
# sql_notes 														Boolean 								Both
# sql_quote_show_create 										Boolean 								Both
# sql_require_primary_key 										Boolean 								Both
# sql_safe_updates 												Boolean 								Both
# sql_select_limit 												Integer 								Both
# sql_slave_skip_counter 										Integer 								Global
#
# sql_warnings 													Boolean 								Both
# ssl_fips_mode 													Enumeration 						global
# stored_program_cache 											Integer 								Global
# stored_program_definition_cache 							Integer 								Global
# super_read_only 												Boolean 								Global
# sync_binlog 														Integer 								Global
# sync_master_info 												Integer 								Global
# sync_relay_log 													Integer 								Global
# sync_relay_log_info 											Integer 								Global
# syseventlog.facility 											String 								Global
# syseventlog.include_pid 										Boolean 								Global
# syseventlog.tag 												String 								Global
# table_definition_cache 										Integer 								Global
# table_open_cache 												Integer 								Global
# tablespace_definition_cache 								Integer 								Global
# temptable_max_ram 												Integer 								Global
# thread_cache_size 												Integer 								Global
#
# thread_pool_high_priority_connection 					Integer 								Both
# thread_pool_max_unused_threads 							Integer 								Global
# thread_pool_prio_kickup_timer 								Integer 								Both
# thread_pool_stall_limit 										Integer 								Global
# time_zone 														String 								Both
# timestamp 														Numeric 								Session
# tmp_table_size 													Integer 								Both
# transaction_alloc_block_size 								Integer 								Bothh
# transaction_isolation 										Enumeration 						Both
# transaction_prealloc_size 									Integer 								Both
# transaction_read_only 										Boolean 								Both
# transaction_write_set_extraction 							Enumeration 						Both
# tx_isolation 													Enumeration 						Both
# tx_read_only 													Boolean 								Both
# unique_checks 													Boolean 								Both
# updatable_views_with_limit 									Boolean 								Both
# use_secondary_engine 											Enumeration 						Session
# validate_password_check_user_name 						Boolean 								Global
# validate_password_dictionary_file 						File name 							Global
# validate_password_length 									Integer 								Global
# validate_password_mixed_case_count 						INteger 								Global
# validate_password_number_count 							Integer 								Global
# validate_password_policy 									Enumeration 						Global
# validate_password_special_char_count 					Integer 								Global
# validate_password.check_user_name 						Boolean 								Global
# validate_password.dictionary_file 						File name 							Global
# validate_password.length 									integer 								Global
# validate_password.mixed_case_count 						Integer 								Global
# validate_password.number_count 							Integer 								Global
# validate_password.policy 									Enumeration 						Global
# validate_password.special_char_count 					Integer 								Global
# version_tokens_session 										String 								Both
# wait_timeout 													Integer 								Both
# windowing_use_high_precision 								Boolean 								Both
#
# The following pertains to Persisted System Variables:
#
# The MySQL server maintains sys vars that configure its operations. A sys var can have a global value that
# effects server ops as a whole, current session or both.
#
# Many sys vars are dynamic, can be changed during runtime using SET to affect current session.
# SET can also be used to persist certain global sys vars to the mysqld-auto.cnf in the data dir - which affects subsequent startups.
#
# RESET_PERSIST removes persisted settings from mysqld-auto.cnf
#
# The following pertains to a OVERVIEW of the persisted Sys vars:
#
# Many sys_vars can be set at startup from a my.cnf option file or at runtime using the SET
# statement, those methods of configing the server either requires a login access to the server host,
# or do not provide the capability of persistently configuring the server at runtime or remotely:
#
# 		Modifying an option file requires direct access to that file, which requires login access to the MySQL server host.
#
# 		MOdifying sys_vars with SET_GLOBAL is a runtime capability that can be done from clients run locally 
# 		or from remote hosts, but the changes affect only the current running server instance. i.e, nont persistent.
#
# To persist sys_vars to a file named mysqld-auto.cnf - in the data dir - we can do as follows:
#
# 		SET PERSIST max_connections = 1000;
# 		SET @@persist.max_connections = 1000;
#
# 		SET PERSIST ONLY back_log = 100;
# 		SET @@persist_only.back_log = 100;
#
# MySQL also provides a RESET PERSIST statement for removing persisted sys vars from mysqld-auto.cnf
#
# Server configs performed by persisted sys_vars, has these chareteristics:
#
# 		Made at runtime
#
# 		Permanent, apply across server restarts
#
# 		Can be made from local or clients who connect from a remote host.
# 		(can configure multiple remote MySQL servers from a central client host)
#
# 		To persist sys_vars only reqs the privs for it, not login access or akin.
#
# 		Admin rights allows you to reconfig servers by persisting sys_vars, then cause the 
# 		server to use the changed settings by executing a RESTART statement.
#
# 		Persisted settings provide immediate feedback about errors, because if you try to SET 
# 		a malformed setting or syntax error - it does not change the server config, due to failing.
#
# The following pertains to the SYNTAX for persisting Sys_Vars:
#
# 		To persist a global sys_var to mysqld-auto.cnf option file in the data dir, we can use PERSIST Or the @@persist qualifier:
#
# 			SET PERSIST max_connections = 1000;
# 			SET @@persist.max_connections = 1000;
#
# 			Like SET_GLOBAL, SET_PERSIST sets the global var runtime - but also writes the var setting to mysqld-auto.cnf 
# 			(replaces existing var settings if they are there)
#
# 		To persist a global sys var to the mysqld-auto.cnf without setting the global var runtime value - we can use PERSIST_ONLY or @@persist_only.back_log
#
# 			SET PERSIST_ONLY back_log = 1000;
# 			SET @@persist_only.back_log = 1000;
#
# 			(Writes to the mysqld-auto.cnf file - but does not modify the global var runtime value)
# 			(Suitable for configing read_only sys_vars that can only be done at server startup)
#
# These RESET_PERSIST syntax ops can be used for removing persisted sys_vars:
#
# 		To remove all persisted vars from mysqld-auto.cnf, use RESET_PERSIST without naming any sys var:
# 			
# 			RESET PERSIST;
#
# 		To remove a specified persisted var from mysqld-auto.cnf, name it in the statement:
#
# 			RESET PERSIST system_var_name;
#
# 		To remove a specific persisted var from mysqld-auto.cnf, but produce a warning rather than an error
# 		if the var is not present in the file, we can do IF EXISTS:
#
# 			RESET PERSIST IF EXISTS system_var_name;
#
#
# A sys_var implemented by a plugin can be persisted if the plugin is installed when the SET statement is executed.
# Assignment of the persisted plugin variable takes effect for subsequent server restarts if the plugin is still installed.
#
# If the plugin is no longer installed, the plugin variable will not exist when the server reads the mysqld-auto.cnf file
# The server writes a warning to the error log and continues:
#
# 		currently unknown variable '<var_name>'
# 		was read from the persisted config file
#
# The following pertains to obtaining information About Persisted Sys Vars:
#
# 		The Performance Schema <persisted_variables> table provides an SQL interface to the mysqld-auto.cnf file, enabling its
# 		contents to be inspected at runtime using SELECT statements.
#
# 		The Performance Schema <variables_info> table contains info showing when and by which user each sys_var was most recently set.
#
# 		RESET_PERSIST affects the contents of the persisted_variables table because the table contents correspond to the contents
# 		of the mysqld-auto.cnf file.
#
# 		On the other hand, because RESET_PERSIST does not change variable values, it has no effect on the contents of the variables_info
# 		table until the server is restarted.
#
# The following pertains to FORMAT AND SERVER HANDLING OF THE MYSQLD-AUTO.CNF FILE:
#
# It's akin to JSON:
#
# {
# 		"Version": 1,
# 		"mysql_server": {
# 			"max_connections": {
# 				"Value": 	"152",
# 				"Metadata": {
# 					"Timestamp": 1.51.. (etc.)
# 					"User": 	"root",
# 					"Host": 	"localhost"
# 				}
# 		},
# 		"transaction_isolation": {
# 			"Value": "READ-COMMITTED",
# 			"Metadata": {
# 				"Timestamp": 1.51.. (etc)
# 				"User": "root",
# 				"Host": "localhost"
# 			}
# 		},
# 		"mysql_server_static_options": {
# 			"innodb_api_enable_mdi": {
# 				"Value": "0",
# 				"Metadata": {
# 					"Timestamp": 1.51.. (etc)
# 					"User": "root",
# 					"Host": "localhost"
# 				}
# 			},
# 			"log_slave_updates": {
# 				"Values": "1",
# 				"Metadata": {
# 					"Timestamp": 1.51... (etc)
# 					"User": "root",
# 					"Host": "localhost"
# 				}
# 			}
# 		}
# 	}	
#}
#
# At startup the server processes the mysqld-auto.cnf file after all other option files.
# The server handles the file contents as follows:
#
# 		If the persisted_globals_load sys_var is disabled, the server ignores the mysqld-auto.cnf file.
#
# 		Only read-only variables persisted using SET_PERSIST_ONLY appear in the "mysql_server_static_options" section.
# 		All variables present inside this section are appended to the cmd line and processed with other cmd line options.
#
# 		All remaining persisted variables are set by executing the equivalent of a SET_GLOBAL statement later, just before
# 		the server starts listening for client connections.
#
# 		These settings therefore do not take effect until late in the startup process, which might be unsuitable for certain
# 		sys_vars.
#
# 		For example, a variable such as log_error_verbosity that affects logging to the error log takes effect later in the 
# 		startup process if persisted to mysqld-auto.cnf than if set in my.cnf. It may be preferable to set such variables
# 		in my.cnf rather than in mysqld-auto.cnf
#
# Management of the mysqld-auto.cnf file should be left to the server. Manipulation of it should only occur through SET and RESET_PERSIST statements.
#
# Removing the file, causes loss of all persisted settings at hte next server startup.
#
# Manual changes to the file may result in a parse error at server startup.
# In this case, the server reports an error and exits.
#
# If said issue occurs, start the server with the persisted_globals_load sys_var disabled,
# or with the --no-defaults option.
#
# Or remove mysqld-auto.cnf.
#
# The following pertains to nonpersistent Sys_vars:
#
# SET_PERSIST and SET_PERSIST_ONLY enable Global sys_vars to be persisted to the mysqld-auto.cnf option file in the data dir.
# However, not all sys_vars can be persisted.
#
# Might be prevented from being persisted by virtue of:
#
# 		A sys var might be read only. Cannot be set at all, whether at server startup or at runtime.
#
# 		A sys var might be intended only for internal use.
#
# 		A sys var might involve sensitive data. A variable such as secure_file_priv should be settable
# 		only by a user who has direct access to the server host file system - not a remote user. (Due to possible priv escalation)
#
# 		Session sys_vars cannot be persisted. Cannot be set at server startup, so cannot be persisted (no reason)
#
# The following are sys_vars of which cannot be persisted:
#
# 	audit_log_current_session
# 	audit_log_file
# 	audit_log_filter_id
# 	audit_log_format
# 	auto_generate_certs
#
# 	basedir
# 	bind_address
# 	caching_sha2_password_auto_generate_rsa_keys
# 	caching_sha2_password_private_key_path
# 	caching_sha2_password_public_key_path
# 	character_set_system
# 	character_sets_dir
# 	core_file
# 	daemon_memcached_engine_lib_name
#
# 	daemon_memcached_engine_lib_path
# 	daemon_memcached_option
# 	datadir
# 	default_authentication_plugin
# 	ft_stopword_file
# 	have_statement_timeout
# 	have_symlink
# 	hostname
# 	init_file
#
# 	innodb_buffer_pool_load_at_startup
# 	innodb_data_file_path
# 	innodb_data_home_dir
# 	innodb_dedicated_server
# 	innodb_directories
# 	innodb_force_load_corrupted
# 	innodb_log_group_home_dir
# 	innodb_page_size
# 	innodb_read_only
#
# 	innodb_temp_data_file_path
# 	innodb_temp_tablespaces_dir
# 	innodb_undo_directory
# 	innodb_undo_tablespaces
# 	innodb_version
# 	keyring_encrypted_file_data
# 	keyring_encrypted_file_password
# 	large_files_support
# 	large_page_size
# 	lc_messages_dir
#
# 	license
# 	locked_in_memory
# 	log_bin
# 	log_bin_basename
# 	log_bin_index
# 	log_error
# 	lower_case_file_system
# 	mecab_rc_file
# 	named_pipe
# 	persisted_globals_load
# 	pid_file
# 	plugin_dir
# 	port
#
# 	protocol_version
#  relay_log
# 	relay_log_basename
# 	relay_log_index
# 	relay_log_info_file
# 	secure_file_priv
# 	server_uuid
#
# 	sha256_password_auto_generate_rsa_keys
# 	sha256_password_private_key_path
# 	sha256_password_public_key_path
# 	shared_memory
# 	shared_memory_base_name
# 	skip_external_locking
# 	skip_networking
# 	slave_load_tmpdir
# 	socket
# 	ssl_ca
# 	ssl_capath
# 	ssl_cert
# 	ssl_crl
# 	ssl_crlpath
# 	ssl_key
# 	system_time_zone
# 	tmpdir
# 	version_comment
# 	version_compile_machine
# 	version_compile_os
# 	version_compile_zlib
# 	version_tokens_session_number
#
# The following pertains to structured system variables:
#
# A structured Sys_var differs from a regular sys_var in two respects:
#
# 		Its value is a structure with components that specify server parameters considered to be closely related.
#
# 		There might be several instances of a given type of structured variable. Each one has a different name and refers to
# 		a different resource maintained by the server.
#
# MySQL supports one structured variable type, which specifies parameters governing the operation of key caches.
# A key cached structured variable has these components:
#
# 		key_buffer_size
#
# 		key_cache_block_size
#
# 		key_cache_division_limit
#
# 		key_cache_age_threshold
#
# This section describes the syntax for referring to the structured vars. Key cache variables are for examples, their interactions are covered later.
#
# To refer to a component of a structured variable instance, you can use a compound name in instance_name.component_name format, example:
#
# 		hot_cache.key_buffer_size
# 		hot_cache.key_cache_block_size
# 		cold_cache.key_cache_block_size
#
# For each structured sys_var, an instance with the name of <default> is always predefined.
# If you refer to a component of a structured var without any instance name, the <default> instance is used.
#
# Thus, default.key_buffer_size and key_buffer_size refer to the same sys_var.
#
# Structured var instances and components follows these naming rules:
#
# 		For a given type of structured variable, each instance must have a name that is unique within variables of that type.
# 		However, instance names need not be unique across structured variable types.
#
# 		For example, each structured variable has an instance named default, so default is not unique across variable types.
#
# 		The names of the components of each structured variable type must be unique across all sys_var names.
#
# 		If this were not true (that is, two different types of structured vars could share component member names),
# 		it would not be clear which default structured variable to use for references to member names that are not qualified
# 		by an instance name.
#
# 		If a structured variable instance name is not legal as an unquoted identifier, refer to it as a quoted identifier
# 		using backticks. For example, hot-cache is not legal - but `hot-cache` is.
#
# 		global, session and local are not legal instance names. This vaoids a conflict with notations such as @@global.<var_name>
# 		for referring to nonstructured sys_vars.
#
# Currently, the first two rules have no possibility of being violated because the only structured variable type is the one
# for key caches. These rules will assume greater significance if some other type of structured variable is created in the future.
#
# With one exception, you can refer to structured variable components using compound names in any context where simple var names 
# can occur.
#
# For example, you can assign a value to a structured var using a cmd line option:
#
# 		mysqld --hot_cache.key_buffer_size=64K
#
# In a option file:
#
# 		[mysqld]
# 		hot_cache.key_buffer_size=64K
#
# The above entails a key cache named hot_cache with a size of 64KB in addition to the default of 8MB.
#
# We could also do as follows:
#
# 		mysqld --key_buffer_size=256K \
# 			--extra_cache.key_buffer_size=128K \
# 			--extra_cache.key_cache_block_size=2048
#
# In this case, the server sets the size of the default key cache to 256KB. 
# (we could also have written --default.key_buffer_size=256K). 
#
# In addition, we create a second cache named extra_cache that has a size of 128K, with size of
# block buffers for caching table index blocks set to 2048 bytes.
#
# THe following example starts the server with three different key caches having sizes in a 3:1:1 ratio:
#
# 	mysqld --key_buffer_size=6M \
# 		--hot_cache.key_buffer_size=2M \
# 		--cold_cache.key_buffer_size=2M
#
# Structured var vlaues may be set and retrieved at runtime as well. For example, to set a key cache named hot_cache
# to a size of 10MB, use either of:
#
# SET GLOBAL hot_cache.key_buffer_size = 10*1024*1024;
# SET @@global.hot_cache.key_buffer_size = 10*1024*1024;
#
# To retrieve the cache size, do this:
#
# SELECT @@global.hot_cache.key_buffer_size;
#
# However, using:
#
# SHOW GLOBAL VARIABLES LIKE 'hot_cache.key_buffer_size'; 
#
# Would not work, as it would be considered a string match for LIKE regex ops of a simple variable naming.
#
# 
# The following section pertains to Server Status Variables:
#
# The MySQL server maintains many status variables that provide information about its operation.
# You can view these vars and their values by using the SHOW [GLOBAL | SESSION] STATUS statement.
#
# The optional GLOBAL keyword aggregates the values over all connections, and SESSION shows for the current connection.
#
# SHOW GLOBAL STATUS;
#
# +-------------------------------------------------+
# | Variable_name 						| 	Value 		 |
# +---------------------------------+---------------+
# | 											| 					 |
# | Aborted_clients 						| 0 				 |
# | Aborted_connects 					| 0 				 |
# | Bytes_received 						| 155372598 	 |
# | Bytes_sent 							| 1176560426 	 |
# ...
# | Connections 							| 30023 			 |
# | Created_tmp_disk_tables 			| 0 				 |
# | Created_tmp_files 					| 3				 |
# | Created_tmp_tables 					| 2 				 |
# ...
# | Threads_created 						| 217 			 |
# | Threads_running 						| 88 				 |
# | Uptime 									| 1389872 		 |
# +---------------------------------+---------------+
#
# Several status vars provide statement counts. To determine the amount of statements executed, use:
#
# SUM(Com_xxx)
# = Questions + statements executed within stored programs
# = Queries
#
# Many status variables are reset to 0 by the FLUSH_STATUS statement.
#
# The status variables have the following meanings:
#
# 		Aborted_clients
#
# 			Number of connections that were aborted because the client died without closing the connection properly.
#
# 		Aborted_connects
#
# 			The number of failed attempts to connect to the MySQL server.
#
# 			For additional connection-related info, check the Connection_errors_xxx status vars and the host_cache table.
#
# 		Binlog_cache_disk_use
#
# 			Number of transactions that used the temporary binary log cache but that exceeded the value of binlog_cache_size
# 			and used a temporary file to store statements from the transaction.
#
# 			The number of nontransactional statements that caused the binary log transaction cache to be written to disk
# 			is tracked separately in the Binlog_stmt_cache_disk_use status variable.
#
# 		Acl_cache_items_count
#
# 			Number of cached privlege objects. Each object is the privlege combination of a user and its active roles.
#
# 		Binlog_cache_use
#
# 			Number of transactions that used the binary log cache.
#
# 		Binlog_stmt_cache_disk_use
#
# 			Number of nontransaction statements that used the binary log statement cache but that exceeded
# 			the value of of binlog_stmt_cache_size and used a temporary file to store those statements.
#
# 		Binlog_stmt_cache_use
#
# 			Number of nontransactional statements, that used the binary log statement cache.
#
# 		Bytes_received
#
# 			Number of bytes received from all clients.
#
# 		Bytes_sent
#
# 			Number of bytes sent to all clients.
#
# 		Caching_sha2_password_rsa_public_key
#
# 			Public key used by the caching_sha2_password authentication plugin for RSA key-pair based PW exchange.
#
# 			The value is nonempty only if the server successfully intiializes the private and public keys in the
# 			files named by the caching_sha2_password_private_key_path and caching_sha2_password_public_key_path SYS_VARS.
#
# 			The value of Caching_sha2_password_rsa_public_key comes from the latter file.
#
# 		Com_xxx
#
# 			The Com_xxx statement counter variables indicate the number of times each xxx statement has been executed.
#
# 			There is one status variable for each type of statement.
# 			For example, Com_delete and Com_update count DELETE and UPDATE statements, respectively.
#
# 			Com_delete_multi and Com_update_multi are similar but apply to DELETE and UPDATE statements that use multiple-table syntax.
#
# 			All of the Com_stmt_xxx variables are increased even if a prepared statement argument is unknown or an error occured
# 			during execution. In other words, their values correspond to the number of requests issued - not the number of requests successfully completed.
#
# 			The Com_stmt_xxx status variables are as follows:
#
# 				Com_stmt_prepare
#
# 				Com_stmt_execute
#
# 				Com_stmt_fetch
#
# 				Com_stmt_send_long_data
#
# 				Com_stmt_reset
#
# 				Com_stmt_close
#
# 			Those variables stand for prepared statement commands. Their names refer to the COM_xxx command set used
# 			in the network layer.
#
# 			In other words, their values increase whenever prepared statement API calls such as mysql_stmt_prepare(),
# 			mysql_stmt_execute() and so forth are executed.
#
# 			However, Com_stmt_prepare, Com_stmt_execute and Com_stmt_close also increase for PREPARE, EXECUTE or DEALLOCATE_PREPARE,
# 			respectively.
#
# 			Additionally, the values of the older statement counter variables Com_prepare_sql, Com_execute_sql and Com_dealloc_sql
# 			increase for the PREPARE, EXECUTE and DEALLOCATE_PREPARE statements.
#
# 			Com_stmt_fetch stands for the total number of network round-trips issued when fetching from cursors.
#
# 			Com_stmt_reprepare indicates the number of times statements were automatically reprepared by the server after
# 			metadata changes to tables or views referred to by the statement.
#
# 			A reprepare operation increments Com_stmt_reprepare and also Com_stmt_prepare.
#
# 			Com_explain_other indicates the number of EXPLAIN_FOR_CONNECTION statements executed.
#
# 			Com_change_repl_filter indicates the number of CHANGE_REPLICATION_FILTER statements executed.
#
# 		Compression
#
# 			Whether the client connection uses compression in the client/server protocol.
#
# 		Connection_errors_xxx
#
# 			These variables provide info about errors that occur during the client connection process.
#
# 			They are global only and represent error counts aggregated across connections from all hosts.
#
# 			These variable track errors not accounted for by the host cache - such as errors that are not
# 			associated with TCP connections, occur very early in the connection process (even before an IP address is known),
# 			or are not specific to any particular IP address (such as out of memory conditions).
#
# 				Connection_errors_accept
#
# 					The number of errors that occurred during calls to accept() on the listening port.
#
# 				Connection_errors_internal
#
# 					The number of connections refused due to internal errors in the server, such as failure to start
# 					a new thread or an out-of-memory condition.
#
# 				Connection_errors_max_connections
#
# 					Number of connections refused because the server max_connections limit was reached.
#
# 				Connection_errors_peer_address
#
# 					The number of errors that occurred while searching for connecting clientIP addresses.
#
# 				Connection_errors_select
#
# 					Number of errors that occured during calls to select() or poll() on the listening port.
# 					(Failure of this operation does not necessarily mean a client connection was rejected)
#
# 				Connection_errors_tcpwrap
#
# 					The number of connections refused by the libwrap library.
#
# 		Connections - Number of connection attempts (successful or not) to the MySQL server.
#
# 		Created_tmp_disk_tables
#
# 			Number of internal on-disk temporary tables created by the server while executing statements.
#
# 			If an internal temp table is created initially as an in-memory table but becomes too large, MySQL automatically
# 			converts it to an on-disk table.
#
# 			The max size for in-memory temp tables is the minimum of the tmp_table_size and max_heap_table_size values.
#
# 			If Created_tmp_disk_tables is large, you may want to increase the tmp_table_size or max_heap_table_size value
# 			to lessen the likelihood that internal temp tables in memory will be converted to on-disk tables.
#
# 			You can compare the number of internal on-disk temp tables created to the total number of internal temp tables
# 			created by comparing the values of the Created_tmp_disk_tables and Created_tmp_tables variables.
#
# 		Created_tmp_files
#
# 			How many temporary files mysqld has created.
#
# 		Created_tmp_tables
#
# 			Number of internal temporary tables created by the server while executing statements.
#
# 			You can compare the number of internal-on-disk temp tables created to the total number of internal
# 			temp tables created by comparing the values of the Created_tmp_disk_tables and Created_tmp_tables vars.
#
# 			Each invocation of the SHOW_STATUS statement uses an internal temp table and increment the global Created_tmp_tables value.
#
# 		Delayed_errors
#
# 			This status variable is DEPRECATED (delayed is not supported)
#
# 		Delayed_insert_threads, Delayed_writes - Deprecated.
#
# 		dragnet.Status 
#
# 			The result of the most recent assignment to the dragnet.log_error_filter_rules SYS_VAR, empty if no such assignment has occurred.
#
# 		Flush_commands
#
# 			Number of times the server flushes tables, whether because a user executed a FLUSH_TABLES statement or due to internal 
# 			server operation.
#
# 			It is also incremented by receipt of a COM_REFRESH packet. This is in contrast to Com_flush, which indicates how many
# 			FLUSH statements have been executed, whether FLUSH_TABLES, FLUSH_LOGS etc.
#
# 		group_replication_primary_member
#
# 			Shows the primary member's UUID when the group is operating in single-primary mode.
# 			If the group is operating multi-primary mode, shows an empty string.
#
# 			The group_replication_primary_member status variable is deprecated.
#
# 		Handler_commit
#
# 			Number of internal COMMIT statements.
#
# 		Handler_delete
#
# 			Number of times that rows have been deleted from tables.
#
# 		Handler_external_lock
#
# 			The server increments this variable for each call to its external_lock() function, which generally occurs at the
# 			beginning and end of access to a table instance.
#
# 			There might be differences amongst storage engines. This variable can be used, for example, to discover for a statement
# 			that accesses a partitioned table how many partitions were pruned before locking occurred:
#
# 			Check how much the counter increased for the statement, subtract 2 (2 calls for the table itself), then /2 to get number of
# 			partitions locked.
#
# 		Handler_mrr_init
#
# 			Number of times the server uses a storage engine's own Multi-Range Read implementation for table access.
#
# 		Handler_prepare
#
# 			A counter for the prepare phase of two-phase commit operations.
#
# 		Handler_read_first
#
# 			Number of times the first entry in an index was read. If this value is high, it suggests that the server
# 			is doing a lot of full index scans; for example, SELECT col1 FROM foo - assuming that col1 is indexed.
#
# 		Handler_read_key
#
# 			Number of requests to read a row based on a key. If this value is high, it is a good indication that your tables 
# 			are properly indexed for your queries.
#
# 		Handler_read_last
#
# 			The number of requests to read the last key in an index. 
#
# 			With ORDER BY, the server will issue a first-key request followed by several next-key requests,
# 			whereas with ORDER BY DESC, the server will issue a last-key request followed by several previous-key requests.
#
# 		Handler_read_next
#
# 			The number of requests to read the next row in key order. This value is incremented if you are querying an index column with
# 			a range constraint or if you are doing an index scan.
#
# 		Handler_read_prev
#
# 			The number of requests to read the previous row in key order. This read method is mainly used to optimize ORDER BY ... DESC
#
# 		Handler_read_rnd
#
# 			Number of requests to read a row based on a fixed position. 
#
# 			This value is high if you are doing a lot of queries that require sorting of the result.
# 		   You probably have a lot of queries that require MySQL to scan entire tables or you have joins that do not use keys properly.
#
# 		Handler_read_rnd_next
#
# 			The number of requests to read the next row in the data file.
#
# 			This value is high if you are doing a lot of table scans. 
#
# 			Generally this suggests that your tables are not properly indexed or that your queries
# 			are not written to take advantage of the indexes you have.
#
# 		Handler_rollback
#
# 			Number of requests for a storage engine to perform a rollback operation.
#
# 		Handler_savepoint
#
# 			Number of requests for a storage engine to place a savepoint.
#
# 		Handler_savepoint_rollback
#
# 			The number of requests for a storage engine to roll back to a savepoint.
#
# 		Handler_update
#
# 			Number of requests to update a row in a table.
#
# 		Handler_write
#
# 			Number of requests to insert a row in a table.
#
# 		Innodb_available_undo_logs
#
# 			Innodb_available_undo_logs was removed in MySQL 8.0.2.
#
# 			Number of available rollback segments per tablespace may be retrieved using SHOW VARIABLES LIKE 'innodb_rollback_segments';
#
# 		Innodb_buffer_pool_dump_status
#
# 			The progress of an operation to record the pages held in the InnoDB buffer pool, triggered by the setting of
# 			innodb_buffer_pool_dump_at_shutdown or innodb_buffer_pool_dump_now
#
# 		Innodb_buffer_pool_load_status
#
# 			The progress of an operation to warm up the InnoDB buffer pool by reading in a set of pages corresponding to an earlier
# 			point in time, triggered by the setting of innodb_buffer_pool_load_at_startup or innodb_buffer_pool_load_now.
#
# 			If the operation introduces too much overhead, you can cancel it by setting innodb_buffer_pool_load_abort
#
# 		Innodb_buffer_pool_bytes_data
#
# 			The total number of bytes in the InnoDB buffer pool containing data.
#
# 			The number includes borth dirty and clean pages.
#
# 			For more accurate memory usage calculations than with Innodb_buffer_pool_pages_data,
# 			when compressed tables cause the buffer pool to hold pages of different sizes.
#
# 		Innodb_buffer_pool_pages_data
#
# 			The number of pages in the InnoDB buffer pool containing data. The number includes both dirty and clean pages.
#
# 			When using compressed tables, the reported Innodb_buffer_pool_pages_data value may be larger than
# 			Innodb_buffer_pool_pages_total (Bug #595550)
#
# 		Innodb_buffer_pool_bytes_dirty
#
# 			The total current number of bytes held in dirty pages in the InnoDB buffer pool.
#
# 			For more accurate memory usage calculations than with Innodb_buffer_pool_pages_dirty,
# 			when compressed tables cause the buffer pool to hold pages of different sizes.
#
# 		Innodb_buffer_pool_pages_dirty
#
# 			The current number of dirty pages in the InnoDB buffer pool.
#
# 		Innodb_buffer_pool_pages_flushed
#
# 			The number of requests to flush pages from the InnoDB buffer pool.
#
# 		Innodb_buffer_pool_pages_free
#
# 			The number of free pages in the InnoDB buffer pool.
#
# 		Innodb_buffer_pool_pages_latched
#
# 			The number of latched pages in the InnoDB buffer pool.
#
# 			These are pages currently being read or written, or that cannot be flushed or removed for
# 			some other reason.
#
# 			Calculation of this variable is expensive, so it is available only when the UNIV_DEBUG system is defined at server build time.
#
# 		Innodb_buffer_pool_pages_misc
#
# 			The number of pages in the InnoDB buffer pool that are busy because they have been allocated for admin overhead,
# 			such as row locks or the adaptive hash index.
#
# 			This value can also be calculated as Innodb_buffer_pool_pages_total - Innodb_buffer_pool_pages_free - Innodb_buffer_pool_pages_data.
#
# 			When using compressed tables, Innodb_buffer_pool_pages_misc may report an out-of-bounds value (Bug #59550)
#
# 		Innodb_buffer_pool_pages_total
#
# 			The total size of the InnoDB buffer pool, in pages. 
#
# 			When using compressed tables, the reported Innodb_buffer_pool_pages_data value may be larger than
# 			Innodb_buffer_pool_pages_total (Bug #59550)
#
# 		Innodb_buffer_pool_read_ahead
#
# 			The number of pages read into the InnoDB buffer pool by the read-ahead background thread.
#
# 		Innodb_buffer_pool_read_ahead_evicted
#
# 			The number of pages read into the InnoDB buffer pool by the read-ahead background thread that were
# 			subsequently evicted without having been accessed by queries.
#
# 		Innodb_buffer_pool_read_ahead_rnd
#
# 			The number of "random" read-aheads initated by InnoDB. 
#
# 			This happens when a query scans a large portion of a table but in a random order.
# 
# 		Innodb_buffer_pool_read_requests
#
# 			The number of logical read requests.
#
# 		Innodb_buffer_pool_reads
#
# 			The number of logical reads that InnoDB could not satisfy from the buffer pool, and had to read directly
# 			from disk.
#
# 		Innodb_buffer_pool_resize_status
#
# 			The status of an operation to resize the InnoDB buffer pool dynamically triggered by setting the innodb_buffer_pool_size param dynamically.
#
# 			The innodb_buffer_pool_size parameter is dynamic, which allows you to resize the buffer pool without restarting the server.
#
# 		Innodb_buffer_pool_wait_free
#
# 			Normally, writes to the InnoDB buffer pool happen in the background.
#
# 			When InnoDB needs to read or create a page and no clean pages are available, InnoDB flushes
# 			some dirty pages first and waits for that ops. to finish.
#
# 			This counter counts instances of these waits. If innodb_buffer_pool_size has been set properly,
# 			this value should be small.
#
# 		Innodb_buffer_pool_write_requests
#
# 			Number of writes done to the InnoDB buffer pool.
#
# 		Innodb_data_fsyncs
#
# 			The number of fsync() operations so far.
#
# 			The frequency of fsync() calls influenced by the setting of the innodb_flush_method configuration option.
#
# 		Innodb_data_pending_fsyncs
#
# 			The current number of pending fsyncs() operations.
#
# 			The frequency of fsync() calls is influenced by the setting of the innodb_flush_method configuration ops.
#
# 		Innodb_data_pending_reads
#
# 			The current number of pending reads.
#
# 		Innodb_data_pending_writes
#
# 			The current number of pending writes.
#
# 		Innodb_data_read
#
# 			The amount of data read since the server was started (in bytes)
#
# 		Innodb_data_reads
#
# 			The total number of data reads (OS file reads)
#
# 		Innodb_data_writes
#
# 			Total number of data writes
#
# 		Innodb_data_written
#
# 			The amount of data written so far, in bytes.
#
# 		Innodb_dblwr_pages_written
#
# 			The number of pages that have been written to the doublewrite buffer.
#
# 		Innodb_dblwr_writes
#
# 			Number of doublewrite operations that have been performed.
#
# 		Innodb_have_atomic_builtins
#
# 			Indicates whether the server was built with atomic instructions.
#
# 		Innodb_log_waits
#
# 			The number of times that the log buffer was too small and a wait was required for it to be flushed before continuing.
#
# 		Innodb_log_write_requests
#
# 			The number of write requests for the InnoDB redo log.
#
# 		Innodb_log_writes
#
# 			The number of physical writes to the InnoDB redo log file.
#
# 		Innodb_num_open_files
#
# 			The number of files InnoDB currently holds open.
#
# 		Innodb_os_log_fsyncs
#
# 			The number of fsync() writes done to the InnoDB redo log files.
#
# 		Innodb_os_log_pending_fsyncs
#
# 			The number of pending fsync() operations for the InnoDB redo log files.
#
# 		Innodb_os_log_pending_writes
#
# 			The number of pending writes to the InnoDB redo log files.
#
# 		Innodb_os_log_written
#
# 			The number of bytes written to the InnoDB redo log files.
#
# 		Innodb_page_size
#
# 			InnoDB page size (default 16KB).
#
# 			Many values are counted in pages; the page size enables them to be easily converted to bytes.
#
# 		Innodb_pages_created
#
# 			Number of pages created by operations on InnoDB tables.
#
# 		Innodb_pages_read
#
# 			Number of pages read from the InnoDB buffer pool by operations on InnoDB tables.
#
# 		Innodb_pages_written
#
# 			The number of pages written by operations on InnoDB tables.
#
# 		Innodb_row_lock_current_waits
#
# 			The number of row locks currently being waited for by operations on InnoDB tables.
#
# 		Innodb_row_lock_time
#
# 			The total time spent in acquiring row locks for InnoDB tables, in MS.
#
# 		Innodb_row_lock_time_avg
#
# 			The average time to acquire a row lock for InnoDB tables, in MS.
#
# 		Innodb_row_lock_time_max
#
# 			The max time to acquire a row lock for InnoDB tables, in MS.
#
# 		Innodb_row_lock_waits
#
# 			Number of times operations on InnoDB tables had to wait for a row lock.
#
# 		Innodb_rows_deleted
#
# 			The number of rows deleted from InnoDB tables.
#
# 		Innodb_rows_inserted
#
# 			The number of rows inserted into InnoDB tables.
#
# 		Innodb_rows_read
#
# 			The number of rows read from InnoDB tables.
#
# 		Innodb_rows_updated
#
# 			The number of rows updated in InnoDB tables.
#
# 		Innodb_truncated_status_writes
#
# 			The number of times output from the SHOW ENGINE INNODB STATUS statement has been truncated.
#
# 		Key_blocks_not_flushed
#
# 			The number of key blocks in the MyISAM key cache that have changed but have not yet been flushed to disk.
#
# 		Key_blocks_unused
#
# 			The number of unused blocks in the MyISAM key cache.
#
# 			You can use this value to determine how much of the key cache is in use. (Relates to key_buffer_size)
#
# 		Key_blocks_used
#
# 			The number of used blocks in the MyISAM key cache.
#
# 			This value is a high-water mark that indicates the max number of blocks that have ever been
# 			in use at one time.
#
# 		Key_read_requests
#
# 			Number of requests to read a key block from the MyISAM key cache.
#
# 		Key_reads
#
# 			The number of physical reads of a key block from the disk into the MyISAM key cache.
#
# 			If Key_reads is large, then your key_buffer_size value is probably too small.
#
# 			The cache miss rate can be calculated as Key_reads/Key_read_requests
#
# 		Key_write_requests
#
# 			Number of requests to write a key block to the MyISAM key cache.
#
# 		Key_writes
#
# 			Number of physical writes of a key block from the MyISAM key cache to disk.
#
# 		Last_query_cost
#
# 			The total cost of the last compiled query as computed by the query optimizer.
#
# 			Useful for comparing the cost of different query plans for the same query.
#
# 			The default value of 0 means that no query has been compiled yet.
#
# 			The default value is 0. 
#
# 			This var has session scope.
#
# 			The Last_query_cost value can be computed accurately only for simple "flat" queries,
# 			not complex queries such as those with subqueries or UNION.
#
# 			For UNION, it is set to 0.
#
# 		Last_query_partial_plans
#
# 			Number of iterations the query optimizer made in execution plan construction for the previous query.
# 			Has session scope.
#
# 		Locked_connects
#
# 			Number of attempts to connect to locked user accounts.
#
# 			Covered later.
#
# 		Max_execution_time_exceeded
#
# 			The number of SELECT statements for which the execution timeout was exceeded.
#
# 		Max_execution_time_set
#
# 			The number of SELECT statements for which a nonzero execution timeout was set.
#
# 			This includes statements that include a nonzero MAX_EXECUTION_TIME optimizer hint,
# 			and statements that include no such hint but execute while the timeout indicated by the max_execution_time SYS_VAR is nonzero.
#
# 		Max_execution_time_set_failed
#
# 			The number of SELECT statements for which the attempt to set an execution timeout failed.
#
# 		Max_used_connections
#
# 			The max number of connections that have been in use simultaneously since the server started.
#
# 		Max_used_connections_time
#
# 			The time at which Max_used_connections reached its current value.
#
# 		Not_flushed_delayed_rows
#
# 			This Status var is DEPRECATED (DELAYED not supported)
#
# 		mecab_charset
#
# 			The char set currently used by the MeCab full-text parser plugin.
#
# 		Ongoing_anonymous_transaction_count
#
# 			Shows the number of ongoing transactions which have been marked as anon.
# 			This can be Used to ensure that no further transactions are waiting to be processed.
#
# 		Ongoing_anonymous_gtid_violating_transaction_count
#
# 			This status var is only available in debug builds. 
# 			Shows the number of ongoing transactions which use gtid_next=ANONYMOUS and that violate GTID consistency.
#
# 		Ongoing_automatic_gtid_violating_transaction_count
#
# 			This status var is only available in debug builds.
# 			Shows the number of ongoing transactions which use gtid_next=AUTOCOMMIT and that violate GTID consistency.
#
# 		Open_files
#
# 			Number of files that are open. This count includes regular files opened by the server.
#
# 			It does not include other types of files such as sockets or pipes.
#
# 			Also, the count does not include files that storage engines open using their own internal functions
# 			rather than asking the server level to do so.
#
# 		Open_streams
#
# 			Number of streams that are open (used mainly for logging)
#
# 		Open_table_definitions
#
# 			Number of cached table defs.
#
# 		Open_tables
#
# 			The number of tables that are open.
#
# 		Opened_files
#
# 			The number of files that have been opened with my_open() 
# 			(a mysys lib function).
#
# 			Parts of the server that open files without using this function do not increment
# 			the count.
#
# 		Opened_table_definitions
#
# 			Number of table definitions that have been cached.
#
# 		Opened_tables
#
# 			Number of tables that have been opened. 
# 			If Opened_tables is big, your table_open_cache value is probably too small.
#
# 		Performance_schema_xxx
#
# 			Performance Schema status variables are listed later.
#
# 			They provide info about instrumentation that could not be loaded or created due to memory constraints.
#
# 		Prepared_stmt_count
#
# 			The current number of prepared statements. (max number of statements is given by the max_prepared_stmt_count SYS_VAR)
#
# 		Qcache_free_blocks/Qcache_free_memory/Qcache_hits/Qcache_inserts/Qcache_lowmem_prunes/Qcache_not_cached/Qcache_queries_in_cache/Qcache_total_blocks
#
# 			Removed in 8.0.3
#
# 		Queries
#
# 			Number of statements executed by the server.
#
# 			This var includes statements executed within stored programs, unlike the Questions variable.
#
# 			Does not count COM_PING or COM_STATISTICS commands.
#
# 		Questions
#
# 			THe number of statements executed by the server.
#
# 			This includes only statements sent ot hte server by clients and not statements executed
# 			within stored programs, unlike the Queries variable.
#
# 			This variable does not count COM_PING, COM_STATISTICS, COM_STMT_PREPARE, COM_STMT_CLOSE or COM_STMT_RESET commands.
#
# 		Rpl_semi_sync_master_clients
#
# 			Number of semisynch slaves
#
# 			Only available if the master-side semisynch replication plugin is installed.
#
# 		Rpl_semi_sync_master_net_avg_wait_time
#
# 			Average time in MS the master waited for a slave reply.
#
# 			Always 0, deprecated. Only available if master-side semisynch replication plugin is installed.
#
# 		Rpl_semi_sync_master_net_wait_time
#
# 			Total time, same as above. Deprecated.
#
# 		Rpl_semi_sync_master_net_waits
#
# 			Total number of times the master waited for slave replies.
#
# 			Only available if the master-side semisynch replication plugin is installed.
#
# 		Rpl_semi_sync_master_no_times
#
# 			Number of times the master turned off semisynch replication.
#
# 			Onl available if the master-side semisynch replication plugin is installed.
#
# 		Rpl_semi_sync_master_no_tx
#
# 			Number of commits that were not acknowledged successfully by a slave.
#
# 			Same as above, reqs semisynch repl. plugin
#
# 		Rpl_semi_sync_master_status
#
# 			Whether semisynch replication currently is operational on the master.
#
# 			The value is ON if the plugin has been enabled and a commit acknowledgement has occurred.
#
# 			OFF if plugin is off or the Master has fallen back to asynch replication due to commit aknowledge timeout.
#
# 			Reqs the semisynch repl. plugin installed on master-side
#
# 		Rpl_semi_sync_master_timefunc_failures
#
# 			Number of times the master failed when calling time functions such as gettimeofday()
#
# 			Only available if master-side semi-synch replication plugin is installed.
#
# 		Rpl_semi_sync_master_tx_avg_wait_time
#
# 			The average time in ms the master waited for each transaction.
#
# 			Only available if the master-side semi-synch replication plugin is installed.
#
# 		Rpl_semi_sync_master_tx_wait_time
#
# 			Total time in MS instead of avg.
# 			Same req as before.
#
# 		Rpl_semi_sync_master_tx_waits
#
# 			Total number of times the master waited for transactions.
#
# 			Same req as before.
#
# 		Rpl_semi_sync_master_wait_pos_backtraverse
#
# 			total number of times the master waited for an event with binary co-ords lower than events waited for previously.
#
# 			This can occur when the order in which transactions start waiting for a reply is different from the
# 			order in which their binary log events are written.
#
# 			Same req as before
#
# 		Rpl_semi_sync_master_wait_sessions
#
# 			Number of sessions currently waiting for slave replies.
#
# 			Same req as before.
#
# 		Rpl_semi_sync_master_yes_tx
#
# 			Number of commits that were acknowledged successfully by a slave.
#
# 			Same req as before.
#
# 		Rpl_semi_sync_slave_status
#
# 			Whether semisynch replication currently is operational on the slave.
#
# 			This is ON if the plugin has been enabled and the slave I/O thread is running, OFF otherwise.
#
# 			same req as before.
#
# 		Rsa_public_key
#
# 			If MySQL was compiled with OpenSSL.
#
# 			Is the public key vlaue used by the sha256_password authentication plugin for RSA key pair PW exchange.
#
# 			Nonempty only if hte server successfully intiializes the private and public keys in the files named by the
# 			sha256_password_private_key_path and sha256_password_public_key_path SYS_VARs.
#
# 			The Rsa_public_key comes from the latter one.
#
# 		Secondary_engine_execution_count
#
# 			Future use.
#
# 		Select_full_join
#
# 			Number of joins that perform table scans because they do not use indexes.
#
# 			If this value is not 0, check indexes of tables.
#
# 		Select_full_range_join
#
# 			Number of joins that used a range search on a reference table.
#
# 		Select_range
#
# 			Number of joins that used ranges on the first table.
#
# 			Normally not a critical issue even if large.
#
# 		Select_range_check
#
# 			Number of joins without keys that check for key usage after each row.
#
# 			If not 0, check indexes of tables.
#
# 		Select_scan
#
# 			Number of joins that did a full scan of the first table.
#
# 		Slave_heartbeat_period
#
# 			Obsolete. Use HEARTBEAT_INTERVAL column of the replication_connection_configuration table.
#
# 		Slave_last_heartbeat
#
# 			Obsolete. use LAST_HEARTBEAT_TIMESTAMP column of the replication_connection_status table.
#
# 		Slave_open_temp_tables
#
# 			Number of temp tables that the slave SQL thread currently has open.
#
# 			If the value is greater than 0, it is not safe to shut down the slave.
#
# 			This variable reports the total count of open temp tables for ALL replication channels.
#
# 		Slave_received_heartbeats
#
# 			 Obsolete. Use COUNT_RECEIVED_HEARTBEATS column of the replication_connection_status table.
#
# 		Slave_retired_transactions
#
# 			Obsolete. Use COUNT_TRANSACTIONS_RETRIES column of the replication_applier_status table.
#
# 		Slave_rows_last_search_algorithm_used
#
# 			The search algorithm that was most recently used by this slave to locate rows for row-based replication.
#
# 			The result shows whether the slave used indexes, a table scan or hashing as the search algorithm for the
# 			last transaction executed on any channel.
#
# 			The method used depends on the setting for the slave_rows_search_algorithms SYS_VAR, and the keys
# 			that are available on the relevant table.
#
# 			Only available for debug builds of MySQL.
#
# 		Slave_running
#
# 			Obsolete, removed in 8.0.1. Use SERVICE_STATE column of the replication_connection_status and replication_applier_status tables.
#
# 		Slow_launch_threads
#
# 			The number of threads that have taken more than slow_launch_time seconds to create.
#
# 		Slow_queries
#
# 			The number of queries that have taken more than long_query_time seconds.
# 			Increments regardless of whether the slow query log is enabled.
#
# 		Sort_merge_passes
#
# 			The number of merge passes that the sort algorithm has had to do.
# 			If this value is large, you should consider increasing the value of the sort_buffer_size SYS_VAR.
#
# 		Sort_range
#
# 			Number of sorts that were done using ranges
#
# 		Sort_rows
#
# 			Number of sorted rows
#
# 		Sort_scan
#
# 			Number of sorts that were done by scanning the table.
#
# 		Ssl_accept_renegotiates.
#
# 			Number of negotiates needed to establish the connection.
#
# 		Ssl_accepts
#
# 			Number of accepted SSL connections
#
# 		Ssl_callback_cache_hits
#
# 			Number of callback cache hits
#
# 		Ssl_cipher
#
# 			Current encryption cipher (empty for unencrypted connections)
#
# 		Ssl_cipher_list
#
# 			The list of possible SSL ciphers (empty for non-SSL connections)
#
# 		Ssl_client_connects
#
# 			Number of SSL connection attempts to an SSL-enabled master.
#
# 		Ssl_connect_renegotiates
#
# 			Number of negotiates needed to establish the connection to an SSL-enabled master.
#
# 		Ssl_ctx_verify_depth
#
# 			The SSL context verification depth (how many certs in the chain are tested)
#
# 		Ssl_ctx_verify_mode
#
# 			The SSL context verification mode
#
# 		Ssl_default_timeout
#
# 			The default SSL timeout
#
# 		Ssl_finished_accepts
#
# 			Number of successful SSL connections to the server
#
# 		Ssl_finished_connects
#
# 			The number of successful slave connections to an SSL-enabled master.
#
# 		Ssl_server_not_after
#
# 			The last date for which the SSL certificate is valid.
#
# 			To check SSL certificate expiration information, use this statement:
#
# 				SHOW STATUS LIKE 'Ssl_server_not%';
# 				+--------------------------------------------------+
# 				| Variable_name 		   | 	  Value                 |
# 				+-----------------------+--------------------------+
# 				| Ssl_server_not_after  | Apr 28 14:16:39 2025 GMT |
# 				| Ssl_server_not_before | May  1 14:16:39 2015 GMT |
# 				+-----------------------+--------------------------+
#
# 		Ssl_server_not_before
#
# 			The first date for which the SSL certificate is valid.
#
# 		Ssl_session_cache_hits
#
# 			The number of SSL session cache hits.
#
# 		Ssl_session_cache_misses
#
# 			The number of SSL session cache misses.
#
# 		Ssl_session_cache_mode
#
# 			The SSL session cache mode.
#
# 		Ssl_session_cache_overflows
#
# 			The number of SSL session cache overflows.
#
# 		Ssl_session_cache_size
#
# 			The SSL session cache size.
#
# 		Ssl_session_cache_timeouts
#
# 			The number of SSL session cache timeouts
#
# 		Ssl_sessions_reused
#
# 			How many SSL connections were reused from the cache.
#
# 		Ssl_used_session_cache_entries
#
# 			How many SSL session cache entries were used.
#
# 		Ssl_verify_depth
#
# 			The verification depth for replication SSL connections.
#
# 		Ssl_verify_mode
#
# 			The verification mode used by the server for a connection that uses SSL.
#
# 			The value is a bitmask; bits are defined in the openssl/ssl.h header file:
#
# 				# define SSL_VERIFY_NONE 					  0x00
# 				# define SSL_VERIFY_PEER 					  0x01
# 				# define SSL_VERIFY_FAIL_IF_NO_PEER_CERT 0x02
# 				# define SSL_VERIFY_CLIENT_ONCE 			  0x04
#
# 			SSL_VERIFY_PEER indicates that the server asks for a client cert.
#
# 			If the client supplies one, the server performs verification and proceeds only
# 			if verification is successful.
#
# 			SSL_VERIFY_CLIENT_ONCE indicates that a request for the client certificate will be done
# 			only in the initial handshake.
#
# 		Ssl_version
#
# 			The SSL protocol version of the connection; for example, TLSV1. 
# 			If the connection is not encrypted, the value is empty. 
#
#
# 		Table_locks_immediate
#
# 			The number of times that a request for a table lock could be granted immediately.
#
# 		Table_locks_waited
#
# 			The number of times that a request for a table could not be granted immediately and a wait was needed.
#
# 			If this is high and you have performance problems, you should first optimize your queries, and then either
# 			split your table or tables or use replication.
#
# 		Table_open_cache_hits
#
# 			The number of hits for open tables cache lookups
#
# 		Table_open_cache_misses
#
# 			The number of misses for open table cache lookups.
#
# 		Table_open_cache_overflows
#
# 			The number of overflows for the open tables cache.
#
# 			This is the number of times, after a table is opened or closed, a cache instance has an unused
# 			entry and the size of the instance is larger than table_open_cache/table_open_cache_instances
#
# 		tablespace_definition_cache
#
# 			Cmd-line: 		--tablespace-definition-cache=N
# 			Sys_Var: 		tablespace_definition_cache
# 			Scope: 			Global
# 			Dynamic: 		Yes
# 			SET_VAR Hint: 	No
# 			Type: 			Integer
# 			Default: 		256
# 			Min: 				256
# 			Max: 				524288
#
# 			Defines a limit for the number of tablespace definition objects, both used and unused, that can be kept in the dictionary
# 			object cache.
#
# 			Unused tablespace definition objects are only kept in the dictionary object cache when the number in use is less
# 			than the capacity defined by tablespace_definition_cache
#
# 			A setting of 0 means that tablespace definition objects are only kept in the dictionary object cache while they are in use.
#
# 		Tc_log_max_pages_used
#
# 			For the memory-mapped implementation of the log that is used by mysqld when it acts as the transaction coordinator for recovery
# 			of internal XA transactions, this variable indicates the largest number of pages used for the log since the server started.
#
# 			If the product of Tc_log_max_pages_used and Tc_log_page_size is always significantly less than the log size, the size is larger
# 			than necessary and can be reduced.
#
# 			(The size is set by the --log-tc-size option)
#
# 			This variable is unused, it is unneeded for binary log-based recovery, and the memory-mapped recovery log
# 			method is not used unless the number of storage engines that are capable of two-phase commit and that 
# 			supports XA transactions is greater than one.
#
# 			(InnoDB is the only one)
#
# 		Tc_log_page_size
#
# 			The page size used for the memory-mapped implementation of the XA recovery log.
# 			The default value is determined using getpagesize()
#
# 			Unused for the same reason as Tc_log_max_pages_used
#
# 		Tc_log_page_waits
#
# 			For the memory-mapped implementation of the recovery log, this variable increments each time the server
# 			was not able to commit a transaction and had to wait for a free page in the log.
#
# 			If this value is large, might want to increase the log size (with the --log-tc-size option).
#
# 			For binary log-based recovery, this variable increments each time the binary log cannot be closed because
# 			there are two-phase commits in progress.
#
# 			(The close operation waits until all such transactions are finished)
#
# 		Threads_cached
#
# 			The number of threads in the thread cache
#
# 		Threads_connected
#
# 			The number of currently open connections
#
# 		Threads_created
#
# 			The number of threads created to handle connections.
#
# 			If Threads_created is big, you may want to increase the thread_cache_size value.
#
# 			The cache miss rate can be calculated as Threads_created/Connections
#
# 		Threads_running
#
# 			The number of threads that are not sleeping
#
# 		Uptime
#
# 			The number of seconds that the server has been up
#
# 		Uptime_since_flush_status
#
# 			The number of seconds since the most recent FLUSH STATUS statement.
#
# The following section covers the interactions of Server SQL Modes:
#
# The MySQL server can operate in different SQL modes, and can apply these modes differently for different clients,
# depending on the value of the sql_mode SYS_VAR.
#
# DBAs can set the global SQL mode to match site server OS reqs, and each application can set its session SQL mode to its own
# requirements.
#
# Modes affect the SQL syntax MySQL supports and the data validation checks it performs.
# This makes it easier to use MySQL in different envs and to use MySQL together with other DB servers.
#
# When working with InnoDB - we have to keep innodb_strict_mode SYS_VAR. It enables additional error checks for InnoDB tables.
#
#
#
#
#
# The following section pertains to Setting the SQL Mode:
#
# The default SQL mode in MySQL 8.0 includes these modes:
#
# 		ONLY_FULL_GROUP_BY
# 		STRICT_TRANS_TABLES
# 		NO_ZERO_IN_DATE
# 		NO_ZERO_DATE
# 		ERROR_FOR_DIVISION_BY_ZERO
# 		NO_ENGINE_SUBSTITUTION
#
# To set the SQL mode at server startup, use the --sql-mode="modes" option on the cmd line,
# or sql-mode="modes" in an option file such as my.cnf (Unix OS's) or my.ini (Windows).
#
# modes is a list of different modes separated by commas. 
#
# To clear the SQL mode explicitly, set it to an empty string using --sql-mode="" on
# the cmd line, or sql-mode="" in an option file.
#
# Note: MySQL installation programs may configure the SQL mode during the install process.
# 			
# 		  If the SQL mode differs from the default or from what you expect, check for a setting.
#
# To set at runtime:
#
# 		SET GLOBAL sql_mode = 'modes';
# 		SET SESSION sql_mode = 'modes';
#
# Setting the GLOBAL variable requires the SYSTEM_VARIABLES_ADMIN or SUPER privs and affects the operation
# of all clients that connect from that time on.
#
# Setting the SESSION variable affects only the current client.
#
# Each client can change its session sql_mode value at any time.
#
# To determine the current value:
#
# SELECT @@GLOBAL.sql_mode;
# SELECT @@SESSION.sql_mode;
#
# NOTE: 	SQL mode and user-defined partitioning 
#
# 			Changing the server SQL mode after creating and inserting data into partitioned tables can cause major
# 			changes in the behavior of such tables, and could lead to loss or corruption of data.
#
# 			It is strongly recommended that you never change the SQL mode once you have created tables
# 			employing user-defined partitioning.
#
# 			When replicating partitioned tables, differing SQL modes on the master and slave can also lead to
# 			problems.
#
# 			For best results, you should always use the same server SQL mode on the master and slave.
#
# The most important sql_mode values are probably these:
#
# 		ANSI - This mode changes syntax and behavior to conform more closely to standard SQL.
#
# 		STRICT_TRANS_TABLES - If a value could not be inserted as given into a transactional table, abort the statement.
#
# 									 For a nontransactional table, abort the statement if the value occurs in a single-row statement
# 									 or the first row of a multiple-row statement.
#
# 		TRADITIONAL - Make MySQL behave like a "traditional" SQL DB system. Give an error instead of a warning when inserting a incorrect
# 						  value into a column.
#
# 						  NOTE - With TRADITIONAL mode enabled, an INSERT or UPDATE aborts as soon as an error occurs.
#
# 									If you are using a nontransactional storage engine, this may not be what you want because
# 									data changes made prior to the error may not be rolled back, resulting in a "partiall done" update.
#
# "strict mode" here - will refer to STRICT_TRANS_TABLES/STRICT_ALL_TABLES enabled.
#
# The following covers all supported SQL modes:
#
# ALLOW_INVALID_DATES - Do not perform full checking of dates. Check only that the month is in the range from 1 to 12 and that the
# 								day is in the range from 1 to 31.
#
# 								This may be useful for Web applications that obtain year, month and day in three different fields and 
# 								store exactly what the user inserted, without date validation.
#
# 								This mode applies to DATE and DATETIME columns.
# 								It does not apply TIMESTAMP columns, which always require a valid date.
#
# 								With ALLOW_INVALID_DATES enabled, the server requires that month and day values be legal,
# 								and not merely in the range 1 to 12 and 1 to 31.
#
# 								With strict disabled, invalid dates such as '2004-04-31' are converted to '0000-00-00'
# 								and a warning is generated.
#
# 								With strict mode enabled, invalid dates generate an error. To permit it, enable ALLOW_INVALID_DATES.
#
# ANSI_QUOTES - 			Treat " as an identifier quote char (like `) and not as a string quote char.
#
# 								You can still use `to quote identifiers with this mode enabled.
#
# 								With ANSI_QUOTES enabled, you cannot use double quotation marks to quote literal strings
# 								because they are interpreted as identifiers.
#
# ERROR_FOR_DIVISION 	The ERROR_FOR_DIVISION_BY_ZERO mode affects handling of division by zero, which includes MOD(N, 0).
# _BY_ZERO  				
# 								For data-change operations (INSERT,UPDATE) - its effect also depends on whether strict SQL mode is enabled.
#
# 									If this mode is not enabled, division by 0 inserts NULL and produces no warning.
#
# 									If this mode is enabled, division by 0 inserts NULL and produces a warning.
#
# 									If this mode and strict mode are enabled, division by zero produces an error, unless IGNORE is given as well.
# 									For INSERT IGNORE and UPDATE IGNORE, division by zero inserts NULL and produces a warning.
#
# 								For SELECT, division by zero returns NULL. 
#
# 								Enabling ERROR_FOR_DIVISION_BY_ZERO causes a warning to be produced as well, regardless of whether strict mode is enabled.
# 							
# 								ERROR_FOR_DIVISION_BY_ZERO is deprecated. Not part of strict mode, should be used with Strict, on by default.
# 								Causes error if used without strict, and vice versa.
#
# HIGH_NOT_PRECEDENCE 	The precedence of the NOT operator is such that expressions such as NOT a BETWEEN b AND c are parsed as NOT (a BETWEEN b AND c).
#
# 								In some older versions of MySQL, the expression was parsed as (NOT a) BETWEEN b AND c.
#
# 								The old higher-precedence behavior can be obtained by enabling the HIGH_NOT_PRECEDENCE SQL mode.
#
# 								SET sql_mode = '';
# 								SELECT NOT 1 BETWEEN -5 AND 5; #Gives 0 (False), because 1 is between -5 and 5 (1, True), to which inverse of NOT is (0, False)
#
# 								SET sql_mode = 'HIGH_NOT_PRECEDENCE';
# 								SELECT NOT 1 BETWEEN -5 AND 5; #Gives 1 (True), because inversing the result, due to higher not precedence of operator
#
# IGNORE_SPACE 			Permit spaces between a function name and the ( char.
# 								This causes built-in function names to be treated as reserved words.
#
# 								As a result, identifiers that are the same as function names must be quoted.
#
# 								An example, because there is COUNT(), the use of count as a table name, causes an error:
#
# 									CREATE TABLE count (i INT);
# 									ERROR 1064 (42000): You have an error in your SQL syntax
#
# 								The table name should be quoted:
#
# 									CREATE TABLE `count` (i INT);
# 									Query OK, 0 rows affected (0.00 sec)
#
# 								The IGNORE_SPACE SQL mode applies to built-in functions, not to user-defined functions or stored functions.
#
# 								It is always permissible to have spaces after a UDF or stored function name, regardless of whether IGNORE_SPACE is enabled.
#
# NO_AUTO_VALUE_ON_ZERO Affects handling of AUTO_INCREMENT columns.
#
# 								Normally, you generate the next sequence number for the column by inserting either NULL or 0
# 								into it. NO_AUTO_VALUE_ON_ZERO suppresses this behavior for 0 so that only NULL generates the
# 								next sequence number.
#
# 								This mode can be useful if 0 has been stored in a tables AUTO_INCREMENT column.
# 								(Storing 0 is not a recommended practice, by the way)
#
# 								For example, if you dump the table with mysqldump and then reload it, MySQL
# 								normally generates new sequence numbers when it encounters the 0 value, resulting
# 								in a table with contents different from the one that was dumped.
#
# 								Enabling NO_AUTO_VALUE_ON_ZERO before reloading the dump file solves this problem.
#
# 								For this reason, mysqldump automatically includes in its output a statement that enables
# 								NO_AUTO_VALUE_ON_ZERO
#
# NO_BACKSLASH_ESCAPES 	Disables the use of the \ char as an escape char within strings. With this mode enabled, \ becomes an ordinary char like any other.
#
# NO_DIR_IN_CREATE 		When creating a table, ignore all INDEX DIRECTORY and DATA DIRECTORY directives. Useful on slave replication servers.
#
# NO_ENGINE 				Control automatic substitution of the default storage engine when a statement such as CREATE_TABLE or ALTER_TABLE specifies a 
# _SUBSTITUTION 			storage engine that is disabled or not compiled in.
#
# 								By default, NO_ENGINE_SUBSTITUTION is enabled.
#
# 								Because storage engines can be pluggable at runtime, unavailable engines are treated the same way.
#
# 								With NO_ENGINE_SUBSTITUTION disabled, for CREATE TABLE the default engine is used and a warning occurs if the desired
# 								engine is unavailable.
#
# 								For ALTER_TABLE, a warning occurs and the table is not altered.
#
# 								With NO_ENGINE_SUBSTITUTION enabled, an error occurs and the table is not created or altered if the desired engine is unavailable.
#
# NO_UNSIGNED 				Subtraction between integer values, where one is of type UNSIGNED, produces an unsigned result by default.
# _SUBTRACTION 			If the result would otherwise have been negative, an error results:
#
# 									SET sql_mode = '';
# 									Query OK, 0 rows affected (0.00 sec)
#
# 									SELECT CAST(0 AS UNSIGNED) -1;
# 									ERROR 1690 (22003): BIGINT UNSIGNED value is out of range in '(cast(0 as unsigned) - 1)'
#
# 								If the NO_UNSIGNED_SUBTRACTION SQL mode is enabled, the result is negative:
#
# 									SET sql_mode = 'NO_UNSIGNED_SUBTRACTION';
# 									SELECT CAST(0 AS UNSIGNED) - 1;
# 
# 									+---------------------------------------+
# 									| CAST(0 AS UNSIGNED) 	-  	1 			 |
# 									+---------------------------------------+
# 									| 									  -1 			 |
# 									+---------------------------------------+
#
# 								If the result of such an operation is used to update an UNSIGNED integer column, the result is 
# 								clipped to the maximum value for the column type - or clipped to 0 if NO_UNSIGNED_SUBTRACTION is enabled.
#
# 								With strict SQL mode enabled, an error occurs and the column remains unchanged.
#
# 								When NO_UNSIGNED_SUBTRACTION is enabled, the subtraction result is signed, even if any operand is unsigned.
# 		
# 								For example - compare the type of column c2 in table t1 with that of column c2 in table t2:
#
# 									SET sql_mode='';
# 									CREATE TABLE test (c1 BIGINT UNSIGNED NOT NULL);
# 									CREATE TABLE t1 SELECT c1 - 1 AS c2 FROM test;
# 									DESCRIBE t1;
#
# 									+-----------------------------------------------------------------+
# 									| Field 	| 	Type 							| Null | Key | Default| Extra |
# 									+--------+--------------------------+------+-----+--------+-------+
# 									| c2 		| bigint(21) unsigned 		| NO 	 | 	 | 0 		 | 		|
# 									+--------+--------------------------+------+-----+--------+-------+
#
# 									SET sql_mode='NO_UNSIGNED_SUBTRACTION';
# 									CREATE TABLE t2 SELECT c1 - 1 AS c2 FROM test;
# 									DESCRIBE t2;
#
# 									+------------------------------------------------------------------+
# 									| Field | Type 							| Null | Key | Default | Extra |
# 									+-------+---------------------------+------+-----+---------+-------+
# 									| c2 	  | bigint(21) 					| NO 	 | 	 | 0 		  | 		 |
# 									+-------+---------------------------+------+-----+---------+-------+
#
# 								This simply means that BIGINT UNSIGNED is not 100% usable in all contexts.
#
# NO_ZERO_DATE
#
# 								The NO_ZERO_DATE mode affects whether the server permits '0000-00-00' as a valid date.
# 								Its effect also depends on whether strict SQL mode is enabled.
#
# 									If this mode is not enabled, '0000-00-00' is permitted and inserts produce no warning.
#
# 									If this mode is enabled, '0000-00-00' is permitted and inserts produce a warning.
#
# 									If this mode and strict is enabled, '0000-00-00' is not permitted and inserts produce an error,
# 									unless IGNORE is given as well. (For INSERT IGNORE and UPDATE IGNORE, '0000-00-00' is permitted and inserts produce a warning)
#
# 								This mode is deprecated. Should be used with Strict, is not part of it. Produces warning if one is used without other, etc.
#
# NO_ZERO_IN_DATE 		The NO_ZERO_IN_DATE mode affects whether the server permits dates in which the year part is nonzero but the month or day part is 0.
# 								(This mode affects dates such as '2010-00-01' or '2010-01-00' - but not '0000-00-00')
#
# 								To control whether the server permits '0000-00-00', use the NO_ZERO_DATE mode.
#
# 								The effect of NO_ZERO_IN_DATE also depends on whether strict SQL mode is enabled.
#
# 									If this mode is not enabled, dates with zero parts are permitted and inserts produce no warning.
#
# 									If this mode is enabled, dates with zero parts are inserted as '0000-00-00' and produce a warning.
#
# 									If this mode and strict mode is enabled,  dates with zero parts are not permitted and inserts produce an error,
# 									unless IGNORE is given as well. (For INSERT IGNORE and UPDATE IGNORE, dates with zero parts are inserted as '0000-00-00' and produce a warning).
#
#
# 								Deprecated. not part of Strict. Warning if not used with Strict, etc.
#
# ONLY_FULL_GROUP_BY 	Reject queries for which the select list, HAVING condition or ORDER BY list refer to nonaggregated columns that are 
# 								neither named in the GROUP BY clause nor are functionally dependant on (uniquely determined by) GROUP BY columns.
#
# 								A MySQL extension to standard SQL permits references in the HAVING clause to aliased expressions in the select list.
# 								The HAVING clause can refer to aliases regardless of whether ONLY_FULL_GROUP_BY is enabled.
#
# PAD_CHAR_TO_FULL_LENGTH
#
# 								By default, trailing spaces are trimmed from CHAR column values on retrieval.
#
# 								If PAD_CHAR_TO_FULL_LENGTH is enabled, trimming does not occur and retrieved CHAR values are padded
# 								to their full length.
#
# 								This mode does not apply to VARCHAR columns, for which trialing spaces are retained on retrieval.
#
# 								NOTE: Deprecated as of 8.0.13
#
# 								CREATE TABLE t1 (c1 CHAR(10));
# 								Query OK, 0 rows affected (0.37 secs)
#
# 								INSERT INTO t1 (c1) VALUES('xy'));
#  							Query OK, 1 row affected (0.01 sec)
#
# 								SET sql_mode = '';
# 								Query OK, 0 rows affected (0.00 sec)
#
# 								SELECT c1 CHAR_LENGTH(c1) FROM t1;
#
# 								+----------------------------------+
# 								| c1 		| 	CHAR_LENGTH(c1) 		  |
# 								+--------+-------------------------+
# 								| xy 		| 								2 |
# 								+--------+-------------------------+
# 								1 row in set (0.00 sec)
#
# 								SET sql_mode = 'PAD_CHAR_TO_FULL_LENGTH';
# 								Query OK, 0 rows affected (0.00 sec)
#
# 								SELECT c1, CHAR_LENGTH(c1) FROM t1;
# 								+----------------------------------+
# 								| c1 			| 	CHAR_LENGTH(c1) 	  |
# 								+-----------+----------------------+
# 								| xy 			| 						 	10|
# 								+-----------+----------------------+
# 								1 row in set (0.00 sec)
#
# PIPES_AS_CONCAT
#
# Treat |_| as a string concatenation operator (same as CONCAT()) rather than as a synonym for OR.
#
# REAL_AS_FLOAT
#
# Treat REAL as a synonym for FLOAT. By default, MySQL treats REAL as a synonym for DOUBLE.
#
# STRICT_ALL_TABLES
#
# Enable strict SQL mode for all storage engines. INvalid data values are rejected.
#
# STRICT_TRANS_TABLES
#
# Enable strict SQL mode for transactional storage engines, and when possible for nontransactional storage engines.
#
# TIME_TRUNCATE_FRACTIONAL
#
# Control whether rounding or truncation occurs when inserting a TIME, DATE, or TIMESTAMP value with a fractional
# seconds part into a column having the same type but fewer fractional digits.
#
# The behavior is to use rounding. If this mode is enabled, truncation occurs instead.
# The followin sequence of statements illustrates the difference:
#
# 		CREATE TABLE t (id INT tval TIME(1));
# 		SET sql_mode='';
# 		INSERT INTO t (id, tval) VALUES(1, 1.55);
# 		SET sql_mode='TIME_TRUNCATE_FRACTIONAL';
# 		INSERT INTO t (id, tval) VALUES(2, 1.55);
#
# The resulting table looks like this, where the first value has been subject to rounding and the second to truncation:
#
# 		SELECT id, tval FROM t ORDER BY id;
# 		+--------------------------+
# 		| id 		| 		tval 			|
# 		+--------+-----------------+
# 		| 		1 	| 00:00:01.6 		|
# 		| 		2  | 00:00:01.5 		|
# 		+--------+-----------------+
#
# ANSI is equivalent to:
#
# 		REAL_AS_FLOAT, PIPES_AS_CONCAT, ANSI_QUOTES, IGNORE_SPACE and ONLY_FULL_GROUP_BY
#
# 		ANSI mode also causes the server to return an error for queries where a set function S with an outer reference S(outer_ref) cannot be
# 		aggregated in the outer query against which the outer reference has been resolved. This is such a query:
#
# 			SELECT * FROM t1 WHERE t1.a IN (SELECT MAX(t1.b) FROM t2 WHERE ...);
#
# 		Here - MAX(t1.b) cannot aggregate in the outer query because it appears in the WHERE clause of that query.
#
# 		Standard SQL requires an error in this situation. If ANSI mode is not enabled, the server treats S(outer_ref) in such
# 		queries the same way that it would interpret S(const)
#
# TRADITIONAL
#
# 		TRADITIONAL is equivalent to STRICT_TRANS_TABLES, STRICT_ALL_TABLES, NO_ZERO_IN_DATE, NO_ZERO_DATE, ERROR_FOR_DIVISION_BY_ZERO
# 		and NO_ENGINE_SUBSTITUION
#
# The following pertains to STRICT SQL MODE:
#
# Controls how MySQL handles invalid or missing values in data-change statements such as INSERT or UPDATE.
# A value can be invalid for several reasons.
#
# For example, it might have the wrong data type for the column, or it might be out of range.
#
# A value is missing when a new row to be inserted does not contain a value for a non-NULL column that has
# no explicit DEFAULT clause in its definition. (For a NULL column, NULL is inserted if the value is missing).
#
# Strict mode also affects DDL statements such as CREATE_TABLE.
#
# If strict mode is not in effect, MySQL inserts adjusted values for invalid or missing values and produces warnings.
#
# In strict mode, you can produce this behavior by using INSERT_IGNORE or UPDATE_IGNORE.
#
# For statements such as SELECT that do not change data, invalid values generate a warning in stirct mode, not an error.
#
# Strict mode produces an error for attempts to create a key that exceeds the max key length. When strict mode is not enabled,
# this results in a warning and truncation of the key to the max key length.
#
# Strict mode does not affect whether foreign key constraints are checked. Foreign_key_checks can be used for that.
#
# Strict SQL mode is in effect if either STRICT_ALL_TABLES or STRICT_TRANS_TABLES is enabled, although the effects of these
# modes differ somewhat:
#
# 		For transactional tables, an error occurs for invalid or missing values in a data-change statement when either STRICT_ALL_TABLES or 
# 		STRICT_TRANS_TABLES is enabled. The statement is aborted and rolled back.
#
# 		For nontransactional tables, the behavior is the same for either mode if the bad value occurs in the first row to be inserted or updated:
# 			The statement is aborted and the table remains unchanged.
#
# 			If the statement inserts or modifies multiple rows and the bad value occurs in the second or later row, the result depends
# 			on which strict mode is enabled:
#
# 				For STRICT_ALL_TABLES, MySQL returns an error and ignores the rest of the rows.
# 											  However, because the earlier rows have been inserted or updated, the result is a partial update.
# 											  To avoid this, use single-row statements which can be aborted without changing the table.
#
# 				For STRICT_TRANS_TABLES, MySQL converts an invalid value to the closest valid value for the column and inserts the adjusted value.
# 											  If a value is missing, MySQL inserts the implicit default value for the column data type.
#
# 											  In either case, MySQL generates a warning rather than an error and continues processing the statement.
# 											  Implicit defaults are described later.
#
# 		Strict mode affects handling of division by zero, zero dates  and zero in dates as follows:
#
# 			Strict mode affects handling of division by zero, which includes MOD(N,0):
#
# 				For data-change operations (INSERT,UPDATE):
#
# 					If strict mode is not enabled, division by zero inserts NULL and produces no warning.
#	
# 					If strict mode is enabled, division by zero produces an error, unless IGNORE is given as well.
# 					For INSERT IGNORE and UPDATE IGNORE, division by zero inserts NULL and produces a warning.
#
# 				For SELECT, division by zero returns NULL. Enabling strict mode causes a warning to be produced as well.
#
# 			Strict mode affects whether the server permits '0000-00-00' as a valid date:
#
# 				If strict mode is not enabled, '0000-00-00' is permitted and inserts produce no warning.
#
# 				If strict mode is enabled, '0000-00-00' is not permitted and inserts produce an error, unless IGNORE is given as well.
# 				For INSERT IGNORE and UPDATE IGNORE '0000-00-00' is permitted and inserts produce a warning.
#
# 			Strict mode affects whether the server permits dates in which the year part is nonzero but the month or day part is 0 (dates such as '2010-00-01' or '2010-01-00'):
#
# 				If stict mode is not enabled, dates with zero parts are permitted and inserts produce no warning.
#
# 				If strict mode is enabled, dates with zero parts are not permitted and inserts produce an error, unless IGNORE is given as well.
# 				For INSERT IGNORE and UPDATE IGNORE, dates with zero parts are inserted as '0000-00-00' (which is considered valid with IGNORE) and produces a warning.
#
# 			Strict mode affects handling of division by zero, zero dates, and zeros in dates in conjunction with the ERROR_FOR_DIVISION_BY_ZERO, NO_ZERO_DATE and
# 			NO_ZERO_IN_DATE modes.
#
# COMPARISON OF THE IGNORE KEYWORD AND STRICT SQL MODE
#
# 		Compres the effect on statement execution of the IGNORE keyword (which downgrades errors to warnings) and strict SQL mode (which upgrades warnings to
# 		errors). It describes which statements they affect, and which errors they apply to.
#
# 		THe following table presents a summary comparison of statement behavior when the default is to produce an error versus a warning.
#
# 		An example of when the default is to produce an error is inserting a NULL into a NOT NULL column.
#
# 		An example of when the default is to produce a warning is inserting a value of the wrong data type into a 
# 		column (such as inserting the string 'abc' into a integer column)
#
# 						OPS MODE 										WHEN STATEMENT DEFAULT IS ERROR 							WHEN STATEMENT DEFAULT IS WARNING
# 				Without IGNORE or strict SQL mode 				Error 															Warning
# 				With IGNORE 											Warning 															Warning (same as without IGNORE or strict SQL mode)
# 				With strict SQL mode 								Error (same as without IGNORE or strict SQL mode) 	Error
# 				With IGNORE and strict SQL mode 					Warning 															Warning
#
# 		One conclusion to draw from the table is that when the IGNORE keyword and strict SQL mode are both in effect,
# 		IGNORE takes precedence.
#
# 		This means that, although IGNORE and strict SQL mode can be considered to have opposite effects on error handling, they do not cancel each other.
#
# THE EFFECT OF IGNORE ON STATEMENT EXECUTION
#
# Several statements in MySQL support an optional IGNORE keyword. This keyword causes the server to downgrade certain types of errors
# and generate warnings instead. 
#
# For a multiple-row statement, IGNORE causes the statements to skip to the next row instead of aborting.
#
# For example, if the table t has a primary key column i, attempting to insert the same value of i into multiple
# rows normally produces a duplicate-key error:
#
# INSERT INTO t (i) VALUES(1),(1);
# ERROR 1062 (23000): Duplicate entry '1' for key 'PRIMARY'
#
# If we run with IGNORE, A warning is produced instead of an error - though, duplication is still not inserted:
#
# INSERT IGNORE INTO t (i) VALUES(1),(1);
# Query OK, 1 row affected, 1 warning (0.01 sec)
# Records: 2 Duplicates: 1 Warnings: 1
#
# SHOW WARNINGS;
# +----------------------------------------------------------+
# | Level 	| 	Code 	| Message 					  					 |
# +---------+--------+---------------------------------------+
# | Warning | 1062 	| Duplicate entry '1' for key 'PRIMARY' |
# +----------------------------------------------------------+
#
# 1 row in set (0.00 sec)
#
# These statements supports the IGNORE keyword:
#
# 		CREATE TABLE ... SELECT. IGNORE does not apply to the CREATE TABLE or SELECT parts of the statement but to inserts into
# 		the table of rows produced by the SELECT.
#
# 		Rows that duplicate an existing row on a unique key value are discarded.
#
# 		DELETE: IGNORE causes MySQL to ignore errors during the process of deleting rows.
#
# 		INSERT: With IGNORE, rows that duplicate an existing row on a unique key value are discarded.
# 
# 				  Rows set to values that would cause data conversion errors are set to the closest valid values instead.
#
# 				  For partitioned tables where no partition matching a given value is found, IGNORE causes the insert operation 
# 				  to fail silently for rows containing the unmatched value.
#
# 		LOAD_DATA, LOAD_XML: With IGNORE, rows that duplicate an existing row on a unique key value are discarded.
#
# 		UPDATE: With IGNORE, rows for which duplicate-key conflicts occur on a unique key value are not updated.
#
# 				  Rows updated to values that would cause data conversion errors are updated to the closest valid values instead.
#
# The IGNORE keyword applies to the following errors:
#
# 		ER_BAD_NULL_ERROR
# 		ER_DUP_ENTRY
# 		ER_DUP_ENTRY_WITH_KEY_NAME
# 		ER_DUP_KEY
# 		ER_NO_PARTITION_FOR_GIVEN_VALUE
# 		ER_NO_PARTITION_FOR_GIVEN_VALUE_SILENT
# 		ER_NO_REFERENCED_ROW_2
#
# 		ER_ROW_DOES_NOT_MATCH_GIVEN_PARTITION_SET
# 		ER_ROW_IS_REFERENCED_2
# 		ER_SUBQUERY_NO_1_ROW
# 		ER_VIEW_CHECK_FAILED
#
# THE EFFECT OF STRICT SQL MODE ON STATEMENT EXECUTION
#
# The MySQL server can operate in different SQL modes, and can apply these modes differently for different clients, depending
# on the value of the sql_mode SYS_VAR.
#
# In "strict" SQL mode, the server upgrades certain warnings to errors.
#
# For example, in non-strict SQL mode, inserting the string 'abc' into an integer column results in conversion of
# the value to 0 and a warning:
#
# SET sql_mode = '';
# Query OK, 0 rows affected (0.00 sec)
#
# INSERT INTO t (i) VALUES('abc');
# Query OK, 1 row affected, 1 warning (0.01 sec)
#
# SHOW WARNINGS;
# +------------------------------------------------------------------------------+
# | Level 		| Code 	| 		Message 															|
# +------------+--------+--------------------------------------------------------+
# | Warning 	| 1366 	| Incorrect integer value: 'abc' for column 'i' at row 1 |
# +------------+--------+--------------------------------------------------------+
#
# 1 row in set (0.00 sec)
#
# In strict SQL mode, the invalid value is rejected with an error:
#
# SET sql_mode = 'STRICT_ALL_TABLES';
# Query OK, 0 rows affected (0.00 sec)
#
# INSERT INTO t (i) VALUES ('abc');
# ERROR 1366 (HY000): Incorrect integer value: 'abc' for column 'i' at row 1
#
# Strict SQL mode applies the following statements under conditions for which some value might be out of
# range or an invalid row is inserted into or deleted from a table:
#
# ALTER_TABLE
#
# CREATE_TABLE
#
# CREATE_TABLE_..._SELECT
#
# DELETE (both single table and multiple table)
#
# INSERT
#
# LOAD_DATA
# 
# LOAD_XML
#
# SELECT_SLEEP()
#
# UPDATE (both single and multiple tables)
#
# Within stored programs, individual statements of the types just listed execute in strict SQL mode if the program was defined 
# while strict mode was in effect.
#
# Strict SQL mode applies to the following errors, represent a class of errors in which an input value is either invalid or missing.
# A value is invalid if it has the wrong data type for the column or might be out of range.
#
# A value is missing if a new row to be inserted does not contain a value for a NOT NULL column that has no explicit DEFAULT clause
# in its definition.
#
# ER_BAD_NULL_ERROR
# ER_CUT_VALUE_GROUP_CONCAT
# ER_DATA_TOO_LONG
# ER_DATETIME_FUNCTION_OVERFLOW
# ER_DIVISION_BY_ZERO
# ER_INVALID_ARGUMENT_FOR_LOGARITHM
# ER_NO_DEFAULT_FOR_FIELD
# ER_NO_DEFAULT_FOR_VIEW_FIELD
#
# ER_TOO_LONG_KEY
# ER_TRUNCATED_WRONG_VALUE
# ER_TRUNCATED_WRONG_VALUE_FOR_FIELD
# ER_WARN_DATA_OUT_OF_RANGE
# ER_WARN_NULL_TO_NOTNULL
# ER_WARN_TOO_FEW_RECORDS
# ER_WRONG_ARGUMENTS
# ER_WRONG_VALUE_FOR_TYPE
# WARN_DATA_TRUNCATED
#
# The following section pertains to IPv6 Support
#
# Support for IPv6 in MySQL includes these capabilities:
#
# 		MySQL Server can accept TCP/IP connections from clients connecting over IPv6.
#
# 		For example, this command connects over IPv6 to the MySQL server on the local host:
#
# 			mysql -h ::1
#
# 		To use this capability - two conditions must hold true:
#
# 			The system must be configured to support IPv6.
#
# 			The default MySQL server configuration permits IPv6 connections in addition to IPv4 connections.
# 			To change the default configuration, start the server with an appropiate --bind-address option.
#
# 		MySQL account names permit IPv6 addresses to enable DBAs to specify privs for clients that connect 
# 		to the server over IPv6.
#
# 		IPv6 addresses can be specified in account names in statements such as CREATE_USER, GRANT, and REVOKE.
#
# 		For example:
#
# 			CREATE USER 'bill'@'::1' IDENTIFIED BY 'secret';
# 			GRANT SELECT ON mydb.* TO 'bill'@'::1';
#
# 		IPv6 functions enable conversion between string and internal format IPv6 address formats, and checking whether
# 		values represent valid IPv6 addresses.
#
# 		For example, INET6_ATON() and INET6_NTOA() are similar to INET_ATON() and INET_NTOA(), but handle IPv6 in addition
# 		to IPv4 addresses.
#
# The following pertains to verifying system support for IPv6.
#
# Before MySQL server can accept IPv6 connections, the operating system on your server host must support IPv6.
# As a simple test to determine whether that is true - try:
#
# 		ping6 ::1
# 		16 bytes from ::1, icmp_seq=0 hlim=64 time=0.171 ms
# 		16 bytes from ::1, icmp_seq=1 hlim=64 time=0.077 ms
#
# To produce a description of your system's network interfaces, invoke ifconfig -a and look for IPv6 addresses in the output.
#
# If your host does not support IPv6, the reasoning can differ. It can require configuring an existing network config to add an IPv6 address.
# Or you might need to rebuild the kernel with IPv6 options enabled.
#
# There are links to cover for the Linux integrations. But this project focuses on MySQL - one part at a time.
#
# The MySQL server listens on a single network socket for TCP/IP connections.
#
# This socket is bound to a single address, but it is possible for an address to map unto multiple network interfaces.
# To specify an address, use the --bind-address=<addr> option at server startup, where <addr> is an IPv4 or IPv6 address or a host name.
#
# The following pertains to connecting to Local Host address connections using IPv6.
#
# The following procedure shows how to configure MySQL to permit IPv6 connections by clients that connect to the local server using
# the ::1 local host address.
#
# The instructions are based on support of IPv6.
#
# 		1. Start the MySQL server with an appropriate --bind-address option to permit it to accept IPv6 connections.
# 			For example, put the following lines in the server option file and restart the server:
#
# 				[mysqld]
# 				bind-address = *
#
# 			Alternatively, you can bind the server to ::1, but that makes the server more restrictive for TCP/IP connections.
# 			It accepts only IPv6 connections for that single address and rejects IPv4 connections. 
#
# 		2. As an administrator, connect to the server and create an account for a local user who will connect from the ::1 local IPv6 host address:
#
# 				CREATE USER 'ipv6user'@'::1' IDENTIFIED BY 'ipv6pass';
#
# 			For the permitted syntax of Ipv6 addresses in account names - it's covered later.
#
# 			In addition to the CREATE_USER statement, you can issue GRANT statements that give specific
# 			privs to the account, although that is not necessary for this part.
#
# 		3. Invoke the mysql client to connect to the server using the new account:
#
# 				mysql -h ::1 -u ipv6user -pipv6pass
#
# 		4. Try some simple statements that show connection information:
#
# 				STATUS
# 				...
# 				Connection: 	::1 via TCP/IP
# 				...
# 
# 				SELECT CURRENT_USER(), @@bind_address;
# 				+------------------------------------+
# 				| CURRENT_USER() | @@bind_address 	 |
# 				+----------------+-------------------+
# 				| ipv6user@::1   | :: 					 |
# 				+----------------+-------------------+
#
# The following section pertains to Connecting Using IPv6 Nonlocal Host Addresses
#
# The following procedure shows how to configure MySQL to permit IPv6 connections by remote clients.
#
# It is similar to the preceding procedure for local clients, but the server and client hosts are
# distinct and each has its own nonlocal ipv6 address.
#
# The example uses the addresses of:
#
# Server host: 2001:db8:0:f101::1
# Client host: 2001:db8:0:f101::2
#
# These addresses are chosen from the nonroutable address range recommended by IANA for documentation purposes/testing.
# To accept IPv6 connections from clients outside the local network, the server host must have a public address.
#
# If your network provider assigns you an IPv6 address, you can use that.
#
# Otherwise, another way to obtain an address is to use an IPv6 broker.
#
# 		1. Start the MySQL server with an appropriate --bind-address option to permit it to accept IPv6 connections.
# 			For example, put the following lines in the server option file and restart the server:
#
# 				[mysqld]
# 				bind-address = *
#
# 			Alternatively, you can bind the server to 2001:db8:0:f101::1, but that makes the server more restrictive for TCP/IP
# 			connections.
#
# 			It accepts only IPv6 connections for that single address and rejects IPv4 connections.
#
# 		2. On the server host (2001:db8:0:f101::1), create an account for a user who will connect from the client host (2001:db8:f101::2)
#
# 			CREATE USER 'remoteipv6user'@'2001:db8:0:f101::2' IDENTIFIED BY 'remoteipv6pass';
#
# 		3. On the client host (2001:db8:0:f101::2), invoke the mysql client to connect to the server using the new account:
#
# 			mysql -h 2001:db8:0:f101::1 -u remoteipv6user -premoteipv6pass
#
# 		4. Trying some simple commands to see that it works:
#
# 				STATUS
# 				...-
# 				Connection: 	2001:db8:0:f101::1 via TCP/IP
# 				...- 
# 
# 				SELECT CURRENT_USER(), @@bind_address;
# 				+-----------------------------------+----------------+
# 				| CURRENT_USER() 						   | @@bind_address |
# 				+-----------------------------------+----------------+
# 				| remoteipv6user@2001:db8:0:f101::2 | :: 				  |
# 				+-----------------------------------+----------------+
#
# The following part pertains on how to obtain an IPv6 Address from a Broker
#
# If you do not have a public IPv6 address that enables your system to communicate over IPv6 outside of your local network,
# you can obtain one from an Ipv6 broker.
#
# After configuring your server host to use a broker-supplied IPv6 address, start the MySQL server with an appropiate --bind-address
# option to permit the server to accept IPv6 connections.
#
# For example, put the following lines in the server option file and restart the server:
#
# 		[mysqld]
# 		bind-address = *
#
# Alternatively, you can bind the server to the specific IPv6 address provided by the broker, but that makes the server more
# restrictive for TCP/IP connections.
#
# In addition, if the broker allocates dynamic addresses, the address provided for your system might change the next time
# you connect to the broker.
#
# If so, any accounts you create that name the original address, become invalid.
#
# To bind to a specific address but avoid this change-of-address problem, you may be able to arrange with the broker
# for a static IPv6 address.
#
# The following example is for how ot use the Freenet6 as the broker and the gogoc IPv6 client package on Gentoo Linux.
#
# 1. Create an acc on their website -> http://gogonet.gogo6.com
#
# 2. Create the user ID and PW for the IPv6 broker: -> http://gogonet.gogo6.com/page/freenet6-registration
#
# 3. As root, install gogoc:
#
# 		emerge gogoc
#
# 4. Edit /etc/gogoc/gogoc.conf to set the userid and password values. For example:
#
# 		userid=gogouser
# 		passwd=gogopass
#
# 5. Start gogoc:
#
# 		/etc/init.d/gogoc start
#
# 		To start gogoc on system boot:
#
# 		rc-update add gogoc default
#
# 6. ping6 to ping a host:
#
# 		ping6 ipv6.google.com
#
# 7. to see your Ipv6 address:
#
# 		ifconfig tun
#
# The following section pertains to MySQL Server Time Zone Support
#
# MySQL Server maintains several time zone settings:
#
# 		1. The system time zone. When the server starts, it attempts to determine the time zone of the host machine and uses it to set the 
# 		system_time_zone SYS_VAR. Does not change thereafter.
#
# 		Can set the SYS_VAR time zone for MySQL Server at startup with the --timezone=<timezone_name> option to mysqld_safe.
#
# 		You can also set it by setting the TZ environment variable before you start mysqld.
#
# 		The permissible values for --timezone or TZ are system dependent. 
#
# 		2. The server's current time zone. The global time_zone system variable indicates the time zone the server currently is operating in.
# 			The initial value for time_zone is 'SYSTEM', which indicates that the server time zone is the same as the system time zone.
#
# 				NOTE: If set to SYSTEM, every MySQL function call that requires a timezone calculation makes a system library call to determine
# 						the current system timezone. This call may be protected by a global mutex, resulting in contention.
#
# 			The initial global server time zone value can be specified explicitly at startup with the --default-time-zone=<timezone> option on the
# 			cmd line, or you can use the following line in an option file:
#
# 				default-time-zone='timezone'
#
# 			If you have the SYSTEM_VARIABLES_ADMIN or SUPER priv, you can set the global server time zone value at runtime with this statement:
#
# 				SET GLOBAL time_zone = timezone;
#
# 			Per-connection time zones. Each client that connects has its own time zone setting, given by the session time_zone variable.
# 			Initially, the session variable takes its value from the global time_zone variable, but the client can change its own time zone
# 			with this statement:
#
# 				SET time_zone = timezone;
#
# 		The current session time zone setting affects display and storage of time values that are zone-sensitive.
#
# 		This includes the values displayed by functions such as NOW() or CURTIME(), and values stored in and retrieved
# 		from TIMESTAMP columns.
#
# 		Values for TIMESTAMP columns are converted from the current time zone to UTC for storage, and from UTC to the current
# 		time zone for retrieval.
#
# 		The current time zone setting does not affect values displayed by functions such as UTC_TIMESTAMP() or values in DATE, TIME, or DATETIME
# 		columns.
#
# 		Nor are values in those data types stored in UTC; the time zone applies for them only when converting from TIMESTAMP values.
# 		If you want locale-specific arithmetic for DATE, TIME or DATETIME - convert them to UTC, perform the arithemtic, and convert back.
#
# 		The current values of the global and client-specific time zones can be retrieved like this:
#
# 			SELECT @@global.time_zone, @@session.time_zone;
#
# 		<timezone> values can be given in several formats, none of which are case-sensitive:
#
# 			The value 'SYSTEM' indicates that hte time zone should be the same as hte SYS time zone.
#
# 			The vlaue can be given as a string indicating an offset from UTC, such as '+10:00' or '-6:00'
#
# 			The value can be given as a named time zone, such as 'Europe/Helsinki', 'US/Eastern', or 'MET'.
# 			Named time zones can be used only if the time zone information tables in the mysql DB have been created and populated.
#
# POPULATING THE TIME ZONE TABLES
#
# Several tables in the MySQL system DB exists to maintain time zone info.
# The MySQL installation procedure creates the time zone tables, but does not load them.
#
# You must do so manually using the following instructions.
#
# NOTE: Loading the time zone information is not necessarily a one-time operation because the information 
# 		  changes ocassionally. When such changes occur, applications that use the old rules becomes out of date
# 	     and you may find it necessary to reload the time zone tables to keep the information used by your MySQL
# 		  sever current.
#
# If your system has its own zoneinfo DB (the set of files describing time zones), you should use the mysql_tzinfo_to_sql
# program for filling the time zone tables.
#
# Examples of such systems are Linux, FreeBSD, Solaris and macOS. One likely location for these files is the /usr/share/zoneinfo dir.
# If your system does not have a zoneinfo db, you can use the downloadable package described later.
#
# The mysql_tzinfo_to_sql program is used to load the time zone tables.
#
# On the cmd line, pass the zoneinfo dir path name to mysql_tzinfo_to_sql and send the output into the mysql program.
# For example:
#
# 		mysql_tzinfo_to_sql /usr/share/zoneinfo | mysql -u root mysql
#
# mysql_tzinfo_to_sql reads your Systems time zone files and generates SQL statements from them.
# mysql processes those statements to load the time zone tables.
#
# mysql_tzinfo_to_sql also can be used to load a single time zone file or to generate leap second information.
#
# 		> To load a single time zone file <tz_file> that correponds to a time zone name <tz_name>, invoke mysql_tzinfo_to_sql as such:
#
# 			mysql_tzinfo_to_sql <tz_file> <tz_name> | mysql -u root mysql
#
# 		With this approach, you must execute a separate command to load the time zone files for each named zone that hte server needs to know about.
#
# 		> If your time zone needs to account for leap seconds, intiialize the leap second information like this, where <tz_file> is the name of your time zone file:
#
# 			mysql_tzinfo_to_sql --leap <tz_file> | mysql -u root mysql
#
# 		> After running mysql_tzinfo_to_sql, it is best to restart the server so that it does not continue to use any previously cached time zone data.
#
# 		If your system is one that has no zoneinfo DB (for example, Windows), you can use a package that is available for download at the MySQL Developer Zone:
#
# 			https://dev.mysql.com/downloads/timezones.html
#
# 		Download a time zone package that contains SQL statements and unpack it, then load the package file contents into the time zone tables:
#
# 			mysql -u root mysql < <file_name>
#
# 		THen restart the server.
#
# 		Warning: Do NOT use a downloadable package that contains any MyISAM tables. MySQL uses INnoDB for the Time zone Tables. Trying to replace them with MyISAM tables causes issues.
#
# 		Warning: Do NOT use a downloadable package that if your system has a zoneinfo database. Use the mysql_tzinfo_to_sql utility instead.
# 					Othehrwise, you may cause a difference in datetime handling between MySQL and other apps on your system.
#
# The following section pertains to Staying Current with Time Zone Changes
#
# 		When time zone rules change, applications that use the old rules become out of date.
#
# 		TO stay current, it is necessary to make sure that oyur system uses current time zone info.
# 		There are two factors to consider in this.
#
# 			1) The OS time affects the value that the MySQL server uses for times if its time zone is set to SYSTEM.
# 				Make sure that your OS is using the latest time zone info.
#
# 				For most OS's, the latest update or service pack prepares your system for the time changes.
# 				
# 			2) If you replace the system's /etc/localtime timezone file with a version that uses rules differing from those in
# 				effect at mysqld startup, you should restart mysqld so that it uses the updated rules.
#
# 				Otherwise, mysqld might not notice when the system changes its time.
#
# 			3) If you use named time zones with MySQL, make sure that the time zone tables in the mysql DB are up to date.
# 				
# 				IF your system has its own zoneinfo DB, you should reload the MySQL time zone tables whenever hte zoneinfo
# 				DB is updated.
#
# 				FOr systems that do not have their own zoneinfo DB, check the MySQL Develop Zone for updates.
#
# 				When a new update is available, download it and use it to replace the current time zone tables.
#
# 				Mysqld caches time zone information that it looks up, so after updating the time zone tables, you should
# 				restart mysqld to make sure that it does not continue to serve outdated time zone data.
#
# 		If you are uncertain whether named time zones are available, for use either as the server's time zone setting or by clients that
# 		set their own time zone, check whether your time zone tables are empty.
#
# 		The following query determines whether the table that contains time zone names has any rows.
#
# 				SELECT COUNT(*) FROM mysql.time_zone_name;
# 				+-----------------------------+
# 				| COUNT(*) 							|
# 				+-----------------------------+
# 				| 		0 								|
# 				+-----------------------------+
#
# 		A count of zero indicates that its empty.
#
# 		In this case, no one can be using named time zones, and you do not need to update the tables.
#
# 		A count greater than zero indicates that the table is not empty and that its contents are available
# 		to be used for named time support.
#
# 		In this case, you should be sure to reload your time zone tables so that anyone who uses named time zones will get correct query results.
#
# 		To check whether your MySQL installation is updated properly for a change in Daylight Saving Time rules, use a test like the one following.
# 		The example uses values that are appropiate for the 2007 DST 1-hour change that occurs in the US on march 11 at 2 a.m.
#
# 		SELECT CONVERT_TZ('2007-03-11 2:00:00', 'US/Eastern', 'US/Central');
# 		SELECT CONVERT_TZ('2007-03-11 3:00:00', 'US/Eastern', 'US/Central');
#
# 		The two time values indicate the times at which the DST change occurs, and the use of named time zones requires that the time zone tables be used.
# 		THe desired result is that both queries return the same result (the input time, converted to the equivalent value in the 'US/Central' time zone).
#
# 		Before updating the time zone tables, you would see an incorrect result like this:
#
# 			SELECT CONVERT_TZ('2007-03-11 2:00:00', 'US/Eastern', 'US/Central');
# 			+-------------------------------------------------------------------+
# 			| CONVERT_TZ('2007-03-11 2:00:00', 'US/Eastern', 'US/Central') 	  |
# 			+-------------------------------------------------------------------+
# 			| 2007-03-11 01:00:00 															  |
# 			+-------------------------------------------------------------------+
#
# 			SELECT CONVERT_TZ('2007-03-11 3:00:00', 'US/Eastern', 'US/Central');
# 			+-------------------------------------------------------------------+
# 			| CONVERT_TZ('2007-03-11 3:00:00', 'US/Eastern', 'US/Central') 	  |
# 			+-------------------------------------------------------------------+
# 			| 2007-03-11 02:00:00 															  |
# 			+-------------------------------------------------------------------+
#
# 		After updating the tables, you should get hte correct results:
#
# 			SELECT CONVERT_TZ('2007-03-11 3:00:00', 'US/Eastern', 'US/Central');
# 			+-------------------------------------------------------------------+
## 		| CONVERT_TZ('2007-03-11 3:00:00', 'US/Eastern', 'US/Central') 	  |
# 			+-------------------------------------------------------------------+
# 			| 2007-03-11 01:00:00 															  |
# 			+-------------------------------------------------------------------+
#
# The following section covers Time Zone Leap Seond Support
#
# Leap second values are returned with a time part that ends with :59:59.
#
# THis means that a function such as NOW() can return the same value for two or three consecutive
# seconds during the leap second.
#
# It remains true that literal temporal values having a time part that ends with :59:60 or :59:61 are considered invalid.
#
# If it is necessary to search for TIMESTAMP values one second before the leap second, anomalous results may be obtained if you
# use a comparison with 'YYYY-MM-DD hh:mm:ss' values.
#
# The following example demonstrates this. It changes the local time zone to UTC so there is no difference between internal values
# (which are in UTC) and displayed values (which have time zone correction applied)
#
# 		CREATE TABLE t1 (
# 				a INT, ts TIMESTAMP DEFAULT NOW(), PRIMARY KEY (ts));
# 		Query OK, 0 rows affected (0.01 sec)
# 
# 		-- Change to UTC
# 		SET time_zone = '+00:00';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		-- Simulate NOW() = '2008-12-31 23:59:59' -
# 		SET timestamp = 1230767999
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		INSERT INTO t1 (a) VALUES (1);
# 		Query OK, 1 row affected (0.00 sec)
#
# 		-- Simulate NOW() = '2008-12-31 23:59:60'
# 		SET timestamp = 1230768000;
# 		Query OK, rows affected (0.00 sec)
#
# 		INSERT INTO t1 (a) VALUES (2);
# 		Query OK, 1 row affected (0.00 sec)
#
# 		-- values differ internally but display the same
# 		SELECT a, ts, UNIX_TIMESTAMP(ts) FROM t1;
# 		+--------+-----------------+------------------------+
# 		| a 		| ts 					    | UNIX_TIMESTAMP(ts) |
# 		+--------+-----------------+------------------------+
# 		| 		1 	| 2008-12-31 23:59:59 | 1230767999 			 |
# 		| 		2  | 2008-12-31 23:59:59 | 1230768000 			 |
# 		+--------+---------------------+--------------------+
# 		2 rows in set (0.00 sec)
#
# 		-- only the non-leap value matches
# 		SELECT * FROM t1 WHERE ts = '2008-12-31 23:59:59';
# 		+---------+-----------------------------------------+
# 		| a 		 | ts 												 |
# 		+---------+-----------------------------------------+
# 		| 		1 	 | 2008-12-31 		23:59:59 					 |
# 		+---------+-----------------------------------------+
#
# 		-- the leap values with seconds=60 is invalid
# 		SELECT * FROM t1 WHERE ts = '2008-12-31 23:59:60';
# 		Empty set, 2 warnings (0.00 sec)
#
# To work around this, you can use a comparison based on the UTC value actually stored in column,
# which has the leap second correction applied:
#
# -- selecting using UNIX_TIMESTAMP value return leap value
# SELECT * FROM t1 WHERE UNIX_TIMESTAMP(ts) = 1230768000;
# +---------------+----------------------------------------+
# | a 				| 	ts 											  |
# +---------------+----------------------------------------+
# | 		2 			| 	2008-12-31 23:59:59 						  |
# +---------------+----------------------------------------+
# 1 row in set (0.00 sec)
#
# The following section pertains to Server Tracking of Client Session State Changes
#
# The MySQL server implements several session state trackers. A client can enable these trackers to receive notification 
# of changes to its session state.
#
# One use for the tracker mechanism is to provide a means for MySQL connectors and client applications to determine whether
# any session context is available to permit session migration from one server to another.
#
# (To change sessions in a load-balanced environment, it is necessary to detect whether there is session states to take into
#  consideraiton when deciding whether a switch can be made)
#
# Another use for the tracker mechanism is to permit applications to know when transactions can be moved from one session to another.
# Transaction state tracking enables this, which is useful for applications that may wish to move transactions from a busy server
# to one that is less loaded.
#
# For example, a load-balancing connector managing a client connection pool could move transactions between available sessions in the pool.
#
# However, session switching cannot be done at arbitrary times. If a session is in the middle of a transaction for which reads or writes
# have been done, switching to a different session implies a transaction rollback on the original session.
#
# A session switch must be done only when a transaction does not yet have any reads or writes performed within it.
#
# Examples of when transactions might reasonably be switched:
#
# 		Immediately after START_TRANSACTION
#
# 		After COMMIT_AND_CHAIN
#
# In addition to knowing transaction state, it is useful to know transaction characteristics, so as to use the same characteristics if
# the transaction is moved to a different session.
#
# The following characteristics are relevant for this purpose:
#
# 		READ ONLY 
# 		READ WRITE
# 		ISOLATION LEVEL
# 		WITH CONSISTENT SNAPSHOT
#
# To support the preceding session-switching activities, notification is available for these types of client session state information.
#
# 		1) Changes to these attributes of client session state:
#
# 				The default schema (database)
#
# 				Session-specific values for system variables
#
# 				User-defined variables
#
# 				Temporary tables
#
# 				Prepared statements
#
# 			The session_track_state_change system variable controls this tracker.
#
# 		2) Changes to the default schema name. The session_track_schema SYS_VAR controls this tracker.
#
# 		3) Changes to the session values of SYS_VARs. The session_track_system_variables SYS_VAR controls this tracker.
#
# 		4) Available GTIDs. The session_track_gtids SYS_VAR controls this tracker.
#
# 		5) Information about transaction state and characteristics. The session_track_transaction_info SYS_VAR controls this tracker.
#
# The SYS_VARs that permit control over which change notifications occur, but do not provide a way to access notification information.
#
# Notification occurs in the MySQL client/server protocol, which includes tracker information in OK packets so that session
# state changes can be detected.
#
# To enable client applications to extract state-change information from OK packets returned by the server, the MySQL C API
# provides a pair of functions:
#
# 		mysql_session_track_get_first() fetches the first part of the state-change information received from the server.
#
# 		mysql_session_track_get_next() fethces any remaining state-change information received from the server.
# 		Following a successful call to mysql_session_track_get_first(), call this function repeatedly as long as it returns success.
#
# The mysqltest program has disable_session_track_info and enable_session_track_info commands that control whether session tracker
# notifications occur.
#
# You can use theese commands to see from the cmd line what notifications SQL statements produce.
# Suppose that a file testscript contains the following mysqltest script:
#
# 		DROP TABLE IF EXISTS test.t1;
# 		CREATE TABLE test.t1 (i INT, f FLOAT);
# 		--enable_session_track_info
# 		SET @@session.session_track_schema=ON;
# 		SET @@session.session_track_system_variables='*';
# 		SET @@session.session_track_state_change=ON;
# 		USE information_schema;
# 		SET NAMES 'utf8mb4';
# 		SET @@session.session_track_transaction_info='CHARACTERISTICS';
# 		SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
# 		SET TRANSACTION READ WRITE;
# 		START TRANSACTION;
# 		SELECT 1;
# 		INSERT INTO test.t1() VALUES();
# 		INSERT INTO test.t1() VALUES(1, RAND());
# 		COMMIT;
#
# Run the script as follows to see the information provided by the enabled trackers.
#
# For a description of the Tracker: information displayed by mysqltest for the various trackers, its' covered later.
#
# mysqltest < testscript
# DROP TABLE IF EXISTS test.t1;
# CREATE TABLE test.t1 (i INT, f FLOAT);
# SET @@session.session_track_schema=ON;
# SET @@session.session_track_system_variables='*';
# -- Tracker : SESSION_TRACK_SYSTEM_VARIABLES
# -- session_track_system_variables
# -- *
#
# SET @@session.session_track_state_change=ON;
# -- Tracker : SESSION_TRACK_SYSTEM_VARIABLES
# -- session_track_state_change
# -- ON
#
# USE information_schema;
# -- Tracker : SESSION_TRACK_SCHEMA
# -- information_schema
#
# -- Tracker : SESSION_TRACK_STATE_CHANGE
# -- 1
#
# SET NAMES 'utf8mb4';
# -- Tracker : SESSION_TRACK_SYSTEM_VARIABLES
# -- character_set_client
# -- utf8mb4
# -- character_set_connection
# -- utf8mb4
# -- character_set_results
# -- utf8mb4
#
# -- Tracker : SESSION_TRACK_STATE_CHANGE
# -- 1
#
# SET @@session.session_track_transaction_info='CHARACTERISTICS';
# -- Tracker : SESSION_TRACK_SYSTEM_VARIABLES
# -- session_track_transaction_info
# -- CHARACTERISTICS
#
# -- Tracker : SESSION_TRACK_STATE_CHANGE
# -- 1
#
# -- Tracker : SESSION_TRACK_TRANSACTION_CHARACTERISTICS
# --
#
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- ________
#
# SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
# -- Tracker : SESSION_TRACK_TRANSACTION_CHARACTERISTICS
# -- SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;
#
# SET TRANSACTION READ WRITE;
# -- Tracker : SESSION_TRACK_TRANSACTION_CHARACTERISTICS
# -- SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; SET TRANSACTION READ WRITE;
#
# START TRANSACTION;
# -- Tracker : SESSION_TRACK_TRANSACTION_CHARACTERISTICS
# -- SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; START TRANSACTION READ WRITE;
#
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- T______
#
# SELECT 1;
# 1
# 1
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- T_____S_
#
# INSERT INTO test.t1 () VALUES();
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- T___W_S_
#
# INSERT INTO test.t1 () VALUES(1, RAND());
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- T___WsS_
#
# COMMIT;
# -- Tracker : SESSION_TRACK_TRANSACTION_CHARACTERISTICS
# --
#
# -- Tracker : SESSION_TRACK_TRANSACTION_STATE
# -- ________
#
# ok
#
# The following section covers Server-Side Help
#
# MySQL Server supports a HELP statement that returns information from the MySQL HELP Syntax.
# Several tables in the mysql system DB contain the information needed to support this statement.
#
# The proper operation of this statement requires that these help tables be initialized, which is done 
# by processing the contents of the fill_help_tables.sql script.
#
# If you install MySQL using a binary or source distrib on Unix, help table content intialization occurs when
# you initialize the data dir.
#
# For an RPM distrib on Linux or binary distrib on Windows, content initialization occurs as part of the MySQL
# install process.
#
# If you upgrade MySQL using a binary distrib, help table content is not upgraded automatically, but you can upgrade it manually.
# Locate the fill_help_tables.sql file in the share or share/mysql dir.
#
# Change location into that dir and process the file with the mysql client as follows:
#
# 		mysql -u root mysql < fill_help_tables.sql
#
# You can also obtain the latest fill_help_tables.sql at any time to upgrade your help tables.
#
# Download the proper file for your version of MySQL from https://dev.mysql.com/doc/index-other.html
#
# Process it as above.
#
# If you are working with Git and a MySQL dev source tree, you must use a download copy of the fill_help_tables.sql, because the source
# tree is a stub.
#
# NOTE: For a server that participates in replication, the help table content upgrade process involves multiple servers.
#
# The following part pertains to Server Response to Signals
#
# On Unix, signals can be sent to processes. mysqld responds to signals sent to it as follows:
#
# 		1) SIGTERM causes the server to shut down
#
# 		2) SIGHUP causes the server to reload the grant tables and to flush tables, logs, the thread cache and the host cache.
# 			These actions are like various forms of the FLUSH statement.
#
# 			The server also writes a status report to the error log that has this format:
#
# 				Status information:
#
# 				Current dir: /var/mysql/data/
# 				Running threads: 0 Stack size: 196608
# 				Current locks:
#
# 				Key caches:
# 				default
# 				Buffer_size: 			8388600
# 				Block_size: 				1024
# 				Division_limit: 			 100
# 				Age_limit: 					 300
# 				blocks used: 				   0
# 				not flushed: 					0
# 				w_requests: 					0
# 				writes: 							0
# 				r_requests: 					0
# 				reads: 							0
#
# 				handler status:
# 				read_key: 			0
# 				read_next: 			0
# 				read_rnd: 			0
# 				read_first: 		1
# 				write: 				0
# 				delete: 				0
# 				update: 				0
#
# 				Table status:
# 				Opened tables: 				5
# 				Open tables: 					0
# 				Open files: 					7
# 				Open streams: 					0
#
# 				Alaram status: 
# 				Active alarms: 		1
# 				Max used alarms: 		2
# 				Next alarm time: 		67
#
# The following section pertains to The Server Shutdown Process
#
# The server shutdown process takes place as follows:
#
# 		1. The shutdown process is initiated.
#
# 			This can occur initiated several ways. For example, a user with the SHUTDOWN priv can execute a mysqladmin shutdown command.
#
# 			mysqladmin can be used on any platform supported by MySQL. Other OS specific shutdown intiaition methods are possible, as well:
#
# 				The server shuts down on Unix when it receives a SIGTERM signal.
# 				A server running as a service on Windows shuts down when the services manager tells it to.
#
# 		2. The server creates a shutdown thread if necessary.
#
# 			Depending on how shutdown was initiated, the server might create a thread to handle the shutdown process.
# 			If shutdown was requested by a client, a shutdown thread is created. 
#
# 			If shutdown is the result of receiving a SIGTERM signal, the signal thread might handle shutdown itself, or it
# 			might create a separate thread to do so.
#
# 			If the server tries to create a shutdown thread and cannot (for example, if memory is exhausted) - it issues a diagnostic message
# 			that appears in the error log:
#
# 				Error: Can't create thread to kill server
#
# 		3. The server stops accepting new connections
#
# 			To prevent new activity from being initiated during shutdown, the server stops accepting new client connections 
# 			by closing the handlers for the network interfaces to which it normally listens for connections:
#
# 				The TCP/IP port, the Unix socket file, the Windows named pipe, and shared memory on Windows.
#
# 		4. The server terminates current activity
#
# 			For each thread associated with a client connection, the server breaks the connection to the client and marks the thread as killed.
# 			Threads die when they notice that they are marked for it.
#
# 			Threads for idle connections die quickly. 
# 			Threads that currently are processing statements check their state periodically and take longer to die.
# 			
# 			There is more info on the KILL syntax, later on.
#
# 			For threads that have an open transaction, the transaction is rolled back.
#
# 			If a thread is updating a nontransactional table, an operation such as multiple-row
# 			UPDATE or INSERT may leave the table partially updated because the operation can terminate before completion. 
#
# 			If the server is a master replication server, it treats threads associated with currently connected slaves like other
# 			client threads.
#
# 			That is - each one is marked as killed and exits when it next checks its state.
#
# 			If the server is a slave replication server, it stops the I/O and SQL threads, if they are active, before
# 			marking client threads as killed.
#
# 			The SQL thread is permitted to finish its current statement (to avoid causing replication problems), and then stops.
#
# 			If the SQL thread is in the middle of a transaction at this point, the server waits until the current replication 
# 			event group (if any) has finished executing, or until the user issues a KILL_QUERY or KILL_CONNECTION statement.
#
# 			Since nontransactional statements cannot be rolled back, in order to guarantee crash-safe replication, only transactional
# 			tables should be used.
#
# 			NOTE: To guarantee crash safety on the slave, you must run the slave with --relay-log-recovery enabled.
#
# 		5. The server shuts down or closes storage engines.
#
# 			At this stage, the server flushes the table cache and closes all open tables.
#
# 			Each storage engine performs any actions necessary for tables that it manages.
#
# 			InnoDB flushes its buffer pool to disk (unless innodb_fast_shutdown is 2), writes the
# 			current LSN to the tablespace, and terminates its own internal threads. 
#
#			MyISAM flushes any pending index writes for a table. 
#
# 		6. The server exits.
#
# To provide information to management processes, the server returns one of the exit codes described in the following list.
#
# The phrase in paranthesis indicates the action taken by systemd in response to the code, for platforms on which systemd
# is used to manage the server.
#
# 0 = successful termination (no restart done)
# 1 = unsuccessful termination (no restart done)
# 2 = unsuccessful termination (restart done)
#
# The following section pertains to The MySQL Data Directory
#
# Information managed by the MySQL server is stored under a dir known as the data dir.
#
# The following list briefly decribes the items typically found in the data dir, with cross
# references for additional info: 			
#
# 		1) Data dir subdirs. Each subdir of the data dir is a DB directory and corresponds to a DB managed by the server.
# 			All mySQL installations have certain standard DBs:
#
# 				a) The mysql dir corresponds to the mysql system DB, which contains information required by the MySQL server as it runs.
# 					The DB contains data dictionary tables and system tables.
#
# 				b) The performance_schema dir corresponds to the Performance schema, which provides information used to inspect the
# 					internal execution of the server at runtime.
#
# 				c) The sys directory corresponds to the sys schema, which provides a set of objects to help interpret Performance Schema
# 					information more easily.
#
# 				d) The ndbinfo directory corresponds to the ndbinfo database that stores information specific to NDB Cluster 
# 					(present only for installations built to include NDB Cluster)
#
# 				-> Other Subdirs correspond to DBs created by users and applications.
#
# 				NOTE: INFORMATION_SCHEMA is a standard DB, but its implementation uses no corresponding database dir.
#
# 		2) Log files written by the server.
#
# 		3) InnoDB tablespace and log files.
#
# 		4) Default/autogenerated SSL and RSA certificate and key files.
#
# 		5) The server process ID (while the server is running)
#
# 		6) The mysqld-auto.cnf file that stores persisted global SYS_VARs.
#
# Some items in the list can be relocated elsewhere by reconfiguring the server.
#
# In addition, the --datadir option enables the location of the data directory itself to be changed.
# For a given MySQL installation, check the server configuration to determine whether items have been moved.
#
# The following section pertains to The mysql System Database
#
# The mysql database is the system database. It contains tables that store information required by the MySQL server as it runs.
#
# A broad categorization is that the mysql database contains data dictionary tables that store DB objects metadata, and system
# tables used for other operational purposes.
#
# The following discussion furhet subdivies the set of system tables into smaller categories:
#
# Data Dictionary Tables
#
# Grant System Tables
#
# Object Information System Tables
#
# Log System Tables
#
# Server-Side Help System Tables
#
# Time Zone System Tables
# 
# Replication System Tables
#
# Optimizer System Tables
#
# Miscellaneous System Tables
#
# The remainder of this section enumerates the tables in each category, with cross references for additional information.
#
# Data dictionary tables and system tables use the InnoDB storage engine unless otherwise indicated.
#
# mysql system tables and data dictionary tables reside in a single InnoDB tablespace file named mysql.ibd in the MySQL data dir.
# Previously, these tables were created in individual tablespace files in the mysql database dir.
#
# DATA DICTIONARY TABLES
#
# These tables comprise the data dictionary, which contains metadata about DB objects.
#
# IMPORTANT: The data dictionary is new in MysQL 8.0 - A data dictionary-enabled server entails some general operational differences compared to
# 				 previous MySQL releases.
#
# 				More details covered later.
#
# catalogs: Catalog information.
#
# character_sets: Information about available character sets.
#
# collations: Information about collations for each character set.
#
# column_statistics: Histogram statistics for column values.
#
# column_type_elements: Information about types used by columns.
#
# columns: Information about columns in tables.
#
# dd_properties: A table that identifies data dictionary properties, such as its version.
# 					  The server uses this to determine whether the data dictionary must be upgraded to a newer version.
#
# events: Information about Event Scheduler events. The server loads events listed in this table during its startup sequence,
# 			 unless started with the --skip-grant-tables option.
#
# foreign_keys, foreign_key_column_usage: Information about foreign keys.
#
# index_column_usage: Information about columns used by indexes.
#
# index_partitions: information about partitions used by indexes.
#
# index_stats: Used to store dynamic index statitics generated when ANALYZE_TABLE is executed.
#
# indexes: Information about table indexes.
#
# innodb_ddl_log: Stores DDL logs for crash-safe DDL operations.
#
# parameter_type_elements: Information about stored procedure and function parameters, and about return values for stored functions.
#
# parameters: Information about stored procedures and functions.
# 
# resource_groups: information about resource groups.
#
# routines: Information about stored procedures and functions.
#
# schemata: information about schemata. In MySQL, a schema is a database, so this table provides info about DBs.
#
# st_spatial_reference_systems: Information about available spatial reference systems for spatial data.
#
# table_partition_values: Information about values used by table partitions.
#
# table_partitions: Information about partitions used by tables.
#
# table_stats: Information about dynamic table statitics generated when ANALYZE_TABLE is executed.
#
# tables: Information about tables in DBs.
#
# tablespace_files: Information about files used by tablespaces.
#
# tablespaces: Information about active tablespaces.
#
# triggers: Information about triggers
#
# view_routine_usage: Information about dependencies between views and stored functions used by them.
#
# view_table_usage: Used to track dependencies between views and their underlying tables.
#
# Data dictionary tables are invisible. They cannot be read with SELECT, do not appear in the output of
# SHOW_TABLES, are not listed in the INFORMATION_SCHEMA.TABLES table, and so forth.
#
# However, in most cases there are corresponding INFORMATION_SCHEMA tables that can be queried.
# Conceptually, the INFORMATION_SCHEMA provides a view through which MySQL exposes data dictionary metadata.
#
# For example, you cannot select from the mysql.schemata table directly:
#
# 		SELECT * FROM mysql.schemata;
# 		ERROR 3554 (HY000): 	Access to data dictionary table 'mysql.schemata' is rejected.
#
# Instead, select that information from the corresponding INFORMATION_SCHEMA table:
#
# 		SELECT * FROM INFORMATION_SCHEMA.SCHEMATA\G
# 		*************************** 1. row *******************************
# 							CATALOG_NAME: def
# 							SCHEMA_NAME : mysql
# 		DEFAULT_CHARACTER_SET_NAME : utf8mb4
# 			DEFAULT_COLLATION_NAME  : utf8mb4_0900_ai_ci
# 							SQL_PATH    : NULL
# 		*************************** 2. row *******************************
# 							CATALOG_NAME: def
# 							SCHEMA_NAME : information_schema
# 		DEFAULT_CHARACTER_SET_NAME : utf8
# 			DEFAULT_COLLATION_NAME 	: utf8_general_ci
# 							SQL_PATH 	: NULL
#
# There is no INFORMATION_SCHEMA table that corresponds exactly to mysql.indexes, but INFORMATION_SCHEMA.STATISTICS contains
# much of the same information.
#
# As of yet, there are no INFORMATION_SCHEMA tables that correspond exactly to mysql.foreign_keys,
# mysql.foreign_key_column_usage.
#
# The standard SQL way to obtain foreign key information is by using the :
#
# INFORMATION_SCHEMA, REFERENTIAL_CONSTRAINTS and KEY_COLUMN_USAGE tables; 
#
# These tables are now implemented as views on the foreign_keys, foreign_key_column_usage,
# and other data dictionary tables.
#
# Some system tables from before MySQL 8.0 have been replaced by data dictionary tables and are 
# no longer present in the mysql system database:
#
# 		The events data dictionary table supersedes the event table from before MySQL 8.0
#
# 		The parameters and routines data dictionary tables together supersede the proc table from before MySQL 8.0
#
# GRANT SYSTEM TABLES
#
# These system tables contain grant information about user accounts and the privileges held by them.
# For additional information about the structure, contents and purpose - it is covered later.
#
# As of MySQL 8.0, the grant tables are InnoDB (transactional) tables.
# Previously, these were MyISAM (nontransactional) tables.
#
# The change of grant-table storage engine underlies an accompanying change in MySQL 8.0 to the
# behavior of account-management statements such as CREATE_USER and GRANT.
#
# Previously, an account-management statement that named multiple users could succeed for some 
# users and fail for others.
#
# The statements are now transactional and either succeed for all named users or roll back and 
# have no effect if any error occurs.
#
# NOTE: If MySQL is upgraded from an older version but the grant tables have not been upgraded from
# 		  MyISAM to InnoDB, the server considers them read only and account-management statements
# 	     produce an error.
#
# user: User accounts, global privs, and other non-privilege columns.
#
# global_grants: Assignments of dynamic global privileges to users
#
# db: Database-level privileges
#
# tables_priv: Table-level privileges
#
# columns_priv: Column-level privileges
#
# procs_priv: Stored procedure and function privileges
#
# proxies_priv: Proxy-user privileges
#
# default_roles: This table lists default roles to be activated after a user connects and authenticates, or executes SET_ROLE_DEFAULT
#
# role_edges: This table lists edges for role subgraphs
#
# 				  A given user table row might refer to a user account or a role.
#
# 				  The server can distinguish whether a row represents a user account, a role or both by
# 				  consulting the role_edges table for information about relations between authentication IDs.
#
# password_history: Information about password changes
#
# OBJECT INFORMATION SYSTEM TABLES
#
# These system tables contain information about stored programs, components, user-defined functions, and server-side plugins:
#
# 		component: The registry for server components. Any components listed in this table are installed by a loader service
# 					  during the server startup sequence.
#
# 		func: 	  Information about user-defined functions (UDFs).
# 					  The server loads UDFs listed in this table during its startup sequence, unless
# 					  started with the --skip-grant-tables option.
#
# 		plugin: 	  Information about server-side plugins.
# 					  The server loads plugins listed in this table during its startup sequence,
# 					  unless started with the --skip-grant-tables option.
#
# LOG SYSTEM TABLES
#
# The server uses these system tables for logging:
#
# 		general_log: The general query log table.
#
# 		slow_log: The slow query log table.
#
# Log tables use the CSV storage engine.
#
# SERVER-SIDE HELP SYSTEM TABLES
#
# These system tables contain server-side help information:
#
# 		help_category: Information about help categories.
#
# 		help_keyword: Keywords associated with help topics.
#
# 		help_relation: Mappings between help keywords and topics.
#
# 		help_topic: Help topic contents.
#
# TIME ZONE SYSTEM TABLES
#
# These system tables contain time zone information:
#
# 		time_zone: Time zone IDs and whether they use leap seconds.
#
# 		time_zone_leap_second: When leap seconds occur.
#
# 		time_zone_name: Mappings between time zone IDs and names.
#
# 		time_zone_transition,
# 		time_zone_transition_type: Time zone descriptions.
#
# REPLICATION SYSTEM TABLES
#
# The server uses these system tables to support replication:
#
# 		gtid_executed: Table for storing GTID values.
#
# 		ndb_binlog_index: Binary log information for NDB Cluster replication.
#
# 								The ndb_binlog_index table uses the MyISAM storage engine.
# 								It is created only if the server is built with NDB.
#
# 		slave_master_info, : Used to store replication information on slave servers.
# 		slave_relay_log_info,
# 		slave_worker_info 
#  
# OPTIMIZER SYSTEM TABLES
#
# These system tables are for use by the optimizer:
#
# 		innodb_index_stats, innodb_table_stats: Used for InnoDB persistent optimizer statistics.
#
# 		server_cost, engine_cost: The optimizer cost model uses tables that contain cost estimate 
# 										  information about operations that occur during query execution.
#
# 										  server_cost contains optimizer cost estimates for general server operations.
#
# 										  engine_cost contains estimates for operations specific to particular storage engines.
#
# MISC SYSTEM TABLES
#
# 		Other system tables do not fit the preceding categories:
#
# 			audit_log_filter, audit_log_user: If MySQL Enterprise Audit is installed, these tables provide persistent storage
# 														 of audit log filter defs and user accounts.
#
# 			firewall_users, firewall_whitelist: If MySQL Enterprise Firewall is installed, these tables provide persistent storage for info
# 															used by the firewall.
#
# 			servers: Used by the FEDERATED storage engine.
#
# 			innodb_dynamic_metadata: Used by the InnoDB storage engine to store fast-changing table metadata such as auto-increment counter
# 											 value and index tree corruption flags.
#
# 											 Replaces the data dictionary buffer table that resided in the InnoDB system tablespace.
#
# The following section pertains to MySQL Server Logs
#
# MySQL Server has several logs that can help you find out what activity is taking place.
#
# Log Type 					Info Written to Log
#
# Error Log 					Problems encountered starting, running or stopping mysqld
#
# General query log 			Established client connections and statements received from clients
#
# Binary log 					Statements that change data (also used for replication)
#
# Relay log 					Data changes received from a replication master server
#
# Slow query log 				Queries that took more than long_query_time seconds to execute
#
# DDL log (metadata log) 	Metadata operations performed by DDL statements
#
# By default, no logs are enabled, except the error log on Windows.
# (The DDL log is always created when required, and has no user-configurable options)
#
# The following log-specific sections provide information about the server options that enable logging.
#
# By default, the server writes files for all enabled logs in the data directory.
#
# You can force the server to close and reopen the log files (or in some cases switch to a new log file)
# by flushing the logs.
#
# Log flushing occurs when you issue a FLUSH_LOGS statement; execute mysqladmin with a flush-logs or
# or refresh argument; or execute mysqldump with a --flush-logs or --master-data option.
#
# In addition, the binary log is flushed when its size reaches the value of the max_binlog_size SYS_VAR.
#
# You can control the general query and slow query logs during runtime.
# You can enable or disable logging, or change the log file name.
#
# You can tell the server to write general query and slow query entries to log tables, log files or both.
#
# The relay log is used only on slave replication servers, to hold data changes from the master server that must
# also be made on the slave.
#
# Covered later.
#
# THE FOLLOWING PERTAINS TO SELECTING GENERAL QUERY LOG AND SLOW QUERY LOG OUTPUT DESTINATIONS
#
# MySQL Server provides flexible control over the destination of output written to the general query log and the slow query log, if those logs are enabled.
#
# Possible destinations for log entries are log files or the general_log and slow_log tables in the mysql system DB.
# File output, table output, or both can be selected.
#
# LOG CONTROL AT SERVER STARTUP
#
# The log_output system variable specifies the destination for log output. Setting this variable does not in itself enable the logs;
# they must be enabled separately.
#
# 		If log_output is not specified at startup, the default logging destination is FILE.
#
# 		If log_output is specified at startup, its value is a list one or more comma-separated words chosen from TABLE (log to tables),
# 		FILE (log to files), or NONE (do not log tables or files).
#
# 		NONE, if part of the list, has the highest precidence.
#
# The general_log SYS_VAR controls logging to the general query log for the selected log destinations.
# If specified at server startup, general_log takes an optional argument of 1 or 0 to enable or disable the log.
#
# To specify a file name other than the default for file logging, set the general_log_file variable.
#
# Similarly, the slow_query_log variable controls logging to the slow query log for the selected destinations
# and setting slow_query_log_file specifies a file name for file logging.
#
# If either log is enabled, the server opens the corresponding log file and writes startup messages to it.
#
# However, further logging of queries to the file does not occur unless the FILE log destination is selected. 
#
# Examples:
#
# 		To write general query log entries to the log table and the log file, use --log_output=TABLE,FILE to select both
# 		log destinations and --general_log to enable the general query log.
#
# 		To write general and slow query log entries only to the log tables, use --log_output=TABLE to select tables as the log
# 		destinations and --general_log and --slow_query_log to enable both logs.
#
# 		To write slow query log entries only to the log file, use --log_output=FILE to select files as the log destination and
# 		--slow_query_log to enable the slow query log. In this case, because the default log destination is FILE, you could omit the log_output setting.
#
# LOG CONTROL AT RUNTIME
#
# The system variables associated with log tables and files enable runtime control over logging:
#
# 		The log_output variable indicates the current logging destination. It can be modified at runtime to change
# 		the destination.
#
# 		The general_log and slow_query_log variables indicate whether the general query log and slow query log are enabled
# 		(ON) or disabled (OFF). You can set these variables at runtime to control whether the logs are enabled.
#
# 		The general_log_file and slow_query_log_file variables indicate the names of the general query log and slow query log files.
# 		You can set these variables at server startup or at runtime to change the names of the log files.
#
# 		To disable or enable general query logging for the current session, set the session sql_log_off variable to ON or OFF.
# 		(Assuming the general query log itself is enabled)
#
# LOG TABLE BENEFITS AND CHARACTERISTICS
#
# The use of tables for log output offers the following benefits:
#
# 		1) Log entries have a standard format. To display the current structure of the log tables, use these statements:
#
# 				SHOW CREATE TABLE mysql.general_log;
# 				SHOW CREATE TABLE mysql.slow_log;
#
# 		2) Log contents are accessible through SQL statements. This enables the use of queries that selects only those log entries
# 			that satisfy specific criteria.
#
# 			For example, to select log contents associated with a particular client (which can be useful for identifying problematic
# 			queries from that client), it is easier to do this using a log table than a log file.
#
# 		3) Logs are accessible remotely through any client that can connect to the server and issue queries (if the client has the appropiate
# 			log table privileges). It is not necessary to log in to the server host and directly access the file system.
#
# The log table implementation has the following characteristics:
#
# 		1) In general, the primary purpose of log tables is to provide an interface for users to observe the runtime execution of the server,
# 			not to interfere with its runtime execution.
#
# 		2) CREATE_TABLE, ALTER_TABLE and DROP_TABLE are valid operations on a log table. 
# 			For ALTER_TABLE and DROP_TABLE, the log table cannot be in use and must be disabled.
#
# 		3) By default, the log tables use the CSV storage engine that writes data in comma-separated values format.
#
# 			For users who have access to the .CSV files that contain log table data, the files are easy to import into
# 			other programs such as spreadsheets that can process CSV input.
#
# 			The log tables can be altered to use the MyISAM storage engine. You cannot use ALTER_TABLE to alter a log table
# 			that is in use.
#
# 			The log must be disabled first. No engines other than CSV or MyISAM are legal for the log tables.
#
# 				Log Tables and "Too many open files" Errors: If you select TABLE a log destination and the log tables use the CSV storage engine,
# 																			you may find that disabling and enabling the general query log or slow query log repeatedly at runtime
# 																			can open a number of open file descriptors for the .CSV file, possibly resulting in a "Too many open files" error.
#
# 																			To work around this issue, execute FLUSH_TABLES or ensure that the value of open_files_limit is greater than
# 																			the value of table_open_cache_instances.
#
# 		4) To disable logging so that you can alter (or drop) a log table, you can use the following strategy.
# 			The example uses the general query log; the procedure for the slow query log is similar but uses the slow_log table
# 			and slow_query_log SYS_VAR.
#
# 				SET @old_log_state = @@GLOBAL.general_log;
# 				SET GLOBAL general_log = 'OFF';
# 				ALTER TABLE mysql.general_log ENGINE = MyISAM;
# 				SET GLOBAL general_log = @old_log_state;
#
# 		5) TRUNCATE_TABLE is a valid operation on a log table. It can be used to expire log entries.
#
# 		6) RENAME_TABLE is a valid operation on a log table. You can automatically rename a log table (to perform log rotation, for example)
# 			using the following strategy:
#
# 			USE mysql;
# 			DROP TABLE IF EXISTS general_log2;
# 			CREATE TABLE general_log2 LIKE general_log;
# 			RENAME TABLE general_log TO general_log_backup, general_log2 TO general_log;
#
# 		7) CHECK_TABLE is a valid operation on a log table.
#
# 		8) LOCK_TABLES cannot be used on a log table.
#
# 		9) INSERT, DELETE and UPDATE cannot be used on a log table. These operations are permitted only internally to the server itself.
#
# 		10) FLUSH_TABLES_WITH_READ/LOCK and the state of the read_only SYS_VAR have no effect on log tables.
# 			 The server can always write to the log tables.
#
# 		11) Entries written to the log tables are not written to the binary log and thus are not replicated to slave servers.
#
# 		12) To flush the log tables or log files, use FLUSH_TABLES or FLUSH_LOGS, respectively.
#
# 		13) Partitioning of log tables is not permitted.
#
# 		14) A mysqldump dump includes statements to recreate those tables so that they are not missing after reloading the dump file. Log table contents are not dumped.
#
# The following section pertains to The Error Log:
#
# This section discusses how to configure the MySQL server for logging of diagnostic messages to the error log.
# For information about selecting the error message character set or language - it is covered later.
#
# The error log contains a record of mysqld startup and shutdown times.
#
# It also contains diagnostic messages such as errors, warnings and notes that occur during
# server startup and shutdown, and while the server is running. 
#
# For example, if mysqld notices that a table needs to be automatically checked or repaired, it writes
# a message to the error log.
#
# On some OS's the error log contains a stack trace if mysqld exits abnormally.
#
# The trace can be used to determine where mysqld exited.
#
# If used to start mysqld, mysqld_safe may write messages to the error log.
#
# For example, when mysqld_safe notices abnormal mysqld exits, it restarts mysqld
# and writes a mysqld restarted message to the error log.
#
# The following sections are configurations of error logging.
#
# The following section covers Error Log Component Configuration:
#
# In MySQL 8.0, error logging uses the MySQL component architechture since before.
#
# The error log subsystem consists of components that perform log event filter and writing,
# as well as a system variable that configures which components to enable to achieve the desired logging result.
#
# This section is for selecting components for error logging.
# For instructions specific to the system log and JSON log writers - it is covered later.
#
# Component-based error logging offers these features:
#
# 		Log events can be filtered by filter components to affect the information available for writing.
#
# 		Log events are output by sink (writer) components. Multiple sink components can be enabled, to write error log output to multiple destinations.
#
# 		Built-in filter and writer components combine to implement the default error logging format.
#
# 		A loadable writer enables logging to the system log.
#
# 		A loadable writer enables logging in JSON format.
#
# 		System variables control which log components to enable and the rules for filtering log events.
#
# The log_error_services SYS_VAR controls which log components to enable for error logging.
# The variable may contain a list with 0,1 or many elements.
#
# In the latter case, elements may be delimieted by ; or , (>= MySQL 8.0.12), optionally followed by a space.
#
# A given setting cannot use both semicolon and comma separators.
#
# Component order is significant because the server executes components in the order listed.
#
# By default, log_error_services has this  value:
#
# 		SELECT @@GLOBAL.log_error_services;
# 		+---------------------------------------+
# 		| @@GLOBAL.log_error_services 	  		 |
# 		+---------------------------------------+
# 		| log_filter_internal; log_sink_internal|
# 		+---------------------------------------+
#
# That value indicates that log events first pass through the built-in filter component, log_filter_internal,
# then through the built-in log writer component, log_sink_internal.
#
# A filter modifies log events seen by components named later in the log_error_services value.
# A sink is a destination for log events. 
#
# Typically, a sink processes log events into log messages that have a particular format and writes these
# messages to its associated output, such as file or the system log.
#
# NOTE:
#
# 		If log_error_services is assigned a value that contains no writer components, no log output is written from that point.
#
# 		The final component in the log_error_services value should be a writer. If the final component is a filter, it has no effect
# 		because the filtered events are not sent to any writer.
#
# The combination of log_filter_internal and log_sink_internal implements the default error log filtering and output behavior.
# The action of these components is affected by other server options and system variables:
#
# 		1) The output destination is determined by the --log-error option (and, on Windows --pid-file and --console).
# 			These determine whether to write error messages to the console or a file and - if to a file - the error log file name.
#
# 		2) The log_error_verbosity SYS_VAR affects which types of log events log_filter_internal permits or suppresses.
#
# To change the set of log components used for error logging, load components as necessary and modify the log_error_services value.
#
# Adding or removing log components is subject to these constraints:
#
# 		3) To enable a log component, first load it using INSTALL_COMPONENT (unless it is built in or already loaded), then list the component in the
# 			log_error_service value.
#
# 			For a component to be permitted in the log_error_services value - it must be known.
#
# 		 	A component is known by default if it is built in or if it is loadable and has been loaded
# 			using INSTALL_COMPONENT.
#
# 			Attempts to name an unknown component at server startup cause log_error_services to be set to its default value.
# 			Attempts to name an unknown component at runtime produces an error and the log_error_services value remains unchanged.
#
# 		4) To disable a log component, remove it from the log_error_services value. Then, if the component is loadable and you also
# 			want to unload it, use UNINSTALL COMPONENT.
#
# 			Attempts to use UNINSTALL_COMPONENT to unload a loadable component that is still named in the log_error_services value produces an error.
#
# For example, to use the system log writer (log_sink_syseventlog) instead of the default writer (log_sink_internal) - first load the writer component,,
# then modify the log_error_services values:
#
# 		INSTALL COMPONENT 'file://component_log_sink_syseventlog';
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_syseventlog';
#
# NOTE: 
#
# 		The URN to use for loading a log component with INSTALL_COMPONENT is the component name prefixed with file://component_
#
# 		For example, for the log_sink_syseventlog component, the corresponding URN is file://component_log_sink_syseventlog
#
# It is possible to configure multiple log writers to send output to multiple destinations.
#
# To enable the sys log writer in addition to (rather than instead of) the default writer - set the log_error_services as:
#
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_internal; log_sink_syseventlog';
#
# To revert to using only the default writer and unload the system log writer, execute these statements:
#
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_internal;
# 		UNINSTALL COMPONENT 'file://component_log_sink_syseventlog';
#
# To configure a log component to be enabled at each server startup, use this procedure:
#
# 		1) If the component is loadable, load it using INSTALL_COMPONENT. Loading the component registers it in the mysql.component
# 			system table that the server loads it automatically for subsequent startups.
#
# 		2) Set the log_error_services value at startup to include the component name.
#
# 			Set the value either in the server my.cnf file, or use SET_PERSIST - which sets the value for for the running MySQL instance
# 			and also saves the value to be used for subsequent server restarts.
#
# 			A value set in my.cnf takes effect at the next restart. A value set using SET_PERSIST takes effect immediately and for subsequent restarts.
#
# Suppose that you want to configure, for every server startup, use of the JSON log writer (log_sink_json) in addition to the built-in log filter and
# writer (log_filter_internal, log_sink_internal).
#
# First load the JSON Writer if it is not loaded:
#
# INSTALL COMPONENT 'file://component_log_sink_json';
#
# Then set log_error_services to take effect at server startup. You can set it in my.cnf:
#
# [mysqld]
# log_error_services='log_filter_internal; log_sink_internal; log_sink_json'
#
# Or you can set it using SET_PERSIST:
#
# SET PERSIST log_error_services = 'log_filter_internal; log_sink_internal; log_sink_json';
#
# The order of components named in log_error_services is significant, particularly with respect to the 
# relative order of filters and writers. Consider this log_error_services value:
#
# log_filter_internal; log_sink_1; log_sink_2
#
# In this case, log events pass to the built-in filter, then to the first writer, then to the second writer.
# Both writers receive filtered log events.
#
# Compare that to this log_error_services value:
#
# 		log_sink_1; log_filter_internal; log_sink_2
#
# In this case, the only is only applied to the output before being piped to the second writer.
# i.e, sink_1 is unfiltered, sink_2 is filtered.
#
# The following section pertains to DEFAULT ERROR LOG DESTINATION CONFIGURATION
#
# This section discusses which server options configure the default error log destination, which can be the console 
# or a named file.
#
# It also indicates which log writer components base their own output destination on the default destination.
#
# In this discussion, "console" means stderr, the standard error output.
#
# This is your terminal or console window unless the standard error output has been redirected.
#
# The server interprets options that determine the default error log destination somewhat differently for Windows and Unix systems.
# Be sure to configure the destination using the information appropiate to your OS.
#
# After the server interprets the default error log destination options, it sets the log_error SYS_VAR to indicate the default destination,
# which affects where several log writer components writer error messages.
#
# The following section pertains to Default Error Log Destination on Windows
#
# On Windows, mysqld uses the --log-error, --pid-file and --console options to determine whether the default error log destination
# is the console or a file and if a file , the file name:
#
# 		If --console is given, the default destination is the console (--console takes precedence over --log-error if both are given, and the following
# 																							items regarding --log-error do not apply)
#
# 		If --log-error is not given, or is given without naming a file, the default destination is a file named <host_name.err> in the data directory,
# 		unless the --pid-file option is specified. In that case, the file name is the PID file base name with a suffix of .err in the data dir.
#
# 		If --log-error is given to name a file, the default destination is that file (with an .err suffix added if the name has no suffix), located
# 		under the data directory unless an absolute path name is given to specify a different location.
#
# If the default error log destination is the console, the server sets the log_error SYS_VAR to stderr.
# Otherwise, the default destination is a file and the server sets log_error to the file name.
#
# The following pertains to Default Error Log Destination on Unix and Unix-Like Systems
#
# On Unix and Unix-like systems, mysqld uses the --log-error option to determine whether the default error log destination
# is the console or a file - and, if a file - the file name
#
# 		If --log-error is not given, the default destination is the console.
#
# 		If --log-error is given without naming a file, the default destination is a file named <host_name.err> in the data dir.
#
# 		If --log-error is given to name a file, the default destination is that file (with an .err suffix added if the name has no suffix),
# 		located under the data dir unless an absolute path name is given to specify a different location.
#
# 		If --log-error is given an option file in a [mysqld], [server], or [mysqld_safe] section, mysqld_safe finds and uses the option, and passes it to mysqld.
#
# 			NOTE:
#
# 				It is common for Yum or APT package installations to configure an error log file location under /var/log with an option like log-error=/var/log/mysqld.log
# 				in a server configuration file.
#
# 				Removing the file name from the option causes the <host_name.err> file in the data directory to be used.
#
# If the default error log destination is the console, the server sets the log_error SYS_VAR to stderr. Otherwise, the default destination is a file and
# the server sets log_error to the file name.
#
# HOW THE DEFAULT ERROR LOG DESTINATION AFFECTS LOG WRITERS
#
# After the server interprets the error log destination configuration options, it sets the log_error SYS_VAR to indicate the
# default error log destination.
#
# Log writer components may base their own output destination on the log_error value, or determine their destination independently of log_error.
#
# If log_error is stderr, the default error log destination is the console, and log writers that base their output destination also write to the
# console:
#
# 		log_sink_internal, log_sink_json, log_sink_test: These writers write to the console.
#
# 																		 This is true even for writers such as log_sink_json that can be enabled multiple times; all instances write to the console.
#
# 		log_sink_syseventlog: This writer writes to the system log, regardless of the log_error value.
#
# If log_error is not stderr, the default error log destination is a file and log_error indicates the file name.
#
# Log writers that base their output destination on the default destination base output file naming on that file name.
#
# (A writer might use exactly that name, or it might use some variant thereof). Suppose that the log_error value <file_name>.
# Then log writers use the name like this:
#
# 		log_sink_internal, log_sink_test: These writers write to <file_name>
#
# 		log_sink_json: Successive instances of this writer named in the log_error_services value 	write to files named <file_name> plus a numbered .<NN>.json suffix:
#			
# 			<file_name>.00.json, <file_name>.01.json and so forth
#
# 		log_sink_syseventlog: This writer writes to the system log, regardless of the log_error value.
#
# The following section pertains to the Error Logging to the System Log
#
# It is possible to have mysqld write the error log to the system log (the Event Log on Windows, and syslog on Unix and Unix-like systems)
#
# This section describes how to configure error logging using the built-in filter, log_filter_internal, and the system log writer,
# log_sink_syseventlog - to take effect immediately and for subsequent server startups.
#
# To enable the system log writer, first load the writer component, then modify the log_error_services value:
#
# 		INSTALL COMPONENT 'file://component_log_sink_syseventlog';
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_syseventlog';
#
# To set log_error_services to take effect at server startup - use earlier sectioning desc.
#
# Those instructions apply to other error-logging SYS_VARs as well.
#
# NOTE:
#
# 		For MySQL 8.0 configuration, you must enable error logging to the system log explicitly.
#
# 		This differs from 5.7 MySQL and earlier, for which error logging to the sys log is enabled by default on Windows,
# 		and on all platforms requires no component loading.
#
# 		Error logging to the system log may require additional SYS_CONFIG.
#
# On Windows, error messages written to the Event Log within the Application log have these characteristics:
#
# 		Entries marked as Error, Warning, and Note are written to the Event Log, but not messages such as information statements from
# 		individual storage engines.
#
# 		Event Log entries have a source of MySQL (or MySQL-<tag> if syseventlog.tag is defined as <tag>)
#
# On Unix and Unix-like systems, logging to the system log uses syslog.
# The following SYS_VARs affect syslog messages:
#
# 		syseventlog.facility - The default facility for syslog messages is daemon. Set this variable to specify a different facility.
#
# 		syseventlog.include_pid - Whether to include the server process ID in each line of syslog output.
#
# 		syseventlog.tag - This variable defines a tag to add to the server identifier (mysqld) in syslog messages.
# 								If defined, the tag is appended to the identifier with a leading hyphen.
#
# 			NOTE: Prior to MySQL 8.0.13, use the log_syslog_facility, log_syslog_include_pid and log_syslog_tag SYS_VAR rather than
# 					the syseventlog.<xxx> variables.
#
# MySQL uses the custom label "System" for important system messages about non-error situations, such as startup, shutdown and some significant
# changes to settings.
#
# In logs that do not support custom labels, including the Event Log on Windows, and syslog on Unix and Unix-like systems, system messages
# are assigned the label used for the information level of severity.
#
# However, these messages are printed to the log even if the MySQL log_error_verbosity setting would normally exclude
# messages at the information level.
#
# When a log writer must fall back to a label of "Information" instead of "System" in this way, and the log event is further
# processed outside of the MySQL server (for example, filtered or forwarded by a syslog configuration), these events may
# by default be processed by the secondary application as being of "Information" severity rather than "System" severity.
#
# The following section pertains to Error Logging in JSON Format:
#
# This section describes how to configure error logging using the built-in filter, log_filter_internal, and the JSON writer, log_sink_json to take
# effect immediately and  for subsequent server startups.
#
# To enable the JSON writer, first load the writer component, then modify the log_error_services value:
#
# 		INSTALL COMPONENT 'file://component_log_sink_json';
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_json';
#
# It is permitted to name log_sink_json multiple times in the log_error_services value.
#
# For example, to write unfiltered events with one instance and filtered events with another instance,
# you could set log_error_services like this:  		
#
# 		SET GLOBAL log_error_services = 'log_sink_json; log_filter_internal; log_sink_json';
#
# The JSON log writer determines its output destination based on the default error log destination, which is given by
# the log_error SYS_VAR.
#
# If log_error names a file, the JSON writer bases output file naming on that file name, plus a numbered .<NN>.json suffix,
# with <NN> starting at 00.
#
# For example, if log_error is <file_name> - successive instances of log_sink_json named in the log_error_services value 
# write to <file_name>.00.json, <file_name>.01.json and so forth.
#
# If log_error is stderr, the JSON writer writes to the console.
#
# If log_json_writer is named multiple times in the log_error_services value, they all write
# to the console which is likely not useful.
#
# The following section pertains to Error Log Filtering:
#
# Error log configuration normally includes one log filter component and one or more log writer component.
# For error log filtering, MySQL offers a choice of components:
#
# 		log_filter_internal: This filter component provides error log filtering based on log event prio, in combination with
# 									the log_error_verbosity SYS_VAR.
#
# 									log_filter_internal is built in and enabled by default.
#
# 		log_filter_dragnet: 	This filter component provides error log filtering based on user-supplied rules, in combination
# 									with the dragnet.log_error_filter_rules SYS_VAR.
#
# log_filter_internal: Priority-Based Error Log Filtering
#
# 		Error log verbosity control is a simple form of log filtering based on error event prio.
# 		It is implemented by the log_filter_internal log filter component.
#
# 		To affect how log_filter_internal is built in and enabled by default, but if disabled, changes to log_error_verbosity has no effect.
#
# 		Permitted log_error_verbosity values are 1 (errors only), 2 (errors and warnings), 3 (errors, warnings and notes)
#
# 		If log_error_verbosity is set to >= 2, the server logs messages about statements that are unsafe for statement-based logging.
# 		If the value is 3, the server logs aborted connections and access-denied errors for new connection attempts.
#
# 		If you use replication, setting log_error_verbosity to >= 2 is recommended, to get more info about what is happening, such as messages
# 		about network failures and reconnections.
#
# 		If a slave server has log_error_verbosity >= 2, the slave prints messages to the error log to provide information about its status, such as
# 		the binary log and relay log coordinates where it starts its job, when it is switching to another relay log, when it reconnects after a DC, etc.
#
# 		Selected important system messages about non-error situations are printed to the error log regardless of the log_error_verbosity value.
# 		These messages include startup and shutdown messages, and some significant changes to settings.
#
# 		In the MySQL error log, system messages are labeled as "System". Other log writers might or might not follow the same convention,
# 		and in the resulting logs, system messages might be assigned the label used for the information level of severity, such as "Note"
# 		or "Information".
#
#		If you apply any additional filtering or redirection for logging based on the labeling of messages, system messages do not override
# 		your filter, but are handeled by it in the same way as other messages.
#
# log_filter_dragnet: Rule-Based Error Log Filtering
#
#		The log_filter_dragnet log filter component enables log filtering based on user-defined rules.
# 		To define the applicable rules, set the dragnet.log_error_filter_rules SYS_VAR.
#
# 		To enable the log_filter_dragnet filter, first load the filter component, then modify the log_error_services value.
# 		The following example enables log_filter_dragnet in combination with the built-in log writer:
#
# 			INSTALL COMPONENT 'file://component_log_filter_dragnet';
# 			SET GLOBAL log_error_services = 'log_filter_dragnet; log_sink_internal';
#
# 		To set log_error_services to take effect at server startup, see earlier notes.
#
# 		With log_filter_dragnet enabled, define its filter rules by setting the dragnet.log_error_filter_rules SYS_VAR.
# 		A rule set consists of zero or more rules, where each rule is an IF statement terminated by a period (.) char.
#
# 		If the var value is empty (zero rules), no filtering occurs.
#
# 		Example 1.
#
# 			This rule set drops information events, and, for other events, removes the source_line field:
#
# 				SET GLOBAL dragnet.log_error_filter_rules = 
# 					'IF prio>=INFORMATION THEN drop. IF EXISTS source_line THEN unset source_line.';
#
# 			This effect is similar to the filtering performed by the log_sink_internal filter with a setting of
# 			log_error_verbosity=2
#
# 		Example 2.
#
# 			This rule limits information events to no more than one per 60 seconds:
#
# 				SET GLOBAL dragnet.log_error_filter_rules = 
# 					'IF prio>=INFORMATION THEN throttle 1/60.';
#
# Once you have the filtering configuration set up, consider assignment dragnet.log_error_filter_rules using SET_PERSIST rather than
# the SET_GLOBAL to make the setting persist across server restarts.
#
# Alternatively, add the setting to the server option file.
#
# To stop using the filtering language, first remove it from the set of error logging components. Usually this means using a
# different filter component rather than no filter component.
#
# For example:
#
# 		SET GLOBAL log_error_services = 'log_filter_internal; log_sink_internal';
#
# Again, consider using SET_PERSIST rather than SET_GLOBAL to make the settings persist across server restarts.
#
# Then uninstall the filter log_filter_dragnet component:
#
# 		UNINSTALL COMPONENT 'file://component_log_filter_dragnet';
#
# THe following section describes aspects of log_filter_dragnet operation in more detail:
#
# 		log_filter_dragnet Rule language
#
# 		log_filter_dragnet Rule Actions
#
# 		log_filter_dragnet Rule Fields
#
# log_filter_dragnet Rule Language
#
# The following grammar defines the language for log_filter_dragnet filter rules.
# Each rule is an IF statement terminated by a (.) char.
#
# The language is not case sensitive:
#
# rule:
# 		IF condition THEN action
# 		[ELSEIF condition THEN action] ...
# 		[ELSE action]
#
# condition: 	{
# 		drop
# 	| throttle {count | count / window_size}
# 	| set field [:= | =] value
# 	| unset [field]
# }
#
# field: {
# 		core_field
# 	| optional_field
# 	| user_defined_field
# }
#
# 
# core_field: {
# 		time
# 	| msg
# 	| prio
# 	| label
# 	| err_code
# 	| err_symbol
# 	| SQL_state
# 	| subsystem
# }
#
# optional_field: {
# 		OS_errno
# 	 | OS_errmsg
# 	 | user
# 	 | host
# 	 | thread
# 	 | query_id
# 	 | source_file
# 	 | source_line
# 	 | function
# }
#
# user_defined_field:
# 		sequence of characters in [a-zA-Z0-9_] class
#
# comparator: {== | != | <> | >= | => | <= | =< | < | >}
#
# value: {
# 		string_literal
# 	 | integer_literal
# 	 | float_literal
# 	 | error_symbol
# 	 | severity
# }
#
# count: integer_literal
# window_size: integer_literal
#
# string_literal:
# 		sequence of characters quoted as '...' or "..."
#
# integer_literal:
# 		sequence of characters in [0-9] class
#
# float_literal:
# 		integer_literal[.integer_literal]
#
# error_symbol:
# 		valid MySQL error symbol such as ER_ACCESS_DENIED_ERROR or ER_STARTUP
#
# severity: {
# 		ERROR
# 	 | WARNING
# 	 | INFORMATION
# }
#
# Simple conditions compare a field to a value or test field existence.
# To construct more complex conditions, use the AND and OR operators.
#
# Both operators have the same precedence and evaluate left to right.
#
# To escape a character within a string, precede it with \.
# A backslash is required to include \ or the string-quoting char, optional for othe chars.
#
# For convenience, log_filter_dragnet supports symbolic names for comparisons to certain fields.
# Where applicable, symbols are preferable to numeric - for readability and portability.
#
# 		) Event severity values 1,2 and 3 can be specified as ERROR, WARNING , and INFORMATION.
# 		  Severity symbols are recognized only in comparisons with the prio field.
#
# 		  These comparisons are equivalent:
#
# 				IF prio == INFORMATION THEN ...
# 				IF prio == 3 THEN ...

# 		) Error codes can be specified in numeric form or as the corresponding error symbol.
#
# 		  For example, ER_STARTUP is the symbolic name for error 1408, so these comparisons are eqv.:
#
# 				IF err_code == ER_STARTUP THEN ...
# 				IF err_code == 1408 THEN ...
#
# Error symbols are recognized only in comparisons with the err_code field and user-defined fields.
#
# To find hte error symbol corresponding to a given error code number:
#
# 		Use the perror command, which when given an error number argument, displays info about the error, including its symbol.
#
# Suppose that a rule set with error numbers looks like this:
#
# 		IF err_code == 10927 OR err_code == 10914 THEN drop.
# 		If err_code == 1131 THEN drop.
#
# Using perror, determine the error symbols:
#
# 		perror 10927 10914 1131
# 		MySQL error code MY-010927 (ER_ACCESS_DENIED_FOR_USER_ACCOUNT_LOCKED)::
# 		Access denied for user '%-.48s'@'%-.64s'. Account is locked.
# 		MySQL error code MY-010914 (ER_ABORTING_USER_CONNECTION):
# 		Aborted connection %u to db: '%-.192s' user: '%-.48s' host:
# 		'%-.64s' (%-.64s).
# 		MySQL error code MY-001131 (ER_PASSWORD_ANONYMOUS_USER):
# 		You are using MySQL as an anonymous user and anonymous users are not allowed to change PWs.
#
# Substituting error symbols for numbers, the rule set becomes:
#
# 		IF err_code == ER_ACCESS_DENIED_FOR_USER_ACCOUNT_LOCKED
# 			OR err_code == ER_ABORTING_USER_CONNECTION THEN drop.
# 		IF err_code == ER_PASSWORD_ANONYMOUS_USER THEN drop.
#
# Symbolic names can be specified as quoted strings for comparison with string fields, but in such cases
# the names are strings that have no special meaning and log_filter_dragnet does not resolve them to
# the corresponding numeric value.
#
# Also, typos may go undetected, whereas an error is thrown immediately on SET for attempts to use an unquoted
# symbol unknown to the server.
#
# LOG_FILTER_DRAGNET RULE ACTIONS
#
# log_filter_dragnet supports these actions in filter rules:
#
# 		drop: Drop the current log event (do not log it)
#
# 		throttle: apply rate limiting to reduce log verbosity for events matching particular conditions.
# 					 The argument indicates a rate, in the form <count> or <count>/<window_size>.
#
# 					The <count> value indicates the permitted number of events to log per time window.
# 					The <window_size> value is the time window in seconds; if omitted, the default window is 60 seconds.
#
# 					Both values must be integer literals.
#
# 					This rule throttles plugin-shutdown messages to 5/60 sec:
#
# 						IF err_code == ER_PLUGIN_SHUTTING_DOWN_PLUGIN THEN throttle 5.
#
# 					This rule throttles errors and warnings to 1000/hour and information messages to 100/hour:
#
# 						IF prio <= INFORMATION THEN throttle 1000/3600 ELSE throttle 100/3600.
#
# 		set: Assign a value to a field (and cause the field to exist if it did not already).
# 			  In subsequent rules, EXISTS tests against the field name are true, and the new value can
# 			  be tested by comparison conditions.
#
# 		unset: Discard a field. In subsequent rules, EXISTS tests against hte field name are false and comparisons of the field against
# 				 any value are false.
#
# 				 In the case that the condition refers to exactly one field name, the field name following unset is optional and
# 				 unset discards the named field..
#
# 				 These rules are equivalent:
#
# 						IF myfield == 2 THEN unset myfield.
# 						IF myfield == 2 THEN unset.
#
# LOG_FILTER_DRAGNET RULE FIELDS
#
# 		log_filter_dragnet supports core, optional and user-defined fields in rules:
#
# 			1) A core field is set up automatically for error events. However, its presence in the event is not guaranteed because
# 			a core field, like any type of field, may be unset by filter rules.
#
# 			If so, the field will be found missing by later rules within the rule set and by components that execute after the filter (such as log writers)
#
# 			2) An optional field is normally absent but may be present for certain event types. When present, an optional field provides additional event 
# 				information as appropriate and available.
#
# 			3) A user-defiend field is any field with a name that is not already defined as a core or optional field.
# 				A user-defined label does not exist until created with the <set> action.
#
# 		As implied by the preceding desc., any given field may be absent, either because it was not present or discarded by a filtering rule.
#
# 		For log writers, the effect of field absence is writer specific. For example, a writer might omit the field from the log message,
# 		indicate that the field is missing or substitute a default.
#
# 		When in doubt, use a filter rule to unset the field, then check what the log writer does with it.
#
# 		These fields are core fields:
#
# 			time
#
# 				The event timestamp
#
# 			msg
#
# 				THe event message string
#
# 			prio
#
# 				The event priority, to indicate error, warning or note/information event. This field corresponds to severity in syslog.
#
# 				In comparisons, each prio can be specified as a symbolic severity name or an integer literal.
# 				Severity symbols are recognized only in comparisons with the prio field.
#
# 				These comparisons are equivalent:
#
# 					IF prio == INFORMATION THEN ...
# 					IF prio == 3 THEN ...
#
# 				The prio levels are:
#
# 					Error events: 1, Warning events: 2, Note/information events: 3
#
# 				Prio values follow hte principle that higher prios have lower values, and vice versa.
# 				Prio values begin at 1 for the most severe events (errors) and increase for events with decreasing severity.
#
# 				For example, to discard events with lower prio than warnings, test for prio values higher than WARNING:
#
# 					IF prio > WARNING THEN drop.
#
# 				The following shows the log_filter_dragnet rules to achieve an effect similar to each log_error_verbosity
# 				value permitted by the log_filter_internal filter:
#
# 					Errors only (log_error_verbosity=1):
#
# 						IF prio > ERROR THEN drop.
#
# 					Errors and Warnings (log_error_verbosity=2):
# 
# 						IF prio > WARNING THEN drop.
#
# 					Errors, warnings and notes (log_error_verbosity=3):
#
# 						IF prio > INFORMATION THEN drop.
#
# 					This rule can actually be omitted because it drops nothing.
#
# err_code
#
# 		The numeric event error code. In comparisons, the value to test can be specified as a symbolic error name or an 
# 		integer literal.
#
# 		Error symbols are recognized only in comparisons with the err_code field and user-defined roles.
#
# 		These comparisons are equal:
#
# 			IF err_code == ER_ACCESS_DENIED_ERROR THEN ...
# 			IF err_code == 1045 THEN ...
#
# err_symbol
#
# 		The event error symbol, as a string; for example, 'ER_DUP_KEY'
#
# 		err_symbol values are intended more for identifying particular lines in log output than for use in filter
# 		rule comparisons because log_filter_dragnet does not resolve comparison values specified as strings to the equivalent numeric error codes.
#
# SQL_state
#
# 		The event SQLSTATE value, as a string, for example '23000'
#
# subsystem
#
# 		The subsystem in which the event occurred. Possible values are InnoDB (the InnoDB storage engine), 
# 		Repl (the replication subsystem), Server (otherwise)
#
# OPtional fields fall into the following categories:
#
# 		Additional information about the error, such as the error signaled by the OS or the error lable:
#
# 			OS_errno
#
# 				The OS error number
#
# 			OS_errmsg
#
# 				The OS error message
#
# 			label
#
# 				The label corresponding to the prio value, as a string.
# 				Filter rules can change the label for log writers that support custom labels.
#
# 				label values are intended more for identifying parituclar lines in log output than
# 				for use in filter rule comparisons because log_filter_dragnet does not resolve
# 				comparison values specified as strings to the equivalent Numeric Prio.
#
# Identification of the client for which the event occurred:
#
# 		user
# 			The client User
#
# 		host
# 			The client host
#
# 		thread
# 			The thread ID
#
# 		query_id
# 			The query ID
#
# Debugging information:
#
# 		source_file
#
# 			The source file in which the event occurred. The file name should omit any leading path.
# 			For example, to test for the sql/gis/distance.cc file, write the comparison like this:
#
# 				IF source_file == "distance.cc" THEN ...
#
# 		source_line
#
# 			The line within the source file at which the event occurred
#
# 		function
#
# 			The function in which the event occurred.
#
# 		component
#
# 			The component or plugin in which the event occurred.
#
# The following pertains to ERROR LOG MESSAGE FORMAT
#
# Each error log sink (writer) component has a characteristic output format it uses to write messages to its destination,
# but other factors may influence the content of the messages:
#
# 			) The information available to the log writer.
#
# 			  If a log filter component executed prior to execution of the writer component removes a log event attribute,
# 			  that attribute is not available for writing.
#
# 			) System variables that may affect log writers.
#
# For all log writers, the ID included in error log messages is that of the thread within mysqld responsible for writing the message.
#
# This indicates which part of the server produced the message, and consistent with general query log and slow query log messages, which include
# the connection thread ID. 
#
# OUTPUT FORMAT FOR LOG_SINK_INTERNAL
#
# This log writer produces the traditional error log output. It writes messages using this format:
#
# 		timestamp thread_id [severity] [err_code] [subsystem] message
#
# The [] are literal chars in the message format, it does not indicate optional.
#
# The [err_code] and [subsystem] fields were added in MySQL 8.0.
# THey will be missing from logs generated by older servers.
#
# Log parsers can treat these fields as parts of the message text that will present only for logs written by servers
# recent enough to include them.
#
# Parsers must treat the err_code part of [err_code] indicators as a string value.
#
# Examples:
#
# 		2018-03-22T12:35:47.... 0 [Note] [MY-012487] [InnoDB] InnoDB: DDL log recovery : begin
# 		2018-03-22T12:35:47.... 0 [Warning] [MY-010068] [Server] CA certificate /var/mysql/sslinfo/cacert.pem is self signed.
# 		2018-03-22T12:35:47.... 4 [Note] [MY-010051] [Server] Event Scheduler: scheduler thread started with id 4
# 		2018-03-22T12:35:47.... 0 [Note] [MY-010253] [Server] IPv6 is available.
#
# OUTPUT FORMAT FOR LOG_SINK_JSON
#
# The JSON-format log writer produces messages as JSON objects that contain key/value pairs. For example:
#
#  { 	"prio": 3, "err_code": 10051, "subsystem": "Server",
# 		"source_file": "event_scheduler.cc", "function": "run",
# 		"msg": "Event Scheduler: scheduler thread started with id 4",
# 		"time": "2018-03-22T12:35:47....", "thread": 4,
# 		"err_symbol": "ER_SCHEDULER_STARTED", "SQL_state": "HY000",
# 		"label": "Note" }
#
# OUTPUT FORMAT FOR LOG_SINK_SYSEVENTLOG
#
# The system log writer produces output that conforms to the system log format used on the local platform.
#
# OUTPUT FORMAT FOR EARLY-STARTUP LOGGING
#
# The server generates some error log messages before startup options have been processed,
# and thus before it knows error log settings such as the log_error_verbosity and log_timestamps values,
# and which log components are to be used.
#
# The server handles error log messages that are generated early in the startup process as follows:
#
# 		) Prior to MySQL 8.0.14, the server generates messages with the default timestamp, format and verbosity level, and buffers them.
# 	     After the startup options are processed and the error log configuration is known, the server flushes the buffered messages.
#
# 		  Because these early messages use the default log configuration, they may differ from what is specified by the startup options.
# 		  Also, the early messages are not flushed to log writers other than the default.
#
# 		  For example, logging to the JSON writer does not include these messages because they are not in JSON format.
#
# 		) As of MySQL 8.0.14, the server buffer log events rather than formatted log messages.
# 		  This enables it to retroactively apply configuration settings to those events after hte settings are known,
# 		  with the result that flushed messages use the configured settings, not the defaults.
#
# 		  Also messages are flushed to all configured writers, not just the default writer.
#
# 		  If a fatal error occurs before log configuration is known and the server must exit, the server so they are not lost.
#
# 		  If no fatal error occurs but startup is excessively slow prior to processing startup options, the server
# 		  periodically formats and flushes buffered messages using the logging defaults so as not to appear unresponsive.
#
# 		  Although these behaviors are similar to pre-8.0.14 in that the defaults are used, they are preferable to losing messages
# 		  when exceptional conditions occur.
#
# Sytem variables That affect error log format
#
# The log_timestamps SYS_VAR controls the time zone of timestamps in messages written to the error log
# (as well as to general query log and slow query log files).
#
# Permitted values are UTC (The default), and SYSTEM(local system time zone)
#
# The following section pertains to ERROR LOG FILE FLUSHING AND RENAMING
#
# If you flush the error log using FLUSH_ERROR_LOGS, FLUSH_LOGS or mysqladmin flush-logs, the server closes
# and reopens any error log file to which it is writing.
#
# To rename an error log file, do so manually before flushing.
# Flushing the logs then opens a new file with the original file name.
#
# For example, assuming a log file name of <host_name>.err - to rename the file and create a new one,
# use the following commands:
#
# 		mv host_name.err host_name.err-old
# 		mysqladmin flush-logs
# 		mv host_name.err-old backup-directory
#
# On windows, use rename rather than MV.
#
# If the location of an error log file is not writable by the server, the log-flushing ops fail to 
# create a new log file.
#
# For example, on Linux, the server might write hte error log to the /var/log/mysqld.log file, where the
# /var/log directory is owned by root and is not writable by mysqld.
#
# If the server is not writing to a named error log file, no error log file renaming occurs when the error log is flushed.
#
# The following Chapter pertains to THE GENERAL QUERY LOG
#
# The general query log is a general record of what mysqld is doing.
# The server writes information to this log when clients connect or disconnect, and it logs each SQL
# statement received from clients.
#
# The general query log can be very useful when you suspect an error in a client and want to know exactly what
# the client sent to mysqld.
#
# Each line that shows when a client connects also includes using <connection_type> to indicate the protocol used
# to establish the connection.
#
# <connection_type> is one of:
#
#		 TCP/IP (TCP/IP connection established without SSL)
# 		 SSL/TLS (TCP/IP established with SSL),
# 		 Socket (Unix socket file connection)
# 		 Named pipe (Windows named pipe)
# 		 Shared memory (Windows shared memory connection)
#
# mysqld writes statements to the query log in the order that it receives them, which might differ from the order
# in which they are executed.
#
# This logging order is in contrast with that of the binary log, for which statements are written after they are
# executed but before any locks are released.
#
# In addition, the query log may contain statements that only select data while such statements are never written to the binary log..
#
# When using statement-based binary logging on a replication master server, statements received by its slaves are written to the query
# log of each slave.
#
# Statements are written to the query log of the master service if a client reads events with the mysqlbinlog utility and passes them to
# the server.
#
# However, when using row-based binary logging, updates are sent as row changes rather than SQL statements, and thus these statements
# are never written to the query log when binlog_format is ROW.
#
# A given update also might not be written to teh query log when this variable is set to MIXED, depending on the statement used.
#
# By default, the general query log is disabled. To specify the initial general query log state state explicitly, use --general_log[={0|1}].
# With no argument or an argument of 1, --general_log enables the log.
#
# With an argument of 0, this option disables the log.
#
# To specify a log file name, use --general_log_file=<file name>.
# To specify the log destination, use the log_output SYS_VAR.
#
# If you specify no name for the general query log file, the default name is <host_name>.log
# The server creates the file in the data dir unless an absolute path name is given to specify a different dir.
#
# To disable or enable the general query log or change the log file name at runtime, use the global general_log and
# general_log_file SYS_VAR.
#
# Set general_log to 0/OFF to disable the log or to 1/ON to enable.
#
# Set general_log_filter to specify name of the log file.
#
# If a log file is already opened, it's closed and a new one is opened.
#
# When the general query log is enabled, the server writes output to any destinations specified by the log_output SYS_VAR.
# If you enable the log, the server opens the log file and writes startup messages to it.
#
# However, further logging of queries to the file does not occur unless the FILE log designation is selected.
# If that destination is NONE, the server writes no queries even if it is enabled.
#
# Setting the log file name has no effect on logging if the log destination value does not contain FILE.
#
# Server restarts and log flushing do not cause a new general query log file to be generated (although flushing closes and reopens it).
# To rename the file and create a new one, use the following commands:
#
# 		mv <host_name>.log <host_name>-old.log
# 		mysqladmin flush-logs
# 		mv <host_name>-old.log <backup-dir>
#
# On Windows, use rename instead of mv.
#
# You can also rename the general query log file at runtime by disabling the log:
#
# 		SET GLOBAL general_log = 'OFF';
#
# With the log disabled, rename the log file externally -- for example, by cmd. THen enable it again:
#
# 		SET GLOBAL general_log = 'ON';
#
# This method works on any platform and does not require a server restart.
#
# To disable or enable general query logging for the current session, set the session sql_log_off variable to ON or OFF.
# (This assumes that the general query log itself is enabled)
#
# PWs in statements written to the general query log are rewritten by the server not to occur literally in plain text.
# Password rewriting can be suppressed for the general query log by starting the server with --log-raw option.
#
# THis option may be useful for diagnostics purposes, to see the exact text of statements as received by the
# server, but for security reasons - do not use this kind of mode in production mode.
#
# An implication of PW rewriting is that statements that cannot be parsed (due, for example, to syntax errors)
# are not written to the general query log because they cannot be known to be PW free.
#
# If you wish to log all, use --log-raw 
#
# PW rewriting occurs only when plain text PWs are expected.
# For statements with syntax that expect a PW hash value, no rewriting occurs.
#
# If plain text PW is supplied errorneously for such syntax, teh PW is logged as given - without rewriting.
#
# The log_timestamps SYS_VAR controls the time zone of timestamps in messages written to the general query log file
# (as well as to the slow query log file and the error log)
#
# It does not affect the time zone of general query log and slow query log messages written to log tables, but rows retrieved
# from those tables can be converted from the local system time zone ot any desired time zone with CONVERT_TZ() or by setting the
# session time_zone SYS_VAR.
#
# 
# The following pertains to THE BINARY LOG
#
# The binary log contains "events" that describe DB changes such as table creation operations or changes to table data.
# 
# It also contains events for statements that potentionally could have made changes (for example, a DELETE which matched no rows),
# unless row-based logging is used.
#
# The binary log also contains information about how long each statement took that updated data.
# The binary log has two important purposes:
#
# 		) For replication, the binary log on a master replication server provides a record of the data changes to be sent to slave servers.
#
# 		  The master server sends the events contained in its binary log to its slaves, which execute those events to make the same
# 		  data changes that were made on the master.
#
# 		) Certain data recovery operations require use of the binary log.
#
# 			After a backup has been restored, the events in the binary log that were recorded after the backup was
# 			made are re-executed.
#
# 			These events bring databases up to date from the point of the backup.
#
# The binary log is not used for statements such as SELECT or SHOW that do not modify data.
#
# To log all statements (for example, to identify a problem query), use the general query log
#
# Running a server with binary logging enabled makes performance slightly slower. 
#
# However, the benefits of the binary log in enabling you to set up replication and 
# for restore operations generally outweigh this minor performance decrement.
#
# The binary log is resillient to unexpected halts. Only complete events or transactions are logged or read back.
#
# PWs in statements written to the binary log are rewritten by the server not to occur literally in plain text.
#
# The following section pertains to server options and variables that affect the operation of binary logging.
#
# Binary logging is enabled by default (the log_bin SYS_VAR is set to ON). 
#
# The exception is if you use mysqld to initialize the data dir manually by invoking it with 
# the --initialize or --initialize-insecure option, when binary logging is disabled by default, but can be enabled by specifying the --log-bin option.
#
# To disable binary logging, you can specify the --skip-log-bin or --disable-log-bin option at startup.
# If either of these options is specified and --log-bin is also specified, the option specified later takes precedence.
#
# The --log-slave-updates and --slave-preserve-commit-order options require binary logging.
#
# If you disable binary logging, either omit these options, or specify --skip-log-slave-updates and
# --skip-slave-preserve-commit-order.
#
# MySQL disables these options by default when --skip-log-bin or --disable-log-bin is specified.
#
# If you specify --log-slave-updates or --slave-preserve-commit-order together with --skip-log-bin or
# --disable-log-bin, a warning error message is issued.
#
# The --log-bin[=<base name>] option is used to specify the base name for binary log files.
# If you do not supply the --log-bin option, MySQL uses binlog as the default base name for the binary log files.
#
# For compability with earlier releases, if you supply the --log-bin option with no string or with an empty string,
# the base name defaults to <host_name>-bin, using the name of the host machine.
#
# It is recommended that you specify a base name, so that if the host name changes, you can easily continue to use
# the same binary log file names. 
#
# If you supply an extension in the log name (for example, --log-bin=<base_name.extension>), the extension is silently removed and ignored.
# 
# mysqld appends a numeric extension to the binary log base name to generate binary log file names. The number increases each time the server
# creates a new log file, thus creating an ordered series of files.
#
# The server creates a new file in the series each time it starts or flushes the logs.
# The server also creates a new binary log file automatically after the current log's size reaches max_binlog_size.
#
# A binary log file may become larger than max_binlog_size if you are using large transaction because a transaction
# is written ot hte file in one piece, never split between files.
#
# To keep track of which binary log files have been used, mysqld also creates a binary log index file that contains the names
# of all used binary log files. 
#
# By default, this has the same base name as the binary log file, with the extension '.index'.
#
# You can change the name of the binary log index file with the --log-bin-index[=<file name>] option.
# You should not manually edit this file while mysqld is running: doing so would confuse mysqld.
#
# The term "binary log file" denotes a individual numbered file containing DB events. The term "binary log" collectively
# denotes the set of numbered binary log files plus the index file.
#
# The default location for binary log files and the binary log index file is the data directory.
#
# You can use the --log-bin option to specify an alternative location, by adding a leading absolute path name to the base name
# to specify a different dir.
#
# When the server reads an entry from the binary log index file, which tracks the binary log files that have been used,
# it checks whether the entry contains a relative path.
#
# If it does, the relative part of the path is replaced with the absolute path set using the --log-bin option.
#
# An absolute path recorded in the binary log index file remains unchanged; in such a case, the index file must be edited
# manually to enable a new path or paths to be used. 
#
# The binary log file base name and any specified path are available as the log_bin_basename SYS_VAR.
#
# In MySQL 5.7, a server ID had to be specified when binary logging was enabled, or the server would not start.
#
# In MySQL 8.0, the server_id SYS_VAR is set to 1 by default.
#
# The server can be started with this default ID when binary logging is enabled, but an informational message is issued
# if you do not specify a server ID explicitly using the --server-id option.
#
# For servers that are used in a replication topology, you must specify a unique nonzero server ID for each server.
#
# A client that has privs sufficient to set restricted session SYS_VARs can disable binary logging of its own statements
# by using a SET_sql_log_bin=OFF statement.
#
# By default, the server logs the length of the event as well as the event itself and uses this to verify that the event
# was written correctly.
#
# You can also cause the server to write checksums for the events by setting the binlog_checksum SYS_VAR.
#
# When reading back from the binary log, the master uses the event length by default, but can be made to use checksums
# if available by enabling the master_verify_checksum SYS_VAR.
#
# The slave I/O thread also verifies events received from the master. 
# You can cause the slave SQL thread to use checksums if available when reading from the relay log by enabling the slave_sql_verify_checksum SYS_VAR.
#
# The format of the events recorded in the binary log is dependent on the binary logging format. 
# Three format types are supported: row-based logging, statement-based logging and mixed-based logging.
#
# The binary logging format used depends on the MySQL version.
#
# The server evaluates the --binlog-do-db and --binlog-ignore-db options in the same way as it does the
# --replicate-do-db and --replicate-ignore-db options.
#
# A replication slave server is started with the --log-slave-updates setting enabled by default, meaning that the
# slave writes to its own binary log any data modifications that are received from the replication master.
#
# The binary log must be enabled for this setting to work.
# This setting enables the slave to act as a master to other slaves in chained replication.
#
# You can delete all binary log files with the RESET_MASTER statement or a subset of them with PURGE_BINARY_LOGS.
#
# If you are using replication, you should not delete old binary log files on the master until you are sure that no slave
# still needs to use them.
#
# For example, if your slaves never run more than three days behind, once a day you can execute mysqladmin flush-logs on the master
# and then remove any logs that are more than three days old.
#
# You can remove the files manually, but it is preferable to use PURGE_BINARY_LOGS, which also safely updates the binary log index
# file for you (and which can take a date argument)
#
# You can display the contents of binary log files with the mysqlbinlog utility.
# This can be useful when you want to reprocess statements in the log for a recovery operation.
#
# For example, you can update MySQL server from the binary log as follows:
#
# 	mysqlbinlog <log_file> | mysql -h <server_name>
#
# mysqlbinlog also can be used to display replication slave relay log file contents because they are written using the same
# format as binary log files.
#
# Binary logging is done immediately after a statement or transaction completes but before any locks are released or any commit is done.
# This ensures that the log is logged in commit order.
#
# Updates to nontransactional tables are stored in the binary log immediately after execution.
#
# Within an uncommitted transaction, all updates (UPDATE, DELETE or INSERT) that change transactional tables such as InnoDB tables
# are cached until a COMMIT statement is received by the server. 
#
# At that point, mysqld writes the entire transaction to the binary log before the COMMIT is executed.
#
# Modifications to nontransactional tables cannot be rolled back. If a transaction that is rolled back
# includes modifications to nontransactional tables, the entire transaction is logged with a ROLLBACK
# statement at the end to ensure that the modifications to those tables are replicated.
#
# When a thread that handles the transaction starts, it allocates a buffer of binlog_cache_size to buffer
# statements.
#
# If a statement is bigger than this, the thread opens a temporary file to store the transaction.
# The temporary file is deleted when the thread ends.
#
# The Binlog_cache_use status variable shows the number of transactions that used this buffer (and possibly a temporary file) for storing statements.
# The Binlog_cache_disk_use status variable shows how many of those transactions actually had to use a temporary file.
#
# These two variables can be used for tuning binlog_cache_size to a large enough value that avoids the use of temporary files.
#
# The max_binlog_cache_size SYS_VAR (default 4GB, which is also the maximum), can be used to restrict the total size used
# to cache a multiple-statement transaction.
#
# If a transaction is larger than this many bytes, it fails and rolls back. The min value is 4096.
#
# If you are using the binary log and row based logging, concurrent inserts are converted to normal inserts for CREATE ... SELECT or
# INSERT ... SELECT statements.
#
# This is done to ensure that you can re-create an exact copy of your tables by applying the log during a backup operation.
#
# If you are using statement-based logging, the original statement is written to the log.
#
# The binary log format has some known limitations that can affect recovery from backups. Later covered.
#
# Binary logging for stored programs is done and described later.
#
# Note htat hte binary log format differs in MySQL 8.0 from previous versions of MySQL, due to enhancements in replication.
#
# Writes to the binary log file and binary log index file are handled in the same way as writes to MyISAM tables.
#
# By default, the binary log is synched to disk at each write (sync_binlog=1). 
#
# If sync_binlog was not enabled, and the OS or machine (not only the MySQL server) crashed, there is a chance that the last
# statements of the binary log could be lost.
#
# To prevent this, enable the sync_binlog SYS_VAR to synch the binary log to disk after every N commit groups.
#
# The safest value for sync_binlog is 1 (the default), but this is also the slowest.
#
# In earlier MySQL releases, there was a chance of inconsistency between the table content and binary log content if a crash occured,
# even with sync_binlog set to 1.
#
# For example, if you are using InnoDB tables and the MySQL server processes a COMMIT statement, it writes many prepared transactions
# to the binary log in sequence, synchs the binary log, and then commits the transaction into InnoDB.
#
# If the server crashed between those two operations, the transaction would be rolled back by InnoDB at restart but still exist in the binary log.
#
# Such an issue was resolved in previous releases by enabling InnnoDB support for two-phase commit in XA transactions.
#
# In >= 5.8, the InnoDB support for two-phase commit in XA transactions is always enabled.
#
# InnoDB support for two-phase commit in XA transactions ensures that the binary log and InnoDB data files are synched.
# However, the MySQL server should also be configured to synch the binary log and the InnoDB logs to disk before committing the transactions.
#
# THe InnoDB logs are synched by default, and sync_binlog=1 ensures that the binary log is synchronized.
#
# The effect of implicit InnoDB support for two-phase commit in XA transactions and sync_binlog=1 is that at restart
# after a crash, after doing a rollback of transactions, the MySQL server scans the latest binary log file to collect
# transactions <xid> values and calculate the last valid position in the binary log file.
#
# The MySQL server then tells InnoDB to complete any prepared transactions that were successfully written to the binary log,
# and truncates the binary log to the last valid position.
#
# This ensures that the binary log reflects the exact data of InnoDB tables, and therefore the slave remains in synch
# with the master because it does not receive a statement which has been rolled back.
#
# If the MySQL Server discovers at crash recovery that the binary log is shorter than it should have been, it lacks at least
# one successfully committed InnoDB transaction.
#
# This should not happen if sync_binlog=1 and the disk/file system do an actual sync when they requested to (some do not), so the
# server prints an error message:
#
# 		The binary log <file_name> is shorter than its expected size.
#
# In this case, this binary log is not correct and replication should be restarted from a fresh snapshot of the master's data.
#
# The session values of the following SYS_VAR's are written to the binary log and honored by the replication slave when parsing the binary log:
#
# 		sql_mode (except that the NO_DIR_IN_CREATE mode is not replicated)
#
# 		foreign_key_checks
#
# 		unique_checks
#
# 		character_set_client
#
# 		collation_connection
#
# 		collation_database
#
# 		collation_server
#
# 		sql_auto_is_null
#
# The following pertains to Binary Logging Formats
#
# The server uses several logging formats to record information in the binary log:
#
# 		) Replication capabilities in MySQL originally were based on propagation of SQL statements from master to slave.
# 		  This is called statement-based logging.
#
# 		  You can cause this format to be used by starting the server with --binlog-format=STATEMENT
#
# 		) In <row-based loggin> (the default), the master writes events to the binary log that indicate how individual table rows
# 		  are affected.
#
# 		  You can cause the server to use row-based logging by starting it with --binlog-format=ROW
#
# 		) A third option is also available: mixed logging.
#
# 		  With mixed logging, the statement-based logging is used by default, but the logging mode switches automatically to
# 		  row-based in certain cases as described below.
#
# 		  You can cause MySQL to use mixed logging explicitly by starting mysqld with the option --binlog-format=MIXED
#
# The logging format can also be set or limited by the storage engine being used.
#
# This helps to eliminate issues when replicating certain statements between a master and slave which are using different storage engines.
#
# With statement-based replication, there may be issues with replicating nondeterministic statements.
#
# In deciding whether or not a given statement is safe for statement-based replication, MySQL determines whether it can guarantee
# that the statement can be replicated using statement-based logging.
#
# If MySQL cannot make this guarantee, it marks the statement as potentionally unreliable and issues the warning, Statement may not be safe to log in statement format.
#
# You can avoid these issues by using MySQL's row-based replication instead.
#
# The following pertains to Setting The Binary Log Format
#
# You can select the binary logging format explicitly by starting the MySQL server with --binlog-format=<type>.
# The supported values for <type> are:
#
# 		STATEMENT causes logging to be statement based.
#
# 		ROW causes logging to be row based. This is the default.
#
# 		MIXED causes logging to use mixed format.
#
# The logging format also can be switched at runtime, although note that there are a number of situations in which
# you cannot do this, as discussed later in this section.
#
# Set the global value of the binlog_format SYS_VAR to specify the format for clients that connect subsequent to the change:
#
# 		SET GLOBAL binlog_format = 'STATEMENT';
# 		SET GLOBAL binlog_format = 'ROW';
# 		SET GLOBAL binlog_format = 'MIXED';
#
# An individual client can control the logging format for its own statements by setting the session value of binlog_format:
#
# 		SET SESSION binlog_format = 'STATEMENT';
# 		SET SESSION binlog_format = 'ROW';
# 		SET SESSION binlog_format = 'MIXED';
#
# Changing the global binlog_format value requires privs sufficient to set Global SYS_VARs.
#
# Changing the session binlog_format value requires privs sufficient to set restricted SYS_VARs. 
#
# There are several reasons why a client might want to set binary logging on a per-session basis:
#
# 		) A session that makes many small changes to the DB might want to use row-based logging.
#
# 		) A session that performs updates that match many rows in the WHERE clause might want to use statement-based logging
# 		  because it will be more efficient to log a few statements than many rows.
#
# 		) Some statements require a lot of execution time on the master, but result in just a few rows being modified.
#
# 		  It might therefore be beneficial to replicate them using row-based logging.
#
# There are exceptions when you cannot switch the replication format at runtime:
#
# 		) The replication format cannot be changed from within a stored function or a trigger.
#
# 		) If the NDB storage engine is enabled.
#
# 		) If a session has open temporary tables, the replication format cannot be changed for the session (SET @@SESSION.binlog_format)
#
# 		) If any replication channel has open temporary tables, the replication format cannot be changed globally (SET @@GLOBAL.binlog_format or 
# 		  SET @@PERSIST.binlog_format)
#
# 		) If any replication channel applier thread is currently running, the replication format cannot be changed globally
# 		  (SET @@GLOBAL.binlog_format or SET @@PERSIST.binlog_format)
#
# Trying to switch the replication format in any of these cases (or attempting to set the current replication format) results in an error.
#
# You can, however - use PERSIST_ONLY (SET @@PERSIST_ONLY.binlog_format) to change the replication format at any time, because this action
# does not modify the runtime global SYS_VAR and takes effect only after a server restart.
#
# Switching the replication format at runtime is not recommended when any temporary table exist, because temporary tables are logged only
# when using statement-based replication, whereas with row-based replication and mixed replication, they are not logged.
#
# Switching the replication format while replication is ongoing can also cause issues.
#
# Each MySQL Server can set its own and only its own binary logging format (true whether binlog_format is set with global or session scope).
#
# This means that changing the logging format on a replication master does not cause a slave to change its logging format to match.
#
# When using STATEMENT mode, the binlog_format SYS_VAR is not replicated.
#
# When using MIXED or ROW logging mode, it is replicated but is ignored by the slave.
#
# A replication slave is not able to convert binary log entries received in ROW Logging format to STATEMENT format for use in its own binary log.
# 
# The slave must therefore use ROW or MIXED format if the master does. 
#
# Changing the binary logging format on the master from STATEMENT to ROW or MIXED while replication is ongoing to a slave with
# STATEMENT format can cause replication to fail with errors such as Error executing row event:
#
# 	 'Cannot execute statement: impossible to write to binary log since statement is in row format and BINLOG_FORMAT = STATEMENT.'
#
# Changing the binary logging format on the slave to STATEMENT format when the master is still using MIXED or ROW format also
# causes the same type of replication failure.
#
# To change the format safely, you must stop replication and ensure that the same change is made on both the master and the slave.
#
# If you are using InnoDB tables and the transaction isolation level is READ_COMMITTED or READ_UNCOMMITTED, only row-based logging
# can be used.
#
# It is possible to change the logging format to STATEMENT, but doing so at runtime leads very rapidly to errors because InnoDB can no longer perform inserts.
#
# With the binary log format set to ROW, many changes are written to the binary log using the row-based format.
# Some changes, however, still use the statement-based format.
#
# Examples include all DDL (data definition language) statements such as CREATE_TABLE, ALTER_TABLE or DROP_TABLE.
#
# The --binlog-row-event-max-size option is available for servers that are capable of row-based replication.
# Rows are stored into the binary log in chunks having a size in bytes not exceeding the value of this option.
#
# The value must be a x of 256. Default is 8192.
#
# WARNING:
#
# 		When using <statement-based logging> for replication, it is possible for the data on the master and slave to become different if a statement
# 		is designed in such a way that the data modification is nondeterministic.
#
# 		That is, it is left to the will of the query optimizer.
#
# 		In general, this should not be done - even outside of replication.
#
# The following pertains to Mixed Binary Logging Format.
#
# When running in MIXED logging format, the server automatically switches from statement-based to row-based logging under the following conditions:
#
# 		) When a function contains UUID()
#
# 		) When one or more tables with AUTO_INCREMENT columns are updated and a trigger or stored function is invoked.
# 		  Like all other unsafe statements, this generates a warning if binlog_format = <STATEMENT>
#
# 		) When the body of a view requires row-based replication, the statement creating the view also uses it.
#
# 		  For example, this occurs when the statement creating a view uses the UUID() function.
#
# 		) When a call to a UDF is involved.
#
# 		) When FOUND_ROWS() or ROW_COUNT() is used (Bug #12092, Bug #30244)
#
# 		) When USER(), CURRENT_USER(), or CURRENT_USER is used. (Bug #28086)
#
# 		) When one of the tables involved is a log table in the mysql database.
#
# 		) When the LOAD_FILE() function is used. (Bug #39701)
#
# 		) When a statement refers to one or more SYS_VARs (Bug #31168)
#
# 			Exception: The following SYS_VAR, when used with session scope (only), do not cause the logging format to switch:
#
# 				) auto_increment_increment
#
# 				) auto_increment_offset
#
# 				) character_set_client
#
# 				) character_set_connection
#
# 				) character_set_database
#
# 				) character_set_server
#
# 				) collation_connection
#
# 				) collation_database
#
# 				) collation_server
#
# 				) foreign_key_checks
#
# 				) identity
#
# 				) last_insert_id
#
# 				) lc_time_names
#
# 				) pseudo_thread_id
#
# 				) sql_auto_is_null
#
# 				) time_zone
#
# 				) timestamp
#
# 				) unique_checks
#
# 
# In earlier releases, when mixed binary logging format was in use, if a statement was logged by row and the session that executed the
# statement had any temporary tables, all subsequent statements were treated as unsafe and logged in row-based format until all 
# temporary tables in use by that session were dropped.
#
# As of MySQL 8.0, operations on temporary tables are not logged in mixed binary logging format, and the presence of temporary tables
# in the session has no impact on the logging mode used for each statement.
#
# 		NOTE:
#
# 			A warning is generated if you try to execute a statement using statement-based logging that should be written using row-based logging.
# 			The warning is shown both in the client (in the output of SHOW_WARNINGS) and through the mysqld error log.
#
# 			A warning is added to the SHOW_WARNINGS table each time such a statement is executed.
# 			However, only the first statement that generated the warning for each client session is written to the error log to prevent flooding the log.
#
# In addition to the decisions above, individual engines can also determine the logging format used when information in a table is updated.
# The logging capabilities of an individual engine can be defined as follows:
#
# 		) If an engine supports row-based logging, the engine is said to be row-logging capable.
#
# 		) If an engine supports statement-based logging, the engine is said to be statement-logging capable.
#
# A given storage engine can support either or both logging formats.
#
# The following table lists the formats supported by each engine.
#
# 	Storage Engine 	Row Logging Supported 				Statement Logging Supported
# 	ARCHIVE  			Yes 										Yes
# 	BLACKHOLE 			Yes 										Yes
#  CSV 					Yes 										Yes
# 	EXAMPLE 				Yes 										No
# 	FEDERATED 			Yes 										Yes
# 	HEAP 					Yes 										Yes
# 	
# 	InnoDB 				Yes 										Yes when the transaction isolation level is REPEATABLE_READ or SERIALIZABLE. No otherwise.
# 	MyISAM 				Yes 										Yes
# 	MERGE 				Yes 										Yes
# 	NDB 					Yes 										No
#
# Whether a statement is to be logged and the logging mode to be used is determined according to:
#
# 		) the type of statement (safe, unsafe, or binary injected)
#
# 		) the binary logging format (STATEMENT, ROW or MIXED)
# 
# 		) the logging capabilities of the storage engine (statement capable, row capable, both or neither)
#
# 		(Binary injection refers to logging a change that must be logged using ROW format)
#
# Statements may be logged with or without a warning; failed statements are not logged, but generate errors in the log.
# This is shown in the following decision table:
#
# 		Type, binlog_format, SLC and RLC columns outline the conditions
#
# 		Error/Warning and Logged as columns represent the corresponding actions.
#
# 		SLC/RLC is for "statement-logging capable"/"row-logging capable"
#
# 	Type 		binlog_format 			SLC 		RLC 		Error/Warning 								 			Logged as
#
# 	* 			* 							No 		No 		Error: Cannot execute statement. 	 			-
# 																	Binary logging is impossible since
# 																	at least one engine is involved that is
# 																	both row-incapable and statement-incapable.
#
#  Safe 		STATEMENT 				Yes 		No 		- 															STATEMENT
#
# 	Safe 		MIXED 					Yes 		No 		- 															STATEMENT
#
# 	Safe 		ROW 						Yes 		No 		Error: Cannot execute statement. 				- 				-
# 																	Binary logging is impossible since
# 																	BINLOG_FORMAT = ROW and at least one
# 																	table uses a storage engine that is not
# 																	capable of row-based logging.
#
# 	Unsafe 	STATEMENT 				Yes 		No 		Warning: Unsafe statement binlogged in 		STATEMENT
# 																	statement format, since BINLOG_FORMAT = 
# 																	STATEMENT.
#
# 	Unsafe 	MIXED 					Yes 		No 		Error: Cannot execute statement. 				-
# 																	Binary logging of an unsafe statement
# 																	is impossible when the storage engine
# 																	is limited to statement-based logging,
# 																	even if BINLOG_FORMAT = MIXED.
#
# 	Unsafe 	ROW 						Yes 		No 		Error: Cannot execute statement. 				-
# 																	Binary logging is impossible since 
# 																	BINLOG_FORMAT = ROW and at least one
# 																	table uses a storage engine that is not
# 																	capable of row-based logging.
#
# 	Row inj. STATEMENT 				Yes 		No 		Error: Cannot execute row injection. 			-
# 																	Binary logging is not possible since
# 																	at least one table uses a storage engine
# 																	that is not capable of row-based logging.
#
# 	Row inj. MIXED 					Yes 		No 		Error: Cannot execute row injection. 			-
# 																	Binary logging is not possible since at
# 																	least one table uses a storage engine
# 																	that is not capable of row-based logging.
#
# 	Row inj. ROW 						Yes 		No 		Error: Cannot execute row injection. 			-
# 																	Binary logging is not possible since at least
# 																	one table uses a storage engine that is not
# 																	capable of row-based logging.
#
# 	Safe 		STATEMENT 				No 		Yes 		Error: Cannot execute statement. 		 		-		-
#	 																Binary logging is impossible since
#  																BINLOG_FORMAT = STATEMENT and at least one
# 																	table uses a storage engine that is 
# 																	not capable of statement-based logging.
#
# 	Safe 		MIXED 					No 		Yes 		- 															ROW
#
# 	Safe 		ROW 						No 		Yes 		- 															ROW
#
# 	Unsafe 	STATEMENT 				No 		Yes 		Error: Cannot execute statement.  				-				-
# 																	Binary logging is impossible since BINLOG
# 																	_FORMAT = STATEMENT and at least one
# 																	table uses a storage engine that is not
# 																	capable of statement-based logging.
#
# 	Unsafe 	MIXED 					No 		Yes 		- 															ROW
#
# 	Unsafe 	ROW 						No 		Yes 		- 															ROW
#
# 	Row Inj. STATEMENT 				No 		Yes 		Error: Cannot execute row injection. 			-
# 																	Binary logging is not possible since
# 																	BINLOG_FORMAT = STATEMENT.
#
# 	Row Inj. MIXED 					No 		Yes 		- 															ROW
#
# 	Row Inj. ROW 						No 		Yes 		- 															ROW
#
# 	Safe 		STATEMENT 				Yes 		Yes 		- 															STATEMENT
#
# 	Safe 		MIXED 					Yes 		Yes 		- 															STATEMENT
#
# 	Safe 		ROW 						Yes 		Yes 		- 															ROW
#
# 	Unsafe 	STATEMENT 				Yes 		Yes 		Warning: Unsafe statement binlogged in  		STATEMENT
# 																	statement format since BINLOG_FORMAT =
# 																	STATEMENT.
#
# 	Unsafe 	MIXED 					Yes 		Yes 		- 															ROW
#
# 	Unsafe 	ROW 						Yes 		Yes 		- 															ROW
#
# 	Row Inj. STATEMENT 				Yes 		Yes 		Error: Cannot execute row injection. 			-
# 																	Binary logging is not possible because
# 																	BINLOG_FORMAT = STATEMENT.
#
# 	Row Inj. MIXED 					Yes 		Yes 		- 															ROW
#
# 	Row Inj. ROW 						Yes 		Yes 		- 															ROW
#
# When a warning is produced by determination, a standard MySQL warning is produced (and is available using SHOW_WARNINGS).
# The information is also written to the mysqld error log.
#
# Only one error for each error instance per client connection is logged to prevent flooding the log.
# The log message includes the SQL statement that was attempted.
#
# If a slave server has log_error_verbosity set to display warnings, the slave prints messages to the error log to provide
# information about its status, such as the binary log and relay log co-ords where it starts its job, when it is switching
# to another relay log - when it reconnects after a disconnect, statements that are unsafe for statement-based logging, etc.
#
# The following pertains to Logging Format for Changes to mysql Database Tables
#
# The contents of the grant tables in the mysql database can be modified directly (for example, with INSERT or DELETE) or 
# indirectly (for example, with GRANT or CREATE USER).
#
# Statements that affect mysql database tables are written to the binary log using the following rules:
#
# 		) Data manipulation statements that change data in mysql database tables directly are logged according ot the setting of
# 		  the binlog_format SYS_VAR.
#
# 	     This pertains to statements such as INSERT, UPDATE, DELETE, REPLACE, DO, LOAD_DATA_INFILE, SELECT, and TRUNCATE_TABLE.
#
# 		) Statements that change the mysql db indirectly are logged as statements regardless of the value of binlog_format.
#
# 		  This pertains to statements such as GRANT, REVOKE, SET_PASSWORD, RENAME_USER, CREATE (all forms except CREATE_TABLE_..._SELECT),
# 		  ALTER(all forms) and DROP(all forms)
#
# CREATE_TABLE_..._SELECT is a combination of data definition and data manipulation.
#
# The CREATE_TABLE part is logged using statement format and the SELECT part is logged according to the value of binlog_format.
#
# The following pertains to The Slow Query Log:
#
# The slow query log consists of SQL statements that take more than long_query_time seconds to execute and require at least
# min_examined_row_limit rows to be examined.
#
# The slow query log can be used to find queries that take a long time to execute and are therefore candidates for optimizations.
#
# However, examining a long slow query log can be a time-consuming task. You can use mysqldumpslow to process a slow query log file
# and summarize its contents.
#
# The time to acquire the initial locks is not counted as execution time. 
#
# mysqld writes a statement to the slow query log after it has been executed and after all locks have been released, so log order might differ from execution order.
#
# The following pertains to Slow Query Log Parameters
#
# The minimum and default values of long_query_time are 0 and 10, respectively.
# The value can be specified to a resolution of microseconds.
#
# By default, administrative statements are not logged, nor are queries that do not use indexes for lookups.
#
# This behavior can be changed using log_slow_admin_statements and log_queries_not_using_indexes, described later.
#
# By default, the slow query log is disabled.
# To specify the initial slow query log state explicitly, use --slow_query_log[={0|1}].
#
# WIth no argument or an arg of 1, --slow_query_log enables the log.
# With an arg of 0, this option disables the log.
#
# To specify a log file name, use --slow_query_log_file=<file_name>.
# To specify log destination, use the log_output SYS_VAR.
#
# 		NOTE: If you specify the TABLE log destination - a possible error is too many tables opening.
#
# If you specify no name for the slow query log file, the default name is <host_name>-slow.log
# The server creates the file in the data directory unless an absolute path name is given to specify a different one.
#
# To disable or enable the slow query log or change the log file name at runtime, use the global slow_query_log and slow_query_log_file SYS_VARs.
# Set slow_query_log to 0 to disable the log or to 1 to enable it.
#
# Set slow_query_log_file to specify the name of the log file.
# If a log file already is open, it is closed and the new file is opened.
#
# The server writes less info to the slow query log if you use the --log-short-format option.
#
# To include slow admin statements in the slow query log, enable the log_slow_admin_statements SYS_VAR.
# Admin statements include ALTER_TABLE, ANALYZE_TABLE, CHECK_TABLE, CREATE_INDEX, DROP_INDEX, OPTIMIZE_TABLE
# and REPAIR_TABLE.
#
# To include queries that do not use indexes for row lookups in the statements written to the slow query log,
# enable the log_queries_not_using_indexes SYS_VAR.
#
# Even with that var enabled, the server does not log queries that would not benefit from the presence of an index
# due to the table having fewer than two rows.
#
# When queries that do not use an index are logged, the slow query log may grow quickly.
#
# It is possible to put a rate limit on these queries by setting the log_throttle_queries_not_using_indexes SYS_VAR.
#
# By default, this var is 0 - which means there is no limit. Positive values imposes a per-minute limit on logging
# of queries that do not use indexes.
#
# The first such query opens a 60-second widnow within which the server logs queries up to the given limit, then suppresses
# additional queries.
#
# If there are suppressed queries when the window ends, the server logs a summary that indicates how many there were and the
# aggregate time spent in them.
#
# The next 60-second window begins when the server logs the next query that does not use indexes.
#
# The server uses the controlling parameter in the following order to determine whether to write a query to the slow query log:
#
# 		1) The query must either not be an administrative statement, or log_slow_admin_statements must be enabled.
#
# 		2) The query must have taken at least long_query_time seconds, or log_queries_not_using_indexes must be enabled and the query
# 			used no indexes for row lookups.
#
# 		3) THe query must have examined at least min_examined_row_limit rows.
#
# 		4) The query must not be suppressed according to the log_throttle_queries_not_using_indexes setting.
#
# The log_timestamps SYS_VAR controls the time zone of timestamps in messages written to the slow query log file 
# (as well as to the general query log file and the error log).
#
# It does not affect the time zone of general query log and slow query log messages written to log tables, but rows
# retrieved from those tables can be converted from the local system time zone to any desired time zone with CONVERT_TZ()
# or by setting the session time_zone SYS_VAR.
#
# By default, a replication slave does not write replicated queries to the slow query log.
# To change this, enable the log_slow_slave_statements SYS_VAR.
#
# The following pertains to Slow Query Log Contents
#
# When the slow query log is enabled, the server writes output to any destinations specified by the log_output SYS_VAR.
# If you enable the log, the server opens the log file and writes startup messages to it.
#
# However, further logging of queries to the file does not occur unless the FILE log destination is selected.
# If the destination is NONE, the server writes no queries even if the slow query log is enabled.
#
# Setting the log file name has no effect on logging if FILE is not selected as an output destination.
#
# If the slow query log is enabled and FILE is selected as an output destination, each statement written to the log
# is preceded by a line that begins with a # char and has these fields (with all fields or a single line):
#
# 		Query_time: <duration>
#
# 			The statement execution time in seconds
#
# 		Lock_time: <duration>
#
# 			The time to acquire locks in seconds.
#
# 		Rows_sent: <N>
#
# 			The number of rows sent to the client
#
# 		Rows_examined:
#
# 			The number of rows examined by the optimizer.
#
# Enabling the log_slow_extra SYS_VAR (available as of MySQL 8.0.14) causes the server to write the following extra fields
# to FILE output in addition to those just listed (TABLE output is unaffected).
#
# Some field descriptions refer to Status variables names.
# In the slow query log, the counters are per-statement values, not cumulative per-session values.
#
# 		Thread_id: ID
#
# 			The statement thread identifier.
#
# 		Errno: <error_number>
#
# 			The statement error number, or 0 if no error occurred.
#
# 		Killed: <N>
#
# 			If the statement was terminated, the error number indicating why or 0 if the statement terminated normally.
#
# 		Bytes_received: <N>
#
# 			The Bytes_received value for the statement.
#
# 		Bytes_sent: <N>
#
# 			The Bytes_sent value for the statement.
#
# 		Read_first: <N>
#
# 			The Handler_read_first value for the statement
#
# 		Read_last: <N>
#
# 			The Handler_read_last value for the statement.
#
# 		Read_key: <N>
#
# 			The Handler_read_key value for the statement
#
# 		Read_next: <N>
#
# 			The Handler_read_next value for the statement
#
# 		Read_prev: <N>
#
# 			The Handler_read_prev value for the statement.
#
# 		Read_rnd: <N>
#
# 			The Handler_read_rnd value for the statement.
#
# 		Read_rnd_next: <N>
#
# 			The Handler_read_rnd_next value for the statement.
#
# 		Sort_merge_passes: <N>
#
# 			The Sort_merge_passes value for the statement.
#
# 		Sort_range_count: <N>
#
# 			The Sort_range value for the statement.
#
# 		Sort_rows: <N>
#
# 			The Sort_rows value for the statement.
#
# 		Sort_scan_count: <N>
#
# 			The Sort_scan value for the statement.
#
# 		Created_tmp_disk_tables: <N>
#
# 			The Created_tmp_disk_tables value for the statement.
#
# 		Created_tmp_tables: <N>
#
# 			The Created_tmp_tables value for the statement.
#
# 		Start: <timestamp>
#
# 			The statement execution start time
#
# 		End: <timestamp>
#
# 			The statement execution end time.
#
# A given slow query log file may contain a mix of lines with and without the extra fields added by enabling log_slow_extra.
# Log file analyzers can determine whether a line contains the additional fields by the field count.
#
# Each statement written to the slow query log file is preceded by a SET statement that includes a timestamp.
# As of MySQL 8.0.14 - the timestamp indicates when the slow statement began executing.
#
# < 8.0.14 MySQL the timestamp indicates when the slow statement was logged (which occurs after statement finishes executing)
#
# PWs in statements written to the slow query log are rewritten by the server not to occur literally in plain text.
#
# The following pertains to The DDL Log:
#
# The DDL log, or metadata log, records metadata operations generated by data definition statements such as DROP_TABLE and ALTER_TABLE.
#
# MySQL uses this log to recover from crashes occurring in the middle of a metadata operation.
#
# When executing the statement DROP TABLE t1, t2 - we need to ensure that both t1 and t2 are dropped, and that each table
# drop is complete.
#
# ANother example of this type of SQL statement is ALTER_TABLE_t3_DROP_PARTITION_p2, where we must make certain that the partition
# is completely dropped and that its definition is removed from the list of partitions for table t3.
#
# A record of metadata operations such as those just described are written to the file ddl_log.log in the MySQL Data dir.
# This is a binary file, it is not intended to be human-readable, and do not modify it.
#
# ddl_log.log is not created until it is actually needed for recording metadata statements, and is removed following a successful start of
# mysqld.
#
# Thus, it is possible for this file not ot be present on a MySQL server that is functioning in a completely normal manner.
#
# Currently, ddl_log.log can hold up to 1048573 entries, or 4 GB. once this limit is exceeded, you must rename or remove the file before
# it is possible to execute any additional DDL statements. This is a known issue being worked on.
#
# There are no user-config server options or variables related to this file.
#
# The following pertains to Server Log Maintenance:
#
# MySQL Servers can create several different log files to help you see what activity is taking place.
# However, one must regularly clean up the logs.
#
# When using MySQL with logging enabled, you may want to back up and remove old log files from time to time and tell MySQL to start
# logging to new files.
#
# On a Linux (Red Hat) installation, you can use the mysql-log-rotate scripts for this.
#
# If you installed MySQL from an RPM distrib, this script should have been installed automatically.
#
# Be careful with said script if you are using binary log for replication. You should not remove binary logs until you are certain that
# their contents have been processed by all slaves.
#
# On other systems, you must install a short script yourself that you start from cron (or its equivalent) for hanling log files.
#
# Binary logs are automatically removed after the server's binary log expiration period.
# Removal of the files can take place at startup and when the binary log is flushed.
#
# The default binary log expiration period is 30 days. You can specify an alternative expiration period using the binlog_expire_logs_seconds
# SYS_VAR.
#
# If you are using replication, you should specify an expiration period that is no lower than the maximum amount of time your slaves might lag
# behind the master.
#
# To remove binary logs on demand, use the PURGE_BINARY_LOGS statement.
#
# You can force MySQL to start using new log files by flushing the logs.
#
# Log flushing occurs when you issue a FLUSH_LOGS statement or execute a mysqladmin flush-logs,
# mysqladmin refresh, mysqldump --flush-logs or mysqldump --master-data cmd.
#
# In addition, the binary log is flushed when its size reaches the value of the max_binlog_size SYS_VAR.
#
# FLUSH_LOGS supports optional modifiers to enable selective flushing of individual logs (for example, FLUSH_BINARY_LOGS)
#
# A log-flushing operation does the following:
#
# 		) If general query logging or slow query logging to a log file is enabled, the server closes and reopens the general query log file or slow query log file.
#
# 		) If binary logging is enabled, the server closes the current binary log file and opens a new log file with the next sequence number.
#
# 		) If the server was started with the --log-error option to cause the error log to be written to a file, the server closes and reopens the log file.
#
# The server creates a new binary log file when you flush the logs.
# However, it just closes and reopens the general and slow query log files.
#
# To cause new files to be created on Unix, rename the current log files before flushing them.
# At flush time, the server opens new log files with the original names.
#
# For example, if the general and slow query log files are named mysql.log and mysql-slow.log, you can use
# a series of commands akin to:
#
# 	cd <mysql-data-directory>
# 	mv mysql.log mysql.old
# 	mv mysql-slow.log mysql-slow.old
# 	mysqladmin flush-logs
#
# On Windows, it's rename rather than mv.
#
# At this point, you can make a backup of mysql.old and mysql-slow.old and remove them from the disk.
#
# A similar strategy can be used to back up the error log file, if there is one.
#
# You can rename the general query log or slow query log at runtime by disabling the log:
#
# 		SET GLOBAL general_log = 'OFF';
# 		SET GLOBAL slow_query_log = 'OFF';
#
# With the logs disabled, rename the log files externally; for example, from the cmd line.
# Then enable the logs again:
#
# 		SET GLOBAL general_log = 'ON';
# 		SET GLOBAL slow_query_log = 'ON';
#
# This method works on any platform and does not require a server restart.
#
# NOTE:
#
# 		For the server to recreate a given log file after you have renamed the file externally, the file location
# 		must be writable by the server.
#
# 		This may not always be the case. For example, on Linux, the server might write the error log as /var/log/mysqld.log,
# 		where /var/log is owned by root and not writable by mysqld.
#
# 		In this case, the log-flushing operation will fail to create a new log file.
#
# 		To handle this situation, you must manually create the new log file with the proper ownership after renaming
# 		the original log file.
#
# 		For example, execute these commands as root:
#
# 			mv /var/log/mysqld log /var/log/mysqld.log.old
# 			install -omysql -gmysql -m0644 /dev/null /var/log/mysqld.log
#
# The following pertains to MySQL Server Components
#
# MySQL Server includes a component-based infrastructure for extending server capabilities.
# A component provides services that are available to the server and other components.
#
# (With respect to service use, the server is a component, equal to other components)
# Components interact with each other only through the services they provide.
#
# MySQL distributions include several components that implement server extensions:
#
# 		) Components for configuring error logging.
#
# 		) A component for checking PWs.
#
# SYS_VARs and STATUS_VARs implemented by a server component are exposed when the component is installed and have names that
# begin with a component-specific prefix.
#
# For example, the log_filter_dragnet error log filter component implements a SYS_VAR named log_error_filter_rules,
# the full name of which is dragnet.log_error_filter_rules.
#
# To refer to this var, use the full name.
#
# The following section describes how to install and uninstall components, and how to determine at runtime which components
# are installed and obtain information about them.
#
# For information about the internal implementation of components, it's covered later.
# For example, if you intend to write your own components, this information is important for understanding how components work.
#
# The following pertains to Installing and Uninstalling Components
#
# Server components must be loaded into the server before they can be used.
# MySQL supports component loading at runtime.
#
# The INSTALL_COMPONENT and UNINSTALL_COMPONENT SQL statements enable component loading and unloading.
# For example:
#
# 		INSTALL COMPONENT 'file://component_validate_password';
# 		UNINSTALL COMPONENT 'file://component_validate_password';
#
# A loader service handles component loading and unloading, and also lists loaded components in the <component> table of the
# <mysql> SYS_DB that serves as a registry.
#
# The SQL statements for component manipulation affect server operation and the mysql.component SYS_TABLE as follows:
#
# 		) INSTALL_COMPONENT loads components into the server.
# 		The components become active immediately.
#
# 		The loader service also registers loaded components in the mysql.component SYS_TABLE.
#
# 		For subsequent server restarts, the loader service loads any components listed in mysql.component during
# 		the startup sequence.
#
# 		This occurs even if the server is started with the --skip-grant-tables option.
#
# 		) UNINSTALL_COMPONENT deactivates components and unloads them from the server.
#
# 		The loader service also unregisters the components from the mysql.component SYS_TABLE
# 		so that they are no longer loaded during the startup sequence for subsequent server restarts.
#
# Compared to the corresponding INSTALL_PLUGIN statement for server plugins, the INSTALL_COMPONENT statement for components
# offers the significant advantage that it is not nessecary to know any platform-specific file name suffix for naming the component.
#
# This means that a given INSTALL_COMPONENT statement can be executed uniformly across platforms.
#
# The following pertains to Obtaining Server Component Information:
#
# The component table in the mysql system database contains information about currently loaded components and shows which
# components have been registered with INSTALL_COMPONENT.
#
# To see which components are installed, use:
#
# 		SELECT * FROM mysql.component;
#
# The following pertains to Error Log Components:
#
# This section describes the characteristics of individual error log components.
# 
# A log component can be a filter or a sink:
#
# 		) A filter processing log events, to add, remove or modify event fields, or to delete events entirely.
# 		  The resulting events pass to the next log component named in the log_error_services SYS_VAR.
#
# 		) A sink is a destination (writer) for log events. Typically, a sink processes log events into log messages
# 		  that have a particular format and writes these messages to its associated output, such as a file or the system log.
#
# The server executes filters and sinks in the log_error_services value in the order they are named.
# The rightmost component should therefore be a sink.
#
# If the rightmost component is a filter, any changes it has on events have no effect on output.
#
# The following sections describe individual log components, grouped by component type:
#
# 		Error Log Filter Components
#
# 		Error Log Sink Components
#
# Component descriptions include these types of information:
#
# 		) The component name and intended purpose.
#
# 		) Whether the component is built in or must be loaded.
#
# 		  For a loadable component, the description specifies the URN to use to load and unload the component with
# 		  the INSTALL_COMPONENT and UNINSTALL_COMPONENT statements.
#
# 		) Whether the component can be listed multiple times in the log_error_services value.
#
# 		) For a sink component, the destination to which the component writes output.
#
# Error Log Filter Components
#
# 		Error log filter components implement filtering of error log events:
#
# 			) If no filter component is enabled, no filtering occurs.
#
# 			) Any enabled filter component affects log events only for components listed later in the log_error_services value.
# 			  In particular, for any log sink component listed in log_error_services earlier than any filter component, no log event filtering occurs.
#
# The log_filter_internal Component
#
# 		) Purpose: Implements filtering based on the log_error_verbosity SYS_VAR.
#
# 		) URN: This component is built in and need not be loaded with INSTALL_COMPONENT before use.
#
# 		) Multiple uses permitted: No.
#
# 		Because log_error_verbosity affects the log_filter_internal component, log_error_verbosity has no effect on logging if
# 		log_filter_internal is not enabled.
#
# The log_filter_dragnet Component
#
# 		) Purposes: Implements filtering based on the rules defined by the dragnet.log_error_filter_rules SYS_VAR.
# 		
# 		) URN: file://component_log_filter_dragnet
#
# 		) Multiple uses permitted: No.
#
# Error Log Sink Components
#
# Error log sink components are writers that implement error log output. If no sink component is enabled, no log output occurs.
#
# Some sink component descriptions refer to the default error log destination.
# This is the console or a file and is indicated by the fault of the log_error SYS_VAR.
#
# The log_sink_internal Component
#
# 		) Purpose: Implements traditional error log message output format.
#
# 		) URN: This component is built in and need not be loaded with INSTALL_COMPONENT before use.
#
# 		) Multiple uses permitted: No.
#
# 		) Output destination: Writes to the default error log destination.
#
# The log_sink_json Component
#
# 		) Purpose: Implements JSON-format error logging.
#
# 		) URN: file://component_log_sink_json
#
# 		) Multiple uses permitted: Yes.
#
# 		) Output destination: The JSON log writer determines its output destination based on the default error log destination,
# 									 which is given by the log_error SYS_VAR:
#
# 									 		) If log_error names a file, the JSON writer bases output file naming on that file name, plus a numbered .<NN> json suffix,
# 											  with NN starting at 00.
#
# 											  For example, if log_error is <file_name>, successive instances of log_sink_json named in the log_error_services
# 											  value write to <file_name>.00.json, <file_name>.01.json and so forth.
#
# 											) If log_error is stderr, the JSON writer writes to the console.
#
# 											  If log_json_writer is named multiple times in the log_error_services value, they all write
# 											  to the console, which is likely not useful.
#
# The log_sink_syseventlog Component:
#
# 		) Purpose: Implements error logging to the system log. This is the Event Log on Windows, and syslog on Unix and Unix-like systems.
#
# 		) URN: file://component_log_sink_syseventlog
#
# 		) Multiple uses permitted: No.
#
# 		) Output destination: Writes to the system log. Does not use the default error log destination.
#
# The log_sink_test Component:
#
# 		) Purposes: intended for internal use in writing test cases. Not intended for production use.
#
# 		) URN: file://component_log_sink_test
#
# 		) Multiple uses permitted: Yes.
#
# 		) Output destination: Writes to the default error log destination.
#
# The following pertains to MySQL Server Plugins:
#
# MySQL supports a plugin API that enables creation of server components.
#
# PLugins can be loaded at server startup, or loaded and unloaded at runtime without restarting the server.
#
# The components supported by this interface include, but are not limited to, storage engines, INFORMATION_SCHEMA tables,
# full-text parser plugins and server extensions.
#
# MySQL distributions include several plugins that implement server extensions:
#
# 		) Plugins for authenticating attempts by clients to connect to MySQL Server.
# 		  Plugins are available for several authentication protocols.
#
# 		) A connection-control plugin that enables administrators to introduce an increasing delay after a certain number of consecutive
# 		  failed client connection attempts.
#
# 		) A password-validation plugin implements password strength policies and assesses the strength of potentional PWs.
#
# 		) Semisynch replication plugins implement an interface to replication capabilities that permit the master to proceed
# 		  as long as at least one slave has responded to each transaction.
#
# 		) Group Replication enables you to create a highly available distributed MySQL service across a group of MySQL server instances,
# 		  with data consistency, conflict detection and resolution, and group membership services - are all built-in.
#
# 		) MySQL Enterprise Edition includes a thread pool plugin that manages connection threads to increase server performance by
# 		  effectively managing statement execution threads for large numbers of client connections.
#
# 		) MySQL Enterprise Edition includes an audit plugin for monitoring and logging of connection and query activity.
#
# 		) MySQL Enterprise Edition includes a firewall plugin that implements an application-level firewall to enable DB admin to permit
# 		  or deny SQL statement execution based on matching against whitelists of accepted statement patterns.
#
# 		) A query rewrite plugin examines statements received by MySQL Server and possibly rewrites them before the server executes them.
#
# 		) Version Tokens enable creation of and Synching around server tokens that applications can use to prevent accessing incorrect or
# 		  out-of-date data.
#
# 		  Version Tokens is based on a plugin lib that implements a version_tokens plugin and a set of user-defined functions.
#
# 		) Keyring plugins provide secure storage for sensitive info.
#
# 		) X Plugin extends MySQL server to be able to function as a document store.
#
# 		  Running X Plugin enables MySQL Server to communicate with clients using the X protocol, which is designed 
# 		  to expose the ACID compliant storage abilities of MySQL as a document store.
#
# 		) Test framework plugins test server services. 
#
# The following section pertains to installation and uninstallation of plugins, and how to determine at runtime which plugins
# are installed and obtain information about them.
#
# More info about writing them later.
#
# The following section pertains to Installing and Uninstalling Plugins:
#
# Server plugins must be loaded into the server before they can be used.
# MySQL supports plugin loading at server startup and runtime.
#
# It is also possible to control the activation state of loaded plugins at startup, and to unload them at runtime.
#
# While a plugin is loaded, information about it is available from the INFORMATION_SCHEMA.PLUGINS table and the SHOW_PLUGINS statement.
#
# INSTALLING PLUGINS:
#
# Before a server plugin can be used, it must be installed using one of the following methods.
#
# In the desc., <plugin_name> stands for a plugin name such as innodb, csv or validate_password.
#
# Built-in plugins:
#
# 		A built-in plugin is known by the server automatically. Normally, the server enables the plugin at startup.
# 		Some built-in plugins permits this to be changed with the --plugin_name[=<activation_state>] option.
#
# Plugins registered in the mysql.plugin system table:
#
# 		The plugin table in the mysql system database serves as a registry of plugins (other than built-in plugins, which need not be registered).
#
# 		At startup, the server loads each plugin listed in the table. Normally, for a plugin loaded from the mysql.plugin table,
# 		the server also enables the plugin.
#
# 		This can be changed with the --plugin_name[=<activation_state>] option.
#
# 		If the server is started with the --skip-grant-tables option, it does not consult the mysql.plugin table and does not
# 		load the plugins listed there.
#
# Plugins named with command-line options:
#
# 		A plugin located in a plugin library file can be loaded at server startup with the --plugin-load, --plugin-load-add,
# 		or --early-plugin-load option.
#
# 		Normally, for a plugin loaded at startup, teh server also enables the plugin. This can be changed with the --<plugin_name>[=<activation_state>] option.
#
# 		The --plugin-load and --plugin-load-add options load plugins after built-in plugins and storage engines have initialized during the
# 		server startup sequence.
#
# 		The --early-plugin-load option is used to load plugins that must be available prior to initialization of built-in plugins and storage engines.
#
# 		The value of each plugin-loading option is a semicolon-separated list of <name>=<plugin_library> and <plugin_library> values.
#
# 		Each <name> is the name of a plugin to load, and <plugin_library> is the name of the library file that contains the plugin code.
# 		If a plugin library is named without any preceding plugin name, the server loads all plugins in the library.
#
# 		The server looks for plugin library files in the directory named by the plugin_dir SYS_VAR.
#
# 		Plugin-loading options do not register any plugin in the mysql.plugin table.
#
# 		For subsequent restarts, the server loads the plugin again only if --plugin-load, --plugin-load-add, or --early-plugin-load is given again.
# 		 		 		
# 		I.e, it produces a one-time plugin-installation operation that persists for a single server invocation.
#
# 		--plugin-load, --plugin-load-add, and --early-plugin-load enable plugins to be loaded even when --skip-grant-tables is given
# 		(which causes the server to ignore the mysql.plugin table)
#
# 		--plugin-load, --plugin-load-add and --early-plugin-load also enables plugins to be loaded at startup that cannot be loaded at runtime.
# 		
# 		The --plugin-load-add option complements the --plugin-load option:
#
# 			) Each instance of --plugin-load resets the set of plugins to load at startup, whereas --plugin-load-add adds a plugin or plugins to the set
# 			of plugins to be loaded without resetting the current set.
#
# 			Consequently, if multiple instances of --plugin-load are specified, onl the last one takes effect.
# 			With multiple instances of --plugin-load-add, all of them take effect.
#
# 			) The argument format is the same as for --plugin-load, but multiple instances of --plugin-load-add can be used to avoid specifying
# 			a large set of plugins as a single long unwieldy --plugin-load argument.
#
# 			) --plugin-load-add can be given in the absence of --plugin-load, but any instance of --plugin-load-add that appears before --plugin-load
# 			has no effect because --plugin-load resets the set of plugins to load.
#
# For example, these options:
#
# 		--plugin-load=x --plugin-load-add=y is equivalent to --plugin-load="x;y"
#
# But:
#
# 		--plugin-load-add=y --plugin-load=x is equal to --plugin-load=x (due to ordering)
#
# The following pertains to Plugins installed with the INSTALL_PLUGIN statement:
#
#		A plugin located in a plugin library file can be loaded at runtime with the INSTALL_PLUGIN statement.
#
# 		The statement also registers the plugin in the mysql.plugin table to cause the server to load it on 
# 		on subsequent restarts. For this reason, INSTALL_PLUGIN requires the INSERT privs for the mysql.plugin table.
#
# 		The plugin library file base name depends on your platform. Common suffixes are .so (Unix/Unix-based systems), .dll for Windows
#
# 		Example: The --plugin-load option installs a plugin at server startup. To install a plugin named myplugin from a plugin library file
# 					named somepluglib.so, use these lines in a my.cnf file:
#
# 					[mysqld]
# 					plugin-load=myplugin=somepluglib.so
#
# 		In this case, the plugin is not registered in mysql.plugin. Restarting the server without the --plugin-load option causes the plugin not to be loaded at startup.
#
# 		Alternatively, the INSTALL_PLUGIN statement causes the server to lodd the plugin code from the library file at runtime:
#
# 			INSTALL PLUGIN myplugin SONAME 'somepluglib.so';
#
# 		INSTALL_PLUGIN also causes "permanent" plugin registration: The plugin is listed in the mysql.plugin table to ensure that the
# 		server loads it on subsequent restarts.
#
# 		Many plugins can be loaded either at server startup or at runtime. However, if a plugin is designed such that it must be loaded
# 		and initialized during server startup, attempts to load it at runtime using INSTALL_PLUGIN produces an error:
#
# 			INSTALL PLUGIN myplugin SONAME 'somepluglib.so';
# 			ERROR 1721 (HY000): Plugin 'myplugin' is marked as not dynamically
# 			installable. You have to stop the server to install it.
#
# 		In this case, you must use --plugin-load, --plugin-load-add or --early-plugin-load.
#
# 		If a plugin is named both using a --plugin-load, --plugin-load-add or --early-plugin-load option
# 		(as a result of an earlier INSTALL_PLUGIN statement) in the mysql.plugin table, the server starts but
# 		writes these mesages to the error log:
#
# 			[ERROR] Function 'plugin_name' already exists
# 			[Warning] Couldn't load plugin named 'plugin_name' with soname 'plugin_object_file'
#
# Controlling Plugin Activation State:
#
# 		If the server knows about a plugin when it starts (for example, because the plugin is named using a --plugin-load option or is registered
# 		in the mysql.plugin table), the server loads and enables the plugin by default.
#
# 		It is possible to control activation state for such a plugin using a --<plugin_name>[=<activation_state>] startup option,
# 		where <plugin_name> is the name of the plugin to affect, such as innodb, csv or validate_password.
#
# 		As with other options, dashes and underscores are interchangable in option names.
# 		Also, activation state values are not case-sensitive.
#
# 		For example, --my_plugin=ON and --my-plugin=on are equivalent.
#
# 			--<plug_name>=OFF - Tells the server to disable the plugin. This may not be possible for certain built-in plugins, such as mysql_native_password.
#
# 			--<plugin_name>[=ON] - tells the server to enable the plugin. (Specifying the option as --<plugin_name> without a value has the same effect.)
# 										  If the plugin fails to initialize, the server runs with the plugin disabled.
#
# 			--<plugin_name>=FORCE - Tells the server to enable the plugin, but if plugin initialization fails, the server does not start.
# 											In other words, this option forces the server to run with the plugin enabled or not at all.
#
# 			--<plugin_name>=FORCE_PLUS_PERMANENT - Like FORCE, but in addition prevents the plugin from being unloaded at runtime.
# 																If a user attempts to do so with UNINSTALL_PLUGIN, an error occurs.
#
# 		PLugin activation states are visible in the LOAD_OPTION column of the INFORMATION_SCHEMA.PLUGINS table.
#
# 		Suppose that CSV, BLACKHOLE and ARCHIVE are built-in pluggable storage engines and that you want the server to load them at startup,
# 		subject to these conditions:
#
# 			) The server is permitted to run if CSV initialization fails 
# 			) must require that BLACKHOLE initialization succeeds 
# 			) should disable ARCHIVE.
# 			
# 			To accomplish that, use these lines in an option file:
#
# 				[mysqld]
# 				csv=ON
# 				blackhole=FORCE
# 				archive=OFF
#
# 			The --enable-<plugin_name> option format is a synonym for --<plugin_name>=ON.
# 			The --disable-<plugin_name> and --skip-<plugin_name> option formats are synonyms for --<plugin_name>=OFF
#
# 			If a plugin is disabled, either explicitly with OFF or implicitly because it was enabled with ON but failed to initialize,
# 			aspects of server operation that require the plugin will change.
#
# 			For example, if the plugin implements a storage engine, existing tables for the storage engine becomes inaccessible,
# 			and attempts to create new tables for the storage engine result in tables that use the default storage engine unless
# 			the NO_ENGINE_SUBSTITUTION SQL mode is enabled to cause an error to occur instead.
#
# 			Disabling a plugin may require adjustment to other options.
#
# 			For example, if you start the server using --skip-innodb to disable InnoDB, other innodb_<xxx> options likely
# 			will need to be omitted at startup.
#
# 			In addition, because InnoDB is the default storage engine - it will not start unless you specify another available storage
# 			engine with --default_storage_engine.
#
# 			You must also set --default_tmp_storage_engine.
#
# UNINSTALLING PLUGINS
#
# 		At runtime, the UNINSTALL PLUGIN statement disables and uninstalls a plugin known to the server.
#
# 		The statement unloads the plugin and removes it from the mysql.plugin system table, if it is registered there.
# 		
# 		For this reason, UNINSTALL_PLUGIN statements require the DELETE privs for the mysql.plugin table.
# 		With the plugin no longer registered in the table, the server does not load the plugin automatically for subsequent restarts.
#
# 		UNINSTALL_PLUGIN can load a plugin regardless of whether it was loaded at runtime with INSTALL_PLUGIN or at startup with a 
# 		plugin-loading option, subject to these conditions:
#
# 			) It cannot unload plugins that are built in to the server. These can be identified as those that have a library name of NULL in the output
# 			  from INFORMATION_SCHEMA.PLUGINS or SHOW_PLUGINS.
#
# 			) It cannot unload plugins for which the server was started with --<plugin_name>=FORCE_PLUS_PERMANENT, which prevents plugin unloading at runtime.
# 			  These can be identified from the LOAD_OPTION column of the INFORMATION_SCHEMA.PLUGINS table.
#
# 		To uninstall a plugin that currently is loaded at server startup with a plugin-loading option, use this procedure:
#
# 			1. Remove any options related to the plugin from the my.cnf file.
#
# 			2. Restart the server.
#
# 			3. Plugins normally are installed using either a plugin-loading option at startup or with INSTALL_PLUGIN at runtime,
# 				but not both.
#
# 				However, removing options fora plugin from the my.cnf file may not be sufficient to uninstall it if at some point,
# 				INSTALL_PLUGIN has also been used.
#
# 				If the plugin still appears in the output from INFORMATION_SCHEMA.PLUGINS or SHOW_PLUGINS,
# 				use UNINSTALL_PLUGIN to remove it from the mysql.plugin table.
#
# 				Then restart the server again.
#
# The following pertains to Obtaining Server PLugin Information:
#
# There are several ways to determine which plugins are installed in the server:
#
# 		) The INFORMATION_SCHEMA.PLUGINS table contains a row for each loaded plugin. 
#
# 		  Any that have a PLUGIN_LIBRARY value of NULL are built in and cannot be unloaded.
#
# 		  		SELECT * FROM INFORMATION_SCHEMA PLUGINS\G
# 				**************************** 1. row ****************************
# 									PLUGIN_NAME: binlog
# 								PLUGIN_VERSION: 1.0
# 								PLUGIN_STATUS:  ACTIVE
# 									PLUGIN_TYPE: STORAGE ENGINE
# 						 PLUGIN_TYPE_VERSION: 50158.0
# 								PLUGIN_LIBRARY: NULL
# 					 PLUGIN_LIBRARY_VERSION: NULL
# 					 			 PLUGIN_AUTHOR: MySQL AB
# 						  PLUGIN_DESCRIPTION: This is a pseudo storage engine to represent the binlog in a transaction
# 						  	   PLUGIN_LICENSE: GPL
# 									LOAD_OPTION: FORCE
# 				...
# 				*************************** 10. row ******************************
# 									PLUGIN_NAME: InnoDB
# 								PLUGIN_VERSION: 1.0
# 								 PLUGIN_STATUS: ACTIVE
# 								 	PLUGIN_TYPE: STORAGE ENGINE
# 						 PLUGIN_TYPE_VERSION: 50158.0
# 						      PLUGIN_LIBRARY: ha_innodb_plugin.so
# 					 PLUGIN_LIBRARY_VERSION: 1.0
# 								 PLUGIN_AUTHOR: Innobase Oy
# 						  PLUGIN_DESCRIPTION: Supports transactions, row-level locking, and foreign keys
# 								PLUGIN_LICENSE: GPL
# 									LOAD_OPTION: ON
# ...
#
# 		) The SHOW_PLUGINS statement displays a row for each loaded plugin. Any that have a Library value of NULL are built in and cannot be unloaded.
#
# 				SHOW PLUGINS\G
# 				***************************** 1. row ********************************
# 
# 					Name: binlog
# 				 Status: ACTIVE
# 				   Type: STORAGE ENGINE
#  			Library: NULL
# 				License: GPL
# 				...
# 				****************************** 10. row *******************************
#
# 					Name: InnoDB
# 				 Status: ACTIVE
# 				 	Type: STORAGE ENGINE
# 				Library: ha_innodb_plugin.so
# 				License: GPL
# 				...
#
# 		) The mysql.plugin table shows which plugins have been registered with INSTALL_PLUGIN.
#
# 		  The table contains only plugin names and library file names, so it does not provide as much information as the
# 		  PLUGIN table or the SHOW_PLUGINS statement.
#
# The following section pertains to MySQL Enterprise Thread Pool
#
# NOTE: MySQL Enterprise Thread Pool is an extension included in MySQL Enterprise Edition, a commercial product.
#
# MySQL Enterprise Edition includes MySQL Enterprise Thread Pool, implemented using a server plugin.
# The default thread-handling model in MySQL Server executes statements using one thread per client connection.
#
# As more clients connect to the server and execute statements, overall performance decreases.
#
# The thread pool plugin provides an alternative thread-handling model designed to reduce overhead and improve performance.
#
# The plugin implements a thread pool that increases server performance by efficiently managing statement execution
# threads for large numbers of client connections.
#
# The thread pool addresses several problems of the model that uses one thread per connection:
#
# 		) Too many thread stacks make CPU caches almost useless in highly parallel execution workloads.
#
# 		  The thread pool promotes thread stack reuse to minimize the CPU cache footprint.
#
# 		) With too many threads executing in parallel, context switching overhead is high.
#
# 		  This also presents a challenging task to the OS system scheduler. 
#
# 		  The thread pool controls the number of active threads to keep the parallelism within the MySQL server at a level that it can handle
# 		  and that is appropiate for the server host on which MySQL is executing.
#
# 		) Too many transactions executing in parallel increases resource contention. In InnoDB, this increases the time
# 		  spent holding central mutexes.
#
# 		  The thread pool controls when transactions start to ensure that not too many execute in parallel.
#
# The following pertains to the Thread Pool Components:
#
# The thread pool features comprises these components:
#
# 		) A plugin library file implements a plugin for the thread pool code as well as several associated monitoring tables that provide info about thread pool ops:
#
# 			) As of MySQL 8.0.14, the monitoring tables are Performance Schema Tables
#
# 			)	< 8.0.14, the monitoring tables are INFORMATION_SCHEMA tables.
#
# 			 	The INFORMATION_SCHEMA tables now are deprecated.
#
# 				To transition old tables to new tables, this is pertinent:
#
# 					 SELECT * FROM INFORMATION_SCHEMA.TP_THREAD_STATE;
#
# 				The application should use this query instead:
#
# 					SELECT * FROM performance_schema.tp_thread_state;
#
# 		NOTE: If you do not load all the monitoring tables, some or all MySQL Enterprise Monitor thread pool graphs will be empty.
#
# 		) Several SYS_VARs are related to the thread pool. The thread_handling SYS_VAR has a value of loaded-dynamically when the server
# 		  successfully loads the thread pool plugin.
#
# 		  The other related VARs are implemented by the thread pool plugin; they are not available unless it is enabled:
#
# 				) thread_pool_algorithm: The concurrency algorithm to use for scheduling
#
# 				) thread_pool_high_priority_connection: How to shcedule statement execution for a session
#
# 				) thread_pool_prio_kickup_timer: How long before the thread pool moves a statement awaiting execution from the low-prio queue to high-prio queue.
#
# 				) thread_pool_max_unused_threads: How many sleeping threads to permit.
#
# 				) thread_pool_size: The number of thread groups in the thread pool. This is the most improtant param controlling thread pool performance.
#
# 				) thread_pool_stall_limit: The time before an executing statement is considered to be stalled.
#
# 			If any variable implemented by the plugin is set to an illegal value at startup, plugin initialization fails and the plugin does not load.
#
# 		) The Performance Schema has instruments that expose information about the thread pool and may be used to investiage operational performance.
# 		  
# 		  SELECT * FROM performance_schema.setup_instruments WHERE NAME LIKE '%thread_pool%';
#
# The following section pertains to Thread Pool Installation:
#
# 		This section describes how to install MySQL Enterprise Thread Pool.
# 
# 		To be usable by the server, the plugin library file must be located in the MySQL plugin directory (the directory named by the plugin_dir SYS_VAR).
# 		If necessary - configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# 		The plugin library file base name is thread_pool. The file name suffix differs per platform (for example, .so on UNIX based systems, .dll for Windows)
#
# THREAD POOL INSTALLATION >= MySQL 8.0.14
#
# 		In MySQL 8.0.14 and higher, the thread pool monitoring tables are Performance Schema tables that are loaded and unloaded along with
# 		the thread pool plugin.
#
# 		The INFORMATION_SCHEMA versions of the tables are deprecated but still there. Those are installed per < 8.0.14
#
# 		To enable thread pool capability, load the plugin by starting the server with the --plugin-load-add option.
#
# 		To do this, put these lines in the server my.cnf file (adjust the .so suffix for your platform if needed):
#
# 			[mysqld]
# 			plugin-load-add=thread_pool.so
#
# 		To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
# 		For instance:
#
# 			SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'thread%';
# 			+---------------+---------------+
# 			| PLUGIN_NAME 	 | PLUGIN_STATUS |
# 			+---------------+---------------+
# 			| thread_pool 	 | ACTIVE 		  |
# 			+---------------+---------------+
#
# 		To verify that the Performance Schema monitoring tables are available, examine the INFORMATION_SCHEMA.TABLES table or use
# 		the SHOW_TABLES statement.
#
# 		For example:
#
# 			SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'performance_schema' AND TABLE_NAME LIKE 'tp%';
# 			+-------------------------+
# 			| TABLE_NAME 				  |
# 			+-------------------------+
# 			| tp_thread_group_state   |
# 			| tp_thread_group_stats   |
# 			| tp_thread_state 		  |
# 			+-------------------------+
#
# If the server loads the thread pool plugin successfully, it sets the thread_handling SYS_VAR to loaded-dynamically.
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# THREAD POOL INSTALLATION PRIOR TO MySQL 8.0.14
#
# < 8.0.14, the thread pool monitoring tables are plugins separate from the thread pool plugin and can be installed separately.
#
# To enable thread pool capability, load the plugins to be used by starting the server with the --plugin-load-add option.
# To do this, put these lines in the server my.cnf (adjust the .so suffix for your platformas necessary):
#
# 		[mysqld]
# 		plugin-load-add=thread_pool.so
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'thread%';
# +---------------------------------------+
# | PLUGIN_NAME 		| PLUGIN_STATUS 		|
# +------------------+--------------------+
# | thread_pool 	 	| ACTIVE 				|
# +------------------+--------------------+
#
# To verify that the Performance Schema monitoring table are available, examine the INFORMATION_SCHEMA.TABLES or use the 
# SHOW_TABLES statement.
#
# For example:
#
# SELECT TABLE_NAME FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_SCHEMA = 'performance_schema' AND TABLE_NAME LIKE 'tp%';
#
# +------------------------------------------+
# | TABLE_NAME 										|
# +------------------------------------------+
# | tp_thread_group_state 							|
# | tp_thread_group_stats 							|
# | tp_thread_state 									|
# +------------------------------------------+
#
# If the server loads the thread pool plugin successfully, it sets the thread_handling SYS_VAR to loaded-dynamically.
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# THREAD POOL INSTALLATION PRIOR TO 8.0.14
#
# Before 8.0.14 - the thread pool monitoring tables are plugins separate from the thread pool plugin and can be installed
# separetely.
#
# To enable thread pool capability, load the plugins to be used by starting the server with the --plugin-load-add option.
#
# For example, if you name only hte plugin library file, the server loads all plugins that it contains (that is, the thread pool
# plugin and all the INFORMATION_SCHEMA tables).
#
# To do this, put these lines in the server my.cnf file (adjust the .so suffix for your platform as necessary):
#
# [mysqld]
# plugin-load-add=thread_pool.so
#
# That is equivalent to loading all thread pool plugins by manually naming them individually:
#
# [mysqld]
# plugin-load-add=thread_pool=thread_pool.so
# plugin-load-add=tp_thread_state=thread_pool.so
# plugin-load-add=tp_thread_group_state=thread_pool.so
# plugin-load-add=tp_thread_group_stast=thread_pool.so
#
# If desired, you can load individual plugins from the library file. To load the thread pool plugin but not the INFORMAITON_SCHEMA tables,
# use an option as this:
#
# [mysqld]
# plugin-load-add=thread_pool=thread_pool.so
#
# To load the thread pool plugin and only the TP_THREAD_STATE INFORMATION_SCHEMA table, use options like this:
#
# [mysqld]
# plugin-load-add=thread_pool=thread_pool.so
# plugin-load-add=tp_thread_state=thread_pool.so
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'thread%' OR PLUGIN_NAME LIKE 'tp%';
#
# +------------------------------------------------------------+
# | PLUGIN_NAME 							| 		PLUGIN_STATUS 			|
# +---------------------------------+--------------------------+
# | thread_pool 							| ACTIVE 						|
# | TP_THREAD_STATE 						| ACTIVE 						|
# | TP_THREAD_GROUP_STATE 				| ACTIVE 						|
# | TP_THREAD_GROUP_STATS 				| ACTIVE 						|
# +---------------------------------+--------------------------+
#
# If the server loads the thread pool plugin successfully, it sets the thread_handling SYS_VAR to loaded-dynamically.
#
# If a plugin fails to initialize, check the server error log for diagnostic messages.
#
# The following pertains to THREAD POOL OPERATION:
#
# The thread pool consists of a number of thread groups, each of which manages a set of client connections.
# As connections are established, the thread pool assigns them to thread groups in round-robin fashion.
#
# The number of thread groups is configurable using the thread_pool_size SYS_VAR.
# The default number of groups is 16.
#
# The max number of threads per group is 4096 (or 4096 on systems where one thread is used interally)
#
# The thread pool separates connections and threads, so there is no fixed relationship between connections and the
# threads that execute statements received from those connections.
#
# This differs from the default thread-handling model that associates one thread with one connection such that the
# thread executes all statements from the connection.
#
# The thread pool tries to ensure a maximum of one thread executing in each group at any time, but sometimes permits more
# threads to execute temporarily for best performance.
#
# The algorithm works in the following manner:
#
# 		) Each thread group has a listener thread that listens for incoming statements from the connections assigned to the group.
#
# 	 	  When a statement arrives, the thread group either begins executing it immediately or queues it for later execution:
#
# 				) Immediate execution occurs if the statement is the only one received and no statements are queued or currently executing.
#
# 				) Queueing occurs if the statement cannot begin executing immediately.
#
# 		) If immediate execution occurs, execution is performed by the listener thread.
#
# 		  (This means that temporarily no thread in the groups is listening.)
# 			
# 			If the statement finishes quickly, the executing thread returns to listening for statements.
#
# 			Otherwise, the thread pool considers the statement stalled and starts another thread as a listener thread
# 			(creating it if necessary).
#
# 			To ensure that no thread group becomes blocked by stalled statements, the thread pool has a background thread
# 			that regularly monitors thread group states.
#
# 			By using the listening thread to execute a statement that can begin immediately, there is no need to create 
# 			an additional thread if the statement finishes quickly.
#
# 			This ensures the most efficient execution possible in the case of a lower number of concurrent threads.
#
# 			When the thread pool plugin starts, it creates one thread per group (the listener thread), plus the background thread.
# 			Additional threads are created as necessary to execute statements.
#
# 		) The value of the thread_pool_stall_limit SYS_VAR determines the meaning of "finishes quickly" in the above points.
#
# 		  The default time before threads are considered stalled is 60ms but can be set to a maximum of 6s.
#
# 			This param is configurable to enable you to strike a balance appropiate for the server work load.
#
# 			Short wait values permited threads to start more quickly.
#
# 			Short values are also better for avoiding deadlock situations. Long wait time values are useful for workloads that
# 			include long-running statements, to avoid starting too many new statements while the current one is executing.
#
# 		) The thread pool focuses on limiting the number of concurrent short-running statements.
#
# 			Before an executing statement reaches the stall time, it prevents other statements from beginning to execution.
#
# 			If the statement executes past the stall time, it is permitted to continue but no longer prevents other statements
# 			from starting.
#
# 			In this way, the thread pool tries to ensure that in each thread group there is never more than one short-running statement,
# 			although, there might be multiple long-running statements.
#
# 			It is undesirable to let long-running statements prevent other statements from executing because there is no limit on the amount
# 			of waiting that might be necessary.
#
# 			For example, on a replication master, a thread that is sending binary log events to a slave effectively runs forever.
#
# 		) A statement becomes blocked if it encounters a disk I/O operation or a user level lock (row lock or table lock).
#
# 		  The block would cause the thread group to become unused, so there are callbacks to the thread pool to ensure that
# 			the thread pool can immediately start a new thread in this group to execute another statement.
#
# 			When a blocked thread returns, the thread pool permits it to restart immediately.
#
# 		) There are two queues, a high prio queue and a low prio queue.
#
# 			The first statement in a transaction goes to the low-prio queue. 
#
# 			Any following statements for the transaction go to the high prio queue if the transaction is ongoing
# 			(statements for it have begun executing), or to the low-priority queue otherwise.
#
# 			Queue assignment can be affected by enabling the thread_pool_high_priority_connection SYS_VAR,
# 			which causes all queued statements for a session to go into the high prio queue.
#
# 			Statements for a nontransactional storage engine, or a transactional engine if autocommit is enabled,
# 			are treated as low-prio statements because in this case each statement is a transaction.
#
# 			Thus, given a mix of statements for InnoDB and MyISAM tables, the thread pool prios those for InnoDB
# 			over those for MyISAM unless autocommit is enabled.
#
# 			With autocommit enabled, all statements will be low prio.
#
# 		) When the thread group selects a queued statement for execution, it first looks in the high-priority queue, then in the
# 		  low prio queue.
#
# 			If a statement is found, it is removed from its queue and begins to execute.
#
# 		) If a statement stays in the low prio queue for too long, the thread pool moves it to the high prio queue.
#
# 			The value of the thread_pool_prio_kickup_timer SYS_VAR controls the time before movement.
#
# 			For each thread group, a max of one statement per 10ms or 100 per second will be moved from the low prio queue
# 			to the high prio queue.
#
# 		) The thread pool reuses the most active threads to obtain a much better use of CPU caches. This is a small adjustment that
# 			has a great impact on performance.
#
# 		) While a thread executes a statement from a user connection, Performance Schema instrumentation accounts thread activity
# 		  to the user connection.
#
# 			Otherwise, Performance Schema accounts actvitiy to the thread pool.
#
# Here are examples of conditions under which a thread group might have multiple threads started to execute statements:
#
# 		) One thread begins executing a statement, but runs long enough to be considered stalled.
#
# 		The thread group permits another thread to begin executing another statement even though the first thread is doing it's job.
#
# 		) One thread begins executing a statement, then becomes blocked and reports this back to the thread pool.
#
# 			The thread group permits another thread to begin executing another statement.
#
# 		) One thread begins executing a statement, becomes blocked, but does not report back that it is blocked because the
# 		  block does not occur in code that has been instrumented with thread pool callbacks.
#
# 			In this case, teh thread appears to the thread group to be still running.
#
# 			If the block lasts long enough for the statement to be considered stalled, the group permits another thread to begin
# 			executing another statement.
#
# The thread pool is designed to be scalable across an increasing number of connections. It is also designed to avoid
# deadlocks that can arise from limiting the number of actively executing statements.
#
# It is important that threads that do not report back to the thread pool do not prevent other statements from executing
# and thus causes the thread pool to become deadlocked.
#
# Examples of such statements are:
#
# 		) Long running statements. These would lead to all resources only used by a few statements, and they could prevent all others from accessing the server.
#
# 		) Binary log dump threads that read the binary log and sends it to slaves.
#
# 			This is a kind of long running "statement" (i.e, constantly) that runs for a very long time, and should not prevent other statements from executing.
#
# 		) Statements blocked on a row lock, table lock, sleep or any other blocking acvitiy that has not been reported back to the thread pool by MySQL
# 			Server or a storage engine.
#
# In each case, to prevent deadlock, the statement is moved to the stalled category when it does not complete quickly,
# so that the thread group can permit another statement to begin executing.
#
# With this design, when a thread executes or becomes blocked for an extended time, the thread pool moves the thread to the stalled category
# and for the rest of the statements execution,, it does not prevent other statements from executing.
#
# The max number of threads that can occur is the sum of max_connections and thread_pool_size.
#
# This can happen in a situation where all connections are in execution mode and an extra thread is created per group
# to listen for more statements.
#
# It can happen, albeit not very feasible.
#
# The following pertains to Thread Pool Tuning:
#
# This section provides guidelines on setting thread pool system variables for best performance, measured using a metric such as trans/sec.
#
# thread_pool_size is the most important parameter controlling thread pool performance.
# It cna be set only at server startup.
#
# Our experience in testing the thread pool indicates the following:
#
# 	) If the primary storage engine is InnoDB, the optimal thread_pool_size setting is likely between 16 and 36, with the most common
# 	  optimal values leaning towards 26 - 36. We have not seen any situation where the setting has been optiomal beyond 36.
#
# 	  There may be special cases where  avalue of smaller than 16 is optimal.
#
# 		For workloads such as DBT2 and Sysbench, the optimum for InnoDB seems to be usually around 36.
#
# 		For very write-intensive workloads, the optimal setting can sometimes be lower.
#
# 	) If the primary storage engine is MyISAM the thread_pool_Size setting should be fairly low.
#
# 		We tend to get optimal performance for values from 4 to 8.
#
# 		Higher values tend to have slightly negative but not dramatic impact on performance.
#
# Another SYS_VAR, thread_pool_stall_limit, is important for handling of blocked and long-running statements.
#
# If all calls that block the MySQL Server are reported to the thread pool, it would always know when execution
# threads are blocked.
#
# However, this may not always be true. For example, blocks could occur in code that has not been instrumented with
# thread pool callbacks.
#
# For such cases, the thread pool must be able to identify threads that appear to be blocked.
#
# This is done by means of a timeout, the length of which can be tuned using the thread_pool_stall_limit SYS_VAR.
#
# This parameter ensures that the server does not become completely blocked.
#
# The v alue of thread_pool_stall_limit has an upper limit of 6 seconds to prevent the risk of deadlock servers.
#
# thread_pool_stall_limit also enables the thread pool to handle long-running statements.
#
# If a long-running statement was permitted to block a thread group, all other connections assigned
# to the group would be blocked and unable to start execution until the long-running statements were completed.
#
# In the worst case, this could take hours or even days.
#
# The value of thread_pool_stall_limit should be chosen such that statements that execute longer than its value are
# considered stalled.
#
# Stalled statements generate a lot of extra overhead since they involve extra context switches and in some cases even
# extra thread creations.
#
# On the other hand, setting the thread_pool_stall_limit param too high means that long-running statements will block
# a number of short-running statements for longer than necessary.
#
# Short wait values permit threads to start more quickly.
#
# Short values are also better for avoiding deadlock situations. 
#
# Long wait values are useful for workloads that include long-running statements, to avoid starting
# too many new statements while the current one executes.
#
# Suppose a server executes a workload where almost all statements complete within 100ms even when the server is loaded,
# and the remaining statements take between 100ms and 2 hours fairly evenly spread.
#
# In this case, it would make sense to set thread_pool_stall_limit to 10 (meaning 100ms).
# The default value of 60ms is okay for servers that primarily execute very simple statements.
#
# The thread_pool_stall_limit PARAM can be changed at runtime to enable you to strike a balance appropiate for the
# server work load.
#
# Assuming that the tp_thread_group_stats table is enabled, you can use the following query to determine the fraction
# of executed statements that stalled:
#
# SELECT SUM(STALLED_QUERIES_EXECUTED) / SUM(QUERIES_EXECUTED) FROM performance_schema.tp_thread_group_stats;
#
# This number should be as low as possible. To decrease the likelihood of statements stalling, increase the value of
# thread_pool_stall_limit. 
#
# When a statement arrives, what is the max value time it can be delayed before it actually starts executing?
#
# Assume:
#
# ) htere are 200 statements queued in the low prio
#
# ) There are 10 statements queued in the high prio queue
#
# ) thread_pool_prio_kickup_timer is set to 10K (10 sec)
#
# ) thread_pool_stall_limit is set to 100 (1 sec)
#
# In the worst case, the 10 high prio statements present 10 tranactions that continue executing for a long time.
#
# Thus, worst case, no statements will be moved to high prio - because it's always awaiting an execution of a statement.
#
# After 10 seconds, the new statement is eligible to be moved to high prio.
#
# However, before it can move - all statements before it must be moved as well.
#
# This could take anotehr 2 sec because a max of 100 statements per sec are moved to high prio queue.
#
# Now when the statement reaches the high prio queue, there could potentionally be many long-running statements
# ahead of it.
#
# In the worst case, everyone of those will become stalled and take 1 second each before the next statement is retrieved
# from the high prio queue.
#
# Thus - in that scenario, it would take 222 seconds before the new statements starts executing.
#
# ----
#
# thread_kick_up = 10 seconds
#
# ----
#
# high prio queue: 
#
# 10 ----- 1 second stall ------->
# 
# low prio queue:
#
# 200 ----------->
#
# New statement:
#
# 1 --------------->
#
# 
# low -> high = 100/sec MAX
#
# 200 low -> high = 200/100 sec (2 sec)
#
# KICK-UP TIME FROM LOW TO HIGH (10 sec)
#
# IF ALL STALL:
#
# 210 statements stall * STALL TIME (1 second, 210)
#
# 210 + 10 + 2
#
# Total of 222 seconds.
#
# ----
#
# The following pertains to The Rewriter Query Rewrite Plugin
#
# MySQL supports query rewrite plugins that can examine and possibly modify SQL statements received by the server before the
# server executes them.
#
# MySQL distribs include a postparse query rewrite plugin named Rewriter and scripts for installing the plugin and its associated components.
# These components work together to provide statement-rewriting capability:
#
# 		) A server-side plugin named Rewriter examines statements and may rewrite them, based on its in-memory cache of rewrite rules.
#
# 		) These statements are subject to rewriting:
#
# 			) >= 8.0.12 -> SELECT, INSERT, REPLACE, UPDATE and DELETE
#
# 			) < 8.0.12 -> SELECT
#
# 		  Standalone statements and prepared-statements are subject to rewriting. Statements occuring within view definitions or stored programs
# 		  are not subject to rewriting.
#
# 		) The Rewriter plugin uses a database named query_rewrite containing a table named rewrite_rules.
#
# 			The table provides persistent storage for the rules that the plugin uses to decide whether to rewrite statements.
#
# 			Users communicate with the plugin by modifying the set of rules stoed in this table.
#
# 			The plugin communicates with users by setting the message column of table rows.
#
# 		) The query_rewrite DB contains a stored procedure named flush_rewrite_rules() that loads the contents of the rules table into the plugin.
#
# 		) A user defined function named load_rewrite_rules() is used by the flush_rewrite_rules() stored procedure.
#
# 		) The Rewriter plugin exposes SYS_VARs that enable plugin configuration and STATUS vars that provide runtime operational information.
#
# The following section describes how to install and use the Rewriter plugin.
#
# The following pertains to Installing or Uninstalling the Rewriter Query Rewrite Plugin
#
# NOTE:
#
# 		If installed, the Rewriter plugin involves some overhead even when disabled. To avoid this overhead, do not install the plugin lest you intend to use it.
#
# To install or uninstall the Rewriter query rewrite plugin, choose the appropriate script located in the share directory of your MysQL app:
#
# 		install_rewriter.sql : Choose this script to install the Rewriter plugin and its associated components.
#
# 		uninstall_rewriter.sql : Choose this script to uninstall the Rewriter plugin and its associated components.
#
# Run the chosen scripts as follows:
#
# 		mysql -u root -p < install_rewriter.sql
# 		Enter PW (root PW here)
#
# The example here uses the install_rewriter.sql installation script.
# 
# To verify that it is installed and enabled, run this statement:
#
# 		SHOW GLOBAL VARIABLES LIKE 'rewriter_enabled';
# 
# 		+----------------------------------+
# 		| Variable_name 		| Value 		  |
# 		+--------------------+-------------+
# 		| rewriter_enabled 	| ON 			  |
# 		+--------------------+-------------+
#
# The following pertains to how to Use the Rewriter Query Rewrite Plugin:
#
# To enable or disable the plugin, enable or disable the rewriter_enabled SYS_VAR.
#
# By default, the Rewriter plugin is enabled when you install it.
# To set the initial plugin state explicitly, you can set the variable at server startup.
#
# For example, to enable the plugin in an option file - use these lines:
#
# 		[mysqld]
# 		rewriter_enabled=ON
#
# It is also possible to enable or disable the plugin at runtime:
#
# 		SET GLOBAL rewriter_enabled = ON;
# 		SET GLOBAL rewriter_enabled = OFF;
#
# Assuming that the Rewriter plugin is enabled, it examines and possibly modifies each rewritable statement received by the server.
#
# The plugin determines whether to rewrite statements based on its in-memory cache of rewriting rules, which are loaded from the
# rewrite_rules table in the query_rewrite DB.
#
# These statements are subject to rewriting:
#
# 		>= 8..0.12 : SELECT, INSERT, REPLACE, UPDATE and DELETE
#
# 		< 8.0..12 : SELECT
#
# Standalone statements and prepared statements are subject to rewriting.
#
# Statements occuring within view defs or stored programs are not subject to rewriting.
#
# ADDING REWRITE RULES
#
# To add rules for the Rewriter plugin, add rows to the rewrite_rules table, then invoke the flush_rewrite_rules() stored procedure
# to load the rules from the table into the plugin.
#
# The following example creates a simple rule to match statements that select a single literal value:
#
# INSERT INTO query_rewrite.rewrite_rules (pattern, replacement)
# VALUES('SELECT ?', 'SELECT ? + 1');
#
# The resulting table contents will look as follows:
#
# 		SELECT * FROM query_rewrite.rewrite_rules\G
# 		****************************** 1. row ******************************
# 									id: 1
# 							pattern: SELECT ?
# 					pattern_database: NULL
# 				replacement: 		SELECT ? + 1
# 				enabled: 			YES
# 				MESSAGE: 			NULL
# 				pattern_digest: 	NULL
# 			normalized_pattern:  NULL
#
# The rule specifies a pattern template indicating which SELECT statements to match and a replacement template indicating how to
# rewrite matching statements.
#
# However, adding rules to the rewrite_rules table is not sufficient to cause the Rewriter plugin to use the rule.
# You must invoke the flush_rewrite_rules() to load the table contents into the plugin in-memory cache:
#
# 		CALL query_rewrite.flush_rewrite_rules();
#
# TIP: 
# 		If your rewrite rules seem not to be working properly, make sure that you have reloaded the rules by calling the flush_rewrite_rules()
#
# When the plugin reads each rule from the rules table, it computes a normalized (statement digest) form from the pattern and a digest
# hash value, and uses them to update the normalized_pattern and pattern_digest column:
#
# 		SELECT * FROM query_rewrite.rewrite_rules\G
# 		************************** 1. row ****************************
# 										id: 1
# 								pattern: SELECT ?
# 					pattern_database: NULL
# 						replacement:  	SELECT ? + 1
# 							enabled: 	YES
# 								message: NULL
# 					  pattern_digest: <digest>
# 				 normalized_pattern: select ?
#
# If a rule cannot be loaded due to some error, calling flush_rewrite_rules() produces an error:
#
# 		CALL query_rewrite.flush_rewrite_rules();
# 		ERROR 1644 (45000): Loading of some rule(s) failed.
#
# When this occurs, the plugin writes an error message to the message column of the rule row to communicate the problem.
# Check the rewrite_rules table for rows with non-NULL message column values to see what problems exist.
#
# Patterns use the same syntax as prepared statements. Within a pattern template, ? chars act as param markes that match
# data values.
#
# Param markers can be used only where data values should appear, not for SQL keywords, identifiers and so forth.
# The ? characters should not be enclosed within quotation marks.
#
# Like the pattern, the replacement can contain ? chars. For a statement that matches a pattern template,
# the plugin rewrites it, replacing the ? param marker in the replacement using data values matched by the
# corresponding markers in the pattern.
#
# The result is a complete statement string.
#
# The plugin asks the server to parse it, and returns the results to the server as the representaiton of the rewritten statement.
#
# After adding and loading the rule, check whether rewriting occurs according to whether statements match the rule pattern:
#
# 		SELECT PI();
# 		+----------------+
# 		| PI() 			  |
# 		+----------------+
# 		| 3.141593 		  |
# 		+----------------+
# 		1 row in set (0.01 sec)
#
# 		SELECT 10;
# 		+------------+
# 		| 10 + 1 	 |
# 		+------------+
# 		| 			11  |
# 		+------------+
#
# 		1 row in set, 1 warning (0.00 sec)
#
# No rewriting occurs for hte first, but does for the second.
#
# The second statement illustrates that when the Rewriter plugin rewrites a statement, it produces a 
# warning message.
#
# To view the message, use SHOW WARNINGS:
#
# SHOW WARNINGS\G
# ***************************** 1. row ********************************
#
# 		Level: Note
# 		 Code: 1105
# 	 Message: Query 'SELECT 10' rewritten to 'SELECT 10 + 1' by a query rewrite plugin
#
# A statement need not be rewritten to a statement of the same type.
# The following example loads a rule that rewrites DELETE statements to UPDATE statements:
#
# 		INSERT INTO query_rewrite.rewrite_rules (pattern, replacement)
# 		VALUES('DELETE FROM db1.t1 WHERE col = ?',
# 				 'UPDATE db1.t1 SET col = NULL WHERE col = ?');
# 		CALL query_rewrite.flush_rewrite_rules();
#
# To enable or disable an existing rule, modify its enabled column and reload the table into the plugin.
# To disable rule 1:
#
# 		UPDATE query_rewrite.rewrite_rules SET enabled = 'NO' WHERE id = 1;
# 		CALL query_rewrite.flush_rewrite_rules();
#
# This enables you to deactive a rule without removing it from a table.
#
# To re-enable rule 1:
#
# 		UPDATE query_rewrite.rewrite_rules SET enabled = 'YES' WHERE id = 1;
# 		CALL query_rewrite.flush_rewrite_rules();
#
# The rewrite_rules table contains a pattern_database column that Rewriter uses for matching table names that are not 
# qualified with a database name:
#
# 		) Qualified table names in statements match qualified names in the pattern if corresponding database and table names are identical
#
# 		) Unqualified table names in statements match unqualified names in the pattern only if the default database is the same as pattern_database
# 		  and the table names are identical.
#
# Suppose that a table named appdb.users has a column named id and that application are expected to select rows from the
# table using a query of one of these forms, when the secondary can be used only if appdb is the default db:
#
# SELECT * FROM users WHERE appdb.id = id_value;
# SELECT * FROM users WHERE id = id_value; #can only be used if appdb is default DB
#
# Suppose also that the id column is renamed to user_id (perhaps the table must be modified to add another type of ID and it is
# necessary to indicate more specifically what type of ID the id column represents).
#
# The change means that applications must refer to user_id rather than id in the WHERE clause.
#
# But if there are old applications that cannot be written to change the SELECT queries they generate, they will no longer
# work properly.
#
# The Rewriter plugin can solve this problem.
#
# To match and rewrite statements whether or not they qualify the table name, add the following two rules and reload the rules table:
#
# 		INSERT INTO query_rewrite.rewrite_rules
# 			(pattern, replacement) VALUES(
# 			'SELECT * FROM appdb.users WHERE id = ?',
# 			'SELECT * FROM appdb.users WHERE user_id = ?'
# 			);
# 		INSERT INTO query_rewrite.rewrite_rules
# 			(pattern, replacement, pattern_database) VALUES(
# 			'SELECT * FROM users WHERE id = ?',
# 			'SELECT * FROM users WHERE user_id = ?',
# 			'appdb'
# 			);
# 		CALL query_rewrite.flush_rewrite_rules();
#
# Rewriter uses the first rule to match statements that use the qualified table name.
#
# It uses the second to match statements that used the unqualified name, but only if the
# default DB is appdb (the value in pattern_database)
#
# HOW STATEMENTS MATCHING WORKS
#
# The Rewriter plugin uses statement digests and digest hash values to match incoming statements against rewrite rules in stages.
# The max_digest_length SYS_VAR determines the size of the buffer used for computing statement digests.
#
# Larger values enable computation of digests that distinguish longer statements.
#
# Smaller values use less memory but increase the likelihood of longer statements coliding with the same digest value.
#
# The plugin matches each statement to the rewrite rules as follows:
#
# 		1. Compute the statement digest hash value and compare it to the rule digest hash values.
#
# 			This is subject to false positives, but serves as a quick rejection test.
#
# 		2. If the statement digest hash value matches any pattern digest hash value, match the normalized (statement digest) form of the
# 			statement to the normalized form of the matching rule patterns.
#
# 		3. If the normalized statement matches a rule, compare the literal values in the statement and the pattern .
#
# 			A ? char in the pattern matches any literal value in the statement.
#
# 			If the statement prepares a statement, ? in teh pattern also matches ? in the statement.
#
# 			Otherwise, corresponding literals must be the same.
#
# If multiple rules match a statement, it is nondeterminsitic which one the plugin uses to rewrite the statement.
#
# If a pattern contains more markers than the replacement, the plugin discards excess data values.
#
# If a pattern contains fewer markers than the replacement, it is an error.
#
# The plugin notices this when the rules table is loaded, writes an error message to the message column of the rule row to communicate
# the problem, and sets the Rewriter_reload_error status variable to ON. 			 
#
# REWRITING PREPARED STATEMENTS
#
# Prepared statements are rewritten at parse time (that is, when they are prepared), not when they are executed later.
#
# Prepared statements differ from nonprepared statements in that they may contain ? chars as param markers.
# To match a ? in a prepared statement, a Rewriter pattern must contain ? in the same location.
#
# Suppose that a rewrite rule has this pattern:
#
# 		SELECT ?, 3
#
# The following table showcases several prepared SELECT statements and whether the rule pattern matches them.
#
# 		PREPARED STATEMENT 						WHETHER PATTERN MATCHES STATEMENT
#
# 		PREPARE s AS 'SELECT 3,3' 				Yes
# 		PREPARE s AS 'SELECT ?,3' 				Yes
# 		PREPARE s AS 'SELECT 3, ?' 			No
# 		PREPARE s AS 'SELECT ?, ?' 			No -> Won't go through, as prepared statement must have ? in the same placement as Statement, i.e ?,3 is invalid
#
# REWRITER PLUGIN OPERATIONAL INFORMATION
#
# The Rewriter plugin makes information available about its operation by means of several status variables:
#
# 		SHOW GLOBAL STATUS LIKE 'Rewriter%';
#
# 		+---------------------------------------------+
# 		| Variable_name 							| Value 	 |
# 		+-----------------------------------+---------+
# 		| Rewriter_number_loaded_rules 		| 1 		 |
# 		| Rewriter_number_reloads 				| 5 		 |
# 		| Rewriter_number_rewritten_queries | 1		 |
# 		| Rewriter_reload_error 				| ON 		 |
# 		+-----------------------------------+---------+
#
# When you load the rules table by calling the flush_rewrite_rules() stored procedure, if an error occurs for some rule,
# the CALL statement produces an error, and the plugin sets the Rewriter_reload_error status variable to ON:
#
# 		CALL query_rewrite.flush_rewrite_rules();
# 		ERROR 1644 (45000): Loading of some rule(s) failed.
#
# 		SHOW GLOBAL STATUS LIKE 'Rewriter_reload_error';
# 		+--------------------------------+-------+
# 		| Variable_name 						| Value |
# 		+--------------------------------+-------+
# 		| Rewriter_reload_error 			| ON 	  |
# 		+--------------------------------+-------+
#
# In this case, check the rewrite_rules table for rows with non-NULL message column values to see what problems exist.
#
# Rewriter Plugin Use of Character Sets
#
# When the rewrite_rules table is loaded into the Rewriter plugin, the plugin interprets statements using the
# current global value of the character_set_client SYS_VAR.
#
# If the global character_set_client value is changed subsequently, the rules must be reloaded.
#
# A client must have a session character_set_client value identical to what the global value was when the rules table
# was loaded or rule matching will not work for that client.
#
# The following pertains to REWRITER QUERY REWRITE PLUGIN REFERENCE
#
# The following discussion serves as a reference to these components associated with the Rewriter query rewrite plugin:
#
# 		) The Rewriter rules table in the query_rewrite database
#
# 		) Rewriter procedures and functions
#
# 		) Rewriter system and status variables
#
# Rewriter Query Rewrite Plugin Rules Table
#
# The rewrite_rules table in the query_rewrite DB provides a persistent storage for the rules that the Rewriter plugin uses
# to decide whether to rewrite statements.
#
# Users communicate with the plugin by modifying the set of rules stored in this table. The plugin communicates information to users
# by setting the table's message column.
#
# 		NOTE:
#
# 			The rules table is loaded into the plugin by the flush_rewrite_rules stored procedure.
#
# 			Unless the procedure has been called following the most recent table modification,
# 			the table contents do not necessarily correspond to the set of rules the plugin is using.
#
# The rewrite_rules table has these columns:
#
# 		) id
#
# 			The rule ID. This column is the table primary key. You can use the ID to uniquely identify any rule.
#
# 		) pattern
#
# 			The template that indicates the pattern for statements that the rule matches.
# 			Use ? to represent param markers that match data values.
#
# 		) pattern_database
#
# 			The database used to match unqualified table names in statements.
#
# 			Qualified table names in statements match qualified names in the pattern if corresponding database and table names are identical.
#
# 			Unqualified table names in statements match unqualified names in the pattern only if the default database is the same as 
# 			pattern_database and the table names are identical.
#
# 		) replacement
#
# 			The template that indicates how to rewrite statements matching the pattern column value.
#
# 			Use ? to represent param markers that match data values.
#
# 			In rewritten statements, the plugin replaces ? param markers in replacement using data values matched by
# 			the corresponding markers in pattern.
#
# 		) enabled
#
# 			Whether the rule is enabled. Load operations (performed by invoking the flush_rewrite_rules() stored procedure) load the rule
# 			from the table into the Rewriter in-memory cache only if this column is YES.
#
# 			This column makes it possible to deactivate a rule without removing it.
# 			Set the column value to something other than YES and reload the table into the plugin.
#
# 		) message
#
# 			The plugin uses this column for communicating with users.
#
# 			If no error occurs when the rules table is loaded into memory, the plugin sets the message column to NULL.
# 
# 			A non-NULL value indicates an error and the column contents are the error message.
# 			Errors can occur under these circumstances:
#
# 				) Either the pattern or the replacement is an incorrect SQL statement that produces syntax errors.
#
# 				) The replacement contains more ? params markers than the pattern.
#
# 			If a load error occurs, the plugin also sets the Rewriter_reload_error STATUS_VAR to ON.
#
# 		) pattern_digest
#
# 			This column is used for debugging and diagnostics.
#
# 			If the column exists when the rules table is loaded into memory, the plugin updates
# 			it with the pattern digest.
#
# 			This column may be useful if you are trying to determine why some statement fails to be rewritten.
#
# 		) normalized_pattern
#
# 			This column is used for debugging and diagnostics. 
#
# 			If the column exists when the rules table is loaded into memory, the plugin updates it with the normalized
# 			form of the pattern.
#
# 			This column may be useful if you are trying to determine why some statement fails to be rewritten.
#
# REWRITER QUERY REWRITE PLUGIN PROCEDURES AND FUNCTIONS
#
# Rewriter plugin operation uses a stored procedure that loads the rules table into its in-memory cache, and a helper
# user-defined function (UDF).
#
# Under normal operation, users invoke only the stored procedure.
#
# The UDF is intended to be invoked by the stored procedure, not directly by users.
#
# 		) flush_rewrite_rules()
#
# 			This stored procedure uses the load_rewrite_rules() UDF to load the contents of the rewrite_rules table
# 			into the Rewriter in-memory cache.
#
# 			Calling flush_rewrite_rules() implies COMMIT.
#
# 			Invoke this procedure after you modify the rules table to cause the plugin to update its cache from the
# 			new table contents.
#
# 			If any errors occur, the plugin sets the message column for the appropriate rule rows in the table and
# 			sets the Rewriter_reload_error status variable to ON.
#
# 		) load_rewrite_rules()
#
# 			This UDF is a helper routine used by the flush_rewrite_rules() stored procedure.
#
# REWRITER QUERY REWRITE PLUGIN SYS_VARs
#
# The Rewriter query rewrite plugins support the following SYS_VARs.
# These variables are available only if the plugin is installed.
#
# 		) rewriter_enabled
#
# 			SYS_VAR 					rewriter_enabled
# 			Scope: 					Global
# 			Dynamic: 					Yes
# 			SET_VAR Hint applies: 	 No
# 			Type: 					Boolean
# 			Default: 				 	 ON
#
# 			Whether the Rewriter query rewrite plugin is enabled.
#
# 		) rewriter_verbose
#
# 			SYS_VAR 					rewriter_verbose
# 			Scope: 					Global
# 			Dynamic: 				   Yes
# 			SET_VAR Hint: 				No
# 			Type: 						INteger
#
# 			For internal use.
#
# REWRITER QUERY REWRITE PLUGIN STATUS VARS
#
# The Rewriter query rewrite plugin supports the following status vars.
#
# These variables are available only if the plugin is installed.
#
# 			) Rewriter_number_loaded_rules
#
# 				THe number of rewrite plugin rewrite rules successfully loaded from the rewrite_rules table into memory for use by the Rewriter plugin.
#
# 			) Rewriter_number_reloads
#
# 				The number of times the rewrite_rules table has been loaded into the in-memory cache used by the Rewriter plugin
#
# 			) Rewriter_number_rewritten_queries
#
# 				The number of queries rewritten by the Rewriter query rewrite plugin since it was loaded.
#
# 			) Rewriter_reload_error
#
# 				Whether an error occurred the most recent time that the rewrite_rules table was loaded into the in-memory
# 				cache used by the Rewriter plugin.
#
# 				If the value is OFF, no error occured.
#
# 				If the value is ON, an error occured.
#
# 				Check the messages column of the rewriter_rules table for error messages.
#
# VERSION TOKENS
#
# MySQL includes Version Tokens, a feature that enables creation of and synchronization around server tokens that applications
# can use to prevent accessing incorrect or out-of-date Data.
#
# The Version Tokens interface has these characteristics::
#
# 		) Version tokens are pairs consisting of a name that servers as a key or identifier, plus a value
#
# 		) Version tokens can be locked. An application can use token locks to indicate to other cooperating applications that tokens are in used and
# 			should not be modified.
#
# 		) Version token lists are established per server; for example, to specify the server assignment or operational state.
#
# 			In addition, an application that communicates with a server can register its own list of tokens that indicate the state
# 			it requires the server to be in.
#
# 			An SQL statement sent by the application to a server not in the required state produces an error.
#
# 			This is a signal to the application that it should seek a different server in the required state to receive
# 			the SQL statement.
#
# The following section describes the components of Version Tokens, discuss how to install and use them, and provides refernce.
#
# VERSION TOKEN COMPONENTS
#
# Version Tokens is based on a plugin library that implements these components:
#
# 		) A server-side plugin named version_tokens holds the list of version tokens associated with the server and subscribes to
# 		  notifications for statement execution events.
#
# 		  The version_tokens plugin uses the audit plugin API to monitor incoming statements from clients and matches each client's
# 			session-specific version token list against the server version token list.
#
# 			If there is a match, the plugin lets the statement through and the server continues to process it.
#
# 			Otherwise, the plugin returns an error to the client and the statement fails.
#
# 		) A set of user-defined functions (UDFs) provides an SQL-level API for manipulating and inspecting the list of server version
# 		  tokens maintained by the plugin.
#
# 			The VERSION_TOKEN_ADMIN or SUPER privs is required to call any of the Version Token UDFs.
#
# 		) When the version_tokens plugin loads, it defines the VERSION_TOKEN_ADMIN dynamic privilege.
#
# 			This priv can be granted to users of the UDFs.
#
# 		) A SYS_VAR enables clients to specify the list of version tokens that registers the required server state.
#
# 			If the server has a different state when a client sends a statement, the client receives an error.
#
# INSTALLING OR UNINSTALLING VERSION TOKENS
#
# NOTE:
#
# 		If installed, Version Tokens involves some overhead. To avoid this, do not install lest you plan to use them.
#
# This section describes how to install or uninstall Version Tokens, which is implemented in a plugin library file containing
# a plugin and user-defined functions (UDFs).
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin dir (the dir named by the plugin_dir SYS_VAR)
# If necessary, configure the plugin dir location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is version_tokens. The file name suffix differs per platform (for example, .so for Unix
# and Unix-like systems. .dll for Windows)
#
# To install the Version Token plugin and UDFs, use the INSTALL_PLUGIN and CREATE_FUNCTION statements (adjust the .so suffix for your platform, if needed):
#
# 		INSTALL PLUGIN version_tokens SONAME 'version_token.so';
# 		CREATE FUNCTION version_tokens_set RETURNS STRING
# 			SONAME 'version_token.so';
# 		CREATE FUNCTION version_tokens_show RETURNS STRING
# 			SONAME 'version_token.so';
#
#  	CREATE FUNCTION version_tokens_edit RETURNS STRING
# 			SONAME 'version_token.so';
# 		CREATE FUNCTION version_tokens_delete RETURNS STRING
# 			SONAME 'version_token.so';
#
# 		CREATE FUNCTION version_tokens_lock_shared RETURNS INT
# 			SONAME 'version_token.so';
# 		CREATE FUNCTION version_tokens_lock_exclusive RETURNS INT
# 			SONAME 'version_token.so';
#
# 		CREATE FUNCTION version_tokens_unlock RETURNS INT
# 			SONAME 'version_token.so';
#
# You must install the UDFs to manage the server's version token list, but you must also install the plugin ebcause the UDFs will
# not work correctly without it.
#
# If the plugin and UDFs are used on a master replication server, install them on all slave servers as well to avoid replication problems.
#
# Once installed as just described, the plugin and UDFs remain installed until uninstalled.
# To remove them, use the UNINSTALL_PLUGIN and DROP_FUNCTION statements:
#
# 		UNINSTALL PLUGIN version_tokens;
# 		DROP FUNCTION version_tokens_set;
# 		DROP FUNCTION version_tokens_show;
# 		DROP FUNCTION version_tokens_edit;
#
# 		DROP FUNCTION version_tokens_delete;
# 		DROP FUNCTION version_tokens_lock_shared;
# 		DROP FUNCTION version_tokens_lock_exclusive;
# 		DROP FUNCTION version_tokens_unlock;
#
# USING VERSION TOKENS
#
# Before using Version Tokens, install it according to the previous section.
#
# A scenario in which Version Tokens can be useful is a system that accesses a collection of MySQL servers but needs
# to manage them for load balancing purposes by monitoring them and adjusting server assignments according to load changes.
#
# Such a system comprises these components:
#
# 		) The collection of MySQL servers to be managed
#
# 		) An administrative or management application that communicates with the servers and organizes them into high-availability groups.
# 			Groups serve different purposes, and servers within each group may have different assignments.
#
# 			Assignment of a server within a certain group can change at any time.
#
# 		) Client applications that access the servers to retrieve and update data, choosing servers according to the purposes assigned them.
# 			For example, a client should not send an update to a read-only server.
#
# Version Tokens permit server access to be managed according to assignment without requiring clients to repeatedly query the servers about
# their assignments:
#
# 		) The management application performs server assignments and establishes version tokens on each server to reflect its assignment.
# 			The application caches this information to provide a central access point to it.
#
# 			If at some point the management application needs to change a server assignment (for example, to change it from permitting writes to
# 			read only), it changes the server's version token list and updates its cache.
#
# 		) To improve performance, client applications obtain cache information from the management application, enabling them to avoid
# 			having to retrieve information about server assignments for each statement.
#
# 			Based on the type of statements it will issue (for example, reads versus writes), a client selects an appropiate server and connects to it.
#
# 		) In addition, the client sends to the server its own client-specific version tokens to register the assignment it requires of the server.
# 			For each statement sent by the client to the server, the server compares its own token list with the client token list.
#
# 			If the server token list contains all tokens present in the client token list with the same values, there is a match and the server
# 			executes the statement.
#
# 			ON the other hand, perhaps the management application has changed the server assignment and its version token list.
#
# 			IN this case, teh new server assignment may now be incompatible with the client requirements.
#
# 			A token mismatch between the server and client token list occurs and the server returns an error in reply to the
# 			statement.
#
# 			This is an indication to the client ot refresh its version token information from the management application cache,
# 			and to select a new server to communicate with.
#
# The client-side logic for detecting version token errors and selecting a new server can be implemented in different ways:
#
#  		) The client can handle all version token registration, mismatch detection and connection switching itself.
#
# 			) The logic for those actions can be implemented in a connector that manages connections between clients and MySQL servers.
# 				Such a connector might handle mismatch error detection and statemnet resending itself, or it might pass the error to the
# 				application and leave it to the application to resent the statement.
#
# The following example illustrates the preceding discussion in concrete form.
#
# When Version Tokens initialize on a given server, the server's version token list is empty.
# Token list maintenance is performed by calling user-defined functions (UDFs).
#
# The VERSION_TOKEN_ADMIN or SUPER privs is required to call any of the Version Token UDFs, so token list
# modification is expected to be done by management or administrative application that has that priv.
#
# Suppose that a management app communicates with a set of services that are queried by clients to access employee and product DBs
# (named emp and prod, respectively)
#
# All servers are permitted to process data retrieveal statements, but only some of them are permitted to make DB updates.
#
# To handle this on a DB specific basis, the management application establishes a list of version tokens on each server.
#
# In the token list for a given server, token names represent database names and token values are read or write
# depending on wether the database must be used in read-only fashion or whether it can take reads and wrties.
#
# Client applications register a list of version tokens they require the server to match by setting a SYS_VAR.
# Variable settings occurs on a client-specific basis, so different clients can register different requirements.
#
# By default, the client token list is empty, which matches any server token list.
# When a client sets its token list to a nonempty value, matching may succeed or fail, depending on the server version token list.
#
# To define the version token list for a server, the management application calls the version_tokens_set() UDF.
# (There are also UDFs for modifying and displaying the token list, later)
#
# For example, the app might send these statements to a group of three servers:
#
# SERVER 1:
#
# SELECT version_tokens_set('emp=read;prod=read');
# +--------------------------------------------+
# | version_tokens_set('emp=read;prod=read')   |
# +-------------------------------------------+
# | 2 version tokens set. 							  |
# +--------------------------------------------+
#
# SERVER 2:
#
# SELECT version_tokens_set('emp=write;prod=read');
# +---------------------------------------------+
# | version_tokens_set('emp=write;prod=read') 	|
# +---------------------------------------------+
# | 2 version tokens set. 								|
# +---------------------------------------------+
#
# SERVER 3:
#
# SELECT version_tokens_set('emp=read;prod=write');
# +---------------------------------------------+
# | version_tokens_set('emp=read;prod=write') 	|
# +---------------------------------------------+
# | 2 version tokens set. 								|
# +---------------------------------------------+
#
# The token list in each case is specified as a semicolon-separated list of <name=value> pairs.
# The resulting token list values result in these server assignments:
#
# 		) Any server accepts reads for either DB
#
# 		) Only server 2 accepts updates for the emp DB
#
# 		) Only server 3 accepts updates for the prod database
#
# In addition to assigning each server a version token list, the management application also maintains a cache that
# reflects the server assignments.
#
# Before communicating with hte servers, a client application contacts the management application and retrieves information
# about server assignments.
#
# Then the client selects a server based on those assignments. Suppose that a client wants to perform both reads and writes
# on the emp database.
#
# Based on the preceding assignments, only server 2 qualifies.
#
# The client connects to server 2 and registers it server requirements there by setting its version_tokens_session SYS_VAR:
#
# 		SET @@SESSION.version_tokens_session = 'emp=write';
#
# For subsequent statements sent by the client to server 2, the server compares its own version token list to the client list
# to check whether they match.
#
# IF so, statements execute normally:
#
# 		UPDATE emp.employee SET salary = salary * 1.1 WHERE id = 4981;
# 		Query OK, 1 row affected (0.07)
# 		Rows matched: 1 Changed: 1 Warnings: 0
#
# 		SELECT last_name, first_name FROM emp.employee WHERE id = 4981;
# 		+-----------------+-------------------+
# 		| last_name 		| First_name 		  |
#  	+-----------------+-------------------+
# 		| Smith 				| Abe 				  |
# 		+-----------------+-------------------+
# 		1 row in set (0.01 sec)
# 	
# Discrepencies between the server and client version token lists can occur in two ways:
#
# 		) A token name in the version_tokens_session value is not present in the server token list.
# 			In this case, an ER_VTOKEN_PLUGIN_TOKEN_NOT_FOUND error occurs.
#
# 		) A token value in the version_tokens_session value differs from the value of the corresponding token in the 
# 			server token list. In this case, an ER_VTOKEN_PLUGIN_TOKEN_MISMATCH error occurs.
#
# As long as the assignment of server 2 does not change, the client continues to use it for reads and wrties.
# But suppose that hte management application wants to change server assignments so that writes for the emp db must be
# sent to server 1 instead of server 2.
#
# To do so, it uses version_tokens_edit() to modify the emp token vlaue on the two servers (and update its cache of server assignments):
#
# Server 1:
#
# 		SELECT version_tokens_edit('emp=write');
# 		+-----------------------------------------+
# 		| version_tokens_edit('emp=write') 			|
# 		+-----------------------------------------+
# 		| 1 version tokens updated. 					|
# 		+-----------------------------------------+
#
# Server 2:
#
# 		SELECT version_tokens_edit('emp=read');
# 		+-----------------------------------------+
# 		| version_tokens_edit('emp=read') 			|
# 		+-----------------------------------------+
# 		| 1 version tokens updated. 					|
# 		+-----------------------------------------+
#
# version_tokens_edit() modifies the named tokens in the server token list and leaves other tokens unchanged.
#
# The next time the client sends a statement to server 2, its own token list no longer matches the server token list
# and an error occurs:
#
# UPDATE emp.employee SET salary = salary * 1.1 WHERE id = 4982;
# ERROR 3136 (42000): Version token mismatch for emp. Correct value read
#
# In this case, the client should contact the management application to obtain updated information about server assignments,
# select a new server, and send the failed statement to the new server.
#
# NOTE:
#
# 		Each client must cooperate with Version Tokens by sending only statements in accordance with the token list that it registers
# 		with a given server.
#
# 		For example, if a client registers a token list of 'emp=read', there is nothing in Version Tokens to prevent the client
# 		from sending updates for the emp db.
#
# 		The client itself must refrain from doing so.
#
# For each statement received from a client, the server implicitly uses locking, as follows:
#
# 		) Take a shared lock for each token named in the client token list (that is, in the version_tokens_session value)
#
# 		) Perform the comparison between the server and client token lists
#
# 		) Execute the statement or produce an error depending on the comparison result.
#
# 		) Release the locks
#
# The server uses shared locks so that comparisons for multiple sessions can occur without blocking, while preventing
# changes to the tokens for any session that attempts to acquire an exclusive lock before it manipulates tokens of the
# same names in the server tokens list.
#
# THe preceding example uses only a few of the user-defined values in the Version Tokens plugin library, but there are others.
# One set of UDFs permits the server's list of version tokens to be manipulated and inspected.
#
# Another set of UDF's permits version tokens to be locked and unlocked.
#
# These UDFs permit the server's list of version tokens to be created, changed, removed and inspected:
#
# 		) version_tokens_set() completely replaces the current list and assigns a new list.
#
# 			The argument is a semicolon-separated list of <name=value> pairs.
#
# 		) version_tokens_edit() enables partial modifications to the current list.
#
# 			It can add new tokens or change the values of existing tokens.
#
# 			The argument is a semicolon-separated list of <name=value> pairs.
#
# 		) version_tokens_delete() deletes tokens from the current list. The argument is a semicolon separated list of token names.
#
# 		) version_tokens_show() displays the current token list. It takes no argument.
#
# Each of those functions, if successful, returns a binary string indiating what action occurred.
#
# The following example establishes the server token list, modifies it by adding a new token, deletes some tokens,
# and displays the resulting token list:
#
# 		SELECT version_tokens_set('tok1=a;tok2=b;');
# 		+-------------------------------------------+
# 		| version_tokens_set('tok1=a;tok2=b') 		  |
# 		+-------------------------------------------+
# 		| 2 version tokens set. 						  |
# 		+-------------------------------------------+
#
# 		SELECT version_tokens_edit('tok3=c');
# 		+-------------------------------------------+
# 		| version_tokens_edit('tok3=c') 				  |
# 		+-------------------------------------------+
# 		| 1 version token updated. 					  |
# 		+-------------------------------------------+
#
# 		SELECT version_tokens_delete('tok2;tok1');
# 		+-------------------------------------------+
# 		| version_tokens_delete('tok2;tok1') 		  |
# 		+-------------------------------------------+
# 		| 2 version tokens deleted. 					  |
# 		+-------------------------------------------+
#
# 		SELECT version_tokens_show();
# 		+-----------------------------+
# 		| version_tokens_show() 		|
# 		+-----------------------------+
# 		| tok3=c; 							|
# 		+-----------------------------+
#
# Warnings occur if a token list is malformed:
#
# 		SELECT version_tokens_set('tok1=a; =c');
# 		+---------------------------------------+
# 		| version_tokens_set('tok1=a; =c') 		 |
# 		+---------------------------------------+
# 		| 1 version tokens set. 					 |
# 		+---------------------------------------+
#
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		******************************* 1. row *******************************
# 			Level: Warning
# 			Code:  42000
# 		Message:  Invalid version token pair encountered. The list provided is only partially updated.
# 		1 row in set (0.00 sec)
#
# AS mentioned previously, version tokens are defined using a semicolon-separated list of <name=value> pairs.
# Consider this invocation of version_tokens_set();
#
# 		SELECT version_tokens_set('tok1=b;;; tok2= b = b ; tok1 = 1\'2 3"4')
# 		+-------------------------------------------------------------------+
# 		| version_tokens_set('tok1=b;;; tok2= a = b ; tok1 = 1\'2 3"4') 	  |
# 		+-------------------------------------------------------------------+
# 		| 3 version tokens set. 														  |
# 		+-------------------------------------------------------------------+
#
# Version Tokens interprets the argument as follows:
#
# 		) Whitespace around names and values is ignored. Whitespace within names and values is permitted.
# 			(For version_tokens_delete(), which takes a list of names without values, whitespace around names is ignored)
#
# 		) There is no quoting mechanism
#
# 		) Order of tokens is not significant except that if a token list contains multiple instances of a given token name, the last 
# 			value takes precedence over earlier values.
#
# Given those rules, the preceding version_tokens_set() call results in a token list with two tokens:
#
# 		tok1 has the value 1'2 3"4 and tok2 has the value a = b.
#
# 		To verify this, just call version_tokens_show():
#
# 		SELECT version_tokens_show();
# 		+------------------------------+
# 		| version_tokens_show() 		 |
# 		+------------------------------+
# 		| tok2=a = b;tok1=1'2 3"4; 	 |
# 		+------------------------------+
#
# If the token list contains two tokens, why did version_tokens_set() return the value 3 version tokens set?
#
# Because tok1 was assigned twice.
#
# The Version Tokens token-manipulation UDFs place these constraints on token names and values:
#
# 		) Token names cannot contain = or ; characters and have a max length of 64 chars.
#
# 		) Token values cannot contain ; chars. Length of values is constrained by the value of the max_allowed_packet SYS_VAR.
#
# 		) Version Tokens treats token names and values as binary strings, so comparisons are case-sensitive.
#
# Version Tokens also include a set of UDFs enabling tokens to be locked and unlocked:
#
# 		) version_tokens_lock_exclusive() acquires exclusive version token locks. It takes a list of one or more lock names and a timeout value.
#
# 		) version_tokens_lock_shared() acquires shared version token locks. It takes a list of one or more lock names and a timeout value.
#
# 		) version_tokens_unlock() release version token locks (exclusive and shared). No args.
#
# Each locking function returns nonzero for success. Otherwise, an error occurs:
#
# 		SELECT version_tokens_lock_shared('lock1', 'lock2', 0);
# 		+-----------------------------------------------------+
# 		| version_tokens_lock_shared('lock1', 'lock2', 0) 		|
# 		+-----------------------------------------------------+
# 		| 																	1  |
# 		+-----------------------------------------------------+
#
# SELECT version_tokens_lock_shared(NULL, 0);
# ERROR 3131 (42000): Incorrect locking service lock name '(null)'.
#
# Locking using Version Tokens locking function is advisory, applications must agree to cooperate.
#
# It is possible to lock nonexisting token names. This does not create the tokens.
#
# NOTE:
#
# 		Version tokens locking functions are based on the locking service, described later.
# 		And thus must have the same semantics for shared and exclusive locks.
# 		(Version Tokens uses the locking service routines built into the server, not the locking
# 		service UDF interface, so those UDFs need not be installed to use Version Tokens).
#
# 		Locks acquired by Version Tokens use a locking service namespace of version_token_locks.
# 		Locking service locks can be monitored using the Performance Schema, so this is also true
# 		for Version Tokens Locks.
#
# For the Version Tokens locking functions, token name arguments are used exactly as specified.
#
# Surrounding whitespace is not ignored and = and ; chars are permitted.
#
# This is because the Version Tokens simply passes the token names to be locked as is to the locking service.
#
# VERSION TOKENS REFERENCE
#
# VERSION TOKENS FUNCTIONS
#
# The Version Tokens plugin library includes several user-defined functions.
#
# One set of UDF's permits the server's list of version tokens to be manipulated and inspected.
# Another set of UDFs permits version tokens to be locked and unlocked.
#
# The VERSION_TOKEN_ADMIN or SUPER privilege is required to invoke any Version Tokens UDF.
#
# The following UDFs permit the server's list of version tokens to be created, changed, removed and inspected.
# Interpretation of <name_list> and <token_list> arguments (including whitespace handling) occurs as described.
#
# 		) version_tokens_delete(<name_list>)
#
# 			Delete tokens from the server's list of version tokens using the <name_list> argument and returns a binary
# 			string that indicates the outcome of the operation.
#
# 			<name_list> is a semicolon-separated list of version token names to delete.
#
# 			SELECT version_tokens_delete('tok1;tok3');
# 			+------------------------------------------+
# 			| version_tokens_delete('tok1;tok3') 		 |
# 			+------------------------------------------+
# 			| 2 version tokens deleted. 					 |
## 		+------------------------------------------+
#
# 			An argument of NULL is treated as an empty string, which has no effect on the token list.
#
# 			version_tokens_delete() deletes the tokens named in its argument, if they exist.
# 			(It is not an error to delete nonexisting tokens).
#
# 			To clear the token list entirely without knowing which tokens are in the list, pass NULL or a string
# 			containing no tokens to version_tokens_set();
#
# 					SELECT version_tokens_set(NULL);
# 					+-----------------------------------+
# 					| version_tokens_set(NULL) 			|
# 					+-----------------------------------+
# 					| Version tokens list cleared. 		|
# 					+-----------------------------------+
#
# 					SELECT version_tokens_set('');
# 					+-----------------------------------+
# 					| version_tokens_set('') 				|
# 					+-----------------------------------+
# 					| Version tokens list cleared. 		|
# 					+-----------------------------------+
#
# 		) version_tokens_edit(<token_list>)
#
# 			Modifies the server's list of version tokens using the <token_list> arugment and returns a binary string that indicates
## 		the outcome of the operation.
#
# 			<token_list> is a semicolon-separated list of <name=value> pairs specifying the name of each token to be defined
# 			and its value.
#
# 			If a token exists, its value is updated with the given value.
#
# 			If a token does not exist, it is created with the given value. If the argument is NULL or a string containing no tokens,
# 			the token list remains unchanged.
#
# 					SELECT version_tokens_set('tok1=value;tok2=value2');
# 					+--------------------------------------------------+
# 					| version_tokens_set('tok1=value1;tok2=value2') 	|
# 					+--------------------------------------------------+
# 					| 2 version tokens set. 									|
# 					+--------------------------------------------------+
#
# 					SELECT version_tokens_edit('tok2=new_value2;tok3=new_value3');
# 					+-------------------------------------------------------+
# 					| version_tokens_edit('tok2=new_value;tok3=new_value3') |
# 					+-------------------------------------------------------+
# 					| 2 version tokens updated. 									  |
# 					+-------------------------------------------------------+
#
# 		) version_tokens_set(<token_list>)
#
# 			Replaces the server's list of version tokens with the tokens defined in the <token_list> argument and returns a binary
# 			string that indicates the outcome of the operation.
#
# 			<token_list> is a semicolon-separated list of <name=value> pairs specifying name of each token to be defined and its value.
#  		If the argument is NULL or a string containing no tokens, the token list is cleared.
#
# 					SELECT version_tokens_set('tok1=value;tok2=value2');
# 					+--------------------------------------------------------+
# 					| version_tokens_set('tok1=value1;tok2=value2') 			|
# 					+--------------------------------------------------------+
# 					| 2 version tokens set. 											|
# 					+--------------------------------------------------------+
#
# 		) version_tokens_show()
#
# 			Returns the server's list of versions tokens as a binary string containing a semicolon-separated list of <name=value> pairs.
#
# 					SELECT version_tokens_show();
# 					+-------------------------------------+
# 					| version_tokens_show() 				  |
# 					+-------------------------------------+
# 					| tok2=value2;tok1=value1; 			  |
# 					+-------------------------------------+
#
# The following UDFs permit version tokens to be locked and unlocked:
#
# 		) version_tokens_lock_exclusive(<token_name[, <token_name>] ..., <timeout>)
#
# 			Acquires exclusive locks on one or more version tokens, specified by name as strings, timing out with an error if the locks
#  		are not acquired within the given timeout:
#
# 					SELECT version_tokens_lock_exclusive('lock1', 'lock2', 10);
# 					+---------------------------------------------------------+
# 					| version_tokens_lock_exclusive('lock1', 'lock2', 10) 	 |
# 					+---------------------------------------------------------+
# 					| 																	1 		 |
# 					+---------------------------------------------------------+
#
# 		) version_tokens_lock_shared(<token_name>[, <token name>] ..., <timeout>)
#
# 			Acquires shared locks on one or more version tokens, specified by name as strings, timing out 
# 			with an error if the locks are not acquired within the given timeout value.
#
# 					SELECT version_tokens_lock_shared('lock1', 'lock2', 10);
# 					+----------------------------------------------------------+
# 					| version_tokens_lock_shared('lock1', 'lock2', 10) 		  |
# 					+----------------------------------------------------------+
# 					| 																		1 	  |
# 					+----------------------------------------------------------+
# 
# 		) version_tokens_unlock()
#
# 			Releases all locks hat were acquired within the current session using version_tokens_lock_exclusive() and version_tokens_lock_shared()
#
# 					SELECT version_tokens_unlock();
# 					+-------------------------------+
# 					| version_tokens_unlock() 		  |
# 					+-------------------------------+
# 					| 									1 	  |
# 					+-------------------------------+
#
# 
# The locking functions share these characeteristics:
#
# 		) The return value is nonzero for success. Otherwise, an error occurs.
#
# 		) Token names are strings.
#
# 		) In contrast to arugment handling for the UDFs that manipulate the server tokens list, whitespace surrounding token
# 			name arguments is not ignored and = and ; chars are permitted.
#
# 		) it is possible to lock a nonexisting token name. Does not create the token.
#
# 		) Timeout values are nonnegative integer representing teh time in seconds to wait to acquire locks before timing out
# 			with an error.
#
# 			If the timeout is 0, there is no waiting and the function produces an error if locks cannot be acquired instantly.
#
# 		) Version Tokens locking functions are based on the locking service described later.
#
# VERSION TOKENS SYS_VARs
#
# Version tokens support the following SYS_VARs. These VARs are unavailable unless the Version Tokens plugin is installed.
#
# SYS_VARs:
#
# 			) version_tokens_session
#
# 				PROPERTY 				VALUE
# 				cmd line: 				--version-tokens-session=value
# 				Sys_Var: 				version_tokens_session
# 				Scope: 					Global, Session
# 				Dynamic: 				Yes
# 				SET_VAR Hint: 			No
# 				Type: 					String
# 				Default: 				NULL
#
# 				The session value of this variable specifies the client version token list and indicates the tokens that hte client
# 				session requires the server version token list to have.
#
# 				If the version_tokens_session variable is NULL (the default), or has an empty value, any server version token list matches.
# 				(In effect, an empty value disables matching requirements)
#
# 				If the version_tokens_session variable has a nonempty value, any mismatch between its value and the server version token list results
# 				in an error for any statement the session sends to the server. A mismatch occurs under these conditions:
#
# 					) A token name in the version_tokens_session value is not present in the server token list. In this case, an ER_VTOKEN_PLUGIN_TOKEN_NOT_FOUND
# 						error occurs.
#
# 					) A token value in the version_tokens_session value differs from the value of the corresponding token in the server token list.
# 						In this case, an ER_VTOKEN_PLUGIN_TOKEN_MISMATCH error occurs.
#
# 				It is not a mismatch for the server version token list to include a token not named in the version_tokens_session value.
#
# 				Suppose that a management application has set the server token list as follows:
#
# 					SELECT version_tokens_set('tok1=a;tok2=b;tok3=c');
#  				+------------------------------------------------+
# 					| version_tokens_set('tok1=a;tok2=b;tok3=c') 	 |
# 					+------------------------------------------------+
# 					| 3 version tokens set 									 |
# 					+------------------------------------------------+
#
# 				A client registers the tokens it requires the server to match by setting its version_tokens_session value.
#
# 				Then, for each subsequent statement sent by the client, the server checks its token list against the client 
# 				version_tokens_session value and produces an error if there is a mismatch:
#
# 					SET @@SESSION.version_tokens_session = 'tok1=a;tok2=b';
# 					SELECT 1;
# 					+----+
# 					| 1  |
# 					+----+
#  				| 1  |
# 					+----+
#
# 					SET @@SESSION.version_tokens_session = 'tok1=b';
# 					SELECT 1;
# 					ERROR 3136 (42000): Version token mismatch for tok1. Correct value a
#
# 				The first SELECT succeeds because the client tokens tok1 and tok2 are present in the server token list and
# 				each token has the same value in the server list.
#
# 				The second SELECT fails because, although tok1 is present in the server token list, it has a different
# 				value than specified by the client.
#
# 				At this point, any statement sent by the client fails, unless the server token list changes such that it matches again.
# 				Suppose that the management application changes the server token list as follows:
#
# 					SELECT version_tokens_edit('tok1=b');
# 					+-------------------------------------+
# 					| version_tokens_edit('tok1=b') 		  |
# 					+-------------------------------------+
# 					| 1 version tokens updated. 			  |
# 					+-------------------------------------+
# 		
# 					SELECT version_tokens_show();
# 					+---------------------------+
# 					| version_tokens_show() 	 |
# 					+---------------------------+
# 					| tok3=c;tok1=b;tok2=b; 	 |
# 					+---------------------------+
#
# 				Now the client version_tokens_session value matchhes the server token list and the client can once again successfully execute statements:
#
# 					SELECT 1;
#  	 			+---+
# 					| 1 |
# 					+---+
# 					| 1 |
# 					+---+
#			
# 			
# 			) version_tokens_session_number
#
# 				PROPERTY 					VALUE
# 				cmd line: 					--version-tokens-session-number=N
# 				Sys_Var: 					version_tokens_session_number
# 				Scope: 						Global, Session
# 				Dynamic: 					No
# 				SET_VAR Hint: 				No
# 				Type: 						Integer
# 				Default: 					0
#
# 				Internal use.
#
# MYSQL SERVER USER-DEFINED FUNCTIONS
#
# MySQL Server enables user-defined functions (UDFs) to be created and loaded into the server to extend server capabilities.
# Server capabilities can be implemented in whole or in part using UDFs.
#
# In addition, you can write your own UDFs.
# The following showcases how to install and uninstall UDFs, and how to determine at runtime which UDFs are installed and obtain info about them.
#
# INSTALLING AND UNINSTALLING USER-DEFINED FUNCTIONS
#
# User-defined functions (UDFs) must be loaded into the server before they can be used.
# MySQL supports UDF loading at runtime.
#
# To load a UDF, use the CREATE_FUNCTION statement. For example:
#
# 		CREATE FUNCTION metaphon RETURNS STRING SONAME 'udf_example.so';
#
# The UDF file base name depends on your platform. Common suffixes are .so for Unix and Unix-based systems., .dll for Windows.
#
# While a UDF is loaded, information about it is available from the Performance Schema user_defined_functions table.
#
# The statement also registers the UDF in the mysql.func SYSTEM table to cause the server to load it on subsequent 
# restarts.
#
# For this reason, CREATE_FUNCTION requires the INSERT priv for the mysql db.
#
# To remove a UDF, use the DROP_FUNCTION statement. For example:
#
# 		DROP FUNCTION metaphon;
#
# DROP_FUNCTION unloads the UDF and removes it from the mysql.func system table.
# For this reason, DROP_FUNCTION statements require the DELETE priv for the mysql db.
#
# With the UDF No longer registered in the table, the server does not load the UDF automatically for subsequent restarts.
#
# You cannot use CREATE_FUNCTION to reinstall a function that has previously been installed.
# To reinstall a function, first remove it with DROP_FUNCTION, then install it again with CREATE_FUNCTION.
#
# You would need to do this, for example, if you ugprade to  a new version of MySQL that provides an updated implementation
# of the function, so you recompile a new version of a function that you have written.
#
# Otherwise, the Server uses the old version.
#
# If the server is started with the --skip-grant-tables option, it does not consult the mysql.func table and does not
# load the UDFs listed there.
#
# OBTAINING USER-DEFINED FUNCTION INFORMATION
#
# The Performance Schema user_defined_functions table contains information about the currently loaded user-defined functions:
#
# 		SELECT * FROM performance_schema.user_defined_functions;
#
# RUNNING MULTIPLE MYSQL INSTANCES ON ONE MACHINE
#
# In some cases, you might want to run multiple instances of MySQL on a single machine.
# You might want to test a new MySQL release while leaving an existing production setup undisturbed.
#
# Or you might want to give different users access to different mysqld servers that they manage themselves.
# (For example, you might be an ISP that wants to provide independent MySQL installations for different customers)
#
# IT is possible to use a different MySQL server binary per instance, or use the same binary for multiple instances,
# or any combination of the two approaches.
#
# For example, you might run a server of 5.7, and one of 8.0, etc.
#
# Whether or not you use distinct server binaries, each instance that you run must be configured with unique values for
# several operating params.
#
# This eliminates the potentional for conflict between instances.
#
# parameters can be set on the cmd line, in option files, or by setting environment variables.
#
# To see the values used by a given isntance, connect to it and execute a SHOW_VARIABLES statement.
#
# The primary resource managed by a MySQL instance is the data dir. Each instance should use a different
# data dir, the location of which is specified using the --datadir=<dir_name> option.
#
# For methods of configuring each instance with its own data dir, and warnings about the dangers of failing to do so,
# is covered soon.
#
# In addition to using different data directories, several other options must have different values for each server instance:
#
# 		) --port=<port_num>
#
# 			--port controls the port number for TCP/IP connections. Alternatively, if the host has multiple network addresses, you can use
# 			--bind-address to cause each server to listen to a different address.
#
# 		) --socket={<file_name> | <pipe name>}
#
# 			--socket controls the Unix socket file path on Unix or the named pipe name on Windows.
# 			On Windows, it is necessary to specify distinct pipe names only for those servers configured to permit named-pipe connections.
#
# 		) --shared-memory-base-name=<name>
#
# 			This option is used only on Windows. It designates the shared-memory name used by a Windows server to permit clients to connect
# 			using shared memory.
#
# 			It is necessary to specify distinct shared-memory names only for those servers configured to permit shared-memory connections.
#
# 		) --pid-file=<file_name>
#
# 			This option indicates the path name of the file in which the server writes its process ID.
#
# If you use the following log file options, their values must differ for each server:
#
# 		) --general_log_file=<file_name>
#
# 		) --log-bin[=<file_name>]
#
# 		) --slow_query_log_file=<file_name>
#
# 		) --log-error[=<file_name>]
#
# To achieve better performance, you can specify the following option differently for each server, to spread the load between
# several physical disks:
#
# 		) --tmpdir=<dir_name>
#
# Having different temporary directories also makes it easier to determine which MySQL server created any given temp file.
#
# If you have multiple MySQL installations in different locations, you can specify the base dir for each installation with
# the --basedir=<dir_name> option.
#
# This causes each instance to automatically use a different data dir, log files and PID file because the default for each
# of those params is relative to the base dir.
#
# In that case, the only other options you need to specify are the --socket and --port options.
#
# Suppose that you install different versions of MySQL using tar file binary distribs.
#
# These install in different locations, so you can start the server for each installation using the command bin/mysqld_safe under
# its corresponding base dir.
#
# mysqld_safe determines the proper --basedir option to pass to mysqld, and you need specify only the --socket and --port
# options to mysqld_safe.
#
# As discussed in the following sections, it is possible to start additional servers by specifying appropiate command options or
# by setting environment variables.
#
# However, if you need to run multiple servers on a more permanent basis, it is more convenient to use option files to
# specify for each server those option values that must be unique to it.
#
# The --defaults-file option is useful for this purpose.
#
# SETTING UP MULTIPLE DATA DIRS
#
# Each MySQL Instance on a machine should have its own data dir. 
#
# The location is specified using the --datadir=<dir_name> option.
#
# There are different methods of setting up a data dir for a new instance:
#
# 	) Create a new data dir
#
# 	) Copy an existing data dir
#
# WARNING:
#
# 		Normally, you should never have two servers that update data in the same DBs.
#
# 		This may lead to unpleasant suprises if your OS does not support faul-free system locking.
#
# 		If (despite warnings) you run multiple servers using the same data dir and they have logging
# 		enabled, you must use the appropiate options to specify log file names that are unique to each server.
#
# 		Otherwise, the servers try to log to the same files.
#
# 		Even when the preceding precautions are observed, this kind of setup works only with MyISAM and MERGE tables,
# 		and not with any of the other storage engines.
#
# 		Also, this warning against shared data dirs amongst servers always applies in an NFS environment.
# 		Permitting multiple MySQL servers to access a common data dir over NFS is <a terrible idea>
#
# 		The primary problem is that NFS is the speed bottleneck.
# 		It is not meant for such use. Another risk with NFS is that you must devise a way to ensure that
# 		two or more servers do not interfere with each other.
#
# 		Usually NFS file locking is handled by the lockd daemon, but at the moment there is no platform
# 		that performs locking 100% reliably in every situation.
#
# CREATE A NEW DATA DIR
#
# With this method, the data dir will be in the same state as when you first install MySQL.
# It will have the default set of MySQL accounts and no user data.
#
# On Unix, initialize the data dir.
#
# On Windows, the data dir is included in teh MySQL distrib:
#
# 	) MySQL Zip archive distribs for Windows contain an unmodified data dir. You can unpack such a distrib into a temp location, then
# 		copy the <data> dir to where you are setting up the new instance.
#
# 	) Windows MSI package installers createa nd set up the Data dir that the installed server will use, but also creates a pristine
# 		"template" data dir named <data> under the installation dir.
#
# 		After an installation has been performed using an MSA package, the template data dir can be copied to set up additional
# 		MySQL instances.
#
# COPY AN EXISTING DATA DIR
#
# With this method, any MySQL account or user data present in the data dir are carried over to the new data dir.
#
# 1. Stop the existing MySQL instance using the data dir. This must be a clean shutdown so that the instance flushes any pending changes to disk.
#
# 2. Copy the data dir to the location where the new data dir should be.
#
# 3. Copy the my.cnf or my.ini option file used by the existing instance. This serves as q basis for the new instance.
#
# 4. Modify the new option file so that any pathnames referring to the original data dir refer to the new data dir.
#
# 		Also, modify any other options that must be unique per instance, such as the TCP/IP port number and the log files.
#
# 5. Start teh new isntance, telling it to use the new option file.
#
# RUNNING MULTIPLE MySQL Instances on Windows
#
# You can run multiple servers on Windows by starting them manually from the cmd line, each with appropiate operating parameters,
# or by installing several servers as Windows services and running them that way.
#
# The following seciton pertains to how to start each server with different values for those options that must be unique
# per server, such as the data dir.
#
# STARTING MULTIPLE MySQL INSTANCES AT THE WINDOWS CMD LINE
#
# The procedure for starting a single MySQL server manually from the cmd line is refered to earlier.
#
# To start multiple servers this way, you can specify the appropiate options on the cmd line or in an option file.
# It is more convenient to place the options in an option file, but it is necessary to make sure that each server
# gets its own set of options.
#
# To do this, create an option file and tell the server the file name with a --defaults-file option when you run it.
#
# Suppose that you want to run one instance of mysqld on port 3307 with a data dir of C:\mydata1, and another instance on
# port 3308 with a data dir of C:\mydata2.
#
# Do as follows:
#
# 1. Make sure that each data dir exists, including its own copy of the mysql database that contains the grant tables.
#
# 2. Create two option files. For example, create one file named C:\my-opts1.cnf that looks as follows:
#
# 		[mysqld]
# 		datadir = C:/mydata1
# 		port = 3307
#
# Create a second file named C:\my-opts2.cnf that looks as:
#
# 		[mysqld]
# 		datadir = C:/mydata2
# 		port = 3308
#
# 3. Use the --defaults-file option to start each server with its own option file:
#
# 		C:\mysql\bin\mysqld --defaults-file=C:\my-opts1.cnf
# 		C:\mysql\bin\mysqld --defaults-file=C:\my-opts2.cnf
#
# 	Each server starts in the foreground (no new prompt appears until the server exit later), so you will need to issue those
# 	two commands in separate console windows.
#
# To shut down the servers, connect to each using the appropiate port number:
#
# 		C:\mysql\bin\mysqladmin --port=3307 --host=127.0.0.1 --user=root --password shutdown
# 		C:\mysql\bin\mysqladmin --port=3308 --host=127.0.0.1 --user=root --password shutdown
#
# Servers configured as just described permit clients to connect over TCP/IP.
#
# If your version of Windows supports named pipes and you also want to permit named-pipe 
# connections, specify options that enable the named pipe and specify its name.
#
# Each server that supports named-pipe connections must use a unique pipe name.
# For example, the C:\my-opts1.cnf file might be written as:
#
# 		[mysqld]
# 		datadir = C:/mydata1
# 		port = 3307
# 		enable-named-pipe
# 		socket = mypipe1
#
# Modify C:\my-opts2.cnf similarly for use by the second server. Then start the servers as showcased before.
#
# A similar procedure applies for servers that you want to permit shared-memory connections.
#
# Enable such connections with the --shared-memory option and specify a unique shared-memory name
# for each server with the --shared-memory-base-name option.
#
# STARTING MULTIPLE MYSQL INSTANCES AS WINDOWS SERVICES
#
# On Windows, a MySQL server can run as a Windows Service. The procedures for installing, controlling and removing
# a single MySQL service is described earlier.
#
# To set up multiple MySQL services, you must make sure that each instance uses a different service name in addition
# to the other params that must be unique per instance.
#
# For the following instructions, suppose that you want to run the mysqld server from two different versions of MySQL
# that are installed at C:\mysql-5.5.9 and C:\mysql-8.0.15 respectively.
#
# To install MySQL as a Windows Service, use the --install or --install-manual option.
#
# Based on the preceding information, you have several ways to set up multiple services.
#
# The following instructions descrieb some, before any of them - shut down and remove any existing MySQL services.
#
# 		) 1 -> Specify the options for all services in one of the standard option files.
#
# 				To do this, use a different service name for each server. Suppose that you want to run the
# 				5.5.9 mysqld using the service name of mysqld and the 8.0.15 mysqld using the service name mysqld2.
#
# 				In this case, you can use the [mysqld1] group for 5.5.9 and [mysqld2] group for 8.0.15.
#
# 				FOr example, you can set up C:\my.cnf like:
#
# 					#options for mysqld1 service
# 					[mysqld1]
# 					basedir = C:/mysql-5.5.9
#  				port = 3307
# 					enable-named-pipe
# 					socket = mypipe1
#
# 					#options for mysqld2 service
# 					[mysqld2]
# 					basedir = C:/mysql-8.0.15
# 					port = 3308
# 					enable-named-pipe
# 					socket = mypipe2
#
#  			Install the services as follows, using the full server path names to ensure that Windows registers the correct .exe for each service:
#
# 					C:\mysql-5.5.9\bin\mysqld --install mysqld1
# 					C:\mysql-8.0.15\bin\mysqld --install mysqld2
#
# 				To start the services, use the services manager or use NET START with the appropiate service names:
#
# 					NET START mysqld1
# 					NET START mysqld2
#
# 				To stop the services, use the services manager or use the NET STOP with the appropiate service names:
#
# 					NET STOP mysqld1
# 					NET STOP mysqld2
#
# 		) 2 -> Specify options for each server in separate files and use --defaults-file when you install the services to tell
# 					each server what file to use.
#
# 				In this case, each file should list options using a [mysqld]group.
#
# 				With this approach, to specify options for the 5.5.9 mysqld, create a file C:\my-opts1.cnf that looks like:
#
# 					[mysqld]
# 					basedir = C:/mysql-5.5.9
# 					port = 3307
# 					enable-named-pipe
# 					socket = mypipe1
#
# 				For the 8.0.15 mysqld, create a file C:\my-opts2.cnf that looks like this:
#
# 					[mysqld]
# 					basedir = C:/mysql-8.0.15
# 					port = 3308
# 					enable-named-pipe
# 					socket = mypipe2
#
# 				Install the services as follows (each command on a single line):
#
# 					C:\mysql-5.5.9\bin\mysqld --install mysqld1 --defaults-file=C:\my-opts1.cnf
# 					C:\mysql-8.0.15\bin\mysqld --install mysqld2 --defaults-file=C:\my-opts2.cnf
#
# 				When you install a MySQL server as a service and use a --defaults-file option, the service name must precede the option.
#
# 				After installing the services, start and stop them the same as before.
#
# To remove multiple services, use mysqld --remove for each one, specifying a service name following the --remove option.
# If the service name is the default (MySQL) you can omit it.
#
# RUNNING MULTIPLE MYSQL INSTANCES ON UNIX
#
# Note:
#
# 		The discussion here uses mysqld_safe to launch multiple instances of MySQL.
#
# 		For MySQL installation using an RPM distrib, server startup and shutdown is managed by systemd on several
# 		Linux platforms.
#
# 		On these platforms, mysqld_safe is not installed because it is unecessary.
#
# One way to run multiple MySQL instances on Unix is to compile different servers with different default TCP/IP 
# ports and Unix socket files so that each one listens on different network interfaces.
#
# Compiling in different base dirs for each installation also results automatically in a separate,
# compiled-in data dir, log file and PID file location for each server.
#
# Assuming that an existing 5.7 server is configured for the default TCP/IP port number (3306) and Unix socket file (/tmp/mysql.sock).
# To configure a new 8.0.15 server to have different operating Params, use a CMake akin to:
#
# 		cmake . -DMYSQL=port_number \
# 			 -DMYSQL_UNIX_ADDR=file_name \
# 			 -DCMAKE_INSTALL_PREFIX=/usr/local/mysql-8.0.15
#
# Here, <port_number> and <file_name> must be different from the default TCP/IP port number and Unix socket
# file path name, and the CMAKE_INSTALL_PREFIX value should specify an installation dir different from the one
# under which the existing MySQL installation is located.
#
# If you have a MySQL server listening on a given port number, you can use the following command to find out what 
# operating parameters it is using for several important configurable variables, including the base dir and Unix
# socket file name:
#
# 	mysqladmin --host=host_name --port=port_number variables
#
# With said info, you can conclude what options to NOT use when configuring a additional server.
#
# If you specify localhost as the host name, mysqladmin defaults to using a UNIX socket file connection
# rather than TCP/IP.
# 
# To explicitly specify the connection protocol, use the --protocol={TCP|SOCKET|PIPE|MEMORY} option.
#
# You need not compile a new MySQL server just to start with a different Unix socket file and TCP/IP port number.
# It is also possible to use the same server binary and start each invocation of it with different
# params of values at runtime.
#
# ONe way to do so is by using cmd line:
#
# mysqld_safe --socket=file_name --port=port_number
#
# To start a second server, provide different --socket and --port option values, and pass a --datadir=<dir_name> option to
# mysqld_safe so that the server uses a different data dir.
#
# Alternatively, put the options for each server in a different option file, then start each serer using a --defaults-file option
# that specifies the path to the appropiate rspective option file.
#
# For example, if the option files for two server instances are named /usr/local/mysql/my.cnf and /usr/local/mysql/my.cnf2, start the
# servers like:
#
# 		mysqld_safe --defaults-file=/usr/local/mysql/my.cnf
# 		mysqld_safe --defaults-file=/usr/local/mysql/my.cnf2
#
# Another way to achieve a similar effect is to use environment variables to set hte Unix socket file name and TCP/IP port number:
#
# 		MYSQL_UNIX_PORT=/tmp/mysqld-new.sock
# 		MYSQL_TCP_PORT=3307
# 		export MYSQL_UNIX_PORT MYSQL_TCP_PORT
# 		bin/mysqld --initialize --user=mysql
# 		mysqld_safe --datadir=/path/to/datadir &
#
# This is a quick way of startin a second server to use for testing.
#
# The nice thing about this method is that the env variable settings apply to any client programs
# that you invoke from the same shell.
#
# Thus, connections for those clients are automatically directed to the second server.
#
# on Unix, the mysqld_multi script provides another way to start multiple servers.
#
# USING CLIENT PROGRAMS IN A MULTIPLE-SERVER ENVIRONMENT
#
# To connect with a client program to a MySQL server that is listening to different network interfaces from those
# compiled into your client, you can use one of the following methods:
#
# 		) Start the client with --host=<host_name> --port=<port_number> to connect using TCP/IP to a remote server,
# 			--host=127.0.0.1 --port=<port_number> for TCP/IP to local
# 			--host=localhost --socket=<file_name> to a local server using a Unix socket file or a Windows named pipe.
#
# 		) Start the client with --protocol=TCP to connect using TCP/IP, --protocol=SOCKET to connect using a UNIX
# 			socket file, --protocol=PIPE to connect using a named pipe or --protocol=MEMORY to connect using shared memory.
#
# 			For TCP/IP connections, you may also need to specify --host and --port options.
#
# 			For the other types of connections, you may need to specify a --socket option to specify a Unix socket file
# 			or Windows named pipe name, or a --shared-memory-base-name option to specify the shared-memory name.
#
# 			Shared memory is only on Windows.
#
# 		) On Unix, set the MySQL_UNIX_PORT and MYSQL_TCP_PORT env variables to point to the Unix socket file and TCP/IP
# 			port number before you start your clients.
#
# 			If you normally use a specific socket file or port number, you can place commands to set these ENV variables
# 			in your .login files so that they apply each time you log in.
#
# 		) Specify the default Unix socket file and TCP/IP port number in the [client] group of an option file.
#
# 			FOr example, you can use C:\my.cnf on Windows, or the .my.cnf file in your home dir on Unix.
#
# 		) In a C program, you can specify the socket file or port number arguments in the mysql_real_connect() call.
# 			You can also have the program read option files by calling mysql_options()
#
# 		) If you are using the Perl DBD::mysql module, you can read options from MySQL option files. For example:
#
# 			$dsn = "DBI:mysql:test;mysql_read_default_group=client;"
# 						"mysql_read_default_file=/usr/local/mysql/data/my.cnf";
# 			$dbh = DBI->connect($dsn, $user, $password);
#
# Other programming interfaces provide similar capabilities for reading option files.
#
# SECURITY
#
# When thinking about security within a MySQL installation, you should consider a wide range of possible topics and how they
# affect the security of your MySQL server and related apps:
#
# 		) General factors that affect security. These include choosing good PWs, not granting unecessary privs, ensuring application
# 			security by preventing SQL injections and data corruption, etc.
#
# 		) Security of the installation itself. The data files, log files and all the application files of your installation should be
# 			protected to ensure that they are not readable or writable by unauthorized parties.
#
# 		) Access control and security within the database system itself, including the users and database granted with access to the DBs,
# 			views and stored programs in use within the DB.
#
# 		) The features offered by security-related plugins.
#
# 		) Network security of MySQL and your system. The security is related to the grants for individual users, but you may also
# 			wish to restrict MySQL so that it is available only locally on the MySQL server host or a limited set of other hosts.
#
# 		) Ensure that you have adequate and appropiate backups of your DB files, configuration and log files.
# 			Also, be sure that you have a recovery solution in place and test that you are able to successfully
# 			recover the info from your backups.
#
# GENERAL SECURITY ISSUES
#
# Security Guidelines
#
# In discussing security, it is necessary to consider fully protecting the entire server host (not just the MySQL server) against all types
# of applicable attacks: eavesdropping, alerting, playback and denial of service.
#
# MySQL uses security based on Access Control Lists (ACLs) for all connections, queries, and other operations that users can attempt to perform.
# There is also support for SSL-encrypted connections between MySQL clients and servers.
#
# WHen running MySQL, follow these guidelines:
#
# 		) Do not ever give anyone (except MySQL root accounts) access to the user table in the mysql system DB. Critical.
#
# 		) Keep an eye on privs. Use the GRANT and REVOKE statements to control access to MySQL. Do not grant more than necessary, never
# 			grant privs to all hosts.
#
# 				) Try mysql -u root. If you are able to connect successfully without being asked for a PW, anyone can connect to your MySQL
# 					as Root.
#
# 				) Use the SHOW_GRANTS statement to check which accounts have access to what. Then use the REVOKE statement to remove those privs that
# 					are not necessary.
#
# 		) Do not store cleartext PWs in your DB. If your computer becomes compromised, that's an issue.
#
# 			Use SHA2() or some other one-way hashing function and store the hash value.
#
# 		  To prevent PW recovery using rainbow tables, do not use these functions on a plain PW. Use something to be as as a salt,
# 			and go by the form of:
#
# 				hash(hash(password)+salt) 
#
# 		) Do not choose Pws from a Dictionary. Special programs exist to break PWs.
#
# 			Normal considerations of PW consolidation goes here.
#
# 		) Get a firewall. Put the MySQL behind a firewall or in a demilitarized zone (DMZ)
#
# 			) Try to scan your ports from the internet using a tool such as nmap.
#
# 				MySQL uses port 3306 by default.
#
# 				Should not be accessible by untrusted hosts. 
#
# 				Can be checked with: telnet <server_host> 3306 #Should refuse connection and give scrambles back.
#
# 		) Applications that access MySQL should not trust any data entered by users and should be written using proper defensive
# 			programming techniques.
#
# 		) Do not transmit unencrypted data over the Internet. 
#
# 			Use SSL or SSH. MySQL supports internal SSL connections. Another technique is to use SSH port-forwarding to
# 			create an encrypted (and compressed) tunnel for the communication.
#
# 		) learn to use the tcpdump and strings utilities. In most cases, you can check whether MySQL data streams are unencrypted by issuing
# 			a cmd like:
#
# 			tcpdump -l -i eth0 -w - src or dst port 3306 | strings
#
# 			Works under linux, should work under others with small modifications.
#
# 			Warning: If you do not see cleartext data, this does not mean that the info actually is encrypted. 
#
# 			If compression is in use on the connection (MYSQL_OPT_COMPRESS) you will not see plain text but the data is not encrypted.
#
# KEEPING PWS SECURE
#
# PWs occur in several contexts within MySQL.
#
# The following section pertains to guidelines that enable end users and admins to keep their PWs secure and avoid exposing them.
# In addition, the validate_password plugin can be used to enforce a policy on an acceptable PW.
#
# END-USER GUIDELINES FOR PW SECURITY
#
# When you run a client program to connect to the MySQL server, it is inadvisable to specify your PW in a way that exposes it
# to discovery by other users.
#
# The methods you can use to specify your PW when you run client programs are listed - along with an assesment of the risks
# of each method.
#
# In short, the safest methods are to have the client program prompt for the password or to specify the PW in a properly protected
# option file.
#
# 		) Use the mysql_config_editor utility, which enables you to store authentication credentials in an encrypted login path named
# 			.mylogin.cnf 
#
# 			The file can be read later by MySQL client programs to obtain authentication credentials for connecting to MySQL Server.
#
# 		) Use a -p<your_pw> or --password=<your_pass> option on the cmd line. For example:
#
# 			mysql -u francis -pfrank <db_name> #Do not write PWs on cmd prompt
#
# 			WARNING:
#
# 				This is insecure. On some systems, your PW becomes visible to System status programs such as ps that may be invoked by
# 				other users to display cmd lines.
#
# 				MySQL clients typically overwrite the cmd-line PW argument with 0's during their initialization sequence.
#
# 				However, there is a brief interval during which the value is visible.
#
# 				also, on some systems this overwritin strat is ineffective and the PW remains visible to ps. (SystemV Unix systems and perhas others are subject
# 				to this problem)
#
# 			If your operating environment is set up to display your current cmd in the title bar of your terminal window, the PW remains visible
# 			as long as the cmd is running, even if the cmd has scrolled out of view in the window content area.
#
# 		) Use the -p or --password option on the cmd line with no PW value specified. In this case, the client program solicits the PW interactively:
#
# 			mysql -u francis -p <db_name>
# 			Enter PW: 
#
# 			Use a options file instead.
#
# 			it is more secure to enter your PW like this than to specify it on the cmd line because it is not visible to other users.
# 			However, this method of entering a PW is suitable only for programs that you run interactively.
#
# 			If you want to invoke a client from a script that runs noninteractively, there is no opportunity to enter the PW
# 			from the keyboard.
#
# 			On some systems, you may even find that the first line of your script is read and interpreted (incorrectly) as your PW.
#
# 		) Store your PW in an option file. For example, on Unix, you can list your PW in the [client] section of the .my.cnf file in your home dir:
#
# 				[client]
#	 			password=your_pass
#
# 			To keep the PW safe, the file should not be accessible to anyone but yourself.
#
# 			To ensure this, set the file masking to 400 or 600, for example:
#
# 				chmod 600 .my.cnf
#
# 			To name from the cmd line a specific option file containing the PW, use the --defaults-file=<file_name> option,
# 			where file_name is the full path name to the file.
#
# 			For example:
#
# 				mysql --defaults-file=/home/francis/mysql-opts
#
# 		) Store your PW in the MYSQL_PWD env variable.
#
# 			This method of specifying your MySQL PW must be considered extremely insecure and dshould not be used.
#
# 			Some versions of pw include an option to display the ENV vars of the running process.
# 			On some systems, if you set MYSQL_PWD, your PW is exposed to any other user who runs ps.
#
# 			Even on systems without such a version of ps, it is unwise to assume that it's safe, as in, being non able to be inspected.
#
# On Unix, the mysql client writes a record of executed statements to a history file.
# By default, this file is named .mysql_history and is created in your home dir.
#
# PWs can be written as plain text in SQL statements such as CREATE_USER and ALTER_USER, so if you use these statements they are
# logged in the history file.
#
# TO keep this file safe, use a restrictive access mode, teh same way as described earlier for the .my.cnf file
#
# If your command interpreter is configured to maintain a history, any file in which the commands are saved will contain
# MySQL pws entered on the cmd line.
#
# For example, bash uses ~/.bash_history. Any such file should have a restrictive access mode.
#
# ADMINISTRATION GUIDELINES FOR PW SECURITY
#
# Database administrators should use the following guidelines to keep PWs secure.
#
# MySQL stores PWs for user accounts in the mysql.user table. Access to this table should never be granted to any non-admins.
#
# Account PWs can be expired so that users must reset them.
#
# The validate_password plugin can be used to enforce a policy on acceptable PWs.
#
# A user who has access to modify the plugin dir (the value of the plugin_dir SYS_VAR) or the my.cnf file that specifies
# the plugin dir location can replace plugins and modify the capabilities provided by plugins, including authentication plugins.
#
# Files such as log files to which PWs might be written should be protected.
#
# PASSWORDS AND LOGGING
#
# Passwords can be written as plain text in SQL statements such as CREATE_USER, GRANT and SET_PASSWORD.
# If such statements are logged by the MySQL server as written, PWs in them become visible to anyone with access
# to the logs.
#
# Statement logging avoids writing Pws in cleartext for hte following statements:
#
# 		CREATE USER ... IDENTIFIED BY ... 
# 		ALTER USER ... IDENTIFIED BY ...
# 		SET PASSWORD ...
# 		SLAVE START ... PASSWORD = ...
# 		CREATE SERVER ... OPTIONS(... PASSWORD ...)
# 		ALTER SERVER ... OPTIONS(... PASSWORD ...)
#
# Passwords in those statements are rewritten to not appear literally in statement text written to the general query log,
# slow log and binary log.
#
# Rewriting does not apply to other statements.
#
# In particular, INSERT or UPDATE statements for the mysql.user table that refer to literal PWs are logged as is,
# so you should avoid such statements. (Direct modification of grant tables is discouraged, anyway)
#
# For the general query log, password rewriting can be suppressed by starting the server with the --log-raw option.
# For security reasons, this option is not recommended for production use.
#
# For diagnostic purposes, it may be useful to see the exact text of statements as received by the server.
#
# By default, contents of audit log files produced by tthe audit log plugin are not encrypted and may contain
# sensitive information, such as the text of SQL statements.
#
# For security reasons, audit log files should be written to a directory accessible only to the MySQL server and to
# users with a legit reason to view the log.
#
# Statements received by the server may be rewritten if a query rewrite plugin is installed, in this case - the --log-raw
# option affects statements logging as follows:
#
# 		) without --log-raw, the server logs the statement returned by the query rewrite plugin. This may differ from the statement as received.
#
# 		) With --log-raw, the server logs the original statement as received.
#
# An implication of password rewriting is that statements that cannot be parsed (due, for example, to sytnax errors) are not written
# to the general query log because they cannot be known to be PW free.
#
# Use cases that require logging of all statements including those with errors should use the --log-raw option, bearing in mind that
# this also bypasses password rewriting.
#
# Password rewriting occurs only when plain text PWs are expected.
# For statements with syntax that expect a PW hash value, no rewriting occurs.
#
# if a plain text PW is supplied errorneously for such syntax, the pw is logged as given, without rewriting.
#
# To guard log files against unwarranted exposure, locate them in a directory that restricts access to the server
# and the database administrator.
#
# If the server logs to tables in the mysql database, grant access to those tables only to the DB admin.
#
# Replication salves store the PW for the replication master in the master info repostiory, which by default is a table
# in the mysql db named slave_master_info.
#
# The use of a file in the data dir for the master info repository is now deprecated.
# But still posible.
#
# Ensure that hte master info repository can be accseed only by the DB admin.
#
# An alternative to storing the PW in the master info repository is to use the START_SLAVE
# statement to specify credentials for connecting to the master.
#
# Use a restricted access mode to protect DB backups that include log tables or log files containing PWs.
#
# MAKING MYSQL SECURE AGAINST ATTACKERS
#
# When you connect to a MySQL server, you should use a PW. The PW is not transmitted in clear text over the connection.
#
# ALl other info is transferred as text, and can be read by anyone who is able to watch the connection.
#
# If the connection between the client and the server goes through an untrusted network, and you are
# concerned about this, you can use the compressed protocol to make traffic much more difficult to decipher.
#
# You can also use MySQL's internal SSL support to make the connection even more secure.
#
# Alternative, use SSH to get an encrypted TCP/IP conn between a MySQL server and a MySQL client.
#
# To make a MySQL system secure, you should strongly consider the following suggestions:
#
# 		) Require all MySQL accounts to have a PW. A client program does not necessarily know the identity of the person running it.
#
# 			It is common for client/server applications that the user can specify any user name to the client program.
#
# 			For example, anyone can use the mysql program to connect as any other person by simply invoking it as
# 			mysql -u <other_user> <db_name> if other_user has no PW.
#
# 			If all accounts have a PW, connecting using another user's acc becomes much more difficult.
#
# 		) Make sure that the onl Unix user acc with read or write privs in teh DB dirs is the acc used for running mysqld.
#
# 		) Never run the MySQL server as the Unix root user.
#
# 			This is dangerous,because any user with the FILE priv is able to cause the server to create files as root
# 			(For example ~root/.bashrc).
#
# 			To prevent this, mysqld refuses to run as root unless that is specified explicitly using the --user=root option.
#
# 			Mysqld can (and should) be run as an ordinary, unprived user instead.
#
# 			You can create a separate Unix acc named mysql to amek everything even more secure.
#
# 			Use this acc only for administrating MySQL.
#
# 			To start mysqld as a different Unix user, add a user option that specifies the user name in the 
# 			[mysqld] group of the my.cnf option file where you specify server options.
#
# 			For example:
#
# 				[mysqld]
# 				user=mysql
#
# 			This causes hte server to start as the designated user whether oyu start it manually or by using mysqld_safe or mysql.server
#
# 			Running mysqld as Unix user other than root does not mean you need to  change the root user name in teh user table.
# 			User names for MySQL accs have nothing to do with user names for Unix accs.
#
# 		) Do not grant the FILE priv to nonadmin users. Any user that has this priv can write a file anywhere in the file system with the
# 			privs of teh mysqld daemon.
#
# 			this includes teh server's data dir containing the files that implement the priv tables.
#
# 			To make FILE priv ops a bit safer, files generated with SELECT_..._INTO_OUTFILE do not overwrite existing files and are writable
# 			by everyone.
#
# 			The FILE priv may also be used to read any file that is world-readable or accesible to the unix user
# 			that hte server runs as.
#
# 			With this priv, you can read any file into the DB tables. This could be abused, by using LOAD_DATA to load /etc/passwd into a table,
# 			which then can be displayed with SELECT.
#
# 			To limit the location in which files can be read and written, set the secure_file_priv System to a specific dir.
#
# 		) Do not grant the PROCESS or SUPER priv to nonadmins.
#
# 			The output of mysqladmin processlist and SHOW_PROCESSLIST shows the text of any stratements currently being
# 			executed, so any user who is permitted to see the server process list might be able to see statements
# 			issued by other users.
#
# 			mysqld reseves an extra connection for users who have the CONNECTION_ADMIN or SUPER Priv, so that a MySQL root
# 			can log in and check server activity even if all normal connections are in use.
#
# 			The SUPER priv can be used to terminate client connections, change server operation by changing the value of SYS_VARs,
# 			and control replication servers.
#
# 		) Do not permit the use of symlinks to tables. (This capability can be disabled with the --skip-symbolic-links option).
#
# 			This is especially important if you run mysqld as root, because anyone that has write access to the server
# 			data dir then could delete any file in teh system
#
# 		) Stored programs and views should be written using the security guidelines seen later
#
# 		) If you do not trust your DNS, you should use IP addresses rather than host names in teh grant tables.
#
# 			IN any case, you should be very careful about creating grant tables entires using host name values that
# 			contain wildcards.
#
# 		) If you want to restrict the number of connections permitted to a single account, you can do so by setting the max_user_connections
# 			variable in mysqld.
#
# 			The CREATE_USER and ALTER_USER statements also support resource control options for limiting the extent of server use
# 			permitted to an account.
#
# 		) If the plugin dir is writable by the server, it may be possible for a user to write executable code to a file in the 
# 			dir using SELECT_..._INTO_DUMPFILE
#
# 			This can be prevented by making plugin_dir read only to the server or by setting --secure-file-priv to a dir where SELECT
# 			writes can be made safely.
#
# SECURITY-RELATED MYSQLD OPTIONS AND VARIABLES
#
# The following table showcases the mysqld options and system variables that affect security.
#
# 				Name 					Cmd 	Option Sys_Var  Status_var Var_SCope Dynamic
# allow-suspicious-udfs 		yes 	yes	 
# automatic_sp_privileges 						 Yes 						Global 	 Yes
# chroot 							yes   yes 
# des-key-file 					yes 	yes 
# local_infile 									 yes 						Global 	 Yes
# old_passwords 									 yes 						Both 		 Yes
#
# safe-user-create 				yes   Yes 
# secure-auth 						yes   yes 								Global 	  Yes
# - Variable: secure_auth  					 Yes 						Global 	  Yes
# secure-file-priv 				Yes 	Yes 								Global     No
# - Variable: secure_file_priv 				 Yes 						Global 	  No
#
# skip-grant-tables 				Yes 	Yes 								
# skip-name-resolve 				Yes 	Yes 								Global 		No
# - Variable: skip_name_resolve 				 Yes 						Global 	  No
# skip-networking 				Yes 	Yes 								Global 	  No
# - Variable: skip_networking 				 Yes 						Global 	  No
# skip-show-database 			Yes 	Yes 								Global 	  No
# - Variable: skip_show_database 			 Yes 						Global 	  No
#
# HOW TO RUN MYSQL AS A NORMAL USER
#
# On Windows, you can run the server as a Windows service using a normal user acc.
#
# On Linux, for installations performed using a MySQL repository or RPM packages, teh MySQL
# server mysqld should be started by the local mysql OS user.
#
# Starting by another OS user is not supported by the init script that are included as part of the
# MySQL repos.
#
# On Unix (or Linux for installations performed using tar.gz packages), teh MySQL server mysqld can be
# started and run by any user.
#
# However, you should avoid running the server as the Unix root user for security reasons.
#
# To change mysqld to run as a normal unprived Unix user <user_name>, you must do:
#
# 		1. Stop the server if it is running (use mysqladmin shutdown)
#
# 		2. Change the DB dirs and files so that <user_name> has privs to read and write files in them
# 			(you might need to do this as the Unix root user):
#
# 				chown -R <user_name> /path/to/mysql/datadir
#
# 			If you do not do this, teh server will not be able to access DBs or tables when it runs as <user_name>
#
# 			If dirs or files within teh MySQL data dir are symbolic links, chown -R might not follow symbolic links for you.
# 			If it does not, you will also need to follow those links and change the dirs and files they point to.
#
# 		3. Start the server as user <user_name>. ANother alternative is to start mysqld as the Unix root user and use
# 			the --user=<user_name> option.
#
# 			mysqld starts up, then switches to run as the Unix user <user_name> before accepting any connections.
#
# 		4. To start the server as the given user automatically at system startup time, specify the user name by adding
# 			a user option to the [mysqld] group of the /etc/my.cnf option file or the my.cnf option file in the server's
# 			data dir.
#
# 			For example:
#
# 				[mysqld]
# 				user=user_name
#
# If your Unix machine itself is not secured, you should assign PWs to the MySQL root account in the grant tables.
#
# Otherwise, any user with a login account on that machine can run the mysql client with a --user=root option
# and perform any operation.
#
# (It is a good idea to assign PWs to MySQL accs in any case, but especially so when other login accs exist
# on the server host)
#
# SECURITY ISSUES WITH LOAD DATA LOCAL
#
# The LOAD_DATA statement can load a file located on the server host, or if the LOCAL keyword is specified, on the client host.
#
# There are two potentional security issues with the LOCAL version of LOAD_DATA:
#
# 		) The transfer of the file from client host to the server host is initiated by the MySQL server. 
#
# 			In theory,a patched server could be built that would tell the client program to transfer a file of the server's
# 			choosing rather than the file named by the client in the LOAD_DATA statement.
#
# 			Such a server could access any file of the client host to which the user has read acces.
#
# 			(A patched server could in fact reply with a file-transfer request to any statement, not just LOAD_DATA_LOCAL,
# 			so a more fundamental issue is that clients should not connect to untrusted servers.)
#
# 		) In a Web environment where the clients are connecting from a Web server, a user could LOAD_DATA_LOCAL to read
# 			any files that the Web server process has read access to (assuming that a user could run any statement against
# 			the SQL server).
#
# 			In this environment, the client with respect to the MySQL server actually is the Web server, not a remote
# 			program being run by users who connect to the Web server.
#
# To avoid LOAD_DATA issues, clients should avoid using LOCAL.
#
# To avoid connecting to untrusted servers, clients can establish a secure connection and verify the server
# identity by connecting using the --ssl-mode=VERIFY_IDENTITY option and the appropiate CA certificate.
#
# To enable admin and applications to manage the local data loading capability, LOCAL configuration works like this:
#
# 		) On teh server side:
#
# 			) The local_infile SYS_VAR controls server-side LOCAL capability.
# 				Depending on the local_infile setting, teh server refuses or permits local data loading by clients
# 				that have LOCAL enabled on the client side.
#
# 				By default, local_infile is disabled.
#
# 			) To explicitly cause the server to refuse or permit LOAD_DATA_LOCAL statements (regardless of how client programs
# 				and libraries are configured at build time or runtime), start mysqld with local_infile disabled or enabled,
# 				respectively.
#
# 				local_infile can also be set at runtime.
#
# 		) On the client side:
#
# 			) The ENABLED_LOCAL_INFILE CMake option controls the compiled-in default LOCAL capability for the MySQL client lib.
# 				Cliens that make no explicit arrangements therefore have LOCAL capability disabled or enabled according to
# 				the ENABLED_LOCAL_INFILE setting specified at MySQL build time.
#
# 				By default, the client lib in MySQL binary distribs is compiled with ENABLED_LOCAL_INFILE disabled.
# 				If you compile MySQL from source, configure it with ENABLED_LOCAL_INFILE disabled or enabled based on
# 				whether clients clients that make no explicit arrangements should have LOCAL capability disabled or enabled, resp..
#
# 			) Client programs that use the C API can control load data loading explicitly by invoking mysql_options() to disable or 
# 				enable the MYSQL_OPT_LOCAL_INFILE option.
#
# 			) For the Mysql client, local data loading is disabled by default. To disable or enable it explicitly, use the
# 				--local-infile=0 or --local-infile[=1] option.
#
# 			) For the mysqlimport client, local data loading is disabled by default. To disable, or enable it explicitly,
# 				use the --local=0 or --local[=1] option.
#
# 			) If you use LOAD_DATA_LOCAL in Perl scripts or other programs that read the [client] group from option files,
# 				you can add an local-infile option setting to that group.
#
# 				To prevent problems for programs that do not understand this option, specify it using the loose- prefix:
#
# 					[client]
# 					loose-local-infile=0
# 			
# 				or:
#
# 					[client]
# 					loose-local-infile=1
#
# 			) In all cases, successful use of a LOCAL load by a client requires that hte server eprmits it.
#
# If LOCAL capability is disabled, on either server or clietn side, a client that attempts to issue a LOAD_DATA_LOCAL statement
# receives the following error message:
#
# 		ERROR 1148: The used command is not allowed with this MySQL verison
#
# CLIENT PROGRAMMING SECURITY GUIDELINES
#
# Applications that access MySQL should not trust any data entered by users, who can try to trick your code by entering special or escaped
# char sequences in Web forms, URLs or whathever app you have built.
#
# Be sure that your application remains secure if a user enters something like ; DROP DATABASE mysql;
# This is an extreme example, but large security leaks and data loss might occur as a result of hackers using similar techniques,
# if you do not prepare for them.
#
# A common mistake is to protect only string data values. 
#
# Rmember to check numeric data as well. If an application generates a query such as SELECT * FROM table WHERE
# ID=234 when a user enters the value 234, the user can enter the value 234 OR 1=1 to cause the aplication to generate the
# query SELECT * FROM table WHERE ID=234 OR 1=1
#
# as a result, the server retrieves every row in the table.
#
# This exposes every row, and causes excessive server load.
# The simplest way to protect from this type of attack is to use a single quotation mark
# around the numeric constants:
#
# SELECT * FROM table WHERE ID='234'
#
# If the user enters extra info, it all becomes part of the string.
#
# In a numeric context, MySQL automatically converts that string to a number and strip any trailining nonnumeric chars from it.
#
# Sometiems people think that if a DB contains only publicly available data, it need not be protected.
# This is wrong.
#
# Even if it is permissible to display any row in the DB, you should still protect against denial of service attacks
# (for example, those that are based on the technique in the preceding paragraph that cause the server to waste resources)
#
# otherwise, your server becomes unresponsive.
#
# Checklist:
#
# 		) Enable strict SQL mode to tell the server to be more restrictive of what data values it accepts.
#
# 		) Try to enter single and double quotation marks (' and ") in all of your Web forms. If you get any kind of MySQL error, investigate
# 			the problem.
#
# 		) Try to modify dynamic URLs by adding %22("),%23(#) and %27(') to them.
#
# 		) Try to modify data types in dynamic URLs from numeric to char types using the chars shown in the previous example.
# 			Your application should be safe against these and similar attacks.
#
# 		) Try to enter characters, spaces and special symbols rather than numbers in numeric fields.
#
# 			Your application should remove thhem before passing them to MySQL or else generate an error.
#
# 			Passing unchecked values to MySQL is very dangerous.
#
# 		) Check the size of data before passing it to MySQL.
#
#		) Have your application connect to the DB using a user name different from the one you use for the admin purposes.
# 			Do not give your application any access privs they do not need.
#
# Many application programming interfaces provide a means of escaping special characters in data values.
#
# Properly used, this prevents application users from entering values that cause teh application to
# generate statements that have different effect than you intended:
#
# 		) MySQL C API: Use the mysql_real_escape_string_quote() API call
#
# 		) MySQL++: Use the escape and quote modeifiers for query streams
#
# 		) PHP: use either the mysqli or pdo_mysql extensions, and not hte older ext/mysql extension.
# 				The preferred APIs support the improved MySQL authentication protocol and PWs, as well as 
# 				prepared statements with placeholders.
#
# 				If the older ext/mysql extension must be used, then for escaping use the mysql_real_escape_string_quote()
# 				function and not mysql_escape_string() or addslashes() because only mysql_real_escape_string_quote() is
# 				character set-aware: the other functions can be "bypassed" when using (invalid) multibyte char sets.
#
# 		) Perl DBI: Use placeholders or the quote() method
#
# 		) Ruby DBI: Use placeholders or teh quote() method
#
# 		) Java JDBC: Use a PreparedStatement object and placeholders.
#
# etc.
#
# THE MYSQL ACCESS PRIVILEGE SYSTEM:
#
# The primary function of the MySQL privlege system is to authenticate a user who connects from a given host and to associate
# that user with privs on a database such as SELECT, INSERT, UPDATE, and DELETE.
#
# Additionally, functionality includes the ability to have anonymous users and to grant privs for MySQL-specific functions
# such as LOAD_DATA_INFILE and administrative operations.
#
# There are some things that you cannot do with the MySQL privilege system:
#
# 		) You cannot explicitly specify that a given user should be denied access.
# 			That is, you cannot explicity match a user and then refuse the connection.
#
# 		) You cannot specify that a user has privileges to create or drop tables in a database but not to create or drop the DB itself.
#
# 		) A PW applies globally to an account. You cannot associate a Pw with a specific object such as a database, table or routine.
#
# The user interface to the MySQL priv system consists of SQL statements such as CREATE_USER, GRANT and REVOKE.
#
# Internally, the server stores privs information in the grant tables of the mysql system database (that is, in the database named mysql).
# The MySQL server reads teh content of these tables into memory when it starts and base access-control decisions on the in-memory copies
# of the grant tables.
#
# The MySQL priv system ensures that all users may perform only the operations permitted to them.
# As a user, when you connect to a MySQL server, your identity is determined by the host from which you connect and
# the user name you specify.
#
# When you issue requests after connecting, the system grants privileges according to your identity and what you want to do.
#
# MySQL Considers both your host name and user name in idetifying you because there is no reason to assume that a given
# user name belongs to the same person on all hosts.
#
# For example, the user Joe who connects from office.example.com need not be the same per as joe who connects from home.example.com
#
# Mysql handles this by enabling you to distinguish users on different hosts that happen to have the same name:
#
# 		you can grant one set of privs for connections by joe from office.example.com and a different
# 		set of privs for connections by joe from home.example.com
#
# 		To see what privs a given account has, use the SHOW_GRANTS statement, for example:
#
# 				SHOW GRANTS FOR 'joe'@'office.example.com';
# 				SHOW GRANTS FOR 'joe'@'home.example.com'; 			
# 
# MySQL access control involves two stages when you run a client program that connect to the server:
#
# 		Stage 1: The server accepts or rejects the connection based on your identity and whether you can verify your
# 					identity by supplying the correct PW.
#
# 		Stage 2: Assuming that you can connect, the server checks each statement you issue to determine whether you ahve sufficient
# 					privs to eprform it.
#
# 					For example, if you try to select rows from a table in a DB or dopr a table from the DB, the server verifies that
# 					you ahve the SELECT privs for the table or the DROP priv for the database.
#
# 					For a more detailed walkthrough of each stage, covered later.
#
# 					If your privleges are changed (either by yourself or someone else), while you are connected, those changes
# 					do not necesasrily take effect immediately for the next statement that you issue.
#
# PRIVILEGES PROVIDED BY MYSQL
#
# THe privileges granted to a MySQL account determine which operations the account can perform.
#
# MySQL privileges differ in the contexts in which they apply and at different levels of operation:
#
# 		) Administrative privs enable users to manage operation of the MySQL server. These privs are global because they
# 			are not specific to a particular DB.
#
# 		) Database Privs apply to a DB and to all objects within it. These privs can be granted for specific DBs, or globally so
# 			that they apply to all dbs.
#
# 		) Privs for db objects such as tables, indexes, views and stored routines can be granted for specific objects within a
# 			database, for all objects of a given type within a database (for example, all tables in a database) or globally
# 			for all objects of a given type in all DBs.
#
# Privileges also differ in terms of whether they are static (built in to the server) or dynamic (defined at runtime).
# Whether a priv is static or dynamic affects its availability to be granted to user accounts and roles.
#
# Information about account privs is stored in the grant tables in the mysql SYSTEM_DB.
# Covered more later.
#
# The MYSQL server reads teh contents of the grant tables into memory when it starts, and reloads
# them under the circumstances indicated later.
#
# The server bases access-control decisions on the in-memory copies of the grant tables.
#
# Important:
#
# 		Some MySQL releases introduce changes to the grant tables to add new privs or features.
# 		To make sure that you can take advantage of any new capabilities, update your grant
# 		tables to the current structure whenever you upgrade MySQL.
#
# The following sections summarize the available privs, provide more detailed desc of each priv, and offer usage guidelines.
#
# ) Summary of Available Privs
#
# ) Static Priv Desc
#
# ) Dynamic Priv Desc
#
# ) Priv-Granting guidelines
#
# SUMMARY OF AVAILABLE PRIVILEGES
#
# The following tables show the static privilege names used in GRANT and REVOKE statements, along with the COLUMN name associated
# with each priv in the grant tables and the context in which the priv applies.
#
# PERMISSIBLE STATIC PRIVS for GRANT and REVOKE
#
# Privilege 					Grant Table Column 				Context
# ALL_[PRIVILEGES] 			Synonym for "all privileges" 	Server Administration
# ALTER 							Alter_priv 							Tables
# ALTER_ROUTINE 				Alter_routine_priv 				Stored routines
# CREATE 						Create_priv 						Database, tables or Indexes
#
# CREATE_ROLE 					Create_role_priv 					Server administration
# CREATE_ROUTINE 				Create_routine_priv 				Stored routines
# CREATE_TABLESPACE 			Create_tablespace_priv 			Server administration
# CREATE_TEMPORARY_TABLES 	Create_tmp_table_priv 			Tables
#
# CREATE_USER 					Create_user_priv 					Server administration
# CREATE_VIEW 					Create_view_priv 					Views
# DELETE 						Delete_priv 						Tables
# DROP 							Drop_priv 							Databases, tables or views
#
# DROP_ROLE 					Drop_role_priv 					Server administration
# EVENT 							Event_priv 							Databases
# EXECUTE 						Execute_priv 						Stored routines
# FILE 							File_priv 							File access on server host
# GRANT_OPTION 				Grant_priv 							Databases, tables or stored routines
# INDEX 							Index_priv 							Tables
# INSERT 						Insert_priv 						Tables or Columns
#
# LOCK_TABLES 					Lock_tables_priv 					Databases
# PROCESS 						Process_priv 						Server Administration
# PROXY 							proxies_priv table 				Server administration
# REFERENCES 					References_priv 					Databases or Tables
# RELOAD 						Reload_priv 						Server administration
# REPLICATION_CLIENT 		Repl_cient_priv 					Server administration
#
# REPLICATION_SLAVE 			Repl_slave_priv 					Server administration
# SELECT 						Select_priv 						Tables or columns
# SHOW_DATABASES 				Show_db_priv 						Server administration
# SHOW_VIEW 					Show_view_priv 					Views
# SHUTDOWN 						Shutdown_priv 						Server admin
# SUPER 							Super_priv 							Server admin
# TRIGGER 						Trigger_priv 						Tables
# UPDATE 						Update_priv 						Tables or columns
# USAGE 							Synonym for "no privs" 			Server administration
#
# The following table shows the dynamic privlege names used in GRANT and REVOKE statements,
# along with the context in which the privilege applies.
#
# TABLE 6.3 PERMISSIBLE DYNAMIC PRIVILEGES for GRANT and REVOKE
#
# 			Privilege 				Context
#
# AUDIT_ADMIN 				 	Audit log administration
# BACKUP_ADMIN 				Backup administration
# BINLOG_ADMIN 				Backup and Replication Admin
# CONNECTION_ADMIN 			Server administration
#
# ENCRYPTION_KEY_ADMIN 			Server administration
# FIREWALL_ADMIN 					Firewall Administration
# FIREWALL_USER 					Firewall administration
# GROUP_REPLICATION_ADMIN 		Replication Administration
# PERSIST_RO_VARIABLES_ADMIN 	Server administration
#
# REPLICATION_SLAVE_ADMIN 		Replication administration
# RESOURCE_GROUP_ADMIN 			Resource group administration
# RESOURCE_GROUP_USER 			Resource group administration
# ROLE_ADMIN 						Server administration
# 
# SESSION_VARIABLES_ADMIN 		Server administration
# SET_USER_ID 						Server administration
# SYSTEM_VARIABLES_ADMIN 		Server administration
# VERSION_TOKEN_ADMIN 			Server administration
# XA_RECOVER_ADMIN 				Server administration
#
# STATIC PRIVILEGE DESCRIPTIONS
#
# Static privs are built in to the server, in contrast to dynamic privs, which are defined at runtime.
# The following list describes each static priv available in MySQL.
#
# particular SQL statements might have more specific priv requirements than indicated here.
# If so, the description for the statement in question provides the details.
#
# 		) ALL, ALL_PRIVILEGES
#
# 				These privilege specifiers are shorthand for "all privileges available at a given privilege leve"
# 				(except GRANT_OPTION).
#
# 				For example, granting ALL at the global or table level grants all global privs or all table-level privs, respectively.
#
# 		) ALTER
#
# 				Enables use of the ALTER_TABLE statement to change the structure of tables.
#
# 				ALTER_TABLE also requires the CREATE and INSERT privileges.
# 				Renaming a table requires ALTER and DROP on the old table, CREATE and INSERT on the new table.
#
# 		) ALTER_ROUTINE
#
# 				Enables use of statements that alter or drop stored routines (stored procedures and functions)
#
# 		) CREATE
#
# 				Enables use of statements that create new databases and tables
#
# 		) CREATE_ROLE
#
# 				Enables use of the CREATE_ROLE statement. (The CREATE_USER priv also enables use of the CREATE_ROLE statement)
#
# 		) CREATE_ROUTINE
#
# 				Enables use of statements that create stored routines (stored procedures and functions)
#
# 		) CREATE_TABLESPACE
#
# 				Enables use of statements that create, alter or drop tablespaces and log file groups.
#
# 		) CREATE_TEMPORARY_TABLES
#
# 				Enables the creation of temporary tables using the CREATE_TEMPORARY_TABLE statement.
#
# 				After a session has created a temporary table, the server performs no further privilege checks on the table.
#
# 				The creating session can perform any operation on the table, such as DROP_TABLE, INSERT, UPDATE or SELECT.
#
# 		) CREATE_USER
#
# 				Enables use of the ALTER_USER, CREATE_ROLE, CREATE_USER, DROP_ROLE, DROP_USER, RENAME_USER and REVOKE_ALL_PRIVILEGES statements.
#
# 		) CREATE_VIEW
#
# 				Enables use of the CREATE_VIEW statement.
#
# 		) DELETE
#
# 				Enables rows to be deleted from tables in a database.
#
# 		) DROP
#
# 				Enables use of statements that drop (remove) existing databases, tables and views.
#
# 				The DROP privilege is required to use the ALTER TABLE ... DROP PARTITION statement
# 				on a partitioned table.
#
# 				The DROP privilege is also required for TRUNCATE_TABLE
#
# 		) DROP_ROLE
#
# 				Enables use of the DROP_ROLE statement. (The CREATE_USER priv also enables use of the DROP_ROLE statement)
#
# 		) EVENT
#
# 				Enables use of statements that create, alter, drop or display events for the Event Scheduler.
#
# 		) EXECUTE
#
# 				Enables use of statements that execute stored routines (stored procedures and functions)
#
# 		) FILE
#
# 				Affects the following operations and server behaviors:
#
# 					) Enables reading and writing files on the server host using the LOAD_DATA_INFILE and SELECT_..._INTO_OUTFILE 
# 						statements and the LOAD_FILE() function.
#
# 						A user who has the FILE privilege can read any file on the server host that is either world-readable
# 						or readable by the MySQL server.
#
# 						(This implies that the user can read any file in any DB dir, because the server can access any of those files)
#
# 					) Enables creating new files in any directory where the MySQL server has write access.
# 						This includes the server's data dir containing the files that implement the privilege tables.
#
# 					) Enables use of the DATA DIRECTORY or INDEX DIRECTORY table option for the CREATE_TABLE statement.
#
# 				As a security measure, the server does not overwrite existing files.
#
# 				To limit the location in which files can be read and written, set the secure_file_priv SYS_VAR to a specific dir.
#
# 		) GRANT_OPTION
#
# 				Enables you to grant to or revoke from other users those privileges that you yourself possess.
#
# 		) INDEX
#
# 				Enables use of statements that create or drop (remove) indexes. INDEX applies to existing tables.
#
# 				If you have the CREATE privilege for a table, you can include Index definitions in the CREATE_TABLE statement.
#
# 		) INSERT
#
# 				Enables rows to be inserted into tables in a database. INSERT is also required for the ANALYZE_TABLE, OPTIMIZE_TABLE,
# 				and REPAIR_TABLE table-maintenance statements.
#
# 		) LOCK_TABLES
#
# 				Enables use of explicit LOCK_TABLES statements to lock tables for which you have the SELECT privilege.
#
# 				This includes use of write locks, which prevents other sessions from reading the locked table.
#
# 		) PROCESS
#
# 				Enables display of information about the threads executing within the server (that is, information about the
# 				statements being executed by sessions).
#
# 				The privilege enables use of SHOW_PROCESSLIST or mysqladmin processlist to see threads belonging to other accounts;
# 				you can always see your own threads.
#
# 				The PROCESS privilege also enables use of SHOW_ENGINE.
#
# 		) PROXY
#
# 				Enables one user to impersonate or become known as another user.
#
# 		) REFERENCES
#
# 				Creation of foreign key constraint requires the REFERENCES privilege for the parent table.
#
# 		) RELOAD
#
# 				Enables use of the FLUSH statement. 
# 				It also enables mysqladmin commands that are equivalent to FLUSH operations:
#
# 				flush-hosts, flush-logs, flush-privileges, flush-status, flush-tables, flush-threads, refresh and reload.
#
# 				The reload command tells the server to reload the grant tables into memory.
#
# 				flush-privileges is a synonym for real. The refresh command closes and reopens the log files and flushes all
# 				tables.
#
# 				The other flush-xxx commands perform functions similar to refresh, but are more specific and may be preferable
# 				in some instances.
#
# 				For example, if you want to flush just the log files, flush-logs is a better choice than refresh.
#
# 		) REPLICATION_CLIENT
#
# 				Enables use of the SHOW_MASTER_STATUS, SHOW_SLAVE_STATUS and SHOW_BINARY_LOGS statements.
#
# 				Grant this privilege to accounts that are used by slave servers to connect to the current server
# 				as their master.
#
# 		) REPLICATION_SLAVE
#
# 				Enables the account to request updates that have been made to databases on the master server.
#
# 				Grants this privilege to accounts that are used by slave servers to connect to the current server as their master.
#
# 		) SELECT
#
# 				Enables rows to be selected from tables in a database. SELECT statements require the SELECT privilege only if
# 				they actually access tables.
#
# 				Some SELECT statements do not access tables and can be executed without permission for any database.
#
# 				For example, you can use SELECT as a simple calculator to evaluate expresisons that make no reference to tables:
#
# 					SELECT 1+1;
# 					SELECT PI()*2;
#
# 				The SELECT privilege is also needed for other statements that read column values.
#
# 				For example, SELECT is needed for columns referenced on the right hand side of <col_name>=<expr> assignment
# 				in UPDATE statements or for columns named in the WHERE clause of DELETE or UPDATE statements.
#
# 				The SELECT privilege is needed for tables or views used with EXPLAIN, including any underlying
# 				tables in view definitions.
#
# 		) SHOW_DATABASES
#
# 				Enables the account to see database names by issuing the SHOW DATABASE statement.
#
# 				Accounts that do not have this privlege see only databases for which they have some privs, and cannot use
# 				the statement at all if hte server was started with the --skip-show-database option.
#
# 				(Any global priv is considered a priv for all database)
#
# 		) SHOW_VIEW
#
# 				Enables use of the SHOW_CREATE_VIEW satement. This priv is also needed for views used with EXPLAIN.
#
# 		) SHUTDOWN
#
# 				Enables use of the SHUTDOWN and RESTART statements, the mysqladmin shutdown command and the mysql_shutdown() C API function.
#
# 		) SUPER
#
# 				SUPER is a powerful qnd far-reaching privilege and should not be granted lightly.
#
# 				If an account needs to perform only a subset of SUPER operations, it may be possible to achieve the desired
# 				privlege set by instead granting one or more dynamic privs, each of which confers more limited capacities.
#
# 				NOTE: SUPER is deprecated.
#
# 				SUPER affects the following operations and server behaviors:
#
# 					) Enables system variable changes at runtime:
#
# 							) Enables server configuration changes to global system variables with SET_GLOBAL and SET_PERSIST.
#
# 								The corresponding dynamic priv is SYSTEM_VARIABLES_ADMIN
#
# 							) Enables setting restricted session system variables that require a special privilege.
#
# 								The corresponding dynamic priv is SESSION_VARIABLES_ADMIN
#
# 					) Enables changes to global transaction characteristics
#
# 						The corresponding dynamic priv is SYSTEM_VARIABLES_ADMIN
#
# 					) Enables the account to start and stop replication, including Group replication.
#
# 						The corresponding dynamic privlege is REPLICATION_SLAVE_ADMIN for regular replication, GROUP_REPLICATION_ADMIN for Group Replication.
#
# 					) Enables use of the CHANGE_MASTER_TO and CHANGE_REPLICATION_FILTER statements.
#
# 						The corresponding dynamic privlege is REPLICATION_SLAVE_ADMIN.
#
# 					) Enables binary log control by means of the PURGE_BINARY_LOGS and BINLOG statements.
#
# 						The corresponding dynamic priv is BINLOG_ADMIN.
#
# 					) Enables setting the effective authorization ID when executing a view or stored program.
#
# 						A user with this privlege can specify any account in the DEFINER attribute of a view or stored program.
#
# 						The corresponding dynamic privilege is SET_USER_ID.
#
# 					) Enables use of the CREATE_SERVER, ALTER_SERVER and DROP_SERVER statements.
#
# 					) Enables use of the mysqladmin debug command.
#
# 					) Enables InnoDB encryption key rotation.
#
# 						The corresponding dynamic privilege is ENCRYPTION_KEY_ADMIN
#
# 					) Enables execution of Version Tokens user-defined functions.
#
# 						The corresponding dynamic priv is VERSION_TOKEN_ADMIN.
#
# 					) Enables nonempty <graphml> element content in the result from the ROLES_GRAPHML() function.
#
# 						The corresponding dynamic priv is ROLE_ADMIN
#
# 					) Enables control over client connections not permitted to non-SUPER accounts:
#
# 						) Enables use of the KILL statement or mysqladmin kill command to kill threads belonging to other accounts.
# 							(An account can always kill its own threads)
#
# 						) The server does not execute init_connect SYS_VARs content when SUPER client connects.
#
# 						) The server accepts one connection from SUPER client even if the connection limit configured by the max_connections SYS_VAR is reached.
#
# 						) A server in offline mode (offline_mode enabled) does not terminate SUPER client connections at the next client request,
# 							and accepts new connections from SUPER clients.
#
# 						) Updates can be performed even when the read_only SYS_VAR is enabled. This applies to explicit table updates, and to use of account-management
# 							statements such as GRANT and REVOKE that update tables implicitly.
#
# 					The corresponding dynamic priv for the preceding connection-control operations is CONNECTION_ADMIN.
#
# 				The may also need the SUPER priv to create or alter stored functions if binary logging is enabled.
#
# 		) TRIGGER
#
# 			Enables trigger operations. You must have this privilege for a table to create, drop, execute or display triggers for that table.
#
# 			When a trigger is activated (by a user who has privs to execute INSERT, UPDATE or DELETE statements for the table associated with the
# 			trigger), trigger execution requires that the user who defined the trigger still have the TRIGGER priv for the table.
#
# 		) UPDATE
#
# 			Enables rows to be updated in tables in a DB.
#
# 		) USAGE
#
# 			This privlege specifier stands for "no privs". It is used at the global level with GRANT to specify clauses such as WITH GRANT OPTION without
# 			naming specific account privs in the priv list.
#
# 			SHOW_GRANTS displays USAGE to indicate that an account has no privileges at a priv level.
#
# DYNAMIC PRIVILEGE DESCRIPTIONS
#
# Dynamic privileges are defined at runtime, in contrast to static privileges, which are built in to the server.
# The following list describes each dynamic privilege available in MySQL.
#
# Most dynamic privileges are defined at server startup. Others are defined by a particular server component or plugin,
# as indicated in the privilege descriptions.
#
# In such cases, the privilege is unavailable unless the component or plugin that defines it is enabled.
#
# Particular SQL statements might have more specific privilege requirements than indicated here.
# If so, the description for the statement in question provides the details.
#
# 		) AUDIT_ADMIN
#
# 			Enables audit log configuration. This privilege is defined by the audit_log plugin.
#
# 		) BACKUP_ADMIN
#
# 			Enables execution of the LOCK_INSTANCE_FOR_BACKUP statement and access to the Performance Schema Log_status table.
#
# 			The BACKUP_ADMIN privilege is automatically granted to users with the RELOAD privilege when performing an in-place
# 			upgrade to MySQL 8.0 from an earlier version.
#
# 		) BINLOG_ADMIN
#
# 			Enables binary log control by means of the PURGE_BINARY_LOGS and BINLOG statements.
#
# 		) CONNECTION_ADMIN
#
# 			Enables use of the KILL statement or mysqladmin kill command to kill threads belonging to other accounts.
# 			(An account can always kill its own threads).
#
# 			Enables setting SYS_VAR related to client connections, or circumventing restrictions related to client connections.
# 			CONNECTION_ADMIN applies to the effects of these SYS_VARs:
#
# 				) Init_connect: The server does not execute init_connect SYS_VAR content when CONNECTION_ADMIN clients connect.
#
# 				) max_connections: The server accepts one connection from a CONNECTION_ADMIN client even if the connection limit 
# 											configured by the max_connections SYS_VAR is reached.
#
# 				) offline_mode: A server in offline mode (offline mode enabled) does not terminate CONNECTION_ADMIN client connections
# 										at the next client request, and accepts new connections from CONNECTION_ADMIN clients.
#
# 				) read_only: Updates can be performed even when the read_only SYS_VAR is enabled.
#
# 									This applies to explicit table updates, and to use of account-management statements such as GRANT and REVOKE
# 									that update tables implicitly.
#
# 		) ENCRYPTION_KEY_ADMIN
#
# 			Enables InnoDB encryption key rotation.
#
# 		) FIREWALL_ADMIN
#
# 			Enables a user to administer firewall rules for any user.
# 			This privilege is defined by the MYSQL_FIREWALL plugin.
#
# 		) FIREWALL_USER
#
# 			Enables users to update their own firewall rules.
# 			This privilege is defined by the MYSQL_FIREWALL plugin.
#
# 		) GROUP_REPLICATION_ADMIN
#
# 			Enables the account to start and stop GROUP REPLICATION. Grant this privilege to accounts that are used by slave servers to connect to the current server as their master.
#
# 		) PERSIST_RO_VARIABLES_ADMIN
#
# 			For users who also have SYSTEM_VARIABLES_ADMIN, PERSIST_RO_VARIABLES_ADMIN enables use of SET_PERSIST_ONLY to persist global system variables
# 			to the mysqld-auto.cnf option file in the data dir.
#
# 			This statement is similar to SET_PERSIST but does not modify the runtime global SYS_VAR rule.
#
# 			This makes SET_PERSIST_ONLY suitable for configuring read-only SYS_VARS that can be set only at server startup.
#
# 		) REPLICATION_SLAVE_ADMIN
#
# 			Enables the account to connect to the master server, start and stop replication, and use the CHANGE_MASTER_TO and
# 			CHANGE_REPLICATION_FILTER statements.
#
# 			Grant this priv to accounts that are used by slave servers to connect to the current server as their master.
#
# 			This priv does not apply to Group Replication; use GROUP_REPLICATION_ADMIN for that.
#
# 		) RESOURCE_GROUP_ADMIN
#
# 			Enables resource group management: Creating, Altering, and dropping resource groups; and assignment of threads and statements
# 			to resource groups.
#
# 			A user with this privilege can perform any operation relating to resource groups.
#
# 		) RESOURCE_GROUP_USER
#
# 			Enables assigning threads and statements to resource groups. A user with this priv can use the SET_RESOURCE_GROUP statement 
# 			and the RESOURCE_GROUP optimizer hint.
#
# 		) ROLE_ADMIN
#
# 			Enables use of the WITH ADMIN OPTION clause of the GRANT statement.
#
# 			Enables nonempty <graphml> element content in the result from the ROLES_GRAPHML() function.
#
# 		) SERVICE_CONNECTION_ADMIN
#
# 			Enables connections to the network interface that permits only administrative connections.
#
# 		) SESSION_VARIABLES_ADMIN
#
# 			For most SYS_VARs, setting the session value requires no special privileges and can be done by any user to affect
# 			the current session.
#
# 			For some system variables, setting the session value can have effects outside the current session and thus is a restricted
# 			operation.
#
# 			For these, the SESSION_VARIABLES_ADMIN privilege enables the user to set the session value.
#
# 			If a system variable is restricted and requires a special privilege to set the session value, the variable desc. indicates that
# 			restriction.
#
# 			Examples include - binlog_format, sql_log_bin and sql_log_off.
#
# 			SESSION_VARIABLES_ADMIN was added in MySQL 8.0.14.
#
# 			Prior to this, restricted session SYSTEM_VARIABLES can be set only by users who have the
# 			SYSTEM_VARIABLES_ADMIN or SUPER priv.
#
# 			The SESSION_VARIABLES_ADMIN priv is a subset of the SYSTEM_VARIABLES_ADMIN and SUPER privs.
#
# 			A user who has either of those privs is also permitted to set restricted session variables and
# 			effectively has SESSION_VARIABLES_ADMIN by implication and need not be granted SESSION_VARIABLES_ADMIN explicitly. 			
#
# 		) SET_USER_ID
#
# 			Enables setting the effective authorization ID when executing a view or stored program.
#
# 			A user with this priv can specify any account in the DEFINER attribute of a view or stored program.
#
# 		) SYSTEM_VARIABLES_ADMIN
#
# 			Affects the following operations and server behaviors:
#
# 				) Enables system variable changes at runtime:
#
# 					) Enables server configuration changes to global system variables with SET_GLOBAL and SET_PERSIST.
#
# 					) Enables server configuration changes to global system variables with SET_PERSIST_ONLY, if the user also has PERSIST_RO_VARIABLES_ADMIN.
#
# 					) Enables setting restricted session system variables that require a special privilege.
# 						In effect, SYSTEM_VARIABLES_ADMIN implies SESSION_VARIABLES_ADMIN without explicitly granting SESSION_VARIABLES_ADMIN.
#
# 				) Enables changes to global transaction characteristics.
#
# 		) VERSION_TOKEN_ADMIN
#
# 			Enables execution of Version Tokens user-defined functions. This privilege is defined by the version_tokens plugin.
#
# 		) XA_RECOVER_ADMIN
#
# 			Enables execution of the XA_RECOVER statement.
#
# 			Prior to MySQL 8.0, any user could execute the XA_RECOVER statement to discover the XID values for oustanding prepared XA transactions,
# 			possibly leading to commit or rollback of an XA transaction by a user other than the one who started it.
#
# 			In MySQL 8.0, XA_RECOVER is permitted only to users who have the XA_RECOVER_ADMIN privilege, which is expected to be granted
# 			only to administrative users who have need for it.
#
# 			This might be case, for example, for administrators of an XA application if it has crashed and it is necessary to find outstanding
# 			transactions started by the application so they can be rolled back.
#
# 			This privilege requirement prevents users from discovering the XID values for oustanding prepared XA transactions other than their own.
# 			It does not affect normal commit or rollback of an XA transaction because the user who started it knows its XID.
#
# PRIVILEGE-GRANTING GUIDELINES
#
# It is a good idea to grant to an account only those privileges that it needs.
# You should exercise particular caution in granting the FILE and administrative privileges:
#
# 		) FILE can be abused to read into a database table any files that hte MySQL server can read on the server host.
# 			This includes all world-readable files and files in the server's data directory.
#
# 			The table can then be accessed using SELECT to transfer its contents to the client host.
#
# 		) GRANT_OPTION enables users to give their privileges to other users. Two users that have different privileges and with the GRANT_OPTION privilege
# 			are able to combine privileges.
#
# 		) ALTER may be used to subvert the privilege system by renaming tables.
#
# 		) SHUTDOWN can be abused to deny service to other users entirely by terminating the server.
#
# 		) PROCESS can be used to view the plain text of currently executing statements, including statements that set or change PWs.
#
# 		) SUPER can be used to terminate other sessions or change how the server operates.
#
# 		) Privileges granted for the mysql system databse itself can eb used to change Passwords and otehr access privilege information:
#
# 			) Passwords are stored encrypted, so a malicious user cannot simply read them to know the plain text password.
#
# 				However, a user with write access to the mysql.user table authentication_string column can change an account password,
# 				and the connect to the MySQL server using that account.
#
# 			) INSERT or UPDATE granted for the mysql system database enable a user to add privileges or modify existing privileges, respectively.
#
# 			) DROP for the mysql system database enables a user to remote privilege tables, or even the database itself.
#
# An example of creating a concatenated table of different privileges and system variables in terms of privileges:
#
# SELECT password, host, user,
# CONCAT(Select_priv, Lock_tables_priv) AS selock,
# CONCAT(Insert_priv, Update_priv, Delete_priv, Create_priv, Drop_priv) AS modif,
# CONCAT(Grant_priv, References_priv, Index_priv, Alter_priv) AS meta,
# CONCAT(Create_tmp_table_priv, Create_view_priv, Show_view_priv) AS views, #Some of these names might be off in terms of updated privilege sectionings
# etc...
# FROM USER ORDER BY user, host;
#
# STATIC VERSUS DYNAMIC PRIVILEGES
#
# MySQL supports static and dynamic privileges:
#
# 		) Static privs are built into the server. They are always available to be granted to user accounts and cannot be unregistered.
# 
# 		) Dynamic privs can be registered and unregistered at runtime. This affects their availability: A dynamic priv that has not been registered cannot be granted.
#
# For example, the SELECT and INSERT privileges are static and always available, whereas a dynamic privilege becomes available
# only if the server component that implements it has been enabled.
#
# The remainder of this section describes how dynamic privs work in MySQL. The discussion uses the term "components" but it applies equally to plugins.
#
# 		NOTE: 
#
# 			Server admins should be aware of which server components define dynamic privs.
# 			For MySQL distribs, documentation of components that define dynamic privs describe those privs.
#
# 			Third-party components may also define dynamic privs; an admin should understand those privs and not install
# 			components that might conflict or compromise server operations.
#
# 			For example, one component conflicts with another if both define a priv with the same name.
# 			Component devs can reduce the likelihood of this occurence by choosing priv names having a prefix based on the component name.
#
# The server maintains the set of registered dynamic privs internally in memory. Unregistration occurs at server shutdown.
#
# Normally, a server component that defines dynamic privs registers them when it is installed, during its initialization sequence.
# When uninstalled, a server component does not unregister its registered dynamic privs.
#
# (This is current practice, not a requirement. That is, components could - but do not - unregister at any time privs they register)
#
# No warning or error occurs for attempts to register an already registered dynamic priv.
# Consider the following sequence of statements:
#
# 		INSTALL COMPONENT 'my_component';
# 		UNINSTALL COMPONENT 'my_component';
# 		INSTALL COMPONENT 'my_component';
#
# The first INSTALL_COMPONENT registers any privs defined by the server component my_component.
#
# But the UNINSTALL COMPONENT does not unregister them.
#
# For the second INSTALL_COMPONENT statement, the component privs it registers are found to be
# already registered, but no warnings or errors occur.
#
# Dynamic privs apply only at the global level.
#
# The server stores information about current assignments of dynamic privs to user accounts in the
# mysql.global_grants system table:
#
# 		) The server automatically registers privs named in global_grants during server startup (unless the --skip-grant-tables option is given)
#
# 		) The GRANT and REVOKE statements modify the contents of global_grants
#
# 		) Dynamic privs assignments listed in global_grants are persistent. They are not removed at server shutdown.
#
# Example : The following statement grants to user u1 the privileges required to control replication (including Group Replication) on a slave server,
# and to modify system variables:
#
# 		GRANT REPLICATION_SLAVE_ADMIN, GROUP_REPLICATION_ADMIN, BINLOG_ADMIN ON *.* TO 'u1'@'localhost';
#
# Granted dynamic privs appear in the output from the SHOW GRANTS statement and the INFORMATION_SCHEMA USER_PRIVILEGES table.
#
# For GRANT and REVOKE at the global level, any named privileges not recognized as static are checked against the current
# set of registered dynamic privs and granted if found.
#
# Otheriwse, an error occurs to indicate an unknown privilege identifier.
#
# For GRANT and REVOKE the meaning of ALL [PRIVS] at the global level includes all static global privs, as well as all currently
# registered dynamic privs:
#
# 		) GRANT ALL at the global level grants all static global privs and all currently registered dynamic privs.
# 			A dynamic priv registered subsequent to execution of the GRANT statement is not granted retroactively to any account.
#
# 		) REVOKE ALL at the global level revokes all granted static global privs and all granted dynamic privs.
#
# The FLUSH_PRIVILEGES statement reads the global_grants table for dynamic priv assignment and registers any unregistered privs found there.
#
# MIGRATING ACCOUNTS FROM SUPER TO DYNAMIC PRIVS
#
# In MySQL 8.0, many operations that previously required the SUPER priv are also associated with a dynamic priv of more limited scope.
#
# Each such operation can be permitted to an account by granting the associated dynamic priv rather than SUPER.
#
# This change improves security by enabling DBAs to avoid granting SUPER and tailor user privs more closely to the operations
# permitted.
#
# SUPER is deprecated, will be removed.
#
# When removal of SUPER occurs, operations that formerly required SUPER will fail unless accounts granted SUPER are migrated
# to the appropriate dynamic privs.
#
# Use the following instructions to accomplish that goal so that accounts are ready prior to SUPER removal:
#
# 		1. Execute this query to identify accounts that are granted SUPER:
#
# 				SELECT GRANTEE FROM INFORMATION_SCHEMA.USER_PRIVILEGES WHERE PRIVILEGE_TYPE = 'SUPER';
#
# 		2. For each account identified by the preceding query, determine the operations for which it needs SUPER.
#
# 			Then grant the dynamic privs corresponding to those operations, and revoke SUPER.
#
# 			For example, if 'u1'@'localhost' requires SUPER for binary log purging and SYS_VAR modification, these statements
# 			make the required changes to the account:
#
# 				GRANT BINLOG_ADMIN, SYSTEM_VARIABLES_ADMIN ON *.* TO 'u1'@'localhost';
# 				REVOKE SUPER ON *.* FROM 'u1'@'localhost';
#
# 			After said modifications the query in point 1. should return empty in terms of Querying the INFORMATION_SCHEMA.
#
# GRANT TABLES
#
# The mysql System database includes several grant tables that contain information about user accounts and the
# privs held by them.
#
# This section describes those tables.
#
# To manipulate the contents of grant tables, modify them indirectly by using account-management statements such as
# CREATE_USER, GRANT and REVOKE to set up accounts and control the privileges available to each one.
#
# The discussion here describes the underlying structure of the grant tables and how the server uses their
# contents when interacting with clients.
#
# NOTE:
#
# 		Direct modification of grant tables using statements such as INSERT, UPDATE or DELETE is didscouraged and done at your own risk.
# 		The server is free to ignore rows that become malformed as a result of such modifications.
#
# 		For any operation that modifies a grant table, the server checks whether the table has the expected structure and produces an
# 		error if not.
#
# 		mysql_upgrade must be run to update the tables to the expected structure.
#
# These mysql database tables contain grant information:
#
# 		) user: User accounts, global privs and other non-priv columns
#
# 		) global_grants: Assignments of dynamic global privileges to users
#
# 		) db: Database-level privileges
#
# 		) tables_priv: Table-level privs
#
# 		) columns_priv: Column-level privs
#
# 		) procs_priv: Stored procedure and function privs
#
# 		) proxies_priv: Proxy-user privs
#
# 		) default_roles: Default user roles
#
# 		) role_edges: Edges for role subgraphs
#
# 		) password_history: Password changes
#
# In MySQL 8.0, grant tables use the InnoDB storage engine and are transactional.
# Before MySQL 8.0, grant tables used the MyISAM storage engine and were nontransactional.
#
# This change of grant tables storage engine enables an accompanying change to the behavior of account-management statements 
# such as CREATE_USER or GRANT.
#
# Previously, an account-management statement that named multiple users could succeed for some users and fail for others.
#
# Now, each statement is transactional and either succeeds for all named users or rolls back and has no effect if any
# error occurs.
#
# Each grant table contains scope columns and privilege columns:
#
# 		) Scope columns determine the scope of each row in the tables; taht is, the context in which the row applies.
#
# 			For example, a user table row with Host and User values of 'h1.example.net' and 'bob' applies to authenticating
# 			connections made to the server from the host h1.example.net by a client that specifies a user name of bob.
#
# 			Similarly, a db table row with Host, User and Db column values of 'h1.example.net', 'bob' and 'reports' applies
# 			when bob connects from the host h1.example.net to access the reports database.
#
# 			The tables_priv and columns_priv tables contain scope columns indicating tables or table/column combinations
# 			to which each row applies.
#
# 			The procs_priv scope columns indicate the stored routine to which each row applies.
#
# 		) Privilege columns indicate which priv a table row grants; that is, which operations it permits to be performed.
#
# 			The server combines the information in the various grant tables to form a complete description of a user's privs.
#
# 			Rules described later.
#
# The server uses the grant tables in the following manner:
#
# 		) The user table scope columns determine whether to reject or permit incoming connections.
#
# 			For permitted connections, any privileges granted in the user table indicate the user's global privs.
# 			Any privileges granted in this table apply to all databases on the server.
#
# 				CAUTION: 
#
# 					Because any global privilege is considered a privilege for all databases, any global privilege enables a user to 
# 					see all database names with SHOW_DATABASES or by examining the SCHEMA table of INFORMATION_SCHEMA.
#
# 		) The global_grants table lists current assignments of dynamic privileges to user accounts.
#
# 		) The db table scope columns determine which users can access which databases from which hosts.
# 			The privilege columns determine the permitted operations.
#
# 			A privilege granted at the database level applies to the database and to all objects in teh database,
# 			such as tables and stored programs.
#
# 		) The tables_priv and columns_priv tables are similar to the db table, but are more fine-grained:
# 			They apply at the table and column levels rather than at the database level.
#
# 			A privilege granted at the table level applies to the table and to all its columns.
# 			A privilege granted at the column level applies only to a specific column.
#
# 		) The procs_priv table applies to stored routines (stored procedures and functions).
# 			A privilege granted at the routine level applies only to a single procedure or function.
#
# 		) The proxies_priv table indicates which users can act as proxies for other users and whether a user
# 			can grant the PROXY privilege to other users.
#
# 		) The default_roles and role_edges tables contain information about role releationships.
#
# 		) The password_history table retains previously chosen passwords to enable restrictions on password reuse.
#
# The server uses the user and db tables in the mysql database at both the first and second stages of access control.
# The columns in the user and db tables are shown as follows::
#
# TABLE NAME 					user 									db
#
# Scope COlumns 				Host 									Host
# 									User 									Db
# 																			User
#
# Privilege columns 			Select_priv 						Select_priv
# 									Insert_priv 						Insert_priv
# 									Update_priv 						Update_priv
# 									Delete_priv 						Delete_priv
#
# 									Index_priv 							Index_priv
# 									Alter_priv 							Alter_priv
# 									Create_priv 						Create_priv
# 									Drop_priv 							Drop_priv
# 									Grant_priv 							Grant_priv
# 									Create_view_priv 					Create_view_priv
#
# 									Show_view_priv 					Show_view_priv
# 									Create_routine_priv 				Create_routine_priv
# 									Alter_routine_priv 				Alter_routine_priv
# 									Execute_priv 						Execute_priv
# 									Trigger_priv 						Trigger_priv
#
# 									Event_priv 							Event_priv
# 									Create_tmp_table_priv 			Create_tmp_table_priv
# 									Lock_tables_priv 					Lock_tables_priv
# 									References_priv 					References_priv
#
# 									Reload_priv
# 									Shutdown_priv
# 									Process_priv
# 									File_priv
# 									Show_db_priv
# 									Super_priv
# 									Repl_slave_priv
#
# 									Repl_client_priv
# 									Create_user_priv
# 									Create_tablespace_priv
# 									Create_role_priv
# 									Drop_role_priv
#
# Security columns 			ssl_type
# 									ssl_cipher
# 									x509_issuer
# 									x509_subject
# 									plugin
# 									authentication_string
# 									password_expired
#
# 									password_last_changed
# 									password_lifetime
# 									account_locked
# 									Password_reuse_history
# 									Password_reuse_time
# 									Password_require_current
# 
# Resource control columns max_questions
# 									max_updates
# 									max_connections
# 									max_user_connections
#
# The user table plugin and authentication_string columns store authentication plugin and credential information.
#
# The server uses the plugin named in the plugin column of an account row to authenticate connection attempts for the account.
#
# The plugin column must be nonempty. At startup, and at runtime when FLUSH_PRIVILEGES is executed, the server checks user table rows.
# For any row with an empty plugin column, the server writes a warning to the error log of this form:
#
# [Warning] User entry 'user_name'@'host_name' has an empty plugin value.
# The user will be ignored and no one can login with this user anymore.
#
# The password_expired column permits DBAs to expire account PWs and require users to reset their password.
# The default password_expired value is 'N', but can be set to 'Y' with the ALTER_USER statement.
#
# After an account's password has been expired, all operations performed by the account in subsequent connections
# to the server result in an error until the user issues an ALTER_USER statement to establish a new account pw.
#
# It is possible after PW expiration to "reset" a PW by setting it to its current value.
# As a matter of good policy, it is preferable to choose a different PW.
#
# DBAs can enforce non-reuse by establishing an appropiate password-reuse policy.
#
# password_last_changed is a TIMESTAMP column indicating when the password was last changed.
#
# The value is non-NULL only for accounts that use a MySQL built-in authentication plugin (mysql_native_password,
# 	sha256_password or caching_sha2_password)
#
# The value is NULL for other accounts, such as those authenticated using an external authentication system.
#
# Password_last_changed is updated by the CREATE_USER, ALTER_USER and SET_PASSWORD statements, and by GRANT
# statements that create an account or change an account PW.
#
# password_lifetime indicates the account password lifetime, in days. 
#
# If the password is past its lifetime (assessed using the password_last_changed column), the server considers
# the password expired when clients connect using the account.
#
# A value of N greater than zero means that het PW must be changed every N days.
# A value of 0 disables automatic PW expiration.
#
# if the value is NULL (default), the global expiration policy applies, as defined by the default_password_lifetime
# SYS_VARs.
#
# account_locked indicates whether the haccount is locked.
#
# Password_reuse_history is the value of the PASSWORD_HISTORY option for the account, or NULL for the default history.
#
# Password_reuse_time is the value of the PASSWORD_REUSE_INTERVAL option for the account, or NULL for the default interval.
#
# Password_require_current (available as of MySQL 8.0.13), corresponds to the value of the PASSWORD REQUIRE option for
# the account.
#
# PASSWORD_REQUIRE_CURRENT value 		CORRESPONDING PASSWORD REQUIRE OPTION
#
# 'Y' 											PASSWORD REQUIRE CURRENT
#
# 'N' 											PASSWORD REQUIRE CURRENT OPTIONAL
#
# NULL 											PASSWORD REQUIRE CURRENT DEFAULT
#
# During the second stage of access control, the server performs request verification to ensure that each
# client has sufficient privs for each request that it issues.
#
# In addition to the user and db grant tables, teh server may also consult the tables_priv and columns_priv tables
# for requests that involve tables.
#
# The latter tables provide finer privilege control at the table and column levels.
# They have the columns shown in the following table.
#
# 
# Table Name 				TABLES_PRIV 				COLUMNS_PRIV
#
# Scope COlumns 			Host 							Host
# 								Db 							Db
# 								User 							User
# 								Table_name 					Table_name
# 																Column_name
# Privilege columns 		Table_priv 					Column_priv
# 								Column_priv
# Other columns 			Timestamp 					Timestamp
# 								Grantor
#
# The Timestamp and Grantor columns are set to the current timestamp and the CURRENT_USER value, respectively, but are otherwise
# unused.
#
# For verification of requests that involve stored routines, the server may consult the procs_priv table, which has the
# columns shown as follows:
#
# 		procs_priv TABLE COLUMNS
#
# 			Table Name 					procs_priv
#
# Scope columns 						Host
# 											Db
# 											User
# 											Routine_name
# 											Routine_type
#
# Privlege columns 					Proc_priv
# Other columns 						Timestamp
# 											Grantor
#
# The Routine_type column is an ENUM column with values of 'FUNCTION' or 'PROCEDURE' to indicate the type of
# routine the row refers to.
#
# This column enables privileges to be granted separately for a function and a procedure with the same name.
#
# The Timestamp and Grantor columns are unused.
#
# The proxies_priv table records information about proxy accounts. It has these columns:
#
# 		) Host, User: The proxy account; that is, the account that has the PROXY privilege for the proxied account.
#
# 		) Proxied_host, Proxied_user: The proxied account
#
# 		) Grantor, Timestamp: Unused.
#
# 		) With_grant: Whether the proxy account can grant the proxy privlege to other accounts.
#
# For an account to be able to grant the PROXY privs to otehr accounts, it must have a row in the proxies_priv table
# with With_grant set to 1 and Proxied_host and Proxied_user set to indicate the account or accounts for which
# the priv can be granted.
#
# For example, the 'root'@'localhost' account created during MySQL installation has a row in the proxies_priv table that
# enables granting the PROXY privs for ''@'', that is, for all users and all hosts.
#
# This enables root to set up proxy users, as well as to delegate to other accounts the authority to set up proxy users.
#
# The global_grants table lists current assignments of dynamic privileges to user accounts.
# These privileges are global.
#
# The table has these columns:
#
# 		) USER, HOST: The user name and host name of the account to which the priv is granted.
#
# 		) PRIV: The priv name
#
# 		) WITH_GRANT_OPTION: Whether the account can grant the privlege to other accounts.
#
# The default_roles table lists default user roles. It has these columns:
#
# 		) HOST, USER: The account or role to which the default role applies.
#
# 		) DEFAULT_ROLE_HOST, DEFAULT_ROLE_USER: The default role.
#
# The role_edges table lists edges for role subgraphs. It has these columns:
#
# 		) FROM_HOST, FROM_USER: The account that is granted a role.
#
# 		) TO_HOST, TO_USER: The role that is granted to the account.
#
# 		) WITH_ADMIN_OPTION: Whether the account can grant the role to and revoke it from other accounts by using WITH ADMIN OPTION.
#
# The password_history table contains information about password changes.
# It has these columns:
#
# 		Host, User: The account for which the password change occurred.
#
# 		Password_timestamp: The time when the password change occurred.
#
# 		Password: The new password hash value.
#
# The password_history table accumulates a sufficient number of nonempty PWs per account to enable MySQL to perform
# checks against both the acc PW history length and reuse interval.
#
# Automatic pruning of entries that are outside both limits occurs when password-change attempts occur.
#
# NOTE:
#
# 		The empty password does not count in the password history and is subject to reuse at any time.
#
# If an account is renamed, its entries are renamed to match. If an account is dropped or its authentication plugin is changed,
# its entries are removed.
#
# Scope columns in the grant tables contain strings. The default value for each is the empty string.
# The following table shows the number of characters permitted in each column.
#
# GRANT TABLE SCOPE COLUMN LENGTHS
#
# Column Name 					Maximum Permitted Characters
#
# Host, Proxied_host 		60
# User, Proxied_user 		32
# Db 								64
# Table_name 					64
# Column_name 					64
# Routine_name 				64
#
# For access-checking purposes, comparisons of User, Proxied_user, authentication_string, Db and Table_name values are case-sensitive.
#
# Comparisons of Host, Proxied_host, Column_name and Routine_name values are not case-sensitive.
#
# The user and db tables list each priv in a separate column taht is declared as ENUM('N','Y') DEFAULT 'N'.
# In other words, each privilege can be disabled or eanbled, with the default being disabled.
#
# The tables_priv, columns_priv and procs_priv tables declare the priv column as SET columns.
# Vlaues in these columns can contain any combination of the priv controlled by the table.
#
# Only those privs listed in the column value are enabled.
#
# Set-type priv column values
#
# 	TABLE NAME 			COLUMN NAME 				POSSIBLE SET ELEMENTS
#
# tables_priv 			Table_priv 				'Select', 'Insert', 'Update', 'Delete', 'Create',
# 														'Drop', 'Grant', 'References', 'Index', 'Alter',
# 														'Create View', 'Show view', 'Trigger'
#
# tables_priv 			Column_priv 			'Select', 'Insert', 'Update', 'References'
# 
# columns_priv 		Column_priv 			'Select', 'Insert', 'Update', 'References'
#
# procs_priv 			Proc_priv 				'Execute', 'Alter Routine', 'Grant'
#
# Only the user table specifies admin privs, such as RELOAD and SHUTDOWN.
#
# Admin operations are operations on the server itself and are not database-specific, so there is no reason
# to list these privs in the other grant tables.
#
# Consequently, the server need consult only the user table to determine whether a user can perform
# an administrative operation.
#
# The FILE priv also is specified only in the user table.
#
# It is not an administrative priv as such, but a user's ability to read or write files on the server host
# is independent of the DB being accesed.
#
# The server reads the contents of the grant tables into memory when it starts.
# You can tell it to reload the tables by issuing a FLUSH_PRIVILEGES statement or executing a mysqladmin flush-privileges or mysqladmin reload command.
#
# Changes to teh grant tables take effect as indicated.
#
# When you modify an account, it is a good idea to verify that your changes have the intended effect.
# To check the privs for a given account, use the SHOW_GRANTS statement.
#
# For example, to determine the privs that are granted to an account with user name and host name values of bob and pc84.example.com,
# use this statement:
#
# 		SHOW GRANTS FOR 'bob'@'pc84.example.com';
#
# To display nonpriv properties of an account, use SHOW_CREATE_USER:
#
# 		SHOW CREATE USER 'bob'@'pc84.example.com';
#
# SPECIFYING ACCOUNT NAMES
#
# MySQL account names consists of a user name and a host name.
# This enables creation of accounts for users with the same name who can connect from different hosts.
#
# This section describes how to write account names, including special values and wildcard rules.
#
# MySQL role names are similar to account names, with some differences.
#
# In SQL statements such as CREATE_USER, GRANT, and SET_PASSWORD account names follow these rules:
#
# 		) Account name syntax is 'user_name'@'host_name'
#
# 		) An account name consisting only of a user name is equivalent to 'user_name'@'%'.
#  	  For example, 'me' is equivalent to 'me'@'%'
#
# 		) The user name and host name need not be quoted if they are legal as unquoted identifiers.
# 			Quotes are necessary to specify a user_name string containing special chars (such as space or -)
#
# 			or a host_name string containing special characters or wildchar characters (such as . or %); for example,
# 			'test-user'@'%.com'
#
# 		) Quote user names and host names as identifiers or as strings, using either backticks (`), single quotation marks ('),
# 			or double quotation marks (")
#
# 			For string-quoting and identifier-quoting guidelines, see later.
#
# 		) The user name and host name parts, if quoted, must be quoted separately.
#
# 			That is, write 'me'@'localhost', not 'me@localhost'; the latter is equivalent to 'me@localhost'@'%'
#
# 		) A reference to the CURRENT_USER or CURRENT_USER() function is equivalent to specifying the current client's user name
# 			and host name literally.
#
# MySQL stores account names in grant tables in the mysql system database using separate columns for the user name and host name parts:
#
# 		) The user table contains one row for each account. The User and Host columns store the user name and host name.
#
# 			This table also indicates which global privileges the account has.
#
# 		) Other grant tables indicate privileges an account has for databases and objects within databases.
#
# 			These tables have User and Host columns to store the account name.
# 			Each row in these tables associates with the account in the user table that has the same User and Host  values.
#
# 		) For access-checking purposes, comparisons of User values are case-sensitive. Comparisons of Host values are not case sensiive.
#
# For additional detail about grant table structure, see earlier.
#
# User names and host names have certain special values or wildcard conventions, as described:
#
# The user name part of an account name is either a nonblank value that literally matches the user name for incoming connection attempts,
# or a blank value (empty string) that matches any user name.
#
# An account with a blank user name is an anonymous user. To specify an anon user in SQL statements, use a quoted empty user name part,
# such as ''@'localhost'
#
# The host name part of an account name can take many forms, and wildcards are permitted:
#
# 		) A host value can be a host name or an IP address (IPv4 or IPv6).
#
# 			The name 'localhost' indicates the local host. The IP address '127.0.0.1' indicates teh IPv4 loopback interface.
# 			The IP address '::1' is the IPv6 loopback interface.
#
# 		) The % and _ wildcard characters are permitted in host name or IP address values.
#
# 			These have the same meaning as for pattern-matching operations performed with the LIKE operator.
#
# 			For example, a host value of '%' matches any host name, whereas a value of '%.mysql.com' matches
# 			any host in the mysql.com domain.
#
# 			'198.51.100.%' matches any host in the 198.51.100 class C network.
#
# 			Because IP wildcard values are permitted in host values (for example '198.51.100.%' to match every host on a subset),
# 			someone could try to exploit this capability by naming a host 198.51.100.somewhere.com
#
# 			To foil such attempts, MySQL does not perform matching on host names that start with digits and a dot.
# 			For example, if a host is named 1.2.example.com, its name never matches the host part of account names.
#
# 			An IP wildcard value can match only IP addresses, not host names.
#
# 		) For a host value specified as an IPv4 address, a netmask can be given to indicate how many address bits to use for the
# 			network number.
#
# 			Netmask notation cannot be used for IPv6 addresses.
#
# 			The syntax is host_ip/netmask. For example:
#
# 				CREATE USER 'david'@'198.51.100.0/255.255.255.0';
#
# 			This enables david to connect from any client host having an IP address client_ip for which the following condition is true:
#
# 				client_ip & netmask = host_ip
#
# 			That is, for the CREATE_USER statement just shown:
#
# 				client_ip & 255.255.255.0 = 198.51.100.0
#
# 			IP addresses that satisfy this condition range from 198.51.100.0 to 198.51.100.255
#
# 			A netmask typically begins with bits set to 1, followed by bits set to 0. Examples:
#
# 				) 198.0.0.0/255.0.0.0: Any host on the 198 class A network
#
# 				) 198.51.100.0/255.255.0.0: Any host on the 198.51 class B network
#
# 				) 198.51.100.0/255.255.255.0: Any host on the 198.51.100 class C network
#
# 				) 198.51.100.1: Only the host with this specific IP address
#
# The server performs matching of host values in account names against the client host using the value returned
# by the system DNS resolver for the client host name or IP address.
#
# Except in the case that the account host value is specified using netmask notation, the server performs this comparison
# as a string match, even for an account host value given as an IP address.
#
# This means that you should specify account host values in the same format used by DNS.
# Here are examples of problems to watch out for:
#
# 		) Suppose that a host on the local network has a fully qualified name of host1.example.com
# 			If DNS returns name lookups for this host as host1.example.com, use that name in account host values.
#
# 			If DNS returns just host1, use host1 instead.
#
# 		) If the DNS returns the IP address for a given host as 198.51.100.2, that will match an account host value of 198.51.100.2
# 			but not 198.051.100.2
#
# 			Similarly, it will match a pattern of 198.51.100.% but not 198.051.100.%
#
# To avoid problems like these, it is advisable to check the format in which your DNS returns host names and addresses.
# Use values in the same format in MySQL account names.
#
# SPECIFYING ROLE NAMES
#
# MySQL role names refer to roles, which are named collections of privs.
# For role usage example, see later.
#
# Role names have syntax and semantics similar to account names (later).
# Role names differ from account names in these respects:
#
# 		) The user part of role names cannot be blank. Thus, there is no "anon role" analogous to the concept of "anon user".
#
# 		) As for an account name, omitting the host part of a role name results in a host part of '%'.
# 			But unlike '%' in an account name, a host part of '%' in a role name has no wildcard props.
#
# 			For example, for a name 'me'@'%' used as a role name, teh host part '%', the host part ('%'), is just a ltieral value - not a wildcard.
#
# 		) Netmask notation in the host part of a role name has no significance.
#
# 		) An account name is permitted to be CURRENT_USER() in several contexts. A role name is not.
#
# It is possible for a row in the mysql.user system table to serve as both an account and a role.
#
# In this case, any special user or host name matching properties do not apply in contexts for which
# the name is used as a role name.
#
# For example, you cannot execute the following statement with the expectation that it will set the current
# session roles using all roles that have a user part of myrole and any host name:
#
# 		SET ROLE 'myrole'@'%';
#
# Instead, the statement sets the active role for the session to the role with exactly the name 'myrole'@'%'
#
# For this reason, role names are often specified using only the user name part and letting the host name part implicitly
# be '%'.
#
# Specifying a role with a non '%' host part can be useful if you intend to create a name that works as both a role and a user account
# that is permitted to connect from the given host. 
#
# ACCESS CONTROL, STAGE 1: CONNECTION VERIFICATION
#
# When you attempt to connect to a MySQL server, the server accepts or rejects the connection based on these conditions:
#
# 		) Your identity and whether you can verify your identity by supplying the correct PW
#
# 		) Whether your account is locked or unlocked.
#
# The server checks credentials first, then account locking state. A failure fo either step causes the server to deny access to
# you completely.
#
# Otherwise, the server accepts the connection and then enters Stage 2 and waits for requests.
#
# Credential checking is performed using the three user table scope columns (Host, User and authentication_string).
# Locking state is recorded in the user table account_locked column.
#
# The server accepts the connection only if the Host and User columns in some User table row match the client host
# and user name, the client supplies the PW specified in that row, and the account_locked value is 'N'.
#
# The rules for permissible Host and User value are given later.
#
# Account locking can be changed with the ALTER_USER statement.
#
# Your identity is based on two pieces of information:
#
# 		) The client host from which you connect.
#
# 		) Your MySQL user name
#
# If the User column value is nonblank, the user name in an incoming connection must match exactly.
# If the User value is blank, it matches any user name.
#
# If the user table row that matches an incoming connection has a blank user name, the user is considered to be anon without a name,
# not a user with the name that the client actually specified.
#
# This means that a blank user name is used for all further access checking for the duration of the connection (Stage 2).
#
# The authentication_string column can be blank. This is not a wildcard and does not mean that any PW matches.
#
# It means that the user must connect without specifying a PW. If the server authenticates a client using a plugin,
# the authentication method that the plugin implements may or may not use the PW in the authentication_string column.
#
# In this case, it is possible that an external PW is also used to authenticate to the MySQL server.
#
# Nonblank authentication_string values in the user table represent encrypted PWs.
# MySQL does not store PWs in cleartext form for anyone to see.
#
# Rather, the PW supplied by a user who is attempting to connect is encrypted (using the PW hashing method implemented by the
# account authentication plugin).
#
# The encrypted PW then is used during the connection process when checking whether the PW is correct.
# This is done without the encrypted PW ever traveling over the connection.
#
# From MySQL's PoV, the encrypted PW is the real pw, so you should never give anyone access to it.
#
# In particular, do not give nonadmin users read access to tables in the mysql system db.
#
# The following table shows various combinations of User and Host values in teh User table apply to incoming connections.
#
# User Value  Host Value  		Permissible Connections
#
# 'fred' 	'h1.example.net' 	fred, connecting from h1.example.net
#
# '' 			'h1.example.net' 	Any user, connecting from h1.example.net
#
# 'fred' 	'%' 					fred, from any host
#
# '' 			'%' 					Any user, connecting from any host
#
# 'fred'  	'%.example.net' 	fred, any host in the example.net domain
#
# 'fred' 	'x.example.%' 		fred, from any x.example.<extension>, where <extension> is wildcarded
#
# 'fred' 	'198.51.100.177' 	fred, connecting from the host with IP address 198.51.100.177
#
# 'fred' 	'198.51.100.%' 	fred, from any host in the 198.51.100 class C subnet
#
# 'fred'		'198.51.100.0/255.255.255.0' - Same as previous
#
# It is possible for the client host name and user name of an incoming connection to match more than one row in the user table.
# The preceding set of examples demonstrates this: Several of the entries shown match a connection from h1.example.net by fred.
#
# When multiple matches are possible, the server must determine which of them to use.
# It resolves this issue as follows:
#
# 		) Whenever the server reads the user table into memory, it sorts the rows.
#
# 		) When a client attempts to connect, the server looks through the rows in sorted order.
#
# 		) The server uses the first row that matches the client host name and user name.
#
# The server uses sorting rules that order rows with the most specific Host values first.
# Literal host names and IP addresses are the most specific.
#
# (The specificity of a literal IP address is not affected by whether it has a netmask, so,
# 198.51.100.13 and 198.51.100.0/255.255.255.0 are considered equally specific)
#
# The pattern '%' means "any host" and is least specific.
#
# The empty string '' also means "any host" but sorts after '%'.
#
# Rows with the same Host value are ordered with the most-specific User values first
# (a blank User value means "any user" and is least specific).
#
# For rows with equally-specific Host and User values, the order is nondeterministic.
#
# To see how this works, suppose that the user table looks like this:
#
# 		+------------------+----------+-
# 		| Host 				 | User 		| ...
# 		+------------------+----------+-
# 		| % 					 | root 		| ...
# 		| % 					 | jeffrey 	| ...
# 		| localhost 		 | root 	 	| ...
# 		| localhost 		 | 			| ...
# 		+------------------+----------+-
#
# When the reads the table into memory, it sorts the rows using the rules just described.
# The result after sorting looks like this:
#
# 		+------------------+----------+-
# 		| Host 				 | User 		| ...
# 		+------------------+----------+-
# 		| localhost 		 | root 		| ...
# 		| localhost 		 | 			| ...
# 		| % 					 | jeffrey 	| ...
# 		| % 					 | root 		| ...
# 		+------------------+----------+-
#
# When a client attempts to connect, the server looks through the sorted rows and uses the first match found.
#
# For a connection from localhost by jeffrey, two of the rows from the table match: the one with Host and User values of
# 'localhost' and '', and the one with values of '%' and 'jeffrey'.
#
# The 'localhost' row appears first in sorted order, so that is the one the server uses.
#
# Here is another example. Suppose that the user table looks like this:
#
# +----------------------------------+------------+-
# | Host 									 | User 		  | ...
# +----------------------------------+------------+-
# | % 										 | jeffrey 	  | ...
# | h1.example.net 						 | 			  | ...
# +----------------------------------+------------+-
#
# The sorted table looks like this:
#
# +----------------------------------+------------+-
# | Host 									 | User 		  | ...
# +----------------------------------+------------+-
# | h1.example.net 						 | 			  | ...
# | % 										 | jeffrey 	  | ...
# +----------------------------------+------------+-
#
# A connection by jeffrey from h1.example.net is matched by the first row, whereas a connection by jeffrey from any host is
# matched by the second.
#
# Note:
#
# 		It is a common misconception to think that, for a given user name, all rows that explicitly name that user are used
# 		first when the server attempts to find a match for the connection.
#
# 		This is not true.
#
# 		The preceding example illustrates this, where a connection from h1.example.net by jeffrey is first matched
# 		not by the row containing 'jeffrey' as the User column value, but by the row with no user name.
# 		
# 		As a result, jeffrey is authenticated as an anon user, even though he specified a user name when connecting.
#
# If you are able to connect to the server, but your privileges are not what you expect, you probably are being
# authenticated as some other account.
#
# To find out what account you were authenticated as, use the CURRENT_USER() function.
#
# It returns a value in <user_name>@<host_name> format that indicates the User and Host values from the matching
# user table row.
#
# Suppose that jeffrey connects and issues the following query:
#
# 		SELECT CURRENT_USER();
# 		+-----------------------+
# 		| CURRENT_USER() 			|
# 		+-----------------------+
# 		| @localhost 			   |
# 		+-----------------------+
#
# The result shown here indicates that the matching user table row had a blank User column value.
# In other words, the server is treating jeffrey as a anon user.
#
# Another way to diagnose authentication problems is to print out the user table and sort it by hand
# to see where the first match is being made.
#
# ACCESS CONTROL, STAGE 2: REQUEST VERIFICATION
#
# After you establish a connection, the server enters Stage 2 of access control.
#
# For each request that you issue through that connection, the server determines what operation you want to perform,
# then checks whether you have sufficient privs to do so.
#
# This is where the privilege column in the grant tables come into play.
# These privileges can come from any of the user, db, tables_priv, columns_priv or procs_priv tables.
# 
# The user table grants privileges that are assigned to you on a global basis and that apply no matter what
# the default database is.
#
# For example, if the user table grants you the DELETE privilege, you can delete rows from any table in any database
# on the server host.
#
# It is wise to grant privileges in the user table only to people who need them, such as database admins.
#
# For other users, you should leave all privileges in the user table set to 'N' and grant privileges at more specific
# levels only.
#
# You can grant privileges for particular databases, tables, columns or routines.
#
# The db table grants database-specific privileges. Values in the scope columns of this table can take the following forms:
#
# 		) A blank User value matches the anon user. A nonblank value matches literally; there are no wildcards in user names.
#
# 		) The wildcard characters % and _ can be used in the Host and Db columns.
#
# 			These have the same meaning as for pattern-matching operatons performed with the LIKE operator..
# 			If you want to use either character literally when granting privileges, you must escape it with a backslash.
#
# 			For example, to include the underscore character (_) as part of a database name, specify it as \_ in the GRANT statement.
#
# 		) A '%' or blank Host value means "any host".
#
# 		) A '%' or blank Db value means 'any db'.
#
# The server reads the db table into memory and sorts it at the same time that it reads the user table.
# The server sorts the db table based on the Host, Db and User scope columns.
#
# As with the user table, sorting puts the most-specific values first and least-specific values last, and when
# the server looks for matching rows, it uses the first match that it finds.
#
# The tables_priv, columns_priv and procs_priv tables grant table-specific, column-specific and routine-specific privs.
#
# Values in the scope columns of these tables can take the following forms:
#
# 		) The wildcard characters % and _ can be used in the Host column. 
# 			These have the same meaning as for pattern-matching operations performed with the LIKE operator.
#
# 		) A '%' or blank Host value means "any host".
#
# 		) The Db, Table_name, Column_name, and Routine_name columns cannot contain wildcards or be blank.
#
# The server sorts the tables_priv, columns_priv and procs_priv tables based on the Host, Db and User columns.
# This is similar to db table sorting, but simpler because only the Host column can contain wildcards.
#
# The server uses the sorted tables to verify each request that it receives.
#
# For requests that require administrative such as SHUTDOWN or RELOAD, the server checks
# only the user table row because that is the only table that specifies admin privs. 
#
# The server grants access if the row permits the requested operation and denies access otherwise.
#
# For example, if you want to execute mysqladmin shutdown but your user table row does not grant the
# SHUTDOWN priv to you, the server denies access without even checking the db table. 
#
# (It contains no shutdown_priv column, so there is no need to do so)
#
# For database-related requests (INSERT, UPDATE and so on), teh server fist checks the user's global privs by looking in the
# user table row.
#
# If the row permits the requested operation, access is granted.
#
# If the global priv in the user table are insufficient, the server determines the user's db-specific privs by checking
# the db table:
#
# 		The server looks in the db table for a match on the Host, Db and User columns.
# 		The Host and User columns are matched to the connecting user's host name and MySQL user name.
#
# 		The Db column is matched to the database that the user wants to access.
#
# 		If there is no row for the Host and User, access is denied.
#
# After determining the db-specific privs granted by the db table rows, the server adds them to the global privs
# granted by the user table.
#
# If the result permits the requested operation, access is granted.
#
# Otherwise, teh server successively checks the user's table and column privs in the tables_priv and columns_priv tables,
# adds those to the user's priv and permits or denies access based on the result.
#
# For stored-routine operations, the server uses the procs_priv table rather than tables_priv and columns_priv.
#
# Expressed in boolean terms, the preceding desc. of how a user's privs are calculated may be summarized as:
#
# 		global privileges
# 		OR (database privs AND host privs)
# 		OR table privs
# 		OR column privs
# 		OR routine privs
#
# It may not be apparent why, if the global user row privs are initially found to be insufficient for the requested operation,
# the server adds those privs to the database, table and column privs later.
#
# The reason is that a request might require more than one type of privilege.
# For example, if you execute an INSERT_INTO_..._SELECT statement, you need both the INSERT and SELECT privs.
#
# Your privs might be such that the user table row grants one priv and the db table row grants the other.
#
# In this case, you have the necessary privs to perform the request, but the server cannot tell that from either
# table by itself; the privs granted by the rows in both tables must be combined.
#
# WHEN PRIVILEGE CHANGES TAKE EFFECT
#
# When mysqld starts, it reads all grant tables contents into memory. The in-memory tables become effective for access control at that point.
#
# If you modify the grant tables indirectly using account-management statements such as GRANT, REVOKE, SET_PASSWORD or RENAME_USER, the server
# notices these changes and loads the grant tables into memory again immediately.
#
# If you modify the grant tables directly using statements such as INSERT, UPDATE or DELETE, your changes have no effect on priv checking
# until you either restart the server or tell it to reload the tables.
#
# If you change the grant tables directly but forget to reload them, your change have no effect until you restart the server.
# This may leave you wondering why your changes seem to make no difference.
#
# To tell teh server to reload the grant tables, perform a flush-priv operation. This can be done by issuing a FLUSH_PRIVILEGES statement
# or by executing a mysqladmin flush-privileges or mysqladmin reload command.
#
# A grant table reload affects privs for each existing client connection as follows:
#
# 		) Table and column privilege changes take effect with the client's next request.
#
# 		) Database privs changes take effect the next time the client executes a USE <db_name> statment.
#
# 			NOTE: Client applications mayy cache the database name: thus, this effect may not be visible to them without actually changing to a different database.
#
# 		) Global privileges and passwords are unaffected for a connected client. These changes take effect only for subsequent connections.
#
# If the server is started with the --skip-grant-tables option, it does not read the grant tables or implement any access control.
#
# Anyone can connect and do anything, which is insecure.
#
# To cause a server thus started to read the tables and enable access checking, flush the privileges.
#
# TROUBLESHOOTING PROBLEMS CONNECTING TO MYSQL
#
# If you encounter problems when you try to connect to the MySQL server, the following items describe some courses
# of action you can take to correct the problem.
#
# 		) Make sure that the server is running. If it is not, clients cannot connect to it.
#
# 			For example, if an attempt to connect to the servers fails with a message such as one of those following,
# 			one cause might be that the server is not running:
#
# 				mysql
# 				ERROR 2003: Can't connect to MySQL server on 'host_name' (111)
# 				mysql
# 				ERROR 2002: Can't connect to local MySQL server through socket
# 				'/tmp/mysql.sock' (111)
#
# 		) It might be that the server is running, but you are trying to connect using a TCP/IP port, named pipe, or Unix socket
# 			file different from the one on which the server is listening.
#
# 			To correct this when you invoke a client program, specify a --port option to indicate the proper port number or a 
# 			--socket option to indicate the proper named pipe or Unix socket file.
#
# 			To find out where the socket file is, you can use this command:
#
# 				netstat -ln | grep mysql
#
# 		) Make sure that the server has not been configured to ignore network connections or (if you are attempting to connect
# 			remotely) that it has not been configured to listen only locally on its network interfaces.
#
# 			If the server was started with --skip-networking, it will not accept TPC/IP connections at all.
#
# 			If the server was started with --bind-address=127.0.0.1, it will listen for TCP/IP connections only locally
# 			on the loopback interface and will not accept remote connections.
#
# 		) Check to make sure that there is no firewall blocking access to MySQL. Your firewall may be configured on the basis
# 			of the application being executed, or the port number used by MySQL for communication (3306 by default).
#
# 			Under Linux or Unix, check your IP tables (or similar) configuration to ensure that the port has not been
# 			blocked.
#
# 			under Windows, applications such as ZoneAlarm or Windows Firewall may need to be configured not to block the MySQL port.
#
# 		) The grant table must be properly set up so that the server can use them for access control.
#
# 			For some distrib types (such as binary on Windows or RPM distribs on Linux), the installation process initializes the MySQL
# 			data dir, including the mysql system db containing the grant tables.
#
# 			For distribs that do not do this, you must initialize the data dir manually.
#
# 			To determine whether you need to initialize the grant tables, look for a mysql dir under the data dir.
# 			(The data dir normally is named data or var and is located under your MySQL installation dir).
#
# 			Make sure that you have a file named user.MYD in the mysql database directory.
#
# 			If not, initialize the data directory. After doing so and starting the server, you should be able to connect to the server.
#
# 		) After a fresh installation, if you log on to the server as root without using a password, you might get the following error message.
#
# 			mysql -u root
#			ERROR 1045 (28000): Access denied for user 'root'@'localhost' (using password: NO)
#
# 			It means a root PW has already been assigned during installation and it has to be supplied.
#
# 			More on resetting etc., later.
#
# 		) If you have updated an existing MySQL installaiton to a newer version, did you run the mysql_upgrade script?
#
# 			If not, do so.
#
# 			The structure of the grant tables changes ocassionaly when new capabilties are added, so after an upgrade you should
# 			always make sure that your tables have the current structure.
#
# 		) If a client program receives the following error message when it tries to connect, it means that hte server expects
# 			passwords in a newer format than the client is capable of generating:
#
# 				mysql
# 				Client does not support authentication protocol requested
# 				by server; consider upgrading MySQL client
#
# 		) Remmber that client programs use connection parameters specified in option files or environment variables.
#
# 			If a client program seems to be sending incorrect default connection params when you have not specified them on teh cmd line,
# 			check any applicable option file and ENV variables.
#
# 			For example, if you get Access denied when you run a client without any options, make sure that you have not specified an
# 			old password in any of your option files.
#
# 			You can suppress the use of option files by a client program by invoking it with the --no-defaults option.
# 			For example:
#
# 				mysqladmin --no-defaults -u root version
#
# 		) If you get the following error, it means that you are using an incorrect root pw:
#
# 			mysqladmin -u root -pxxx ver
# 			Access denied for user 'root'@'localhost' (using password: YES)
#
# 			If the preceding error occurs when you have not specified a PW, it means that you have an incorrect PW listed in some option file.
# 			Try the --no-defaults option as described in the previous item.
#
# 		) localhost is a synonym for your local host name, and is also the default host to which clients try to connect if you specify no host explicitly.
#
# 			You can use a --host=127.0.0.1 option to name the server host explicitly.
#
# 			This will make TCP/IP connection to the local mysqld server.
#
# 			You can also use TCP/IP by specifying a --host option that uses the actual host name of the local host.
# 			In this case, the host name must be specified in a user table row on the server host, even though you are
# 			running the client program on the same host as the server.
#
# 		) The Access denied error message tells you who you are trying to log in as, the client host from which you are
# 			trying to connect, and whether you were using a password.
#
# 			Normally, you should have one row in tthe user table that exactly matches the host name and user name that
# 			were given in the error message.
#
# 			For example, if you get an error message that contains using password: NO, it means that you tried to log in without a PW.
#
# 		) If you get an Access denied error when trying to connect to the db with mysql -u <user_name>, you may have a problem with the
# 			user table.
#
# 			Check this by executing mysql -u root mysql and issuing this SQL statement:
#
# 				SELECT * FROM user;
#
# 			The result should include a row with the Host and User columns matching your client's host name and your MySQL user name.
#
# 		) if the following error occurs when you try to connect from a host other than the one on which the MySQL server is running,
# 			it means that there is no row in the user table with a Host value that matches the client host:
#
# 				Host ... is not allowed to connect to this MySQL Server
#
# 			You can fix this by setting up an account for the combination of client host name and user name that you are using when trying to connect.
#
# 			If you do not know the IP address or host name of the machine from which you are connecting, you should put a row with '%' as the Host column
# 			value in the user table.
#
# 			After trying to connect from the client machine, use a SELECT USER() query to see how you really did connect.
#
# 			Then change the '%' in the user table row to the actual host name that shows up in the log.
#
# 			Otherwise, your system is left insecure because it permits any host for the given user name.
#
# 			On Linux, another reason that this error might occur is that you are using a binary MySQL version that is compiled with
# 			a different version of the glibc library than the one you are using.
#
# 			In this case, you should either upgrade your OS system or glibc, or download a source distrib of MySQL version and compile
# 			it yourself.
#
# 			A source RPM is normally trivial to compile and install, so this is not a big problem.
#
# 		) If you specify a host name when trying to connect, but get an error message where the host name is not shown or is an IP address,
# 			it means that the mySQL server got an error when trying to resolve the IP address of the client host to a name:
#
# 				mysqladmin -u root -pxxx -h some_hostname ver
# 				Access denied for user 'root'@'' (Using password: YES')
#
# 			If you try to connect as root and get hte following error, it means that you do not have a row in the user table with a User column value
# 			of 'root' and that mysqld cannot reoslve the host name for your client:
#
# 				Access denied for user ''@'unknown'
#
# 			These errors indicate a DNS problem. To fix it, execute mysqladmin flush-hosts to reset the internal DNS host cache.
#
# 			Some solutions are:
#
# 			 )	Determine what is wrong with your DNs and fix it
# 
#  		 ) Specify IP addresses rather than host names in the MySQL grant tables
#
# 			 ) Put an entry for the client machine name in /etc/hosts on Unix or \windows\hosts on Windows
#
# 			 ) start mysqld with the --skip-name-resolve option
#
# 			 ) start mysqld with the --skip-host-cache option
#
# 			 ) On Unix, if you are running the server and the client on teh same machine, connect to localhost.
# 				For connections to localhost, MySQL programs attempt to connect to the local server by using a 
# 				Unix socket file, unless there are connection params specified to ensure that hte client makes a 
# 				TCP/IP connection.
#
# 			 ) On WIndows,if you are running the server and the client on teh same machine and the server supports named pipe connections,
# 				connect to the host name (period). Connections to . use a pipe rather than TCP/IP
#
# 		) if mysql -u root works but mysql -h your_hostname -u root results in Access denied (where your_hostname is the actual host name of the local host),
# 				you may not have the correct name for your host in the user table.
#
# 			A common problem here is that the Host value in teh user table row specifies an unqualified host name, but your systems name resolution
# 			routines return a fully qualified domain name (or vice versa).
#
# 			For example, if you have a row with host 'pluto' in the user table, but your DNS tells MySQL that your host name is 'pluto.example.com'
# 			the row won't work.
#
# 			Try adding a row to the user table that contains the IP address of your host as the Host column value. (alternatively, you could add a row to the
# 			user table with a Host value that contains a wildcard; for example, 'pluto.%'.
#
# 			However, use of Host values ending with % is insecure and not recommended.)
#
# 		) If mysql -u <user_name> works but mysql -u <user_name> <some_db> does not, you have not granted access to the given user for the database named
# 			<some_db>.
#
# 		) if mysql -u <user_name> works when executed on teh server host, but mysql -h <host_name> -u <user_name> does not work when executed on a remote client,
# 			you have not enabled access to the server for the given user name from the remote host.
#
# 		) If you cannot figure out why you get Access denied, remove from the user table all rows that have Host values containing wildcards (rows that contain '%' or '_'
# 			characters)
#
# 			a very common error is to insert a new row with Host='%' and User='some_user', thinking that this enables you to specify localhost to connect
# 			from the same machine.
#
# 			The reason that this does not work is that hte default privs include a row with Host='localhost' and User=''.
#
# 			Because that row has a Host value 'localhost' that is more specific than '%', it is used in preference to the new row when connecting
# 			from localhost.			
#
# 			The correct procedure is to insert a second row with Host='localhost' and User='some_user', or to delete the row with Host='localhost' and User=''.
# 			After deleting the row, remember to issue a FLUSH PRIVILEGES statement to reload the grant tables.
#
# 		) If you are able to connect to the MySQL server, but get an Access denied message whenever you issue a SELECT_..._INTO_OUTFILE or LOAD_DATA_INFILE
# 			statement, your row in the user table does not have the FILE priv enabled.
#
# 		) If you change the grant tables directly (for example, by using INSERT, UPDATE or DELETE statements) and your changes seem to be ignored,
# 			remember that you must execute a FLUSH_PRIVILEGES statement or a mysqladmin flush-privileges command to cause the server to reload
# 			the privilege tables.
#
# 			Otherwise, your changes have no effect until the enxt time the server is restarted.
#
# 			Remember that after you change the root PW with an UPDATE statement, you will not need to specify the new PW until after
# 			you flush the privs, because the server will not know you've changed the PW yet.
#
# 		) If your privs seem to have changed in the middle of a session, it may be that a MySQL admin has changed them.
#
# 			Reloading the grant table affects new client connections, but it also affects existing connections as indicated since before.
#
# 		) If you have access problems with a Perl, PHP, Python or ODBC program, try to connect to the server with mysql -u user_name db_name
# 			or mysql -u user_name -p<your_pw_here> <db_name>
#
# 			If you are able to connect using the mysql client, the problem lies with your program, not with the access privs.
#
# 			(There is no space between -p and the PW. You can also use the --password=<your_pass> syntax to specify the PW)
#
# 			if you use the -p or --password option with no PW value, MySQL prompts you for the PW.
#
# 		) For testing purposes, start hte mysqld server with the --skip-grant-tables option.
#
# 			Then you can change the MySQL grant tables and use the SHOW_GRANTS statement to check whether your modifications
# 			have the desired effect.
#
# 			When you are satisfied with your changes, execute mysqladmin flush-privileges to tell the mysqld server to load
# 			the privs again.
#
# 			This enables you to begin using the new grant table contents without stopping and restarting the server.
#
# 		) If everything else fails, start the mysqld server with a debugging option (for example, --debug=d,general,query)
#
# 		This prints host and user information about attempted connections, as well as information about each command issued.
#
# 		) If you have any other problems with the MySQL grant table and feel you must post the problem to the mailing list, always provide a dump of the
# 			MySQL grant tables.
#
# 			You can dump the tables with the mysqldump mysql command.
#
# 			To file a bug report, see earlier.
#
# 			In some cases, you may need to restart mysqld with --skip-grant-tables to run mysqldump.
#
# MYSQL USER ACCOUNT MANAGEMENT
#
# This section describes how to set up accounts for clients of your MySQL server. It discusses the following topics:
#
# 		) The meaning of account names and PWs as used in MySQL and how that compares to names and PWs used by your OS
#
# 		) How to set up new accounts and remove existing accounts
#
# 		) How to use roles, which are named collections of privs
#
# 		) How to change PWs
#
# 		) Guidelines for using PWs securly
#
# USER NAMES AND PASSWORDS
#
# MySQL stores accounts in the user table of the mysql system database.
#
# An account is defined in terms of a user name and the client host or hosts from which the user can connect to the server.
#
# The account may also have a PW. MySQL supports authentication plugins, so it is possible that an account authenticates using
# some external authentication method.
#
# There are several distinctions between the way user names and PWs are used by MySQL and your OS:
#
# 		) USer names, as used by MySQL for authentication purposes, have nothing to do with user names (login names) as used by Your OS.
#
# 			On Unix, most mySQL clients by default try to log in using the current Unix user name as the MySQL user name, but that's only for convenience.
#
# 			The default can be overridden easily, because client programs permit any user name to be specified with a -u or --user option:
#
# 			This means that anyone can attempt to connect to the server using any user name, so you cannot make a DB secure in any way unless all MySQL
# 			accounts have passwords.
#
# 			Anyone who specifies a user name for an account that has no password is able to connect succesfully to the server.
#
# 		) MySQL user names can eb up to 32 chars long. OS users may be of a different max length. For example, Unix user names typically are 
# 			limited to 8 chars.
#
# 			WARNING:
#
# 				The limit on MySQL user name length is hardcoded in MySQL servers and clients, and trying to circumvent it by modifying the defs of teh table
# 				in teh mysql db does not work.
#
# 				You should never alter the structure of tables in the mysql db in any manner whatsoever except means of the procedure that is
# 				described in upgrading.
#
# 				Attempting ot redefine MySQL's System tables in any other fashion results in undefined (and unsupported) behavior.
#
# 				The server is free to ignore rows that become malformed as a result of such modifications.
#
# 		) To authenticate client connections for accounts that use MySQL native authentication (implemented by the mysql_native_password authentication plugin),
# 			the server uses passwords stored in the user table.
#
# 			These passwords are distinct from passwords for logging in to your OS.
#
# 			There is no necessary connection between the "external" PW you use to log in to a Windows or Unix machine and the PW you use to access the MysQL server
# 			on that machine.
#
# 			If the server authenticates a client using some other plugin, the authentication method that the plugin implements may or may not use a PW stored in the user
# 			table. IN this case, it is possible that an external PW is also used to authenticate to the MySQL server.
#
# 		) Password stored in the user table are encrypted using plugin-specific algorithms.
#
# 		) If the user name and PW contain only ASCII chars, it is possible to connect ot hte server regardless of character setting.
#
# 			To connet when the user name or PW contain non-ascii chars, the client should call the mysql_options() C API function with the
# 			MYSQL_SET_CHARSET_NAME option and appropaite charatet set name as arguments.
#
# 			This casues authentication to take place using the specified character set:
#
# 			Otehrwise, authentication will fail unless the server default character set is the same as the encoding in teh authentication defaults.
#
# 			Standard MySQL client programs support a --default-character-set option that causes mysql_options to be called as just described.
# 			iN addition, the character set autodetection is supported as described later.
#
# 			For programs that use a connector that is not based on the C API, the connector may provide an equivalent ot mysql_options() that can be used instead.
#
# 			The preceding notes do not apply to ucs2, utf16 and utf32, which are not permitted as client char sets.
#
# The MySQL installation process populates the grant tables with an initial root account,  as described earlier.
#
# Thereafter, you normally set up, modify and remove MYSQL accounts using statements such as CREATE_USER, DROP_USER, GRANT, and REVOKE.
#
# To connect to a MySQL server with a command-line script client, specify user name and password options as necessary for the account that you want to use:
#
# 		mysql --user=finley --password db_name
#
# If you prefer short options, the command looks like this:
#
# 		mysql -u finley -p db_name
#
# If you omit the PW value following the --password or -p option on the command line (as just shown),
# the client prompts for one.
#
# Alternatively, the password can be specified on the cmd line:
#
# 		mysql --user=finley --password=password db_name
# 		mysql -u finley -ppassword db_name
#
# If you use the -p option, there must be no space between -p and the PW that follows.
#
# Specifying a PW on the cmd line should be considered insecure.
#
# Use an option file or a login path file instead for the PW decalration.
#
# ADDING USER ACCOUNTS
#
# To create MySQL accounts, use the account-management statements intended for creating accounts and establishing their privs, such as
# CREATE_USER and GRANT.
#
# These statements cause the server to make appropiate modifications to the underlying grant tables.
#
# NOTE:
#
# 		Direct modification of grant tables using statements such as INSERT, UPDATE or DELETE is discouraged and done at your own risk.
#
# 		The server is free to ignore rows that become malform as a result of such modifications.
#
# 		For any operation that modifies a grant table, the server checks whether the table has the expected structure and produces an
# 		error if not. 
#
# 		mysql_upgrade must be run to update the tables to the expected structure.
#
# Another option for creating accounts is to use the GUI tool MySQL workbench.
#
# The following showcases how to use the mysql client program to set up new accounts.
#
# These examples assume that privileges have been set up according to the defualts described earlier.
#
# This means that to make changes, you must connect to the MySQL server as the MySQL root user, which has the CREATE_USER privs.
#
# First, use the mysql program to connect to the server as the MySQL root user:
#
# 		mysql --user=root mysql
#
# If you have assigned a password to the root account, you must also supply a -password or -p option.
#
# After connecting to the server as root, you can add new accounts. The following example uses CREATE_USER and GRANT statements to set up
# four accounts:
#
# 		CREATE USER 'finley'@'localhost' IDENTIFIED BY 'password';
# 		GRANT ALL PRIVLEGES ON *.* TO 'finley'@'localhost'
# 			-> 	WITH GRANT OPTION;
# 		CREATE USER 'finley'@'%' IDENTIFIED BY 'password';
# 		GRANT ALL PRIVILEGES ON *.* TO 'finley'@'%'
# 			-> 	WITH GRANT OPTION;
# 		CREATE USER 'admin'@'localhost' IDENTIFIED BY 'password';
# 		GRANT RELOAD PROCESS ON *.* TO 'admin'@'localhost';
# 		CREATE USER 'dummy'@'localhost';
#
# The accounts created by said statements have the following properties:
#
# 		) Two accounts have a user name of finley. Both are superusers accounts that have full privileges to do anything.
#
# 			The 'finley'@'localhost' account can be used only when connecting from the local host. 
#
# 			The 'finley'@'%' account uses the '%' wildcard for the host part, so it can be used to connect from any host.
#
# 			The 'finley'@'localhost' account is necessary if there is an anon user for localhost. Without the 'finley'@'localhost',
# 			that anon user acc takes precedence when finley connects from the local host and finley is treated as an anon.
#
# 			The reason for this is that the anon user has more specific Host oclumn (see previous section), than the 'finley'@'%' acc
# 			and thus comes earlier in the user table sort order. 
#
# 		) The 'admin'@'localhost' account can be used only by admin to connect from the local host.
#
# 			It is granted the RELOAD and PROCESS administrative privs. 
#
# 			These privs enable the admin user to execute the mysqladmin reload, mysqladmin refresh, and mysqladmin flush-xxx commands, as well as
# 			mysqladmin processlist.
#
# 			No privs are granted for accessing any DBs. You could add such privs using the GRANT statements.
#
# 		) The 'dummy'@'localhost' account has no PW (which is insecure and not recommended). This account can be used only to connect
# 			from the localhost.
#
# 			No rpvis are granted. It is assumed you will grant specific privs to the acc using GRANT statements.
#
# To see the privileges for an account, use SHOW_GRANT:
#
# 		SHOW GRANTS FOR 'admin'@'localhost';
# 		+-----------------------------------------------------+
# 		| Grants for admin@localhost 			 						|
# 		+-----------------------------------------------------+
# 		| GRANT RELOAD, PROCESS ON *.* TO 'admin'@'localhost' |
# 		+-----------------------------------------------------+
#
# To see nonprivlege properties for an account, use SHOW_CREATE_USER:
#
# 		SHOW CREATE USER 'admin'@'localhost'\G
# 		*************************** 1. row ************************
# 		CREATE USER for admin@localhost: CREATE USER 'admin'@'localhost'
# 		IDENTIFIED WITH 'mysql_native_password'
# 		AS '*<numbers/letters>'
# 		REQUIRE NONE PASSWORD EXPIRE DEFAULT ACCOUNT UNLOCK
#
# The next example create three accounts and grant them access to specific DBs.
# Each of them has a user name of custom and password of password:
#
# CREATE USER 'custom'@'localhost' IDENTIFIED BY 'password';
# GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP
# 		-> 		ON bankaccount.*
# 		-> 		TO 'custom'@'localhost';
#
# CREATE USER 'custom'@'host47.example.com' IDENTIFIED BY 'password';
# GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP
# 		-> 		ON expenses.*
# 		-> 		TO 'custom'@'host47.example.com';
#
# CREATE USER 'custom'@'%.example.com' IDENTIFIED BY 'password';
# GRANT SELECT,INSERT,UPDATE,DELETE,CREATE,DROP
# 		-> 		ON customer.*
# 		-> 		TO 'custom'@'%.example.com';
#
# The three accounts cna be used as follows:
#
# 		) The first account can access the bankaccount database, but only from the local host.
#
# 		) The second account can access the expenses database, but only from the host47.example.com
#
# 		) The third account can access the customer database, from any host in the example.com domain.
#
# 			This account has access from all machines in the domain due to use of the % widlcard character in the host part of the account name.
#
# REMOVING USER ACCOUNTS
#
# To remove an account, use the DROP_USER statement, which is described later in greater detail:
#
# 	 DROP USER 'jeffrey'@'localhost';
#
# USING ROLES
#
# A MySQL role is a named collection of privileges. Like user accounts, roles can have privileges granted to and revoked from them.
#
# A user account can be granted roles, which grants to the account the privileges associated with each role.
#
# This enables assignment of sets of privileges to accounts and provides a convenient alternative to granting individual privileges,
# both for conceptualizing desired privilege assignments and implementing them.
#
# The following list summarizes role-management capabilities provided by MySQL:
#
# 		) CREATE_ROLE and DROP_ROLE enable roles to be created and removed.
#
# 		) GRANT and REVOKE enable privilege assignment and revocation for user accounts and roles.
#
# 		) SHOW_GRANTS displays privilege and role assignments for user accounts and roles.
#
# 		) SET_DEFAULT_ROLE specifies which account roles are active by default.
#
# 		) SET_ROLE changes the active roles within the current session.
#
# 		) The CURRENT_ROLE() function displays the active roles within the current session.
#
# 		) The mandatory_roles and activate_all_roles_on_login SYS_VAR enables defining mandatory roles and automatic activation
# 			of granted roles when users log in to the server.
#
# For descriptiosn of individual role-manipulation statements, see later.
#
# The following discussion provides examples of role usage.
#
# Unless otherwise specified, SQL statements shown should be executed using a MySQl acc with admin privileges, such as the root account.
#
# CREATING ROLES AND GRANTING PRIVILEGES TO THEM
#
# Consider this scenario:
#
# 		) An application uses a database named app_db
#
# 		) Associated with the application, there can be accounts for developers who create and maintain the application, and for users who interact with it.
#
# 		) Developers need full access to the database. Some users need only read access, others need read/write access.
#
# To avoid granting privileges individually to possibly many user accounts, create roles as names for the required privilege sets.
# This makes it easy to grant the required privileges to user accounts, by granting them appropiate roles.
#
# To create hte roles, use CREATE_ROLE:
#
# 		CREATE ROLE 'app_developer', 'app_read', 'app_write';
#
# Role names are much like USER ACCS and consists of a user part and a host part in 'user_name'@'host_name' format.
#
# The host part, if omitted, defaults to '%'.
#
# The user and host parts can be unquoted unless they contain special characters such as - or %.
#
# Unlike account names, the user part of role names cannot be blank.
#
# To assign privileges to the roles, execute GRANT using the same sytnax as for assigning privileges to user accounts:
#
# 	GRANT ALL ON app_db.* TO 'app_developer';
# 	GRANT SELECT ON app_db.* TO 'app_read';
# 	GRANT INSERT, UPDATE, DELETE ON app_db.* TO 'app_write';
#
# Now suppose that intially you require one developer account, two user accounts that need read-only access, and one user account
# that needs read/write access.
#
# Use CREATE_USER to create the accounts:
#
# 	CREATE USER 'dev1'@'localhost' IDENTIFIED BY 'dev1pass';
# 	CREATE USER 'read_user1'@'localhost' IDENTIFIED BY 'read_user1pass';
# 	CREATE USER 'read_user2'@'localhost' IDENTIFIED BY 'read_user2pass';
# 	CREATE USER 'rw_user1'@'localhost' IDENTIFIED BY 'rw_user1pass';
#
# To assign each user its required privileges, you could use GRANT statements of the same form as just shown, but that requires
# enumerating individuals privileges for each user.
#
# Instead, use an alternative GRANT syntax that permits granting roles rather than privileges:
#
# 	GRANT 'app_developer' TO 'dev1'@'localhost';
# 	GRANT 'app_read' TO 'read_user1'@'localhost', 'read_user2'@'localhost';
# 	GRANT 'app_read', 'app_write' TO 'rw_user1'@'localhost';
#
# The GRANT statement for the rw_user1 account grans the read and write roles, which combine to provide the required read and write privileges.
#
# The GRANT syntax for granting roles to an account differs from the Syntax for granting privileges:
#
# 		There is an ON clause to assign privileges, whereas there is no ON clause to assign roles.
#
# 		Because the syntaxes are distinct, you cannot mix assigning privileges and roles in the same statement.
# 		(It is permitted to assign both privilegs and roles to an account, but you must use separate GRANT statements,
# 			each with syntax appropiate to what is to be granted)
#
# DEFINE MANDATORY ROLES
#
# It is possible to specify roles as mandatory by naming them in the value of the mandatory_roles SYS_VAR.
# The server treats a mandatory role as granted to all users, so that it need not be granted explicitly to any account.
#
# To specify mandatory roles at server startup, define mandatory_roles in your server my.cnf file:
#
# 		[mysqld]
# 		mandatory_roles='role1,rol2@localhost,r3@%.example.com'
#
# To set and persist mandatory_roles at runtime, use a statement like this:
#
# 		SET PERSIST mandatory_roles = 'role1,role2@localhost, r3@%.example.com';
#
# SET_PERSIST sets the value for the running MySQL instance. It also saves the value to be used for subsequent server restarts.
#
# To change a value for the running MySQL instance without saving it for subsequent restarts, use the GLOBAL keyword rather than PERSIST.
#
# Setting mandatory_roles requires the ROLE_ADMIN privilege, in addition to the SYSTEM_VARIABLES_ADMIN or SUPER privilege normall required
# to set a global system variable.
#
# Mandatory roles, like explicitly granted roles, do not take effect until activated. 
#
# At login time, role activation occurs for all granted roles if the activate_all_roles_on_login system variable is enabled,
# or only for roles that are set as default roles otherwise.
#
# At runtime, SET_ROLE activates roles.
#
# Roles named in the value of mandatory_roles cannot be revoked with REVOKE or dropped with DROP_ROLE or DROP_USER.
#
# If a role named in mandatory_roles is not present in the mysql.user system table, the role is not granted to users.
#
# When the server attempts role activaiton for a user, it does not treat the nonexistent role as mandatory and writes
# a warning ot the error log.
#
# If the role is created later and thus becomes valid, FLUSH_PRIVILEGES may be necessary to cause the server to treat it
# as mandatory.
#
# SHOW_GRANTS displays mandatory roles according to the rules described later.
#
# CHECKING ROLE PRIVS
#
# To verify the privs assigned to an account, use SHOW_GRANTS. For example:
#
# 		SHOW GRANTS FOR 'dev1'@'localhost';
# 		+--------------------------------------------------+
# 		| Grants for dev1localhost 								|
# 		+--------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `dev1`@`localhost`			|
# 		| GRANT `app_developer`@`%` TO `dev1`@`localhost` 	|
# 		+--------------------------------------------------+
#
# However, that shows each granted role without "expanding" it to the privileges the role represents.
# TO show role privileges as well, add a USING clause naming the granted roles for which to display privileges:
#
# 		SHOW GRANTS FOR 'dev1'@'localhost' USING 'app_developer';
# 		+-----------------------------------------------------------+
# 		| Grants for dev1@localhost 											|
# 		+-----------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `dev1`@`localhost` 		            |
# 		| GRANT ALL PRIVILEGES ON `app_db`.* TO `dev1`@`localhost` 	|
# 		| GRANT `app_developer`@`%` TO `dev1`@`localhost` 			   |
# 		+-----------------------------------------------------------+
#
# Verify each other type of user similarly:
#
# 		SHOW GRANTS FOR 'dev1'@'localhost' USING 'app_developer';
# 		+------------------------------------------------------------+
# 		| Grants for read_user1@localhost 									 |
# 		+------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `read_user1`@`localhost` 				 |
# 		| GRANT SELECT ON `app_db`.* TO `read_user1`@`localhost`	 	 |
# 		| GRANT `app_read`@`%` TO `read_user1`@`localhost` 			 |
# 		+------------------------------------------------------------+
#
# 		SHOW GRANTS FOR 'rw_user1'@'localhost' USING 'app_read', 'app_write';
# 		+------------------------------------------------------------------------------+
# 		| Grants for rw_user1@localhost 										 						 |
# 		+------------------------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `rw_user1`@`localhost` 					  						 |
# 		| GRANT SELECT, INSERT, UPDATE, DELETE ON `app_db`.* TO `rw_user1`@`localhost` |
# 		| GRANT `app_read`@`%`, `app_write`@`%` TO `rw_user1`@`localhost` 				 |
# 		+------------------------------------------------------------------------------+
#
# SHOW_GRANTS displays mandatory roles according to the rules described later.
#
# ACTIVATING ROLES
#
# Roles granted to a user account can be active or inactive within account sessions. 
# If a granted role is active within a session, its privileges apply; otherwise, they do not.
#  
# To determine which roles are active within the current session, use the CURRENT_ROLE() function.
#
# By default, granting a role to an account or naming it in the mandatory_role SYS_VAR value does not automatically
# cause the role to become active within account sessions.
#
# For example, because thus far in the preceding discussion no rw_user1 roles have been activated, if you connect to
# the server as rw_user1 and invoke the CURRENT_ROLE() function, the result is NONE(no active roles):
#
# SELECT CURRENT_ROLE();
# +------------------------+
# | CURRENT_ROLE() 			|
# +------------------------+
# | NONE 					   |
# +------------------------+
#
# To specify which roles should become active each time a user connects to the server and authenticates, use SET_DEFAULT_ROLE.
# To set the default to all assigned roles for each account created earlier, use this statement:
#
# 		SET DEFAULT ROLE ALL TO 'dev1'@'localhost', 'read_user1'@'localhost', 'read_user2'@'localhost', 'rw_user1'@'localhost';
#
# Now if you connect as rw_user1, the initial value of CURRENT_ROLE() reflects the new default role assignments:
#
# SELECT CURRENT_ROLE();
# +-------------------------------+
# | CURRENT_ROLE() 			 		 |
# +-------------------------------+
# | `app_read`@`%`,`app_write`@`%`|
# +-------------------------------+
#
# To cause all explicitly granted and mandatory roles to be automatically activated when users connect to the server,
# enable the activate_all_roles_on_login SYS_VAR.
#
# By default, automatic role activation is disabled.
#
# Within a session, a user can execute SET_ROLE to change the set of active roles. For example, for rw_user1:
#
# 	SET ROLE NONE; SELECT CURRENT_ROLE();
# +---------------------+
# | CURRENT_ROLE() 		|
# +---------------------+
# | NONE 					|
# +---------------------+
#
#  SET ROLE ALL EXCEPT 'app_write'; SELECT CURRENT_ROLE();
# +---------------------+
# | CURRENT_ROLE() 		|
# +---------------------+
# | `app_read`@`%` 		|
# +---------------------+
#
# SET ROLE DEFAULT; SELECT CURRENT_ROLE();
# +-------------------------------+
# | CURRENT_ROLE() 					 |
# +-------------------------------+
# | `app_read`@`%`,`app_write`@`%`|
# +-------------------------------+
#
# The first SET_ROLE statement deactives all roles.
# The second makes rw_user1 effectively read only.
#
# The third restores the defualt roles.
#
# The effective user for stored program and view objects is subject to the DEFINER and SQL SECURITY attributes, which
# whether execution occurs in invoker or definer context (covered later):
#
# 		) Stored program and view objects that execute in invoker context execute with the active roles within the current session.
#
# 		) Stored program and view objects that execute in definer context execute with the default roles of the user named in their DEFINER attribute.
#
# 			If activate_all_roles_on_login is enabled, such objects execute with all roles granted to the DEFINER user, including mandatory roles.
# 
# 			For stored programs, if execution should occur with roles different from the default, the program body should execute SET_ROLE to activate the required roles.
# 
# REVOKING ROLES OR ROLE PRIVILEGES
#
# Just as roles can be granted to an account, they can be revoked from an account:
#
# 		REVOKE role FROM user;
#
# Roles named in the mandatory_roles SYS_VAR value cannot be revoked.
#
# REVOKE can also be applied to a role to modify the privileges granted to it.
# This affects not only the role itself, but any account granted that role.
#
# Suppose that you want to temporarily make all application users read only.
#
# To do this, use REVOKE to revoke the modification privileges from the app_write role:
#
# 		REVOKE INSERT, UPDATE, DELETE ON app_db.* FROM 'app_write';
#
# As it happens,that leaves the role with no privleges at all, as can be seen using SHOW_GRANTS (which demonstrates that this statement can be used with roles, not just users):
#
# 		SHOW GRANTS FOR 'app_write';
# 		+--------------------------------------+
# 		| Grants for app_write@% 			  		|
# 		+--------------------------------------+
# 		| GRANT USAGE ON *.* TO `app_write`@`%`|
# 		+--------------------------------------+
#
# Because revoking privileges from a role affects the privileges for any user who is assigned the modified role, rw_user1 now has no table modification
# privileges (INSERT, UPDATE and DELETE are no longer present):
#
# 		SHOW GRANTS FOR 'rw_user1'@'localhost' USING 'app_read', 'app_write';
# 		+-------------------------------------------------------------------+
# 		| Grants for rw_user1@localhost 												  |
# 		+-------------------------------------------------------------------+
# 		| GRANT USAGE ON *.* TO `rw_user1`@`localhost` 							  |
# 		| GRANT SELECT ON `app_db`.* TO `rw_user1`@`localhost`				  |
# 		| GRANT `app_read`@`%`,`app_write`@`%` TO `rw_user1`@`localhost` 	  |
# 		+-------------------------------------------------------------------+
#
# In effect, the rw_user1 read/write user has become a read-only user. 
#
# This also occurs for any other accounts that are granted the app_write role, illustrating how use of roles makes it unecessary to modify privileges for individual accounts.
#
# To restore modification privileges to the role, simply re-grant them:
#
# 		GRANT INSERT, UPDATE, DELETE ON app_db.* TO 'app_write';
#
# Now rw_user1 again has modification privs, as do any other accounts granted the app_write role.
#
# REMOVING ROLES
#
# To remove roles, use DROP_ROLE:
#
# 		DROP ROLE 'app_read', 'app_write';
#
# Dropping a role revokes it from every account to which it was granted.
#
# Roles named in the mandatory_roles system variable cannot be dropped.
#
# USER AND ROLE INTERCHANGEABILITY
#
# As has been hinted at earlier for SHOW_GRANTS, which displays grants for user accounts or roles, accounts and roles can be used
# interchangably.
#
# You can treat a user account like a role and grant that account to another user or a role.
#
# The effect is to grant the account's privileges and roles to the other user or role.
#
# This set of statements demonstrates that you can grant a user to a user, a role to a user, a user to a role, or a role to a role:
#
# 		CREATE USER 'u1';
# 		CREATE ROLE 'r1';
#
# 		GRANT SELECT ON db1.* TO 'u1';
# 		GRANT SELECT ON db2.* TO 'r1';
#
# 		CREATE USER 'u2';
# 		CREATE ROLE 'r2';
# 
# 		GRANT 'u1', 'r1' TO 'u2';
# 		GRANT 'u1', 'r1' TO 'r2';
#
# The result in each case is to grant to the grantee object the privileges associated with the granted object.
#
# After executing those statements, each of u2 and r2 have been granted privs from a user (u1) and a role (r1):
#
#
# 		SHOW GRANTS FOR 'u2' USING 'u1', 'r1';
# 		+------------------------------------+
# 		| Grants for u2@% 						 |
# 		+------------------------------------+
# 		| GRANT USAGE ON *.* TO `u2`@`%` 	 |
# 		| GRANT SELECT ON `db1`.* TO `u2`@`%`|
# 		| GRANT SELECT ON `db2`.* TO `u2`@`%`|
# 		| GRANT `u1`@`%`,`r1`@`%` TO `u2`@`%`|
# 		+------------------------------------+
#
# 		SHOW GRANTS FOR 'r2' USING 'u1', 'r1';
# 		+------------------------------------+
# 		| Grants for r2@% 						 |
# 		+------------------------------------+
# 		| GRANT USAGE ON *.* TO `r2`@`%` 	 |
# 		| GRANT SELECT ON `db1`.* TO `r2`@`%`|
# 		| GRANT SELECT ON `db2`.* TO `r2`@`%`|
# 		| GRANT `u1`@`%`,`r1`@`%` TO `r2`@`%`|
# 		+------------------------------------+
#
# The preceding example is llustrative only, but interchangability of user accounts and roles has practical application;
# such as in the following situation:
#
# 	Suppose that a legacy application development project began before the advent of roles in MySQL, so all user accounts
#  associated with the project are granted privileges directly (rather than granted privileges by virtue of being granted roles).
#
#  One of these accounts is a dev account taht was originally granted privs as follows:
#
# 		CREATE USER 'old_app_dev'@'localhost' IDENTIFIED BY 'old_app_devpass';
# 		GRANT ALL ON old_app.* TO 'old_app_dev'@'localhost';
#
# If this developer leaves the project, it becomes nesesecary to assign the privileges to anotehr user, or perhaps multiple users
# if devleopment activities have expanded.
#
# Here are some ways to deal with the issue:
#
# 		) Without using roles : Change the account PW so the original dev cannot use it, and have a new dev use it instead:
#
# 				ALTER USER 'old_app_dev'@'localhost' IDENTIFIED BY 'new_password';
#
# 		) Using roles: Lock the acc to prevent anyone from using it to connect to the server:
#
# 				ALTER USER 'old_app_dev'@'localhost' ACCOUNT LOCK;
#
# 			Then treat the account as a role. For each dev new to the project, create a new account and grant it to the original dev acc:
#
# 				CREATE USER 'new_app_dev1'@'localhost' IDENTIFIED BY 'new_password';
# 				GRANT 'old_app_dev'@'localhost' TO 'new_app_dev1'@'localhost';
#
# 			The effect is to assign the original dev acc privs to the new account.
#
# RESERVED USER ACCOUNTS
#
# One part of the MySQL installation process is data directory initializaiton.
#
# During data dir initialization, MySQL creates user accounts that should be considered reserved:
#
# 		) 'root'@'localhost': Used for administrative purposes. This account has all privileges and can perform any operation.
#
# 			Strictly speaking, this acc name is not reserved, in the sense that some installations rename the root account to something
# 			else to avoid exposing a highly privleged account with a well-known name.
#
# 		) 'mysql.sys'@'localhost': Used as the DEFINER for sys schema objects. Use of the mysql.sys account avoids problems that occur
# 			if a DBA renames or removes the root account.
#
# 			THis account is locked so that it cannot be used for client applications.
#
# 		) 'mysql.session'@'localhost': Used internally by plugins to access the server. This account is locked so that it cannot be used for client connections.
#
# 		) 'mysql.infoschema'@'localhost': Used as the DEFINER for INFORMATION_SCHEMA views. Use of the mysql.infoschema account avoids problems that occur if a DBA 
# 			renames or removes the root account.
#
# 			This account is locked so that it cannot be used for client connections.
#
# SETTING ACCOUNT RESOURCE LIMITS
#
# One means of restricting client use of MySQL server resources is to set the global max_user_connections SYS_VAR to a > 0 value.
#
# This limits the number of simultaneous connections that can be made by any given account, but places no limits on what a client
# can do once connected.
#
# In addition, setting max_user_connections does not enable management of individual accounts.
#
# Both types of control are of interest to MySQL admins.
#
# To address such concerns, MYSQL permits limits for individual accounts on use of these server resources:
#
# 		) The number of queries an account can issue per hour
#
# 		) The number of updates an account can issue per hour
#
# 		) The number of times an account can connect to the server per hour
#
# 		) The number of simultaneous connections to the server by an account
#
# Any statement that a client can issue counts against the query limit. Only statements that modify databases or tables count against the update limit.
#
# An "account" in this context corresponds to a row in the mysql.user table.
#
# That is, a connection is assessed against the User and Host values in the user table row that applies to the connection.
#
# For example, an account 'usera'@'%.example.com' corresponds to a row in the user table that has User and Host values of usera and
# %.example.com to permit usera to connect from any host in teh example.com domain.
#
# In this case, the server applies resource limits in this row collectively to all connections by usera from any host in the 
# example.com domain because all such connections use the same account.
#
# Before MySQL 5.0, an "account" was assessed against the actual host from which a user connects.
# The older method of accounting may be selected by starting the server with the --old-style-user-limits option.
#
# In this case, if usera connects simultaneously from host1.example.com and host2.example.com, the server applies the
# account resource limits separately to each connection.
#
# If usera connects again from host1.example.com, the server applies the limits for that connection together with the
# existing connection from that host.
#
# To establish resource limits for an account at account-creation time, use the CREATE_USER statement.
#
# To modify the limits for an existing account, use ALTER_USER.
#
# Provide a WITH clause that names each resource to be limited.
#
# The default value for each limit is zero (limitless).
#
# For example, to create a new account that can access the customer database, but only in a limited fashion, issue these statements:
#
# 		CREATE USER 'francis'@'localhost' IDENTIFIED BY 'frank'
# 				-> 	WITH MAX_QUERIES_PER_HOUR 20
# 				-> 		  MAX_UPDATES_PER_HOUR 10
# 				-> 		  MAX_CONNECTIONS_PER_HOUR 5
# 				-> 		  MAX_USER_CONNECTIONS 2;
#
# The limit types need not all be named in the WITH clause, but those named can be present in any order.
#
# The value for each per-hour limit should be an integer representing a count per hour.
#
# For MAX_USER_CONNECTIONS, the limit is an integer representing the maximum number of simultaneous connections
# by the account.
#
# If this limit is set to zero, the global max_user_connections SYS_VAR determines the number of simultaneous connections.
# If max_user_connections is also 0, there is no limit for the account.
#
# To modify limits for an existing account, use an ALTER_USER statement.
#
# The following statement changes the query limit for francis to 100:
#
# 		ALTER USER 'francis'@'localhost' WITH MAX_QUERIES_PER_HOUR 100;
#
# The statement modifies only the limit value specified and leaves the account otehrwise unchagned.
#
# To remove a limit, set its value to zero. For example, to remove the limit on how many times per hour franis can connect,
# set:
#
# ALTER USER 'francis'@'localhost' WITH MAX_CONNECTIONS_PER_HOUR 0;
#
# As mentioned previously, the simultaneous-connection limit for an account is determined from the MAX_USER_CONNECTIONS limit and the
# max_user_connections SYS_VAR.
#
# Suppose that the global max_user_connections value is 10 and three accounts have individual resource limits specified as follows:
#
# 		ALTER USER 'user1'@'localhost' WITH MAX_USER_CONNECTIONS 0;
# 		ALTER USER 'user2'@'localhost' WITH MAX_USER_CONNECTIONS 5;
# 		ALTER USER 'user3'@'localhost' WITH MAX_USER_CONNECTIONS 20;
#
# user1 has a connection limit of 10 (the global max_user_connections value) because it has a MAX_USER_CONNECTIONS limit of 0 (i.e, falls back to Global).
# user2 and user3 has 5 and 20, respectively. (Defined value > 0, higher precedence than Global).
#
# The server stores resource limits for an account in the user table row corresponding to the account.
#
# The max_questions, max_updates and max_connections columns store the per-hour limits, and the max_user_connections column stores
# the MAX_USER_CONNECTIONS limit.
#
# Resource-use counting takes place when any account has a nonzero limit placed on its use of any of the resources.
#
# As the server runs, it counts the number of times each account uses resources.
# If an account reaches its limit on number of connections within the last hour, the server
# rejects further connections for the account until that hour is up.
#
# SImilarly, if the account reaches its limit on the number of queries or updates, the server
# rejects further queries or updates until the hour is up.
#
# In all such cases, the server issues appropriate error messages.
#
# Resource counting occurs per account, not per client.
#
# For example, if your account has a query limit of 50, you cannot increase your limit to 100 by making two
# simultaneous client connections to the serer.
#
# Queries issued on both connections are counted together.
#
# The current per-hour resource-use counts can be reset globally for all accounts, or individually for a given account:
#
# 		) To reset the current count to zero for all accounts, issue a FLUSH_USER_RESOURCES statement.
#
# 			The counts also can be reset by reloading the grant tables (for example, with a FLUSH_PRIVLEGES statement or a mysqladmin reload command)
#
# 		) The counts for an individual account can be reset to zero by setting any of its limits again. Specify a limit value equal to the value currently assigned ot the account.
#
# Per-hour counter resets do not affect the MAX_USER_CONNECTIONS limit.
#
# All counts begin at 0 when the server starts. Counts do not carry over through server restarts.
#
# For the MAX_USER_CONNECTIONS limit, an edge case can occur if the account currently has open the maximum number of connections
# permitted to it:
#
# A disconnect followed quickly by a connect can result in an error (ER_TOO_MANY_USER_CONNECTIONS or ER_USER_LIMIT_REACHED) if the server has not fully processed
# the disconnect by the time the connect occurs.
#
# When the server finishes disconnect processing, another connection will once more be permitted.
#
# ASSIGNING ACCOUNT PASSWORDS
#
# Required credentials for clients that connect to the MySQL server can include a password. This section describes how ot assign PWs for MySQL accs.
#
# MySQL stores credentials in the user table in the mysql system database.

# Operations that assign or modify passwords are permitted only to users with the CREATE_USER privilege, or,
# alternatively, privileges for the mysql databse (INSERT privilege to create new accounts, UPDATE privilege to modify existing accounts).
#
# If the read_only SYS_VAR is enabled, use of account-modification statements such as CREATE_USER or ALTER_USER additionally requires the
# CONNECTION_ADMIN or SUPER privilege.
#
# The discussion here summarizes syntax only for the most common PW assignments. More covered later.
#
# MySQL uses plugins to perform client authentication; more later.
#
# IN password-assigning statements, the authentication plugin associated with an account performs any hashing required of a cleartext
# PW specified.
#
# This enables MySQL to obfuscate PWs prior to storing them in the mysql.user table.
#
# For the statements described here, MySQL automatically hashes the PWs specified.
#
# there are also 	syntaxes for CREATE_USER and ALTER_USER that permit hashed values to be specified literally.
# 
# To assign a PW when you create a new account, use CREATE_USER and include an IDENTIFIED BY clause:
#
# 		CREATE USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';
#
# CREATE_USER also supports syntax for specifying the account authentication plugin.
#
# To assign or change a password for an existing account, 	use the ALTER_USER statement with an IDENTIFIED BY clause:
#
# 		ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY 'password';
#
# If you are not connected as an anon user, you can change your own PW without naming your own account literally:
#
# 		ALTER USER() IDENTIFIED BY 'password';
#
# To change an account PW from the cmd line, use the mysqladmin command:
# 
# 		mysqladmin -u <user_name> -h <host_name> password "password"
#
# The account for which this command sets the PW is the one with a mysql.user table row that matches <user_name> in the User column
# and the client host from which you connect in teh Host column.
#
# WARNING:
#
# 		Setting a PW using mysqladmin should be considered insecure. 
#
# 		ON some systems, your PW becomes visible to System Status programs, such as ps that may be invoked by other users to display
# 		cmd lines.
#
# 		MySQL clients tpyically overwrite the cmd line PW argument with 00's during their initialization sequence.
#
# 		However, there is still a brief interval during which the value is visible.
#
# 		Also, on some systems this overwriting strategy is ineffective and the PW remains visible to ps.
# 		(SystemV Unix systems and perhaps otehrs are subject to this problem).
#
# IF you are using MySQL Replication, be aware that - currently - a a PW used by a replication slave as part of a CHANGE_MASTER_TO statement,
# is effectively limited to 32 chars in len.
#
# If the pw is longer, any excess chars are truncated.
#
# This is not due to any limit imposed by the MySQL Server generally, but rather is an issue specific to MySQL Replication.
# (Bug #43439)
#
# PASSWORD MANAGEMENT
#
# MySQL supports these PW management capabilities:
#
# 	) PW expiration, to require PWs to be changed periodically.
#
# 	) PW reuse restrictions, to prevent old PWs from being chosen again
#
# 	) PW verification, to require that PW changes also specify the current PW to be replaced.
#
# 	) PW strength assesment, to require strong PWs.
#
# The following sections these capabilities, except PW strength assesment, which is implemented using the validate_password plugin
# and is described later.
#
# IMPORTANT:
#
# 		MySQL implements PW management capabilities using tables in the mysql System database.
#
# 		If you upgrade MySQL from an earlier version, your system tables might not be up to date.
# 		In that case, the server writes messages similar to these to the error log during the startup process:
#
# 			[ERROR] Column count of mysql.user is wrong. Expected 49, found 47.
# 			The table is probably corrupted.
# 			[Warning] ACL table mysql.password_history missing.
# 			Some operations may fail.
#
# 		To correct the issue, run mysql_upgrade and restart the server. Until this is done, password changes are not possible.
#
# Note:
#
# 		The password-management capabilities described here apply only to accounts that store credentials internally in the 
# 		mysql.user system table (mysql_native_password, sha256_password or caching_sha2_password)
#
# 		For accounts that use plugins that perform authentication against an external credential system, PW management must be
# 		handled externally against that system as well.
#
# PASSWORD EXPIRATION POLICY
#
# MySQL enables database admins to expire account passwords manually, and to establish a policy for automatic PW expiration.
#
# Expiration policy can be established globally, and individual accounts can be set to either defer to the global policy
# or override the global policy with specific per-account behavior.  
#
# To expire an account password manually, use the ALTER_USER statement:
#
# 		ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE;
#
# This operation marks the PW expired in the corresponding mysql.user table row.
#
# Password expiration according to policy is automatic and is based on password age, which for a given
# account is assessed from the date and time of its most recent password change.
#
# The mysql.user table indicates for each account when its password was last changed, and the server
# automatically treats the pw as expired at client connection time if its age is greater than its
# permitted lifetime.
#
# This works with no explicit manual PW expiration.
#
# To establish automatic pw-expiration policy globally, use the default_password_lifetime system variable.
# Its default value is 0, which disables automatic password expiration.
#
# If the value of default_password_lifetime is a positive integer N, it indicates the permitted password
# lifetime, such that passwords must be changed every N days.
#
# Examples:
#
# 		) To establish a global policy that PWs have a lifetime of approx 6 months, start the server with these lines
# 			in a server my.cnf file:
#
# 				[mysqld]
# 				default_password_lifetime=180
#
# 		) To establish a global policy such that PWs never expire, set default_password_lifetime to 0:
#
# 				[mysqld]
# 				default_password_lifetime=0
#
# 		) default_password_lifetime can also be set and persisted at runtime:
#
# 				SET PERSIST default_password_lifetime = 180;
# 				SET PERSIST default_password_lifetime = 0;
#
# 			SET_PERSIST sets the value for the running MySQL instance.
#
# 			It also saves the value to be used for subsequent server restarts. More later on that.
#
# 			To change a value for the running MySQL instance without saving it for subsequent restarts, just use GLOBAL instead of PERSIST.
#
# The global password-expiration policy applies to all accounts that have not been set to override it.
#
# To establish policy for individual accounts, use the PASSWORD EXPIRE option of the CREATE_USER and ALTER_USER statements.
#
# Example account-specific statements:
#
# 		) Require the password to be changed every 90 days:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE INTERVAL 90 DAY;
#
# 			This expiration option overrides the global policy for all accounts named by the statement.
#
# 		) Disable password expiration:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE NEVER;
#
# 			This expiration option overrides the global policy for all accounts named by the statement.
#
# 		) Defer to the global expiration policy for all accounts named by the statement:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD EXPIRE DEFAULT;
#
# When a client successfully connects, the server determines whether the account password has expired:
#
# 		) The server checks whether the password has been manually expired.
#
# 		) Otherwise, the server checks whether the password age is greater than its permitted lifetime according to the
# 			automatic password expiration policy.
#
# 			If so, the server considers the password expired.
#
# If the password is expired (whether manually or automatically), the server either disconnects the client or restricts the
# operations permitted to it.
#
# Operations performed by a restricted client result in an error until the user establishes a new account password:
#
# 		SELECT 1;
# 		ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement.
#
# 		ALTER USER USER() IDENTIFIED BY 'password';
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		SELECT 1;
# 		+---+
# 		| 1 |
# 		+---+
# 		| 1 |
# 		+---+
# 		1 row in set (0.00 sec)
#
# After the client resets the password, the server restores normal access for the session, as well as for
# subsequent connections that use the account.
#
# It is also possible for an administrative user to reset the account password, but any existing restricted sessions
# for that account remain restricted.
#
# A client using the account must disconnect and reconnect before statements can be executed successfully.
#
# NOTE:
#
# 		It is possible to "reset" a password by setting it to its current value. As a matter of good policy, it is preferable to choose a different PW.
# 		DBAs can enforce non-reuse by establishing an appropiate password-reuse policy.
#
# PASSWORD REUSE POLICY
#
# MySQL enables restrictions to be placed on reuse of previous passwords.
# Reuse restrictions can be established based on number of password changes, time elapsed or
# both.
#
# Reuse policy can be established globally, and individual accounts can be set to either defer to the global
# policy or override the global policy with specific per-account behavior.
#
# The password history for an account consists of passwords it has been assigned in the past.
# MySQL can restrict new passwords from being chosen from this history:
#
# 		) If an account is restricted on the basis of number of password changes, a new password cannot be chosen from a specific number of
# 			the most recent passwords.
#
# 			For example, if the minimum number of password changes is set to 3, a new password cannot be the same as any of the most recent 3 PWs.
#
# 		) If an account is restricted based on time elapsed, a new PW cannot be chosen from PWs in the history that are newer than a specified
# 			number of days.
#
# 			For example, if the PW reuse interval is set to 60, a new PW must not be among those previously chosen within the last 60 days.
#
# 			NOTE: The empty password does not count in the password history and is subject to reuse at any time.
#
# To establish password-reuse policy globally, use the password_history and password_reuse_interval SYS_VARs.
#
# Examples:
#
# 		) To prohibit reusing any of the last 6 passwords or passwords newer than 365 days, put these lines in the server my.cnf file:
#
# 			[mysqld]
# 			password_history=6
# 			password_reuse_interval=365
#
# 		) To set and persist the variables at runtime, use statements like this:
#
# 			SET PERSIST password_history = 6;
# 			SET PERSIST password_reuse_interval = 365;
#
# SET_PERSIST sets the value for the running MySQL instance. It also saves the value to be used for subsequent server restarts.
# More on that later.
#
# To change a value for the running MySQL instance without saving it for subsequent restarts, use the GLOBAL keyword rather than PERSIST.
#
# The global password-reuse policy applies to all accounts that have not been set to override it.
#
# To establish policy for individual accounts, use the PASSWORD HISTORY and PASSWORD REUSE INTERVAL options
# of the CREATE_USER and ALTER_USER statements. More on that later.
#
# Example account-specific statements:
#
# 		) Require a minimum of 5 password changes before permitting reuse:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD HISTORY 5;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD HISTORY 5;
#
# 			This history-length option overrides the global policy for all accounts named by the statemnet.
#
# 		) Require a minimum of 365 days elapsed before permitting reuse:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 365 DAY;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD REUSE INTERVAL 365 DAY;
#
# 			This time-elapsed option overrides the global policy for all accounts named by the statement.
#
# 		) To combine both types of reuse restrictions, use PASSWORD HISTORY and PASSWORD REUSE INTERVAL together:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				PASSWORD HISTORY 5
# 				PASSWORD REUSE INTERVAL 365 DAY;
# 
# 			ALTER USER 'jeffrey'@'localhost'
# 				PASSWORD HISTORY 5
# 				PASSWORD REUSE INTERVAL 365 DAY;
#
# 			These options override both global policy reuse restrictions for all accounts named by the statement.
#
# 		) Defer to the global policy for both types of reuse restrictions:
#
# 			CREATE USER 'jeffrey'@'localhost'
# 				PASSWORD HISTORY DEFAULT
# 				PASSWORD REUSE INTERVAL DEFAULT;
# 			ALTER USER 'jeffrey'@'localhost'
# 				PASSWORD HISTORY DEFAULT
# 				PASSWORD REUSE INTERVAL DEFAULT;
#
# PASSWORD VERIFICATION-REQUIRED POLICY
#
# As of MySQL 8.0.13, it is possible to require that attempts to change an account PW be verified by specifying the current
# PW to be replaced.
#
# This enables DBAs to prevent users from changing a password without proving that they know the current PW.
#
# Such changes could otherwise occur, for example, if one user walks away from a terminal session temporarily without logging out,
# and someone uses the session to change the original user's MySQL PW.
#
# This can cause things like:
#
# ) The original user becoming unable to access MySQL, until PW reset by a admin
#
# ) Until the PW reset occurs, the malicious user can access MySQL with the benign user's changed credentials.
#
# PW-verification policy can be established globally, and individual accounts can be set to either defer to the global policy
# or override the global policy with specific per-account behavior.
#
# For each account, its mysql.user row indicates whether there is an account-specific setting requiring verification of
# the current PW for PW change attempts.
#
# The setting is established by the PASSWORD REQUIRE option of the CREATE_USER and ALTER_USER statements:
#
# 		) If the account setting is PASSWORD REQUIRE CURRENT, PW changes must specify the current PW.
#
# 		) If the account setting is PASSWORD REQUIRE CURRENT OPTIONAL, password changes may but need not specify the current PW
#
# 		) If the account setting is PASSWORD REQUIRE CURRENT DEFAULT, the password_require_current SYSTEM_VARIABLE determines the verification-required policy
# 			for the account:
#
# 				) If password_require_current is enabled, password changes must specify the current password.
#
# 				) If password_require_current is disabled, password changes may but need not specify the current PW.
#
# IN other words, if the account setting is not PASSWORD REQUIRE CURRENT DEFAULT, the account setting takes precedence over the
# global policy established by the password_require_current SYS_VAR.
#
# Otherwise, the account defers to the password_require_current setting.
#
# By default, PW verification is optional: password_require_current is disabled and accounts created with no PASSWORD REQUIRE
# option default to PASSWORD REQUIRE CURRENT DEFAULT.
#
# The following table shows how per-account settings interact with password_require_current SYS_VAR values to
# determine account password verification-required policy.
#
# PER-ACCOUNT SETTING 				password_require_current SYS_VAR 		Password Changes Require Current PW?
#
# PASSWORD REQUIRE CURRENT 		OFF 												Yes
#
# PASSWORD REQUIRE CURRENT 		ON 												Yes
#
# PASSWORD REQUIRE CURRENT OPT.	OFF 												No
#
# PASSWORD REQUIRE CURRENT OPT. 	ON 												No
#
# PASSWORD REQUIRE CURRENT DEF. 	OFF 												No
#
# PASSWORD REQUIRE CURRENT DEF. 	ON 												Yes
#
# Note:
#
# 		Privleged users can change any account password without specifying the current password, regardless of the verification-required
# 		policy.
#
# 		A privileged user is one who has the global CREATE_USER privlege or the UPDATE privilege for the mysql system database.
#
# To establish PW-verification policy globally, use the password_require_current SYS_VAR.
#
# Its default value is OFF, so it is not required that account password changes specify the current password.
#
# Examples:
#
# 	) To establish a global policy that PW changes must specify the current PW, start the server with these lines in the server my.cnf file:
#
# 		[mysqld]
# 		password_require_current=ON
#
# 	) To set and persist password_require_current at runtime, use a statement such as one of these:
#
# 		SET PERSIST password_require_current = ON;
# 		SET PERSIST password_require_current = OFF;
#
# SET_PERSIST sets the value for the running MySQL instance.
#
# It also saves the value to be used for subsequent server restarts. More on that later.
#
# To change a value for the running MySQL instance without saving it for subsequent restarts, use the GLOBAL keyword rather than PERSIST.
#
# The global PW verification-required policy applies to all accounts that have not been set to override it.
# To establish policy for individual accounts, use the PASSWORD REQUIRE options of the CREATE_USER and ALTER_USER statements. More on this later.
#
# Example account-specific statements:
#
# 		) Require that password changes specify the current password:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT;
#
# 			This verification option overrides the global policy for all accounts named by the statemnt.
#
# 		) Do not require that password changes specify the current password (the current PW may but need not be given):
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT OPTIONAL;
#
# 			This verification option overrides the global policy for all accounts named by the statement.
#
# 		) Defer to the global PW verification-required policy for all accounts named by the statement:
#
# 			CREATE USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;
# 			ALTER USER 'jeffrey'@'localhost' PASSWORD REQUIRE CURRENT DEFAULT;
#
# Verification of the current password comes into play when a user changes a password using the ALTER_USER or SET_PASSWORD statement.
# The examples use ALTER_USER, which is preferred ver SET_PASSWORD, but the principles described here are the same for both statements.
#
# In PW-change statements, a REPLACE clause specifies the current password to be replaced.
# Examples:
#
# 	) Change the current user's password:
#
# 			ALTER USER USER() IDENTIFIED BY 'auth_string' REPLACE 'current_auth_string';
#
# 	) Change a named user's password:
#
# 			ALTER USER 'jeffrey'@'localhost' IDENTIFIED BY 'auth_string' REPLACE 'current_auth_string';
#
# 	) Change a named user's auth plugin and PW:
#
# 			ALTER USER 'jeffrey'@'localhost' IDENTIFIED WITH caching_sha2_password BY 'auth_string' REPLACE 'current_auth_string';
#
# The REPLACE clause works like this:
#
# 	) REPLACE must be given if PW changes for the account are required to specify the current password, as verification that the user attempting to make
# 		the change actually knows the current password.
#
# 	) REPLACE is optional if PW changes for the account may but need not specify the current PW.
#
# 	) If REPLACE is specified, it must specify the correct current password, or an error occurs. This is true even if REPLACE is optional.
#
# 	) REPLACE can be specified only when changing the account password for the current user. (This means that in the examples just shown, the statements
# 		that explicitly name the account for jeffrey fail unless the current user is jeffrey).
#
# 		This is true even if the change is attempted for another user by a privileged user.
#
# 		However, if you have the privs for it, you can do such a change without REPLACE.
#
# 	) REPLACE is omitted from the binary log to avoid writing cleartext PWs to it.
#
# SERVER HANDLING OF EXPIRED PWs
#
# MySQL provides password-expiration capability, which enables database administration to require that users reset their password.
# Passwords can be expired manually, and on the basis of a policy for automatic expiration.
#
# For each connection that uses an account with an expired password, the server either disconnects the client or restricts the client
# to "sandbox mode", in which the server permits to the client only those operations necessary to reset the expired password.
#
# Which action is taken by the server depends on both client and server settings, as discussed later.
#
# If the server disconnects the client, it returns an ER_MUST_CHANGE_PASSWORD_LOGIN error:
#
# 	mysql -u myuser -p
# 	Password: ********
# 	ERROR 1862 (HY000): Your password has expired. to log in you must change it using a client that supports expired PWs.
#
# If the server restricts the client to sandbox mode, these operations are permitted within the client session:
#
# 		) The client can reset the account password with ALTER_USER or SET_PASSWORD.
# 			After the password has been reset, the server restores normal access for the session, as well as for subsequent connections that use the account.
#
# 			It is possible to "reset" a password by setting it to its current value.
# 			As a matter of good policy, it is preferable to chose a different password.
#
# 			DBAs can enforce non-reuse by establishing an appropriate PW reuse policy.
#
# 		) The client can use SET statements.
#
# For any operation not permitted within the session, the server returns an ER_MUST_CHANGE_PASSWORD error:
#
# 		USE performance_schema;
# 		ERROR 1820 (HY000): You must reset your PW using ALTER USER statement before executing this statement.
#
# 		SELECT 1;
# 		ERROR 1820 (HY000): You must reset your password using ALTER USER statement before executing this statement.
#
# That is what normally happens for interactive invocations of the mysql client because by default such invocations are put in sandbox mode.
# To clear the error and resume normal functioning, select a new PW.
#
# For noninteractive invocations of the mysql client (for example, in batch mode) - the server normally disconnects the client if the PW is expired.
#
# To permit noninteractive mysql invocations to stay connected so that the PW can be changed (using the statements just described) - add the --connect-expired-password
# option to the mysql command.
#
# As mentioned previously, whether the server disconnects an expired-password client or restricts it to sandbox mode depends on a combination
# of client and server settings.
#
# The following discussion describes the relevant settings and how they interact.
#
# the discussion applies only for accounts with expired PWs. If a client connects using a nonexpired PW, the server handles the client normally.
# 
# On the client side, a given client indicates whether it can handle sandbox mode for expired passwords.
# For clients that use the C client library, there are two ways to do this:
#
# 		) Pass the MYSQL_OPT_CAN_HANDLE_EXPIRED_PASSWORDS flag to mysql_options() prior to connecting:
#
# 			arg = 1;
# 			result = mysql_options(mysql, MYSQL_OPT_CAN_HANDLE_EXPIRED_PASSWORDS, &arg);
#
# 			The mysql client enables MYSQL_OPT_CAN_HANDLE_EXPIRED_PASSWORDS if invoked interactively or the --connect-expired-password option is given.
#
# 		) Pass the CLIENT_CAN_HANDLE_EXPIRED_PASSWORDS flag to mysql_real_connect() at connection time:
#
# 			mysql = mysql_real_connect(mysql, host, user, password, db, port, unix_socket, CLIENT_CAN_HANDLE_EXPIRED_PASSWORDS);
#
# Other MySQL Connectors have their own conventions for indicating readiness to handle sandbox mode.
#
# See respective documentation for respective connector.
#
# On the server side, if a client indicates that it can handle expired passwords, the server puts it in sandbox mode.
#
# If a client does not indicate that it can handle expired passwords (or use an older version of the client library that cannot so indicate)
# The server action depends on the value of the disconnect_on_expired_password SYS_VAR:
#
# 		) If disconnect_on_expired_password is enabled (the default), the server disconnects the client with an ER_MUST_CHANGE_PASSWORD_LOGIN error.
#
# 		) If disconnect_on_expired_password is disabled, the server puts the client in sandbox mode.
#
# PLUGGABLE AUTHENTICATION
#
# When a client connects to the MySQL server, the server uses the user name provided by the client and the client host to select
# the appropriate account row from the mysql.user system table.
#
# The server then authenticates the client, determining from the account row which authentication plugin applies to the client:
#
# 		) If the server cannot find the plugin, an error occurs and the connection attempt is rejected.
#
# 		) Otherwise, the server invokes that plugin to authenticate the user, and the plugin returns a status to the server indicating
# 			whether the user provided the correct password and is permitted to connect.
#
# Pluggable authentication enables these important capabilities:
#
# 		) Choice of authentication methods. Pluggable authentication makes it easy for DBAs to choose and change the authentication method
# 			using for individual MySQL accounts.
# 
# 		) External authentication. Pluggable authentication makes it possible for clients to connect to the MySQL server with credentials appropriate
# 			for authentication methods that store credentials elsewhere than in the mysql.user system table.
#
# 			For example, plugins can be created to use external authentication methods such as PAM, Windows login IDs, LDAP or Kerberos.
#
# 		) Proxy users: If a user is permitted to connect, an authentication plugin can return to the server a user name different from the name of the
# 			connecting user, to indicate that the connecting user is a proxy for another user (the proxied user).
#
# 			While the connection lasts, the proxy user is treated, for purposes of access control, as having the privileges of the proxied user.
#
# 			In effect, one user impersonates another.
#
# 			NOTE:
#
# 				If you start the server with the --skip-grant-tables option, authentication plugins are not used even if loaded because the server performs
# 				no client authentication and permits any client to connect.
#
# 				Because this is insecure, if the server is started with the --skip-grant-tables option, it enables --skip-networking automatically to prevent
# 				remote connections.
#
# AVAILABLE AUTHENTICATION PLUGINS
#
# MySQL 8.0 provides these authentication plugins:
#
# 		) A plugin that performs native authentication. That is , authentication based on the PW hashing method in use from before the introduction of
# 			pluggable authentication in MySQL.
#
# 			The mysql_native_password plugin implements authentication based on this native password hashing method.
#
# 		) Plugins that perform authentication using SHA-256 password hashing.
#
# 			This is stronger encryption than available with native authentication.
#
# 		) A client-side plugin that sends the password to the server without hasing or encryption. This plugin is used in conjunction with
# 			server-side plugins that require access to the password exactly as provided by the client user.
#
# 		) A plugin thaht performs external authentication using PAM (Pluggable Authentication Modules), enabling MySQL Server to use PAM to authenticate
# 			MySQL users..
#
# 			This plugin supports proxy users as well.
#
# 		) A plugin that performs external authentication on Windows, enabling MySQL server to use native Windows services to authenticate client connections.
# 		 	USers who have logged in to Windows can connect from MySQL client programs to the server based on the information in their environment without
# 			specifying an additional PW.
#
# 			This plugin supports proxy users as well.
#
# 		) Plugins that perform authentication using LDAP (Lightweight Directory Access Protocol) to authenticate MySQL users by accessing directory services
# 			such as X.500
#
# 			These plugins support proxy users as well.
#
# 		) A plugin that prevents all client connections to any account that uses it. Use cases for this plugin include proxied accounts that should never permit
# 			direct login but are accessed only  through proxy accounts and accounts that must be able to execute stored programs and views with elevated privileges
# 			without exposing those privileges to ordinary users.
#
# 		) A plugin that authenticates clients that connect from the local host through the Unix socket file.
#
# 		) A test plugin that  checks account credentials and logs success or failure to the server error log. This plugin is intended for testing
# 			and development purposes - as an example of how to write an authentication plugin, covered later.
#
# NOTE:
#
# 		For information about current restrictions on the use of pluggable authentication, include which connectors support which plugins.
#
# 		Third-party connector developers should read that section to determine the extent to which a connector can take advantage of pluggable
# 		authentication capabilities and what steps to take to become more compliant.
#
# If you are interested in writing own authentication plugins, more later.
#
# AUTHENTICATION PLUGIN USAGE
#
# This section provides general instructions for installing and using authentication plugins.
# For instructions specific to a given plugin, see the section later.
#
# In general, pluggable authentication uses a pair of corresponding plugins on the server and client sides, so you use a given authentication method
# like this:
#
# 		) If necessary, install the plugin library or libraries containing the appropiriate plugins.
#
# 			On the server host, install the library containing the server-side plugin, so that the server can use it to authenticate
# 			client connections.
#
# 			SImilarly, on each client host, install the library containing the client-side plugin for use by client programs.
#
# 			Authentication plugins that are built in need not be installed.
#
# 		) For each MySQL account that you create, specify the appropriate server-side plugin to use for authentication. If the account
# 			is to use the default authentication plugin, the account-creation statement need not specify the plugin explicitly.
#
# 			The default_authentication_plugin SYS_VAR configures the default authentication plugin.
#
# 		) When a client connects, the server-side plugin tells the client program which client-side plugin to use for authentication.
#
# In the case that an account uses an authentication method that is the default for both the server and the client program, the server
# need not communicate to the client which client-side plugin to use, and a round trip in client/server negotiation can be avoided.
#
# For standard MySQL clients such as mysql and mysqladmin, the --default-auth=plugin_name option can be specified on the command line
# as a hint about which client-side plugin the program can expect to use, although the server will override this if the server-side plugin
# associated with the user account requires a different client-side plugin.
#
# If the client program does not find the client-side plugin library file, specify a --plugin-dir=dir_name option to indicate the plugin
# library directory location.
#
# AUTHENTICATION PLUGIN CLIENT/SERVER COMPATIBILITY
#
# Pluggable authentication enables flexibility in the choice of authentication method for MySQL accounts, but in some cases client connections
# cannot be established due to authentication plugin incompatibility between the client and server..
#
# The general compatibility principle for a successful connection to a given account on a given server is that the client and 
# server both must support the autheitcation method required by the account.
#
# Because authentication methods are implemented by authentication plugins, the client and server both must support the authentication
# plugin required by the account.
#
# Authentication plugin incompatibilities can arise in various ways. Examples:
#
# 		) Connect using a MySQL 5.7 client from 5.7.22 or lower to a MysQL 8.0 server account that authenticates with caching_sha2_password.
#
# 			This fails because the 5.7 client does not recognize the plugin, which was introduced in 8.0
#
# 			(This issue was addressed in MySQL 5.7 as of 5.7.23, when caching_sha2_password client-side support was added to the MySQL client library
# 			and client programs).
#
# 		) Connect using a MySQL 5.5 client to a MySQL 5.6 client server acc that authenticates with sha256_password.
#
# 			This fails because the 5.5. does not recognize the plugin, whic was introduced in MySQL 5.6
#
# 		) connect using a MySQL 5.7 client  from a community distrib to a MySQL 5.7 >Enterprise server account that authenticates using one of the
# 			Enterprise-only LDAP authentication plugins. This fails because the community client does not have access to said plugin.
#
# In general, these compatibility issues do not arise when connections are made between a client and server from the same MySQL distrib.
# When connections are made between a client and server from different MySQL series, issues can arise.
#
# these issues are inherent in the development process when MysQL introduces new authentication plugins or removes old ones.
# To minimize the potentional for incompatibilities, regularly update the server, clients and connectors on a timely basis.
#
# AUTHENTICATION PLUGIN CONNECTOR-WRITING CONSIDERATIONS
#
# Various implementations of the MySQL client/server protocol exist. The libmysqlclient C API client library is one implementation.
#
# Some MySQL connectors (typically those not written in C) provide their own implementation. However, not all protocol implementations
# handle plugin authentication in the same way.
#
# This section describes an authentication issue that protocl implementors should take into account.
#
# In the client/Server protocol, the server tells connecting clients which authentication plugin it considers the default.
#
# If the protocol implementation used by the client tries to load the default plugin and that plugin does not exist on the client side,
# the load ops fails.
#
# this is an unnecessary failure if the default is not the plugin actually required by the account to which the client is trying to connect. 
#
# If a client/server protocol implementation does not have its own notion of default authentication plugin and always tried to load the default
# plugin specified by the server, it will fail with an error if that plugin is not available.
#
# To avoid this problem, the protocol implementation used by the client should have its own default plugin and should use it as its first choice,
# (or, alternatively, fall back to this default in case of failrue to load the default plugin specified by the server). Example:
#
# 		) In MysQL 5.7, libmysqlclient uses as its default choice either mysql_native_password or the plugin specified through the MYSQL_DEFAULT_AUTH option
# 			for mysql_options()
#
# 		) When a 5.7 client tries to connect to a 8.0 server, the server specifies caching_sha2_password as its default authentication plugin, but the client
# 		still sends credential details per either mysql_native_password or whatever is specified through MYSQL_DEFAULT_AUTH
#
# 		) The only time the client loads the plugin specified by the server is for a change-plugin request,, but in that case it can be any plugin
# 			depending on the user account.
#
# 			IN this case, the client must try to load the plugin, and if that plugin is N/A - an error is not optional.
#
# PROXY USERS
#
# The MySQL server authenticates client connections using authentication plugins. The plugin that authenticates a given connection may request that
# 	the connecting (external) user be treated as a different user for privilege-checking purposes.
#
# This enables the external user to be a proxy for the second user; that is, to assume the privileges of teh second user:
#
# 		) The external user is a "proxy user" (a user who can impersonate or become known as another user)
#
# 		) The second user is a "proxied user" (a user whose identity and privs can be assumed by a proxy user)
#
# This section describes how the proxy user capabilitiy works. For general information about auth plugins, see earlier.
#
# FOr more info about seeing how to write a plugin that supports authentication of proxy users, see later.
#
# NOTE:
#
# 		AS an alternative to the use of proxy users, role support may provide a suitable way to map users onto specific sets
# 		of named privileges.
#
# REQUIREMENTS FOR PROXY USER SUPPORT
#
# For proxying to occur for a given authentication plugin, these conditions must be satisfied:
#
# 		) Proxying must be supported, either by the plugin itself, or by the MySQL server on behalf of the plugin.
# 			In teh latter case, server support may need to be enabled explicitly.
#
# 		) The proxy user account must be set up to be authenticated by the plugin. Use the CREATE_USER statement to associate
# 			an account with an authentication plugin, or ALTER_USER to change its plugin.
#
# 		) The proxied user account must be created and granted the privileges to be assumed by the proxy user. Use the CREATE_USER and GRANT statements for this.
#
# 		) The proxy user account must have the PROXY privilege for hte proxied account. Use the GRANT statemnet for this.
#
#		) For a client connecting to the proxy account to be treated as a proxy user, the authentication plugin must return a user name different
#			from the client user name - to indicate the user name of the proxied account that defines the privileges to be assumed by the proxy user.
#
# 			Alternatively, for plugins that are provided proxy mapping by the server, the proxied user is determined from the PROXY privilege held by the proxy user.
#
# The proxy mechanism permits mapping only the client user name to the proxied user name.
#
# THere is no provision for mapping host names. When a connecting client matches a proxy account, the server attempts to find a match
# for a proxied account using the user name returned by the authentication plugin and teh host name of the proxy account.
#
# Consider the following account definitions:
#
# 		-- create proxy account
# 		CREATE USER 'employee_ext'@'localhost' IDENTIFIED WITH my_auth_plugin AS 'my_auth_string';
#
# 		--  create proxied account and grant its privileges
# 		CREATE USER 'employee'@'localhost' IDENTIFIED BY 'employee_pass';
# 		GRANT ALL ON employees.* TO 'employee'@'localhost';
#
# 		-- grant PROXY privilege to proxy account for proxied account
# 		GRANT PROXY ON 'employee'@'localhost' TO 'employee_ext'@'localhost';
#
# When a client connects as employee_ext from the local host, MySQL uses the plugin named my_auth_plugin to perform
# authentication.
#
# SUppose that my_auth_plugin returns a user name of employee to the server, based on the content of 'my_auth_string' and perhaps
# by consulting some external authentication system.
#
# The name employee differs from employee_ext, so returning employee serves as a request to the server to treat the employee_ext client,
# for purposes of privilege checking, as the employee local user.
#
# In this case, employee_ext is the proxy user and employee is the proxied user.
#
# The server verifies that proxy authentication for employee is possible for the employee_ext user by checking whether employee_ext
# (the proxy user) has the PROXY privilege for employee (the proxied user).
#
# If this privilege has not been granted, an error occurs. Otherwise, employee_ext assumes the privileges of employee.
# The server checks statements executed during the client session by employee_ext against the privileges granted to employee.
#
# IN this case, employee_ext can access tables in the employee database.
#
# WHen proxying occurs, the USER() and CURRENT_USER() functions can be used to see the difference between the connecting user 
# (the proxy user) and the account whose privileges apply during the current session (the proxied user).
#
# For the example just described, those functions return these values:
#
# 		SELECT USER(), CURRENT_USER();
# 		+------------------------+--------------------+
# 		| USER() 					 | CURRENT_USER() 	 |
# 		+------------------------+--------------------+
# 		| employee_ext@localhost | employee@localhost |
# 		+------------------------+--------------------+
#
# In the CREATE_USER statement that creates the proxy user account, the IDENTIFIED WITH clause that names the authenticatiojn
# plugin is optionally followed by an AS 'auth_string' clause specifying a string that hte server passes to the plugin when the
# user connects.
#
# If present, the string provides information that helps the plugin determine how to map the external client user name to a proxied user name.
# It is up to each plugin whether it requires the AS clause.
#
# If so, the format of the authentication string depends on how the plugin intends to use it.
# Consult the documentation for a given plugin for information about the authentication string values it accepts.
#
# GRANTING THE PROXY PRIVLEGE
#
# The PROXY privilege is needed to enable an external user to connect as and have the privileges of another user..
# To grant this privilege, use the GRANT statement.
#
# For example:
#
# 		GRANT PROXY ON 'proxied_user' TO 'proxy_user';
#
# THe statement creates a row in the mysql.proxies_priv grant table.
#
# At connection time, proxy_user must represent a valid externally authenticated MysQL user, and proxied_user must represent
# a valid locally authenticated user.
#
# Otheriwse, the connection attempt fails.
#
# The corresponding REVOKE syntax is:
#
# 		REVOKE PROXY ON 'proxied_user' FROM 'proxy_user';
#
# MySQL GRANT and REVOKE syntax extensions wokr as usual. For example:
#
# 		GRANT PROXY ON 'a' TO 'b', 'c', 'd';
#		GRANT PROXY ON 'a' TO 'd' WITH GRANT OPTION;
# 		GRANT PROXY ON 'a' TO ''@'';
# 		REVOKE PROXY ON 'a' FROM 'b', 'c', 'd';
#
# The PROXY privilege can be granted in these cases:
#
# 		) By a user that has GRANT PROXY ... WITH GRANT OPTION for proxied_user.
#
# 		) By proxied_user for itself: The value of USER() must exactly match CURRENT_USER() and proxied_user, for both the user name and host name parts
#			of the account name.
#
# The initial root account created during MySQL installation has the PROXY_..._WITH_GRANT_OPTION privileges for ''@'', that is, for all users and all hosts.
# This enables root to set up proxy users, as well as to delegate to other accoutns the authority to set up proxy users.
#
# FOr example, root can do this:
#
# 		CREATE USER 'admin'@'localhost' IDENTIFIED BY 'test';
# 		GRANT PROXY ON ''@'' TO 'admin'@'localhost' WITH GRANT OPTION;
#
# Those statements create an admin user that can manage all GRANT PROXY mappings. For example, admin can do this:
#
# 		GRANT PROXY ON sally TO joe;
#
# DEFAULT PROXY USERS
#
# To specify that some or all users should connect using a given authentication plugin, create a "blank" MySQL acc (''@''), associate it
# with that plugin, and let hte plugin reutrn the real authenticated user name (if different from the blank user).
#
# For example, suppose that there exists a plugin named ldap_auth that implements LDAP authentication and maps connecting
# users unto either a developer or manager account.
#
# To set up proxying of users unto these accounts, use the following statements:
#
# 		-- create default proxy account
# 		CREATE USER ''@'' IDENTIFIED WITH ldap_auth AS '0=Oracle, OU=MySQL';
#
# 		-- create proxied accounts
# 		CREATE USER 'developer'@'localhost' IDENTIFIED BY 'developer_pass';
# 		CREATE USER 'manager'@'localhost' IDENTIFIED BY 'manager_pass';
#
# 		-- grant PROXY privileges to default proxy acount for proxied accounts
# 		GRANT PROXY ON 'manager'@'localhost' TO ''@'';
# 		GRANT PROXY ON 'developer'@'localhost' TO ''@'';
#
# Now assume that a client connects as follows:
#
# 		mysql --user=myuser --password
# 		Enter PW: *****
#
# The server will not find myuser defined as a MySQL user. But because there is a blank user account (''@'') that matches
# the client user name and host name, the server authenticates the client against that account.
#
# The server invokes the ldap_auth authentication plugin and passes myuser and myuser_pass to it as the user name and user PW.
#
# If the ldap_auth plugin finds in the LDAP directory that myuser_pass is not the  correct password for myuser, authentication
# fails and the server rejects the connection.
#
# If the PW is correct and ldap_auth finds that myuser is a developer, it returns the user name developer to the MySQL server, rather than
# myuser.
#
# Returning a user name different from the client user name of myuser signals to the server that it hsould treat myuser as a proxy.
# THe server verifies that ''@'' can authenticate as developer (because that account has the PROXY privilege to do so), and accepts the connection.
#
# The session proceeds with myuser having the privileges of developer, the proxied user.
#
# (These privileges should be set up by the DBA using GRANT stratements, not shown).
#
# The USER() and CURRENT_USER() functions return these values:
#
# SELECT USER(), CURRENT_USER();
# +---------------------+-----------------+
# | USER() 			   | CURRENT_USER() 	   |
# +------------------+--------------------+
# | myuser@localhost | developer@localhost|
# +------------------+--------------------+
#
# If the plugin instead finds in the LDAP directory that myuser is a manager, it returns manager as the user name and session proceeds
# with myuser having the privileges of manager.
#
# SELECT USER(), CURRENT_USER();
# +------------------+------------------+
# | USER() 			   | CURRENT_USER() 	 |
# +------------------+------------------+
# | myuser@localhost | manager@localhost|
# +------------------+------------------+
#
# For simplicity, external authentication cannot be multilevel: Neither the credentials for developer nor those for manager are taken into account
# in the preceding example.
#
# However, they are still used if a client tries to connect and authenticate directly as the developer or manager account, which is why
# those accounts should be assigned PWs.
#
# DEFAULT PROXY USER AND ANON USER CONFLICTS
#
# If you intend to create a default proxy user, check for other existing "match any user" accounts that take precedence over the default proxy
# user because they can prevent that user from working as intended.
#
# In the preceding discussion, the default proxy user account has '' in the host part, which matches any host. 
#
# If oyu set up a default proxy user, take care to also check whether nonproxy accounts exist with the same user part and '%' in the host part,
# because '%' is wildcard matching, but has precedence over '' because it's more specific.
#
#
# Suppose that a MySQL installation includes these two accounts:
#
# 		-- create default proxy account
# 		CREATE USER ''@'' IDENTIFIED WITH some_plugin AS 'some_auth_string';
# 		-- create anonymous account
# 		CREATE USER ''@'%' IDENTIFIED BY 'some_password';
#
# The first account (''@'') is intended as the default proxy user, used to authenticate connections for users who do not otherwise match a 
# more-specific account.
#
# THe second account (''@'%') is a anonymous user acc, which might have bene created for example, to enable users without their own acc to connect anonymously.
#
# Both accounts have the same user part (''), which matches any user.
# And each account has a host part that matches any host.
#
# Nevertheless, there is a prio in account matching for connection attempts because the matching rule sort a host of '%' ahead of ''.
# For accoutns that do not match any more-specific account, the server attempts to authenticate them against ''@'%' (anon), rather than ''@'' (default proxy).
#
# The result is that the default proxy acc is never used.
#
# To avoid this, use one of the following strategies:
#
# 		) Remove the anon account so that it does not conflict with the default proxy user.
# 			This might be a good idea anyway, if  you want to associate every connection with a named user.
#
# 		) Use a more-specific default proxy user that matches ahead of the anon user. For example, to permit only localhost proxy connections, use ''@'localhost':
#
# 			CREATE USER ''@'localhost' IDENTIFIED WITH some_plugin AS 'some_auth_string';
#
# 			In addition, modify any GRANT PROXY statements to name ''@'localhost' rather than ''@'' as the proxy user.
#
# 			This prevents anon users from localhost, as they will be funneled to the proxy instead.
#
# 		) Create multiple proxy users, one for local connections and one for "everything else" (remote).
# 			This can be useful particularly when local users should have different privileges from remote users.
#
# 			Create the proxy users:
#
# 				-- create proxy user for local connections
# 				CREATE USER ''@'localhost' IDENTIFIED WITH some_plugin AS 'some_auth_string';
# 				-- create proxy user for remote connections
# 				CREATE USER ''@'%' IDENTIFIED WITH some_plugin AS 'some_auth_string';
#
# 			Create the proxied users:
#
# 				-- create proxied user for local connections
# 				CREATE USER 'developer'@'localhost' IDENTIFIED BY 'some_password';
# 				-- create proxied user for remote connections
# 				CREATE USER 'developer'@'%' IDENTIFIED BY 'some_password';
#
# 			Grant the proxy privilege to each proxy user for the corresponding proxied user:
#
# 				GRANT PROXY ON 'developer'@'localhost' TO ''@'localhost';
# 				GRANT PROXY ON 'developer'@'%' TO ''@'%';
#
# 			Finally, grant appropiate privs to the local and remote proxied users (not shown)
#
# 			Assume that the some_plugin/'some_auth_string' combination causes some_plugin to map the client user name
# 			to developer.
#
# 			Local connections match the ''@'localhost' proxy user, which maps to the 'developer'@'localhost' proxied user.
# 			Remote connections match the ''@'%' proxy user, which maps to the 'developer'@'%' proxied user.
#
# SERVER SUPPORT FOR PROXY USER MAPPING
#
# 	Some authentication plugins implement proxy user mapping for themselves (for example, the PAM and Windows authentication plugins).
# 	Other authentication plugins do not support proxy users by default.
#
# 	Of these, some can request that hte MySQL server itself map proxy users according to granted proxy privileges:
#
# 		mysql_native_password, sha256_password.
#
# 	If the check_proxy_users SYS_VAR is enabled, the server performs proxy user mapping for any authentication plugins that make such a request:
#
# 		) By default, check_proxy_users is disabled, so the server performs no proxy user mapping even for authentication plugins that request server support for proxy users.
#
# 		) If check_proxy_users is enabled, it may also be necessary to enable plugin-specific SYS_VAR to take advantage of server proxy user mapping support:
#
# 			) For the mysql_native_password plugin, enable mysql_native_password_proxy_users.
#
# 			) For the sha256_password plugin, enable sha256_password_proxy_users
#
# Proxy user mapping performed by the server is subject to these restrictions:
#
# 		) The server will not proxy to or from an anon user, even if the associated PROXY privilege is granted.
#
# 		) When a single account has been granted proxy privileges for more than one proxied account, server proxy user mapping is nondeterministic.
# 			Therefore, granting to a single account proxy privileges for multiple proxy accounts is discouraged.
#
# PROXY USER SYSTEM VARIABLES
#
# Two system variables help trace the proxy login process:
#
# 		) proxy_user: THis value is NULL if proxying is not used. Otherwise, it indicates the proxy user account.
# 							For example, if a client authenticates through the ''@'' proxy account, this variable is set as follows:
#
# 								SELECT @@proxy_user;
# 								+---------------------------+
# 								| @@proxy_user 				 |
# 								+---------------------------+
# 								| ''@'' 							 |
# 								+---------------------------+
#
# 		) external_user: Sometimes the authentication plugin may use an external user to authenticate to the MySQL server.
#
# 								For example, when using Windows native authentication, a plugin that authenticates using the Windows API does not need the
# 								login ID passed to it.
# 
# 								However, it still uses Windows user ID to authenticate.
# 								The plugin may return this external user ID (or the first 512 UTF-8 bytes of it)
# 								to the server using the external_user read-only session variable.
#
# 								If the plugin does not set this variable, its value is NULL.
#
# USER ACCOUNT LOCKING
#
# MySQL supports locking and unlocking user accounts using the ACCOUNT LOCK and ACCOUNT UNLOCK clause for the CREATE_USER and ALTER_USER statements:
#
# 		) When used with CREATE_USER, these clauses specify the initial locking state for a new account.
#
# 			IN the absence of either clause, the account is created in an unlocked state.
#
# 		) WHen used with ALTER_USER, these clauses specify the new locking state for an existing account.
#
# 			In the absence of either clause, the account locking state remains unchanged.
#
# Account locking state is recorded in the account_locked column of the mysql.user table.
# The output from SHOW_CREATE_USER indicates whether an account is locked or unlocked.
#
# If a client attempts to connect to a locked account, the attempt fails. 
#
# THe server increments the Locked_connects status variable that indicates the number 
# of attempts to connect to a locked account, returns an ER_ACCOUNT_HAS_BEEN_LOCKED error, and writes am essage to the error log:
#
# 		Access denied for user 'user_name'@'host_name'
# 		Account is locked.
#
# Locking an account does not affect being able to connect using a proxy user that assumes the identity of the locked account.
# It also does not affect the ability to execute stored programs or views that have a DEFINER clause naming the locked account.
#
# That is, teh ability to use a proxied account or stored programs or views is not affected by locking the account.
#
# The account-locking capability depends on the presence of the account_locked column in the mysql.user table.
# For upgrades to MysQL 5.7 and later from older versions, run mysql_upgrade to ensure that this column exists.
#
# For nonupgraded installations that have no account_locked column, the server treats all accounts as unlocked,
# and using the ACCOUNT LOCK or ACCOUNT UNLOCK clause produces an error.
#
# SQL-BASED MYSQL ACCOUNT ACTIVITY AUDITING
#
# Applications can use the following guidelines to perform SQL-based auditing that ites database activity
# to MySQL accounts.
#
# MySQL accounts correspond to rows in the mysql.user table. WHen a client connects successfully, the server
# authenticates the client to a particular row in this table.
#
# The User and Host column vlaues in this row uniquely identify the account and correspond to the 'user_name'@'host_name'
# format in which account names are written in SQL statements.
#
# The account used to authenticate a client determines which privileges the client has.
# Normally, the CURRENT_USER() function can be invoked to determien which account this is for the client user.
#
# Its value is constructed from the User and Host columns of the user table row for the account.
#
# However, there are circumstances under which the CURRENT_USER() value corresponds not to the client user but to
# a different account.
#
# this occurs in contexts when privilege checking is not based on the client's account:
#
# 		) Stored routines (procedures and functions) defined with the SQL SECURITY DEFINER characteristic
#
# 		) Vies defined with the SQL SECURITY DEFINER characteristic
#
# 		) Triggers and events
#
# In those contexts, privlege checking is odne against the DEFINER account and CURRENT_USER() refers to that account
# for the client who invoked the stored routine or view or who caused the trigger to activate.
#
# To determine the invoking user, you can call the USER() function, which returns a value indicating the  actual
# user name provided by the client and the host from which the client connected.
#
# However, this value does not necessarily correspond directly to an account in the user table, because 	the USER()
# value never contains wildcards, whereas account values (as returned by the CURRENT_USER()) may contain user name
# and host name Wildcards.
#
# For example, a blank user name matches any user, so an account of ''@'localhost' enables clients to connect as anon users
# from the local host with any user name.
#
# In this case, if a client as user1 from the local host, USER() and CURRENT_USER() return different values:
#
# SELECT USER(), CURRENT_USER();
# +------------------------------------+
# | USER() 				| CURRENT_USER() 	|
# +------------------+-----------------+
# | user1@localhost 	| @localhost 		|
# +------------------+-----------------+
#
# The host name part of an account can contain wildcards, too.
#
# If the host name contains '%' or '_' pattern chars or uses netmask notation, the account can be used for
# clients connecting from multiple hosts and the current_USER() value will not indicate which one.
#
# For example, the account 'user2'@'%.example.com' can be used by user2 to connect from any host inb the example.com domain.
# If user2 connects from remote.example.com, USER() and CURRENT_USER() return sdifferent values:
#
# SELET USER(), CURRENT_USER();
# +----------------------------+----------------------+
# | USER() 							| CURRENT_USER() 			|
# +---------------------------+-----------------------+
# | user@remote.example.com 	| user2@%.example.com 	|
# +---------------------------+-----------------------+
# 
# If an application must invoke USER() for user auditing (for example, if it does auditing from within triggers) but must also
# be able to associate the USER() value with an account in the user table, it is necessary to avoid accounts that contain wildcards
# in the User and Host column.
#
# Specifically, do not permit User to be empty (which creates an anonymous-user account), and do not permit pattern characters
# or netmask notation in Host values.
#
# All accounts must have a nonempty User  value and literal Host value.
#
# WIth respect to the previous examples, the ''@'localhost' and 'user2'@'%.example.com' accounts should be changed not to use wildcards:
#
# RENAME USER ''@'localhost' TO 'user1'@'localhost';
# RENAME USER 'user2'@'%.example.com' TO 'user2'@'remote.example.com';
#
# If user2 must be able to ocnnect from several hosts in the example.com domain, there should be a separate account for each host.
#
# To extract the user name or host name part from a CURRENT_USER() or USER() value, use the SUBSTRING_INDEX() function:
#
# SELECT SUBSTRING_INDEX(CURRENT_USER(), '@',1);
# +-------------------------------------------------+
# | SUBSTRING_INDEX(CURRENT_USER(), '@', 1) 			 |
# +-------------------------------------------------+
# | user1 														 |
# +-------------------------------------------------+
#
# SELECT SUBSTRING_INDEX(CURRENT_USER(), '@', -1);
# +-------------------------------------------------+
# | SUBSTRING_INDEX(CURRENT_USER(), '@', -1) 		 |
# +-------------------------------------------------+
# | localhost 													 |
# +-------------------------------------------------+
#
# USING ENCRYPTED CONNECTIONS
#
# With an unencrypted connection between the MySQL client and the server, someone with access to the network could watch
# all your traffic and inspect the data being sent or received between client and server.
#
# When you msut move information over a network in a secure fahsion, an unencrypted connection is unacceptable.
# To make ay kind of data unreadable, use encryption.
#
# Encryption algorithms must include security elements to resist many kinds of known attacks such as changing the order of encrypted messages
# or replaying data twice.
#
# MySQL supports encrypted connections between clients and the server using the TLS (Transport Layer Security) protocol.
#
# TLS is sometimes referred to as SSL (Secure SOcket Layer), but MySQL doesn ot actually use the SSL protocol for encrypted connections
# because it's encryption is weak.
#
# TLS uses encryption algorithms to ensure htat data received over a public network can be trusted.
#
# It has mechanisms to detect data change, loss or replay. TLS also incorporates algorithms that provide identity verification
# using the X.509 standard
#
# X.509 makes it possible to identify someone on the Internet. IN basic terms, there should be some entity called a "Certificate Authority" (or CA) that assigns
# electronic certificates to anyone who needs them.
#
# Certificates rely on asymmetric encryption algorithms that have two encryption keys (public and secret).
# A ceritifcate owner  can present the certificate to naother party as proof of identity.
#
# A certificate consists of its owner's public key. Any data encrypted using this public key can be decrypeted using only the corresponding
# secret key, which is held by the owner of the cert.
#
# MySQL can be compiled for encrypted-connection support using OPenSSL or wolfSSL. More on that later.
#
# By default, MySQL propgrams attempts to connect using encryption if the server supports encrypted connections, falling back to
# an unencrypted connection if an encrypted connection cannot be established.
#
# MySQL performs encryption on a per-connection basis, and use of encryption for a given user can be optional or mandatory.
# This enables you to choose an encrypted or unencrypted connection according to the reuqirements of individual applications.
#
# For more info on how to requrie users to use encrypted connections, see the discussion of the REQUIRE clause of the CREATE_USER statement
# (more on that later).
#
# See also the desc. of the require_secure_transport System variable.
#
# ENcrypted connections can be used between master and slave replication servers, more on that later.
#
# For more info about using encrypted connections from the MySQL C API, more on that later.
#
# It is also possible to connect using encryption from within an SSH connection to the MySQL server host.
#
# CONFIGURING MYSQL TO USE ENCRYPTED CONNECTIONS
#
# Several options are avilable to indicate whether to use encrypted connections, and to specify the appropriate certificate and key files.
# This section provides general guideance about configuring the server and clients for encrypted connections:#
# 
# SERVER-SIDE CONFIGURATION FOR ENCRYPTED CONNECTIONS
#
# On the server side, the --ssl option specifies that the server permits but does not require encrypted connections.
# This option is enabled by default.
#
# These options on the server side identify the certificate and key files the server uses when permitting clients to establish
# encrypted connections:
#
# 		) --ssl-ca: The path name to the Ceritifcate Authority (CA) cert file (--ssl-capath is similar but specifies the path name of a directory of CA certificate files)
#
# 		) --ssl-cert: tHe path name of hte server public key certificate file. This can be sent to the client nad authenticated against the CA ceritifcate that it has.
#
# 		) --ssl-key: The path name of the server private key file.
#
# For example to enable the server for encrypted connections, start it with these lines in the my.cnf file, changing the ifle names as necessary:
#
# 		[mysqld]
# 		ssl-ca=ca.pem
# 		ssl-cert=server-cert.pem
# 		ssl-key=server-key.pem
#
# Each option names a file in PEM format. If oyu need to create the reuqired certificate and key files, see more later.
#
# Alternatively, if you have a MySQL source distrib, you can test your setup using the demonstration certificate and key files in tis
# mysql-test/std_data dir.
#
# MySQL servers compiled using OpenSSL can generate missing certificate and key files automatically at startup.
#
# THe server performs certificate and key file autodiscovery. If --ssl is enabled (possibly along with --ssl-cipher) and other --ssl-xxx options are not given
# to configure encrypted connections explicitly, the server attemtps to enable support for encrypted connections automatically at startup:
#
# 		) If the server discovers valid certificate and key files named ca.pem, server-cert.pem, and server-key.pem in the data dir, it enables support for
# 			encrypted connections by clients. (The files need not have been generated automatically, what matters is that they have the indicated names and are valid).
#
# 		) If the server does not find valid certificate and key files in the data directory, it continues executing but without support for encrypted connections.
#
# If the server automatically enables support for encrypted connections, it writes a note to the error log.
# If the server discovers that hte CA certificate is self-signed, it writes a 	warning to hte error log .(Teh certificate if self-signed if created automatically by the server,
# or manually using mysql_ssl_rsa_setup).
#
# The server uses the names of any automatically discovered and used certificate and key files to set the corresponding system variable (ssl_ca, ssl_cert, ssl_key)
#
# For further control over whether clients must connect using encryption, use the require_secure_transport system variable.
# To specify permitted encrypted protocols explicitly, use the tls_verison system variable.
#
# CLIENT-SIDE CONFIGURATION FOR ENCRYPTED CONNECTIONS
#
# By default, MySQL client programs attempt to establish an encrypted connection if the server supports encrypted connections, with further control
# available through the -ssl-mode option:
#
# 		) In the absence of an --ssl-mode option, clients attempt to connect using encryption, falling back to an unencrypted connection if an encrypted
# 			connection cannot be established.
#
# 			THis is also the behavior with an explicit --ssl-mode=PREFFERED option.
#
# 		) With --ssl-mode=REQUIRED, clients requrie an encrypted connection and fail ifo ne cannto be stablished.
#
# 		) with --ssl-mode=DISABLED, client use an unencrypted connection.
#
# 		) With --ssl-mode=VERIFY_CA or --ssl-mode=VERIFY_IDENTITY, clients require an encrypted connection, and also perform verification
# 			against the server CA certificate and (with VERIFY_IDENTITY) against the server host name in its certificate.
#
# The following options on the client side identify the certificate and key files clients use when establishing encrypted connections to the server.
# They are similar to the options used on the server side, but --ssl-cert and --ssl-key identify the client public and privat key:
#
# 		) --ssl-ca: The path name of the Certificate Authority (CA) certificate file. This option, if used, must specify the same ceritifcate used by the server.
# 						(the --ssl-capath is similar but specifies the path name of a  DIrectory of CA certificate files).
#
# 		) --ssl-cert: The path name of the client public key certificate file.
#
# 		) --ssl-key: THe path name of the client private key file.
#
# For additional security relative to that provided bny the default encryption, clients can supply a CA certificate matching the one used by the
# server and enable host name identity verification.
#
# IN this way, teh servr and client place their trust in the same CA certificate and client verifies that the host to which it connected
# is the one intended:
#
# 		) To specify the CA certificate, use --ssl-ca (or --ssl-capath), and specify --ssl-mode=VERIFY_CA
#
# 		) To enable host name identity verification as well, use --ssl-mode=VERIFY_IDENTITY rather than --ssl-mode=VERIFY_CA
#
# 		NOTE:
#
# 			Host name identity verification does not work with self-signed certificates created automatically by the server, or manually using 
# 			mysql_ssl_rsa_setup.
#
# 			Such self-signed certificates do not contain the server name as the Common Name value.
#
# Depending on the encryption requirements of the MySQL account used by a client, the client may be required to specify certain
# options to connect using encryption to a MYSQL server that supports encrypted connections.
#
# Suppose that you weant to connect using an account that has no special encryption requirements or was created using a CREATE_USER
# statement that includes the REQUIRE SSL option.
#
# Assuming that the server supports encrypted connections, a client can connect using encryption with no --ssl-mode option or
# with an explicit --ssl-mode=PREFFERED option:
#
# 		mysql
#
# OR
#
# 		mysql --ssl-mode=PREFERRED
#
# For an account with REQUIRE SSL, the connection attempt fails if an encrypted connection cannot be established.
#
# FOr an account with no special encryption requirements, the attempt falls back to an unencrypted connection if an 
# encrypted connection cannot be established.
#
# To prevent fallback and fail if an encrypted connection cannot be obtained, connect like this:
#
# 		mysql --ssl-mode=REQUIRED
#
# If the account has no more stringent security requirements, other options must be specified to establish an encrypted connection:
#
# 		) For accounts with REQUIRE X509, clients must specify at least --ssl-cert and --ssl-key. In addition, --ssl-ca (or --ssl-capath)
# 			is recommended so that hte public certificate provided by the server can be verified.
#
# 			For example:
#
# 			mysql --ssl-ca=ca.pem \
# 					--ssl-cert=client-cert.pem \
# 					--ssl-key=client-key.pem 
#
# 		) For accounts that have REQUIRE ISSUER or REQUIRE SUBJECT, the option requirements are the same as for REQUIRE X509, but the certificate
# 			must match the issue or subject, respectively, specified in the account definition.
#
# FOr additional informaton about the REQUIRE clause, more later.
#
# To prevent use of encryption and override other -ssl-xxx options, invoke the client  program with --ssl-mode=DISABLED
#
# 		mysql --ssl-mode=DISABLED
#
# To specify 	permitted encryption protocls explicitly, use the --tls-version option, more later.
#
# To determine whether the current connection with the server user encryption, check the vlaue of the Ssl_cipher status variable.
# If the value is empty, the connection is not encrypted.
#
# Otherwise, the connection is encrypted and the value indicates the encryption ciher. For example:
#
# 	SHOW SESSION STATUS LIKE 'Ssl_cipher';
# +---------------------------------------------+
# | Variable_name  | Value 							|
# +----------------+----------------------------+
# | Ssl_cipher 	 | DHE-RSA-AES128-GCM-SHA256  |
# +----------------+----------------------------+
#
# For the mysql client, an alternative is to use the STATUS or \s command and check the SSL line:
#
# 		\s
# 		... 
# 		SSL: Not in use
# 		... 
#
# OR
#
# \s
# ...
# SSL: Cipher in use is DHE-RSA-AES128-GCM-SHA256
# ...
# 
# COMMAND OPTIONS FOR ENCRYPTED CONNECTIONS
#
# This section describes options that specify whether to use encrypted connections, the names of certificate and key files,
# and other params related to encrypted-connection support.
#
# These options can be given on the command line or in an option file.
#
# For examples of suggested use and how to check whether a connection is encrypted, more later.
#
# For info about using encrypted connections from the MySQL C API, more later.
#
# ENCRYPTED-CONNECTION OPTION SUMMARY
#
# 		FORMAT 					DESCRIPTION 												INTRODUCED
#
# --skip-ssl 		Do not use encrypted connection
#
# --ssl 				Enable encrypted connection
#
# --ssl-ca 			File that contains list of trusted SSL Certificate Authorities
#
# --ssl-capath 	Directory that contains trusted SSL Certificate Authority certificate files
#
# --ssl-crl 		File that contains certificate revocation lists
#
# --ssl-crlpath 	Directory that contains certificate revocation list files
#
# --ssl-fips-mode Whether to enable FIPS mode on the client side 				8.0.11
#
# --ssl-key 		File that contains X.509 key
#
# --ssl-mode 		Security state of connection to server
#
# --tls-version 	Protocols permitted for encrypted connections
#
# 	) --ssl
#
# 			NOTE: The client side --ssl option is removed in MySQL 8.0. For Cient programs, use --ssl-mode instead.
#
# 		On the server side, the --ssl option specifies that hte server permits but does not require encrypted connections.
#
# 		The option is enabled on the server side by default. --ssl is implied by other --ssl-xxx options, as indicated in the desc for those options.
#
# 		The --ssl option in negated form indicates that encryption should not be used and overrides other --ssl-xxx options.
# 		SPecify the options as --ssl=0 or a synonym (--skip-ssl, --disable-ssl)
#
# 		TO specify additional parameters for encrypted connections, use at least --ssl-cert and --ssl-key on the server side and
# 		--ssl-ca on the client side.
#
# 		Read earlier sections for that. That section also describes server capabilities for certificate and key file autogeneration and autodiscovery.
#
# ) --ssl-ca=<file_name>
#
# 		The path name of the Certificate Authority (CA) certificate file in PEM format. On the server side, this option implies --ssl.
#
# 		To tell the client not to authenticate the server certificate when establishing an encrypted connection to the server,
# 		specify neither --ssl-ca nor --ssl-capath.
#
# 		THe server still verifies the client according to any applicable requirements established for the client account, and sitll
# 		uses any --ssl-ca or --ssl-capath option values specified on the server side.
#
# ) --ssl-capath=dir_name
#
 #		THe path name of hte directory that contains trusted SSL ceritifcate authority (CA) certificate files in PEM format: On the server side,
 # 		this option implies --ssl.
 #
 # 	To tell the client not to authenticate the server certificate when establishing an encrypted connection to the server,
 # 	specify neither --ssl-ca nor --ssl-capath.
 #
 # 	The server sitll verifies the client according to any applicable requirements established for the client account,
 # 	and it sitll uses any --ssl-ca or --ssl-capath option values specified on the server side.
 #
 # 	MySQL distribs compiled using OpenSSL support the --ssl-capath option (see later).
 #
 # 	Distribs compiled using wolfSSL do not because wolfSSL does not look in any directory and do not followed chained certificate trees.
 # 	wolfSSL requries that all components of the CA certificate tree be contained within a single CA certificate tree and that each
 # 	certificate in the file has a unique SubjectName vlaue.
 #
 # 	To work around this wolfSSL limitation, concatenate the individual certificate files comprising the certificate tree into
 # 	a new file and specify that file as the  value of the --ssl-ca option.
 #
 # ) --ssl-cert=file_name
 #
 # 	The path name of the SSL public key certificate file in PEM format. 
 #
# 		ON the client side, this is the client public key. On teh server side, this is the server pubic key certificate.
#
# 		On the server side, this option implies --ssl.
#
# 	--ssl-cipher=cipher_list
#
# 		The list of permitted ciphers for connection encryption. If no cipher in the list is supported, encrypted connections will not work.
#
# 		ON the server side, this option implies --ssl.
#
# 		For greatest portability, cipher_list should be a list of one or more cipher names, separated by colons.
# 		Example:
#
# 			--ssl-cipher=AES128-SHA
# 			--ssl-cipher=DHE-RSA-AES128-GCM-SHA256:AES128-SHA
#
# 		OpenSSL supports a more flexible syntax for specifying ciphers, as described in the OpenSSL documentation.
#
# 		wolfSSL does not, so attempts to use that extended syntax fail for a MySQL distrib compiled using wolfSSL.
#
# 		For info about which encryption ciphers MySQL supports, more on that later.
#
# ) --ssl-crl=file_name
#
# 		The path name of the file certificate revocation lists in PEM format.
#
# 		On the server side, this option implies --ssl.
#
# 		If neither --ssl-crl nor --ssl-crlpath  is given, no CRL checks are performed, even if the CA path contains certificate revocation lists.
#
# 		MySQL distribs compiled using OpenSSL support the --ssl-crl option.
# 		Distribs compiled using wolfSSL do not because revocation lists do not work with wolfSSL.
#
# )--ssl-crlpath=dir_name
#
# 		The path name of the directory that contains certificate revocation list files in PEM format.
#
# 		On the server side, this option implies --ssl.
#
# 		If neither --ssl-crl nor --ssl-crlpath is given, no CRL checks are performed, even if the CA path contains certificate revocation lists.
#
# 		MySQL distribs compiled using OpenSSL suport the --ssl-crlpath.
# 		distribs compiled using wolfSSL do not because revocation lists do not work with wolfSSL.
#
# ) --ssl-fips-mode={OFF|ON|STRICT}
#
# 		Controls whether to enable FIPS mode on the client side. 
#
# 		The --ssl-fips-mode option differs from other --ssl-xxx options in that it is not used
# 		to establish encrypted connections, but rahter to affect which cryptographic operations are permitted.
#
# 		These --ssl-fips-mode vlaues are permitted:
##
# 			) OFF -> disalbes FIPS mode.
#
# 			) ON -> Enable FIPS mode.
#
# 			) STRICT -> Enable "strict" FIPS mode.
#
# 				NOTE:
#
# 					If the OpenSSL FIPS Object Module is not available, the only permitted value for --ssl-fips-mode is OFF.
# 					In this case, setting --ssl-fips-mode to ON or STRICT causes the client to produce a warning at startup and to operate in non-FIPS mode.
#
# )  --ssl-key=file_name
#
# 		The path name of hte SSL private key in PEM format. On the client side, this is the client private key.
# 		ON the server side, this is the server private key.
#
# 		On the server side, this option implies --ssl.
#
# 		If the key file is protected by a passphrase, the program prompts the user for the passphrase.
# 		The password must be given interactively; it cannot be stored in a file.
#
# 		If hte passphrase is incorrect, the program continues as if it could not read the key.
#
# 		For better security - use a certificate with an RSA key size of at least 2048 bits.
#
# ) --ssl-mode=mode
#
# 		This option is available only for client programs, not hte server.
#
# 		It specifies the security state of the connection to the server.
# 		These option values are permitted:
#
# 			) PREFERRED - Establishes an encrypted connection if the server supports encrypted connections, falling back to an unencrypted connection
# 								if an encrypted connection cannot be established.
#
# 								This is the default if --ssl-mode is not specified.#
# 
# 								Encrypted connections over Unix sockets are disabled by default, so PREFERRED does not establish an encrypted connection.
# 								To enforce encryption on Unix socket connections, use REQUIRED or above.
#
# 			) REQUIRED - Establish an encrypted connection if the server supports encrypted connections. The connection attempts fail if an encrypted
# 								connection cannot be established.
#
# 			) VERIFY_CA: Like REQUIRED, but additionally verify the server Certificate Authority (CA) certificate againstr the configured CA certificates.
# 							The connection attempt fails if no valid matching CA certificates are found.
#
# 			) VERIFY_IDENTITY: Like VERIFY_CA, but additionally perform host name identity verification by checking the host name the client uses
# 										for connecting to the server against the identity in the certificate that hte server sends to the client:
#
# 										) As of MySQL 8.0.12, if the client uses OpenSSL 1.0.2 or higher, the client checks whether the host name that it uses
# 											for connecting matches either the Subject Alternative Name value or the Common Name value in the server certificate.
#
# 										) Otherwise, the client checks whether the host name that it uses for connecting matches the Common Name value in the server certificate.
#
# 									The connection fails if there is a mismatch. For encrypted connections, this option helps prevent man-in-the-middle attacks.
#
# 										NOTE:
#
# 											Host name identity verification does not work with self-signed certificates created automatically by the server,
#												or manually using mysql_ssl_rsa_setup.
#
# 											Such self-signed certificates do not contain the server name as the Common Name Value.
#
# 			) DISABLED: Establish an unencrypted connection.
#
# 			The --ssl-mode option interacts with CA certificate options as follows:
#
# 				) If --ssl-mode is not explicitly set otherwise, use of --ssl-ca or --ssl-capath implies --ssl-mode=VERIFY_CA
#
# 				) For --ssl-mode values of VERIFY_CA or VERIFY_IDENTITY, --ssl-ca or --ssl-capath is also required, to supply a CA certificate
#					that matches the one used by the server.
#
# 				) An explicit --ssl-mode option with a value other than VERIFY_CA or VERIFY_IDENTITY, together with an explicit --ssl-ca or --ssl-capath option,
# 					produces a warning that no verification of the server certificate will be done, despite a CA certificate option being specified.
#
# To require use of encrypted connections by a MySQL account, use CREATE_USER to create the account with a REQUIRE SSL clause, or use ALTER_USER
# for an existing account to add a REQUIRE SSL clause.
#
# Connection attempts by a client that uses the account will be rejected unless MySQL supports encrypted connections and an encrypted connection
# can be established.
#
# The REQUIRE clause permits other encryption-related options, which can be used to enforce security requirements stricter than REQUIRE SSL.
#
# For additional details about which command options may or must be specified by clients that connect using accounts configured using the various
# REQUIRE options, see more later on CREATE USER syntax.
#
# ) --tls-version=protocol_list
#
# 	For client programs, the protocols permitted by the client for encrypted connections.
#
# 	The value is a comma-separated list containing one or more protocol names.
#
#  For example:
#
# 		mysql --tls-version="TLSv1.1,TLSv1.2"
#
# For protocols that can be named for this option depend on the SSL library used to compile MySQL.
#
# On the server side, use the tls_version system variable instead.
#
# CREATING SSL AND RSA CERTIFICATES AND KEYS
#
# The following discussion describes how ot create the files required for SSL and RSA support in MysQL.
# File creation can be performed using facilities provided by MySQL itself, or by invoking the openssl command directly.
#
# SSL certificate and key files enable MySQL to support sencrypted connections using SSL.
#
# RSA key files enable MySQL to support secure password exchange over unencrypted connections for accounts authenticated 
# by the sha256_password or caching_sha2_password plugin.
#
# CREATING SSL AND RSA CERTIFICATES AND KEYS USING MYSQL
#
# MySQL provides these ways to create the SSL certificate and key files and RSA key-pair files required to support
# encrypted connections using SSL and secure password exchange over RSA over unenecrypted connections,, if those files are missing:
#
# 		) The server can autogenerate these files at startup, for MySQL distribs compiled using OpenSSL
#
# 		) Users can invoke the mysql_ssl_rsa_setup utility manually.
#
# 		) For some distribution types, such as RPM packages, mysql_ssl_rsa_setup, invocation occurs during data directory initialization.
# 			In this case, the MySQL distrib need not have been compiled using OpenSSL as long as the openssl command is available.
#
# 			IMPORTANT:
#
# 				Server autogeneration and mysql_ssl_rsa_setup help lower the barrier to using SSL by making it easier to generate
# 				the required files.
#
# 				However, certificates generated by these methods are self-signed, which may not be very secure.
#
# 				After you gain experience using such files, consider obtaining certificate/key material from a registered
# 				certificate authority.
#
# AUTOMATIC SSL AND RSA FILE GENERATION
#
# For MySQL distributions compiled using OpenSSL, the MySQL server has the capability of automatically generating missing SSL
# and RSA files at startup.
#
# The auto_generate_certs, sha256_password_auto_generate_rsa_keys, and caching_sha2_password_auto_generate_rsa_keys System Variable
# contain automatic generation of these files.
#
# Both variables are enabled by default.
#
# They can be enabled at startup and inspected but not set at runtime.
#
# At startup, the server automatically generates server-side and client-side SSL certificate and key files in the data direcotry if the
# auto_generate_certs System Variable is enabled, no SSL options other than --ssl are specified, and the server-side SSL files
# are missing from the data directory.
#
# These files enable encrypted client connections using SSL.
#
# 	1. The server checks the data directory for SSL files with hte following names:
#
# 			ca.pem
# 			server-cert.pem
# 			server-key.pem
#
# 	2. If any of those files are present, the server creates no SSL files.
# 		Otherwise, it creates them, plus some additional files:
#
# 			ca.pem 				Self-signed CA certificate
# 			ca-key.pem 			CA private key
#
# 			server-cert.pem 	Server certificate
# 			server-key.pem 	Server private key
#
# 			client-cert.pem 	Client certificate
# 			client-key.pem 	Client private key	
#
# 	3. If the server autogenerates SSL files, it uses the names of the ca.pem, server-cert.pem and server-key.pem files to set
# 		the corresponding system variables (ssl_ca, ssl_cert, ssl_key)
#
# At startup, the server automatically generates RSA private/public key-pair files in the data directory if all of these conditions are true:
#
# The sha256_password_auto_generate_rsa_keys or caching_sha2_password_auto_generate_rsa_keys system variable is enabled;
#
# No RSA options are specified;
#
# The RSA files are missing from the data directory.
#
# These key-pair files enable secure password exchange using RSA over unencrypted connections for accounts authenticated
# by the sha256_password or caching_sha2_password plugin.
#
# 1. The server checks the data directory for RSA files with the following names:
#
# 			private_key.pem 		Private member of private/public key pair
# 			public_key.pem 		Public member of private/public key pair
#
# 2. If any of these files are present, the server creates no RSA files. Otherwise, it creates them.
#
# 3. If the server autogenerates the RSA files, it uses their names to set the corresponding system variables
# 		(sha256_password_private_key_path and sha256_password_public_key_path, caching_sha2_password_private_key_path and
# 		caching_sha2_password_public_key_path)
#
# MANUAL SSL AND RSA FILE GENERATION USING MYSQL_SSL_RSA_SETUP
#
# MySQL distribs include a mysql_ssl_rsa_setup utility that can be invoked manually to generate SSL and RSA files.
#
# This utility is included with all MySQL distributions (whether compiled using OpenSSL or wolfSSL), but it does reuqire
# that the openssl command be available.
#
# SSL AND RSA FILE CHARACHTERISTICS
#
# SSL and RSA files created automatically by the server or by invoking mysql_ssl_rsa_setup have these characteristics:
#
# 		) SSL and RSA keys have the size of 2048 bits.
#
# 		) The SSL CA certificate is self signed.
#
# 		) The SSL server and client certificates are signed with the CA certificate and key, using the sha256WithRSAEncryption signature algorithm.
#
# 		) SSL certs use these common names (CN) values, with the appropriate certificate type (CA, Server,Client):
#
# 			ca.pem: 				MySQL_Server_suffix_Auto_Generated_CA_Certificate
# 			server-cert.pm: 	MySQL_Server_suffix_Auto_Generated_Server_Certificate
# 			client-cert.pm: 	MySQL_Server_suffix_Auto_Generated_Client_Certificate
#
# 			The suffix value is based on the MySQL version number.
#
# 			For files generated by mysql_ssl_rsa_setup, the suffix can be specified explicitly using the --suffix option.
#
# 			For files generated by the server, if the resulting CN values exceed 64 characters, the _suffix portion of the name is omitted.
#
# 		) SSL files have blank values for Country (C), State of Province (ST), Organization (O), Organization Unit Name (OU) and email address.
#
# 		) SSL files created by the server or by mysql_ssl_rsa_setup are valid for ten years from the time of generation.
#
# 		) RSA files do not expire.
#
# 		) SSL files have different serial numbers for each certificate/key pair (1 for CA, 2 for Server, 3 for Client)
#
# 		) Files created automatically by the server are owned by the account that runs the server.
#
# 			Files created using mysql_ssl_rsa_setup are owned by the user who invoked that program.
#
# 			This can be changed on systems that support the chown() system call if the program is invoked by root and --uid option is given
# 			to specify the user who should own the files.
#
# 		) On Unix and Unix-like systems, the file access mode is 644 for certificate files (that is, world readable), and 600 for key files (only accessible by the acc that runs the server)
#
# To see the contents of an SSL certificate (for example, to check the range of dates over which it is valid), invoke openssl directly:
#
# 		openssl x509 -text -in ca.pem
# 		openssl x509 -text -in server-cert.pem
# 		openssl x509 -text -in client-cert.pem
#
# It is also possible to check SSL certificate expiration information using this SQL statement:
#
# 		SHOW STATUS LIKE 'Ssl_server_not%';
# 		+----------------------+-------------------------+
# 		| Variable_name 		  | Value   	 			    |
# 		+----------------------+-------------------------+
# 		| Ssl_server_not_after | Apr 28 14:16:39 2027 GMT|
# 		| Ssl_server_not_before| May 	1 14:16:39 2017 GMT|
# 		+----------------------+-------------------------+
# 
# CREATING SSL CERTIFICATES AND KEYS USING OPENSSL
#
# This section describes how ot use openssl command to set up SSL certificate and key files for use by MySQL servers and clients.
# The first example shows a simplified procedure such as you might use from the command line.
#
# The second shows a script that contains more detail.
#
# The first two examples are intended for use on Unix and both use the openssl command that is part of OpenSSL.
# The third example describes how to set up SSL files on Windows.
#
# NOTE:
# 		There are easier alternatives to generating the files required for SSL than the procedure described here: Let the server autogenerate them or
# 		use the mysql_ssl_rsa_setup program.
#
# IMPORTANT:
#
# 		Whatever method you use to generate the certificate and key files, the Common Name value used for the server and client certificates/keys must each
# 		differ from the Common Name value used for the CA certificate.
#
# 		Otherwise, the certificate and key files will not work for servers compiled using OpenSSL.
# 		A typical error in this case is:
#
# 			ERROR 2026 (HY000): SSL connection error:
# 			error: 00000000001:lib(0):func(0):reason(1)
#
# EXAMPLE 1: CREATING SSL FILES FROM THE COMMAND LINE ON UNIX
#
# 	The following examples show a set of commands to create MySQL and client certificates and key files.
# 	You will need to respond to several prompts by the openssl commands.
#
# 	To generate test files, you can press Enter to all prompts.
# 	To generate files for production use, you should provide nonempty responses.
#
# 	# Create clean environment
# 	rm -rf newcerts
# 	mkdir newcerts && cd newcerts
#
# 	# Create CA certificate
# 	openssl genrsa 2048 > ca-key.pem
#	openssl req -new -x509 -nodes -days 3600 \
# 				-key ca-key.pem -out ca.pem
#
# 	# Create server certificate, remove passphrase, and sign it
# 	# server-cert.pem = public key, server-key.pem = private key
# 	openssl req -newkey rsa:2048 -days 3600 \
# 				-nodes -keyout server-key.pem -out server-req.pem
# 	openssl rsa -in server-key.pem -out server-key.pem
# 	openssl x509 -req -in server-req.pem -days 3600 \
# 				-CA ca.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem
#
# # Create client certificate, remove passphrase, and sign it
# # client-cert.pem = public key, client-key.pem = private key
# openssl req -newkey rsa:2048 -days 3600 \
# 			-nodes -keyout client-key.pem -out client-req.pem
#
# openssl rsa -in client-key.pem -out client-req.pem
# openssl x509 -req -in client-req.pem -days 3600 \
# 			 -CA ca.pem -CAkey ca-key.pem -set_serial 01 -out client-cert.pem
#
# After generating the certificates, verify them:
#
# 		openssl verify -CAfile ca.pem server-cert.pem client-cert.pem
#
# You should see a response like this:
#
# 	server-cert.pem: OK
# 	client-cert.pem: OK
#
# To see the contents of a certificate (for example, ,to check the range of dates over which a certificate is valid), invoke openssl like this:
# 	
# 	openssl x509 -text -in ca.pem
# 	openssl x509 -text -in server-cert.pem
# 	openssl x509 -text -in client-cert.pem
#
# Now you have a set of files that can be used as follows:
#
# 	) ca.pem: Use this as the argument to --ssl-ca on the server and client sides. (The CA certificate, if used, must be the same on both sides.)
#
# 	) server-cert.pem, server-key.pem: Use these as the arguments to --ssl-cert and --ssl-key on the server side.
#
# 	) client-cert.pem, client-key.pem: Use these as the arguments to --ssl-cert and --ssl-key on the client side.
#
#
# EXAMPLE 2: CREATING SSL FILES USING A SCRIPT ON UNIX
#
#
# Here is an example script that shows how to set up SSL certificate and key files for MySQL.
# After executing the script, use the files for SSL connections as described earlier.
#
# DIR=`pwd`/openssl
# PRIV=$DIR/private
#
# mkdir $DIR $PRIV $DIR/newcerts
# cp /usr/share/ssl/openssl.cnf $DIR
# replace ./demoCA $dir -- $DIR/openssl.cnf
#
# # Create necessary files: $database, $serial and $new_certs_dir
# # directory (optional)
#
# touch $DIR/index.txt
# echo "01" > $DIR/serial
#
# #
# # Generation of Certificate Authority (CA)
# #
# 
# openssl req -new -x509 -keyout $PRIV/cakey.pem -out $DIR/ca.pem \
# 		-days 3600 -config $DIR/openssl.cnf
#
# Sample out:
# Using configuration from /home/mont/openssl/openssl.cnf
# Generating a 1024 bit RSA private key
# .....................+++++++++
# ...............+++++++++++
# writing new private key to '/home/monty/openssl/private/cakey.pem'
# Enter PEM pass phrase:
# Verifying password - Enter PEM pass phrase:
# --------
# You are about to be asked to enter information that will be incorporate into your certificate request.
# What you are about to enter is what is called a Distinguished Name or a DN.
#
# There are quite a few fields but you can leave some blank.
# For some fields there will be a default value.
# If you enter '.'; the field will be left blank.
# ---------
#
# Country Name (2 letter code) [AU]:FI
# State or Province Name (full name) [Some-State]:.
# Locality Name (eg, city) []:
# Organization Name (eg, company) [Internet Widgits Pty Ltd]:MySQL AB
# Organizational Unit Name (eg, section) []:
# Common Name (eg, YOUR name) []:MySQL admin
# Email Address []:
#
# Create server request and key
#
# openssl req -new -keyout $DIR/server-key.pem -out \
# 		$DIR/server-req.pem -days 3600 -config $DIR/openssl.cnf
#
# Sample output:
# REPEAT OF LAST CHUNK
#
# Remove the passphrase from the key
#
# openssl rsa -in $DIR/server-key.pem -out $DIR/server-key.pem
#
# Sign server cert
#
# openssl ca -cert $DIR/ca.pem -policy policy_anything \
# 		-out $DIR/server-cert.pem -config $DIR/openssl.cnf \
# 		-infiles $DIR/server-req.pem
#
# Sample output:
# Using configuration from /home/monty/openssl/openssl.cnf
# Enter PEM pass phrase:
# Check that the request matches the signature
# Signature ok
# The Subjects Distinguished Name is as follows
# countryName 							:PRINTABLE:'FI'
# organizationName 	 				:PRINTABLE:'MySQL AB'
# commonName 							:PRINTABLE:'MySQL admin'
# Certificate is to be certified until Sep 13 14:22:46 2003 GMT
# (365 days)
#  Sign the certificate? [y/n]:y
#
# 1 out of 1 certificate requests certified, commit? [y/n]y
# Write out database with 1 new entries
# Data Base Updated
#
# Create client request and key
#
# openssl req -new -keyout $DIR/client-key.pem -out \
# 		$DIR/client-req.pem -days 3600 -config $DIR/openssl.cnf
#
# Repeat chunk
#
# Remove the passphrase from the key
#
# openssl rsa -in $DIR/client-key.pem -out $DIR/client-key.pem
#
# Sign client cert
#
# openssl ca -cert $DIR/ca.pem -policy policy_anything \
# 		-out $DIR/client-cert.pem -config $DIR/openssl.cnf \
# 		-infiles $DIR/client-req.pem
#
# Repeat
#
# Create a my.cnf file that you can use to testr the certificates
#
# cat <<EOF > $DIR/my.cnf
# [client]
# ssl-ca=$DIR/ca.pem
# ssl-cert=$DIR/client-cert.pem
# ssl-key=$DIR/client-key.pem
# [mysqld]
# ssl-ca=$DIR/ca.pem
# ssl-cert=$DIR/server-cert.pem
# ssl-key=$DIR/server-key.pem
# EOF
#
#
# CREATING RSA KEYS USING OPENSSL
#
# This section describes how to use the openssl command to set up the RSA key files that enable MySQL to support secure
# PW exchange over unenecrypted connectiosn for accounts authenticated by the sha256_password and caching_sha2_password plugins.
#
# NOTE:
#
# 		There are easier alternatives to generating the files required for RSA than the procedure described here:
# 		Let the server autogenerate them or use the mysql_ssl_rsa_setup.
#
# To create hte RSA private and public key-pair files, run these commands while logged into the system account used to run the MySQL
# server so the files will be owned by that account:
#
# 		openssl genrsa -out private_key.pem 2048
# 		openssl rsa -in private_key.pem -pubout -out public_key.pem
#
# Those commands create 2,048 bit-keys. To create stronger keys, use a larger value.
#
# Then set the access modifiers for the key files.
# THe private key should be readable only by the server, whereas the public key can be freely distributed
# to client users:
#
# chmod 400 privte_key.pem
# chmod 444 public_key.pem
#
# OPENSSL VERSUS WOLFSSL
#
# MySQL can be compiled using OpenSSL or wolfSSL, both of which enable encrypted connections based on the openSSL API:
#
# 		) MysQL enterprise edition binary distribs are compiled using OpenSSL. It is not possible to use wolfSSL with MYSQL enterprise edition
#
# 		) mySQL community edition binary distribs are ocmpiled using openSSL
#
# 		) MySQL community edition source distribs can be compiled using either OpenSSL or wolfSSL.
#
# OpenSSL and wolfSSL offer the same basic functionality, but MySQL distribs compiled using OpenSSL have additional features.
#
# 		) OpenSSL supports a wider range of encryption ciphers from which to choose for the --ssl-cipher option.
# 			OpenSSL supports the --ssl-capath, --ssl-crl and --ssl-crlpath options.
#
# 		) Accounts that authenticate using the sha256_password plugin can use RSA key files for secure PW exchanges over unencrypted connections.
#
# 			Accounts that authenticate using caching_sha2_password plugin can use RSA key pair-based PW exchange regardless
# 			of whether MysQL was compiled using OpenSSL or wolfSSL.
#
# 		) The server can automatically generate missing SSL and RSA certificate and key files at startup.
#
# 		) OpenSSL supports more encryption modes for the AES_ENCRYPT() and AES_DECRYPT() functions. MOre later on that.
##
# Certain OpenSSL-related System and Status variables are present only if MysQL was compiled using OpenSSL.
#
# These are:
#
# ) auto_generate_certs
#
# ) caching_sha2_password_auto_generate_rsa_keys
#
# ) sha256_password_auto_generate_rsa_keys
#
# ) sha256_password_private_key_path
#
# ) sha256_password_public_key_path
#
# ) Rsa_public_key
#
# To determine whether a server was compiled using openSSL, test the existence of any of those variables.
#
# For example, this statement returns a row if OpenSSL was used and an empty result if wolfSSL was used:
#
# SHOW STATUS LIKE 'Rsa_public_key';
#
# Building MySQL with Support for Encrypted Connections
#
# To use encrypted connections between the MySQL server and client programs, your system must support either OpenSSL or wolfSSL:
#
# 		) MySQL enterprise edition binary distribs are compiled using OPenSSL. It is not possible to use wolfSSL with MysQL enterprise edition.
#
# 		) MySQL community edition binary distribs are compiled using OpenSSL.
#
# 		) mySQL community edition source distrib can be compiled using either OpenSSL or wolfSSL.
#
# IF you compile MySQL from a source distrib, CMake configures the distribs to use OpenSSL by default.
#
# To compile using OpenSSL, use this procedure:
#
# 	1. Ensure that OPenSSL 1.0.1 or higher is installed. IF the installed OPenSSL is lower than 1.0.1, CMake produces an error
# 		at MySQL config time.
#
# 	2. The WITH_SSL CMake option determines which SSL library to use for compiling MySQL.
#
# 		The default is -DWITH_SSL=system which uses OpenSSL.
#
# 		To make this explicit, specify that option on the CMake cmd line.
# 		For example:
#
# 		cmake . -DWITH_SSL=system
#
# 		That command configures the distrib to use the installed OpenSSL lib.
#
# 		Alternatively, to explicitly specify the path name to the OpenSSL installation, use the 
#  	following syntax:
#
# 		This can be useful if you have multiple versions of OpenSSL installed, ot prevent CMake from choosing the wrong one:
#
# 			cmake . -DWITH_SSL=path_name
#
# 	3. Compile and install the dstrib
#
# To compile using wolfSSL, download the wolfSSL distrib and apply a small patch.
# For instructions, see the extra/README_wolfssl.txt file.
#
# To check whether a mysqld server supports encrypted connections, examine the value of the have_ssl SYS_VAR:
#
# 	SHOW VARIABLES LIKE 'have_ssl';
# 	+---------------------------------+
# 	| Variable_name 		| 	Value 	 |
# 	+--------------------+------------+
# 	| have_ssl 				| YES 		 |
# 	+--------------------+------------+
#
# If the value is YES, the server supports encrypted connections. If the value is DISABLED, the server is capable of supporting
# encrypted connections - but was not started with the appropriate --ssl-xxx options to eanble encrypted connections to be used.
#
# ENCRYPTED CONNECTION PROTOCOLS AND CIPHERS
#
# To determine which encryption protocol and cipher are in use for an encrypted connection, use the following statemnts to check
# the vlaues of the Ssl_version and Ssl_cipher status variables:
#
# 	SHOW SESSION STATUS LIKE 'Ssl_version';
# 	+------------------------------------+
# 	| Variable_name 		| Value 			 |
# 	+--------------------+---------------+
# 	| Ssl_version 			| TLSv1 			 |
# 	+--------------------+---------------+
#
# SHOW SESSION STATUS LIKE 'Ssl_cipher';
# +---------------------------------------+
# | Variable_name 		| Value 				|
# +---------------------+-----------------+
# | Ssl_cipher | DHE-RSA-AES128-GCM-SHA256|
# +------------+--------------------------+
#
# If the connection is not encrypted, both variables have an empty value.
#
# MySQL supports encrypted connections using the TLSv1, TLSv1.1 and TLSv1.2 protocols.
#
# The value of the tls_version system variable determines which protocols the server is permitted to use from those that are available.
# The tls_version value is a comma-separated list containing one or more of these protocols (not case-sensetive):
#
# TLSv1, TlSv1.1, TLSv1.2
#
# By default, this variable lists all protocols supported by the SSL library used to compile MySQL.
# To determine the value of tls_version at runtime, use this statement:
#
# SHOW GLOBAL VARIABLES LIKE 'tls_version';
# +------------------------------------------+
# | Variable_name 		| 	Value 				|
# +---------------------+--------------------+
# | tls_version 	| TLSv1, TLSv1.1, TLSv1.2  |
# +---------------------+--------------------+
#
# To change the value of tls_version, set it at server startup.
#
# For example, to prohibit connections that use the less secure TLSv1 protocol use these lines at the server
# my.cnf file:
#
# 	[mysqld]
# 	tls_version=TLSv1.1,TLSv1.2
#
# To be even more restrictive and only permit TLSv1.2 connections, use tls_version like this:
#
# 	[mysqld]
# 	tls_version=TLSv1.2
#
# For client programs, the --tls-version option enables specifying the TLS protocols permitted per client invocation.
#
# The value format is the same as for tls_version.
#
# by default, MySQL attempts to use the highest TLS protocol verison avaialable, depending on which SSL library was used
# to compile the server and client, which key size is used and whether the server or client are restricted from using
# some protocols; for example, by means of tls_version/--tls-version
#
# ) TLSv1.2 is used if possible
#
# ) TLSv1.2 does not work with all ciphers that have a key size of 512 bits or less. To use this protocol with such a key, use --ssl-cipher to 
# 		specify the cipher name explicit:
#
# 			AES128-SHA
# 			AES128-SHA256
# 			AES256-SHA
# 			AES256-SHA256
# 			CAMELLIA128-SHA
# 			CAMELLIA256-SHA
# 			DES-CBC3-SHA
# 			DHE-RSA-AES256-SHA
# 			RC4-MD5
# 			RC4-SHA
# 			SEED-SHA
#
# ) For better security, use a certificate with an RSA key size of at least 2048 bits.
#
# If the server and client protocol capabilities have no protocol in common, the server terminates the connection request.
#
# FOr example, if the server is configured with tls_version=TLSv1.1, TLSv1.2 - connection attempts will fail for clients invoked
# with --tls-version=TLSv1, and for older clients that do not support the --tls-version option and implicitly support only TLSv1.
#
# MySQL permits specifying a list of protocols to support.
#
# This list is passed directly down to the underlying SSL library and is ultimately up to that library what protocols it
# actually enables from the supplied list.
#
# Please refer to the MySQL source code and SSL_CTX_new documentation for information about how the SSL library handles this.
#
# For openSSL, see the SSL_CTX_new documentation.
#
# To determine which ciphers a given server supports, use the following statements to check the value of the Ssl_cipher_list status variable:
#
# 		SHOW SESSION STATUS LIKE 'Ssl_cipher_list';
#
# Order of ciphers passed by MySQL to the SSL library is significant.
# More secure ciphers are mentioned first in the list, and the first cipher supported by the provided certificate is selected.
#
# MySQL passes this cipher list to the SSL library:
#
# ECDHE-ECDSA-AES128-GCM-SHA256
# ECDHE-ECDSA-AES256-GCM-SHA384
# ECDHE-RSA-AES128-GCM-SHA256
# etc.
#
# //This list is long and largely uninteresting.
#
# These cipher restrictions are in place:
#
# 		) The following ciphers are permanently restricted:
#
# 			!DHE-DSS-DES-CBC3-SHA
# 			!DHE-RSA-DES-CBC3-SHA
# 			!ECDH-RSA-DES-CBC3-SHA
# 			!ECDH-ECDSA-DES-CBC3-SHA
# 			!ECDHE-RSA-DES-CBC3-SHA
# 			!ECDHE-ECDSA-DES-CBC3-SHA
#
# 		) The following categories of ciphers are permanently restricted:
#
# 			!aNULL
# 			!eNULL
# 			!EXPORT
# 			!LOW
# 			!MD5
# 			!DES
# 			!RC2
# 			!RC4
# 			!PSK
# 			!SSLv3
#
# IF the server is started using a compatible certificate that uses any of the preceding restricted ciphers or cipher categories,
# the server starts with support for encrypted connections disabled.
#
# CONNECTING TO MYSQL REMOTELY FROM WINDOWS WITH SSH
#
# This section describes how to get an encrypted connection to a remote MySQL server with SSH.
# 
# 1. Install an SSH client on your Windows machine. For a comparison of SSH clients, see places.
#
# 2. Start your Windows SSH client. Set Host_name = yourmysqlserver_URL_OR_IP.
# 	
# 		Set userid=your_userid to log in to your server.
#
# 		This userid value might not be the same as the user name of your MySQL account.
#
# 3. Set up port forwarding. Either do a remote forward (set Local_port: 3306, remote_host: yourmysqlservername_or_ip, remote_port: 3306) or a local
# 		forward (Set port: 3306,host: localhost, remote port: 3306)
#
# 4. save
#
# 5. Log in with the SSH
#
# 6. Start some ODBC app.
#
# 7. Create a new file in Windows and link to MySQL using the ODBC driver the same way you normally do.
# Except type in localhost for the MySQL host server, not yourmysqlservername
#
# At this point, you should have an ODBC connection to MySQL, encrypted using SSH.
#
#
# SECURITY COMPONENTS AND PLUGINS
#
# MySQL includes several components and plugins that implement security features:
#
# 		) Plugins for authenticating attempts by clients to connect to MySQL server.
#
# 			Plugins are avialable for several authentication protocols.
#
# 		) A PW validation component for implementing PW strength policies and assessing their strength of potetional PWs.
#
# 		) Keyring plugins that provide secure storage for sensitive information.
#
# The following pertain to MysQL Enterprise only:
#
# 		) MySQL Enterprise also has MySQL Enterprise Audit, implemented using a server plugin - uses the open MySQL audit API
# 			to enable standard, policy-based monitoring and logging of connection and query activity executed on specific MySQL servers.
#
# 			Designed to meet the Oracle audit specification, MySQl Enterprise Audit provides an otu of teh box, easy to use Auditing and compliance
# 			solution for applications that are governed by both internal and external regulation guidelines.
#
# 		)  MysQL Enterprise firewall, an application-level firewall that enables DB admins to permit or deny SQL statements execution based
# 			on matching against whitelists of accepted statement patterns.
#
# 			This helps harden MySQL servers against attacks such as Injections or attempts to exploit applications by using them outside
# 			of their legitimate query workload characteristics.
#
# 		) MySQL Enterprise Data Masking and De-identification, imeplement as a plugin library containing a plugin and a set of user-defined
#			functions.
#
# 			Data masking hides senseitive information by replacing rela values with substitutes.
#
# 			Enables obfuscation, generation of formatted random data and data replacement or substitution.
#
# AUTHENTICATION PLUGINS
#
# The following seciton describes pluggable authentication methods available in MysQL and the plugins that implement these methods.
#
# The default plugin is indicated by the value of the default_authentication_plugin system variable.
#
# NATIVE PLUGGABLE AUTHENTICATION
#
# MySQL includes a mysql_native_password plugin that implements native authentication;
# That is, authentication based on the PW hashing method in use from before the introduction of pluggable authentication.
#
# The following table shows the plugin names on the server and client sides.
#
# PLUGIN AND LIBRARY NAMES OR NATIVE PW AUTHENTICATION
#
# plugin or file 			Name
#
# Server-side plugin 	mysql_native_password
#
# Client-side plugin 	mysql_native_password
#
# Library file 			None (plugins are built in)
#
# INSTALLING NATIVE PLUGGABLE AUTHENTICATION
#
# THe mysql_native_password plugin exists in server and client form:
#
# ) THe server-side plugin is built into the server, need not be loaded explicitly and cannot be disabled by unloading it.
#
# ) The client side plugin is built into the libmysqlclient client library and is available to any program linked against libmysqlclient.
#
# USING NATIVE PLUGGABLE AUTHENTICATION
#
# MySQL client programs use mysql_native_password by default.
#
# The --default-auth option can be used as a hint about which client-side plugin the program can expect
# to use:
#
# mysql --default-auth=mysql_native_password
#
# SHA-256 PLUGGABLE AUTHENTICATION
#
# MySQL provides two authentication plugins that implement SHA-256 hashing for user account PWs:
#
# 	) sha256_passwords: Implements basic SHA-256 authentication
#
# 	) caching_sha2_password: Implements SHA-256 authentication (like sha256_password), but uses caching on the server side for better performance 
# 		and has additional features for wider applicability.
#
# THis section is for the original noncaching SHA-2 authentication plugin.
#
# IMPORTANT:
#
# 		IN MySQL 8.0, caching_sha2_password is the default authentication plugin rather than mysql_native_password.
#
# 		For information about the implications of this change for server ops and compability of the server with clients 
# 		and connectors, see caching_sha2_password as the Preferred Authentication PLugin
#
# IMPORTANT:
#
# 		To connect to the server using a account that authenticates with the sha256_password plugin, you must use either a TLS connection
# 		or an unencrypted connection that supports PW exchange using an RSA key pair, as described later in this section.
#
# 		Either way, the sha256_password plugin uses MySQL's encryption capabilities.
#
# Note:
#
# 		In the name sha256_password, "sha256" refers to the 256-bit length the plugin uses for encryption.
# 		In the name caching_sha2_password "sha2" refers more generally to the SHA-2 class of encryption algorithms.
#
# 		Of which, 256-bit encryption is one instance.
#
# PLUGIN AND LIBRARY NAMES FOR SHA-256 AUTHENTICATION
#
# Plugin or File 			Plugin or File name
#
# server-side plugin 	sha256_password
#
# Client-side plugin 	sha256_password
#
# Library file 			None (built in)
#
# INSTALLING SHA-256 PLUGGABLE AUTHENTICATION
#
# The sha256_password plugin exists in server and client forms:
#
# 		) The server-side plugin is built into the server, need not be loaded explicitly, and cannot be disabled by unloading it.
#
# 		) The client-side plugin is built into the libmysqlclient library and is available to any program linked against libmysqlclient
#
# USING SHA-256 PLUGGABLE AUTHENTICATION
#
# To set up an account taht uses the sha256_password plugin for SHA-256 PW hashing, use the following statement, where PW is the desired acc pw:
#
# CREATE USER 'sha256user'@'localhost' IDENTIFIED WITH sha256_password BY 'password';
#
# The server assigns the sha256_password plugin to the account and uses it ot encrypt the PW using SHA-256, storing those values
# in the plugin and authentication_string columns of the mysql.user system table.
#
# The preceding instructions do not assume that sha256_password is teh default authentication plugin.
#
# If sha256_password is the default authentication plugin, a simpler CREATE_USER syntax can be used.
#
# To start the server with the default authentication plugin set to sha256_password, put these lines in the server option file:
#
# 		[mysqld]
# 		default_authentication_plugin=sha256_password
#
# That causes the sha256_password plugin to be used by default for new accounts.
#
# As a result, it is possible to create the account and set its Password without naming the plugin explicitly:
#
# 	CREATE USER 'sha256user'@'localhost' IDENTIFIED BY 'password';
#
# Anotehr consequence of setting default_authentication_plugin to sha256_password, is that - to use some other plugin for account creation,
# you must specify that plugin explicitly.
#
# For example - to use the mysql_native_password plugin - use this statement:
#
# 		CREATE USER 'nativeuser'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
#
# sha256_password supports connections over secure transport.
#
# Sha256_password also supports encrypted password exchange using RSA over unencrypted connections, if these conditions are satisfied:
#
# 		) MYSQL is compiled using OpenSSL.
#
# 			MySQL can be compiled using either OpenSSL or yaSSL, and sha256_password works with distribs compiled using
# 			either package, but RSA support requires OpenSSL.
#
# 		) The MYSQL server to which you wish to connect is configured to support RSA (using the RSA configuration procedure given later in this section)
#
#
# RSA support has these characeteristics:
#
# 		) On the server side, two system variables name the RSA private and public key-pair files:
#
# 				sha256_password_private_key_path 
#
# 				and
#
# 				sha256_password_public_key_path
#
# 			The Database admin must set these vars at server startup if the key files to use have names that differ
# 			from the SYS_VAR default values.
#
# 		) The server uses the sha256_password_auto_generate_rsa_keys SYS_VAR to determine whether to automatically
#			generate the RSA key-pair file.
#
# 		) The Rsa_public_key status variable displays the RSA public key used by the sha256_password authentication plugin.
#
# 		) Clients that are in possession of the RSA public key can perform RSA key pair-based password exchange with the server
# 			during the connection process, as described later.
#
# 		) For connections by accounts that authenticate with sha256_password and RSA public key pair-based PW exchange, the server
# 			sends the RSA public key to the client as needed.
#
# 			However, if a copy of the public key is available on the client host, the client can use it to save a round trip in the client
# 			/Server protocol:
#
# 				) For these command-line clients, use the --server-public-key-path option to specify the RSA public key file:
#
# 						mysql, mysqladmin, mysqlbinlog, mysqlcheck, mysqldump, mysqlimport, mysqlpump, mysqlshow, mysqlslap, mysqltest, mysql_upgrade
#
# 				) For programs that use the C API, call mysql_options() to specify the RSA public key file by passing the MYSQL_SERVER_PUBLIC_KEY
#					option and the name of the file.
#
# 	 			) For replication slaves, use the  CHANGE_MASTER_TO statement with the MASTER_PUBLIC_KEY_PATH option to specify the RSA public key file.
# 					For Group replication, the group_replication_recovery_get_public_key SYSTEM VARIABLE serves the same purpose.
#
# For clients that use the sha256_password plugin, passwords are never exposed as cleartext when connecting to the server.
# How password transmission occurs depends on whether a secure connection or RSA encryption is used:
#
# 		) If the connection is secure, an RSA key pair is unnecessary and is not used. This applies to encrypted connections that use TLS.
# 			The password is sent as cleartext but cannot be snooped because the connection is secure.
#
# 		) If the connection is not secure, and an RSA key pair is available, teh connection remains unencrypted.
#
# 			This applies to unencrypted connections without TLS. RSA is used only for password exchange between client and server,
# 			to prevent password snooping.
#
# 			When the server receives the encrypted password, it decrypts it. A scramble is used in the encryption to prevent repeat attacks.
#
# 		) If a secure connection is not used and RSA encryption is not available, the connection attempt fails because the PW cannot be sent without
# 			being exposed as cleartext.
#
# As mentioned previously, RSA password encryption is available only if MySQL was compiled using OpenSSL.
#
# The implication for MySQL distribs compiled using wolfSSL is that - to use SHA-256 PWs, clients MUST use an encrypted
# connection to access the server.
#
# NOTE:
#
# 		To use RSA pw encryption with sha256_password, the client and server both must be compiled using OpenSSL, not just one of them.
#
# Assuming that MySQL has been compiled using OpenSSL, use the following procedure to enable the use of an RSA key pair for PW exchange
# during the client connection process:
#
# 		1. Create the RSA private and public key-pair files using the previous instructions.
#
# 		2. If the private and public key files are located in the data directory and are named private_key.pem and public_key.pem
# 			(the default values of the sha256_password_private_key_path and sha256_password_public_key_path system variables), the server
# 			uses them automatically at startup.
#
# 			otherwise, to name the key files explicitly, set the system variables to the key file names in the server option file.
#
# 			If the files are located in the server data directory, you need not specify their full path names:
#
# 				[mysqld]
# 				sha256_password_private_key_path=myprivkey.pem
# 				sha256_password_public_key_path=mypubkey.pem
#
# 			If the key files are not located in the data directory, or to make their locations explicit in the system variable values,
# 			use full path names:
#
# 				[mysqld]
# 				sha256_password_private_key_path=/usr/local/mysql/myprivkey.pem
# 				sha256_password_public_key_path=/usr/local/mysql/mypubkey.pem
#
# 		3. Restart the server, then connect to it and check the Rsa_public_key status variable value.
#
# 			The value will differ from that shown here, but should be nonempty:
#
# 				SHOW STATUS LIKE 'Rsa_public_key'\G
# 				*********************** 1. row ****************************
# 				
# 				Variable name: Rsa_public_key
# 						Value: ---------- BEGIN PUBLIC KEY --------------
# 				<values>
# 				---------- END PUBLIC KEY -------------
#
# 			If the value is empty, the server found some problem with the key files.
# 			Check the error log for diagnostic information.
#
# After the server has been configured with the RSA key files, accounts that authenticate with the sha256_password plugin
# have the option of using those key files to connect to the server.
#
# As mentioned previously, such accounts can use either a secure connection (in which case RSA is not used) or an unencrypted
# connection that performs password exchange using RSA. Suppose that an unenecrypted connection is used.
#
# For example:
#
# 		mysql --ssl-mode=DISABLED -u sha256user -p
# 		Enter password: password
#
# For this connection attempt by sha256user, the server determines that sha256_password is the appropriate authentication plugin
# and invokes it (because that was the plugin specified at CREATE_USER point of time).
#
# The plugin finds that the connection is not encrypted and thus requires the password to be transmitted using RSA encryption.
# In this case, the plugin sends the RSA public key to the client, which uses it to encrypt the PW and returns the result to the sever.
#
# The plugin uses the RAS private key on the server side to decrypt the password and accepts or rejects the connection based
# on whether the password is correct.
#
# The server sends the RSA public key to the client as needed. However, if the client has a file containing a local coppy of the
# RSA public key required by the server, it can specify the file using the --server-public-key-path option:
#
# 		mysql --ssl-mode=DISABLED -u sha256user -p --server-public-key-path=file_name
# 		Enter password: password
# 
# The public key value in the file named by the --server-public-key-path option should be the same as the key value in the server-side
# file named by the sha256_password_public_key_path system variable.
#
# If the key file contains a valid public key value but the value is incorrect, an access-denied error occurs.
# If the key file does not contain a valid public key, the client program cannot use it.
#
# In this case, the sha256_password plugin sends the public key to the client as if no --server-public-key-path option had been specified.
#
# Client users can obtain the RSA public key two ways:
#
# 		) The database administrator can provide a copy of the public key file.
#
# 		) A client user who can connect to the server some other way can use a SHOW STATUS LIKE 'Rsa_public_key' statement
# 			and save the returned key value in a file.
#
# CACHING SHA-2 PLUGGABLE AUTHENTICATION
#
# MySQL provides two authentication plugins that implement SHA-256 hashing for user account passwords:
#
# 		) sha256_password: Implements basic SHA-256 authentication
#
# 		) caching_sha2_password: Implements SHA-256 authentication (like sha256_password), but uses caching on the server side
# 			for better performance and has additional features for wider applicability
#
# This section describes the caching SHA-2 authentication plugin.
#
# IMPORTANT:
#
# 		In MySQL 8.0, caching_sha2_password is the default authentication plugin rather than mysql_native_password.
#
# 		For more information about the implications of this change for server ops and compatibility of the server with
# 		clients and connectors, see later.
#
# IMPORTANT:
#
# 		To connect to the server using an account that authenticates with the caching_sha2_password plugin, you must
# 		use either a secure connection or an unencrypted connection that supports password exchange using an RSA key pair,
# 		as described later in this section.
#
# 		Either way, the caching_sha2_password plugin uses MySQL's encryption capabilities.
#
# NOTE:
#
# 		In the name sha256_password, "sha256" refers to the 256-bit digest length the plugin uses for encryption.
#
# 		In the name caching_sha2_password, "sha2" refers more generally to the SHA-2 class of encryption algorithms,
# 		of which 256-bit encryption is one instance
#
# 		The latter name choice leaves room for future expansion of possible digest lengths without changing the plugin name.
#
# The caching_sha2_password plugin has these advantages, compared to sha256_password:
#
# 		) On the server side, an in-memory cache enables faster reauthentication of users who have connected previously when they connect again.
#
# 		) RSA-based password exchange is available regardless of the SSL library against which MySQL is linked.
#
# 		) Support is provided for client connections that use the Unix socket-file and shared-memory protocols.
#
# PLUGIN AND LIBRARY NAMES FOR SHA-2 AUTHENTICATION
#
# Plugin or File 				Plugin or File name
#
# Server-side plugin 		caching_sha2_password
#
# Client-side plugin 		caching_sha2_password
#
# Library file 				None (plugins are built in)
#
# Installing SHA-2 Pluggable Authentication
#
# The caching_sha2_password plugin exists in server and client forms:
#
# 		) The server-side plugin is built into the server, need not be loaded explicitly, and cannot be disabled by unloading it.
#
# 		) The client-side plugin is built into the libmysqlclient client library and is available to any program linked against libmysqlclient
#
# The server-side plugin uses the sha2_cache_cleaner audit plugin as a helper to perform password cache management.
# sha2_cache_cleaner, like caching_sha2_password is built in and need not be installed.
#
# USING SHA-2 PLUGGABLE AUTHENTICATION
#
# To set up an account that uses the caching_sha2_password plugin for SHA-256 password hashing, use the following statement,
# where password is the desired account password:
#
# 		CREATE USER 'sha2user'@'localhost' IDENTIFIED WITH caching_sha2_password BY 'password';
#
# The server assigns the caching_sha2_password plugin to the account and uses it to encrypt the password using SHA-256,
# storing those values in the plugin and authentication_string columns of the mysql.user system table.
#
# The preceding instructions do not assume that caching_sha2_password is the default authentication plugin.
#
# If caching_sha2_password is the default authentication plugin, a simpler CREATE_USER syntax can be used.
#
# To start the server with the default authentication plugin set to caching_sha2_password, put these lines in the
# server option file:
#
# 		[mysqld]
# 		default_authentication_plugin=caching_sha2_password
#
# That causes the caching_sha2_password plugin to be used by default for new accounts.
# As a result, it is possible to create the account and set its password without naming the plugin explicitly:
#
# 		CREATE USER 'sha2user'@'localhost' IDENTIFIED BY 'password';
#
# Another consequence of setting default_authentication_plugin to caching_sha2_password is that, to use some other
# plugin for account creation, you must specify that plugin explicitly.
#
# For example, to use the mysql_native_password plugin, use this statement:
#
# 		CREATE USER 'nativeuser'@'localhost' IDENTIFIED WITH mysql_native_password BY 'password';
#
# caching_sha2_password supports connections over secure transport.
#
# If you follow the RSA configuration procedure given later in this section, it also supports encrypted
# password exchange using RSA over unencrypted connections.
#
# RSA support has these characteristics:
#
# 		) On the server side, two system variables named the RSA private and public key-pair files:
#
# 				caching_sha2_password_private_key_path
#
# 				and
#
# 				caching_sha2_password_public_key_path
#
# 			The database administrator must set these variables at server startup if the key files to use have names
# 			that differ from the system variable default values.
#
# 		) The server uses the caching_sha2_password_auto_generate_rsa_keys system variable to determine whether to automatically
# 			generate the RSA key-pair files.
#
# 		) The Caching_sha2_password_rsa_public_key status variable displays the RSA public key value used by the caching_sha2_password 
# 			authentication plugin.
#
# 		) Clients that are in possession of the RSA public key can perform RSA key pair-based password exchange with the server during
# 			the connection process, as described later.
#
# 		) For connections by accounts that authenticate with caching_sha2_password and RSA key pair-based password exchange, the server does
# 			not send the RSA public key to clients by default.
#
# 			Clients can use a client-side copy of the required public key, or request the public key from the server.
#
# 			Use of a trusted local copy of the public key enables the client to avoid a round trip in the client/server protocol, and is
# 			more secure than requesting the public key from the server.
#
# 			On the other hand, requesting the public key from the server is more convenient (it requires no management of a client-side file)
# 			and may be acceptable in secure network environments.
#
# 				) For command-line clients, use the --server-public-key-path option to specify the RSA public key file.
#
# 					Use the --get-server-public-key option to request the public key from the server.
#
# 					The following programs support the two options: mysql, mysqlsh ,mysqladmin, mysqlbinlog, mysqlcheck, mysqldump,
# 					mysqlimport, mysqlpump, mysqlshow, mysqlslap, mysqltest, mysql_upgrade
#
# 				) For programs that use the C API, call mysql_options() to specify the RSA public key file by passing the MYSQL_SERVER_PUBLIC_KEY
# 					option and the name of the file, or request the public key from the server by passing the MYSQL_OPT_GET_SERVER_PUBLIC_KEY option.
#
#
# 				) For replication slaves, use the CHANGE_MASTER_TO statement with the MASTER_PUBLIC_KEY_PATH option to specify the RSA public key file,
# 					or the GET_MASTER_PUBLIC_KEY option to request the public key from the master.
#
# 					For Group Replication, the group_replication_recovery_public_key_path and group_replication_recovery_get_public_key system variables
# 					serve the same purpose.
#
# In all cases, if the option is given to specify a valid public key file, it takes precedence over the option to request the public key from the server.
#
# For clients that use the caching_sha2_password plugin, passwords are never exposed as cleartext when connecting to the server.
#
# How password transmission occurs depends on whether a secure connection or RSA encryption is used:
#
# 		) If the connection is secure, an RSA key pair is unnecessary and is not used. This applies to encrypted TCP connections that use TLS,
# 			as well as Unix socket-file and shared-memory connections.
#
# 			The password is sent as cleartext but cannot be snooped because the conn is secure.
#
# 		) If the connection is not secure, an RSA key pair is used. This applies to unencrypted TCP connections without TLS and named-pipe connections.
# 			RSA is used only for password exchange between client and server, to prevent password snooping.
#
# 			When the server receives the encrypted password, it decrypts it. A scramble is used in the encryption to prevent repeat attacks.
#
# To enable use of an RSA key pair for password exchange during the client connection process, use the following procedure:
#
#  	1. Create the RSA private and public key-pair files using earlier instructions.
#
# 		2. If the private and public key files are located in the data directory and are named private_key.pem and public_key.pem
# 			(the default values of the caching_sha2_password_private_key_path and caching_sha2_password_public_key_path system variables), the server
# 			uses them automatically at startup.
#
# 			Otherwise, to name the key files explicitly, set the system variables to the key file names in the server option file.
# 			
# 			If the files are located in the server data directory, you need not specify their full path names:
#
# 				[mysqld]
# 				caching_sha2_password_private_key_path=myprivkey.pem
# 				caching_sha2_password_public_key_path=mypubkey.pem
#
# 			If the key files are not located in the data directory, or to make their locations explicit in the system variable values, use full path names:
#
# 				[mysqld]
# 				caching_sha2_password_private_key_path=/usr/local/mysql/myprivkey.pem
# 				caching_sha2_password_public_key_path=/usr/local/mysql/mypubkey.pem
#
# 		3. Restart the server, then connect to it and check the Caching_sha2_password_rsa_public_key status variable value.
#
# 			The value will differ from that shown here, but should be nonempty:
#
# 				SHOW STATUS LIKE 'Caching_sha2_password_rsa_public_key'\G
# 				************************* 1. row ****************************
# 				Variable_name: Caching_sha2_password_rsa_public_key
# 							Value: -------BEGIN PUBLIC KEY----------
# 				<values>
# 				---------END PUBLIC KEY-------
#
# 			If the value is empty, the server found some problems with the key files.
# 			Check the error log for diagnostic information.
#
# 			After the server has been configured with the RSA key files, accounts that authenticate with the caching_sha2_password plugin
# 			have the option of using thoose key files to connect to the server.
#
# 			As mentioned previously, such accounts can use either a secure connection (in which case RSA is not used) or
# 			an unencrypted connection that performs password exchange using RSA.
#
# 			Suppose that an unencrypted connection is used. For example:
#
# 				mysql --ssl-mode=DISABLED -u sha2user -p
# 				Enter password: password
#
# 			For this connection attempt by sha2user, the server determines that caching_sha2_password is the appropriate authentication
# 			plugin and invokes it (because that was the plugin specified at CREATE_USER time).
#
# 			The plugin finds that the connection is not encrypted and thus requires the password to be transmitted
# 			using RSA encryption.
#
# 			However, the server does not send the public key to the client, and the client provided no public key,
# 			so it cannot encrypt the PW and teh connection fails:
#
# 			ERROR 2061 (HY000): Authentication plugin 'caching_sha2_password'
# 			reported error: Authentication requires secure connection
#
# 			To request the RSA public key from the server, specify the --get-server-public-key option:
#
# 				mysql --ssl-mode=DISABLED -u sha2user -p --get-server-public-key
# 				Enter password: password
#
# 			In this case, the server sends the RSA public key to the client, which uses it to encrypt the password and returns the 
# 			result to the server.
#
# 			The plugin uses the RSA private key on the server side to decrypt the PW and accepts or rejects the conection based
# 			on whether the PW is correct.
#
# 			Alternatively, if the client has a file containing a local copy of the RSA public key required by the server, it can
# 			specify the file using the --server-public-key-path option:
#
# 				mysql --ssl-mode=DISABLED -u sha2user -p --server-public-key-path=file_name
# 				Enter password: password
#
# 			In this case, the client uses the public key to encrypt the password and returns the results to the server.
# 			The plugin uses the RSA private key on the server side to decrypt the PW and accepts or rejects based on correctness.
#
# 			The public key value in the file named by the --server-public-key-path option should be the same as the key value
# 			in the server-side file named by the caching_sha2_password_public_key_path system variable.
#
# 			If the key file contains a valid public key value but the value is incorrect, an access-denied error occurs.
#
# 			If the key file does not contain a valid public key, the client program cannot use it.
#
# 			Client users can obtain the RSA public key two ways:
#
# 				) The database admin can provide a copy of the public key file
#
# 				) A client user who can connect to the server some other way can use a SHOW STATUS LIKE 'Caching_sha2_password_rsa_public_key"
# 					statement and save the returned key value in a file.
#
# CACHE OPERATION FOR SHA-2 PLUGGABLE AUTHENTICATION
#
# On the server side, the caching_sha2_password plugin uses an in-memory cache for faster authentication of clients who have
# connected previously.
#
# Entries consists of account-name/password-hash pairs. The cache works like this:
#
# 		1. When a client connects, caching_sha2_password checks whether the client and password match some cache entry.
#
# 			If so, authentication succeeds.
#
# 		2. If there is no matching cache-entry, the plugin attempts to verify the client against the credentials in the mysql.user system table.
#
# 			If this succeeds, caching_sha2_password adds an entry for the client to the hash. Otherwise, authentication fails and the connection is rejected.
#
# In this way, when a client first connects, authentication against the mysql.user system table occurs.
#
# When the client connects subsequently, faster authentication against the cache occurs.
#
# Password cache operations other than adding entries are handled by the sha2_cache_cleaner audit plugin,
# which performs these actions on behalf of caching_sha2_password:
#
# 		) It clears the cache entry for any account that is renamed or dropped, or any account for which the credentials or authentication
# 			plugins are changed.
#
# 		) It empties the cache when the FLUSH_PRIVILEGES statement is executed.
#
# 		) It empties the cache at server shutdown. (This means the cache is not persistent across server restarts).
#
# Cache cleaning operations affect the authentication requirements for subsequent client connections.
#
# For each user account, the first client connection for the user after any of the following operations must use a 
# secure connection (made using TCP using TLS credentials, a Unix socket file, or shared memory) or RSA key pair-based
# PW exchange:
#
# 		) After account creation
#
# 		) After a PW change for the account
#
# 		) After RENAME_USER for the account
#
# 		) After FLUSH_PRIVILEGES
#
# FLUSH_PRIVILEGES clears the entire cache and affects all accounts that use the caching_sha2_password plugin.
# The other operations clear specific cache entries and affect only accounts that are part of the operation.
#
# Once the user authenticates successfully, the account is entered into the cache and subsequent connections do not require
# a secure connection or the RSA key pair, until another cache clearing event occurs that affects the account.
#
# (When the cache can be used, the server uses a challenge-response mechanism that does not use cleartext password
# transmission and does not require a secure connection).
#
# CLIENT-SIDE CLEARTEXT PLUGGABLE AUTHENTICATION
#
# A client-side authentication plugin is available that sends the PW to the server without hashing or encryption.
#
# THis plugin is built into the MySQL client lib.
#
# The following table shows the plugin name.
#
# PLUGIN AND LIBRARY NAMES FOR CLEARTEXT AUTHENTICATION
#
# Plugin or File 			Plugin or File Name
# Server-side plugin 	None, see discussion
#
# Client-side plugin 	mysql_clear_password
#
# Library file 			None (plugin is built in)
#
# With many MySQL authentication methods, the client performs hashing or encryption of the password before sending it to the server.
# This enables the client to avoid sending the PW in clear text.
#
# Hashing or encryption cannot be done for authentication schemes that require the server to receive the PW as entered on the client side.
# In such cases, the client-side mysql_clear_password plugin is used to send the PW to the server in clear text.
#
# There is no corresponding server-side plugin. Rather, the client-side plugin can be used by any server-side plugin that needs
# a cleartext PW.
#
# Examples are PAM and simple LDAP authentication plugins.
#
# The following discussion provides usage information specific to clear text pluggable authentication.
# For general information about pluggable authentication in MySQL, see earlier.
#
# NOTE:
#
# 		Sending PWs in clear text may be a security problem in some configurations.
#
# 		To avoid problems if there is any possibility that the password would be intercepted,
# 		clients should connect to MySQL Server using a method that protects the password.
#
# 		Possibilities include SSL, IPsec or a private network.
#
# To make inadvertent use of the mysql_clear_password plugin less likely, MySQL clients must explicitly enable it.
# This can be done in several ways:
#
# 		) Set the LIBMYSQL_ENABLE_CLEARTEXT_PLUGIN environment variable to a value that begins with 1, Y or y.
#
# 			This enables the plugin for all client connections.
#
# 		) The mysql, mysqladmin, mysqlcheck, mysqldump, mysqlshow and mysqlslap client programs support an --enable-cleartext-plugin option
# 			that enables the plugin on a per-invocation basis.
#
# 		) The mysql_options() C API function supports a MYSQL_ENABLE_CLEARTEXT_PLUGIN option that enables the plugin on a per-connection basis.
#
# 			Also, any program that uses libmysqlclient and reads option files can enable the plugin by including an enable-cleartext-plugin option
# 			in an option group read by the client library.
#
# PAM PLUGGABLE AUTHENTICATION
#
# NOte:
#
# 		The PAM pluggable authentication is an extension included in MySQL Enterprise Edition, a commercial product.
# 
# MySQL Enterprise Edition supports an authentication method that enables MySQL Server to use PAM (Pluggable Authentication Modules)
# to authenticate MySQL users.
#
# PAM enables a system to use a standard interface to access various kinds of authentication methods, such as UNIX passwords or an LDAP directory.
#
# PAM pluggable authentication provides these capabilities:
#
# 		) External authentication: PAM authentication enables MySQL server to accept connections from users defined outside the MySQL grant tables
# 			and that authenticate using methods supported by PAM.
#
# 		) Proxy user support: PAM authentication can return to MySQL a user name different from the login user, based on the groups the external user
# 										is in and the authentication string provided.
#
# 									This means that the plugin can return the MySQL user that defines the privileges the external PAM-authenticated user should have.
#
# 									For example, a user named joe can connect and have the privileges of the user named developer.
#
# PAM pluggable authentication has been tested on Linux and macOS.
#
# The PAM plugin uses the information passed to it by MySQL Server (such as user name, host name, password and authentication string),
# 	plus whatever method is available for PAM lookup.
#
# The plugin checks the user credentials against PAM and returns 'Authentication succeeded, Username is user_name' or
# 'Authentication failed'.
#
# The following table shows the plugin and library file names. The file name suffix might differ on your system.
#
# The file must be located in the directory named by the plugin_dir SYSTEM VARIABLE.
#
# PLUGIN AND LIBRARY NAMES FOR PAM AUTHENTICATION
#
# PLugin or File 					PLugin or file name
#
# Server-side plugin 			authentication_pam
#
# Client-side plugin 			mysql_clear_password
#
# Library file 					authentication_pam.so
#
# The client-side clear-text plugin that communicates with the server-side PAM plugin is built into the libmysqlclient client library
# and is included in all distribs, including community distribs.
#
# Inclusion of the client-side clear-text plugin in all MySQL distribs enables clients from any distrib to connect
# to a server that has the server-side plugin loaded.
#
# INSTALLING PAM PLUGGABLE AUTHENTICATION
#
# This section describes how ot install the PAM authentication plugin. 
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin dir (the dir named by the plugin_dir 
# system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is authentication_pam. The file name suffix differs per platform (for example, .so for Unix and
# Unix-like systems, .dll for Windows)
#
# To load the plugin at server startup, use the --plugin-load-add option to name the library file that contains it.
#
# With this plugin-loading method, the option must be given each time the server starts.
# For example, put these lines in the server my.cnf file (adjust the .so suffix for your platform as necessary):
#
# 		[mysqld]
# 		plugin-load-add=authentication_pam.so
#
# After modifying my.cnf, restart the server to cause the new settings to take effect.
#
# Alternatively, to register the plugin at runtime, use this statement (adjust the .so suffix as necessary):
#
# 		INSTALL PLUGIN authentication_pam SONAME 'authentication_pam.so';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it in the mysql.plugins system table to cause
# the server to load it for each subsequent normal startup.
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# for example:
#
# 		SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA PLUGINS WHERE PLUGIN_NAME LIKE '%pam%';
# 		+-------------------------------+
# 		| PLUGIN_NAME | 					  |
# 		+-------------+-----------------+
# 		| authentication_pam | ACTIVE   |
# 		+-------------------------------+
#
# If the plugin fails to intiialize, check the server error log for diagnostic messages.
#
# To associate MySQL accounts with the PAM plugin, see Using PAM Pluggable Authentication.
#
# UNINSTALLING PAM PLUGGABLE AUTHENTICATION
#
# The method used to uninstall the PAM authentication plugin depends on how you installed it:
#
# 		) If you installed the plugin at server startup using a --plugin-load-add option, restart the server without the option.
#
# 		) If you installed the plugin at runtime using INSTALL_PLUGIN, it remains installed across server restarts. To uninstall it, use UNINSTALL_PLUGIN:
#
# 			UNINSTALL PLUGIN authentication_pam;
#
# USING PAM PLUGGABLE AUTHENTICATION
#
# This section describes how to use the PAM authentication plugin to connect from MySQL client programs to the server.
# It is assumed that the server is running with the server-side plugin enabled, as described in Installing PAM Pluggable Authentication.
#
# TO refer to the PAM authentication plugin in the IDENTIFIED WITH clause of a CREATE_USER statement, use the name authentication_pam.
# For example:
#
# 		CREATE USER user
# 			IDENTIFIED WITH authentication_pam
# 			AS 'authentication_string';
#
# The authentication string specifies the following types of information:
#
# 		) PAM supports the notion of "service name", which is a name that the system administrator can use to configure
# 			the authentication method for a particular application.
#
# 			There can be several such "applications" associated with a single database server instance, so the choice of service name
# 			is left to the SQL application developer.
#
# 			When you define an account that hsould authenticate using PAM, specify the service name in the authentication string.
#
# 		) PAM provides a way for a PAM module to return to the server a MySQL user name other than the login name supplied at login time.
# 			Use the authentication string to control the mapping between login name and MySQL user name.
#
# 			If you want to take advantage of proxy user capabilities, the authentication string must include this kind of mapping.
#
# For example, if the service name is mysql, and users in the root and users PAM groups should be mapped to the developer and data_entry
# MySQL users, respectively, use a statement like this:
#
# 		CREATE USER user
# 			IDENTIFIED WITH authentication_pam
# 			AS 'mysql, root=developer, users=data_entry';
#
# Authentication string syntax for the PAM authentication plugin follows these rules:
#
# 		) The string consists of a PAM service name, optionally followed by a group mapping list consisting of one or more keyword/value pairs
# 			each specifying a group name and a MysQL user name:
#
# 				pam_service_name[,group_name=mysql_user_name]...
# 
# 			The plugin parses the authentication string on each login check. To minimize overhead, keep the string as short as possible.
#
# 		) Each group_name=mysql_user_name pair must be preceded by a comma.
#
# 		) Leading and trailing spaces not inside double "" marks are ignored.
#
# 		) Unquoted pam_service_name, group_name and mysql_user_name values can contain anything except =, , or space
#
# 		) If a pam_service_name, group_name or mysql_user_name value is quoted with ", everything between the quotation marks is part of a value.
# 
# 			tHis is necessary, fo rexample, if the value contains space chars.
#
# 			All characters are legal except double quotation mark and \.
# 			To include either character, escape it with a \.
#
# If the plugin successfully authenticates a login name, it looks for a group mappings list in the authentication string and,
# if present, uses it to return a different user name to teh MySQL server based on the groups the external user is a member of:
#
# 		) If the authentication string contains no group mapping list, the plugin returns the login name.
#
# 		) If the authentication string does contain a group mapping list, the plugin examines each group_name=mysql_user_name pair in the
# 			list from left to right and tries to find a match for the group_name value in a non-MySQL directory of the groups assigned
# 			to the authenticated user and returns mysql_user_name for the first match it finds.
#
# 			If the plugin finds no match for any group, it returns the login name.
#
# 			If the plugin is not capable of looking up a group in a directory, it ignores the group mapping list and
# 			returns the login name.
#
# THe following sections describe how to set up several authentication scenarios that use the PAM authentication plugin:
#
# 	) No proxy users. This uses PAM only to check login names and PWs.
#
# 		Every external user permitted to connect to MySQL Server should have a matching MySQL account that is defined to use
# 		external PAM authentication.
#
# 		(For a MySQL account of user_name@host_name to match the external user, user_name must be the login name and host_name
# 		must match the host from which the client connects).
#
# 		Authentication can be performed by various PAM-supported methods.
#
# 		The discussion shows how to use traditional Unix PWs and LDAP.
#
# 		PAM authentication, when not done through proxy users or groups, requires the MySQL account to have the same
# 		user name as the Unix account.
#
# 		MySQL user names are limited to 32 chars.
#
# 		Which limits PAM nonproxy authentication to Unix accounts with a name of at most 32 chars.
#
# ) Proxy login only and group mapping. For this scenario, create one or a few MySQL accounts that define different sets of privileges.
#
# 		(Ideally, nobody should connect using those accounts directly).
#
# 	Then define a default user authenticating through PAM that uses some mapping scheme (usually by the external groups the users are in)
# to map all the external logins to the few MySQL accounts holding the privilege sets.
#
# Any user that logs in is mapped to one of the MySQL accoutns and uses its privileges.
#
# THe discussion shows how ot set htis up using Unix PWs, but other PAM methods such as LDAP could be used instead.
#
# Variations of these scenarios are possible. For example, you can permit some users to log in  directly (without proxying)
# but reuqire others to connect through proxies.
#
# the examples make the following assumptions. You might need to make some adjustments, if your system is set up differently.
#
# 	) The PAM configuration directory is /etc/pam.d
#
# 	) The PAM service name is mysql, which means that you must set up a PAM file named mysql in the PAM configuration directory (creating
# 		the file if it does not exist).
#
# 		If you use a service name different from mysql, the file name will differ and you must use a different name in the AS `auth_string` 
# 		clause of CREATE_USER statements.
#
# 	) The examples use a login name of antonio and a password of verysecret. Change these accoridng to the user you want ot authenticate.
#
# The PAM authentication plugin checks at initialization time whether the AUTHENTICATION_PAM_LOG environemtn value is set in the server's
# startup environment.
#
# If so, the plugin enables logging of diagnostic messages to the standard output.
#
# Depeding on how  your server is started, the message might appear on the console or in the error
# log.
#
# These messages can be helpful for debugging PAM-related problems that occur when the plugin performs authentication.
#
# UNIX PASSWORD AUTHENTICATION WITHOUT PROXY USERS
#
# The authentication scenario uses PAM only to check Unix user login names and passwords.
#
# Every external user permitted to connect to MySQL Server should have a matching MySQL account that is defined
# to use external PAM authentication.
#
# 1) Verify that Unix authentication in PAM permits you to log in as the respective user.
#
# 2) Set up PAM to authenticate the mysql service by creating a file named /etc/pam.d/mysql.
#
# 		The file contents are system dependent, so check existing login-related files in the
# 		/etc/pam.d directory to see what they look like.
#
# 		On Linux, the mysql file might look like this:
#
# 			#%PAM-1.0
# 			auth 				include 			password-auth
# 			account 			include 			password-auth
#
# 		For Gentoo Linux, use system-login rather than password-auth. For macOS, use login rather than password-auth
#
# 		The PAM file format might differ on some systems. For example, on Ubuntu and other Debian-based systems, use these files
# 		contents instead:
#
# 			@include common-auth
# 			@include common-account
# 			@include common-session-noninteractive
#
# 3) Create a MySQL account with the same user name as the Unix login name and define it to authenticate using the PAM plugin:
#
# 		CREATE USER 'antonio'@'localhost'
# 			IDENTIFIED WITH authentication_pam AS 'mysql';
# 		GRANT ALL PRIVILEGES ON mydb.* TO 'antonio'@'localhost';
#
# 4. Connect to the MySQL server using the mysql command-line client. For example:
#
# 		mysql --user=antonio --password 	--enable-cleartext-plugin mydb
# 		Enter password: verysecret
#
# The server should permit the connection and the following query hsould return output as shown:
#
# 		SELECT USER(), CURRENT_USER(), @@proxy_user;
# 		+-----------------------------------------------------+
# 		| USER() 				| CURRENT_USER() 	 | @@proxy_user|
# 		+--------------------+------------------+-------------+
# 		| antonio@localhost 	| antonio@localhost| NULL 		   |
# 		+--------------------+------------------+-------------+
#
# This demonstrates that antonio uses the privileges granted to the antonio MySQL acc, and taht no proxy has occured.
#
# NOTE:
#
# 		The client-side mysql_clear_password plgin with which the sever-side PAM plugin communicates sends the PW to the MySQL server in clear
# 		text so it can be passed to PAM.
#
# 		THis is necessary to use the server-side PAM library, but may be a security problem in some configurations.
#
# 		These measures minimize the risk:
#
# 				) To make inadvertent use of the mysql_clear_password plugin less likely, MySQL clients must explicitly enable it;
# 					for example, with the --enable-cleartext-plugin option.
#
# 			) To avoid PW exposure with the mysql_clear_password plugin enabled, MySQL clients should connect to the MySQL server
# 				using a secure connection.
#
# NOTE:
#
# 		On some systems, Unix authentication uses /etc/shadow, a file that typically has restricted access permissions.
#
# 		This can cause MySQL PAM-based authentication to fail. Unfortunately, the PAM implementation does not permit
# 		distinguishing "PW could not be checked" (due to failed permissions to read /etc/shadow) from "PW did not match".
#
# 		IF your system uses /etc/shadow, you may be able to enable access to it by MySQL using thsi method (assuming that
# 			the MySQL server is run from the mysql system account):
#
# 		1. Create a shadow group in /etc/group
#
# 		2. Add the mysql user to the shadow group in /etc/group.
#
# 		3. Assign /etc/group to the shadow group and enable the group read permission:
#
# 			chgrp shadow /etc/shadow
# 			chmod g+r /etc/shadow
#
# 		4. Restart the MySQL server
#
# LDAP Authentication without Proxy Users
#
# This authentication scenario uses PAM only to check LDAP user login names and passwords.
#
# Every external user permitted to connect to MySQL Server should have a matching MySQL account that is defined
# to use external PAM authentication.
#
# 	1. Verify that LDAP authentication in PAM permits you to log in as antonio with password verysecret
#
# 	2. Set up PAM to authenticate the mysql service through LDAP by creating a file named /etc/pam.d/mysql.
#
# 		The file contents are system dependent, so check existing login-related files in the /etc/pam.d direcotry
# 		to see what they look like. On Linux, the mysql file might look like this:
#
# 			#%PAM-1.0
# 			auth 			required 		pam_ldap.so
# 			account 		required 		pam_ldap.so
#
# 		If PAM object files have a suffix different from .so on your system, substitute the correct suffix.
#
# 		The PAM file format might differ on some systems.
#
# 	3. MySQL account creation and connecting to the server is the same as described in UNIX PW AUTHENTICATION WITHOUT PROXY USERS.
#
# UNIX PASSWORD AUTHENTICATION WITH PROXY USERS AND GROUP MAPPING
#
# The authentication scheme described here uses Proxying and group mapping to map connecting MySQL users who authenticate using
# PAM onto other MySQL accounts that define different sets of privileges.
#
# USers do not connect directly through the accounts that define the privileges.
#
# INstead, they connect through a default proxy user authenticated using PAM, such that all
# the external logins are mapped to the MySQL accounts that holds the privileges.
#
# Any user who connects is mapped to one of those MySQL accounts, the privileges for which
# determines the database operations permitted to the external user.
#
# The procedure shown here uses Unix password authentication. To use LDAP instead, see earlier.
#
# 1. Verify that Unix authentication in PAM permits you to log in as antonio with password verysecret and that
# 		antonio is a member of the root of users group.
#
# 2. Set up PAM to authenticate the mysql service. Put the following in /etc/pam.d/mysql:
#
# 		#%PAM-1.0
# 		auth 				include 			password-auth
# 		account 			include 			password-auth
#
# 		For Gentoo Linux, use system-login rather than password-auth.
# 		For macOS, use login rather than password-auth.
#
# 		The PAM file format might differ on some systems. For example, on Ubuntu and other Debian-based systems,
# 		use these file contents instead:
#
# 			@include common-auth
# 			@include common-account
# 			@include common-session-noninteractive
#
# 3. Create a default proxy user (''@'') that maps the external PAM users to the proxied accounts.
#
# 		It maps external users from the root PAM group to the developer MySQL account and the external users
# 		from the users PAM group to the data_entry MySQL account:
#
# 			CREATE USER ''@'' IDENTIFIED WITH authentication_pam AS 'mysql, root=developer, users=data_entry';
#
# The mapping list following the service name is required when you set up proxy users. Otheriwse, the plugin cannot
# 	tell how to map the name of PAM groups to the proper proxied user name.
#
# NOTE:
#
# 		IF your MySQL installation has anon users, they might conflict with the defualt proxy user.
#
# 4. Create the proxied accounts that will be used to access the database:
#
# 		CREATE USER 'developer'@'localhost' IDENTIFIED BY 'very secret PW';
# 		GRANT ALL PRIVILEGES ON mydevdb.* TO 'developer'@'localhost';
# 		CREATE USER 'data_entry'@'localhost' IDENTIFIED BY 'very secret PW';
# 		GRANT ALL PRIVILEGES ON mydb.* TO 'data_entry'@'localhost';
#
# If you do not let anyone know the PWs for these accs, other user cannot use them to 
# cornect directly to the MySQL server.
#
# iNStead, it is expected that users will authneticate using PAM and that they will use the
# developer or data_entry account by proxy on their PAM group.
#
# 5. Grant the PROXY privilege to the proxy account for the proxied accounts:
#
# 		GRANT PROXY ON 'developer'@'localhost' TO ''@'';
# 		GRANT PROXY ON 'data_entry'@'localhost' TO ''@'';
#
# 6. Connect to the MySQL server using the mysql command-line client. For example:
#
# 		mysql --user=antonio --password --enable-cleartext-plugin mydb
# 		Enter password: verysecret
#
# The server authenticates the connection using the ''@'' account.
#
# THe privileges antonio will have dependson what PEM groups he is a member of.
#
# If antonio is a member of  the root PAM group, the PAM plugin maps root to the developer 
# MySQL user name and returns that name to the server.
#
# The server verifies that ''@'' has the PROXY privilege for developer and permits the connection.
# THe following queyr should return output as shown:
#
# SELECT USER(), CURRENT_USER(), @@proxy_user;
# +-----------------------------------------------------+
# | USER() 			   | CURRENT_USER() 	   | @@proxy_user|
# +-----------------------------------------------------+
# | antonio@localhost| developer@localhost| ''@'' 		  |
# +-----------------------------------------------------+
#
# THis demonstrates that anotnio uses the privielges granted to the developer MySQl account, and that proxying
# occurred through the  default proxy user account.
#
# If antonio is not a member of the root PAM group but is a member of the users
# group, a similar process occurs, but the plugin maps user group membership to the data_entry MySQL user name and
# returns that name to the server.
#
# In this case, antonio uses the privileges of the data_entry MySQL account:
#
# SELECT USER(), CURRENT_USER(), @@proxy_user;
# +-------------------------------------------------------+
# | 	USER() 			| 		CURRENT_USER()  |  @@proxy_user| 		
# +-------------------------------------------------------+
# | antonio@localhost| data_entry@localhost|''@'' 			 |
# +-------------------------------------------------------+
#
# NOTE:
#
# THe client-side mysql_clear_password plugin with which the server-side PAM plugin communicates sends the password
# to the MySQL server in clear text so it can be passed to PAM.
#
# This is necessary to use the server-side PAM library, but may be a security problem in some configs.
#
# These measures minimize hte risk:
#
# 		) To make inadvertent use of the mysql_clear_password plugin less likely, MySQL clients must explicitly enable it;
# 			For example, with the --enable-cleartext-plugin option.
#
# 		) To avoid password exposure with the mysql_clear_password plugin enabled, MySQL clients should connect to
# 			the MySQL server using a secure connection.
#
# PAM PLUGGABLE AUTHENTICATION DEBUGGING
#
# The PAM authentication plugin checks at intiailizaiton time whether the AUTHENTICATION_PAM_LOG envrionment value is set
# (the value does not matter).
#
# IF so, the plugin enables logging of diagnostic messages to the standard output.
#
# These messages may be helpful for debugging PAM-related problems that occur when the plugin performs
# authentication.
#
# SOme messages include reference to PAM plugin source files and line numbers, which enables plugin actions to be tied more closely
# to the location in the code where they occur.
#
# WINDOWS PLUGGABLE AUTHENTICATION
#
# NOTE:
#
# 		WIndows pluggable authentication is an extension included in MySQL Enterprise Edition, a commercial product.
#
# MySQL Enterprise Edition for Windows supports an authentication method that performs external authentication on Windows,
# 	enabling MySQL Server to use Native Windows services to authenticate client connections.
#
# Users who have logged in to Windows can connect from MySQL client programs to the server based on the information in the
# environment without specifying an additonal PW.
#
# The client and server exchanges data packets in the authentication handshake. As a result of this exchange, the server
# creates a security context object that represents the identity of the client in the Windows OS.
#
# This identity includes the name of the client account.
#
# WIndows pluggable authentication uses the identity of the client to check whether it is a given account or a member of a group.
# By default, negotiation uses Kerberos to atuehtnicate, then NTLM if Kerberos is unavailable.
#
# Windows pluggable authentication provides these capabilities:
#
# 		) External authentication: Windows authentication enables MySQL Server to accept connections from users defined outside the
# 			MySQL grant tables who ahve logged in to Windows.
#
# 		) Proxy user support: Windows authentication can return to MySQL a user name different from the client user.
#
# 			THis means that the plugin can return the MySQL user that defines the privileges the external Windows-authenticated
# 			user should have.
#
# 			FOr example, a user named joe can connect and have the privileges of the user named developer.
#
# The following tbale shows the plugin and library file names. The file must be located in the directory named by the
# plugin_dir system varaible.
#
# PLUGIN AND LIBRARY NAMES FOR WINDOWS AUTHENTICATION
#
# Plugin or File 			Plugin or File name
# 
# Server-side plugin 	authentication_windows
#
# Client-side plugin 	authentication_windows_client
#
# Library file 			authentication_windows.dll
#
# The library file includes only the server-side plugin. THe client-side plugin is built into the libmysqlclient client library.
#
# The server-side Windows authentication plugin is included only in MySQL Enterprise Edition.
# It is not included in MySQL community distributions.
#
# The client-side plugin is included in all distirbutions, including community distribs. This permits clients from any distrib
# to connect to a server that has the server-side plugin loaded.
#
# The Windows authentication plugin is supported on any version of Windows supported by MySQL 8.0
#
# INSTALLING WINDOWS PLUGGABLE AUTHENTICATION
#
# This section describes how ot install the Windows auth plugin. 
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory (the directory named by the
# plugin_dir SYSTEM VARIABLE).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# To load the plugin at server startup, use the --plugin-load-add option to name the library file that contains it.
# WIth this plugin-loading method, the option must be given each time the server starts.
#
# For example, put these lines in the server my.cnf file:
#
# 		[mysqld]
# 		plugin-load-add=authentication_windows.dll
#
# AFter modifying my.cnf, restart the server to cause the new settins to tkae effect.
#Q
# Alternatively, to register the plugin at runtime, use this statement:
#
# INSTALL PLUGIN authentication_windows SONAME 'authentication_windows.dll';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it in the mysql.plugins system table to cause the
# server to load it for each subsequent normal startup.
#
# TO verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement
#
# For example:
#
# 		SELECT PLUGIN_NAME, PLUGIN_STATUS
# 		FROM INFORMATION_SCHEMA.PLUGINS
# 		WHERE PLUGIN_NAME LIKE '%windows%';
# 		+----------------------------------------------+
# 		| PLUGIN_NAME 		        | PLUGIN_STATUS 	  |
# 		+----------------------------------------------+
# 		| authentication_windows  | ACTIVE 				  |
# 		+----------------------------------------------+
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# UNINSTALLING WINDOWS PLUGGABLE AUTHENTICATION
#
# The method used to uninstall the Windows authentication plugin depends  on how you installed it:
#
# 		) If you installed the plugin at server startup using a --plugin-load-add option, restart the server without the option
#
# 		) If you installed the plugin at runtime using INSTALL_PLUGIN, it remains installed across server restarts. to unstainll it, use UNINSTALL_PLUGIN:
#
# 			UNINSTALL PLUGIN authentication_windows;
#
# In addition, remove any startup options that set Windows plugin-related System Variables
#
# USING WINDOWS PLUGGABLE AUTHENTICATION
#
# The Windows authentication plugin supports the use of MySQL accounts such that users who have logged in to Windows can connect to the 
# MySQL server without having to specify an additional PW.
#
# IT is assumed that hte server is runnning with the server-side plugin enabled.
#
# Once the DBA has enabled the server-side plugin and set up accounts to use it, clients can connect using those accounts
# with no other setup required on their part.
#
# To refer to the Windows authentication plugin in the IDENTIFIED WITH clause of a CREATE_USER statement, use the name
# authentication_windows.
#
# Suppose that the Windows uses Rafal and Tasha should be permitted to connect to MySQL, as well as any users in the Administrators or Power Users group.
#
# To set this up, create a MySQL account named sql_admin that uses the Windows plugin for authentication:
#
# 		CREATE USER sql_admin IDENTIFIED WITH authentication_windows AS 'Rafal, Tasha, Administration, "Power Users"';
#
# The plugin name is authentication_windows.
#
# the string following the AS Keyword is the authentication string. It specifies that hte Windows user named Rafal or Tasha are permitted
# to authenticate to the server as the MysQL user sql_admin, as are any Windows users in the Administrators or Power Users group.
#
# The latter group name contains a space, so it must be quoted with double quote chars.
#
# After you create the sql_admin account, a user who has logged in to WIndows can attempt to connect to the server using that account:
#
# 		mysql --user=sql_admin
#
# no password is required here. The authentication_windows plugin uses the WIndows security API to check which Windows user is connecting.
#
# If that user is named Rafal or Tasha, or is in the Administrators or Power Users group, the server grants access and the client
# is authenticated as sql_admin and has whatever privileges are granted to the sql_admin account.
#
# Otherwise, the server denies access.
#
# Authentication string syntax for the Windows authentication plugin follows these rules:
#
# 		) The string consists of one or more user mappings separated by commas.
#
# 		) Each user mapping associates a Windows user or group name with a MySQL user name:
#
# 			win_user_or_group_name=mysql_user_name
# 			win_user_or_group_name
#
#			For the latter syntax, with no mysql_user_name value given, the implicit value is the MySQL user created by the CREATE_USER statement.
#
# 			Thus, these statements are equivalent:
#
# 				CREATE USER sql_admin IDENTIFIED WITH authentication_windows AS 'Rafal, Tasha, Administrators, "Power Users"';
#
# 				CREATE USER sql_admin IDENTIFIED WITH authentication_windows AS 'Rafal=sql_admin, Tasha=sql_admin, Administrators=sql_admin, "Power Users"=sql_admin';
#
# 		) Each blackslash ('\') in a value must be doubled becuase backslash is the escape char in MySQL strings.
#
# 		) Leading and trailing spaces not inside " marks are ignored
#
# 		) Unuquoted win_user_or_group_name and mysql_user_name values can contain anything except equal signs, comma or spaces.
#
# 		) If a win_user_or_group_name and/or mysql_user_name value is quoted with ", everything between the "" marks is part of the value.
# 			This is necessary, for example, if the name contains space characters.
#
# 			All chars within " are legal except " and \, to include those, escape them with \
#
# 		) win_user_or_group_name values use conventional syntax for Windows principals, either local or in a domain.
#
# 			Examples (note the doubling of backslashes):
#
# 				domain\\user
# 				.\\user
# 				domain\\group
# 				.\\group
# 				BUILTIN\\WellKnownGroup
#
# WHen invoked by the server to authenticate a client, the plugin scans the authentication string left to right for a user or group match
# to the WIndows user.
#
# If there is a match, the plugin returns the corresponding mysql_user_name to the MySQL server. If there is no match, authentication fails.
#
# A user name match takes preference over a group name match. Suppose that the Windows user named win_user is a member of win_group and the
# authentication string looks like this:
#
# 		'win_group = sql_user1, win_user = sql_user2'
#
# When win_user connects to the MySQL server, there is a match both to win_group and to win_user.
#
# The plugin authenticates the user as sql_user2 because the more specific user match takes precedence over the group match,
# even if the group is listed as the first param in the authentication string.
#
# Windows authentication always works for connections from the same computer on which the server is running.
#
# For cross-computer connections, both computers must be registered with Windows Active Directory.
#
# If they are in the same Windows domain, it is unnecessary to specify a domain name.
#
# It is also possible to permit connections from a different domain, as in this example:
#
# 		CREATE USER sql_accounting IDENTIFIED WITH authentication_windows AS 'SomeDomain\\Accounting';
#
# Here SomeDomain is the name of the other domain. The \ is doubled because it is the MySQL escape char within strings.
#
# MySQL supports the concept of proxy users whereby a client can connect and authenticate to the MySQL server using one account
# but while connected has the privileges of another account.
#
# Suppose that you want Windows users to connect using a single user name but be mapped based on their Windows user and group
# names onto specific MySQL accounts as follows:
#
# 		) The local_user and MyDomain\domain_user local and domain Windows users should map to the local_wlad MySQL account.
#
# 		) Users in the MyDomain\Developers domain group should map to the local_dev MySQL account.
#
# 		) Local machine administrators should map to the local_admin MySQL account.
#
# To set this up, create a proxy account for WIndows users to connect to, and configure this account so taht users and groups
# map to the appropriate MySQL accounts (local_wlad, local_dev, local_admin).
#
# In addition, grant the MySQL accounts the privileges appropriate to the operations they need to perform.
#
# The following instructions use win_proxy as the proxy account, and local_wlad, local_dev and local_admin as the proxied accounts.
#
# 1. Create the proxy MySQL account:
#
# 		CREATE USER win_proxy IDENTIFIED WITH authentication_windows AS 'local_user = local_wlad, MyDomain\\domain_user = local_wlad,
# 																							 MyDomain\\Developers = local_dev, BUILTIN\\Administrators = local_admin';
#
# 		NOTE : If your MySQL installation has anon users, they might conflict with the default proxy user.
#
# 2. For proxying to work, the proxied accounts must exist, so create them:
#
# 		CREATE USER local_wlad IDENTIFIED BY 'wlad_pass';
# 		CREATE USER local_dev IDENTIFIED BY 'dev_pass';
# 		CREATE USER local_admin IDENTIFIED BY 'admin_pass';
#
# 		If you do not let anyone know the passwords for these accounts, other users cannot use them to connect directly to the MySQL server.
#
# 		You should also issue GRANT statements (not shown) that grant each proxied account the privileges it needs.
#
# 3. The proxy account must have the PROXY privilege for each of the proxied accounts:
#
# 		GRANT PROXY ON local_wlad TO win_proxy;
# 		GRANT PROXY ON local_dev TO win_proxy;
# 		GRANT PROXY ON local_admin TO win_proxy;
#
# Now the Windows users local_user and MyDomain\domain_user can connect to the MySQL server as win_proxy and when authenticated
# have the privileges of the account given in the authentication string - in this case, local_wlad.
#
# A user in the MyDomain\Developers group who connects as win_proxy has the privileges of the local_dev account.
#
# A user in the BUILTIN\Administrators group has privileges of the local_admin account.
#
# To configure authentication so that all Windows users who do not have their own MySQL account go through a proxy account,
# substitute the default proxy user (''@'') for win_proxy in teh preceding example.
#
# To use the Windows authentication plugin with Connector/NET connection strings in Connector/NET 6.4.4 and higher, see the instructions.
#
# Additional control over the Windows authentication plugin is provided by the authentication_windows_use_principal_name and
# authentication_windows_log_level SYSTEM VARIABLES.
#
# LDAP PLUGGABLE AUTHENTICATION
#
# NOTE: LDAP pluggable authentication is an extension included in MySQL Enterprise Edition, a commercial product.
#
# MySQL Enterprise Edition supports an authetication method that enables MySQL Server to use LDAP (Lightweight Directory Access Protocol)
# to authenticate MySQL users by accessing directory services such as X.500
#
# MySQL uses LDAP to fetch user, credential and group information.
#
# LDAP pluggable authentication provides these capabilities:
#
# 		) External authentication: LDAP authentication enables MySQL Server to accept connections from users defined outside the MySQL grant tables in LDAP directories.
#
# 		) Proxy user support: LDAP authentication can return to MySQL a user name different from the login user, based on the LDAP group of the external user.
#
# 		This means that an LDAP plugin can return the MySQL user that defines the privileges the external LDAP-authenticated user should have.
#
# 		For example, an LDAP user named joe can connect and have the privileges of the MySQL user named developer, if the LDAP group for joe is developer.
#
# 		) Security: Using TLS, connections to the LDAP server can be secure.
#
# The following table shows the plugin and library file names. The file name suffix might differ on your system.
#
# The files must be located in the directory named by the plugin_dir system variable.
#
# PLUGIN AND LIBRARY NAMES FOR LDAP AUTHENTICATION
#
# Plugin or File 					Plugin or File Name
# Server-side plugin names 	authentication_ldap_sasl, authentication_ldap_simple
#
# Client-side plugin names 	authentication_ldap_sasl_client, mysql_clear_password
#
# Library file names 			authentication_ldap_sasl.so, authentication_ldap_sasl_client.so, authentication_ldap_simple.so
#
# The library files include only the authentication_ldap_XXX plugins. The client-side mysql_clear_password plugin is built into the
# libmysqlclient client library.
#
# There are two server-side LDAP plugins, each of which works with a specific client-side plugin:
#
# 	) The server-side authentication_ldap_simple plugin performs simple LDAP authentication.
#
# 		For connections by accounts that use this plugin, client programs use the client-side mysql_clear_password plugin, which sends the
# 		PW to the server in clear text.
#
# 		No PW hashing or encryption is used, so a secure connection between the MySQL client and the server is recommended to prevent PW exposure
#
# ) The server-side authentication_ldap_sasl plugin performs SASL-based LDAP authentication.
#
# 	For connections by accounts that use this plugin, client programs use the client-side authentication_ldap_sasl_client plugin.
#
# The client-side and server-side SASL LDAP plugins use SASL messages for secure transmission of credentials within the LDAP protocol,
# to avoid sending the clear-text PW between the MySQL client and server.
#
# NOTE:
# 		If your system supports PAM and permits LDAP as a PAM authentication method, another way to use LDAP for MySQL user authentication
# 		is to use the server-side authentication_pam plugin.
#
# PREREQUISITES FOR LDAP PLUGGABLE AUTHENTICATION
#
# To use LDAP pluggable authentication for MySQL, these prerequisites must be satisfied:
#
# 		) An LDAP server must be available for the LDAP authentication plugins to communicate with.
#
# 		) LDAP users to be authenticated by MySQL must be present in teh directory managed by the LDAP server.
#
# 		) An LDAP client library must be available on systems where the server-side authentication_ldap_sasl or
# 			authentication_ldap_simple plugins is used.
#
# 			Currently, supported libraries are the Windows native LDAP library or the OpenLDAP library on non-Windows systems.
#
# 		) To use SASL-based LDAP authentication:
#
# 			) The LDAP server must be configured to communicate with a SASL server.
#
# 			) A SASL client library must be available on systems where the client-side authentication_ldap_sasl_client plugin is used.
#
# 				Currently, the only supported library is the Cyrus SASL library.
#
# HOW LDAP AUTHENTICATION OF MYSQL USERS WORKS
#
# This section provides a general overview of how MySQL and LDAP work together to authenticate MySQL users.
#
# For example showing how to set up MySQL accounts to use specific LDAP authentication plugins, see later.
#
# The client connects to the MySQL server, providing the MySQL client user name and the LDAP password:
#
# 		) For simple LDAP authentication, the client-side and server-side plugins communicate the plugin in clear text.
#
# 		) For SASL-based LDAP authentication, the client-side and server-side plugins use SASL messages for secure transmission of credentials 
# 			within the LDAP protocol, to avoid sending the clear-text password between the MySQL client and server.
#
# If the client user name and host name match no MySQL account, the connection is rejected.
#
# If there is a matching MySQL account, authentication against LDAP occurs. The LDAP server looks for an entry matching the user
# and authenticates the entry against the password:
#
# 		) If the MySQL account names and the LDAP user distinguished name (DN), LDAP authentication uses that value and the 
# 			LDAP password provided by the client.
#
# 			(To associate an LDAP user DN with a MySQL account, include a BY clause in the CREATE_USER statement that creates the account)
#
# 		) If the MySQL account names no LDAP user DN, LDAP authentication uses the user name and LDAP password provided by the client.
#
# 			In this case, the authentication plugin first binds to the LDAP server using the root DN and password as credentials to find
# 			the user DN based on the client user name, then authenticates the user DN against the LDAP password.
#
# 			The bind using the root credentials fails if teh root DN and password are set but to incorrect values, or are empty
# 			(not set) and the LDAP server does not permit anon connections.
#
# If the LDAP server finds no match or multiple matches, authentication fails and the client connection is rejected.
#
# If the LDAP serer finds a single match, LDAP authentication succeeds (assuming that the PW is correct), the LDAP server returns
# the LDAP entry, and the authetication plugin determines the name of the authenticated user based on that entry:
#
# 		) If the LDAP entry has a group attribute (by default, the cn attribute) - the plugin returns its value as the authenticated user name.
#
# 		) If the LDAP entry has no group attribute, the authentication plugin returns the client user name as the authenticated user name.
#
# The MySQL server compares the client user name with the authenticated user name to determine whether proxying occurs for teh client session:
#
# 		) If the names are the same, no proxying occurs: The MySQL account matching the client user name is used for privilege checking.
#
# 		) If the names differ, proxying occurs: MySQL looks for an account matching the authenticated user name.
#
# 			That account becomes the proxied user, which is used for privilege checking.
# 			The MySQL account that matched the client user name is treated as the external proxy user.
#
# INSTALLING LDAP PLUGGABLE AUTHENTICATON
#
# This section describes how to install the LDAP authentication plugins. 
#
# To be usable by the server, the plugin library files must be located in the MySQL plugin directory (the directory named by the plugin_dir system variable)
# 
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The server-side plugin library file base names are authentication_ldap_sasl and authentication_ldap_simple.
#
# The file name suffix differs per platform (for example, .so for Unix and Unix-like systems, .dll for windows)
#
# To laod the plugins at server startup, use --plugin-load-add options to name the library file that contain them.
# With this plugin-loading method, the options must be given each time the server starts.
#
# ALso, specify values for any plugin-provided System variables you wish to configure.
#
# Each server-side LDAP plugin exposes a set of system variables that enable its operation to be configured.
#
# Setting most of these is optional, but you must set the variables that specify the LDAP server host (so the plugin knows where to connect)
# and base distinguished names for LDAP bind operations (to limit the scope of searches and obtain faster searches). 
#
# For more about hte LDAP System variables, they are covered later.
#
# To load the plugins and set the LDAP server host and base distinguished name for LDAP bind operations, put lines such
# as these in your my.cnf file (adjust the .so suffix accordingly):
#
# 		[mysqld]
# 		plugin-load-add=authentication_ldap_sasl.so
# 		authentication_ldap_sasl_server_host=127.0.0.1
# 		authentication_ldap_sasl_bind_base_dn="dc=example,dc=com"
# 		plugin-load-add=authentication_ldap_simple.so
# 		authentication_ldap_simple_server_host=127.0.0.1
# 		authentication_ldap_simple_bind_base_dn="dc=example,dc=com"
#
# After modifying my.cnf, restart the server to cause the new settings to take effect.
#
# Alternatively, to register the plugins at runtime, use these statements (adjust the .so suffix as necesary):
#
# 		INSTALL PLUGIN authentication_ldap_sasl SONAME 'authentication_ldap_sasl.so';
# 		INSTALL PLUGIN authentication_ldap_simple SONAME 'authentication_ldap_simple.so';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it in the mysql.plugins system table to cause the
# server to load it for each subsequent normal startup.
#
# After installing the plugins at runtime, their system variables become available and you can add settings for them
# to your my.cnf file to configure the plugins for subsequent restarts.
#
# For example:
#
# [mysqld]
# authentication_ldap_sasl_server_host=127.0.0.1
# authentication_ldap_sasl_bind_base_dn="dc=example,dc=com"
# authentication_ldap_simple_server_host=127.0.0.1
# authentication_ldap_simple_bind_base_dn="dc=example,dc=com"
#
# After modifying my.cnf, restart the server to cause the new settings to take effect.
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# For example:
#
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA PLUGINS WHERE PLUGIN_NAME LIKE '%ldap%';
# +---------------------------------------------+
# | PLUGIN_NAME 						| PLUGIN_STATUS|
# +------------------------------+--------------+
# | authentication_ldap_sasl 		| ACTIVE 		| 
# | authentication_ldap_simple 	| ACTIVE 		| 
# +------------------------------+--------------+
#
# If a plugin fails to initialize, check the server error log for diagnostic messages.
#
# ADDITIONAL NOTES FOR SELINUX:
#
#
# 		ON systems running EL6 or EL that have SELinux enabled, changes to the SELinux policy are required to enable
# 		the MySQL LDAP plugins to communicate with the LDAP service:
#
# 			1. Create a file mysqlldap.te with these contents:
#
# 				module mysqlldap 1.0:
#
# 				require {
# 							type ldap_port_t;
# 							type mysqld_t;
# 							class tcp_socket name_connect;
# 				}
#
# 				#================= mysqld_t =====================
#
# 				allow mysqld_t ldap_port_t:tcp_socket name_connect;
#
# 			2. COmpile the security policy module into binary representation
#
# 				checkmodule -M -m mysqlldap.te -o mysqlldap.mod
#
# 			3. Create an SELinux policy module package:
#
# 				semodule_package -m mysqlldap.mod -o mysqlldap.pp
#
# 			4. install teh module package:
#
# 				semodule -i mysqlldap.pp
#
# 			5. When the SELinux policy changes has been made, restart the MySQL server:
#
# 				service mysqld restart
#
# UNINSTALLING LDAP PLUGGABLE AUTHENTICATION
#
# This section describes how to enable MySQL accounts to connect to the MySQL servers using LDAP pluggable authentcation.
#
# It is assumed that hte servers is running with the appropriate server-side plugins enabled, and that the
# appropriate client-side plugins are available on the client host.
#
# This section does not describe LDAP configuration or administration. It is assumed that oyu are fmiliar with such.
#
# There are two server-side LDAP plugins, each of which works with a specific client-side plugin:
#
# 		) The server-side authentication_ldap_simple plugin performs simple LDAP authentication.
#
# 			For connections by accounts that uses this plugin, client programs use the client-side mysql_clear_password plugin,
# 			which sends the PW to the server in clear text.
#
# 			No password hashing or encryption is used, so to secure connections between the MySQL client and server is recommended to prevent PW exposure.
#
# 		) The server-side authentication_ldap_sasl plugin performs SASL-based LDAP authentication.
# 
# 			For connections by accounts that use this plugin, client programs use the client-side authentication_ldap_sasl_client
# 			plugin.
#
# 			The client-side and server-side SASL LDAP plugins use SASL messages for secure transmission of
# 			credentials within the LDAP protocol, to avoid sending hte clear-text password between the MySQL client and server.
#
# Overall reuqirements for LDAP authentication of MySQL Users:
#
# 		) There must be an LDAP directory entry for each user to be authenticated.
#
# 		) THere msut be a MySQL user account that specifies a server-side LDAP authentication plugin and optionally
# 			names the associated LDAP users distinguished name (DN).
#
# 			(To associate an LDAP user DN with a MySQL account, include a BY clause in the CREATE_USER statement htat creates
# 			the Acc)
#
# 			IF an account names no LDAP string, LDAP authentication uses the user name specified by the client to find the LDAP entry.
#
# 		) Client programs connect using the connection method approriate for the server-side authentication plugin the MySQl account uses.
#
# 			For LDAP authentication, connections require the MysQl user name and LDAP password.
#
# 			In adddition, for accounts that use the server-side authentication_ldap_simple plugin, invoke
# 			client programs with the --enable-cleartext-plugin option to eanble the client-side mysql_clear_password plugin.
#
# The instructions here assume the following scenario:
#
# 		) MySQL users betsy and boris authenticate to the LDAP entries for betsy_ldap and boris_ldap, respectively.
#
# 			(It is not necessary that the MySQL and LDAP user names differ, but using differnet names here helps clairy whether
# 				an operation context is MySQL or LDAP)
#
# 		) LDAP entries use the uid attribute to specify user names. (This may vary depending on LDAP server. Some LDAP servers use
# 			the cn attribute for user names rather than uid)
#
# 		) These LDAP entries are available in the directory managed by the LDAP server, to provide distinguished name values that uniquely
# 			identify each other:
#
# 				uid=betsy_ldap, pwd=pwd1, ou=People,dc=example,dc=com
# 				uid=boris_ldap, pwd=pwd2, ou=people,dc=example,dc=com
#
# 		) CREATE_USER statements that create MySQL accounts name an LDAP user in the BY clause, to indicate which 
# 			LDAP entry teh MySQL account authenticates against.
#
# The instructions for setting up an account that uses LDAP authentication dependso n which server-side LDAP plugins is used.
#
# SIMPLE LDAP AUTHENTICATION
#
# To configure a MYSQL account for simple LDAP authentication, the CREATE_USER statement should specify the 
# authentication_ldap_simple plugin, and optionally name the LDAP user distinguished name (DN):
#
# 		CREATE USER user IDENTIFIED WITH authentication_ldap_simple [BY 'LDAP user DN'];
#
# Suppose that a MySQL user betsy has this entry in the LDAP directory:
#
# 		uid=betsy_ldap,pwd=pwd1,ou=People,dc=example,dc=com
#
# Then the statement to create hte MySQL account for besty woudl look like this:
#
# 		CREATE USER 'betsy'@'localhost' IDENTIFIED WITH authentication_ldap_simple BY 'uid=betsy_ldap,ou=People,dc=example,dc=com';
#
# The authentication string specified in teh BY clause does not include the LDAP password.
# That msut be provided by the client user at connection time.
#
# Clients ocnnect to the MySQL server by providing the MySQL user name and LDAP password, and by enabling the client-side
# mysql_clear_password plugin:
#
# 		mysql --user=betsy --password --enable-cleartext-plugin
# 		Enter Password: pwd1 (betsy_ldap LDAP password)
#
# NOTE:
#
# 		The client-side mysql_clear_password plugin with which the server-side authentication_ldap_simple plugin
# 		communicates sends the password to the MySQL server in clear text so it can be passed as is to the LDAP server.
#
# 		This is necessary to use the server-side LDAP library without SASL, but may be a security problem in some configurations.
#
# 		These measures minimize the risk:
#
# 			) To make inadvertent use of the mysql_clear_password plugin less likely, MySQL clients must explicitly enable it.
# 				For example, with the --enable-cleartext-plugin option.
#
# 			) To avoid password exposure with hte mysql_clear_password plugin enabled, MySQL clients should connect to the MySQL
# 				server using a secure connection.
#
# The authentication process is as follows:
#
# 1. The client-side plugin sends besty and pwd1 as the client user name and LDAP pw to the mysql server
#
# 2. The connection attempt matches the 'betsy'@'localhost' account. 
#
# 		The server-side LDAP plugin finds that this account has an authentication string of 'uid=betsy_ldap,ou=People,dc=example,dc=com'
# 		to name the LDAP user DN.
#
# 		The plugin sends this string and hte LDAP password to the LDAP server.
#
# 3. The LDAP server finds the LDAP entry for betsy_ldap and the password matches, so LDAP authentication succeeds.
#
# 4. The LDAP entry has no group attribute, so the server-side plugin returns the client user name(betsy) as the authenticated user.
#
# 		This is the same user name supplied by the client, so no proxying occurs nad the clietn uses the 'betsy'@'localhost' account for privilege checking.
#
# Had the matching LDAP entry contained a group attribute, that attribute value would have been authenticated user name and, if the value differed from Betsy,
# proxying would have occurred.
#
# For examples that use the group attribute, see LDAP Authentication with Proxying.
#
# Had the CREATE_USER statement contained no BY clause to specify the betsy_ldap LDAP distinguished name, authentication
# attempts would use the user name provided by the client (in this case, betsy).
#
# In the absence of an LDAP entry for betsy, authentication would fail.
#
# SASL-Based LDAP Authentication
#
# To configure a MySQL account for SASL LDAP authentication, the CREATE_USER statement should specify the authentication_ldap_sasl plugin,
# and optionally name the LDAP user distinguished name (DN):
#
# 		CREATE USER user IDENTIFIED WITH authentication_ldap_sasl [BY 'LDAP user DN'];
#
# Suppose that a MySQL user boris has this entry in the LDAP directory:
#
# 		uid=boris_ldap,pwd=pwd2,ou=People,dc=example,dc=com
#
# Then the statement to create the MySQL account for boris looks like this:
#
# 		CREATE USER 'boris'@'localhost' IDENTIFIED WITH authentication_ldap_sasl BY 'uid=boris_ldap, ou=People, dc=example, dc=com';
#
# The authentication string specified in the BY clause does not include the LDAP pw.
#
# That msut be provided by the user at connection time.
#
# Clients connect to the Mysql server by providing the MySQL user name and teh LDAP PW:
#
# mysql --user=boris --password
#
# FOr hte server-side authentication_ldap_sasl plugin, clients use the client-side authentication_ldap_sasl_client plugin.
#
# If a client program does not find the client-side plugin, specify a --plugin-dir opton that names hte directory where
# the plugin library file is installed.
#
# The authentication process for boris is similar to htat previously described for betsy with simple LDAP authentication, except that
# the Client-side and server-side SASL LDAP plugins use SASL messages for secure transmission of credentials within the LDAP
# protocol, to avoid sending the clear-text PW between the MySQL client and server.
#
# LDAP Authentication User DN Suffixes
#
# LDAP authentication plugins permit the authentication string that provides user DN informatio nto begin with a + char.
#
# in the abseence of this char, the authentication string value is treated as is without modification.
#
# If the authentication string begins with +, the plugin constructs the full user DN value from the account user name as the
# cn attribute value, together with the authentication string (with the + removed).
#
# The authentication string is stored as given in the mysql.user system table, with the full user DN constructed on the fly before
# authentication.
#
# this account authentication string does not have + at the beginning, so it is taken as teh full user DN:
#
# 		CREATE USER 'admin' IDENTIFIED WITH authentication_ldap_simple BY "cn=admin,ou=People,dc=example,dc=com";
#
# This account authentication string does have a + at hte start, so it is taken as just part of the full user DN:
#
# 		CREATE USER 'accounting' IDENTIFIED WITH authentication_ldap_simple BY "+ou=People,dc=example,dc=com";
#
# IN this case, the full user DN is constructed using accounting as the cn attribute together with the authetnication string to yield:
#
# "cn=accounting,ou=People,dc=example,dc=com"
#
# For acount names that include a host name part, the user name is tkaen from the user name sent by the client.
#
# (effectively, this is the user name part of the account name, ignoring the host name part)
#
# LDAP Authentication with Proxying
#
# The authentication scheme described here uses proxying based on LDAP group attribute values to map
# connecting MySQL users who authenticate using LDAP onto other MysQL accounts that define different sets of privileges.
#
# USers do not connect directly through the accounts that define the privileges.
#
# Instead, they connect through a default proxy user authenticated with LDAP, such that all external logins are mapped to the
# MySQL accounts taht hold the privileges.
#
# any user who connects is mapped to one of those MySQL accounts, the privileges for which determines the database operatons
# permitted to the external user.
#
# The instructions here assume the following scenario:
#
# 		) LDAP entries use the uid and cn attributes to specify user name and group values, respectively.
#
# 			To use different user and group attribute names, set the appropriate system variables to configure the plugin:
#
# 				) For authentication_ldap_simple: Set authentication_ldap_simple_user_search_attr and authentication_ldap_simple_group_search_attr
#
# 				) For authentication_ldap_sasl: Set authentication_ldap_sasl_user_search_attr and authentication_ldap_sasl_group_search_attr
#
# 		) These LDAP entries are available in the directory managed by the LDAP server, to provide distinguished name values that uniquely identify each user:
#
# 			uid=basha,pwd=pwd3,ou=People,dc=example,dc=com,cn=accounting
# 			ui=basil,pwd=pwd4,ou=People,dc=example,dc=com,cn=front_office
#
# 			The group attribute values will become the authenticated user names, so they name the proxied accounts, accounting and front_office.
#
# 		) The examples assume use of SASL LDAP authentication. Make the appropriate adjustments for simple LDAP authentication.
#
# Create hte default proxy MySQL account:
#
# 		CREATE USER ''@'%' IDENTIFIED WITH authentication_ldap_sasl;
#
# The proxy account definiton has no BY 'auth_string' clause to name an LDAP user DN, so that when the client connects, the client user name
# is used as the LDAP User name to search for.
#
# The matching LDAP entry is expected to include a group attribute naming the proxied MySQL account that defines the privileges
# the client should have.
#
# Note:
#
# 		IF your MySQL installation has anonymous users, they might conflict with the default proxy user.
# 		
#
# Create hte proxied accounts and grant their privileges:
#
# 		CREATE USER 'accounting'@'localhost' ACCOUNT LOCK;
# 		CREATE USER 'front_office'@'localhost' ACCOUNT LOCK;
#
# 		GRANT ALL PRIVILEGES 
# 			ON accountingdb.*
# 			TO 'accounting'@'localhost';
# 		GRANT ALL PRIVILEGES
# 			ON frontdb.*
# 			TO 'front_office'@'localhost';
#
# Grant hte PROXY privilege to the proxy account for the proxied accounts:
#
# 		GRANT PROXY
# 			ON 'accounting'@'localhost'
# 			TO ''@'%';
# 		GRANT PROXY
# 			ON 'front_office'@'localhost'
# 			TO ''@'%';
#
# Connect to the MySQL 	server as basha using the mysql command-line client:
#
# 		mysql --user=basha --password
#
# The server authenticates the connection using the ''@'%' account, for client user Basha.
# The matching LDAP entry has group attribute cn=accounting, so accounting becomes the authenticated user.
#
# THis differs from the client user name basha, with the result that basha is treated as a proxy for accounting and 
# basha assumes the privileges of the accounting account.
#
# The followuing query should return output as shown:
#
# SELECT USER(), CURRENT_USER(), @@proxy_user;
# +------------------------------------------------------+
# | USER() 				| CURRENT_USER()      | @@proxy_user|
# +------------------------------------------------------+
# | basha@localhost 	| accounting@localhost| ''@'%' 		|
# +------------------------------------------------------+
#
# This demonstrates that basha uses the privileges granted to the accounting MYSQL account, and that proxying occurred
# through the default proxy user account.
#
# Now connect as basil instead:
#
# mysql --user=basil --password
# Enter password: pwd4 (basil LDAP password)
#
#
# The authentication process for basil is similar to that previously described for basha.
#
# IN this case, teh amtchign LDAP entry has group attribute cn=front_office.
#
# So, front_office becomes the authenticated user. This differs from the lcient user basil, with the result
# that basil is treated as a proxy for front_office and basil assumes the privileges of the front_office account.
#
# The following query should return output as shown:
#
# SELECT USER(), CURRENT_USER(), @@proxy_user;
# +------------------------------------------------------------------+
# | USER() 					| CURRENT_USER() 					| @@proxy_user |
# +------------------------------------------------------------------+
# | basil@localhost 		| front_office@localhost 		| ''@'%' 		|
# +------------------------------------------------------------------+
#
#
# This demosntrates that basil uses the privileges granted to the front_office MySQL account.
# (i.e proxying through the default proxy user account)
#
# NO-LOGIN PLUGGABLE AUTHENTICATION
#
# The mysql_no_login sever-side authentication plugin prevents all client connections to any account that uses it.
#
# USe cases for such a plugin includes proxied accounts that should never permit direct login but are accessed
# only through proxy accounts and accounts that must be able to execute stored programs and views with elevated
# privileges without exposing those privileges to ordinary users.
#
# THe following table shows the plugin and library file names. 
# The file name suffix might differ on respective system.
#
# The file must be located in the dir named by the plugin_dir system variable.
#
# PLUGIN NAD LIBRARY NAMES FOR NO-LOGIN AUTHENTICATION
#
# Server-side plugin 		mysql_no_login
# Client-side plugin 		None
# library file 				mysql_no_login.so
#
# The following sections provide installation and usage information specific to no-login pluggable authentication:
#
# ) installing no-login pluggalbe authentication
#
# ) uninstalling no-login pluggable authentication
#
# ) Using no-login pluggable authentication
#
# INSTALLING NO-LOGIN PLUGGABLE AUTHENTICATION
#
# TO be usable by the server, the plugin library file must be located in the MySQL plugin directory (the direcotry named by teh
# plugin_dir system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is mysql_no_login. The file name suffix differs per platform (.so for UNIX based, .dll for Windows)
#
# To load the plugin at server startup, use the --plugin-load-add option to name the library file that contains it.#
# With this plugin-loading method, the option must be given each time the server starts.
#
# For example, we can circumvent that and force it by registration to option files:
#
# [mysqld]
# plugin-load-add=mysql_no_login.so (or .dll for Windows)
# 
# After modifying my.cnf, restart the server to cause hte new settings to take effect.
#
# Alternatively, to register the plugin at runtime, use this statement (adjust hte . suffix as needed9:
#
# INSTALL PLUGIN mysql_no_login SONAME 'mysql_no_login.so';
#
# INSTALL_PLUGIN loads the plugin immeadiately, and also registers it in the mysql.plugins system table to cause teh server to load
# it for each subsequent normal startup.
#
# To verify the installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement:
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS,
# 			FROM INFORMATION_SCHEMA.PLUGINS
# 			WHERE PLUGIN_NAME LIKE '%login%';
# +-------------------------------------------+
# | PLUGIN_NAME 		| PLUGIN_STATUS 			 |
# +-------------------------------------------+
# | mysql_no_login 	| ACTIVE 					 |
# +-------------------------------------------+
#
# If the plugin fails to initialize - check the server error log for diagnostic messages.
#
# UNINSTALLING NO-LOGIN PLUGGABLE AUTHENTICATION
#
# The method used to uninstall the no-login authentication plugin depends on how you install it:
#
# 		) If oyu installed the plugin at server startup using a --plugin-load-add option, restart the server without the option.
#
# 		) If you installed the plugin at runtime using INSTALL_PLUGIN, it remains INSTALLED across server Restarts.
# 			To uninstall it, use UNINSTALL_PLUGIN:
#
# 			UNINSTALL PLUGIN mysql_no_login;
#
# USING NO-LOGIN PLUGGABLE AUTHENTICATION
#
# This section describes how to use the no-login authentication plugin to prevent connections from MySQL client programs to the server.
#
# It is assumed that the server is running with the server-side plugin enabled.
#
# To refer to the no-login authentication plugin in the IDENTIFIED WITH clause of a CREATE_USER statement, use the name mysql_no_login.
#
# An account that authenticates using mysql_no_login may be used as the DEFINER for stored program and view objects.
#
# IF such an object definition also include SQL SECURITY DEFINER, it executes with that accounts privileges.
#
# DBAs cna use this behavior to provide access to confidential or sensitive data that is exposed only
# through well-controlled interfaces.
#
# The following example provides a simple illustration of these principles. It defines an account that does not permit
# client connections, and associates with it a view that exposes only certain columns of the mysql.user system table:
#
# CREATE DATABASE nologindb;
# CREATE USER 'nologin'@'localhost'
# 		IDENTIFIED WITH mysql_no_login;
#
# GRANT ALL ON nologindb.*
# 		TO 'nologin'@'localhost';
#
# GRANT SELECT ON mysql.user
#		TO 'nologin'@'localhost';
#
# CREATE DEFINER = 'nologin'@'localhost'
# 		SQL SECURITY DEFINER
# 		VIEW nologindb.myview
# 		AS SELECT User, Host FROM mysql.user;
#
# To provide protected access to the view to an ordinary user, do this:
#
# GRANT SELECT ON nologindb.myview TO 'ordinaryuser'@'localhost';
#
# Now the ordinary user can use the view to access the limited information it presents:
#
# SELECT * FROM nologindb.myview;
#
# Attempts by the user to access columns other than those exposed by the view result in an error,
# as do all attempts to select from the view by users not granted access to it.
#
# NOTE:
#
# 		Because the nologin account cannot be used directly, the operations required to set up objects
# 		must be performed by root or similar accounts with hte privileges required to create the obejcts and set DEFINER values.
#
# An account that authenticates using mysql_no_login may be used as a proxied base user for proxy accounts:
#
# -- Create the proxied account
# CREATE USER 'proxy_base'@'localhost'
# 		IDENTIFIED WITH mysql_no_login;
#
# -- Grant privileges to proxied account
# GRANT ... TO 'proxy_base'@'localhost';
#
# -- Permit real_user to be proxy for proxied account
# GRANT PROXY ON 'proxy_base'@'localhost'
# 		TO 'real_user'@'localhost';
#
# THis enables clients to access MySQL through the Proxy account (real_user) but not to bypass the proxy mechanism
# by connecting directly as the proxied user (proxy_base).
#
# SOCKET PEER-CREDENTIAL PLUGGABLE AUTHENTICATION
#
# The server-side auth_socket authentication plugin authenticates clients that connect from the local host through
# the Unix socket file.
#
# The plugin uses the SO_PEERCRED socket option to obtain information about the user running the client program.
#
# Thus, the plugin can be used only on systems that support the SO_PEERCRED option, such as Linux.
#
# The source code for this plugin can be examined as simple example of demonstrating how to write a loadable authentication plugin.
#
# The following table shows the plugin and library file names. The files msut be located in the directory named by the
# plugin_dir system variable.
#
# PLugin or File 					PLugin or File Name
# Server-side PLugin 			auth_socket
#
# Client-side plugin 			None
#
# Library file  					auth_socket.so
#
# INSTALLING SOCKET PLUGGABLE AUTHENTICATION
#
# This section describes hwo to install the socket authentication plugin.
# 
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory
# (the direcotry named by the plugin_dir system variable).
#
# if necessary, configure the plugin directory location by setting hte value of plugin_dir at server startup.
#
# To load the plugin at server startup, use the --plugin-load-add option to name the library file that contains it.
# With this plugin-loading method, the option must be given each time the server starts.
#
# For example, put these lines in the server my.cnf file:
#
# [mysqld]
# plugin-load-add=auth_socket.so
#
# After modifying the file, restart the server to cause the new settings to take effect.
#
# Alternatively, to register the plugin at runtime, use this statement:
#
# 		INSTALL PLUGIN auth_socket SONAME 'auth_socket.so';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it n the mysql.plugins system table to cause the
# server to load it for each subsequent normal startup.
#
# TO verify the plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# For example:
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS
# FROM INFORMATION_SCHEMA.PLUGINS
# WHERE PLUGIN_NAME LIKE '%socket%';
# +--------------------------------------+
# | PLUGIN_NAME 		| PLUGIN_STATUS 	  |
# +--------------------------------------+
# | auth_socket 		| ACTIVE 			  |
# +--------------------------------------+
#
# If the plugin fails to initialize, check the server error log for diagnostics.
#
# UNINSTALLING SOCKET PLUGGABLE AUTHENTICATION
#
# The method used to uninstall the socket authentication plugin depends on how you installed it:
#
# 		) If you installed the plugin at server startup using a --plugin-load-add option ,restart the serer without the option.
#
# 		) If you isntalled the plugin at runtime using INSTALL_PLUGIN, it remains installed across server restarts.
#
# 			To uninstall it, use UNINSTALL_PLUGIN:
#
# 			UNINSTALL PLUGIN auth_socket;
#
# USING SOCKET PLUGGABLE AUTHENTICATION
#
# THe socket plugin checks whether the socket user name (the OS user name) matches the MySQL user name specified
# by the client program to the server.
#
# If the names do not match, the plugin checks whether the socket user name matches the name specified in the 
# authentication_string column of the mysql.user system table row.
#
# IF a match is found, the plugin permits teh connection.
#
# The authentication_string value can be specified using an IDENTIFIED ... AS clause with CREATE_USER through the 
# socket file:
#
# CREATE USER 'valerie'@'localhost' IDENTIFIED WITH auth_socket;
#
# IF a user on the local host with a login name of stefanie invokes MySQL with the option --user=valerie to connect through
# the socket file, the server uses auth_socket to authenticate the client.
#
# The plugin determines that hte --user option (valerie) differs form the client user's name (Stephanie) and refuses the connection.
#
# If a user named valerie tries the same thing,  the plugin finds taht the user name and the MySQL user name are bot hthe same and permits it.
#
# HOwever, the plugin refuses the connection even for valerie if the connection is made using a different protocol,
# such as TCP/IP.
#
# To permit both the valerie and stephanie system users to access MySQL through socket file connections that use the account,
# this cna be done in two ways:
#
# ) Name both users at account-creation time, one following CREATE_USER and the otehr in the authentication string:
#
# 			CREATE USER 'valerie'@'localhost' IDENTIFIED WITH auth_socket AS 'stephanie';
#
# ) If you have already used CREATE_USER To create the account for a single user, use ALTER_USER to add the second user:
#
# 			CREATE USER 'valerie'@'localhost' IDENTIFIED WITH auth_socket;
# 			ALTER USER 'valerie'@'localhost' IDENTIFIED WITH auth_socket AS 'stephanie';
#
# To access the account, both valerie and stephanie specify --user=valerie at connect time.
#
# TEST PLUGGABLE AUTHENTICATION
#
# MySQL includes a test plugin that checks account credentials and logs success or failure to the server error log.
#
# This is a loadable plugin (not built in) and must be installed prior to use.
#
# The test plugin source code is separate from the server source, unlike the built-in native plugin, so it can be examined
# as a relativily simple example demonstrating how to write a loadable authentication plugin.
#
# NOTE:
#
# 		This plugin is intended for testing and development purposes, and is not for use in production environments or on servers that
# 		are exposed to public networks.
#
# The following table shows the plugin and library file names. The file name suffix might differ on your system.
# The file must be located in the directory named by the plugin_dir system variable.
#
# PLUGIN AND LIBRARY NAMES FOR TEST AUTHENTICATION
#
# Plugin or File 				Plugin or File Name
#
# Server-side plugin 		test_plugin_server
#
# Client-side plugin 		auth_test_plugin
#
# library file 				auth_test_plugin.so
#
# INSTALLING TEST PLUGGABLE AUTHENTICATION
#
# This section describes how to install the test authentication plugin.
# For gerneral info about installing plugins, see earlier.
#
# TO be usable by the server, the plugin library file must be located in the MySQL plugin directory 
# (the directory named by the plugin_dir system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# To load the plugin at server startup, use the --plugin-load-add option to name the library that contains it.
# With this plugin-loading method, the option must be given each time the server starts.
#
# For example, put these lines in the server my.cnf file (adjust the .so suffix for your platform as necessary):
#
# 	[mysqld]
# 	plugin-load-add=auth_test_plugin.so
#
# After modifying my.cnf, restart the server to cause the new settings to take effect.
#
# Alternatively, to register the plugin at runtime, use this statement (adjust the .so suffix as necessary):
#
# INSTALL PLUGIN test_plugin_server SONAME 'auth_test_plugin.so';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it in the mysql.plugins system table to cause the
# server to load it for each subsequent normal startup.
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.plugin table or use the SHOW_PLUGIN statement.
#
# For example:
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS
# FROM INFORMATION_SCHEMA.PLUGINS
# WHERE PLUGIN_NAME LIKE '%test_plugin%';
#
# +-------------------------------------------+
# | PLUGIN_NAME 				| PLUGIN_STATUS 	 |
# +-------------------------------------------+
# | test_plugin_server 		| ACTIVE 			 |
# +-------------------------------------------+
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# UNINSTALLING TEST PLUGGABLE AUTHENTICATION
#
# The method used to uninstall the test authentication plugin depends on how you installed it:
#
# 		) If you installed the plugin at server startup using a --plugin-load-add option, restart the server without the option.
#
# 		) If you installed the plugin at runtime using INSTALL_PLUGIN it remains installed across server restarts.
# 			To uninstall it, use UNINSTALL_PLUGIN:
#
# 			UNINSTALL PLUGIN test_plugin_server;
#
# USING TEST PLUGGABLE AUTHENTICATION
#
# To use  the test authentication plugin, create an account and name that plugin in the IDENTIFIED WITH clause:
#
# 	CREATE USER 'testuser'@'localhost'
# 	IDENTIFIED WITH test_plugin_server
# 	BY 'testpassword';
#
# Then provide the --user and --password optons for that account when you connect to the server.
# For example:
#
# mysql --user=testuser --password
# Enter password: testpassword
#
# The plugin fetches the password as received from the client and compares it with the value
# stored in the authentication_string column of the account row in the mysql.user system table
#
# If the two values match, the plugin returns the authentication_string value as the new effective user ID.
#
# You can look in the server error log for a message indicating whether authentication succeeded
# (notice that the password is reported as the "user"):
#
# [Note] Plugin test_plugin_server reported:
# 'successfully authenticated user testpassword'
#
# PLUGGABLE AUTHENTICATION SYSTEM VARIABLES
#
# These variables are unavailable unless the appropriate server-side plugin is installed:
#
# 		) authentication_ldap_sasl for system variables with names of the form authentication_ldap_sasl_xxx
#
# 		) authentication_ldap_simple for system variables with names of the form authentication_ldap_simple_xxx
#
# AUTHENTICATION PLUGIN SYSTEM VARIABLE SUMMARY
#
# 		Name 														Cmd-line  Option File 		System Var 	Status Var 		Var Scope 		Dynamic
#
# authentication_ldap_sasl_auth_method_name 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_bind_base_dn 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_bind_root_dn 				Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_sasl_bind_root_pwd 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_ca_path  					Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_group_search_attr 		Yes 			Yes 				Yes 								Global 			Yes
# 
# authentication_ldap_sasl_init_pool_size 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_log_status 					Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_max_pool_size 				Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_sasl_server_host 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_server_port 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_tls 							Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_sasl_user_search_attr 			Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_simple_auth_method_name 		Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_bind_base_dn 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_bind_root_dn 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_bind_root_pwd 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_ca_path 					Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_simple_group_search_attr 		Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_init_pool_size 			Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_log_status 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_max_pool_size 			Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_simple_server_host 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_server_port 				Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_tls 						Yes 			Yes 				Yes 								Global 			Yes
# authentication_ldap_simple_user_search_attr 		Yes 			Yes 				Yes 								Global 			Yes
#
# authentication_ldap_sasl_auth_method_name
#
# Property 											Value
#
# Cmd line format 								--authentication-ldap-sasl-auth-method-name=value
# Introduced 										8.0.11
# System Variable 								authentication_ldap_sasl_auth_method_name
# Scope 												Global
# Dynamic 											Yes
# SET_VAR Hint applies 							No
# Type 												String
# Default: 											SCRAM-SHA-1
#
# For SASL LDAP authentication, the authentication method name.
# Communication between the authentication plugin and the LDAP server occurs according to this authentication method.
# These authentication method values are permitted:
#
# 		) SCRAM-SHA-1: Authentication uses a SASL challenge-response mechanism to ensure password security.
#
# 							The client-side authentication_ldap_sasl_client plugin communicates with the SASL server, using the
# 							password to create a challenge and obtain a SASL request buffer, then passes this buffer to the server-side
# 							authentication_ldap_sasl plugin.
#
# 							The client-side and server-side SASL LDAP plugins use SASL messages for secure transmission
# 							of credentials within the LDAP protocol, to avoid sending the clear-text between the MySQL client and server.
#
# authentication_ldap_sasl_bind_base_dn
#
# Property 											Value
#
# Cmd line format 								--authentication-ldap-sasl-bind-base-dn=value
# Introduced 										8.0.11
# System variable 								authentication_ldap_sasl_bind_base_dn
# Scope 												Global
# Dynamic 											Yes
# SET_VAR Hint applies 							No
# Type 												String
# Default value 									NULL
#
# For SASL LDAP authentication, the base distinguished name (DN).
# This variable can be used to limit the scope of searches by anchoring them at a certain location
# (the "base") within the search tree.
#
# Suppose that members of one set of LDAP user entries each have this form:
#
# 		uid=user_name,pwd=user_password,ou=People,dc=example,dc=com
#
# And that members of another set of LDAP user entries each have this form:
#
# 		uid=user_name,pwd=user_password,ou=Admin,dc=example,dc=com
#
# Then searches work like this for different base DN values:
#
# 		) If the base DN is ou=People,dc=example,dc=com: Searches find user entries only in the first set.
#
# 		) If the base DN is ou=Admin,dc=example,dc=com: Searches find user entries only in the second set.
#
# 		) If the base DN is ou=dc=example,dc=com: Searches find user entires in the first or second set.
#
# In general, more specific base DN values result in faster searches because they limit the search scope more.
#
# authentication_ldap_sasl_bind_root_dn
#
# Property 											Value
#
# Cmd line format 								--authentication-ldap-sasl-bind-root-dn=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_bind_root_dn
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default value: 									NULL
#
# for SASL LDAP authentication, the root distinguished name (DN). This variable is used in conjunction with 
# authentication_ldap_sasl_bind_root_pwd as the credentials for authenticating to the LDAP server for the purpose of
# performing searches.
#
# Authentication uses either one or two LDAP bind operations, depending on whether the MYSQL account names an LDAP user DN:
#
# 		) If the account does not name a user DN: authentication_ldap_sasl performs an initial LDAP binding using authentication_ldap_sasl_bind_root_dn
# 			and authentication_ldap_sasl_bind_root_pwd.
#
# 			(These are both empty by default, so if they are not set, the LDAP server must permit anonymous connections)
#
# 			The resulting bind LDAP handle is used to search for the user DN, based on the client user name. 
#
# 			authentication_ldap_sasl performs a second bind using the user DN and client-supplied password.
#
# 		) If the account does name a user DN: the first bind operation is unnecessary in this case.
# 			authentication_ldap_sasl performs a single bind using the user DN and client-supplied password.
#
# 			This is faster than if the MySQL account does not specify an LDAP user DN.
#
# authentication_ldap_sasl_bind_root_pwd
#
# Property 											Value
# 
# Cmd line format 								--authentication-ldap-sasl-bind-root-pwd=value
# Introduced: 										8.0.11
# System variable 								authentication_ldap_sasl_bind_root_pwd
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default value: 									NULL
#
# For SASL LDAP authentication, the password for the root distinguished name.
# This variable is used in conjunction with authentication_ldap_sasl_bind_root_dn.
#
# See above.
#
# authentication_ldap_sasl_ca_path
#
# Property 											Value
#
# Cmd line format 								--authentication-ldap-sasl-ca-path=value
# Introduced: 										8.0.11
# System variable 								authentication_ldap_sasl_ca_path
# Scope 												Global
# Dynamic 											Yes
# SET_VAR Hint applies 							No
# Type: 												String
# Default value: 									NULL
#
# For SASL LDAP authentication, the absolute path of the certificate authority file.
#
# Specify this file if it is desired that the authentication plugin perform verification
# of the LDAP server certificate.
#
# NOTE:
#
# 		In addition to setting the authentication_ldap_sasl_ca_path variable to the file name,
# 		you must add the appropriate certificate authority certificates to the file and enable the 
# 		authentication_ldap_sasl_tls system variable.
#
# authentication_ldap_sasl_group_search_attr
#
# Property 											Value
# Cmd line format 								--authentication-ldap-sasl-group-search-attr=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_sasl_group_search_attr
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default Value: 									cn
#
# For SASL LDAP authentication, the name of the attribute that specifies group names in LDAP directory entries.
#
# If authentication_ldap_sasl_group_search_attr has its default value of cn, searches return the cn value as the
# group name.
#
# For example, if an LDAP entry with a uid value of user1 has a cn attribute of mygroup, searches for user1 return
# mygroup as the group name.
#
# This variable should be the empty string if you want no group or proxy authentication.
#
# If the group search attribute is isMemberOf, LDAP authentication directly retrieves the user attribute isMemberOf
# value and assigns it as group information.
#
# If the group search attribute is not isMemberOf, LDAP authentication searches for all groups where the user is a member.
# (The latter is the default behavior)
#
# This behavior is based on how LDAP group information can be stored two ways: 
#
# 1) A group entry can have an attribute named memberUid or member with a value that is a user name;
#
# 2) A user entry can have an attribute named isMemberOf with values that are group names.
#
# authentication_ldap_sasl_group_search_filter
#
# Property 											Value
# Cmd line format 								--authentication-ldap-sasl-group-search-filter=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_sasl_group_search_filter
# Scope: 											Global
# Dynamic:  										Yes
# SET_VAR Hint Applies 							No
# Type 												String
# Default Value 									(|(&(objectClass=posixGroup) (memberUid=%s))(&(objectClass=group)(member=%s)))
#
# For SASL LDAP authentication, the custom group search filter.
#
# The search filter value can contain {UA} and {UD} notation to represent the user name and the full user DN.
#
# For example, {UA} is replaced with a user name such as "admin", whereas {UD} is replaced with a use full DN
# such as "uid=admin,ou=People,dc=example,dc=com".
#
# The following value is the default, which supports both OpenLDAP and Active Directory:
#
# 		(|(&(objectClass=posixGroup)(memberUid={UA}))(&(objectClass=group)(member={UD})))
#
# In some cases for the user scenario, memberOf is a simple user attribute that holds no group information.
#
# For additional flexibility, an optional {GA} prefix can be used with the group search attribute.
# Any group attribute with a {GA} prefix is treated as a user attribute having group names.
#
# For example, with a value of {GA}MemberOf, if the group value is the DN, the first attribute value
# from the group DN is returned as the group name.
#
# authentication_ldap_sasl_init_pool_size
#
# Property 											Value
#
# Command-line format 							--authentication-ldap-sasl-init-pool-size=value
# Introduced 										8.0.11
# System Variable 								authentication_ldap_sasl_init_pool_size
# Scope 												Global
# Dynamic 											Yes
# SET_VAR Hint applies 							No
# Type: 												Integer
# Default value: 									10
# Minimum value: 									0
# Maximum value: 									32767
#
# For SASL LDAP authentication, the initial size of the pool of connections to the LDAP server.
#
# Choose the value for this variable based on the average number of concurrent authentication
# requests to the LDAP server.
#
# The plugin uses authentication_ldap_sasl_init_pool_size and authentication_ldap_sasl_max_pool_size together
# for connection-pool management:
#
# 		) When the authentication plugin initializes, it creates authentication_ldap_sasl_init_pool_size connections, unless
# 			authentication_ldap_sasl_max_pool_size=0 to disable pooling.
#
# 		) If the plugin receives an authentication request where there are no free connectiosn in the current connection pool,
# 			the plugin can create a new connection, up to the maximum connection pool size given by authentication_ldap_sasl_max_pool_size.
#
# 		) If the plugin receives a request when the pool size is already at its maximum and there are no free connections, authentication fails.
#
# 		) When the plugin unloads, it closes all pooled connections.
#
# Changes to plugin system variable settings may have no effect on connections already in the pool.
# For example, modifying the LDAP server host, port or TLS settings does not affect existing connections.
#
# However, if the original variable values were invalid and the connection pool could not be initialized,
# the plugin attempts  to reinitialize the pool for the next LDAP request.
#
# In this case, the new system variable values are used for the reinitialization attempt.
#
# If authentication_ldap_sasl_max_pool_size=0 to disable pooling, each LDAP connection opened by the plugin
# uses the value the system variables have at that time.
#
# authentication_ldap_sasl_log_status
#
# Property 											Value
# cmd line format: 			 					--authentication-ldap-sasl-log-status=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_log_status
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Integer
# Default: 											1
# Min: 												1
# Max: 												5
#
# For SASL LDAP authentication, the logging level. 
#
# Log levels for authentication_ldap_sasl_log_status
#
# Option value 			Type of messages logged
#
# 1 							No messages
# 2 							Error messages
# 3 							Error and warning messages
# 4 							Error, warning and information messages
# 5 							All messages
#
# On the client side, messages can be logged to the standard output by setting the AUTHENTICATION_LDAP_CLIENT_LOG environment variable.
#
# The permitted and default values are the same as for authentication_ldap_sasl_log_status.
#
# The AUTHENTICATION_LDAP_CLIENT_LOG environment variable applies only to SASL LDAP authentication.
#
# It has no effect for simple LDAP authentication because the client plugin in that case is mysql_clear_password,
# which knows nothing about LDAP operations.
#
# authentication_ldap_sasl_max_pool_size
#
# Property 											Value
# Cmd line format: 								--authentication-ldap-sasl-max-pool-size=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_max_pool_size
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Integer
# Default Value: 									1000
# Minimum value: 									0
# Maximum value: 									32767
#
# For SASL LDAP authentication, the maximum size of the pool of connections to the LDAP server.
# To disable connection pooling, set this variable to 0.
#
# This variable is used in conjunction with authentication_ldap_sasl_init_pool_size.
# 
# authentication_ldap_sasl_server_host
#
# Property 											Value
# Command-line format: 							--authentication-ldap-sasl-server-host=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_server_host
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
#
# For SASL LDAP authentication, the LDAP server host.
# The permitted values for this variable depend on the authentication method:
#
# 		) For authentication_ldap_sasl_auth_method_name=SCRAM-SHA-1: The LDAP server host can be a host name or IP address.
#
# authentication_ldap_sasl_server_port
#
# property 											Value
# Command-line format: 							--authentication-ldap-sasl-server-port=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_server_port
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Integer
# Default value: 									389
# Min value: 										1
# Max value: 										32376
#
# For SASL LDAP authentication, the LDAP server TCP/IP port number.
#
# authentication_ldap_sasl_tls
#
# Property 											Value
# Command-line format: 							--authentication-ldap-sasl-tls=value
# Introduced: 										8.0.11
# System variable: 								authentication_ldap_sasl_tls
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Boolean
# Default value: 									OFF
#
# For SASL LDAP authentication, whether connections by the plugin to the LDAP server are secure.
# If this variable is enabled, the plugin uses TLS to connect securely to the LDAP server.
#
# If you enable this variable, you may also wish to set the authentication_ldap_sasl_ca_path variable.
#
# MySQL LDAP plugins support the StartTLS method, which initializes TLS on top of a plain LDAP connection.
# The ldaps method is deprecated and MYSQL does not support it.
#
# authentication_ldap_sasl_user_search_attr
#
# Property 											Value
# Command-line format: 							--authentication-ldap-sasl-user-search-attr=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_sasl_user_search_attr
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default Value: 									uid
#
# For SASL LDAP authentication, the name of the attribute that specifies user names in LDAP directory entries.
# If a user distinguished name is not provided, the authentication plugin searches for the name using this attribute.
#
# For example, if the authentication_ldap_sasl_user_search_attr value is uid, a search for the user name user1 finds entries
# with a uid value of user1.
#
# authentication_ldap_simple_auth_method_name
#
# Property 											Value
# Command-Line Format 							--authentication-ldap-simple-auth-method-name=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_simple_auth_method_name
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint Applies 							No
# Type: 												String
# Default Value: 									SIMPLE
#
# For simple LDAP authentication, the authentication method name.
#
# Communication between the authentication plugin and the LDAP server occurs according to this
# authentication method.
#
# These authentication method values are permitted:
#
# 		) SIMPLE: This authentication method uses either one or two LDAP bind operations, depending on whether the
# 						MySQL account names an LDAP user distinguished name.
#
# 						See the description of authentication_ldap_simple_bind_root_dn
#
# 		) AD-FOREST: authentication_ldap_simple searches all the domains in the Active Directory forest, performing an LDAP bind to each
# 						Active Directory domain until the user is found in some domain.
# 
# NOTE:
#
# 		FOr simple LDAP authentication, it is recommended to also set TLS parameters to require that communication with the LDAP server
# 		take place over secure connections.
#
# authentication_ldap_simple_bind_base_dn
#
# Property 											Value 
# Command-line format: 							--authentication-ldap-simple-bind-base-dn=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_simple_bind_base_dn
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint Applies: 						No
# Type: 												String
# Default Value: 									NULL
#
# For simple LDAP authentication, the base distinguished name (DN).
#
# This variable can be used to limit the scope of searches by anchoring them
# at a certain location (the "base") within the search tree.
#
# Suppose that members of one set of LDAP user entries each have this form:
#
# 	uid=user_name,pwd=user_password,ou=People,dc=example,dc=com
# 
# And that members of another set of LDAP user entries each have this form:
#
# 	uid=user_name,pwd=user_password,ou=Admin,dc=example,dc=com
#
# Then searches work like this for different base DN values:
#
# 		) If the base DN is ou=People,dc=example,dc=com. Searches find user entries only in the first set.
#
# 		) If the base DN is ou=Admin,dc=example,dc=com. Searches find user entries only in the second set.
#
# 		) If the base DN is ou=dc=example,dc=com. Searches find user entries in the first or second set.
#
# In general, more specific base DN values result in faster searches because they limit the search scope more.
#
# authentication_ldap_simple_bind_root_dn
#
# Property 											Value
# Command-Line Format 							--authentication-ldap-simple-bind-root-dn=value
# Introduced 										8.0.11
# System Variable 								authentication_ldap_simple_bind_root_dn
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies 							No
# Type: 												String
# Default Value: 									NULL
#
# For simple LDAP authentication, the root distinguished name (DN).
#
# This variable is used in conjunction with authentication_ldap_simple_bind_root_pwd as the credentials
# for authenticating to the LDAP server for the purpose of performing searches.
#
# Authentication uses either one or two LDAP bind operations, depending on whether the MySQL account
# account names an LDAP user DN:
#
# 			) If the account does not name a user DN: authentication_ldap_simple performs an initial LDAP binding using
# 				authentication_ldap_simple_bind_root_dn and authentication_ldap_simple_bind_root_pwd.
#
# 				(These are both empty by default, so if they are not set, the LDAP server must permit anonymous connections)
#
# 				The resulting bind LDAP handle is used to search for the user DN, based on the client user name.
# 				authentication_ldap_simple performs a second bind using the user DN and client-supplied password.
#
# 			) If the account does name a user DN: the first bind operation is unnecessary in this case.
#
# 				authentication_ldap_simple performs a single bind using the user DN and client-supplied password.
#
# 				THis is faster than if the MYSQL account does not specify an LDAP user DN.
#
# authentication_ldap_simple_bind_root_pwd
#
# Property 											Value
# 
# Command-line Format 							--authentication-ldap-simple-bind-root-pwd=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_simple_bind_root_pwd
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default value: 									NULL
#
# For simple LDAP authentication, the password for the root distinguished name.
# This variable is used in conjunction with authentication_ldap_simple_bind_root_dn.
#
# authentication_ldap_simple_ca_path
#
# Property 											value
# Command-line format 							--authentication-ldap-simple-ca-path=value
# Introduced 										8.0.11
# System Variable: 								authentication_ldap_simple_ca_path
# Scope 												Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default value: 									NULL
#
# For simple LDAP authentication, the absolute path of the certificate authority file.
#
# Specify this file if it is desired that the authentication plugin perform verification of the
# LDAP server certificate.
#
# NOTE:
#
# 		In addition to setting the authentication_ldap_simple_ca_path variable to the file name, you must add
# 		the appropriate certificate authority certificates to the file and enable the authentication_ldap_simple_tls system variable.
#
# authentication_ldap_simple_group_search_attr
#
# Property 											Value
# Command-line format 							--authentication-ldap-simple-group-search-attr=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_simple_group_search_attr
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
# Default value: 									cn
#
# For simple LDAP authentication, the name of the attribute that specifies group names in LDAP directory entries.
# If authentication_ldap_simple_group_search_attr has its default value of cn, searches return the cn value as the group name.
#
# For example, if an LDAP entry with a uid value of user1 has a cn attribute of mygroup, searches for user1 return mygroup as the group name.
#
# If the group search attribute is isMemberOf, LDAP authentication directly retrieves the user attribute isMemberOf
# value and assigns it as group information.
#
# If the group search attribute is not isMemberOf, LDAP authentication searches for all groups where the user is a member.
# (The latter is the default behavior).
#
# This behavior is based on how LDAP group information can be stored two ways:
#
# 1) A group entry can have an attribute named memberUid or member with a value that is a user name;
#
# 2) A user entry can have an attribute named isMemberOf with values that are group names.
#
# authentication_ldap_simple_group_search_filter
#
# Property 											Value
# Command-line format 							--authentication-ldap-simple-group-search-filter=value
# Introduced 										8.0.11
# System Variable 								authentication_ldap_simple_group_search_filter
# Scope 												Global
# Dynamic 											Yes
# SET_VAR Hint Applies 							No
# Type 												String
# Default Value: 									(|(&(objectClass=posixGroup) (memberUid=%s))(&(objectClass=group)(member=%s)))
#
# 	For simple LDAP authentication, the custom group search filter.
#
# 	The search filter value can contain {UA} and {UD} notation to represent the user name and the full user DN.
# For example, {UA} is replaced with a user name such as "admin", whereas {UD} is replaced with a use full DN such as "uid=admin,ou=People,dc=example,dc=com".
#
# The following value is the default, which supports both OpenLDAP and Active Directory:
#
# 		(|(&(objectClass=posixGroup)(memberUid={UA}))(&(objectClass=group)(member={UD})))
#
# In some cases for the user scenario, memberOf is a simple user attribute that holds no group information.
# For additional flexibility, an optional {GA} prefix can be used with the group search attribute.
#
# Any group attribute with a {GA} prefix is treated as a user attribute having group names.
#
# For example, with a value of {GA}MemberOf, if the group value is the DN, the first attribute value from the group DN is returned as the group name.
#
# authentication_ldap_simple_init_pool_size
#
# Property 											Value
# Command-Line Format: 							--authentication-ldap-simple-init-pool-size=value
# Introduced: 										8.0.11
# System Variable: 								authentication_ldap_simple_init_pool_size
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Integer
# Default Value: 									10
# Min: 												0
# Max: 												32767
#
# For simple LDAP authentication, the initial size of the pool of connections to the LDAP server.
#
# Choose the value for this variable based on the average number of concurrent authentication
# reuqests to the LDAP server.
#
# The plugin uses authentication_ldap_simple_init_pool_size and authentication_ldap_simple_max_pool_size
# together for connection-pool management:
#
# 		) When the authentication plugin initializes, it creates authentication_ldap_simple_init_pool_size connections,
# 			unless authentication_ldap_simple_max_pool_size=0 to disable pooling.
#
# 		) If the plugin receives an authentication request when there are no free connections in the current connection pool,
# 			the plugin can create a new connection - up to the maximum connection pool size given by authentication_ldap_simple_max_pool_Size.
#
# 		) If the plugin receives a request when the pool size is already at its maxium and there are no free connections, authentication fails.
#
# 		) When the plugin unloads, it closes all pooled connections.
#
# Changes to plugin system variable settings may have no effect on connections already in the pool.
# For example, modifying the LDAP server host, port or TLS settings does not affect existing connections.
#
# However, if the original variable values were invalid and the connection pool could not be initialized,
# the plugin attempts to reinitialize the pool for the next LDAP request.
#
# In this case, the new system variable values are used for the reinitialization attempt.
#
# If authentication_ldap_simple_max_pool_size=0 to disable pooling, each LDAP connection opened by the plugin
# uses the values the system variables have at that time.
#
# authentication_ldap_simple_log_status
#
# Property 											Value
# Command-Line Format 							--authentication-ldap-simple-log-status=value
# Introduced 										8.0.11
# System Variable 								authentication_ldap_simple_log_status
# Scope: 											Global
# DYnamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												Integer
# Default value: 									1
# Min: 												1
# Max: 												5
#
# For a simple LDAP authentication, the logging level. 
#
# Log levels for authentication_ldap_simple_log_status
#
# Option value 		Types of Messages Logged
# 1 						No messages
# 2 						Error messages
# 3 						Error and warning messages
# 4 						Error,warning and information messages
# 5 						All messages
#
# authentication_ldap_simple_max_pool_size
#
# Property 											Value
# Command-line format 							--authentication-ldap-simple-max-pool-size=value
# Introduced 										8.0.11
# System Variable: 								authentication_ldap_simple_max_pool_size
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint Applies: 						No
# Type: 												Integer
# Default Value: 									1000
# Min value: 										0
# Max value: 										32767
#
# For simple LDAP authentication, the maximum size of the pool of connections to the LDAP server.
# To disable connection pooling, set this variable to 0.
#
# This variable is used in conjunction with authentication_ldap_simple_init_pool_size.
#
# authentication_ldap_simple_server_host
#
# Property 											Value
# Command-Line format 							--authentication-ldap-simple-server-host=value
# Introduced 										8.0.11
# System Variable: 								authentication_ldap_simple_server_host
# Scope: 											Global
# Dynamic: 											Yes
# SET_VAR Hint applies: 						No
# Type: 												String
#
# For simple LDAP authentication, the LDAP server host.
# The permitted values for this variable depends on the authentication method:
# 
# 		) For authentication_ldap_simple_auth_method_name=SIMPLE: The LDAP server host can be a host name or IP address.
#
# 		) For authentication_ldap_simple_auth_method_name=AD-FOREST. The LDAP server host can be an Active Directory domain name.
# 																			For example, for an LDAP server URL of ldap://example.mem.local:389, the server name can be mem.local
#
# 			An Active Directory forest setup can have multiple domains (LDAP server IPs), which can be discovered using DNS.
#
# 			On UNIX/UNIX based systems, some additional setup may require that you configure your DNS with SRV records that specify the LDAP servers
# 			for the Active Directory domain.
# 			
# 			Suppose that your configuration has these properties:
#
# 				) The name server that provides information about Active Directory domains has IP address 10.172.166.100
#
# 				) The LDAP servers have names ldap1.mem.local through ldap3.mem.local and IP addresses 10.172.166.101 through 10.172.166.103
#
# 			you want hte LDAP servers to be discoverable using SRV searches. For example, at the cmd line, a command like this should list the
# 			LDAP servers:
#
# 				host -t SRV _ldap._tcp.mem.local
#
# 			Perform the DNS configuration as follows:
#
# 				1. Add a line to /etc/resolv.conf to specify the name server that provides information about Active Directory domains:
#
# 					nameserver 10.172.166.100
#
# 				2. Configure the appropriate zone file for the name server with SRV records for the LDAP servers:
#
# 					_ldap._tcp.mem.local. 86400 IN SRV 0 100 389 ldap1.mem.local.
# 					_ldap._tcp.mem.local. 86400 IN SRV 0 100 389 ldap2.mem.local.
# 					_ldap._tcp.mem.local. 86400 IN SRV 0 100 389 ldap3.mem.local.
#
# 				3. It may also be necessary to specify the IP address for the LDAP servers in /etc/hosts if the server host cannot be resolved.
#
# 					For example, add lines like this to the file:
#
# 						10.172.166.101 ldap1.mem.local
# 						10.172.166.102 ldap2.mem.local
# 						10.172.166.103 ldap3.mem.local
#
# 					With the DNS configured as just described, the server-side LDAP plugin can discover the LDAP servers and will try to
# 					authenticate in all domains until authentication succeeeds or there are no more servers.
#
# 					Windows need no such settings as just described. Given the LDAP server host in the authentication_ldap_simple_server_host value,
# 					the Windows LDAP library searches all domains and attempts to authenticate.
#
# authentication_ldap_simple_server_port
#
# Property 												Value
# Command-line format 								--authentication-ldap-simple-server-port=value
# Introduced: 											8.0.11
# System variable: 									authentication_ldap_simple_server_port
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint applies 								No
# Type: 													Integer
# Default: 												389
# Min: 													1
# Max: 													32376
#
# For simple LDAP authentication, teh LDAP server TCP/IP port number.
#
# authentication_ldap_simple_tls
#
# Property 												Value
# Command-line format 								--authentication-ldap-simple-tls=value
# Introduced 											8.0.11
# System Variable: 									authentication_ldap_simple_tls
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint applies: 							No
# Type: 													Boolean
# Default Value: 										OFF
#
# For simple LDAP authentication, whether connections by the plugin to the LDAP servers are secure.
# If this variable is enabled, the plugin uses TLS to connect securely to the lDAP server.
#
# If you enable this variable, you may also wish to set the authentication_ldap_simple_ca_path variable.
#
# MySQL LDAP plugins support the StartTLS method, which initializes TLS on top of a plain LDAP connection.
# The ldaps method is deprecated and MySQL does not supporti t.
#
# authentication_ldap_simple_user_search_attr
#
# Property 												Value
# Command-line FOrmat 								--authentication-ldap-simple-user-search-attr=value
# Introduced: 											8.0.11
# System variable: 									authentication_ldap_simple_user_search_attr
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint applies: 							No
# Type: 													String
# Default: 												uid
#
# For simple LDAP authentication, the name of the attribute that specifies user names in LDAP directory entries.
# If a user distinguished name is not provided, the authentication plugin searches for the name using this attribute.
#
# For example, if the authentication_ldap_simple_user_search_attr value is uid, a search for hte user name
# user1 finds entries with a uid value of user1.
#
# THE CONNECTION CONTROL PLUGINS
#
# MySQL Server includes a plugin library that enables administrators to introduce an increasing delay in server responses
# to clients after a certain number of consecutive failed connection attempts.
#
# This capability provides a deterrent that slows down brute force attacks that attempt to access MysQL user accs.
# the plugin library contains two plugins:
#
# 		) CONNECTION_CONTROL checks incoming connections and adds a delay to server responses as necessary.
#
# 			This plugin also exposes system variables that enables its operation to be configured and a status
# 			variable that provides rudimentary monitoring information.
#
# 			The CONNECTION_CONTROL plugin uses the audit plugin interface.
#
# 			To collect information, it subscribes to the MYSQL_AUDIT_CONNECTION_CLASSMASK event class,
# 			and processes MYSQL_AUDIT_CONNECTION_CONNECT and MYSQL_AUDIT_CONNECTION_CHANGE_USER subevents to
# 			check whether the server should introduce a delay befor responding to client connection attempts.
#
# 		) CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS implements an INFORMATION_SCHEMA table that exposes more detailed monitoring
# 			information for failed connection attempts.
#
# The following section provides information about connection-control plugin installation and configuration.
#
# More info about the CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS later.
#
# CONNECTION-CONTROL PLUGIN INSTALLATION
#
# This section describes how ot install the connection-control plugins, CONNECTION_CONTROL and CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS.
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory (the directory named by the plugin_dir
# system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is connection_control. The file name suffix differs per platform (for example, .so for Unix and Unix-like systems,
# .dll for Windows)
#
# To load the plugins at server startup, use the --plugin-load-add option to name the library file that contains them.
# With this plugin-loading method, the option must be given each time the server starts.
#
# For example, put these lines in the server my.cnf file (adjust the .so suffix for your platform as necessary):
#
# 		[mysqld]
# 		plugin-load-add=connection_control.so
#
# After modifying my.cnf, restart the server to cause the new settings to take efect.
#
# Alternatively, to register the plugins at runtime, use these statements (adjust the .so suffix as called for):
#
# 		INSTALL PLUGIN CONNECTION_CONTROL
# 			SONAME 'connection_control.so';
# 		INSTALL PLUGIN CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS
# 			SONAME 'connection_control.so';
#
# INSTALL_PLUGIN loads the plugin immediately, and also registers it in the mysql.plugins system table to cause the server to load it for each
# subsequent normal startup.
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS statement.
#
# For example:
#
# 		SELECT PLUGIN_NAME, PLUGIN_STATUS
# 		FROM INFORMATION_SCHEMA.PLUGINS
# 		WHERE PLUGIN_NAME LIKE 'connection%';
#
#
# +------------------------------------------------------------+
# | PLUGIN_NAME 											| PLUGIN_STATUS|
# +------------------------------------------------------------+
# | CONNECTION_CONTROL 									| ACTIVE 		|
# | CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS  	| ACTIVE 		|
# +------------------------------------------------------------+
#
# If a plugin fails to initialize, check the server error log for diagnostic messages.
#
# If the plugins have been previously registered with INSTALL_PLUGIN or are loaded with --plugin-load-add, you can use the
# --connection-control and --connection-control-failed-login-attempts options at server startup to control plugin activation.
#
# For example, to load the plugins at startup and prevent them from being removed
# at runtime, use these options:
#
# [mysqld]
# plugin-load-add=connection_control.so
# connection-control=FORCE_PLUS_PERMANENT
# connection-control-failed-login-attempts=FORCE_PLUS_PERMANENT
#
# If it is desired to prevent the server from running without a given connection-control plugin, use an option value
# of FORCE or FORCE_PLUS_PERMANENT to force server startup to fail if the plugin does not initialize successfully.
#
# NOTE:
#
# 		It is possible to install one plugin without the other, but both must be installed for full connection-control capability.
#
# 		In particular, installing only the CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS plugin is of little use because without
# 		the CONNECTION_CONTROL plugin to provide the data that populates the CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS table,
# 		retrievals from the table will always be empty.
#
# CONNECTION DELAY CONFIGURATION
#
# To enable you to configure its operation, the CONNECTION_CONTROL plugin exposes several system variables:
#
# 		) connection_control_failed_connections_threshold: 
# 				
# 			The number of consecutive failed connection attempts permitted to clients before the server
# 			adds a delay for subsequent connection attempts.
#
# 		) connection_control_min_connection_delay: The amount of delay to add for each consecutive connection failure above the TH.
#
# 		) connection_control_max_connection_delay: The maximum delay to add.
#
# To entirely disable checking for failed connection attempts, set connection_control_failed_connections_threshold to zero.
#
# If connection_control_failed_connections_threshold is > 0, the amount of delay is zero up through that many consecutive
# failed connection attempts.
#
# Thereafter, the amount of delay is the number of failed attempts above the TH, multiplied by connection_control_min_connection_delay MS.
#
# For example, with the default connection_control_failed_connections_threshold and connection_control_min_connection_delay values of 3
# and 1000, respectively - there is no delay for the first consecutive failed connection attempts by a client, and a additive of 1000 MS
# per fail there after.
#
# Up until the max delay permitted by connection_control_max_connection_delay.
#
# You can set the CONNECTION_CONTROL system variables at server startup or runtime.
#
# Suppose that you want to permit four consecutive failed conn attempts before the server starts delaying its reponses - and to
# increase the delay to 1500 MS for each additional failure after that.
#
# To set the relevant variables at server startup, put these lines in the server my.cnf file:
#
# 		[mysqld]
# 		plugin-load-add=connection_control.so
# 		connection_control_failed_connections_threshold=4
# 		connection_control_min_connection_delay=1500
#
# To set and persist the variables at runtime, use these statements:
#
# 		SET PERSIST connection_control_failed_connections_threshold = 4;
# 		SET PERSIST connection_control_min_connection_delay = 1500;
#
# SET_PERSIST sets the value for the running MySQL instance.
#
# It also saves the value to be used for subsequent server restarts.
# to change a value for the running MySQL instance without saving it for subsequent restarts, use the GLOBAL keyword rather than PERSIST.
#
# The connection_control_min_connection_delay and connection_control_max_connection_delay System Variables have fixed
# min and max values of 1000 and 2.147.483.647, respectively.
#
# In addition, the permitted range of values of each variable also depends on the current value of hte other:
#
# 		) connection_control_min_connection_delay cannot be set greater than the current value of connection_control_max_connection_delay
#
# 		) connection_control_max_connection_delay cannot be set less than the current value of connection_control_min_connection_delay
#
# Thus - to make the changes required for some configurations, you might need to set the variables in a specific order.
#
# Suppose that the current minimum and maximum delays are 1000 and 2000, and that you want to set them to 3000 and 5000.
#
# You cannot first set connection_control_min_connection_delay to 3000, because that is greater than the current
# connection_control_max_connection_delay value of 2k.
#
# Instead, set connection_control_max_connection_delay to 5000, then connection_control_min_connection_delay to 3000.
#
# CONNECTION FAILURE ASSESSMENT
#
# When the CONNECTION_CONTROL plugin is installed, it checks connection attempts and tracks whether they fail or succeed.
#
# For this purpose, a failed connection attempt is one for which the client user and host match a known MySQL account
# but the provided credentials are incorrect, or do not match any known account.
#
# Failed-connection counting is based on the user/host combination for each connection attempt.
#
# Determination of the applicable user name and host name takes proxying into account and occurs as follows:
#
# 		) If the client user proxies another user, the proxying user's information is used.
#
# 			For example, if external_user@example.com proxies proxy_user@example.com, connection counting
# 			uses the proxying user, external_user@example.com, rather than the proxied user - proxy_user@example.com
#
# 			Both external_user@example.com and proxy_user@example.com must have valid entries in the mysql.user system table
# 			and a proxy relationship betweem them must be defined in the mysql.proxies_priv system table.
#
# 		) If the client user does not proxy another user, but does match a mysql.user entry, counting uses the CURRENT_USER()
# 		value corresponding to that entry.
#
# 		For example, if a user user1 connecting from a host host1.example.com matches a user1.host1.example.com entry, counting
# 		uses user1@host1.example.com
#
# 		If the user matches a user1@%.example.com, user1@%.com or user1@% entry instead, counting uses user1@%.example.com, user1@%.com or user1@%, respectively.
#
# For the cases just described, the connection attempt matches some mysql.user entry and whether the request succeeds or fails depends 
# on whether the client provides the correct authentication credentials.
#
# For example, if the client presents an incorrect password, the connection attempt fails.
#
# If the connection attempt matches no mysql.user entry, the attempt fails. 
#
# In this case, no CURRENT_USER() value is avaialable and connection-failure counting uses the user name
#  provided by the client and the client host as determined by the server.
#
# For example, if a client attempts to connect as user user2 from host host2.example.com, the user name part is available
# in the client request and the server determines the host information.
#
# The user/host combination used for counting is user2@host2.example.com
#
# NOTE:
#
# 		The server maintains information about which client hosts can possibly connect to the server (essentially the union of host values for mysql.user entries).
# 		If a client attempts to connect from any other host, the server rejects the attempt at an early stage of connection setup:
#
# 			ERROR 1130 (HY000): Host 'host_name' is not allowed to connect to this MySQL server
#
# 		Because this type of rejection occurs so early, CONNECTION_CONTROL does not see it, and does not count it.
#
# CONNECTION FAILURE MONITORING
#
# To monitor failed connections, use these information sources:
#
# 		) The Connection_control_delay_generated status variable indicates the number of times the server added a delay to its response
# 			to a failed connection attempt.
#
# 			This does not count attempts that occur before reaching the threshold defined by the connection_control_failed_connections_threshold system variable.
#
# 		) The INFORMATION_SCHEMA CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS table provides information about the current number of consecutive failed connection
# 			attemtps per client user/host combination.
#
# 			This counts all failed attempts, regardless of whether they were delayed.
#
# Assigning a value to connection_control_failed_connections_threshold at runtime resets all accumulated failed-connection counters to 0,
# which has these visible effects:
#
# 		) The Connection_control_delay_generated status variable is reset to 0.
#
# 		) The CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS table becomes empty.
#
# CONNECTION-CONTROL SYSTEM AND STATUS VARIABLES
#
# This section describes the system and status variables that the CONNECTION_CONTROL plugin provides to enable its
# operation to be configured and monitored.
#
# CONNECTION-CONTROL SYSTEM VARIABLES
#
# If the CONNECTION_CONTROL plugin is installed, it exposes these system variables:
#
# connection_control_failed_connections_threshold
#
# Property 												Value
# Command-line Format 								--connection-control-failed-connections-threshold=#
# Introduced: 											8.0.1
# System variable: 									connection_control_failed_connections_threshold
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint applies: 							No
# Type: 													Integer
# Default value: 										3
# Min: 													0
# Max: 													2147483647
#
# The number of consecutive failed connection attempts permitted to clients before the server adds a delay for 
# subsequent connection attempts:
#
# 		) If the variable has a nonzero value N, the server adds a delay beginning with consecutive failed attempt N+1.
#
# 			If a client has reached the point where connection responses are delayed, the delay also occurs for 
# 			the next subsequent successful connection.
#
# 		) Setting this variable to 0 disables failed-connection counting. In this case, the server never adds delays.
#
# For information about how connection_control_failed_connections_threshold interacts with other connection-control
# system and status variables, see earlier.
#
# connection_control_max_connection_delay
#
# Property 												Value
# Command-line Format 								--connection-control-max-connection-delay=#
# Introduced: 											8.0.1
# System Variable: 									connection_control_max_connection_delay
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint applies: 							No
# Type: 													Integer
# Default: 												2.147.483.647
# Min: 													1000
# Max: 												   2.147.483.647
# 													
#
# The maximum delay in milliseconds for server response to failed connection attempts, if connection_control_failed_connections_threshold
# is greater than 0.
#
# For information about how connection_control_max_connection_delay interacts with other connection-control system and status variables,
# see earlier.
#
# connection_control_min_connection_delay
#
# Property 												Value
# Command-Line Format 								--connection-control-min-connection-delay=#
# Introduced: 											8.0.1
# System Variable: 									connection_control_min_connection_delay
# Scope: 												Global
# Dynamic: 												Yes
# SET_VAR Hint Applies: 							No
# Type: 													Integer
# Default value: 										1000
# Min value: 											1000
# Max value: 											2.147.483.647
#
# The minimum delay in MS for sever responses to failed connection attempts, if connection_control_failed_connections_threshold is greater
# than 0.
#
# This is also the amount by which the server increases the delay for additional successive failures once it begins delaying.
#
# For more information about how connection_control_min_connection_delay interacts with other connection-control system and status variables
# , see previous details.
#
# CONNECTION-CONTROL STATUS VARIABLES
#
# If the CONNECTION_CONTROL plugin is installed, it exposes this status variable:
#
# 		) Connection_control_delay_generated
#
# 				The number of times the server added a delay to its response to a failed connection attempt.
# 				This does not count attempts that occur before reaching the threshold defined by the connection_control_failed_connections_threshold system variable.
#
# 				This variable provides a simple counter. For more detailed connection-control monitoring information, examine the INFORMATION_SCHEMA
# 				CONNECTION_CONTROL_FAILED_LOGIN_ATTEMPTS table. More on that later.
#
# 				Assigning a value to connection_control_failed_connections_threshold at runtime resets Connection_control_delay_generated to zero.
#
# THE PASSWORD VALIDATION COMPONENT
#
# The validate_password components serves to test passwords and improve security.
# This component exposes system variables that enable you to define password policy, and status variables for component monitoring.
#
# NOTE:
#
# 		In MySQL 8.0.4, the validate_password plugin was reimplemented as the validate_password component.
# 		The following instructions describe how to use the component, not the plugin.
#
# 		For instructions on using it, see external resources.
#
# 		The plugin form of validate_password is available but is deprecated and will be removed.
# 		MySQL installations that use it - should transition to using the component instead. More on that later.
#
# The validate_password component implements these capabilities:
#
# 		) In SQL statements that assign a password supplied as a cleartext value, the component checks the password against
# 			the current password policy and rejects the password if it is weak (the statement returns an ER_NOT_VALID_PASSWORD error)
#
# 			This applies to the ALTER_USER, CREATE_USER, GRANT and SET_PASSWORD statements.
#
# 		) The VALIDATE_PASSWORD_STRENGTH() SQL function asssesses the strength of potentional PWs. 
#
# 			The function takes a PW argument and returns an integer from 0 (weak) to 100 (strong)
#
# For example, validate_password checks the cleartext password in the following statement.
#
# Under the default password policy, which requires passwords to be at least 8 characters long -
# the PW is weak and the statement produces an error.
#
# 		ALTER USER USER() IDENTIFIED BY 'abc';
# 		ERROR 1819 (HY000): Your password does not satisfy the current policy requirements
#
# Passwords specified as hashed values are not checked because the original password values is not available
# for checking:
#
# ALTER USER 'jeffrey'@'localhost'
# IDENTIFIED WITH mysql_native_password
# AS '<hash>';
# Query OK, 0 rows affected (0.01 sec)
#
# To configure PW checking, modify the system variable having names of the form validate_password.xxx, these are the
# parameters that control password policy. See later.
#
# If validate_password is not installed, the validate_password.xxx system variables are not available, passwords
# in statements are not checked and the VALIDATE_PASSWORD_STRENGTH() function always returns 0.
#
# For example, without the plugin installed, accounts can be assigned PWs shorter than 8 chars.
#
# Assuming that validate_password is installed, it implements three levels of PW checking:
#
# LOW, MEDIUM and STRONG.
#
# The default is MEDIUM; to change this, modify the value of validate_password.policy
#
# The policies implement increasingly strict password tests. 
# The following descriptions refer to default param values, which can be modified by changing the appropriate system variables.
#
# 	) LOW policy test password length only. Passwords must be at least 8 chars long. To change this length, modify the validate_password.length
#
# 	) MEDIUM policy adds the conditions that passwords must contain at least 1 numeric character, 1 lowercase character, 1 uppercase character,
# 		and 1 special (nonalphanumeric) character.
#
# 		TO change these values, modify validate_password.number_count, validate_password.mixed_case_count and
# 		validate_password.special_char_count.
#
# 	) STRONG policy adds the condition that password substrings of length 4 or longer must not match words in the dictioanry file,
# 		if one has been specified.
#
# 		To specify the dictionary file, modify validate_password.dictionary_file
#
# In addition, validate_password supports the capability of rejecting passwords that match the user name part of the effective
# user account for the current session, either forward or in reverse.
#
# To provide control over this capabiblity, validate_password exposes a validate_password.check_user_name system variable,
# which is enabled by default.
#
# PASSWORD VALIDATION COMPONENT INSTALLATION AND UNINSTALLATION
#
# This section describes how to install and uninstall the validate_password password-validation component.
# For general info, see earlier.
#
# NOTE:
#
# 		If you install MySQL 8.0 using the MySQL Yum repository, MySQL SLES Repository or RPM packages provided by Oracle,
# 		the validate_password component is enabled by default after you start your MySQL Server for the first time.
#
# 		Upgrades to MySQL 8.0 from 5.7 using Yum or RPM packages leave the validate_password plugin in place.
# 		To make the transition from the validate_password plugin to the validate_password component, see later.
#
# To be usable by the server, the component library file must be located in the MySQL plugin directory
# (the directory named by the plugin_dir system variable)
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# To install validate_password, use this statement:
#
# INSTALL COMPONENT 'file://component_validate_password';
#
# Component installation is a one-time operation that need not be done per server startup.
#
# INSTALL_COMPONENT loads the component, and also registers it in the mysql.component system table
# to cause it to be loaded during subsequent server startups.
#
# To uninstall validate_password, use this statement:
#
# UNINSTALL COMPONENT 'file://component_validate_password';
#
# UNINSTALL_COMPONENT unloads the component, and deregisters it from the mysql.component system table
# to cause it not to be loaded during subsequent server startups.
#
# PASSWORD VALIDATION OPTIONS AND VARIABLES
#
# This section describes the system and status variables that validate_password provides to enable
# its operation to be configured and monitored.
#
# PASSWORD VALIDATION COMPONENT SYSTEM VARIABLES
#
# If the validate_password component is enabled, it exposes several system variables that enable configuration
# of password checking:
#
# SHOW VARIABLES LIKE 'validate_password.%';
# +----------------------------------------------+
# | Variable_name 						   | Value   |
# +----------------------------------------------+
# | validate_password.check_user_name   | ON 	 |
# | validate_password.dictionary_file 	 | 		 |
# | validate_password.length 			    | 8 	    |
# | validate_password.mixed_case_count  | 1 	    |
# | validate_password.number_count 	    | 1 	    |
# | validate_password.policy 			    | MEDIUM |
# | validate_password.special_char_count| 1 		 |
# +----------------------------------------------+
#
# To change how PWs are checked, you can set these system variables at server startup or at runtime.
# The following list describes the meaning of each variable.
#
# validate_password.check_user_name
#
# 	Property 								Value
# Command-line Format 					--validate-password.check-user-name
# Introduced 								8.0.4
# System Variable 						validate_password.check_user_name
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint Applies 					No
# Type 										Boolean
# Default value 							ON
#
# Whether validate_password compares passwords to the user name part of the effective user account
# for the current session and rejects them if they match.
#
# This variable is unavailable unless validate_password is installed.
#
# By default, validate_password.check_user_name is enabled. This variable controls user name matching independent of the value
# of validate_password.policy
#
# When validate_password.check_user_name is enabled, it has these effects:
#
# 		) Checking occurs in all contexts for which validate_password is invoked, which includes use of statements such as ALTER_USER
# 			or SET_PASSWORD to change the current user's password, and invocation of functions such as VALIDATE_PASSWORD_STRENGTH()
#
# 		) The user names used for comparison are taken from the values of the USER() and CURRENT_USER() functions for the current session.
#
# 			An implication is that a user who has sufficient privileges to set another user's password can set the password to that user's name,
# 			and cannot se that user's password to the name of the user executing the statement.
#
# 			For example, 'root'@'localhost' can set the password for 'jeffrey'@'localhost' to 'jeffrey', but cannot set the password
# 			to 'root'
#
# 		) Only the user name part of the USER() and CURRENT_USER() function values is used, not the host name part.
#
# 			If a user name is empty, no comparison occurs.
#
# 		) If a password is the same as the user name or its reverse, a match occurs and the PW is rejected.
#
# 		) User-name matching is case sensitive. The password and user name values are compared as binary strings on a byte-by-byte basis.
#
# 		) If a password matches the user name, VALIDATE_PASSWORD_STRENGTH() returns 0 regardless of how other validate_password system variables are set.
#
# validate_password.dictionary_file
#
# Property 									Values
# Introduced 								8.0.4
# System Variable 						validate_password.dictionary_file
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint applies 					No
# Type 										File name
#
# The path name of the dictionary file that validate_password uses for checking passwords.
# This variable is unavailable unless validate_password is installed.
#
# By default, this variable has an empty value and dictionary checks are not performed.
# For dictionary checks to occur, the variable value must be nonempty.
#
# If the file is named as a relative path, it is interpreted relative to the server data directory.
# File contents should be lowercase, one word per line.
#
# Contents are treated as having a character set of utf8.
# The maximum permitted file size if 1mb.
#
# For the dictionary file to be used during password checking, the password policy must be set 
# to 2 (Strong); see the description of the validate_password.policy system variable.
#
# Assuming that is true, each substring of the password of length 4 p to 100 is compared to the
# words in the dictionary file.
#
# Any match causes the password to be rejected. Comparisons are not case sensitive.
#
# For VALIDATE_PASSWORD_STRENGTH(), the password is checked against all policies, including STRONG - so the strength
# assessment includes the dictionary check regardless of the validate_password.policy value
#
# validate_password.dictionary_file can be set at runtime and assigning a value causes the named file to be
# read without a server restart.
#
# validate_password.length
#
# Property 									Value
# Introduced 								8.0.4
# System Variable 						validate_password.length
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint Applies 					No
# Type 										Integer
# Default  value 							8
# Min 										0
#
# The minimum number of charachters that validate_password requires PWs to have.
# This variable is unavailable unless validate_password is installed.
#
# The validate_password.length minimum value is a function of several other related system variables.
# The value cannot be set less than the value of this expression:
#
# validate_password.number_count + validate_password.special_char_count + (2 * validate_password.mixed_case_count)
#
# If validate_password adjusts the value of validate_password.length due to the preceding constraint, it writes
# a message to the error log.
#
# validate_password.mixed_case_count
#
# Property 									Value
# Introduced 								8.0.4
# System Variable 						validate_password.mixed_case_count
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint applies 					No
# Type 										Integer
# Default 									1
# Min 										0
#
# THe minimum number of lowercase and uppercase characters that validate_password requires passwords to have if the password
# policy is MEDIUM or stronger.
#
# This variable is unavailable unless validate_password is installed.
#
# For a given validate_password.mixed_case_count value, the password must have that many lowercase characters,
# and that many uppercase characters.
#
# validate_password.number_count
#
# Property 									Value
# Introduced 								8.0.4
# System variable 						validate_password.number_count
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint applies 					No
# Type 										Integer
# Default  									1
# Min 										0
#
# The minimum number of numeric (digit) characters that validate_password requires passwords to have if the password
# policy is MEDIUM or stronger.
#
# This variable is unavailable unless validate_password is installed.
#
# validate_password.policy
#
# Property 									Value
# Introduced 								8.0.4
# System Variable 						validate_password.policy
# Scope 										Global
# DYnamic 									Yes
# SET_VAR Hint Applies 					No
# Type 										Enumeration
# Default 									1
# Valid 										0
# 												1
# 												2
#
# The password policy enforced by validate_password. This variable is unavailable unless validate_password is installed.
#
# validate_password.policy affects how validate_password uses its other policy-setting system variables,
# except for checking passwords against user names, which is controlled independently by validate_password.check_user_name
#
# The validate_password.policy value can be specified using numeric values 0, 1,2 - or the corresponding symbolic values LOW, MEDIUM, STRONG.
# The following table describes the tests performed for each policy.
#
# For the length test, the required length is the value of the validate_password.length system variable.
# Similarly, the required values for the other tests are given by other validate_password.xxx variables.
#
# Policy 				Tests Performed
# 0 or LOW 				Length
# 1 or MEDIUM 			Length; numeric, lowercase/uppercase and special characters
# 2 or STRONG 			Length; numeric, lowercase/uppercase and special characters; dictionary file
#
# validate_password.special_char_count
#
# Property 									Value
# Introduced 								8.0.4
# System Variable 						validate_password.special_char_count
# Scope 										Global
# Dynamic 									Yes
# SET_VAR Hint Applies 					No
# Type 										INteger
# Default 									1
# Min 										0
#
# The minimum number of nonalphanumeric characters that validate_password requires passwords to have
# if the password policy is MEDIUM or higher.
#
# This variable is unavailable unless validate_password is installed.
#
# PASSWORD VALIDATION COMPONENT STATUS VARIABLES
#
# If the validate_password component is enabled, it exposes status variables that provide operational information:
#
# SHOW STATUS LIKE 'validate_password.%';
# +--------------------------------------------+-------------------------+
# | Variable_name 									       | Value 			    |
# +----------------------------------------------------------------------+
# | validate_password.dictionary_file_last_parsed 	 | 2018-01-15 08:33:49|
# | validate_password.dictionary_file_words_count 	 | 1902 					 |
# +----------------------------------------------------------------------+
#
# The following list describes the meaning of each status variable.
#
# validate_password.dictionary_file_last_parsed
#
# 		WHen the dictionary file was last parsed. This variable is unavailable unless validate_password is installed.
#
# validate_password.dictionary_file_words_count
#
# 		THe number of words read from the dictionary file. This variable is unavailable unless validate_password is installed.
#
# PASSWORD VALIDATION PLUGIN OPTIONS
#
# NOTE:
#
# 		In MysQL 8.04, the validate_password plugin was reimplemented as the validate_password component.
# 		The validate_password plugin is deprecated and will be removed.
#
# 		Transition to the component instead. More about this later.
#
# To control the activation of the validate_password plugin, use this option:
#
# --validate-password[=value]
#
# Property 									Value
# Command-line Format 					--validate-password[=value]
# Type 										Enumeration
# Default: 									ON
# Valid: 									ON, OFF, FORCE, FORCE_PLUS_PERMANENT
#
# This option controls how the server loads the deprecated validate_password plugin at startup.
#
# The value should be one of those available for plugin-loading options.
#
# For example, --validate-password=FORCE_PLUS_PERMANENT tells the server to load the plugin
# at startup and prevents it from being removed while the server is running.
#
# This option is available only if the validate_password plugin has been previously registered with
# INSTALL_PLUGIN or is loaded with --plugin-load-add.
#
# PASSWORD VALIDATION PLUGIN SYSTEM VARIABLES
#
# Note:
#
# 		In MySQL 8.0.4, the validate_password plugin was reimplemented as the validate_password component.
# 		The validate_password plugin is deprecated.
#
# 		Thus, it's system variables are also deprecated, use the component system variables instead.
#
# validate_password_check_user_name
#
# Property 								Value
# Command-line Format 				--validate-password-check-user-name
# System variable 					validate_password_check_user_name
# Scope 									Global
# Dynamic 								Yes
# SET_VAR Hint Applies 				No
# Type 									Boolean
# Default Value 						ON
#
# This validate_password plugin system variable is deprecated.
# Use corresponding validate_password.check_user_name system variable of the validate_password component instead.
#
# // The system variables of which are for the plugin are deprecated and mirror the updated Componeont system variables.
#
# TRANSITIONING TO THE PASSWORD VALIDATION COMPONENT
#
# Note:
#
# 		In MySQL 8.0.4, the validate_password plugin was reimplemented as the validate_password component.
# 		The validate_password plugin is deprecated.
#
# MySQL installations that currently use the validate_password plugin should make the transition
# to using the validate_password component instead.
#
# To do so, use the following procedure.
#
# The procedure installs the component before uninstalling the plugin, to avoid having a time window during which no PW validation
# occurs.
#
# (The component and plugin can be installed simultaneously. In this case, the server attempts ot use the component,
# falling back to the plugin if the component is unavailable).
#
# 1. Install the validate_password component:
#
# 		INSTALL COMPONENT 'file://component_validate_password';
#
# 2. Test the validate_password component to ensure that it works as expected.
#
# If you need to set any validate_password.xxx SYSTEM VARIABLES, you can do so at
# runtime using SET GLOBAL (Any option file changes that must be made are performed in the next step)
#
# 3. Adjust any references to the plugin system and status variables to refer to the corresponding component system and
# 		status variables.
#
# 		Suppose that you configure the plugin at startup using an option file like this:
#
# 		[mysqld]
# 		validate-password=FORCE_PLUS_PERMANENT
# 		validate_password_dictionary_file=/usr/share/dict/words
# 		validate_password_length=10
# 		validate_password_number_count=2
#
# To adjust hte option file, omit the --validate-password option (it applies only to the plugin, not the component),
# and modify the system variable references:
#
# 		[mysqld]
# 		validate_password.dictionary_file=/usr/share/dict/words
# 		validate_password.length=10
# 		validate_password.number_count=2
#
# Similar adjustments are needed for applications that refer at runtime to validate_password plugin system and status variables.
#
# 4. Uninstall the validate_password plugin:
#
# 		UNINSTALL PLUGIN validate_password;
#
# If the validate_password plugin is loaded at server startup using a --plugin-load or --plugin-load-add option
# omit that option from the server startup procedure.
#
# For example, if the option is listed in a server option file, remove it from the file.
#
# 5. Restart the Server.
#
# THE MYSQL KEYRING
#
# MySQL Server supports a keyring service that enables internal server components and plugins to securly store sensitve information
# for later retrieval. The implementation is plugin-based:
#
# 	) The keyring_file plugin stores keyring data in a file local to the server host. This plugin is available in all MySQL distribs.
# 		Both community and Enterprise included.
#
# 	) The keyring_encrypted_file plugin stores keyring data in an encrypted file local to the server host.
# 		This plugin is available in MySQL Enterprise Edition distribs.
#
# 	) keyring_okv is a KMIP 1.1 plugin for use with KMIP-compatible back end keyring storage products such as Oracle Key Vault and 
# 		Gemalto SafeNet KeySecure Applicance.
#
# 		Available in the Enterprise edition distribs.
#
# ) The keyring_aws plugin communicates with the Amazon Web Services Key Management Service for key generation and uses a local file
# 		for key storage.
#
# 		This plugin is available in MySQL Enterprise Distribs.
#
# ) A MySQL server operational mode enables migration of keys between underlying keyring keystores.
# 		This enables DBAs to switch a MySQL installation from one keyring plugin to another.
#
# ) An SQL interface for keyring key management is implemented as a set of user-defined functions (UDFs)
#
# WARNING:
#
# 		The keyring_file and keyring_encrypted_file plugins for encryption key management are not intended as regulatory compliance solution.
# 		Security standards such as PCI, FIPS and others require use of key management systems to secure, manage and protect encryption keys
# 		in key vaults or hardware security modules (HSMs)
#
# Uses for the keyring within MySQL include:
#
# ) The innoDB sotrage engine uses the keyring to store its key for tablespace encryption.
# 		InnoDB can use any supported keyring plugin.
#
# ) MYSQL Enterprise Audit uses the keyring to store the audit log file encryption password.
# 		The audit login plugin can use any supported keyring plugin.
#
# Keyring plugins and UDFs access a keyring service that provides the interface for server components to the keyring.
# More of this and other things, later.
#
# KEYRING PLUGIN INSTALLATION
#
# Keyring service consumers require a keyring plugin to be installed. MySQL provides these plugin choices:
#
# 		) keyring_file: A plugin that stores keyring data in a file local to the server host. Available in all MySQL distribs.
#
# 		) keyring_encrypted_file: A plugin that stores keyring data in an encrypted file local to the server host. Available in MySQL EE Distribs.
#
# 		) keyring_okv: A plugin that uses KMIP-compatible back end keyring storage products such as Oracle Key Vault and Gemalto SafeNet KeySecure applicance.
# 							Available in MySQL EE distribs.
#
# 		) keyring_aws: A plugin that communicates with the Amazon Web Services Key Management Services as a back end for key generation and uses a local file
# 							for key storage. available in MySQL EE distribs.
#
# This section describes how to install the keyring plugin of your choosing. 
#
# If you intend to use keyring user-defined functions (UDFs) in conjunction with the keyring plugin, install the UDFs following
# keyring installation using the instructions described later.
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory (the dir named by the plugin_dir
# system variable). If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# Installation for each keyring plugin is similar. The following instructions use keyring_file. Users of a different keyring plugin
# can substitute its name for keyring_file.
#
# The keyring_file plugin library file base name is keyring_file.
#
# The file name suffix differs per platform (for example .so for Unix based systems, .dll for Windows)
#
# NOTE:
# 		Only one keyring plugin should be enabled at a time. Enabling multiple keyring plugins is unsupported and results may not be as anticipated.
#
# The keyring plugin must be loaded early during the server startup sequence so that server components can access it as necessary
# during their own initialization.
#
# For example, the InnoDB storage engine uses the keyring for tablespace encryption, so the keyring plugin must be loaded
# and available prior to InnoDB initialization.
#
# To load the plugin, use the --early-plugin-load option to name the plugin library file that contains it.
#
# For example, on platforms where the plugin library file suffix is .so, use these lines in the server my.cnf
# file (adjust the .so suffix for your platform as necessar):
#
# [mysqld]
# early-plugin-load=keyring_file.so
#
# Before starting the server, check the notes for your chosen keyring plugin to see whether it permits or requires additional configuration.
#
# After performing any plugin-specific configuration, verify plugin installation.
#
# With the MySQL server running, examine the INFORMATION_SCHEMA.PLUGINS table or use the
# SHOW_PLUGINS statement.
#
# For example:
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'keyring%';
# +--------------------------------++
# | PLUGIN_NAME 		| PLUGIN_STATUS|
# +------------------+--------------+
# | keyring_file 		| ACTIVE 		|
# +------------------+--------------+
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# If no keyring plugin is available when a server component tries to access the keyring service,
# the service cannot be used by that component.
#
# As a result, the component may fail to initialize or may initialize with limited functionality.
#
# For example, if InnoDB finds that there are encrypted tablespaces when it initializes, it attempts
# to access the keyring.
#
# If the keyring is unavailable, InnoDB can access only unencrypted tablespaces.
#
# To ensure that InnoDB can access encrypted tablespaces as well, use --early-plugin-load to
# load the keyring plugin. 
#
# Plugins can be loaded by other methods, such as the --plugin-load or --plugin-load-add option or the
# INSTALL_PLUGIN statement.
#
# However, keyring plugins loaded using those methods may be available too late in the server
# startup sequence for certain server components, such as InnoDB:
#
# 		) Plugin loading using --plugin-load or --plugin-load-add occurs after InnoDB initialization
#
# 		) PLugins installed using INSTALL_PLUGIN are registered in the mysql.plugin system table and
# 			loaded automatically for subsequent server restarts.
#
# 			However, because mysql.plugin is an InnoDB table, any plugins named in it can be loaded
# 			during startup only after InnoDB initialization.
#
# USING THE KEYRING_FILE FILE-BASED PLUGIN
#
# The keyring_file is a keyring plugin that stores keyring data in a file local to the server host.
#
# Warning:
#
# 		The keyring_file plugin for encryption key management is not intended as a regulatory compliance solution.
# 		Security standards such as PCI, FIPS, and others require use of key management systems to secure,
# 		manage and protect encryption keys in key vaults or hardware security modules (HSMs)
#
# To install the keyring_file plugin, use the general keyring installation found earlier, together
# with the configuration information specific to keyring_file found here.
#
# TO be usable during the server startup process, keyring_file must be loaded using the --early-plugin-load
# option.
#
# The keyring_file_data system variable optionally configures the location of the file used by the keyring_file
# plugin for data storage.
#
# The default value is platform specific. To configure the file location explicitly, set the variable value at
# startup.
#
# For example, use these lines in the server my.cnf file (adjust the .so suffix and file location for your platform as necessary):
#
# 		[mysqld]
# 		early-plugin-load=keyring_file.so
# 		keyring_file_data=/usr/local/mysql/mysql-keyring/keyring
#
# Keyring operations are transactional: The keyring_file plugin uses a backup file during write operations
# to ensure that it can roll back to the original file if an operation fails.
#
# The backup file has the same name as the value of the keyring_file_data system variable with a suffix of .backup
#
# For additional info about keyring_file_data, see later.
#
# To ensure that keys are flushed only when the correct keyring storage file exists, keyring_file stores a 
# SHA-256 checksum of the keyring in the file.
#
# Before updating the file, the plugin verifies that it contains the expected checksum.
#
# The keyring_file plugin supports the functions that comprise the standard keyring service interface.
#
# Keyring operations performed by those functions are accessible at two levels:
#
# 		) SQL interface: In SQL statements, call the user-defined functions (UDFs)
#
# 		) C interface: In C-language code, call the keyring service functions described later.
#
# Example (using UDFs):
#
# 		SELECT keyring_key_generate('MyKey', 'AES', 32);
# 		SELECT keyring_key_remove('MyKey');
#
# THe key types permitted by keyring_file are described later.
#
# USING THE KEYRING_ENCRYPTED FILE KEYRING PLUGIN
#
# Note:
#
# 		The keyring_encrypted_file plugin is an extension included in MySQL EE.
#
# The keyring_encrypted_file plugin is a keyring plugin that stores keyring data in a encrypted
# file local to the server host.
#
# Warning:
#
# 		The keyring_encrypted_file plugin for encryption key management is not intended as a regulatory compliance solution.
# 		Security standards such as PCI, FIPS and others require use of key management systems to secure, manage and protect
# 		keys in key vaults or hardware security modules (HSMs)
#
# To install the keyring_encrypted_file plugin, use the general keyring installation instructions found earlier, together
# with the configuration information specific to keyring_encrypted_file found here.
#
# TO be usable during the server startup process, keyring_encrypted_file must be loaded using the --early-plugin-load
# option.
#
# TO specify the password for encrypting the keyring data file, set the keyring_encrypted_file_password system variable.
# (The password is mandatory; if not specified at server startup, keyring_encrypted_file initialization fails).
#
# THe keyring_encrypted_file_data system variable optionally configures the location of the file used by the 
# keyring_encrypted_file plugin for data storage.
#
# The default value is platform specific.
#
# To configure the file location explicitly, set the variable value at startup.
# For example, use these lines in the server my.cnf file (adjust the .so suffix and file location for your platform as necesary and subsittue your chosen PW):
#
# 	[mysqld]
# 	early-plugin-load=keyring_encrypted_file.so
# 	keyring_encrypted_file_data=/usr/local/mysql/mysql-keyring/keyring-encrypted
# 	keyring_encrypted_file_password=password
#
# Because the my.cnf file stores a PW when written as shown, it should have a restrictive mode and and be accesible 
# only to the account used to run the MySQL server.
#
# Keyring operations are transactional: The keyring_encrypted_file plugin uses a backup file during write operations to ensure
## that it can roll back to the original file if an operation fails.
#
# The backup file has the same name as the value of the keyring_encrypted_file_data system variable with a suffix of .backup
#
# For additional information about the system variables used to configure the keyring_encrypted_file plugin, see later.
#
# To ensure that keys are flushed only when the correct keyring storage file exists, keyring_encrypted file stores a
# SHA-256 checksum of the keyring in the file.
#
# Before updating the file, the plugin verifies that it contains the expected checksum.
#
# In addition, keyring_encrypted_file encrypts file contents using AES before writing the file,
# and decrypts the file contents after reading the file.
#
# The keyring_encrypted_file plugin supports the functions that comprise the standard keyring service interface.
#
# Keyring operations performed by those functions are accessible at two levels:
#
# ) SQL interface: In SQL statements, call the user-defined functions (UDFs)
#
# ) C interface: In C-language code, call the keyring service functions
#
# Example (using UDFs):
#
# 		SELECT keyring_key_generate('MyKey', 'AES', 32);
# 		SELECT keyring_key_remove('MyKey');
#
# THe key types permitted by keyring_encrypted_file are described later.
#
# USING THE KEYRING_OKV KMIP PLUGIN
#
# Note:
#
# 		The keyring_okv plugin is an extension included in MySQL EE.
#
# The Key Management Interoperability Protocol (KMIP) enables communication of cryptographic keys between
# a key management service and its clients.
#
# The keyring_okv keyring plugin uses the KMIP 1.1 protocol to communicate securely as a client of a KMIP backend.
#
# Keyring material is generated exclusively by the backend, not by keyring_okv.
#
# THe plugin works with these KMIP-compatible products:
#
# 		) Oracle Key Vault
#
# 		) Gemalto SafeNet KeySecure Appliance
#
# The keyring_okv plugin supports the functions that comprise the standard keyring service interface.
# Keyring operations performed by those functions are accessible at two levels:
#
# ) SQL interface: In SQL statements, call the user-defined functions (UDFs)
#
# ) C interface: In C-language code, call the keyring service function, described later
#
# Example (using UDFs):
#
# 		SELECT keyring_key_generate('MyKey', 'AES', 32);
# 		SELECT keyring_key_remove('MyKey');
#
# The key types permitted by keyring_okv are described later.
#
# TO install the keyring_okv plugin, use the general keyring installation instructions described earlier,
# together with the configuration information specific to keyring_okv found here:
#
# GENERAL KEYRING_OKV CONFIGURATION
#
# Regardless of which KMIP backend the keyring_okv plugin uses for keyring storage,
# the keyring_okv_conf_dir system variable configures the location of the directory used 
# by keyring_okv for its support files.
#
# The default value is empty, so you must set the variable to name a properly configured directory
# before the plugin can communicate with the KMIP backend.
#
# Unless you do so, keyring_okv writes a message to the error log during server startup that it cannot
# communicate:
#
# [Warning] Plugin keyring_okv reported: 'For keyring_okv to be initialized, please point the keyring_okv_conf_dir
# variable to a directory containing Oracle Key Vault configuration file and ssl materials'
#
# The keyring_okv_conf_dir variable must name a directory that contains the following items:
#
# ) okvclient.ora - A file that contains details of the KMIP backend with which keyring_okv will communicate.
#
# ) ssl - A directory that contains the certificate and key files required to establish a secure connection with the KMIP backend:
# 			CA.pem, cert.pem and key.pem.
#
# 			If the key file is password-protected, the ssl directory can contain a single-line text file named password.txt
# 			containing the password needed to decrypt the key file
#
# Both the okvclient.ora file and ssl directory with the certificate and key files are required for keyring_okv to work
# properly.
#
# The procedure used to populate the configuration directory with these files depends on the KMIP backend used with
# keyring_okv, as described elsewhere.
#
# The configuration directory used by keyring_okv as the location for its support files should have a restrictive
# mode and be accessible only to the account used to run the MySQL server.
#
# For example, on Unix and Unix based systems, to use the /usr/local/mysql/mysql-keyring-okv directory, the following
# commands (executed as root) create the directory and set its mode and ownership:
#
# 		cd /usr/local/mysql
# 		mkdir mysql-keyring-okv
# 		chmod 750 mysql-keyring-okv
# 		chown mysql mysql-keyring-okv
# 		chgrp mysql mysql-keyring-okv
#
# To be usable during the server startup process, keyring_okv must be loaded using the --early-plugin-load option.
# Also, set the keyring_okv_conf_dir system variable to tell the keyring_okv where to find its configurations dir.
#
# For example, use these lines in the server my.cnf file (adjust the .so suffix need be):
#
# 		[mysqld]
# 		early-plugin-load=keyring_okv.so
# 		keyring_okv_conf_dir=/usr/local/mysql/mysql-keyring-okv
#
# For additional info regarding keyring_okv_conf_dir - see later.
#
# CONFIGURING KEYRING_OKV FOR ORACLE KEY VAULT
#
# The discussion here assumes that you are familiar with Oracle Key Vault.
# Some pertinent info can be found externally.
#
# In Oracle Key Vault terminology, clients that use Oracle Key to store and retrieve security objects 
# are called endpoints.
#
# To communicate with Oracle Key Vault, it is necessary to register as an endpoint and enroll by downloading
# and installing endpoint support files.
#
# The following procedure briefly summarizes the process of setting up keyring_okv for use with Oracle Key Vault:
#
# 		1. Create the configuration directory for the keyring_okv plugin to use.
#
# 		2. Register an endpoint with Oracle Key Vault to obtain an enrollment token.
#
# 		3. Use the enrollment token to obtain the okvclient.jar client software download
#
# 		4. Install the client software to populate the keyring_okv configuration directory that contains the
# 			Oracle Key Vault support files.
#
# Use the following procedure to configure keyring_okv and Oracle Key Vault to work together.
# This description only summarizes how to interact with Oracle Key Vault.
#
# For details, visit the Oracle Key Vault site nad consult the Oracle Key Vault Administrator's Guide
#
# 1. Create the configuration directory that will contain the Oracle Key Vault support files, and make sure
# 		that the keyring_okv_conf_dir system variable is set to name that directory.
#
# 2. Log in to the Oracle Key Vault management console as a user who has the System Admin role.
#
# 3. Select the endpoints tab to arrive at the Endpoints page. On the endpoints page, click add..
#
# 4. Provide the required endpoint information to register.
# 		The endpoint type should be other.
#
# 		Successfully registering results in an enrollment token.
#
# 5. Log out from the Oracle Key Vault server.
#
# 6. Connect again to the Oracle Key Vault server, this time without logging in.
# 		Use the endpoint enrollment token to enroll and request the okvclient.jar software
# 		download.
#
# 		Save this file to your system.
#
# 7. install the okvclient.jar file using the following command (required JDK >= 1.4):
#
# 		java -jar okvclient.jar -d dir_name [-v]
#
# 		The directory name following the -d option is the location in which to install the extracted files.
#
# 		The -v option, if given, causes log information to be produced that may be useful if the command
# 		fails. 
#
# 		When the command asks for an Oracle Key Vault endpoint password, do not provide one.
# 		Instead, just press enter.
#
# 		(The result is that no PW will bw required when the endpoint connects to Oracle Key Vault)
#
# 8. The preceding command produces an okvclient.ora file, which should be in this location under the
# 		directory named by the -d option in the preceding java -jar command:
#
# 		install_dir/conf/okvclient.ora
#
# 		The file contents include lines that look something like this:
#
# 		SERVER=host_ip:port_num
# 		STANDBY_SERVER=host_ip:port_num
#
# 		The keyring_okv plugin attempts to communicate with the server running on the host named
# 		by the SERVER variable and falls back to STANDBY_SERVER if that fails:
#
# 			) For the SERVER variable, a setting in the okvclient.ora file is mandatory
#
# 			) For the STANDBY_SERVER variable, a setting in the okvclient.ora file is optional
#
# 9. Go to the Oracle Key Vault installer directory and test the setup by running this command:
#
# 		okvutil/bin/okvutil list
#
# 		The output should look something like this:
#
# 			Unique ID 									Type 				Identifier
# 			<value> 										Symmetric Key  -
# 			<value> 										Symmetric key  -
#
# 		For a fresh Oracle Key Vault server (a server without any key in it), the output looks like this instead,
# 		to indicate that there are no keys in the vault:
#
# 			no objects found
#
# 10. Use this command to extract the ssl directory containing SSL materials from the okvclient.jar file:
#
# 		jar xf okvclient jar ssl
#
# 11. Copy the Oracle Key Vault support files (the okvclient.ora file and the ssl directory) into the configuration directory.
#
# 12. (Optional) If you wish to password-protect the key file, use the instructions given later.
#
# After completing the procedure, restart the MySQL server. It loads the keyring_okv plugin and keyring_okv uses the file
# in its configuration directory to communicate with Oracle Key Vault.
#
# Configuring keyring_okv for Gemalto SafeNet KeySecure Appliance
#
# Gemalto SafeNet KeySecure Appliance uses the KMIP protocol (version 1.1 or 1.2).
# The keyring_okv keyring plugin (which supports KMIP 1.1) can use KeySecure as its KMIP backend for keyring storage.
#
# Use the following procedure to configure keyring_okv and KeySecure to work together.
# THe description only summarizes how to interact with KeySecure.
#
# For details, consult the section named Add a KMIP server in the KeySecure User Guide.
#
# 1. Create the configuration directory that will contain the KeySecure support files, and make sure
# 		that the keyring_okv_conf_dir system variable is set to name that directory.
#
# 		(For details, see the General keyring_okv Configuration)
#
# 2. In the configuration directory, create a subdirectory named ssl to use for storing the required
# 		SSL certificate and key files.
#
# 3. In the configuration directory, create a file named okvclient.ora. It should have the following format:
#
# 		SERVER=host_ip:port_num
# 		STANDBY_SERVER=host_ip:port_num
#
# 		For example, if KeySecure is running on host 198.51.100.20 and listening on port 9002, the okvclient.ora file looks like this:
#
# 		SERVER=198.51.100.20:9002
# 		STANDBY_SERVER=198.51.100.20:9002
#
# 4. Connect to the KeySecure Management Console as an administrator with credentials for Certificate Authorities access.
#
# 5. Navigate to Security >> Local CAs and create a local certificate authority (CA)
#
# 6. Go to Trusted CA lists. Select Default and click on Properties.
#
# 		Then select Edit for Trusted Certificate Authority List and add the CA just created.
#
# 7. Download the CA and save it in the SSL directory as a file named CA.pem
#
# 8. Navigate to Security >> Certificate Requests and create a certificate.
# 		Then you will be able to download a compressed tar file containing certificate PEM files.
#
# 9. Extract the PEM files from in the downloaded file.
# 		For example, if the file name is csr_w_pk_pkcs8.gz, decompress and unpack it using this command:
#
# 		tar zxvf csr_w_pk_pkcs8.gz
#
# 		Two files result from the extraction operation: certificate_request.pem and private_key_pkcs8.pem
#
# 10. Use this openssl command to decrypt the private key and create a file named key.pem:
#
# 		openssl pkcs8 -in private_key_pkcs8.pem -out key.pem
#
# 11. Copy the key.pem file into the ssl directory
#
# 12. Copy the certificate request in certificate_request.pem into the clipboard.
#
# 13. Navigate to Security >> Local CAs.
#
# 		Select the same CA that you created earlier (the one you downloaded to create the CA.pem file),
# 		and click Sign Request.
#
# 		Paste the Certificate Request from the clipboard, choose a certificate purpose of Client (the keyring is a client
# 		of KeySecure), and click Sign Reqeuest.
#
# 		The result is a certificate signed with the selected CA in a new page.
#
# 14. Copy the signed certificate to the clipboard, then save the clipboard contents as a file named cert.pem in the ssl directory.
#
# 15. (Optional) If you wish to password-protect the key file, use the instructions in Password-Protecting the keyring_okv Key File.
#
# After completing the preceding procedure, restart the MySQL server.
#
# It loads the keyring_okv plugin and keyring_okv uses the files in its configuration directory to
# communicate with KeySecure.
#
# Password-Protecting the keyring_okv Key File
#
# You can optionally protect the key file with a password and supply a file containing the password to enable the key
# file to be decrypted.
#
# To do so, change location to the ssl directory and perform these steps:
#
# 		1. Encrypt the key.pem key file. For example, use a command like this, and enter the encryption password at the prompts:
#
# 			openssl rsa -des3 -in key.pem -out key.pem.new
# 			Enter PEM pass phrase:
# 			Verifying - Enter PEM pass phrase:
#
# 		2. Save the encryption password in a single-line text file named password.txt in the ssl directory.
#
# 		3. Verify that the encrypted key file can be decrypted using the following command.
#
# 			The decrypted file should display on the console:
#
# 			openssl rsa -in key.pem.new -passin file.password.txt
#
# 		4. Remove the original key.pem file and rename key.pem.new to key.pem
#
# 		5. Change the ownership and access mode of new key.pem file and password.txt file as
# 			necessary to ensure that they have the same restrictions as other files in the SSL Dir.
#
# USING THE KEYRING_AWS AMAZON WEB SERVICES KEYRING PLUGIN
#
# Note:
# 		The keyring_aws plugin is an extension included in MySQL EE.
#
# The keyring_aws plugin is a keyring plugin that communicates with the Amazon Web Services Key Management Service 
# (AWS KMS) as a backend for key generation and uses a local file for key storage.
#
# All keyring material is generated exclusively by the AWS server, not by keyring_aws.
#
# keyring_aws is available on these platforms:
#
# 		) Debian 8
#
# 		) EL7
#
# 		) macOS 10.12
#
# 		) OS X 10.10 and 10.11
#
# 		) SLES 12
#
# 		) Ubuntu 14.04 and 16.04
#
# 		) Windows
#
# The discussion here assumes that you are familiar with AWS in general and KMS in particular.
# SOme pertinent info sources:
#
# 	<AWS site>
#
# 	<KMS docs>
#
# The following section provide configuration and usage information for the keyring_aws keyring plugin.
#
# KEYRING_AWS CONFIGURATION
#
# To install the keyring_aws plugin, use the general installation instructions found in the installation part,
# together with the plugin-specific configuration information found here.
#
# THe plugin library contains the keyring_aws plugin and two user-defined functions (UDFs),
# keyring_aws_rotate_cmk() and keyring_aws_rotate_keys().
#
# To configure keyring_aws, you must obtain a secret access key that provides credentials for
# communicating with AWS KMS and write it to a configuration file:
#
# 1. Create an AWS KMS account
#
# 2. Use AWS KMS to create a secret access key ID and secret access key.
# 		The access key serves to verify your identity and that of your applications.
#
# 3. Use the AWS KMS account to create a customer master key (CMK) ID.
# 		At MySQL startup,, set the keyring_aws_cmk_id system variable to the CMK ID value.
#
# 		This variable is mandatory and there is no default. (Its value can be changed at runtime if desired using SET_GLOBAL)
#
# 4. If necessary, create the directory in which the configuration file will be located.
#
# 		The directory should have a restrictive mode and be accessible only to the account
# 		used to run the MySQL server.
#
# 		For example, on UNIX based systems, to use /usr/local/mysql/mysql-keyring/keyring_aws_conf as the
# 		file name, the following commands (executed as root) create its parent directory and set the directory
# 		mode and ownership:
#
# 			cd /usr/local/mysql
# 			mkdir mysql-keyring
# 			chmod 750 mysql-keyring
# 			chown mysql mysql-keyring
# 			chgrp mysql mysql-keyring
#
# 		At MySQL startup, set the keyring_aws_conf_file system variable to /usr/local/mysql/mysql-keyring/keyring_aws_conf to indicate
# 		the configuration file location to the server.
#
# 5. Prepare the keyring_aws configuration file, which should contain two lines:
#
# 		) Line 1: The secret access key ID
#
# 		) Line 2: The secret access key
#
# 		For example, if the key ID is 10xEXAMPLE and the key is 10y/10z/10x, the config file looks like this:
#
# 			10xEXAMPLE
# 			10y/10z/10x
#
# To be usable during the server startup process, keyring_aws must be loaded using the --early-plugin-load option.
#
# The keyring_aws_cmk_id system variable is mandatory and configures the customer master key (CMK) Id obtained from
# the AWS KMS server.
#
# The keyring_aws_conf_file and keyring_aws_data_file system variables optionally configure the locations of the
# files used by the keyring_aws plugin for configuration information and data storage.
#
# The file location variable default values are platform specific.
#
# To configure the locations explicitly, set the variable values at startup.
#
# For example, use these lines in the server my.cnf file (adjust the .so if needed):
#
# 		[mysqld]
# 	 	early-plugin-load=keyring_aws.so
# 		keyring_aws_cmk_id='arn:aws:kms:us-west-2:111111111222222223333333:key/abcd1234etc.'
# 		keyring_aws_conf_file=/usr/local/mysql/mysql-keyring/keyring_aws_conf
# 		keyring_aws_data_file=/usr/local/mysql/mysql-keyring/keyring_aws_data
#
# For the keyring_aws plugin to start successfully, the configuration file must exist and contain
# valid secret access key information, intiailized as described previously.
#
# The storage file need not exist. If it does not, keyring_aws attempts to create it
# (as well as its parent directory, if necessary)
#
# For additional information about the system variables used to configure the keyring_aws plugin,
# see later.
#
# Start the MySQL server and install the UDFs associated with the keyring_aws plugin.
#
# This is a one-time operation, performed by executing the following statements
# (Adjust the .so need be):
#
# 		CREATE FUNCTION keyring_aws_rotate_cmk RETURNS INTEGER SONAME 'keyring_aws.so';
# 		CREATE FUNCTION keyring_aws_rotate_keys RETURNS INTEGER SONAME 'keyring_aws.so';
#
# KEYRING_AWS OPERATION
#
# At plugin startup, the keyring_aws plugin reads the AWS secret access key ID and key from its configuration file.
# It also reads any encrypted keys contained in its storage file into its in-memory cache.
#
# During operation, keyring_aws maintains encrypted keys in the in-memory cache and uses the storage file as
# local persistent storage.
#
# Each keyring operation is transactional: keyring_aws either successfully changes both the in-memory key cache
# and the keyring storage file; or the operation fails and the keyring state remains unchanged.
#
# To ensure that keys are flushed only when the correct keyring storage file exists, keyring_aws stores a
# SHA-256 checksum of the keyring in the file.
#
# Before updating the file, the plugin verifies that it contains the expected checksum.
#
# The keyring_aws plugin supports the functions that comprise the standard keyring service interface.
# Keyring operations performed by these functions are accessible at two levels:
#
# ) C interface: In C-language code, call the keyring-service functions described later
#
# ) SQL interface: In SQL statements, call the user-defined functions (UDFs) described later
#
# Example (using UDFs):
#
# 		SELECT keyring_key_generate('MyKey', 'AES', 32);
# 		SELECT Keyring_key_remove('MyKey');
#
# In addition, the keyring_aws_rotate_cmk() and keyring_aws_rotate_keys() UDFs "extend" the keyring plugin
# interface to provide AWS-related capabilities not covered by the standard keyring service interface.
#
# These capabilities are accessible only by calling the UDFs.
#
# There are no corresponding C-language key service functions.
#
# The key types permitted by keyring_aws are described later.
#
# KEYRING_AWS CREDENTIAL CHANGES
#
# Assuming that the keyring_aws plugin has initialized properly at server startup, it is possible to change the credentials
# used for communicating with AWS KMS:
#
# 	1. Use AWS KMS to create a new secret access key ID and secret access key.
#
# 	2. Store the new credentials in the configuration file (the file named by the keyring_aws_conf_file system variable).
#
# 		The file format is as described previously.
#
# 	3. Reinitialize the keyring_aws plugin so that it rereads the configuration file.
# 
# 		Assuming that the new credentials are valid, the plugin should initialize successfully.
#
# 		There are two ways to reinitialize the plugin:
#
# 			) Restart the server. This is simpler and has no side effects, but is not suitable for installations that require
# 				minimal server downtime with as few restarts as possible.
#
# 			) Reinitialize the plugin without restarting the server by executing the following statements (adjust the .so suffix as called for):
#
# 				UNINSTALL PLUGIN keyring_aws;
# 				INSTALL PLUGIN keyring_aws SONAME 'keyring_aws.so';
#
# 		Note:
#
# 			In addition to loading a plugin at runtime, INSTALL_PLUGIN has the side effect of registering the plugin in the mysql.plugin system table.
#
# 			Because of this, if you decide to stop using keyring_aws, it is not sufficient to remove the --early-plugin-load
# 			option from the set of options used to start the server.
#
# 			That stops the plugin from loading early, but the server still attempts to load it when
# 			it gets to the point in the startup sequence where it loads the plugins registered in mysql.plugin
#
# 			Consequently, if you execute the UNINSTALL_PLUGIN plus INSTALL_PLUGIN sequence just described to change
# 			the AWS KMS credentials, then to stop using keyring_aws, it is necessary to execute UNINSTALL_PLUGIN again to
# 			unregister the plugin in addition to removing the --early-plugin-load option.
#
# MIGRATING KEYS BETWEEN KEYRING KEYSTORES
#
# The MySQL server supports an operational mode that enables migration of keys between underlying
# keyring keystores.
#
# This enables DBAs to switch a MySQL installation from one keyring plugin to another.
#
# A migration server (that is, a server started in key migration mode) does not accept client connections.
# 
# Instead, it runs only long enough to migrate keys, then exits.
#
# A migration server reports errors to the console (the standard error output)
#
# It is possible to perform offline or online key migration:
#
# 		) If you are sure that no running server on the local host is using the source or destination keystore,
# 			an offline migration is possible.
#
# 			In this case, the migration server can modify the keystores without possibility of a running server
# 			modifying keystore content during the migration.
#
# 		) If a running server on the local host is using the source or destination keystore, an online migration
# 			must be performed.
#
# 			In this case, the migration server connects to the running server and instructs it to pause keyring operations
# 			while key migration is in progress.
#
# The result of a key migration operation is that the destination keystore contains the keys it had prior to the migration,
# plus the keys from the source keystore.
#
# THe source keystore is the same before and after the migration because keys are copied, not moved.
#
# If a key to be copied already exists in the destination keystore, an error occurs and the destination keystore
# is restored to its premigration state.
#
# The user who invokes the server in key-migration mode must not be the root system user, and must have
# permission to read and write the keyring files.
#
# To perform a key migration operation, determine which key migration options are needed.
#
# Migration options indicate which keyring plugins are involved,, and whether to perform an
# offline or online migration.
#
# ) TO indicate the source and destination keyring plugins, specify these options:
#
# 		) --keyring-migration-source: The source keyring plugin that manages the keys to be migrated.
#
# 		) --keyring-migration-destination: The destination keyring plugin to which the migrated keys are to be copied.
#
# 		These options tell the server to run in key migration mode. Both options are mandatory for all key migration
# 		operations.
#
# 		The source and destination plugins must differ, and the migration server must support both plugins.
#
# ) For an offline migration, no additional key migration options are needed.
#
# 	WARNING:
#
# 		Do not perform an offline migration involving a keystore that is in used by a running server.
#
# ) For an online migration, some running server currently is using the source or destination keystore.
#
# 		Specify the key migration options that indicate how to connect to the running server.
#
# 		This is necessary so that hte migration server can connect to the running server and tell it to
# 		pause keyring use during the migration operation.
#
# 		uSe of any of the following options signifies an online migration:
#
# 			) --keyring-migration-host: The host where the running server is located. This is always the local host.
#
# 			) --keyring-migration-user, --keyring-migration-password: The user name and PW for the account to use to connect to the running server.
#
# 			) --keyring-migration-port: For TCP/IP Connections, the port number to connect on the running server.
#
# 			) --keyring-migration-socket: For UNIX socket file or Windows named pipe connections, the socket file or named pipe to connect to
# 													on the running server.
#
# For additional details about the key migration options, see later.
#
# Start the migration server with the key migration options determined as just described, possibly with other options.
#
# Keep the following considerations in mind:
#
# 		) Other server options might be required, such as other configuration parameters for the two keyring plugins.
#
# 		For example, if keyring_file is one of the plugins, you must set the keyring_file_data system variable if the keyring
# 		data file location is not the default location.
#
# 		Other non-keyring options may be required as well.
#
# 		One way to specify these options is by using --defaults-file to name an option file that contains the required options.
#
# 		) If you invoke the migration server from a system account different from that normally used to run MySQL, it might create
# 			keyring directories or files that are inaccessible to the server during normal operations.
#
# 			Suppose that mysqld normally runs as the mysql system user, but you invoke the migration server while logged in
# 			as isabel.
#
# 			Any new directories or files created by the migration server will be owned by isabel.
#
# 			Subsequent startup will fail when a server run as the mysql system user attempts to access file system
# 			objects owned by isabel.
#
# 			To avoid this problem, start the migration server as the root system user and provide a --user=user_name option,
# 			where user_name is the system account normally used to run MySQL.
#
# 		) The migration server expects path name options values to be full paths.
#
# 			Relative path names may not be resolved as you expect.
#
# Example command line for offline key migration:
#
# 		mysqld --defaults-file=/usr/local/mysql/etc/my.cnf
# 			--keyring-migration-source=keyring_file.so
# 			--keyring-migration-destination=keyring_encrypted_file.so
# 			--keyring_encrypted_file_password=password
#
# Example command line for online key migration:
#
# 		mysqld --defaults-file=/usr/local/mysql/etc/my.cnf
# 			--keyring-migration-source=keyring_file.so
# 			--keyring-migration-destination=keyring_encrypted_file.so
# 			--keyring_encrypted_file-password=password
# 			--keyring-migration-host=localhost
# 			--keyring-migration-user=root
# 			--keyring-migration-password=root_password
#
# The key migration server performs the migration operation as follows:
#
# 	1. (Online migration only) Connect to the running server using the connection options.
#
# 		The account used to connect must have the privileges required to modify the
# 		global keyring_operations system variable (ENCRYPTION_KEY_ADMIN in addition to either SYSTEM_VARIABLES_ADMIN or SUPER)
#
# 	2. (Online migration only) Disable keyring_operations on the running server. ( The running server must support keyring_operations)
#
# 	3. Load the source and destination keyring plugins.
#
# 	4. Copy keys from the source keyring to the destination keyring.
#
# 	5. Unload the keyring plugins.
#
#  6. (Online migration only) Enable keyring_operations on the running server.
#
#  7. (Online migration only) Disconnect from the running server
#
# 	8. Exit
#
# If an error occurs during key migration, any keys that were copied to the destination plugin are removed,
# leaving the destination keystore unchanged.
#
# Important:
#
# 		For an online migration operation, the migration server takes care of enabling and disabling keyring_operations on the running server.
#
# 		However, if the migration server exits abnormally (for example, if someone forcibly terminates it), it is possible
# 		that keyring_operations will not have been re-enabled on the running server, leaving it unable to perform keyring operations.
#
# 		In this case, it may be necessary to connect to the running server and enable keyring_operations manually.
#
# After a successful online key migration operation, the running server might need to be restarted:
#
# 		) If the running server was using the source keystore, it need not be restarted after the migration.
#
# 		) If the running server was using the source keystore before the migration but should use the destination keystore after the migration,
# 			it must be reconfigured to use the destination keyring plugin and restarted.
#
# 		) If the running server was using the destination keystore and will continue to use it, it should be restarted after the migration
# 			to load all keys migrated into the destination keystore.
#
# NOTE:
#
# 		MySQL server key migration mode supports pausing a single running server.
#
# 		To perform a key migration if multiple key servers are using the keystores involved,
# 		use this procedure:
#
# 			1. Connect each running server manually and set keyring_operations=OFF
#
# 			2. Use the migration server to perform an offline key migration.
#
# 			3. Connect to each running server manually and set keyring_operations=ON
#
# ALl running servers must support the keyring_operations=ON system variable.
#
# SUPPORTED KEYRING KEY TYPES
#
# MySQL keyring supports generating keys of different types (encryption algorithms) and lengths.
#
# The available key types depend on which keyring plugin is installed.
# A given plugin may also impose constraints on key lengths per key type.
#
# The following table summarizes the permitted key types per keyring plugin.
# Lengths are in bytes.
#
# For a key generated using one of the keyring user-defined functions (UDFs) described later,
# the length can be no longer than 2,048 bytes, due to limitations of the UDF interface.
#
# KEYRING PLUGIN KEY TYPES
#
# Plugin Name 						Permitted Key Type 						Permitted Key lengths for Key Type
#
# keyring_encrypted_file 		AES DSA RSA 								No special restrictions
#
# keyring_file 					AES DSA RSA 								NO special restrictions
#
# keyring_okv 						AES 											16, 24, 32
#
# keyring_aws 						AES 											16, 24, 32
#
# GENERAL PURPOSE KEYRING KEY MANAGEMENT FUNCTIONS
#
# MySQL Server supports a keyring service that enables internal server components and plugins to securly store sensetive information for later retrieval.
#
# MySQL Server also includes an SQL interface for keyring key management, implemented as a set of general-purpose user-defined functions
# (UDFs) that access the functions provided by the internal keyring service.
#
# The keyring UDFs are contained in a plugin library file, which also contains a keyring_udf plugin that must be
# enabled prior to UDF invocation.
#
# For these UDFs to be used, a keyring plugin such as keyring_file or keyring_okv must be enabled.
#
# The UDFs described here are general purpose and intended for use with any keyring plugin.
#
# A given keyring plugin might have UDFs of its own that are intended for use only with that plugin.
#
# THe following section provides installation instructions for the keyring UDFs and demonstrates how to use them.
# For information about the keyring service functions invoked by teh UDFs, see later.
#
# INSTALLING OR UNINSTALLING GENERAL-PURPOSE KEYRING FUNCTIONS
#
# This section describes how to install or uninstall the keyring user-defined functions (UDFs), which are implemented
# in a plugin library file that also contains a keyring_udf plugin.
#
# For general information about installing or uninstalling plugins and UDFs, see later.
#
# The keyring UDFs enable keyring management operations, but the keyring_udf plugin must also be installed
# because the UDFs will not work correctly without it.
#
# Attempts to use the UDFs without hte keyring_udf plugin result in an error.
#
# TO be usable by the server, the plugin library file must be located in the MySQL plugin directory (the directory named
# by the plugin_dir system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is keyring_udf. The file name suffix differs per platform (for example,
# .so is UNIX based, .dll for Windows)
#
# To install the keyring_udf plugin and the UDFs, use the INSTALL_PLUGIN and CREATE_FUNCTION statements
# (Adjust the .so suffix if need be):
#
# INSTALL PLUGIN keyring_udf SONAME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_generate RETURNS INTEGER
# 		SONAME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_fetch RETURNS STRING
# 		SONAME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_length_fetch RETURNS INTEGER
# 		SONAME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_type_fetch RETURNS STRING
# 		SONAME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_store RETURNS INTEGER
# 		SOANME 'keyring_udf.so';
#
# CREATE FUNCTION keyring_key_remove RETURNS INTEGER
# 		SONAME 'keyring_udf.so';
#
# If the plugin and UDFs are used on a master replication server, install them on all slave servers as well, to avoid replication
# problems.
#
# Once installed as just described, the plugin and UDFs remain installed until uninstalled.
#
# To remove them, use the UNINSTALL_PLUGIN and DROP_FUNCTION statements:
#
# 		UNINSTALL PLUGIN keyring_udf;
# 		DROP FUNCTION keyring_key_generate;
# 		DROP FUNCTION keyring_key_fetch;
# 		DROP FUNCTION keyring_key_length_ fetch;
#
# 		DROP FUNCTION keyring_key_type_fetch;
# 		DROP FUNCTION keyring_key_store;
# 		DROP FUNCTION keyring_key_remove;
#
# USING GENERAL-PURPOSE KEYRING FUNCTIONS
#
# Before using the keyring user-defined functions (UDFs), install them according to the instructions provided later.
#
# The keyring UDFs are subject to these constraints:
#
# 		) To use any keyring UDF, the keyring_udf plugin must be enabled.
# 			Otherwise, an error occurs:
#
# 			ERROR 1123 (HY000): Can't initialize function 'keyring_key_generate';
# 			This function requires keyring_udf plugin which is not installed.
# 			Please install
#
# 			To install the keyring_udf plugin, see later.
#
# 		) The keyring UDFs invoke keyring service (see later)
#
# 			These service functions in turn use whatever keyring plugin is installed
# 			(for example, keyring_file or keyring_okv).
#
# 			Therefore, to use any keyring UDF, some underlying keyring plugin must be installed.
#
# 			Otherwise, an error occurs:
#
# 				ERROR 3188 (HY000): Function 'keyring_key_generate' failed because underlying keyring
# 				service returned an error.
#
# 				Please check if a keyring plugin is installed and that provided arguments are valid for the
# 				keyring you are using.
#
# 			To install a keyring plugin, see earlier.
#
# 		) To use any keyring UDF, a user must possess the global EXECUTE privilege.
# 			Otherwise, an error occurs:
#
# 				ERROR 1123 (HY000): Can't initialize function 'keyring_key_generate';
# 				The user is not privileged to execute this function.
# 				Use needs EXECUTE privilege.
#
# 			To grant the global EXECUTE privilege, use this statement:
#
# 				GRANT EXECUTE ON *.* TO user;
#
# 			Alternatively, should you prefer to avoid granting the global EXECUTE privilege while still permitting
# 			users to access specific key-management operations, "wrapper" stored programs can be defined
# 			(a technique described later in this section)
#
# 		) A key stored in the keyring by a given user can be manipulated later only by the same user.
#
# 			That is, the value of the CURRENT_USER() function at the time of key manipulation, must have the
# 			same value as when the key was stored in the keyring.
#
# 			(This constraint rules out the use of the keyring UDFs for manipulation of instance-wide keys, such as
# 			those created by InnoDB support tablespace encryption)
#
# 			To enable multiple users to perform operations on the same key, "wrapper" stored programs can be defined
# 			(a technique described later in these sections)
#
# 		) Keyring UDFs support the key types and lengths supported by the underlying keyring plugin, with the additional
# 			constraint that keys cannot be longer than 2,048 bytes (16,384 bits), due to limitations on the UDF interface.
#
# TO create a new random key and store it in the keyring, call keyring_key_generate(), passing to it an ID for the key,
# along with the key type (encryption method) and its length in bytes.
#
# The following call creates a 2,048-bit DSA-encrypted key named MyKey
#
# SELECT keyring_key_generate('MyKey', 'DSA', 256);
# +------------------------------------------------+
# | keyring_key_generate('MyKey', 'DSA', 256) 		|
# +------------------------------------------------+
# | 														1 		|
# +------------------------------------------------+
#
# a return value of 1 indicates success.
#
# IF the key cannot be created, the return value is NULL and an error occurs.
# One reason this might occur, is that hte underlying keyring plugin does not support the specified
# combination of key type and key length. See earlier.
#
# To be able to check the return type regardless of whether an error occurs, use SELECT ... INTO @var_name and
# test the variable value:
#
# SELECT keyring_key_generate('','',-1) INTO @x;
# ERROR 3188 (HY000): Function 'keyring_key_generate' failed because underlying keyring service
# returned an error.
#
# Please check if a keyring plugin is installed and that provided arguments are valid for the keyring
# you are using.
#
# SELECT @x;
# +--------+
# | @x 	  |
# +--------+
# | NULL   |
# +--------+
#
# SELECT keyring_key_generate('x', 'AES', 16) INTO @x;
# SELECT @x;
# +--------+
# | @x 	  |
# +--------+
# | 		1 |
# +--------+
#
# This technique also applies to other keyring UDFs that for failure return a value and an error.
#
# The ID passed to keyring_key_generate() provides a means by which to refer ot the key in subsequent UDF calls.
# For example, use the key ID to retrieve its type as a string or its length in bytes as an integer.
#
# SELECT keyring_key_type_fetch('MyKey');
# +--------------------------------------+
# | keyring_key_type_fetch('MyKey') 	  |
# +--------------------------------------+
# | DSA 											  |
# +--------------------------------------+
#
# SELECT keyring_key_length_fetch('MyKey');
# +---------------------------------------+
# | keyring_key_length_fetch('MyKey') 		|
# +---------------------------------------+
# | 					256 							|
# +---------------------------------------+
#
# To retrieve a key value, pass the key ID to keyring_key_fetch().
#
# The following example uses HEX() to display the key value because it may contain nonprintable
# chars.
#
# The example also uses a short key for brevity, but be aware that longer keys provide better security:
#
# SELECT keyring_key_generate('MyShortKey', 'DSA' 8);
# +---------------------------------------------------+
# | keyring_key_generate('MyShortKey', 'DSA', 8) 		|
# +---------------------------------------------------+
# | 																1 	|
# +---------------------------------------------------+
#
# SELECT HEX(keyring_key_fetch('MyShortKey'));
# +-------------------------------------------------+
# | HEX(keyring_key_fetch('MyShortKey')) 				 |
# +-------------------------------------------------+
# | <value> 													 |
# +-------------------------------------------------+
#
# Keyring UDFs treat key IDs, types and values as binary strings, so comparisons are case-sensitive.
# For example, IDs of MyKey and mykey refer to different keys.
#
# To remove a key, pass the key ID to keyring_key_remove():
#
# 	SELECT keyring_key_remove('MyKey');
# +-----------------------------------+
# | keyring_key_remove('MyKey') 		  |
# +-----------------------------------+
# | 1 										  |
# +-----------------------------------+
#
# To obfuscate and store a key that you provide, pass the key ID, type and value to keyring_key_store():
#
# 	SELECT keyring_key_store('AES_key', 'AES', 'Secret string');
# +------------------------------------------------------------+
# | keyring_key_store('AES_key', 'AES', 'Secret string') 		|
# +------------------------------------------------------------+
# | 1 																		   |
# +------------------------------------------------------------+
#
# As indicated previously, a user must have the global EXECUTE privilege to call keyring UDFs, and the user who
# stores a key in the keyring initially must be the same user who performs subsequent operations on the key later, as determined
# from the CURRENT_USER() value in effect for each UDF call.
#
# To permit key operations to users who do not have the global EXECUTE privilege, or who may not be the
# key "owner", use this technique:
#
# 1. Define "wrapper" stored programs that encapsulate the required key operations and have a DEFINER value equal to the key owner.
#
# 2. Grant the EXECUTE privilege for specific stored programs to the individual users who should be able to invoke them.
#
# 3. If the operations implemented by the wrapper stored programs do not include key creation, create any necessary keys in advance,
# 		using the account named as the DEFINER in the stored program definitions.
#
# This technique enables keys to be shared among users and provides to DBAs more fine-grained control over who can do what
# with keys, without having to grant global privs.
#
# The following eample shows how to set up a shared key named SharedKey that is owned by the DBA, and a get_shared_key()
# stored function that provides access to the current key value.
#
# THe value can be retrieved by any user with the EXECUTE privilege for that function, which is created in the key_schema schema.
#
# From a MySQL administrative account ('root'@'localhost' in this example), create the administrative schema and the stored
# function to access the key:
#
# CREATE SCHEMA key_schema;
#
# CREATE DEFINER = 'root'@'localhost'
# FUNCTION key_schema.get_shared_key()
# RETURNS BLOB READS SQL DATA 
# RETURN keyring_key_fetch('SharedKey');
#
# From the administrative account, ensure that the shared key exists:
#
# SELECT keyring_key_generate('SharedKey', 'DSA', 8);
# +----------------------------------------------+
# | keyring_key_generate('SharedKey', 'DSA', 8)  |
# +----------------------------------------------+
# | 														1 	 |
# +----------------------------------------------+
#
# From the administrative account, create an ordinary user account to which key access is to be granted:
#
# CREATE USER 'key_user'@'localhost'
# IDENTIFIED BY 'key_user_pwd';
#
# From the key_user account, verify that without the proper EXECUTE privilege, the new account cannot
# access the shared key:
#
# SELECT HEX(key_schema.get_shared_key());
# ERROR 1370 (42000): execute command denied ot user 'key_user'@'localhost'
# for routine 'key_schema.get_shared_key'
#
# For the administrative account, grant EXECUTE to key_user for the stored function:
#
# GRANT EXECUTE ON FUNCTION key_schema.get_shared_key TO 'key_user'@'localhost';
#
# From the key_user account, verify that the key is now accessible:
#
# SELECT HEX(key_schema.get_shared_key());
# +--------------------------------------+
# | HEX(key_schema.get_shared_key()) 	  |
# +--------------------------------------+
# | <value> 									  |
# +--------------------------------------+
#
# GENERAL-PURPOSE KEYRING FUNCTION REFERENCE
#
# For each general-purpose keyring user-defined function (UDF), this section describes its purpose,
# calling sequence, and return value.
#
# For information about the conditions under which these UDFs can be invoked, see later.
#
# ) keyring_key_fetch(key_id)
# 	
# 		Given a key ID, deobfuscates and returns the key value.
#
# 		Args:
# 			) key_id:A string that specifies the key ID.
#
# 		Returns:
#
# 			Reutnrs the key value as a string for success, NULL if the key does not exist, or NULL and an error for failure.
#
# 		NOTE: 
#
# 			Keyring values retrieved using keyring_key_fetch() are limited to 2,048 bytes, due to limitations of the UDF interface.
# 			A keyring value longer than that length can be stored using a keyring service function, but if retreived using
# 			keyring_key_fetch() - it is truncated to 2,048 bytes.
#
# Example:
#
# SELECT keyring_key_generate('RSA_key', 'RSA', 16);
# +---------------------------------------------------+
# | keyring_key_generate('RSA_key', 'RSA', 16) 		   |
# +---------------------------------------------------+
# | 																1  |
# +---------------------------------------------------+
#
# SELECT HEX(keyring_key_fetch('RSA_key'));
# +----------------------------------------+
# | HEX(keyring_key_fetch('RSA_key')) 		 |
# +----------------------------------------+
# | <value> 										 |
# +----------------------------------------+
#
# SELECT keyring_key_type_fetch('RSA_key');
# +-----------------------------------------+
# | keyring_key_type_fetch('RSA_key') 		  |
# +-----------------------------------------+
# | RSA 												  |
# +-----------------------------------------+
#
# SELECT keyring_key_length_fetch('RSA_key');
# +-----------------------------------------+
# | keyring_key_length_fetch('RSA_key') 	  |
# +-----------------------------------------+
# | 										16 		  |
# +-----------------------------------------+
#
# The example uses HEX() to display the keyy value because it may contain nonprintable chars.
# The example also uses a short key for brevity, but be aware that longer keys are safer.
#
# ) Keyring_key_generate(key_id, key_type, key_length)
#
# Generates a new random key with a given ID, type and length, and stores it in the keyring.
#
# The type and length values must be consistent with the values supported by the underlying
# keyring plugin, with the additional constraint that keys cannot be longer than 2,048 bytes (16,384 bits),
# due to limitations of the UDF interface.
#
# For the permitted types per plugin, see later.
#
# Arguments:
#
# 		) key_id:A string that specifies the key ID.
#
# 		) key_type: A string that specifies the key type
#
# 		) key_length: a integer that specifies the key length in bytes. Max length is 2,048
#
# Return value:#
#
# 		Returns 1 for success, or NULL and an error for failure.
#
# Example:
#
# 		SELECT keyring_key_generate('RSA_key', 'RSA', 384);
# 		+--------------------------------------------------+
#  	| keyring_key_generate('RSA_key', 	'RSA', 384) 	|
# 		+--------------------------------------------------+
# 		| 																1 	|
# 		+--------------------------------------------------+
#
# ) keyring_key_length_fetch(key_id)
#
# 		Given a key ID, returns the key length.
#
# 		Arguments:
#
# 			) key_id: A string that specifies the key ID.
#
# 		Return value:
#
# 			Returns the key length in bytes as an integer for success, NULL if the key does not exist, or NULL and an error for failure.
#
# 		Example:
#
# 		See the description of keyring_key_fetch()
#
# ) keyring_key_remove(key_id)
#
# Removes the key with a given ID from the keyring.
#
# Arguments:
#
# 		) key_id: A string that specifies the key ID.
#
# 	Return value:
#
# 		Returns 1 for success, or NULL for failure.
#
# 	Example:
#
# 		SELECT keyring_key_remove('AES_key');
# 		+------------------------------------------+
# 		| keyring_key_remove('AES_key') 				 |
# 		+------------------------------------------+
# 		| 											1 			 |
# 		+------------------------------------------+
#
# ) keyring_key_store(key_id, key_type, key)
#
#  Obfuscates and stores a key in the keyring.
#
# 		Arguments:
#
# 			) key_id: A string that specifies the key ID.
#
# 			) key_type: A string that specifies the key type.
#
# 			) key: A string that specifies the key value.
#
# 		Return value:
#
# 		Returns 1 for success, or NULL and an error for failure.
#
# 		Example:
#
# 			SELECT keyring_key_store('new key', 'DSA', 'My key value');
# 			+-----------------------------------------------------------+
# 			| keyring_key_store('new key', 'DSA', 'My key value' 			|
# 			+-----------------------------------------------------------+
# 			| 																1 				|
# 			+-----------------------------------------------------------+
#
# ) keyring_key_type_fetch(key_id)
#
# 	Given a key ID, returns the key type.
#
# 	Arguments:
#
# 		) key_id: A string that specifies the key ID.
#
# 	Return value:
#
# 		Returns the key type as a string for success, NULL if the key does not exist, and an error for failure.
#
# 	Example:
#
# 		See the description of keyring_key_fetch()
#
# PLUGIN-SPECIFIC KEYRING KEY-MANAGEMENT FUNCTIONS
#
# For each keyring plugin-specific user-defined function (UDF), this section describes its purpose, calling sequence, and return value.
#
# For information about general-purpose keyring UDFs, see earlier.
#
# ) keyring_aws_rotate_cmk()
#
# 		This UDF is associated with the keyring_aws plugin. Its use requires the SUPER Privilege.
#
# 		keyring_aws_rotate_cmk() rotates the customer master key (CMK).
# 		Rotation changes only the key that AWS KMS uses for subsequent data key-encryption operations.
#
# 		AWS KMS maintains previous CMK versions, so keys generated using previous CMKs remain decryptable
# 		after rotation.
#
# 		Rotation changes the CMK values used inside AWS KMS but does not change the ID used to refer to it,
# 		so there is no need to change the keyring_aws_cmk_id system variable after calling keyring_aws_rotate_cmk().
#
# 		Arguments: NONE
#
# 		Return value: Returns 1 for success, or NULL and an error for failure.
#
# ) keyring_aws_rotate_keys()
#
# 		This UDF is associated with the keyring_aws plugin. Its use requires the SUPER privilege.
#
# 		keyring_aws_rotate_keys() rotates keys stored in the keyring_aws storage file named by the keyring_aws_data_file
# 		system variable.
#
# 		Rotation sends each key stored in the to AWS KMS for re-encryption using the value of the keyring_aws_cmk_id system
# 		variable as the CMK value, and stores the new encrypted keys in the file.
#
# 		keyring_aws_rotate_keys() is useful for key re-encryption under these circumnstances:
#
# 			) After rotating the CMK; that is, after invoking the keyring_aws_rotate_cmk() UDF
#
# 			) After changing the keyring_aws_cmk_id system variable to a different key value
#
# 		Arguments: None
#
# 		Return value:. 1 for success, NULL and an error for failure.
#
# KEYRING COMMAND OPTIONS
#
# MySQL supports the following keyring-related command-line options:
#
# 		) --keyring-migration-destination=plugin
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-destination=plugin_name
# 			Introduced: 		8.0.4
# 			Type: 				String
#
# 			The destination keyring plugin for key migration.
# 			See later.
#
# 			The format and interpretation of the option value is the same as described
# 			for the --keyring-migration-source option.
#
# 			NOTE:
#
# 				--keyring-migration-source and --keyring-migration-destination are mandatory for all keyring
# 				migration operations.
#
# 				The source and destination plugins must differ, and the migration server must support both plugins.
#
# 		) --keyring-migration-host=host_name
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-host=host_name
# 			Introduced: 		8.0.4
# 			Type: 				String
# 			Default: 			localhost
#
# 			The host location of the running server that is currently using one of the key migration keystores.
# 			See later.
#
# 			Migration always occurs on the local host, so the option always specifies a value for connecting to a local server,
# 			such as localhost, 127.0.0.1, ::1 or the local host IP address or host name.
#
# 		) --keyring-migration-password[=password]
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-password[=password]
# 			Introduced: 		8.0.4
# 			Type: 				String
#
# 			The password for connecting to the running server that is currently using one of the key migration
# 			keystores.
#
# 			See later.
#
# 			If you omit the password value following the option name on the command line, the server prompts for one.
#
# 			Specifying a password on the command line should be considered insecure.
# 			See earlier.
#
# 			You can use an option file to avoid giving the password on the command line.
# 			In this case, the file should have a restrictive mode and be accessible only to the account
# 			used to run the migration server.
#
# 		) --keyring-migration-port=port_num
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-port=port_num
# 			Introdued: 			8.0.4
# 			Type 					Numeric
# 			Default: 			3306
#
# 			For TCP/IP connections, the port number for connecting to the running server that is currently
# 			using one of the key migration keystores.
#
# 			See later.
#
# 		) --keyring-migration-socket=path
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-socket={file_name|pipe_name}
# 			Introduced: 		8.0.4
# 			Type: 				String
#
# 			For Unix socket file or Windows named pipe connections, the socket file
# 			or named pipe for connecting to the running server that is currently using one of the
# 			key migration keystores.
#
# 			See previous.
#
# 		) --keyring-migration-source=plugin
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-source=plugin_name
# 			Introduced: 		8.0.4
# 			Type: 				String
#
# 			The source keyring plugin for key migration. See earlier.
#
# 			The option value is similar to that for --plugin-load, except that only one plugin library can be specified.
# 			The value is given as name=plugin_library or plugin_library.
#
# 			The name is the name of a plugin to load, and plugin_library is the name of the library
# 			file that contains the plugin code.
#
# 			If the plugin library is named without any preceding plugin name, the server loads all plugins in the library.
# 			The server looks for plugin library files in the directory named by the plugin_dir system variable.
#
# 			NOTE:
#
# 				--keyring-migration-source and --keyring-migration-destination are mandatory for all keyring
# 				migration operations.
#
# 				The source and destination plugins must differ, and the migration server must support both plugins.
#
# 		) --keyring-migration-user=user_name
#
# 			Property 			Value
# 			Cmd line: 			--keyring-migration-user=user_name
# 			Introduced: 		8.0.4
# 			Type: 				String
#
# 			The user name for connecting to the running server that is currently using one of the key migration keystores.
# 			See previous.
#
# KEYRING SYSTEM VARIABLES
#
# MySQL Keyring plugins support the following system variables.
# Use them to configure keyring plugin operation.
#
# These variables are unavailable unless the appropriate keyring plugin is installed.
#
# ) keyring_aws_cmk_id
#
# 	Property 				Value
# 	Cmd line: 				--keyring-aws-cmk-id
# 	Introduced: 			8.0.11
# 	System var: 			keyring_aws_cmk_id
# 	Scope: 					Global
# 	Dynamic: 				Yes
# 	SET_VAR Hint: 			No
# 	Type: 					String
#
# 	The customer master key (CMK) ID obtained from the AWS KMS server and used by the keyring_aws plugin.
#
# 	This variable is unavailable unless that plugin is installed, but if it is installed, a value
# 	for this variable is mandatory.
#
# ) keyring_aws_conf_file
#
# 	Property 				Value
# 	Cmd line: 				--keyring-aws-conf-file
# 	Introduced:: 			8.0.11
# 	System var: 			keyring_aws_conf_file
# 	Scope: 					Global
# 	Dynamic: 				No
# 	SET_VAR Hint: 			No
# 	Type: 					File name
# 	Default: 				platform specific
#
# 	The location of the configuration file for the keyring_aws keyring plugin.
# 	This variable is unavailable unless that plugin is installed.
#
# 	At plugin startup, keyring_aws reads the AWS secret access key ID and key from the configuration file.
#
# 	For the keyring_aws plugin to start successfully, the configuration file must exist and contain
# 	valid secret access key information, initialized as previously described.
#
# 	The default file name is keyring_aws_conf, located in the default keyring file directory.
# 	The location of this default directory is the same as for the keyring_file_data system variable.
#
# 	See the description of that variable for details, as well as for considerations to take into account if you
# 	create the directory manually.
#
# ) keyring_aws_data_file
#
# 	Property 				Value
# 	Cmd line: 				--keyring-aws-data-file
# 	Introduced: 			8.0.11
# 	System variable: 		keyring_aws_data_file
# 	Scope: 					Global
# 	Dynamic: 				No
# 	SET_VAR Hint: 			No
# 	Type: 					File name
# 	Default: 				platform specific
#
# 	The location of the storage file for the keyring_aws keyring plugin.
# 	This variable is unavailable unless that plugin is installed.
#
# 	At plugin startup, if the value assigned to keyring_aws_data_file specifies a file
# 	that does not exist, the keyring_aws plugin attempts to create it (as well as its parent
# 	directory, if necessary).
#
# 	If the file does exist, keyring_aws reads any encrypted keys contained in the file into
# 	its in-memory cache.
#
# 	keyring_aws does not cache unencrypted keys in memory.
#
# 	The default file name is keyring_aws_data, located in the default keyring file directory.
#
# 	The location of this default directory is the same as for the keyring_file_data
# 	system variable.
#
# 	See the description of that variable for details, as well as for considerations to take into
# 	account if you create the directory manually.
#
# ) keyring_aws_region
#
# 	Property 				Value
# 	Cmd line: 				--keyring-aws-region
# 	Introduced: 			8.0.11
# 	Sys var: 				keyring_aws_region
# 	Scope: 					Global
# 	Dynamic: 				Yes
# 	SET_VAR Hint: 			No
# 	Type: 					Enumeration
# 	Default: 				us-east-1
# 	Valid: 					ap-northeast-1
# 								ap-northeast-2
# 								ap-south-1
# 								ap-southeast-1
# 								ap-southeast-2
# 								eu-central-1
# 								eu-west-1
# 								sa-east-1
# 								us-east-1
# 								us-west-1
# 								us-west-2
#
# The AWS region
#
# ) keyring_encrypted_file_data
#
# 	Property 				Value
# 	Cmd line: 				--keyring-encrypted-file-data=file_name
# 	Introduced: 			8.0.11
# 	System variable: 		keyring_encrypted_file_data
# 	Scope: 					Global
# 	Dynamic: 				Yes
# 	SET_VAR Hint: 			No
# 	Type: 					File name
# 	Default: 				platform specific
#
# 	The path name of the data file used for secure data storage by the keyring_encrypted_file plugin.
# 	This variable is unavailable unless that plugin is installed.
#
# 	The file location should be in a directory considered for use only by the keyring plugins.
# 	For example, do not locate the file under the data directory.
#
# 	Keyring operations are transactional: The keyring_encrypted_file plugin uses a backup file during write
# 	operations to ensure that it can roll back to the original file if an operation fails.
#
# 	The backup file has the same name as the value of the keyring_encrypted_file_data system variable with a suffix of .backup
#
# 	Do not use the same keyring_encrypted_file data file for multiple MySQL instances.
# 	Each instance should have its own unique data file.
#
# 	The default file name is keyring_encrypted, located in a directory that is platform specific and depends on the
# 	value of the INSTALL_LAYOUT CMake option, as shown in the following table.
#
# 	To specify the default directory for the file explicitly if you are building from source,
# 	use the INSTALL_MYSQLKEYRINGDIR CMake option.
#
# 	INSTALL_LAYOUT value 				Default keyring_encrypted_file_data Value
#
# 	DEB, RPM, SLES, SVR4 				/var/lib/mysql-keyring/keyring_encrypted 
#
# 	Otherwise 								keyring/keyring_encrypted under the CMAKE_INSTALL_PREFIX value
#
# 	At plugin startup, if the value assigned to keyring_encrypted_file_data specifies a file that does not exist,
# 	the keyring_encrypted_file plugin attempts to create it (as well as its parent directory, if necessary)
#
# 	If you create the directory manually, it should have a restrictive mode and be accessible only to the
# 	account used to run the MySQL server.
#
# 	For example, on UNIX based systems, to use the /usr/local/mysql/mysql-keyring directory, the following commands
# 	(executed as root) create the directory and set its mode and ownership:
#
# 	cd /usr/local/mysql
# 	mkdir mysql-keyring
# 	chmod 750 mysql-keyring
# 	chown mysql mysql-keyring
# 	chgrp mysql mysql-keyring
#
# 	If the keyring_encrypted_file plugin cannot create or access its data file, it writes an error message
# 	to the error log.
#
# 	If an attempted rutime assignment to keyring_encrypted_file_data results in an error, the variable value remains unchanged.
#
# 	Important:
#
# 		Once the keyring_encrypted_file plugin has created its data file and started to use it, it is important
# 		not to remove the file.
#
# 		Loss of the file will cause data encrypted using its keys to become inaccessible.
#
# 		(It is permissible to rename or move the file, as long as you change the value of keyring_encrypted_file_data to match)
#
# ) keyring_encrypted_file_password
#
# 	Property 							Value
# 	Cmd line: 							--keyring-encrypted-file-password=password
# 	Introduced: 						8.0.11
# 	System variable: 					keyring_encrypted_file_password
#	Scope: 								Global
# 	Dynamic: 							Yes
# 	SET_VAR Hint: 						No
# 	Type: 								String
#
# 	The password used by the keyring_encrypted_file plugin.
# 	This variable is unavailable unless that plugin is installed.
#
# 	The password is mandatory for plugin operation; if not specified at server startup,
# 	keyring_encrypted_file initialization fails.
#
# 	If this variable is specified in an option file, the file should have a restrictive mode
# 	and be accessible only to the account used to run the MySQL server.
#
# 	Important:
#		Once the keyring_encrypted_file_password value has been set, changing it does not rotate the
# 		keyring password and could make the server inaccessible.
#
# 		If an incorrect password is provided, the keyring_encrypted_file plugin cannot load keys
# 		from the encrypted keyring file.
#
# 	The password value cannot be displayed at runtime with SHOW_VARIABLES or the Performance Schema
# 	global_variables table because the display value is obfuscated.
#
# keyring_file_data
#
# Property 								Value
# Cmd line: 							--keyring-file-data=file_name
# System variable: 					keyring_file_data
# Scope: 								Global
# Dynamic: 								Yes
# SET_VAR Hint: 						No
# Type: 									File name
# Default value: 						platform specific
#
# THe path name of the data file used for secure data storage by the keyring_file plugin.
# This  variable is unavailable unless that plugin is installed.
#
# The file location should be in a directory considered for use only by the keyring plugins.
# For example, do not locate the file under the data directory.
#
# Keyring operations are transactional: The keyring_file plugin uses a backup file during 
# write operations to ensure that it can roll back to the original file if an operation fails.
#
# The backup file has the same name as the value of the keyring_file_data system variable with a suffix of .backup
#
# Do not use the same keyring_file data file for multiple MySQL instances.
# Each instance should have its own unique data file.
#
# The default file name is keyring, located in a directory that is platform specific and depends on
# the value of the INSTALL_LAYOUT CMake option, as shown as follows.
#
# To specify the default directory for the file explicitly if you are building from source,
# use the INSTALL_MYSQLKEYRINGDIR CMake option.
#
# INSTALL_LAYOUT Value 					Default keyring_file_data Value
#
# DEB, RPM, SLES, SVR4 					/var/lib/mysql-keyring/keyring  
#
# Otherwise 								keyring/keyring under the CMAKE_INSTALL_PREFIX value
#
# At plugin startup, if the value assigned to keyring_file_data specifies a file that does not exist,
# the keyring_file plugin attempts to create it (as well as its parent directory, if called for)
#
# If you create the directory manually, it should have a restrictive mode and be accessible only to the
# account used to run the MySQL server.
#
# For example, on Unix and UNIX based systems, to use the /usr/local/mysql/mysql-keyring directory, the following
# commands (executed as root) create the directory and set its mode and ownership:
#
# 		cd /usr/local/mysql
# 		mkdir mysql-keyring
# 		chmod 750 mysql-keyring
# 		chown mysql mysql-keyring
# 		chgrp mysql mysql-keyring
#
# If the keyring_file plugin cannot create or access its data file, it writes an error message to the error log.
#
# If an attempted runtime assignment to keyring_file_data results in an error, the variable value remains unchanged.
#
# Important:
#
# 		Once the keyring_file plugin has created its data file and started to use it, it is important not to remove the file.
#
# 		For example, InnoDB uses the file to store the master key used to decrypt the data in tables that use
# 		InnoDB tablespace encryption, see more later.
#
# 		Loss of the file will cause data in such tables to become inaccessible.
#
# 		(It is permissible to rename or move the file, as long as you change the value of keyring_file_data to match)
#
# 		It is recommended that you create a separate backup of the keyring data file immediately after you
# 		create the first encrypted table and before and after master key rotation.
#
# ) keyring_okv_conf_dir
#
# 	Property 						Value
# 	Cmd line:						--keyring-okv-conf-dir=dir_name
# 	Introduced: 					8.0.11
# 	System variable: 				keyring_okv_conf_dir
# 	Scope: 							Global
# 	Dynamic: 						Yes
# 	SET_VAR Hint: 					No
# 	Type: 							Directory name
# 	Default: 						empty string
#
# The path name of the directory that stores configuration information used by the keyring_okv plugin.
# This variable is unavailable unless that plugin is installed.
#
# The location should be a directory considered for use only by the keyring_okv plugin.
#
# For example, do not locate the directory under the data directory.
#
# The default keyring_okv_conf_dir value is empty.
#
# For the keyring_okv plugin to be able to access Oracle Key Vault, the value must be set
# to a directory that contains Oracle Key Vault configuration and SSL materials.
#
# For instructions on setting up this directory, see earlier.
#
# The directory should have a restrictive mode and be accessible only to the account used
# to run the MySQL server.
#
# For example, on UNIX based systems, to use the /usr/local/mysql/mysql-keyring-okv directory,
# the following commands (executed as root) create the directory and set its mode and ownership:
#
# 	cd /usr/local/mysql
# 	mkdir mysql-keyring-okv
# 	chmod 750 mysql-keyring-okv
# 	chown mysql mysql-keyring-okv
# 	chgrp mysql mysql-keyring-okv
#
# If the value assigned to keyring_okv_conf_dir specifies a directory that does not exist, or that does
# not contain configuration information that enables a connection to Oracle Key Vault to be established, keyring_okv
# writes an error message to the error log.
#
# If an attempted runtime assignment to keyring_okv_conf_dir results in an error, the variable and keyring operation remain
# unchanged.
#
# ) keyring_operations
#
# Property 					Value
# Introduced: 				8.0.4
# System Variable 		keyring_operations
# Scope: 					Global
# Dynamic: 					Yes
# SET_VAR Hint: 			No
# Type 						Boolean
# Default: 					ON
#
# Whether keyring operations are enabled.
#
# This variable is used during key migration operations.
#
# The privileges required to modify this variable are ENCRYPTION_KEY_ADMIN,
# in addition to either SYSTEM_VARIABLES_ADMIN or SUPER.
#
# MYSQL ENTERPRISE AUDIT
#
# Note:
# 		MySQL Enterprise Audit is an extension included in MySQL EE.
#
# MySQL EE includes MysQL Enterprise Audit, implemented using a server plugin named audit_log.
#
# MySQL Enterprise Audit uses the open MySQL Audit API to enable standard, policy-based monitoring, logging and
# blocking of connection and query activity executed on specific MySQL servers.
#
# Designed to meet Oracle audit specification, MysQL Enterprise Audit provides a out of the box, easy to use Auditing
# and compliance solution for applications that are governed by both internal and external regulatory guidelines.
#
# When installed, the audit plugin enables MySQL Server to produce a log file containing an audit record of server activity.
#
# The log contents include when clients connect and disconnect, and what actions they perform while connected,
# such as which databases and tables they access.
#
# After you install the audit plugin, it writes an audit log file.
#
# By default, the file is named audit.log in the server data directory.
#
# To change the name of the file, set the audit_log_file system variable at server startup.
#
# By default, audit log file contents are written in new-style XML format, without compression or encryption.
# To select the file format, set the audit_log_format system variable at server startup.
#
# For details on file formats and contents, see later.
#
# For more information about controlling how logging occurs, including audit log file naming and format selection,
# see later.
#
# To perform filtering of audited events, see later.
#
# For descriptions of the parameters used to configure the audit log plugin, se later.
#
# If the audit log plugin is enabled, the Performance Schema has instrumentation for it.
# To identify such relevant instruments, use this query:
#
# 		SELECT NAME FROM performance_schema.setup_instruments WHERE NAME LIKE '%/alog/%';
#
# AUDIT LOG COMPONENTS
#
# MySQL Enterprise Audit is based on the audit log plugin and related components:
#
# 		) A server-side plugin named audit_log examines auditable events and determines whether to write them to the audit log.
#
# 		) User-defined functions enable manipulation of filtering definitions that control logging behavior, the encryption PW and log file reading.
#
# 		) Tables in the mysql system database provide persistent storage of filter and user account data.
#
# 		) System variables enable audit log configuration and status variables provide runtime operational information.
#
# 		) An AUDIT_ADMIN privilege enable users to administer the audit log.
#
# INSTALLING OR UNINSTALLING MySQL ENTERPRISE AUDIT
#
# This section describes how to install or uninstall MySQL Enterprise Audit, which is implemented using
# the audit log plugin and related components described later.
#
# For general information about installation plugins, see earlier.
#
# Note:
# 		If installed, the audit_log plugin involves some minimal overhead even when disabled.
# 		To avoid this overhead, do not install MySQL Enterprise Audit unless you plan to use it.
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory
# (the directory named by the plugin_dir system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# To install MySQL Enterprise Audit, look in the share directory of your MySQL installation and choose the
# script that is appropriate for your platform.
#
# The available scripts differ in the suffix used to refer to the plugin library file:
#
# 		) audit_log_filter_win_install.sql: Choose this script for Windows systems that use .dll as the file name suffix.
#
# 		) audit_log_filter_linux_install.sql: Choose this script for Linux and similar systems that use the .so file name suffix.
#
# Run the script as follows. The examples here use the Linux installation script.
# Make the appropriate substitution for your system.
#
# mysql -u root -p < audit_log_filter_linux_install.sql
# Enter password: (enter root password here)
#
# Note:
#
# 		Some MySQL versions have introduced changes to the structure of the MySQL Enterprise Audit tables.
# 		To ensure that your tables are up to date for upgrades from earlier than 8.0, run mysql_update --force (which will also perform any other needed updates).
#
# 		If you prefer to run the update statements only for the MySQL Enterprise Audit tables, see the 
# 		following discussion.
#
# 		As of MySQL 8.0.12, for new MySQL installations, the USER and HOST columns in the audit_log_user table
# 		used by MySQL Enterprise Audit have definitions that better correspond ot the definitions of the User
# 		and Host columns in the mysql.user system table.
#
# 		FOr upgrades to an installation for which MySQL Enterprise Audit is already installed, it is recommended
# 		that you alter the table defs as follows:
#
# 			ALTER TABLE mysql.audit_log_user
# 				DROP FOREIGN KEY audit_log_user_ibfk_1;
#
# 			ALTER TABLE mysql.audit_log_filter
# 				CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_as_ci;
#
# 			ALTER TABLE mysql.audit_log_user
# 				CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_as_ci;
#
# 			ALTER TABLE mysql.audit_log_user
# 				MODIFY COLUMN USER VARCHAR(32);
#
# 			ALTER TABLE mysql.audit_log_user
# 				ADD FOREIGN KEY (FILTERNAME) REFERENCES mysql.audit_log_filter(NAME);
#
# To verify plugin installation, examine the INFORMATION_SCHEMA.PLUGINS table or use the SHOW_PLUGINS
# statement.
#
# For example:
#
# SELECT PLUGIN_NAME, PLUGIN_STATUS FROM INFORMATION_SCHEMA.PLUGINS WHERE PLUGIN_NAME LIKE 'audit%';
# +------------------------------+
# | PLUGIN_NAME 	| PLUGIN_STATUS|
# +------------------------------+
# | audit_log 		| ACTIVE 		|
# +------------------------------+
#
# If the plugin fails to initialize, check the server error log for diagnostic messages.
#
# After MySQL Enterprise Audit is installed, you can use the --audit-log option for subsequent server startups
# to control audit_log plugin activation.
#
# For example, to prevent the plugin from being removed at runtime, use this option:
#
# 	[mysqld]
# 	audit-log=FORCE_PLUS_PERMANENT
#
# If it is desired to prevent the server from running without the audit plugin, use --audit-log with
# a value of FORCE or FORCE_PLUS_PERMANENT to force server startup to fail if the plugin does not initialize successfully.
#
# Important:
#
# 		By default, rule-based audit log filtering logs no auditable events for any users.
#
# 		This differs from legacy audit log behavior, which logs all auditable events for all users.
#
# 		SHould you wish to produce log-everything behavior with rule-based filtering, create
# 		a simple filter to enable logging and assign it to the default account:
#
# 			SELECT audit_log_filter_set_filter('log_all', '{ "filter": { "log": true } }');
# 			SELECT audit_log_filter_set_user('%', 'log_all');
#
# 		The filter assigned to % is used for connections from any account that has no explicitly assigned filter (which initially
# 		is true for all accounts)
#
# Once installed as just described, MySQL Enterprise Audit remains installed until uninstalled.
# TO remove it, execute the following statements:
#
# DROP TABLE IF EXISTS mysql.audit_log_filter;
# DROP TABLE IF EXISTS mysql.audit_log_user;
# UNINSTALL PLUGIN audit_log;
# DROP FUNCTION audit_log_filter_set_filter;
# DROP FUNCTION audit_log_filter_remove_filter;
# DROP FUNCTION audit_log_filter_set_user;
#
# DROP FUNCTION audit_log_filter_remove_user;
# DROP FUNCTION audit_log_filter_flush;
# DROP FUNCTION audit_log_encryption_password_get;
# DROP FUNCTION audit_log_encryption_password_set;
#
# DROP FUNCTION audit_log_read;
# DROP FUNCTION audit_log_read_bookmark;
#
# MySQL ENTERPRISE AUDIT SECURITY CONSIDERATIONS
#
# By default, contents of audit log files produced by the audit log plugin are not encrypted and may
# contain sensetive information, such as the text of SQL statements.
#
# For security reasons, audit log files should be written to a directory accessibly only to the MySQL
# server and to users with a legitimate reason to view the log.
#
# The default file name is audit.log in the data directory.
#
# This can be changed by setting the audit_log_file system variable at server startup.
#
# Other audit log files may exist due to log rotation.
#
# For additional security, enable audit log file encryption.
#
# AUDIT LOG FILE FORMATS
#
# The MySQL server calls the audit log plugin to write an audit record to its log file whenever
# an auditable event occurs.
#
# Typically, ,the first audit record written after plugin startup contains the server description and
# startup options.
#
# Elements following that one represents events such as client connect and disconnect events,
# executed SQL statements and so forth.
#
# Only top-level statements are logged, not statements within stored programs such as triggers
# or stored procedures.
#
# Contents of files referenced by statements such as LOAD_DATA_INFILE are not logged.
#
# To select the logging format that the audit log plugin uses to write its log file,
# set the audit_log_format system variable at server startup.
#
# These formats are available:
#
# 		) Old-style XML format (audit_log_format=OLD): The original audit logging format used by default in older MySQL series.
#
# 		) New-style XML format (audit_log_format=NEW): An XML format that has better compatibility with Oracle Audit Vault than old-style
# 			XML format.
#
# 			MySQL 8.0 uses new-style XML format by default.
#
# 		) JSON format (audit_log_format=JSON)
#
# By default, audit log file contents are written in new-style XML format, without compression or encryption.
#
# NOTE:
# 		FOr information about issues to consider when changing log format, see Audit Log File Format.
#
# OLD-STYLE XML AUDIT LOG FILE FORMAT
#
# Here is a sample log file in old-style XML format (audit_log_format=OLD), reformatted slightly for readability:
#
# 	<?xml version="1.0" encoding="utf-8"?>
# 	<AUDIT>
# 		<AUDIT_RECORD
# 			TIMESTAMP="2017-10-16T14:25:00 UTC"
# 			RECORD_ID="1_2017-10-16T14:25:00"
# 			NAME="Audit
# 			SERVER_ID="1"
# 			VERSION="1"
# 			STARTUP_OPTIONS="--port=3306"
# 			OS_VERSION="i686-Linux"
# 			MYSQL_VERSION="5.7.21-log"/>
# 		<AUDIT_RECORD
# 			TIMESTAMP="2017-10-16T14:25:24 UTC"
# 			RECORD_ID="2_2017-10-16T14:25:00"
# 			NAME="Connect"
# 			CONNECTION_ID="4"
# 			STATUS="0"
# 			STATUS_CODE="0"
# 			USER="root"
# 			OS_LOGIN=""
# 			HOST="localhost"
# 			IP="127.0.0.1"
# 			COMMAND_CLASS="connect"
# 			CONNECTION_TYPE="SSL/TLS"
# 			PRIV_USER="root"
# 			PROXY_USER=""
# 			DB="test"/>
#
# ...
# 
# 	<AUDIT_RECORD
# 		TIMESTAMP="2017-10-16T14:25:24 UTC"
# 		RECORD_ID="6_2017_10-16T14:25:00"
# 		NAME="Query"
# 		CONNECTION_ID="4"
# 		STATUS="0"
# 		STATUS_CODE="0"
# 		USER="root[root] @ localhost [127.0.0.1]"
# 		OS_LOGIN=""
# 		HOST="localhost"
# 		IP="127.0.0.1"
# 		COMMAND_CLASS="drop_table"
# 		SQLTEXT="DROP TABLE IF EXISTS t"/>
#
# ---
#
# <AUDIT_RECORD
# 		TIMESTAMP="2017-10-16T14:25:24 UTC"
# 		RECORD_ID="8_2017-10-16T14:25:00"
# 		NAME="Quit"
# 		CONNECTION_ID="4"
# 		STATUS="0"
# 		STATUS_CODE="0"
# 		USER="root"
# 		OS_LOGIN=""
# 		HOST="localhost"
# 		IP="127.0.0.1"
# 		COMMAND_CLASS="connect"
# 		CONNECTION_TYPE="SSL/TLS"/>
#	<AUDIT_RECORD
# 		TIMESTAMP="2017-10-16T14:25:32 UTC"
# 		RECORD_ID="12_2017-10-16T14:25:00"
# 		NAME="NoAudit"
# 		SERVER_ID="1"/>
# 	</AUDIT>
#
#
# The audit log file is written as XML, using UTF-8 (up to 4 bytes per character).
#
# The root element is <AUDIT>. The root element contains <AUDIT_RECORD> elements, each of which provides
# information about an audited event. 
#
# When the audit log plugin begins writing a new log file, it writes the XML declaration and opening
# <AUDIT> root element tag.
#
# When the plugin closes a log file, it writes the closing </AUDIT> root element tag.
# The closing tag is not present while the file is open.
#
# Attributes of <AUDIT_RECORD> elements have these characteristics:
#
# 		) Some attributes appear in every <AUDIT_RECORD> element. 
#  		Others are optional and may appear depending on the audit record type.
#
# 		) Order of attributes within an <AUDIT_RECORD> element is not guaranteed.
#
# 		) Attribute values are not fixed length.
# 			Long values may be truncated as indicated in teh attribute desc. given later.
#
# 		) The <,>, " and &  chars are encoded as &lt;, &gt;, &quot; and &amp; respectively.
#  			NUL bytes (U+00) are encoded as the ? char.
#
# 		) Characters not valid as XML characters are encoded using numeric character references.
# 			Valid XML characters are:
#
# 				#x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] | [#x10000-#x10FFFF]
#
# The following attributes are mandatory in every <AUDIT_RECORD> element:
#
# ) NAME:
# 
#  	A string representing the type of instruction that generated the audit event, such as a command that hte server received from a client.
#
# 		Example: NAME="Query"
#
# 		Some common NAME values:
#
# 			Audit 	When auditing starts, which may be server startup time
#
# 			Connect 	When a client connects, also known as logging in			 
#
# 			Query 	An SQL statement (executed directly)
#
# 			Prepare 	Preparation of an SQL statement; usually followed by Execute
#
# 			Execute 	Execution of an SQL statement; usually follows Prepare
#
# 			Shutdown Server shutdown
#
# 			Quit 		When a client disconnects
#
# 			NoAudit 	Auditing has been turned off
#
# 		The possible values are: Audit, Binlog, Dump, Change user, Close stmt, Connect out, Connect, Create DB, Daemon, Debug, Delayed
# 											insert, Drop DB, Execute, Fetch, Field List, Init, DB, Kill, Long, Data, NoAudit, Ping, Prepare
#
# 											Processlist, Query, Quit, Refresh, Register Slave, Reset stmt, Set option, Shutdown, Sleep,
# 											Statistics, Table Dump, Time
#
# 		With the exception of "Audit" and "NoAudit", these values correspond to the COM_XXX command values listed in the my_command.h header file.
# 		For example, "Create DB" and "Change user" correspond to COM_CREATE_DB and COM_CHANGE_USER, respectively.
#
# ) RECORD_ID:
#
# 		A unique identifier for the audit record.
#
# 		The value is composed from a sequence number and timestamp, in the format SEQ_TIMESTAMP. 
#
# 		When the audit log plugin opens the audit log file, it initializes the sequence number to the size of the audit log file,
# 		then increments the sequence by 1 for each record logged.
#
# 		The timestamp is a UTC value in YYYY-MM-DDThh:mm:ss format indicating the date and time when the
# 		audit log plugin opened the file.
#
# 		Example: RECORD_ID="12_2017-10-16T14:25:00"
#
# ) TIMESTAMP:
#
# 		A string representing a UTC value in YYYY-MM-DDThh:mm:ss UTC format indicating the date and time when the audit event
# 		was generated.
#
# 		For example, the event corresponding to execution of an SQL statement received from a client has a TIMESTAMP value
# 		occuring after the statement finishes, not when it was received.
#
# 		Example: TIMESTAMP="2017-10-16T14:25:32 UTC"
#
# The following attributes are optional in <AUDIT_RECORD> elements.
#
# Many of them occur only for elements with specific values of the NAME attribute:
#
# ) COMMAND_CLAS
#
# 		A string that indicates the type of action performed.
#
# 		Example: COMMAND_CLASS="drop_table"
#
# 		The values correspond to the statement /sql/xxx command counters; for example, xxx
# 		is drop_table and select for DROP_TABLE and SELECT statements, respectively.
#
# 		The following statement displays the possible names:
#
# 			SELECT REPLACE(EVENT_NAME, 'statement/sql/', '') AS name
# 			FROM performance_schema.events_statements_summary_global_by_event_name
# 			WHERE EVENT_NAME LIKE 'statement/sql/%'
# 			ORDER BY name;
#
# ) CONNECTION_ID
#
# 		A unsigned integer representing the client connection identifier.
#
# 		This is the same as the value returned by the CONNECTION_ID() function within the session.
#
# 		Example: CONNECTION_ID="127"
#
# ) CONNECTION_TYPE
#
# 		The security state of the connection to the server.
# 		Permitted values are TCP/IP (TCP/IP connections established without encryption),
# 		SSL/TLS (TCP/IP connection established with encryption),
# 		Socket (Unix socket file connection),
# 		Named Pipe (Windows named pipe connection),
# 		and Shared Memory (Windows shared memory connection)
#
# 		Example: CONNECTION_TYPE="SSL/TLS"
#
# ) DB
#
# 		A string representing the default database name.
#
# 		Example: DB="test"
#
# ) HOST
#
# 		A string representing the client host name
#
# 		Example: HOST="localhost"
#
# ) IP
#
# 		A string representing the client IP address.
#
# 		Example: IP="127.0.0.1"
#
# ) MYSQL_VERSION
#
# 		A string representing the MySQL server version.
#
# 		This is the same as the value of the VERSION() function or version system variable.
#
# 		Example: MYSQL_VERSION="5.7.21-log"
#
# ) OS_LOGIN
#
# 		A string representing the external user name used during the authentication process, as set by
# 		the plugin used to authenticate the client.
#
# 		With native (built-in) MySQL authentication, or if the plugin does not set the value, this attribute is empty.
#
# 		The value is the same as that of the external_user system variable.
#
# 		Example: OS_LOGIN="jeffrey"
#
# ) OS_VERSION
#
# 		A string representing the operating system on which the server was built or is running.
#
# 		Example: OS_VERSION="x86_64-Linux"
#
# ) PRIV_USER
#
# 		A string representing the user that the server authenticated the client as.
#
# 		This is the user name that hte server uses for privilege checking, and it may differ
# 		from the USER value.
#
# 		Example: PRIV_USER="jeffrey"
#
# ) PROXY_USER
#
# 		A string representing the proxy user.
# 		The value is empty if user proxying is not in effect.
#
# 		Example: PROXY_USER="developer"
#
# ) SERVER_ID
#
# 		a unsigned integer representing the server ID.
#
# 		This is the same as the value of the server_id system variable.
#
# 		Example: SERVER_ID="1"
#
# ) SQLTEXT
#
# 		A string representing the text of an SQL statement.
# 		The value can be empty. Long values may be truncated.
#
# 		The string, like the audit log file itself, is written using UTF-8 (up to 4 bytes per character),
# 		so the value may be the result of conversion.
#
# 		For example, the original statement might have been received from the client as an SJIS string.
#
# 		Example: SQLTEXT="DELETE FROM t1"
#
# ) STARTUP_OPTIONS
#
# 		A string representing the options that were given on the command line or in option files when the MySQL server was started.
#
# 		Example: STARTUP_OPTIONS="--port=3306 --log_output=FILE"
#
# ) STATUS
#
# 		An unsigned integer representing the command status: 0 for success, nonzero if an error occurred.
#
# 		This is the same as the value of the mysql_errno() C API function.
#
# 		See the description for STATUS_CODE for information about how it differs from STATUS.
#
# 		The audit log does not contain the SQLSTATE value or error message. To see theh associations between error codes,
# 		SQLSTATE values, and messages - see later.
#
# 		Warnings are not logged.
#
# 		Example: STATUS="1051"
#
# ) STATUS_CODE
#
# 		An unsigned integer representing the command status: 0 for success, 1 if an error occurred.
#
# 		The STATUS_CODE value differs from the STATUS value: STATUS_CODE is 0 for success and 1 for error, which is compatible
# 		with the EZ_collector consumer for Audit Vault.
#
# 		STATUS is the value of the mysql_errno() C API function.
#
# 		This is 0 for success and nonzero for error, and thus is not necessarily 1 for error.
#
# 		Example: STATUS_CODE="0"
#
# ) USER
#
# 		A string representing the user name sent by the client. This may differ from the PRIV_USER value.
#
# ) VERSION
#
# 		An unsigned integer representing the version of the audit log file format.
#
# 		Example: VERSION="1"
#
# NEW-STYLE XML AUDIT LOG FILE FORMAT
#
# Here is a sample log file in new-style XML format (audit_log_format=NEW), reformatted slightly for readability:
#
# 	<?xml version="1.0" encoding="utf-8"?>
# 	<AUDIT>
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:06:33 UTC</TIMESTAMP>
# 			<RECORD_ID>1_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>Audit</NAME>
# 			<SERVER_ID>1</SERVER_ID>
# 			<VERSION>1</VERSION>
# 			<STARTUP_OPTIONS>/usr/local/mysql/bin/mysqld
# 				--socket=/usr/local/mysql/mysql.sock
# 				--port=3306</STARTUP_OPTIONS>
# 			<OS_VERSION>i686-Linux</OS_VERSION>
# 			<MYSQL_VERSION>5.7.21-log</MYSQL_VERSION>
# 		</AUDIT_RECORD>
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:09:38 UTC</TIMESTAMP>
# 			<RECORD_ID>2_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>Connect</NAME>
# 			<CONNECTION_ID>5</CONNECTION_ID>
# 			<STATUS>0</STATUS>
# 			<STATUS_CODE>0</STATUS_CODE>
# 			<USER>root</USER>
# 			<OS_LOGIN/>
# 			<HOST>localhost</HOST>
# 			<IP>127.0.0.1</IP>
# 			<COMMAND_CLASS>connect</COMMAND_CLASS>
# 			<CONNECTION_TYPE>SSl/TLS</CONNECTION_TYPE>
# 			<PRIV_USER>root</PRIV_USER>
# 			<PROXY_USER/>
# 			<DB>test</DB>
# 		</AUDIT_RECORD>
# ---
#
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:09:38 UTC</TIMESTAMP>
# 			<RECORD_ID>6_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>Query</NAME>
# 			<CONNECTION_ID>5</CONNECTION_ID>
# 			<STATUS>0</STATUS>
# 			<STATUS_CODE>0</STATUS_CODE>
# 			<USER>root[root] @ localhost [127.0.0.1]</USER>
# 			<OS_LOGIN/>
# 			<HOST>localhost</HOST>
# 			<IP>127.0.0.1</IP>
# 			<COMMAND_CLASS>drop_table</COMMAND_CLASS>
# 			<SQLTEXT>DROP TABLE IF EXISTS t</SQLTEXT>
# 		</AUDIT_RECORD>
# ---
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:09:39 UTC</TIMESTAMP>
# 			<RECORD_ID>8_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>Quit</NAME>
# 			<CONNECTION_ID>5</CONNECTION_ID>
# 			<STATUS>0</STATUS>
# 			<STATUS_CODE>0</STATUS_CODE>
# 			<USER>root</USER>
# 			<OS_LOGIN/>
# 			<HOST>localhost</HOST>
# 			<IP>127.0.0.1</IP>
# 			<COMMAND_CLASS>connect</COMMAND_CLASS>
# 			<CONNECTION_TYPE>SSL/TLS</CONNECTION_TYPE>
# 		</AUDIT_RECORD>
#
# ---
#
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:09:43 UTC</TIMESTAMP>
# 			<RECORD_ID>11_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>Quit</NAME>
# 			<CONNECTION_ID>6</CONNECTION_ID>
# 			<STATUS>0</STATUS>
# 			<STATUS_CODE>0</STATUS_CODE>
# 			<USER>root</USER>
# 			<OS_LOGIN/>
# 			<HOST>localhost</HOST>
# 			<IP>127.0.0.1</IP>
# 			<COMMAND_CLASS>connect</COMMAND_CLASS>
# 			<CONNECTION_TYPE>SSL/TLS</CONNECTION_TYPE>
# 		</AUDIT_RECORD>
# 		<AUDIT_RECORD>
# 			<TIMESTAMP>2017-10-16T14:09:45 UTC</TIMESTAMP>
# 			<RECORD_ID>12_2017-10-16T14:06:33</RECORD_ID>
# 			<NAME>NoAudit</NAME>
# 			<SERVER_ID>1</SERVER_ID>
# 		</AUDIT_RECORD>
# 	</AUDIT>
#
# The audit log file is written as XML, using UTF-8 (up to 4 bytes per char).
# The root element is <AUDIT>. It contains the <AUDIT_RECORD> elements, each of which provides
# information about an audited event.
#
# When the audit log plugin begins writing a new log file, it writes the XML Declaration and opening <AUDIT>
# root element tag.
#
# When the plugin closes a log file, it writes the closing </AUDIT> root element tag.
#
# The closing tag is not present while the file is open.
#
# Elements within <AUDIT_RECORD> elements have these characteristics:
#
# 		) Some elements appear in every <AUDIT_RECORD> element. Others are optional and may appear depending on the audit record type.
#
# 		) Order of elements within an <AUDIT_RECORD> element is not guaranteed.
#
# 		) Element values are not fixed length. Long values may be truncated as indicated in the element descriptions given later.
# 		
# 		) The <,>,", and & characters are encoded as &lt;, &gt;, &quot; and &amp; respetively. NUL bytes (U+00) are encoded as the ? character.
#
# 		) Characters not valid as XML characters are encoded using numeric character references.
#
# 			Valid XML characters are:
#
# 			#x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] | [#x10000-#x10FFFF]
#
# The following elements are mandatory in every <AUDIT_RECORD> element:
#
# 		) <NAME>
#
# 		a string representing the type of instruction that generated the audit event.
# 		Such as a command that the server received from a client.
#
# 		Example:
#
# 			<NAME>Query</NAME>
#
# 		Some common <NAME> values:
#
# 			Audit: When auditing starts, which may be server startup time
# 			Connect: When a client connects, also known as logging in
# 			Query: An SQL statement (executed-directly)
#
# 			Prepare: Preparation of an SQL statement; usually followed by Execute
# 			Execute: Execution of an SQL statement; usually follows Prepare
# 			Shutdown: Server shutdown
# 	
# 			Quit: When a client disconnects
# 			NoAudit: Auditing has been turned off
#
# The possible values are:
#
# Audit, Binlog Dump, Change user, Close stmt, Connect Out, Connect, Create DB, Daemon, Debug, Delayed insert,
# Drop DB, Execute, Fetch, Field List, Init DB, Kill, Long Data, NoAudit, Ping, Prepare, Processlist, Query,
# Quit, Refresh, Register Slave, Reset stmt, Set option,, Shutdown, Sleep, Statistics, Table Dump, Time
#
# With the exception of Audit and NoAudit, these values correspond to the COM_xxx command values listed in
# the my_command.h header file.
#
# For example, Create DB and Change user correspond to COM_CREATE_DB and COM_CHANGE_USER, respectively.
#
# 
# ) <RECORD_ID>
#
# 		A unique identifier for the audit record. The value is composed from a sequence number and timestamp, in the format SEQ_TIMESTAMP.
#
# 		When the audit log plugin opens the audit log file, it initializes the sequence number to the size of the audit log file,
# 		then increments the sequence by 1 for each record logged.
#
# 		The timestamp is a UTC value in YYYY-MM-DDThh:mm:ss format indicating the date and time when the audit log plugin opened the file.
#
# 		Example:
#
# 			<RECORD_ID>12_2017-10-16T14:06:33</RECORD_ID>
#
# ) <TIMESTAMP>
#
# 		A string representing a UTC value in YYYY-MM-DDYhh:mm:ss UTC format indicating the date and time when the audit event
# 		was generated.
#
# 		For example, the event corresponding to execution of an SQL statement received from a client has a <TIMESTAMP> value occurring
# 		after the statement finishes, not when it was received.
#
# 		Example:
#
# 			<TIMESTAMP>2017-10-16T14:09:45 UTC</TIMESTAMP>
#
# The following elements are optional in <AUDIT_RECORD> elements. Many of them occur only with specific <NAME> element values.
#
# 		) <COMMAND_CLASS>
#
# 			A string that indicates the type of action performed.
#
# 			Example:
#
# 				<COMMAND_CLASS>drop_table</COMMAND_CLASS>
#
# 			The values correspond to the statement/sql/xxx commands counters, for example, xxx is drop_table and select
# 			for DROP_TABLE and SELECT statements, respectively.
#
# 			The following statement displays the possible names:
#
# 				SELECT REPLACE(EVENT_NAME, 'statement/sql/', '') AS name
# 				FROM performance_schema.events_statements_summary_global_by_event_name
# 				WHERE EVENT_NAME LIKE 'statement/sql/%' ORDER BY name;
#
# 		) <CONNECTION_ID>
#
# 			An unsigned integer representing the client connection identifier.
#
# 			This is the same as the value returned by the CONNECTION_ID() function within the session.
#
# 			Example:
#
# 				<CONNECTION_ID>127</CONNECTION_ID>
#
# 		) <CONNECTION_TYPE>
#
# 			The security state of the connection to the server.
#
# 			Permitted values are TCP/IP (TCP/IP connection established without encryption),
# 			SSL/TLS (TCP/IP connection established with encryption), Socket (Unix socket file connection),
# 			Named Pipe (Windows named pipe connection), and Shared Memory (Windows shared memory connection)
#
# 			Example:
#
# 				<CONNECTION_TYPE>SSL/TLS</CONNECTION_TYPE>
#
# 		) <DB>
#
# 			A string representing the default database name.
#
# 			Example:
#
# 				<DB>test</DB>
#
# 		) <HOST>
#
# 			a string representing the client host name.
#
# 			Example:
#
# 				<HOST>localhost</HOST>
#
# 		) <IP>
#
# 			a string representing the client IP address.
#
# 			Example:
#
# 				<IP>127.0.0.1</IP>
#
# 		) <MYSQL_VERSION>
#
# 			A string representing the MySQL server version. This is the same as the value of the VERSION() function or
# 			version system variable.
#
# 			Example:
#
# 				<MYSQL_VERSION>5.7.21-log</MYSQL_VERSION>
#
# 		) <OS_LOGIN>
#
# 			A string representing the external user name used during the authentication process, as
# 			set by the plugin used to authenticate the client.
#
# 			With native (built-in) MySQL authentication, or if the plugin does not set the value, this element is empty.
#
# 			The value is the same as that of the external_user system variable.
#
# 			Example:
#
# 				<OS_LOGIN>jeffrey</OS_LOGIN>
#
# 		) <OS_VERSION>
#
# 			A string representing the operating system on which the server was built or is running.
#
# 			Example:
#
# 				<OS_VERSION>x86_64-Linux</OS_VERSION>
#
# 		) <PRIV_USER>
#
# 			A string representing the user that the server authenticated the client as.
#
# 			This is the user name that the server uses for privilege checking, and may differ from
# 			the <USER> value.
#
# 			Example:
#
# 				<PRIV_USER>jeffrey</PRIV_USER>
#
# 		) <PROXY_USER>
#
# 			A string representing the proxy user. This value is empty if user proxying is not in effect.
#
# 			Example:
#
# 				<PROXY_USER>developer</PROXY_USER>
#
# 		) <SERVER_ID>
#
# 			An unsigned integer representing the server ID.
# 			This is the same as the value of the server_id system variable.
#
# 			Example:
#
# 				<SERVER_ID>1</SERVER_ID>
#
# 		) <SQLTEXT>
#
# 			A string representing the text of an SQL statement.
#
# 			The value can be empty. Long values may be truncated.
#
# 			The string, like the audit log file itself, is written using UTF-8 (up to 4 bytes per character),
# 			so the value may be the result of conversion.
#
# 			For example, the original statement might have been received from the client as an SJIS string.
#
# 			Example:
#
# 				<SQLTEXT>DELETE FROM t1</SQLTEXT>
#
# 		) <STARTUP_OPTIONS>
#
# 			A string representing the options that were given on the command line or in option files when the MySQL
# 			server was started.
#
# 			The first option is the path to the server executable.
#
# 			Example:
#
# 				<STARTUP_OPTIONS>/usr/local/mysql/bin/mysqld
# 					--port=3306 --log_output=FILE</STARTUP_OPTIONS>
#
# 		) <STATUS>
#
# 			An unsigned integer representing the command status: 0 for success, nonzero if an error occurred.
#
# 			This is the same as the value of the mysql_errno() C API function.
#
# 			See the description for <STATUS_CODE> for information about how it differs from <STATUS>
#
# 			The audit log does not contain the SQLSTATE value or error message..
# 			To see the associations between error codes, SQLSTATE values and messages - see later.
#
# 			Warnings are not logged.
#
# 			Example: <STATUS>1051</STATUS>
#
# 		) <STATUS_CODE>
#
# 			An unsigned integer representing the command status: 0 for success, 1 if an error occurred.
#
# 			The STATUS_CODE value differs from the STATUS value: STATUS_CODE is 0 for success and 1 for error,
# 			which is compatible with the EZ_collector consumer for Audit Vault.
#
# 			STATUS is the value of the mysql_errno() C API function. This is 0 for success and nonzero for error,
# 			and thus is not necesarily 1 for error.
#
# 			Example:
#
# 				<STATUS_CODE>0</STATUS_CODE>
#
# 		) <USER>
#
# 			A string representing the user name sent by the client. This may differ from the <PRIV_USER> value.
#
# 			Example:
#
# 				<USER>root[root] @ localhost [127.0.0.1]</USER>
#
# 		) <VERSION>
#
# 			An unsigned integer representing the version of the audit log file format.
#
# 			Example:
#
# 				<VERSION>1</VERSION>
#
# JSON Audit Log File Format
#
# For JSON-format audit logging (audit_log_format=JSON), the log file contents form a JSON array with each array
# element representing an audited event as a JSON hash of key/value pairs.
#
# Examples of complete event records appear later in this section.
#
# The following is an excerpt of partial events:
#
# [
# 		{
# 			"timestamp": "2018-01-15 13:50:01",
# 			"id": 0,
# 			"class": "audit",
# 			"event": "startup",
# 			---
# 		},
# 		{
# 			"timestamp": "2018-01-15 15:02:32",
# 			"id": 0,
# 			"class": "connection",
# 			"event": "connect",
# 			---
# 		},
# 		---
# 		{
# 			"timestamp": "2018-01-15 17:37:26"
# 			"id": 0,
# 			"class": "table_access",
# 			"event": "insert",
# 			---
# 		}
# 		---
# ]
#
# The audit log file is written using UTF-8 (up to 4 bytes per char).
# When the audit log plugin begins writing a new log file, it writes the opening [ array marker.
#
# When the plugin closes a log file, it writes the closing ] array marker. The closing marker is not
# present while the file is open.
#
# Items within audit records have these characteristics:
#
# 		) Some items appear in every audit record. Others are optional and may appear depending on the audit record type.
#
# 		) Order of items within an audit record is not guaranteed.
#
# 		) Item values are not fixed length. Long values may be truncated as indicated in the item descriptions given later.
#
# 		) The " and \ characters are encoded as \" and \\, respectively.
#
# The following example shows the JSON object formats for different event types (as indicated by the class and event items),
# reformatted slightly for readability.
#
# Auditing startup event:
#
# 		{ "timestamp": "2018-01-15 14:21:56",
# 		  "id": 0,
# 		  "class": "audit",
# 		  "event": "startup",
# 		  "connection_id": 0,
# 		  "startup_data": { "server_id": 1,
# 								  "os_version": "i686-Linux",
# 								  "mysql_version": "5.7.21-log",
# 								  "args": ["/usr/local/mysql/bin/mysqld",
# 											  "--loose-audit-log-format=JSON",
# 											  "--log-error=log.err",
# 											  "--pid-file=mysqld.pid",
# 											  "--port=3306" ] } }
#
# When the audit log plugin starts as a result of server startup (as opposed to being enabled at runtime),
# connection_id is set to 0, and account and login are not present.
#
# Auditing shutdown event:
#
# 		{ "timestamp": "2018-01-15 14:28:20",
# 		  "id": 3,
# 		  "class": "audit",
# 		  "event": "shutdown",
# 		  "connection_id": 0,
# 		  "shutdown_data": { "server_id": 1 } }
#
# When the audit log plugin is uninstalled as a result of server shutdown (as opposed to being disabled at runtime),
# connection_id is set to 0, and account and login are not present.
#
# Connect or change-user event:
#
# 		{ "timestamp": "2018-01-15 14:23:18",
# 		  "id": 1,
# 		  "class": "connection",
# 		  "event": "connect",
# 		  "connection_id": 5,
# 		  "account": { "user": "root", "host": "localhost" },
# 		  "login": { "user": "root", "os": "", "ip": "::1", "proxy": "" },
# 		  "connection_data": { "connection_type": "ssl",
# 									  "status": 0,
# 									  "db": "test" } }
#
# Disconnect event:
#
# 		{ "timestamp": "2018-01-15 14:24:45",
# 		  "id": 3,
# 		  "class": "connection",
# 		  "event": "disconnect",
# 		  "connection_id": 5,
# 		  "account": { "user": "root", "host": "localhost" },
# 		  "login": { "user": "root", "os": "", "ip": "::1", "proxy": "" },
# 		  "connection_data": { "connection_type": "ssl" } }
#
# Query event:
#
# 		{ "timestamp": "2018-01-15 14:23:35",
# 			"id": 2,
# 			"class": "general",
# 			"event": "status",
# 			"connection_id": 5,
# 			"account": { "user": "root", "host": "localhost" },
# 			"login": { "user": "root", "os": "", "ip": "::1", "proxy": "" },
# 			"general_data": { "command": "Query",
# 									"sql_command": "show_variables",
# 									"query": "SHOW VARIABLES",
# 									"status": 0 } }
#
# Table access event (read, delete, insert, update):
#
# 		{ "timestamp": "2018-01-15 14:23:41",
# 		  "id": 0,
# 	     "class": "table_access",
# 		  "event": "insert",
# 	     "connection_id": 5,
# 		  "account": { "user": "root", "host": "localhost" },
# 		  "login": { "user": "root", "os": "", "ip": "127.0.0.1", "proxy": "" },
# 		  "table_access_data": { "db": "test",
# 										 "table": "t1",
# 										 "query": "INSERT INTO t1 (i) VALUES(1),(2),(3)",
# 										 "sql_command": "insert" } }
#
# The items in the following list appear at the top level of JSON-format audit records:
# Each item value is either a scalar or a JSON hash.
#
# For items that have a hash value, the description lists only the item names within that hash.
# For more complete descriptions of second-level hash items, see later in this section.
#
# ) account
#
# 		The MySQL account associated with the event.
#
# 		The value is a hash containing these items equivalent to the value of the CURRENT_USER() function
# 		within the section:
#
# 		user,host.
#
# 		Example:
#
# 			"account": { "user": "root", "host": "localhost" }
#
# ) class
#
# 		A string representing the event class.
# 		The class defines the type of event, when taken together with the event item that specifies the event subclass.
#
# 		Example:
#
# 			"class": "connection"
#
# 		The following table shows the permitted combinations of class and event values.
#
# 		TABLE 6.26 AUDIT LOG CLASS AND EVENT COMBINATIONS
#
# 		Class Value 				Permitted Event Values
# 		audit 						startup, shutdown
#
# 		connection 					connect, change_user, disconnect
#
# 		general 						status
#
# 		table_access_data 		read, delete, insert, update
#
# ) connection_data
#
# Information about a client connection.
#
# The value is a hash containing these items: connection_type, status,db.
# This item occurs only for audit records with a class value of connection.
#
# Example:
#
# 		"connection_data": { "connection_type": "ssl",
# 									"status": 0,
# 									"db": "test" }
#
# ) connection_id
#
# An unsigned integer representing the client connection identifier.
# This is the same as the value returned by the CONNECTION_ID() function within the session.
#
# Example:
#
# 		"connection_id": 5
#
# ) event:
#
# A string representing the subclass of the event class.
#
# The subclass defines the type of event, when taken together with the class item that specifies the event class.
# For more information, see the class item desc.
#
# Example:
#
# 		"event": "connect"
#
# ) general_data
#
# 	Information about an executed statement or command. The value is a hash containing these items:
# 	command, sql_command, query, status.
#
# This item occurs only for audit records with a class value of general.
#
# Example:
#
# 		"general_data": { "command": "Query",
# 								"sql_command": "show_variables",
# 								"query": "SHOW VARIABLES",
# 								"status": 0 }
#
# ) id
#
# 	An unsigned integer representing an event ID.
#
# Example:
#
# 		"id": 2
#
# For audit records that have the same timestamp value, their id values distinguish them and form a sequence.
# Within the audit log, timestamp/id pairs are unique.
#
# These pairs are bookmarks that identify event locations within the log.
#
# ) login
#
# Information indicating how a client connected to the server.
# The value is a hash containing these items: users, os, ip, proxy.
#
# Example:
#
# 		"login": { "user": "root", "os": "", "ip": "::1", "proxy": "" }
#
# ) shutdown_data
#
# Information pertaining to audit log plugin termination.
# The value is a hash containing these items: server_id.
#
# This item occurs only for audit records with class and event values of audit and shutdown, respectively.
#
# Example:
#
# 		"shutdown_data": { "server_id": 1 }
#
# ) startup_data
#
# Information pertaining to audit log plugin initialization.
# The value is a hash containing these items: server_id, os_version, mysql_version, args.
#
# THis item occurs only for audit records with class and event values of audit and startup,
# respectively.
#
# Example:
#
# 	"startup_data": { "server_id": 1,
# 							"os_version": "i686-Linux",
# 							"mysql_version": "5.7.21-log",
# 							"args": ["/usr/local/mysql/bin/mysqld",
# 										"--loose-audit-log-format=JSON",
# 										"--log-error=log.err",
# 										"--pid-file=mysqld.pid",
# 										"--port=3306" ] }
#
# ) table_access_data
#
# Information about an access to a table.
#
# The value is a hash containing these items: db, table, query, sql_command.
#
# This item occurs only for audit records with a class value of table_access.
#
# Example:
#
# 	"table_access_data": { "db": "test",
# 								  "table": "t1",
# 								  "query": "INSERT INTO t1 (i) VALUES(1),(2),(3)",
# 								  "sql_command": "insert" }
#
# ) timestamp
#
# A string representing a UTC value in YYYY-MM-DD hh:mm:ss format indicating the date and time when the audit
# event was generated.
#
# For example, the event corresponding to execution of an SQL statement received from a client has a timestamp
# value occurring after the statement finishes,, not when it was received.
#
# Example:
#
# 		"timestamp": "2018-01-15 13:50:01"
#
# For audit records that have the same timestamp value, their id values distinguished them and form a sequence.
# Within the audit log, timestamp/id pairs are unique.
#
# These pairs are bookmarks that identify event locations within the log.
#
# These items appear within hash values associated with top-level items of JSON-format audit records:
#
# 	) args
#
# 		An array of options that were given on the command line or in option files when the MySQL server was started.
# 		The first option is the path to the server executable.
#
# 		Example:
#
# 			"args": ["/usr/local/mysql/bin/mysqld",
# 						"--loose-audit-log-format=JSON",
# 						"--log-error=log.err",
# 						"--pid-file=mysqld.pid",
# 						"--port=3306" ]
#
# 	) command
#
# 		A string representing the type of instruction that generated the audit event, such as a command that the server
# 		received from a client.
#
# 		Example:
#
# 			"command": "Query"
#
# 	) connection_type
#
# 		The security state of the connection to the server.
# 		Permitted values are tcp/ip (TCP/IP connection established without encryption),
# 		ssl(TCP/IP connection established with encryption),
# 		socket(Unix socket file connection),
# 		named_pipe(Windows named pipe connection),
# 		shared_memory(Windows shared memory connection)
#
# 		Example:
#
# 			"connection_type": "tcp/tcp"
#
# ) db
#
# 		A string representing a database name.
# 		For connection_data, it is the default database.
#
# 		For table_access_data, it is the table database.
#
# 		Example:
#
# 			"db": "test"
#
# ) host
#
# 		A string representing the client host name.
#
# 		Example:
#
# 			"host": "localhost"
#
# ) ip
#
# 		A string representing the client IP address.
#
# 		Example:
#
# 			"ip": "::1"
#
# ) mysql_version
#
# 		A string representing the MySQL server version.
# 		This is the same as the value of the VERSION() function or version system variable.
#
# 		Example:
#
# 			"mysql_version": "5.7.21-log"
#
# ) os
#
# 		A string representing the external user name used during the authentication process, as set by the plugin used to authenticate
# 		the client.
#
# 		With native (built-in) MySQL authentication, or if the plugin does not set the value, this attribute is empty.
#
# 		The value is the same as that of the external_user system variable.
#
# 		Example:
#
# 			"os": "jeffrey"
#
# ) os_version
#
# 		A string representing the operating system on which the server was built or is running.
#
# 		Example:
#
# 			"os_version": "i686-Linux"
#
# ) proxy
#
# 		A string representing the proxy user. The value is empty if user proxying is not in effect.
#
# 		Example:
#
# 			"proxy": "developer"
#
# ) query
#
# 		A string representing the text of an SQL statement.
# 		The value can be empty.
#
# 		Long values may be truncated. The string, like the audit log file itself, is written using UTF-8
# 		(up to 4 bytes per character), so the value may be the result of conversion.
#
# 		For example, the original statement might have been received from the client as an SJIS string.
#
# 		Example:
#
# 			"query": "DELETE FROM t1"
#
# ) server_id
#
# 		An unsigned integer representing the server ID.
# 		THis is the same as the value of the server_id system variable.
#
# 		Example:
#
# 			"server_id": 1
#
# ) sql_command
#
# 		A string that indicates the SQL statement type.
#
# 		Example:
#
# 			"sql_command": "insert"
#
# 		The values correspond to the statement/sql/xxx command counters.
# 		For example, xxx is drop_table and select for DROP_TABLE and SELECT statements, respectively.
#
# 		The following statement displays the possible names:
#
# 			SELECT REPLACE(EVENT_NAME, 'statement/sql/', '') AS name
# 			FROM performance_schema.events_statements_summary_global_by_event_name
# 			WHERE EVENT_NAME LIKE 'statement/sql/%'
# 			ORDER BY name;
#
# ) status
#
# 		An unsigned integer representing the command status: 0 for success, nonzero if an error occurred.
# 		This is the same as the value of the mysql_errno() C API function.
#
# 		The audit log does not contain the SQLSTATE value or error message.
#
# 		To see the associations between error codes, SQLSTATE values and messages, see later.
#
# 		Warnings are not logged.
#
# 		Example:
#
# 			"status": 1051
#
# ) table
#
# 		A string representing a table name.
#
# 		Example:
#
# 			"table": "t1"
#
# ) user
#
# 		A string representing a user name. The meaning differs depending on the item within which user occurs:
#
# 			) Within account items, user is a string representing the user that the server authenticated the client as.
#
# 				This is the user name that the server uses for privilege checking.
#
# 			) Within login items, user is a string representing the user name sent by the client.
#
# 		Example:
#
# 			"user": "root"
#
# AUDIT LOG LOGGING CONTROL
#
# This section describes how to control general characteristics of audit logging, such as the file to which
# the audit log plugin writes events, the format of written events and whether compression and encryption
# are enabled.
#
# For more info about user-defined functions and system variables that affect audit logging, see earlier.
#
# The audit log plugin can also control which audited events are written to the audit log file, based on
# teh account from which events originate or even content.
#
# More on this, later.
#
# AUDIT LOG FILE NAME
#
# To control the audit log file name, set the audit_log_file system variable at server startup.
# By default, the name is audit.log in the server data directory.
#
# For security reasons, the audit log file should be written to a directory accessible only 
# to the MySQL server and to users with a legitimate reason to view the log.
#
# The plugin interprets the audit_log_file value as composed of a base name and an optional suffix.
#
# If compression or encryption are enabled, the effective file name (the name actually used to create the log file)
# differs from the configured file name because it has additional suffixes:
#
# 		) If compression is enabled, the plugin adds a suffix of .gz
#
# 		) If encryption is enabled, the plugin adds a suffix of .enc
#
# The effective audit log file name is the resulting name after adding possible compression
# and encryption suffixes to the configured file name. 	
#
# For example, if the configured audit_log_file is audit.log, the effective file name is one of these values:
#
# 		audit.log 			Not  compressed or encrypted
# 		audit.log.gz 		Compressed
#		audit.log.enc 		Encrypted
# 		audit.log.gz.enc 	Compressed and encrypted
#
# The audit log plugin performs certains actions at initialization and termination time based on the audit log file name:
#
# 		) During initialization, the plugin checks whether a file with the audit log file name already exists and renames it if so.
# 			(In this case, the plugin assumes that the previous server invocation exited unexpectedly with the audit log plugin running).
#
# 			The plugin then writes to a new empty audit log file.
#
# 		) At termination, the plugin renames the audit log file.
#
# 		) When renaming occurs (whether at plugin initialization or termination), the renamed file has a timestamp
# 			inserted after its base name and before its suffix.
#
# 			For example, if the file name is audit.log, the plugin renames it to a value such as audit.20180115T140633.log
# 			The timestamp is a UTC value in YYYYMMDDThhmmss format.
#
# AUDIT LOG FILE FORMAT
#
# To control the audit log file format, set the audit_log_format system variable at server startup.
# By default, the form is NEW (new-style XML format).
#
# For details about each format, see earlier.
#
# If you change udit_log_format, it is recommended that you also change audit_log_file.
# Otherwise, there will be two sets of log files with the same base name but different formats.
#
# AUDIT LOG FILE COMPRESSION
#
# Audit log file compression can be enabled for any logging format.
#
# To control whether audit log file compression is enabled, set the audit_log_compression system variable at server startup.
# Permitted values are NONE (no compression; the default) and GZIP (GNU Zip compression).
#
# If both compression and encryption are enabled, compression occurs before encryption.
# To recover the original file manually, first decrypt it - then uncompress it.
#
# See more later.
#
# AUDIT LOG FILE ENCRYPTION
#
# Audit log file encryption can be enabled for any logging format.
# Encryption is based on a user-defined password.
#
# To use this feature, the MySQL keyring must be enabled because audit logging uses it
# for password storage.
#
# Any keyring plugin can be used; see earlier.
#
# To control whether audit log file encryption is enabled, set the audit_log_encryption system variable
# at server startup.
#
# Permitted values are NONE (no encryption; the default) and AES (AES-256-CBC cipher encryption)
#
# To set or get the encryption password, use these user-defined functions (UDFs):
#
# 		) To set the encryption password, invoke audit_log_encryption_password_set(), which stores the password in the keyring,
# 			renames the current log file and begins a new log file encrypted with the new password.
#
# 			The renamed file has a timestamp inserted after its base name and before its suffix.
#
# 			For example, if the file name is audit.log.enc, the plugin renames it to a value such as audit.20180115T140633.log.enc
#
# 			The timestamp is a UTC value in YYYYMMDDThhmmss format.
#
# 			Previously written audit log files are not re-encrypted with the new password.
# 			Remember the previous password should you need to decrypt those files.
#
# 		) To get the current encryption password, invoke audit_log_encryption_password_get(), which retrieves the password from the keyring.
#
# For the first server startup after audit log encryption is enabled, the audit log plugin automatically generates
# the initial encryption password and stores it in the keyring.
#
# To discover this password, invoke audit_log_encryption_password_get()
#
# For additional information about audit log encryption functions, see earlier.
#
# If both compression and encryption are enabled, compression occurs before encryption.
# To recover the original file manually, first decrypt it, then uncompress it.
#
# See later for more info.
#
# AUDIT LOG FILE MANUAL UNCOMPRESSION AND DECRYPTION
#
# Audit log files can be uncompressed and decrypted using standard tools.
#
# This should be done only for log files that have been closed and are no longer in use,
# not for the log file that the audit log plugin is currently writing.
#
# You can recognize closed log files because they will have been renamed by the audit log plugin
# to include a timestamp in the file name.
#
# For this discussion, assume that audit_log_file is set to audit.log
#
# IN that case, a closed audit log file has one of these names:
#
# 		audit.timestamp.log 			Not compressed or encrypted
# 		audit.timestamp.log.gz 		Compressed
# 		audit.timestamp.log.enc 	Encrypted
# 		audit.timestamp.log.gz.enc Compressed and encrypted
#
# To uncompress a compressed log file manually, use gunzip, gzip -d or equivalent commands.
#
# For example:
#
# 		gunzip -c audit.timestamp.log.gz > audit.timestamp.log
#
# To decrypt an encrypted log file manually, use the openssl command.
# For example:
#
# 	openssl enc -d -aes-256-cbc -pass pass:password -md sha256 -in audit.timestamp.log.enc -out audit.timestamp.log
#
# If both compression and encryption are enabled for audit logging, compression occurs before encryption.
# In this case, the file name has .gz and .enc suffixes added, corresponding to the order in which those operations occur.
#
# To recover the original file manually, perform the operations in reverse.
# That is, first decrypt the file, then uncompress it:
#
# 		openssl enc -d -aes-256-cbc -pass pass:password -md sha256 -in audit.timestamp.log.gz.enc -out audit.timestamp.log.gz 
# 		gunzip -c audit.timestamp.log.gz > audit.timestamp.log
#
# AUDIT LOGGING WRITE STRATEGY
#
# The audit log plugin can cause any of several strategies for log writes.
# Regardless of strategy, logging occurs on a best-effort basis, with no guarantee of consistency.
#
# To specify a write strategy, set the audit_log_strategy system variable at server startup.
#
# By default, the strategy value is ASYNCHRONOUS and the plugin logs asynchronously to a buffer,
# waiting if the buffer is full.		 		
#
# It is possible to tell the plugin not to wait (PERFORMANCE) or to log synchronously, either using
# file system caching (SEMISYNCHRONOUSLY) or forcing output with a sync() call after each write request (SYNCHRONOUS)
#
# For asynch write strategy, the audit_log_buffer_size system variable is teh buffer size in bytes.
# Set this variable at server startup to change the buffer size.
#
# The plugin uses a single buffer, which it allocates when it initializes and removes when it terminates.
# The plugin does not allocate this buffer for nonasynch write strategies.
#
# Asynch logging strategy has these characteristics:
#
# 		) Minimal impact on server performance and scalability
#
# 		) Blocking of threads that generate audit events for the shortest possible time; that is, time to allocate the buffer plus
# 			time to copy the event to the buffer.
#
# 		) Output goes to the buffer. A separate thread handles writes from the buffer to the log file.
#
# With asynch logging, the integrity of the log file may be compromised if a problem occurs during a write
# to the file or if the plugin does not shutdown cleanly (for example, in the event that the server host exits unexpectedly).
#
# To reduce this risk, set audit_log_strategy to use synch logging.
#
# A disadvantage of PERFORMANCE strategy is that it drops events when the buffer is full.
# For a heavily loaded server, the audit log may have events missing.
#
# AUDIT LOG FILE SPACE MANAGEMENT AND NAME ROTATION
#
# The audit log file has the potentional to grow  very large and consume a lot of disk space.
#
# To enable management of the space used by its log files, the audit log plugin provides
# the audit_log_rotate_on_size and audit_log_flush system variables, which control audit log file
# rotation and flushing.
#
# Rotation can be done manually or automatically based on file size.
#
# MANUAL AUDIT LOG FILE ROTATION.
#
# By default, audit_log_rotate_on_size=0 and there is no log rotation except that which you perform manually.
#
# IN this case, the audit log plugin closes and reopens the log file when the audit_log_flush value changes from disabled
# to enabled.
#
# Log file renaming must be done externally to the server. 
#
# Suppose that the log file name is audit.log and you want to maintain the three most recent log files,
# cycling through the names audit.log.1.xml through audit.log.3.xml.
#
# On Unix, perform rotation manually like this:
#
# 1. From the cmd line, rename the current log files:
#
# 			mv audit.log.2.xml audit.log.3.xml
# 			mx audit.log.1.xml audit.log.2.xml
# 			mv audit.log audit.log.1.xml
#
# At this point, the plugin is still writing to the current log file, which has been renamed to audit.log.1.xml
#
# 2. Connect to the server and flush the log file so the plugin closes it and reopens a new audit.log file:
#
# 		SET GLOBAL audit_log_flush = ON;
#
# NOTE:
#
# 		FOr JSON-format logging, renaming audit log files manually makes them unavailable to the log-reading functions
# 		because the audit log plugin no longer can determine that they are part of the log file sequence.
#
# 		Consider setting audit_log_rotate_on_size greater than 0 to use size-based rotation instead.
#
# AUTOMATIC SIZE-BASED AUDIT LOG FILE ROTATION.
#
# If audit_log_rotate_on_size is greater than 0, setting audit_log_flush has no effect.
#
# Instead, whenever a write to the log file causes its size to exceed the audit_log_rotate_on_size value,
# the audit log plugin closes the file, renames it and opens a new log file.
#
# When the plugin renames the original file, the renamed file has a timestamp inserted after its base name
# and before its suffix.
#
# For example, if the file name is audit.log, the plugin renames it to a value such as audit.20180115T140633.log
#
# The timestamp is a UTC value in YYYYMMDDThhmmss format.
#
# NOTE:
#
# 		With size-based log file rotation, renamed log files do not rotate off the end of the name sequence.
#
# 		Instead, they have unique names and accumulate indefinitly.
# 		To avoid excessive space use, remove old files periodically, backing them up first as necessary.
#
# AUDIT LOG FILE READING
#
# The audit log plugin enables bookmarking and reading of JSON-format audit log files.
# (These capabilities do not apply to files written in other log formats).
#
# When the audit log plugin initializes and is configured for JSON logging, it uses the directory
# containing the audit log file (determined from the audit_log_file value), as the location to search
# for readable audit log files.
#
# To do this, it uses the value of audit_log_file to determine the file base name and suffix values,
# then looks for files with names that match the following pattern, where [...] indicates optional file name parts:
#
# 		basename[.timestamp].suffix[.gz][.enc]
#
# The plugin opens each matching file, checks that it really contains JSON audit records, and sorts them using
# the timestamps from the first record of each file to construct a list of log files that are subject to use with the log-reading functions.
#
# The plugin cannot include in the sequence files that were renamed manually and do not match the preceding pattern,
# or that were encrypted with a password different from the current password.
#
# To read events from the audit log, use these user-defined functions (UDFs):
#
# 		) audit_log_read_bookmark() returns a JSON string representing a bookmark for the most recently written audit log event.
#
# 			This bookmark is suitable for passing to audit_log_read() to indicate to that function where to begin reading.
#
# 			Example bookmark:
#
# 			{ "timestamp": "2018-01-15 21:03:44", "id": 0 }
#
# 		) audit_log_read() reads events from the audit log and returns a JSON string containing an array of audit events.
#
# Example audit_log_read() invocation using the current bookmark:
#
# 		SELECT audit_log_read(audit_log_read_bookmark());
# 		+---------------------------------------------------------------------------+
# 		| audit_log_read(audit_log_read_bookmark()) 		 									 |
#   	+---------------------------------------------------------------------------+
# 		| [ {"timestamp":"2018-01-15 22:41:24", "id":0, "class":"connection", ... 	 |
# 		+---------------------------------------------------------------------------+
#
# Each event in the audit_log_read() return value is a JSON hash, except that the last array element may be a JSON null value
# to indicate no following events are available to read.
#
# For example:
#
# [
# 		{ "timestamp": "2018-01-15 22:08:08", "id": 10,
# 		  "class": "general", "event": "status",
# 		  ---
# 		},
# 		{
# 		  "timestamp": "2018-01-15 22:08:08", "id": 11,
# 		  "class": "connection", "event": "disconnect",
# 			---
# 		},
# 		{
# 			"timestamp": "2018-01-15 13:39:33", "id": 0,
# 			"class": "connection", "event": "connect",
# 			---
# 		},
# 		{
# 			"timestamp": "2018-01-15 13:39:33", "id": 1,
# 			"class": "general", "event": "status",
# 			---
# 		},
# 		{
# 			"timestamp": "2018-01-15 13:39:33", "id": 2,
# 			"class", "connection", "event": "disconnect",
# 			---
# 		},
# 		null
# ]
#
# Use audit_log_read() like this:
#
# ) For the first call to audit_log_read() within a session, pass a bookmark indicating where to begin reading.
#
# ) If the final value of the returned array is not a JSON null value, there are more events following those just read
# 		and audit_log_read() can be called without or with a bookmark argument.
#
# 		Without an argument, reading continues with the next unread event.
# 		With a bookmark argument, reading continues from the bookmark.
#
# ) If the final value of the returned array is a JSON null value, there are no more events left to be read and the next call
# 		to audit_log_read() must include a bookmark argument.
#
# A bookmark is a JSON hash that indicates where and how much to read. The following items are significant in the bookmark value
# (other items are ignored):
#
# 	) timestamp, id: The location within the audit log of the first event to read.
# 							Both items must be present to completely specify a position.
#
# 	) max_array_length: The maximum number of events to read from the log.
# 	
# 								If omitted, the default is to read to teh end of the log or until the 
# 								read buffer is full, whichever comes first.
#
# The result returned from either log-reading function is a binary string.
#
# To use the string with functions that require a nonbinary string (such as the functions that manipulate JSON values),
# convert it to utf8mb4.
#
# Suppose that a bookmark has this value:
#
# SELECT @mark := audit_log_read_bookmark() AS mark;
# +-------------------------------------------------+
# | mark 											 			 |
# +-------------------------------------------------+
# | { "timestamp": "2018-01-15 16:10.28", "id": 2 } |
# +-------------------------------------------------+
#
# Calling audit_log_read() with that bookmark can return multiple events.
#
# To set a limit on the number of events read by audit_log_read(), convert the bookmark
# to utf8mb4 then add to it a max_array_length item with a value of 1.
#
# For example, using the preceding bookmark, convert and modify it as follows:
#
# 		SET @mark = CONVERT(@mark USING utf8mb4);
# 		SET @mark := JSON_SET(@mark, '$.max_array_length', 1);
# 		SELECT @mark;
# 		+-------------------------------------------------------------------------+
# 		| @mark 																						  |
# 		+-------------------------------------------------------------------------+
# 		| {"id": 2, "timestamp", "2018-01-15 16:10:28", "max_array_length": 1 	  |
# 		+-------------------------------------------------------------------------+
#
# The modified bookmark, when passed to audit_log_read() - produces a result of a single audit record.
#
# To set a limit on the number of bytes that audit_log_read() reads, set the audit_log_read_buffer_size system variable.
# As of MySQL 8.0.12, this variable has a default of 32kb and can be set at runtime.
#
# Each client should set its session value of audit_log_read_buffer_size appropriately for its use of audit_log_read().
# Prior to MySQL 8.0.12, audit_log_read_buffer_size has a default of 1 MB, affects all clients, and can be changed
# only at server startup.
#
# Each call to audit.log_read() returns as many available items as fit within the buffer size,
# skipping items that do not fit within the buffer size.
#
# Given this behavior, consider these factors when assessing the proper buffer size for an application:
#
# ) There is a tradeoff between number of calls to audit_log_read() and items returned per call:
#
# 	With a smaller buffer size, calls return fewer times - so more calls are needed.
#
# With a large buffer - calls return more items, so fewer calls are needed.
#
# ) With a smaller buffer size, such as the default size of 32kb, there is a greater chance that
# items will exceed the buffer size and audit_log_read() will skip them.
#
# Skipped items generate warnings.
#
# For additional information about audit log-reading functions, see later.
#
# AUDIT LOG FILTERING
#
# Note:
#
# 		This section describes how audit log filtering works as of if the audit log plugin and the accompanying audit 
# 		tables and UDFs are installed.
#
# 		If the plugin is installed, but not the accompanying audit tables and UDFs, the plugin operates in legacy
# 		filtering mode.
#
# 		Legacy mode is filtering behavior as it was prior to MySQL 5.7.13. I.e, before rule-based filtering.
#
# In legacy filtering mode - the audit log plugin had the capability of controlling logging of audited events
# by filtering them based on the account from which events originate or event status.
#
# Current filtering capabilities are extended:
#
# 		) Audited events can be filtered using these characteristics:
#
# 			) USer account
#
# 			) Audit event class
#
# 			) Audit event subclass
#
# 			) Value of event fields such as those that indicate operation status or SQL statement executed
#
# 		) Audit filtering is rule based:
#
# 			) A filtering definition creates a set of auditing rules.
#
# 				Definitions can be configured to include or exclude events for logging based on
# 				the characeristics just described.
#
# 			) Filter rules have the capability of blocking (aborting) execution of qualifying events,
# 				in addition to existing capabilities for event logging.
#
# 			) Multiple filters can be defined, and any given filter can be assigned to any number of user accounts.
#
# 			) It is possible to define a default filter to use with any user account that has no explicitly assigned filter.
#
# 		) Audit filters can be defined, displayed and modified using an SQL interface based on user-defined functions (UDFs)
#
# 		) Audit filter definitions are stored in the tables in the mysql system database.
#
# 		) Within a given session, the value of the read-only audit_log_filter_id system variable indicates whether a filter
# 			has been assigned to the session.
#
# 			NOTE:
#
# 				By default, rule-based audit log filtering logs no auditable events for any users.
#
# 				To log all auditable events for all users, use the following statements, 
# 				which create a simple filter to enable logging and assign it to the default account:
#
# 					SELECT audit_log_filter_set_filter('log_all', '{ "filter": { "log": true } }');
# 					SELECT audit_log_filter_set_user('%', 'log_all');
#
# 				The filter assigned to % is used for connections from any account that has no explicitly assigned filter
# 				(which initially is true for all accounts)
#
# The following list briefly summarizes the UDFs that implement the SQL interface for audit filtering control:
#
# 		) audit_log_filter_set_filter(): Define a filter
#
# 		) audit_log_filter_remove_filter(): Remove a filter
#
# 		) audit_log_filter_set_user(): Start filtering a user account
#
# 		) audit_log_filter_remove_user(): Stop filtering a user account
#
# 		) audit_log_filter_flush(): Flush manual changes to the filter tables to affect ongoing filtering.
#
# For usage examples and complete details about the filtering functions, see later.
#
# Audit log filtering functions are subject to these constraints:
#
# 		) To use any filtering function, the audit_log plugin must be enabled.
#
# 			Otherwise, an error occurs:
#
# 			SELECT audit_log_filter_flush();
# 			+---------------------------------------------------------------------------+
# 			| audit_log_filter_flush() 															    | 
# 			+---------------------------------------------------------------------------+
# 			| ERROR: audit_log plugin has not been installed with INSTALL PLUGIN syntax |
# 			+---------------------------------------------------------------------------+
#
# 			The audit tables must also exist or an error occurs:
#
# 			SELECT audit_log_filter_flush();
# 			+---------------------------------------------------------------------------+
# 			| audit_log_filter_flush() 																 |
# 			+---------------------------------------------------------------------------+
# 			| ERROR: Could not reinitialize audit log filters 									 |
# 			+---------------------------------------------------------------------------+
#
# 			To install the audit_log plugin, see earlier.
#
# 		) To use any filtering function, a user must possess the SUPER privilege. Otherwise, an error occurs:
#
# 			SELECT audit_log_filter_flush()\G
# 			********************************* 1. row *********************************
# 			audit_log_filter_flush(): ERROR: Request ignored for 'user1'@'localhost'.
# 											  SUPER_ACL needed to perform operation
#
# 			To grant the SUPER privilege to a user account, use this statement:
#
# 			GRANT SUPER ON *.* TO user;
#
# 			Alternatively, should you prefer to avoid granting the SUPER privilege while still permitting
# 			users to access specific filtering functions, "wrapper" stored programs can be defined.
#
# 			This technique is described in the context of keyring UDFs earlier; it can be adapted for use with
# 			filtering UDFs.
#
# 		) The audit_log plugin operates in legacy-mode if it is installed but the accompanying audit tables
# 			and functions are not created.
#
# 			The plugin writes these messages to the error log at server startup:
#
# 			[Warning] Plugin audit_log reported: 'Failed to open the audit log filter tables.'
# 			[Warning] Plugin audit_log reported: 'Audit Log plugin supports a filtering, which has
# 			not been installed yet.
#
# 			Audit Log plugin will run in the legacy mode, which will be disabled in teh enxt release.
#
# 			In legacy mode, filtering can be done based only on event account or status.
#
# USING AUDIT LOG FILTERING FUNCTIONS
#
# Before using the audit log user-defined functions (UDFs), install them according to earlier.
# The SUPER privilege is required to use any of these functions.
#
# The audit log filtering functions enable filtering control by providing an interface to create,
# modify and remove filter definitions and assign filters to user accounts.
#
# Filter definitions are JSON values. For information about using JSON data in MySQL, see later.
#
# This section shows some simple filter definitions. For more info about filter definitions, see earlier.
#
# When a connection arrives, the audit log plugin determines which filter to use for the new session by
# searching for the user account name in the current filter assignments:
#
# 		) If a filter is assigned to the user, the audit log uses that filter.
#
# 		) Otherwise, if no user-specific filter assignment exists, but there is a filter assigned to the 
# 			default account (%), the audit log uses the default filter.
#
# 		) Otherwise, the audit log selects no audit events from the session for processing.
#
# If a change-user operation occurs during a session (see later), filter assignment for the
# session is updated using the same rules but for the new user.
#
# By default, no accounts have a filter assigned, so no processing of auditable events occurs for any account.
#
# Suppose that instead you want the default ot be to log only connection-related activity
#
# (for example, to see connect, change-user and disconnect events - but not the SQL statements
# users execute while connected).
#
# TO achieve this, define a filter (shown here named log_conn_events) that enables logging only
# of events in the connection class, and assign that filter to the default account,
# represented by the % account name:
#
# 		SET @f = '{ "filter": { "class": { "name": "connection" } } }';
# 		SELECT audit_log_filter_set_filter('log_conn_events', @f);
# 		SELECT audit_log_filter_set_user('%', 'log_conn_events');
#
# Now the audit log uses this default account filter for connections from any account that
# has no explicitly defined filter.
#
# To assign a filter explicitly to a particular user account or accounts, define the filter, then assign
# it to the relevant accounts:
#
# 		SELECT audit_log_filter_set_filter('log_all', '{ "filter": { "log": true } }');
# 		SELECT audit_log_filter_set_user('user1@localhost', 'log_all');
# 		SELECT audit_log_filter_set_user('user2@localhost', 'log_all');
#
# Now full logging is enabled for user1@localhost and user2localhost.
#
# COnnections from other accounts continue to be filtered using the default account filter.
#
# To disassociate a user account from its current filter, either unassign the filter or assign a different filter:
#
# 		) Unassign the filter from the user account:
#
# 			SELECT audit_log_filter_remove_user('user1@localhost');
#
# 			Filtering of current sessions for the account remains unaffected.
# 			Subsequent connections from the account are filtered using the default account filter
# 			if there is one, and are not logged otherwise.
#
# 		) Assign a different filter to the user account:
#
# 			SELECT audit_log_filter_set_filter('log_nothing', '{ "filter": { "log": false } }');
# 			SELECT audit_log_filter_set_user('user1@localhost', 'log_nothing');
#
# 		Filtering of current sessions for the account remains unaffected.
#
# 		Subsequent connections from the account are filtered using the new filter.
# 		For the filter shown here, that means no logging for new connections from user1@localhost.
#
# For audit log filtering, user name and host name comparisons are case-sensitive.
#
# This differs from comparisons for privilege checking, for which host name comparisons
# are not case-sensitive.
#
# To remove a filter, do this:
#
# 		SELECT audit_log_filter_remove_filter('log_nothing');
#
# Removing a filter also unassigns it from any user to whom it has been assigned, including any current sessions for those users.
#
# The filtering UDFs just described affect filtering immediately and update the audit log tables
# in the mysql system database that store filters and user accounts.
#
# It is also possible to modify the audit log tables directly using statements such as INSERT, UPDATE and DELETE.
# But such changes do not affect filtering immediately.
#
# To flush your changes and make them operational, call audit_log_filter_flush():
#
# 		SELECT audit_log_filter_flush();
#
# To determine whether a filter has been assigned to the current session, check the session value
# of the read-only audit_log_filter_id system variable.
#
# If the value is 0, no filter is assigned:
# A nonzero value indicates the internally maintained ID of the assigned filter:
#
# 		SELECT @@audit_log_filter_id;
# 		+-------------------------------------------+
# 		| @@audit_log_filter_id 						  |
# 		+-------------------------------------------+
# 		| 						2 								  |
# 		+-------------------------------------------+
#
# WRITING AUDIT LOG FILTER DEFINITIONS
#
# Filter definitions are JSON values.
# For information about using JSON data in MySQL, see later.
#
# Filter definitions have this form, where actions indicates how filtering takes place:
#
# 		{ "filter": actions }
#
# LOGGING ALL EVENTS
#
# To explicitly enable or disable logging of all events, use a log element in the filter:
#
# 		{
# 			"filter": 	{ "log": true }
# 		}
#
# The log value can be either true or false.
#
# The preceding filter enables logging of all events. It is equivalent to:
#
# 		{
# 			"filter": { }
# 		}
#
# Logging behavior depends on the log value and whether class or event items are specified:
#
# 		) With log specified, its given value is used.
#
# 		) Without log specified, logging is true if no class or event item is specified, and false otherwise
# 			(in which case, class or event can include their own log item)
#
# LOGGING SPECIFIC EVENT CLASSES
#
# To log events of a specific class, use a class element in the filter, with its name field denoting the name of the class to log:
#
# 		{
# 			"filter": {
# 				"class": { "name": "connection" }
# 			}
# 		}
#
# The name value can be connection, general or table_access to log connection, general or table-access events, respectively.
#
# The preceding filter enables logging of events in teh connection class.
# IT is equivalent to the following filter with log items made explicit:
#
# 		{
# 			"filter": {
# 				"log": false,
# 				"class":. { "log": true,
# 								"name": "connection" }
# 			}
# 		}
#
# To enable logging of multiple classes, define the class value as a JSON array element that names the classes:
#
# 		{
# 			"filter": {
# 				"class": [
# 					{ "name": "connection" },
# 					{ "name": "general" },
# 					{ "name": "table_access" }
# 				]
# 			}
# 		}
#
# NOTE:
#
# 		When multiple instances of a given item appear at the same level within a filter definition,
# 		the item values can be combined into a single instance of that item within an array value.
#
# 		The preceding definition can be written like this:
#
# 			{
# 				"filter": {
# 					"class": [
# 						{ "name": [ "connection", "general", "table_access" ] }
# 					]
# 				]
# 			}
# 			
#
#
# LOGGING SPECIFIC EVENT SUBCLASSES
#
# To select specific event subclasses, use an event item containing a name item that names the subclasses.
# The default action for events selected by an event item is to log them.
#
# For example, this filter enables logging for the named event subclasses:
#
# 		{
# 			"filter": {
# 				"class": [
# 					{
# 						"name": "connection",
# 						"event": [
# 							{ "name": "connect" },
# 							{ "name": "disconnect" }
# 						]
# 					},
# 					{ "name": "general" },
# 					{
# 						"name": "table_access",
# 						"event": [
# 							{ "name": "insert" },
# 							{ "name": "delete" },
# 							{ "name": "update" }
# 					]
# 				}
# 			]
# 		}
# }	
#
# The event item can also contain explicit log items to indicate whether to log qualifying events.
# This event item selects multiple events and explicitly indicates logging behavior for them:
#
# 		"event": [
# 			{ "name": "read", "log": false },
# 			{ "name": "insert", "log": true },
# 			{ "name": "delete", "log": true },
# 			{ "name": "update", "log": true }
# 		]
#
# The event item can also indicate whether to block qualifying events, if it contains an abort item.
# For details, see later.
#
# EVENT CLASS AND SUBCLASS COMBINATIONS
#
# Event Class 			Event Subclass 				Desc
# connection 			connect 							Connection initiation (successful or unsuccessful)
# connection 			change_user 					Uses re-authentication with different user/pw during session
# connection 			disconnect 						Connection termination
#
# general 				status 							general operation information
#
# table_access 		read 								Table read statements, such as SELECT or INSERT_INTO_..._SELECT
# table_access 		delete 							Table delete statements, such as DELETE or TRUNCATE_TABLE
# table_access 		insert 							Table insert statements, such as INSERT or REPLACE
# table_access 		update 							Table update statements, such as UPDATE
#
# LOG AND ABORT CHARACTERISTICS PER EVENT CLASS AND SUBCLASS COMBINATION
#
# Event Class 			Event Subclass 	Can be logged Can be Aborted
# connection 			connect 							Yes/No
# connection 			change_user 					Yes/No
# connection 			disconnect 						Yes/No
#
# general 				status 							Yes/No
# table_access 		read 								Yes/Yes
# table_access 		delete 							Yes/Yes
# table_access 		insert 							Yes/Yes
# table_access 		update 							Yes/Yes
#
# INCLUSIVE AND EXCLUSIVE LOGGING
#
# A filter can be defined in inclusive or exclusive mode:
#
# 		) Inclusive mode logs only explicitly specified items.
#
# 		) Exclusive mode logs everything but explicitly specified items.
#
# To perform inclusive logging, disable logging globally and enable logging for specific classes.
#
# This filter logs connect and disconnect events in the connection class,
# and events in the general class:
#
# {
# 		"filter": {
# 			"log": false,
# 			"class": [
# 				{
# 					"name": "connection"
# 					"event": [
# 						{ "name": "connect", "log": true },
# 						{ "name": "disconnect", "log": true }
# 					]
# 				},
# 				{ "name": "general", "log": true }
# 			]
# 		}
# 	}
#
# To perform exclusive logging, enable logging globally and disable logging for specific classes.
# This filter logs everything except events in the general class:
#
# {
# 		"filter": {
# 			"log": true,
# 			"class":
# 				{ "name": "general", "log": false }
# 		}
# }
#
# The filter logs change_user events in teh connection class, and table_access events:
#
# {
# 		"filter": {
# 			"log": true,
# 			"class": [
# 				{
# 					"name": "connection",
# 					"event": [
# 						{ "name": "connect", "log": false },
# 						{ "name": "disconnect", "log": false }
# 					]
# 				},
# 				{ "name": "general", "log": false }
# 			]
# 		}
# }
#
# TESTING EVENT FIELD VALUES
#
# To enable logging based on specific event field values, specify a field item within the log item taht indicates
# the field name and its expected value:
#
# {
# 		"filer": {
# 			"class": {
# 			"name": "general",
# 				"event": {
# 					"name": "status",
# 					"log": {
# 						"field": { "name": "general_command.str", "value": "Query" }
# 					}
# 				}
# 			}
# 		}
# 	}
#
# Each event contains event class-specific fields that can be accessed from within a filter to perform custom filtering.
#
# A connection event indicates when a connection-related activity occurs during a session, such as a user connecting or disconnecting from
# the server.
#
# The following table indicates the permitted fields for connection events.
#
# CONNECTION EVENT FIELDS
#
# Field Name 								Field type 						Desc.
#
# status 									integer 							Event Status: 0: OK Otherwise: Failed
# connection_id 							unsigned integer 				Connection ID
# user.str 									string 							User name specified during authentication
#
# user.length 								unsigned integer 				User name length
# priv_user.str 							string 							Authenticated user name (account user name)
# priv_user.length 						unsigned integer 				Authenticated user name length
#
# external_user.str 						String 							External user name (provided by third-party authentication plugin)
# external_user.length 					unsigned integer 				External user name length
#
# proxy_user.str 							String 							Proxy user name
# proxy_user.length 						unsigned integer 				Proxy user name length
#
# host.str 									string 							Connected user host
# host.length 								unsigned integer 				Connected user host length
#
# ip.str 									string 							Connected user IP address
# ip.length 								unsigned integer 				Connected user IP address length
#
# database.str 							string 							Database name specified at connect time
# database.length 						unsigned integer 				Database name length
#
# connection_type 						integer 							Connection type: 
# 																					or "::undefined": undefined
# 																					or "::tcp/ip": TCP/IP
# 																					or "::socket": Socket
# 																					or "::named_pipe": Named pipe
# 																					or "::ssl" TCP/IP with encryption
# 																					or "::shared_memory": Shared memory
#
# The "::xxx" values are symbolic pseudo-constants taht may be given instead of literal numeric values.
# They must bq uoted as string and are case-sensitive.
#
# A general event indicates the status code of an operation and its details.
# The following indicates permitted fields for general events.
#
# GENERAL EVENT FIELDS
#
# Field Name 				Field Type 					Desc.
# 
# general_error_code 	integer 						Event status: 0: OK Otherwise: Failed
# general_thread_id 		unsigned integer 			Connection/thread ID
#
# general_user.str 		string 						User name specified during authentication
# general_user.length 	unsigned integer 			User name length
#
# general_command.str 	string 						Command name
# general_command.length unsigned integer 		Command name length
#
# general_query.str 		String 						SQL statement text
# general_query.length 	unsigned integer 			SQL statement text length
#
# general_host.str 		String 						host name
# general_host.length 	unsigned integer 			Host name length
#
# general_sql_command.str string 					SQL command type name
# general_sql_command.length unsigned integer 	SQL command type name length
#
# general_external_user.str string 					External user name (provided by third-party authentication plugin)
# general_external_user.length unsigned int 		External user name length
#
# general_ip.str 			String 						Connected user IP address
# general_ip.length 		Unsigned integer 			Connection user IP address length
#
# general_command.str indicates a command name: Query, Execute, Quit or Change User.
#
# A general event with the general_command.str field set to Query or Execute contains general_sql_command.str
# set to a value that specifies the type of SQL command: alter_db, alter_db_upgrade, admin_commands, etc.
#
# These values can be seen as the last components of the Performance Schema instruments displayed by this statement:
#
# SELECT NAME FROM performance_schema.setup_instruments
# WHERE NAME LIKE 'statement/sql/%' ORDER BY NAME;
#
# +--------------------------------------+
# | NAME 										  |
# +--------------------------------------+
# | statement/sql/alter_db 				  |
# | statement/sql/alter_db_upgrade 		  |
# | statement/sql/alter_event 			  |
# | statement/sql/alter_function 		  |
# | statement/sql/alter_instance 		  |
# | statement/sql/alter_procedure 		  |
# | statement/sql/alter_server 			  |
# ---
#
# A table-access event provides information about specific table accesses.
# The following table indicates the permitted fields for table-access events:
#
# Field Name 			Field Type 					Desc
#
# connection_id 		unsigned integer 			Event connection ID
# sql_command_id 		integer 						SQL command ID
# query.str 			String 						SQL statement text
# query.length 		unsigned integer 			SQL statement text length
#
# table_database.str string 						Database name associated with event
# table_database.len unsigned integer 			Database name length
#
# table_name.str 		String 						Table name associated with event
# table_name.len 		Unsigned int 				Table name length
#
# The following list showcases which statements produce which table-access events:
#
# 		) read event:
#
# 			) SELECT
#
# 			) INSERT_..._SELECT (for tables referenced in SELECT clause)
#
# 			) REPLACE_...._SELECT (for tables referenced in SELECT clause)
#
# 			) UPDATE_..._WHERE (for tables referenced in WHERE clause)
#
# 			) HANDLER_..._READ
#
# 		) delete event:
#
# 			) DELETE
#
# 			) TRUNCATE TABLE
#
# 		) insert event:
#
# 			) INSERT
#
# 			) INSERT_..._SELECT (for table referenced in INSERT clause)
#
# 			) REPLACE
#
# 			) REPLACE_..._SELECT (for table referenced in REPLACE clause)
#
# 			) LOAD DATA INFILE
#
# 			) LOAD XML INFILE
#
# 		) update event:
#
# 			) UPDATE
#
# 			) UPDATE_..._WHERE (for tables referenced in UPDATE clause)
#
# BLOCKING EXECUTION OF SPECIFIC EVENTS
#
# Event items can include an abort item that indicates whether to prevent qualifying events from executing.
# For example, abort enables rules to be written that block execution of specific SQL statements.
#
# The abort item must appear within an event item. For example:
#
# "event": {
# 		"name": qualifying event subclass names
# 		"abort": condition
# 	}
#
# For event subclasses selected by the name item, the abort function is true or false, depending on condition evaluation.
#
# If the condition evaluates to true, the event is blocked.
# Otherwise, the event continues executing.
#
# The condition specification can be as simple as true or false, or it can be more complex such that evaluation
# depends on event characteristics.
#
# This filter blocks INSERT, UPDATE and DELETE statements:
#
# {
# 		"filter": {
# 			"class": {
# 				"name": "table_access",
# 				"event": {
# 					"name": [ "insert", "update", "delete" ],
# 					"abort": true
#				}
# 			}
# 		}
# 	}
#
#  more complex filter, with a subsectioning of blocking the same things, but only for a specific table (finances.bank_account):
#
# {
# 		"filter": {
# 			"class": {
# 				"name": "table_access",
# 				"event": {
# 					"name": [ "insert", "update", "delete" ],
# 					"abort": {
# 						"and": [
# 							{ "field": { "name": "table_database.str", "value": "finances" } },
# 							{ "field": { "name": "table_name.str", "value": "bank_account } }
# 						]
# 					}
# 				}
# 			}
# 		}
# 	}
#
# Statements matched and blocked by the filter return an error to the client:
#
# 	ERROR 1045 (28000): Statemnt was aborted by an audit log filter
#
# Not all events can be blocked.
# For an event that cannot, the audit log writes a warning to the error log rather than blocking it.
#
# For attempts to define a filter in which the abort item appears elsewhere than in an event item, an error occurs.
#
# LOGICAL OPERATORS
#
# Logical operators (and, or, not) can be used in log items. This permits construction of more advanced filtering configurations:
#
# {
# 		"filter": {
# 			"class": {
# 				"name": "general",
# 				"event": {
# 					"name": "status",
# 					"log": {
# 						"or": [
# 							{
# 								"and": [
# 									{ "field": { "name": "general_command.str", "value": "Query" }},
# 									{ "field": { "name": "general_command.length", "value": 5 }}
# 								]
# 							},
# 							{
# 								"and": [
# 									{ "field": { "name": "general_command.str", "value": "Execute" }},
#Q 								{ "field": { "name": "general_command.length", "value": 7 }}
# 								]
# 							}
# 						]
# 					}
# 				}
# 			}
# 		}
# 	}
#
#
# REFERENCING PREDEFINED VARIABLES
#
# To refer to a predefined variable in a log condition, use a variable item, which tests equality against a given value:
#
# {
# 		"filter": {
# 			"class": {
# 				"name": "general",
# 				"event": {
# 					"name": "status",
# 					"log": {
# 						"variable": {
# 							"name": "audit_log_connection_policy_value", "value": "::none"
# 						}
# 					}
# 				}
# 			}
# 		}
# 	}
#
# Each predefined variable correspond to a system variable.
#
# By writing a filter that tests a predefined variable, you can modify filter operation by setting the
# corresponding system variable, without having to redefine the filter.
#
# For examplke, by writing a flter that tests the value of the audit_log_connection_policy_value predefined
# variable, you can modify filter operation by changing the value of the audit_log_connection_policy system varible.
#
# The audit_log_xxx_policy system variable are used for legacy mode audit log.
#
# With rule-based audit log filtering, those variables remain visible (for example, using SHOW_VARIABLES), but changes
# to them have no effect unless you write filters containing constructs that refer to them.
#
# The following list describes the permitted predefined variables for variable items:
#
# 		) audit_log_connection_policy_value
#
# 			This variable corresponds to the value of the audit_log_connection_policy system variable.
# 			The value is an unsigned integer.
#
# 			The following showcases the permitted values and the corresponding audit_log_connection_policy values.
#
# 			Audit_log_connection_policy_value Values
#
# 			Value 				CORRESPONDING audit_log_connection_policy Value
#
# 			0 or "::none" 		NONE
#
# 			1 or "::errors"  	ERRORS
#
# 			2 or "::all" 		ALL
#
# 			The "::xxx" values are symbolic pseudo-constants that may be given instead of the literal numeric values.
# 			They must be quoted as string and are case-sensitive.
#
# 		) audit_log_policy_value
#
# 			This variable corresponds to the value of the audit_log_policy system variable.
#
# 			This value is an unsigned integer.
#
# 			The following table shows the permitted values and the corresponding audit_log_policy values.
#
# 			AUDIT_LOG_POLICY_VALUE VALUES
#
# 			Value 				Corresponding audit_log_policy Value
#
# 			0 or "::none" 		NONE
#
# 			1 or "::logins" 	LOGINS
#
#  		2 or "::all" 		ALL
#
# 			3 or "::queries" 	QUERIES
#
# 			The "::xxx" values are symbolic pseudo-constants that may be given instead of the literal numeric values.
# 			They must be quoted as strings and are case-sensitive.
#
# 		) audit_log_statement_policy_value
#
# 			This variable corresponds to the value of the audit_log_statement_policy system varialbe.
# 			The value is an unsigned integer.
#
# 			The following table shows the perrmited values and the corresponding audit_log_statement_policy values.
#
# 			AUDIT_LOG_STATEMENT_POLICY_VALUE values
#
# 			Value 				Corresponding audit_log_statement_policy Value
#
# 			0 or "::none" 		NONE
#
# 			1 or "::errors" 	ERRORS
#
# 			2 or "::all" 		ALL
#
# 			The "::xxx" values are symbolic pseudo-constants that may be given instead of the literal numeric values.
# 			They must be quoted as strings and are case-sensitive.
#
# REFERENCING PREDEFINED FUNCTIONS
#
# To refer to a predefined function in a log condition, use a function item, which takes
# names and args values to specify the function name and its arguments, respectively:
#
# 	{
# 	  "filter": {
# 			"class": {
# 				"name": "general",
# 				"event": {
# 					"name": "status",
# 					"log": {
# 						"function": {
# 							"name": "find_in_include_list",
# 							"args": [ { "string": [ { "field": "user.str" },
# 															{ "string": "@"},
# 															{ "field": "host.str" } ] } ]
# 						}
# 					}
# 				}
# 			}
# 		}
# 	}
#
# The function as specified in the name item should be the function name only, without paranthesis
# or the argument list.
#
# Arguments in the args item, if there is one, must be given in the order listed in the function desc.
# Arguments can refer to predefined variables, event fields, or string or numeric constants.
#
# The preceding filter determines whether to log general class status events depending on whether the
# current user is found in the audit_log_include_accounts system variable.
#
# That user is constructed using fields in the event.
#
# The following list describes the permitted predefined functions for function items:
#
# 		) audit_log_exclude_accounts_is_null()
#
# 			Checks whether the audit_log_exclude_accounts system variable is NULL.
# 			This function can be helpful when defining filters that correspond to the legacy audit log implementation.
#
# 			arguments: None
#
# 		) audit_log_include_accounts_is_null()
#
# 			Checks whether the audit_log_include_accounts system variable is NULL.
# 			This function can be helpful when defining filters that correspond to the legacy audit log implementation.
#
# 			Argument: None
#
# 		) debug_sleep(millisec)
#
# 			Sleeps for a given number of milliseconds. This function is used during performance measurement.
# 			
# 			debug_sleep() is available for debug builds only.
#
# 			Arguments:
#
# 				) millisec: an unsigned integer that specifies the number of milliseconds to sleep.
#
# 		) find_in_exclude_list(account)
#
# 			Checks whether an account string exists in the audit log exclude list
# 			(the value of the audit_log_exclude_accounts system variable)
#
# 			Arguments:
#
# 				) account: A string that specifies the user account name.
#
# 		) find_in_include_list(account)
#
# 			Checks whether an account string exists in the audit log include list
# 			(the value of the audit_log_include_accounts system variable)
#
# 			Argument:
#
# 				) account: A string that specifies the user account name.
#
# 		) string_find(text, substr)
#
# 			Checks whether the substr value is contained in the text value.
# 			This search is case-sensitive.
#
# 			Arguments:
#
# 				) text: The text string to search.
#
# 				) substr: The substring to search for in text.
#
# REPLACING A USER FILTER
#
# In some cases, the filter definition can be changed dynamically.
# To do this, define a filter configuration within an existing filter.
#
# For example:
#
# {
# 		"filter": {
# 			"id": "main",
# 			"class": {
# 				"name": "table_access",
# 				"event": {
# 					"name": [ "update", "delete" ],
# 					"log": false,
# 					"filter": {
# 						"class": {
# 							"name": "general",
# 							"event": { "name": "status",
# 										  "filter": { "ref": "main" } }
# 					},
# 					"activate": {
# 						"or": [
# 							{ "field": { "name": "table_name.str", "value": "temp_1" } },
# 							{ "field": { "name": "table_name.str", "value": "temp_2" } }
# 						]
# 					}
# 				}
# 			}
# 		}
# 	}
# }
#
# A new filter is activated when the activate element within a subfilter evalutes to true.
# Using activate in a top-level filter is not permitted.
#
# A new filter can be replaced with the original one by using a ref item inside the subfilter
# to refer to the original filter id.
#
# The filter shown operates like this:
#
# 		) The main filter waits for table_access events, either update or delete.
#
# 		) If the update or delete table_access event occurs on the temp_1 or temp_2 table, the filter
# 			is replaced with the internal one (without an id, since there is no need to refer to it explicitly)
#
# 		) If the end of command is signalled (general/status event), an entry is written to the audit log file and
# 			the filter is replaced with the main filter.
#
# The filter is useful to log statements that update or delete anything from the temp_1 or temp_2 tables, such
# 	as this one:
#
# 		UPDATE temp_1, temp_3 SET temp_1.a=21, temp_3.a=23;
#
# The statement generates multiple table_access events, but the audit log file will contain only
# general/status entries.
#
# Note:
#
# 		Any id values used in the definition are evaluted with respect only to that definition.
# 		They have nothing to do with the value of the audit_log_filter_id system variable.
#
# LEGACY MODE AUDIT LOG FILTERING
#
# Note:
# 		THis section describes legacy audit log filtering, which applies if the audit_log plugin is installed
# 		but not the accompanying audit tables and UDFs needed for rule-based filtering.
#
# The audit log plugin can filter audited events.
#
# This enables you to control whether audited events are written to the audit log file based on the account
# from which events originate or event status.
#
# Status filtering occurs separately for connection events and statement events.
#
# EVENT FILTERING BY ACCOUNT
#
# To filter audited events based on the originating account, set one of these system variables at server startup or runtime:
#
# 		) audit_log_include_accounts: The accounts to include in audit logging. If this variable is set, only these accounts are audited.
#
# 		) audit_log_exclude_accounts: The accounts to exclude from audit logging. If this variable is set, all but these accounts are audited.
#
# The value for either variable can be NULL or a string containing one or more comma-separated account names, each in user_name@host_name format.
#
# By default, both variables are NULL, in which case, no account filtering is done and auditing occurs for all accounts.
#
# Modifications to audit_log_include_accounts or audit_log_exclude_accounts affect only connections created subsequent
# to the modification, not existing connections.
#
# Example: To enable audit logging only for the user1 and user2 local host accounts, set the audit_log_include_accounts system
# variable like this:
#
# 		SET GLOBAL audit_log_include_accounts = 'user1@localhost, user2@localhost';
#
# Only one of audit_log_include_accounts or audit_log_exclude_accounts can be non-NULL at a time:
#
# 		) If you set audit_log_include_accounts, the server sets audit_log_exclude_accounts to NULL.
#
# 		) If you attempt to set audit_log_exclude_accounts, an error occurs unless audit_log_include_accounts is NULL.
# 			In this case, you must first clear audit_log_include_accounts by setting it to NULL.
#
# 		-- This sets audit_log_exclude_accounts to NULL
# 		SET GLOBAL audit_log_include_accounts = value;
#
# 		-- This fails because audit_log_include_accounts is not NULL
# 		SET GLOBAL audit_log_exclude_accounts = value;
#
# 		-- To set audit_log_exclude_accounts, first set
# 		-- audit_log_include_accounts to NULL
# 		SET GLOBAL audit_log_include_accounts = NULL;
# 		SET GLOBAL audit_log_exclude_accounts = value;
#
# If you inspect the value of either variable, be aware that SHOW_VARIABLES display NULL as an empty string.
# To avoid this, use SELECT instead:
#
# 		SHOW VARIABLES LIKE 'audit_log_include_accounts';
# 		+-----------------------------------------------+
# 		| Variable_name 					| Value 				|
# 		+-----------------------------------------------+
# 		| audit_log_include_accounts 	| 					   |
# 		+-----------------------------------------------+
#
# 		SELECT @@audit_log_include_accounts;
# 		+--------------------------------------------+
# 		| @@audit_log_include_accounts 					|
# 		+--------------------------------------------+
# 		| NULL 													|
# 		+--------------------------------------------+
#
# If a user name or host name requires quoting because it contains a comma, space or other special character, quote it using
# single quotes.
#
# If the variable value itself is quoted with single quotes, double each inner single quote or escape it with a backlash.
#
# The following statements each enable audit logging for the local root account and are equivalent,
# even though the quoting styles differ:
#
# SET GLOBAL audit_log_include_accounts = 'root@localhost';
# SET GLOBAL audit_log_include_accounts = ''root''@''localhost'';
# SET GLOBAL audit_log_include_accounts = '\'root\'@\'localhost\'';
# SET GLOBAL audit_log_include_accounts = "'root'@'localhost'";
#
# The last statement will nto work if the ANSI_QUOTES sql mode is enabled, because in that mode, double quotes signifiy
# identifier quoting, not string quoting.
#
# EVENT FILTERING BY STATUS
#
# To filter audited events based on status, set the following system variables at server startup or runtime.
# These variables apply only for legacy audit log filtering.
#
# For JSON audit log filteirng, differnet status variables apply.
#
# ) audit_log_connection_policy: Logging policy for connection events
#
# ) audit_log_statement_policy: Logging policy for statement events
#
# Each variable takes a value of ALL (log all associated events, this is the default), ERRORS (lgo only failed events), or NONE (do not log events).
# For example, to log all statement events but only failed connection events, use these settings:
#
# SET GLOBAL audit_log_statement_policy = ALL;
# SET GLOBAL audit_log_connection_policy = ERRORS;
#
# ANother policy system variable, audit_log_policy, is available but does not afford as much control as audit_log_connection_policy and
# audit_log_statement_policy.
#
# It can be set only at server startup. At runtime, it is a readonly variable, it takes a value of ALL (log all events; this is the default),
# LOGINS (log connection events), QUERIES (log statement events), or NONE (do not log events).
#
# For any of those values, the audit log plugin logs all selected events without distinction as to
# success or failure.
#
# Use of audit_log_policy at startup works as follows:
#
# 		) If you do not set audit_log_policy or set it to its default of ALL, any explicit settings for audit_log_connection_policy
# 			or audit_log_statement_policy apply as specified.
#
# 			If not specified, they default to ALL.
#
# 		) If you set audit_log_policy to a non-ALL value, that value takes precedence over and is used to set
# 			audit_log_connection_policy and audit_log_statement_policy, as indicated in the following table.
#
# 			If you also set either of those variables to a value other than their default of ALL, the server
# 			writes a message to the error log to indicate that their values are being overridden.
#
# STARTUP AUDIT_LOG_POLICY VALUE 			RESULTING AUDIT_LOG_CONNECTION_POLICY VALUE 		RESULTING AUDIT_LOG_STATEMENT_POLICY VALUE
#
# LOGINS 											ALL 															NONE
# 
# QUERIES 											NONE 															ALL
#
# NONE 												NON 															NONE
#
# AUDIT LOG REFERENCE
#
# to install the audit log tables and functions, use the instructions provided earlier.
# Unless those components are installed, the audit_log plugin operates in legacy mode.
#
# AUDIT LOG TABLES
#
# MYSQL Enterprise AUdit uses tables in the mysql system database for persistent storage of filter and user account data.
# The tables can be accessed only by users with privlege for that DB.
#
# The tables use the InnoDB storage engine.
#
# If htese tables are missing, the audit_log plugin operates in legacy mode.
#
# The audit_log_filter table stores filter definitions.
# The table has these columns:
#
# 		) NAME
# 
# 			The filter name
#
# 		) FILTER
#
# 			The filter definition associated with the filter name. Definitions are stored as JSON values.
#
# The audit_log_user table stores user account information. The table has these columns:
#
# 		) USER
#
# 			The user name part of an account. For an account user1@localhost, the USER part is user1.
#
# 		) HOST
#
# 			The host name part of an account. For an account user1@localhost, the HOST part is localhost.
#
# 		) FILTERNAME
#
# 			The name of the filter assigned to the account.
# 			The filter name associates the account with a filter defined in the audit_log_filter table.
#
# AUDIT LOG FUNCTIONS
#
# THis section describes, for each audit log user-defined functions (UDFs), its purpose, calling sequence,
# and return value.
#
# For information about the conditions under which these UDFs can be invoked, see earlier.
#
# Each audit log UDF returns a string that indicates whether the operation succeeded.
# OK indicates success. ERROR: message indicates failure.
#
# These audit log UDFs are available:
# 
# 		) audit_log_encryption_password_get()
#
# 			Retrieves the current audit log encryption password as a binary string.
# 			The password is fetched from the MySQL keyring, which must be enabled or an error occurs.
#
# 			Any keyring plugin can be used.
#
# 			For additional information about audit log encryption, see later.
#
# 			Arguments: None
#
# 			Return value: 	The PW string for success (up to 766 bytes), or NULL and an error for failure.
#
# 			Example:
#
# 				SELECT audit_log_encryption_password_get();
# 				+----------------------------------------+
# 				| audit_log_encryption_password_get() 	  |
# 				+----------------------------------------+
# 				| secret 										  |
# 				+----------------------------------------+
#
# 		) audit_log_encryption_password_set(password)
#
# 			Sets the audit log encryption password and stores it in the MySQL keyring, which must be 
# 			enabled or an error occurs.
#
# 			Any keyring plugin can be used, for more info, see keyrings.
#
# 			For additional information about audit log encryption, see later.
#
# 			Arguments:
#
# 				password: The passwrong string. The max length is 766 bytes.
#
# 			Return value:
#
# 				1 for success, 0 for failure.
#
# 			Example:
#
# 				SELECT audit_log_encryption_password_set(password);
# 				+-------------------------------------------------+
# 				| audit_log_encryption_password_set(password) 	  |
# 				+-------------------------------------------------+
# 				| 1 															  |
# 				+-------------------------------------------------+
#
# 		) audit_log_filter_flush()
#
# 			Calling any of the other filtering UDFs affects operational audit log filtering immediately and updates
# 			the audit log tables.
#
# 			If instead you modify the contents of those tables directly using statements such as INSERT, UPDATE and DELETE,
# 			the changes do not affect filtering immediately.
#
# 			To flush your changes and make them operational, call audit_log_filter_flush()
#
# 			audit_log_filter_flush() affects all current sessions and detaches them from their previous filters.
# 			Current sessions are no longer logged unless they disconnect and reconnect, or execute a change-user operation.
#
# 			If this function fails, an error message is returned and the audit log is disabled until the next successful call to
# 			audit_log_filter_flush().
#
# 			Arguments: None
#
# 			Return: A string that indicates whether the operaiton succeeded. OK indicates success. ERROR: message indicates failure.
#
# 			Example:
#
# 				SELECT audit_log_filter_flush();
# 				+-------------------------+
# 				| audit_log_filter_flush()|
# 				+-------------------------+
# 				| OK 							  |
# 				+-------------------------+
#
# 		) audit_log_filter_remove_filter(filter_name)
#
# 			Given a filter name, removes the filter from the current set of filters.
# 			It is not an error for the filter not to exist.
#
# 			If a removed filter is assigned to any user accounts, those users stop being filtered
# 			(they are removed from the audit_log_user table)
#
# 			Termination of filtering includes any current sessions for those users:
#
# 				They are detached from the filter and no longer logged. 
#
# 			Arguments: filter_name: A string that specifies the filter name.
#
# 			Returns: a string that indicates whether the operation succeeded. OK indicates success. ERROR: message indicates failure.
#
# 			Example:
#
# 				SELECT audit_log_filter_remove_filter('SomeFilter');
# 				+---------------------------------------------+
# 				| audit_log_filter_remove_filter('SomeFilter')|
# 				+---------------------------------------------+
# 				| OK 														 |
# 				+---------------------------------------------+
#
# 		) audit_log_filter_remove_user(user_name)
#
# 			Given a user account name, cause the user to be no longer assigned to a filter.
#
# 			It is not an error if the user has no filter assigned. 
# 			Filtering of current sessions for the user remains unaffected.
#
# 			New connections for the user are filtered using the default account filter
# 			if there is one, and are not logged otherwise.
#
# 			If the name is %, the function removes the default account filter that is used for
# 			any user account that has no explicitly assigned filter.
#
# 			Arguments:
#
# 				) user_name: The user account name as a string in user_name@host_name format, or % to represent
# 									the default account.
#
# 			Return value:
#
# 				A string that indicates whether the operation succeeded. OK indicates success. 
# 				ERROR: message indicates failure.
#
# 			Example:
#
# 				SELECT audit_log_filter_remove_user('user1@localhost');
# 				+------------------------------------------------------+
# 				| audit_log_filter_remove_user('user1@localhost') 		 |
# 				+------------------------------------------------------+
# 				| OK 																	 |
# 				+------------------------------------------------------+
#
# 		) audit_log_filter_set_filter(filter name, definition)
#
# 			Given a filter name and definition, adds the filter to the current set of filters. If the filter already exists
# 			and is used by any current sesisons, those sessions are detached from the filter and are no longer logged.
#
# 			This occurs because the new filter definition has a new filter ID that differs from its previous ID.
#
# 			Arguments:
#
# 				) filter_name: A string that specifies the filter name.
#
# 				) definition: A JSON value that specifies the filter definition..
#
# 			Return value:
#
# 				A string that indicates whether the operation succeeded.
# 				OK indicates success. ERROR: message indicates failure.
#
# 			Example:
#
# 				SET @f = '{ "filter": { "log": false } }';
# 				SELECT audit_log_filter_set_filter('SomeFilter', @f);
# 				+----------------------------------------------------+
# 				| audit_log_filter_set_filter('SomeFilter', @f) 	  |
# 				+----------------------------------------------------+
# 				| OK 																  |
# 				+----------------------------------------------------+
#
# 		) audit_log_filter_set_user(user_name, filter_name)
#
# 			Given a user account name and a filter name, assigns the filter to the user.
#
# 			A user can be assigned only one filter, so if the user was already assigned a filter,
# 			the assignment is replaced.
#
# 			Filtering of current sessions for the user remains unaffected.
#
# 			New connections are filtered using the new filter.
#
# 			As a special case, the name % represents the default account.
#
# 			The filter is used for connections from any user account that has no explicitly assigned filter.
#
# 			Arguments:
#
# 				) User_name: The user account name as a string in user_name@host_name format, or % to represent the default account.
#
# 				) filter_name: A string that specifies the filter name.
#
# 			Return value:
#
# 				A string that indicates whether the operation succeeded. OK indicates success. ERROR: messages indicate failure.
#
# 			Example:
#
# 				SELECT audit_log_filter_set_user('user1@localhost', 'SomeFilter');
# 				+-----------------------------------------------------------------+
# 				| audit_log_filter_set_user('user1@localhost', 'SomeFilter') 		|
# 				+-----------------------------------------------------------------+
# 				| OK 																					|
# 				+-----------------------------------------------------------------+
#
# 		) audit_log_read([arg])
#
# 			Reads events from the audit log and returns a binary JSON string containing an array of audit events.
#
# 			IF the audit log format is not JSON, an error occurs.
#
# 			Each event in the return value is a JSON hash, except that the last array element may be a JSON null value 
# 			to indicate no following events are available to read.
#
# 			For hte first call to audit_log_read() within a session, pass a bookmark indicating where to begin reading.
#
# 			If the final value of the returned array is not a JSON null value, there are more events following
# 			those just read and audit_log_read() can be called without or with a bookmark argument.
#
# 			Without an argument, reading continues with the next unread event. With a bookmark argument, reading continues from the bookmark.
#
# 			If the final value of hte returned array is a JSON null value, there are no more events left to be read
# 			and the next call to audit_log_read() must include a bookmark argument.
#
# 			To obtain a bookmark for the most recently written event, call audit_log_read_bookmark()
#
# 			For additional info about audit log-reading functions, see later.
#
# 			Arguments:
#
# 				arg: An optional bookmark, represented as a string containing a JSON hash that indicates where and how much to read.
# 						The following items are significant in the arg value (other items are ignored):
#
# 						) timestamp, id: The location within the audit log of the first event to read.
# 												Both items must be present to completely specify a position.
#
# 						) max_array_length: The maximum number of events ot read from the log.
#
# 													If omitted, the default is to read to the end of the log or until
# 													the read buffer is full, whichever comes first.
#
# 			Return value:
#
# 				A binary JSON string containing an array of audited events for success, or NULL and an error for failure.
#
# 			Example:
#
# 				SELECT audit_log_read(audit_log_read_bookmark());
# 				+-------------------------------------------------------------------------+
# 				| audit_log_read(audit_log_read_bookmark()) 			  							  |
# 				+-------------------------------------------------------------------------+
# 				| [ {"timestamp":"2018-01-15 22:41:24", "id":0, "class":"connection", ... |
# 				+-------------------------------------------------------------------------+
#
# 		) audit_log_read_bookmark()
#
# 			Returns a binary JSON string representing a bookmark for the most recently written audit log event.
#
# 			IF the audit log format is not JSON, an error occurs.
#
# 			The bookmark is a JSON hash with a timestamp and id items indicating the event position within
# 			the audit log.
#
# 			It is suitable for passing to audit_log_read() to indicate to that function where ot begin reading.
#
# 			For additional information about log-reading functions, see later.
#
# 			Arguments: None
#
# 			Returns: A binary JSON string containing a bookmark for success, or NULL and an error for failure.
#
# 			Example:
#
# 				SELECT audit_log_read_bookmark();
# 				+-------------------------------------------------+
# 				| audit_log_read_bookmark() 							  |
# 				+-------------------------------------------------+
# 				| { "timestamp": "2018-01-15 21:03:44", "id": 0 } |
#				+-------------------------------------------------+
#
# AUDIT LOG OPTION and VARIABLE REFERENCE
#
# Audit Log Option and Variable Reference
#
# NAME 									CMD LINE 	OPTION FILE  SYSTEM VAR  STATUS VAR  VAR SCOPE 	DYNAMIC
#
# audit-log 							Yes 			Yes 								 
# audit_log_buffer_size 			Yes 			Yes 			   Yes 							Global 		No
# audit_log_connection_policy 	Yes 			Yes 				Yes 							Global 		Yes 
#
# audit_log_current_session 											Yes 							Both 			No
# audit_log_current_size 																	Yes 		Global 		No
# audit_log_event_max_drop_size 															Yes 		Global 		No
#
# audit_log_events 																			Yes 		Global 		No
# audit_log_events_filtered 																Yes 		Global 		No
# audit_log_events_lost 																	Yes 		Global 		No
#
# audit_log_events_written 																Yes 		Global 		No
# audit_log_exclude_accounts 		Yes 			Yes 				Yes 							Global 		Yes
# audit_log_file 						Yes 			Yes 				Yes 							Global 		No
#
# audit_log_flush 														Yes 							Global 		Yes
# audit_log_format 					Yes 			Yes 				Yes 							Global 		No
# audit_log_include_accounts 		Yes 			Yes 				Yes 							Global 		Yes
#
# audit_log_policy 					Yes 			Yes 				Yes 							Global 		No
# audit_log_rotate_on_size 		Yes 			Yes 				Yes 							Global 		Yes
# audit_log_statement_policy 		Yes 			Yes 				Yes 							Global 		Yes
#
# audit_log_strategy 				Yes 			Yes 				Yes 							Global 		No
# Audit_log_total_size 																		Yes 		Global 		No
# Audit_log_write_waits 																	Yes 		Global 		No
#
# AUDIT LOG OPTIONS AND VARIABLES
#
# This section describes the command options and system variables that control operation of MySQL Enterprise Audit.
#
# If values specified at startup time are incorrect, the audit_log plugin may fail to initialize
# properly and the server does not load it.
#
# In this case, teh server may also produce error messages for other audit log settings
# because it will not recognize them.
#
# To control the activation of the audit log plugin, use this option:
#
# 	) --audit-log[=value]
#
# 			Property 			Value
#  		Cmd-line 			--audit-log[=value]
# 			Introduced: 		8.0.11
# 			Type: 				Enumeration
# 			Default: 			ON
# 			Valid: 				ON, OFF, FORCE, FORCE_PLUS_PERMANENT
#
# This option controls how the server loads the audit_log plugin at startup.
#
# It is available only if the plugin has been previously registered with INSTALL_PLUGIN or is loaded with
# --plugin-load or --plugin-load-add
#
# The option value should be one of those available for plugin-loading options, as described
# in the installation parts.
#
# For example, --audit-log=FORCE_PLUS_PERMANENT tells the server to load the plugin and prevent it from
# being removed while the server is running.
#
# If the audit log plugin is enabled, it exposes several system variables that permit control over logging:
#
# 		SHOW VARIABLES LIKE 'audit_log%';
# 		+-------------------------------------------+
# 		| Variable_name 					 | value      |
#		+-------------------------------------------+
# 		| audit_log_buffer_size 		| 1048576 	  |
# 		| audit_log_connection_policy | ALL 		  |
# 		| audit_log_current_session 	| OFF 		  |
# 		| audit_log_exclude_accounts  | 				  |
# 		| audit_log_file 				   | audit.log   |
# 		| audit_log_filter_id 			| 0 			  |
# 		| audit_log_flush 				| OFF 		  |
# 		| audit_log_format 				| NEW 		  |
# 		| audit_log_include_accounts 	| 				  |
# 		| audit_log_policy 				| ALL 		  |
# 		| audit_log_rotate_on_size 	| 0 			  |
# 		| audit_log_statement_policy 	| ALL 		  |
# 		| audit_log_strategy 			| ASYNCHRONOUS|
# 		+-------------------------------------------+
#
# You can set any of thse variable at server startup, and some of them at runtime.
# Those that are avaialble only for legacy mode audit filtering are so noted.
#
# ) audit_log_buffer_size
#
# 		property 				Value
# 		Cmd line 				--audit-log-buffer-size=value
# 		Introduced: 			8.0.11
# 		System var: 			audit_log_buffer_size
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					INteger
# 		Default: 				1048576
# 		Min value: 				4096
# 		Max: (64-bit) 			a lot
# 		mAx (32-bit) 			Less
#
# 		When the audit log plugin writes events to the log asynchronously, it uses a buffer to store event
# 		contents prior to writing them.
#
# 		This variable controls the size of that buffer, in bytes.
#
# 		The server adjusts the value to a multiple of 4096.
#
# 		The plugin uses a single buffer, which it allocates when it initializes and removes
# 		when it terminates.
#
# ) audit_log_compression
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-compression=value
# 		Introduced: 			8.0.11
# 		Sys var: 				audit_log_compression
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				NONE
# 		Valid: 					NONE, GZIP
#
# 		The type of compression for the audit log file. Permitted values are NONE (no compression),
# 		and GZIP (GNU ZIp Compression)
#
# 		For more info, see later.
#
# ) audit_log_connection_policy
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-connection-policy=value
# 		Introduced: 			8.0.11
# 		System var: 			audit_log_connection_policy
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				ALL
# 		Valid: 					ALL, ERRORS, NONE
#
# 		NOTE: This only applies to legacy audit log filtering
#
# 		The policy controlling how the audit log plugin writes connection events to the log file.
# 		The following table show sthe permitted values:
#
# 			VALUE 	DESC
# 			ALL  		Log all connection events
# 			
# 			ERRORS 	Log only failed connection events
#
# 			NONE 		Do not log connection events
#
# 			NOTE:
# 				At server startup, any explicit value given for audit_log_connection_policy
# 				may be overridden if audit_log_policy is also specified.
#
# ) audit_log_current_session
#
# 		Property 				Value
# 		Introduced: 			8.0.11
# 		System var: 			audit_log_current_session
# 		Scope: 					Global, Session
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Boolean
# 		Default: 				depends on filtering policy
#
# 		Whether audit logging is enabled for the current session. 
# 		The session value of this variable is read only.
#
# 		It is set when the session begins based on teh values of the audit_log_include_accounts
# 		and audit_log_exclude_accounts system variables.
#
# 		The audit log plugin uses the session value to determine whether 
# 		to audit events for the session.
#
# 		(There is a global value, but hte plugin does not use it)
#
# ) audit_log_encryption
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-encryption=value
# 		Introduced: 			8.0.11
# 		System var: 			audit_log_encryption
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				NONE
# 		Valid: 					NONE, AES.
#
# 		The type of encryption for the audit log file.
# 		Permitted values are NONE (no encryption; the default)
# 		AES(AES-256-CBC cipher encryption)
#
# ) audit_log_exclude_accounts
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-exclude-accounts=value
# 		Introduced: 			8.0.11
# 		Sys var: 				audit_log_exclude_accounts
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR Hint: 			No
# 		Type: 					String
# 		Default: 				NULL
#
# 		NOTE: This applies only to legacy mode audit log filtering
#
# 		The accounts for which events should not be logged.
#
# 		The value should be NULL, or a string containing a list of one or more comma-separated
# 		account names.
#
# 		For more info, read earlier.
#
# 		MOdifications to audit_log_exclude_accounts affect only connections created subsequent
# 		to the modifcation, not existing connections.
#
# ) audit_log_file
#
# 		Property 				Value
# 		cmd line: 				--audit-log-file=file_name
# 		Introduced: 			8.0.11
# 		System variable: 		audit_log_file
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					File name
# 		Default: 				audit.log
#
# 		The base name and suffix of the file to which the audit log plugin writes events.
#
# 		The default value is audit.log, regardless of logging format.
#
# 		To have the name suffix correspond to the format, set hte name explicitly,
# 		choosing a different suffix (for example, audit.xml or XML format, audit.json for JSON format)
#
# 		If the value of audit_log_file is a relative path name, the plugin interprets it relative to the data directory.
# 		IF the value is a full path name, the plugin uses the value as is.

# 		A full path name may be useful if it is desirable to locate audit files on a separate file system or directory.
#
# 		For security reasons, the audit log file should be written to a directory accessible only to the MySQL
# 		server and users with a legitimate reason to  view the log. 
#
# 		For details about how the audit log plugin interprets the audit_log_file values and the rules for file renaming
# 		that occurs at plugin initializaiton and termination, see earlier.
#
# 		The audit log plugin uses the directory containing the audit log file (determined from the audit_log_file value)
# 		as the location to search for readable audit log files.
#
# 		From these log files and the current file, the plugin constructs a list of the ones that are subject
# 		to use with the audit log bookmarking and reading functions.
#
# ) audit_log_filter_id
#
# 		Property 				Value
# 		Introduced: 			8.0.11
# 		Sys var: 				audit_log_filter_id
# 		Scope: 					Global, Session
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					integer
#
# 		The session value of this variable indicates the internally maintained ID of the audit files for the current session.
# 		A value of 0 means that the session has no filter assigned.
#
# ) audit_log_flush
#
# 		Property 				Value
# 		INtroduced 				8.0.11
# 		Sys var: 				audit_log_flush
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR HINT: 			No
# 		Type: 					Boolean
# 		Default: 				OFF
#
# 		When this variable is set to enabled (1 or ON), the audit log plugin closes and reopens its log file to flush it.
# 		(The value remains OFF so that you need not disable it explicitly before enabling it again to perform another flush).
#
# 		Enabling this variable has no effect unless audit_log_rotate_on_size is 0.
#
# 		For more info, see earlier.
#
# ) audit_log_format
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-format=value
# 		Introduced: 			8.0.11
# 		System variable: 		audit_log_format
# 		Scope: 					Global
# 		Dynamic: 				No
# 		SET_Var hint: 			No
# 		Type: 					Enumeration
# 		Default: 				NEW
# 		Valid: 					OLD, NEW, JSON
# 	 		 
# 		The audit log file format.
# 		Permitted values are OLD (old-style XML), NEW (new-style XML; the default), and JSON format.
#
# 		More info on log ofrmat, earlier.
#
# ) audit_log_include_accounts
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-include-accounts=value
# 		Introduced: 			8.0.11
# 		Sys var: 				audit_log_include_accounts
# 		Scope: 					Global
# 		Dynamic: 				Yes
# 		SET_VAR HINT: 			No
# 		Type: 					String
# 		Default: 				NULL
#
# 		NOTE: This only applies to legacy mode audit log filtering.
#
# 		The accounts for which events should be logged. The value should be NULL or a string containing a list
# 		of one or more comma separated account names.
#
# 		Modifications to audit_log_include_accounts affect only connections created subsequently to the modifciation, not existing connections.
#
# ) audit_log_policy
#
# 		Property 				Value
# 		Cmd line: 				--audit-log-policy=value
# 		Introduced: 			8.0.11
# 		Sys var: 				audit_log_policy
# 		SCope: 					Global
# 		Dynamic: 				No
# 		SET_VAR Hint: 			No
# 		Type: 					Enumeration
# 		Default: 				ALL
# 		Valid: 					ALL, LOGINS, QUEIES, NONE
#
# 		NOTE: This only applies to legacy mode audit log filtering
#
# 		The policy controlling how the audit login plugin writes events to its log file.
# 		The following table shows the permitted values:
#
# 		Value 		Desc
# 		ALL 			Log all events
# 		LOGINS 		Log only login events
# 		QUERIES 		Log only query events
# 		NONE 			Log nothing (disable the audit stream)
#
# 		audit_log_policy can be set only at server startup.
# 		At runtime, it is a read-only variable.
#
# 		Two other system variables, audit_log_connection_policy and audit_log_statement_policy,
# 		provide finer control over logging policy and can be set either at startup or at runtime.
#
# 		If you use audit_log_policy at startup instead of the other two variables, the server uses
# 		its value to set those variables.
#
# ) audit_log_read_buffer_size
#
# 		PROPERTY 					Value
# 		Cmd line: 					--audit-log-read-buffer-size=#
# 		Introduced: 				8.0.11
# 		Sys var (>= 8.0.11) 		audit_log_read_buffer_size
#
# 		Scope (>= 8.0.12) 		global, Session
# 		scope (8.0.11) 			Global
#
# 		Dynamic (>= 8.0.12) 		Yes
# 		Dynamic (8.0.11) 			No
# 		
# 		SET_VAR Hint (>= 8.0.11) No
#		Type 							Integer
#
# 		Default (>= 8.0.12) 		32768
# 		Default (8.0.11) 			1048576
#
# 		Min (>= 8.0.12) 			32768
# 		Min (8.0.11) 				1024
# 		Max: 							4194304
#
# 		The buffer size for reading from the audit log file, in bytes.
# 		The audit_log_read() function reads no more than this many bytes.
#
# 		Log file reading is supported only for JSON logging format.
#
# 		As of MySQL 8.0.12, this var has a default of 32kb and can be set at runtime.
#
# 		Each client should set its session value of audit_log_read_buffer_size
# 		appropriately for its use of audit_log_read().
#
# 		Prior to MySQL 8.0.12, audit_log_read_buffer_size has a default of 1MB,
# 		affects all clients, and can be changed only at server startup.
#
# ) audit_log_rotate_on_size
#
# 		Property 					Value
# 		Cmd line: 					--audit-log-rotate-on-size=N
# 		Introduced: 				8.0.11
# 		Sys var: 					audit_log_rotate_on_size
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						integer
# 		Default value: 			0
#
# 		If the audit_log_rotate_on_size value is 0, the audit log plugin does not perform automatic log file rotation..
# 		Instead, use audit_log_flush() to close and reopen the log on demmand.
#
# 		IN this case, manually rename the file externally to the server before flushing it.
#
# 		If the audit_log_rotate_on_size value is greater than 0, automatic size-based log file rotation occurs.
#
# 		Whenever a write to the log file causes its size to exceed the audit_log_rotate_on_size value,
# 		the audit log plugin closes the current log file, renames it and opens a new log file.
#
# 		For more info about audit log file rotation, see later.
#
# 		If you set this variable to a value that is not a multiple of 4096, it is truncated to the nearest multiple.
# 		(Thus, setting it to a value less than 4096 bytes has the effect of setting it to 0 and no rotation occurs, except manually)
#
# ) audit_log_statement_policy
#
# 		Property 					Value
# 		Cmd line: 					--audit-log-statement-policy=value
# 		Introduced: 				8.0.11
# 		Sys var: 					audit_log_statement_policy
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Enumeration
# 		Default: 					ALL
# 		Valid: 						ALL, ERRORS, NONE
#
# 		NOTE: Only applies to legacy audit log filtering
#
# 		The policy controlling how the audit log plugin writes statement events to its log file.
# 		The following table shows the permitted values:
#
# 		Value 		Desc
#
# 		ALL 			Log all statemnts events
#
# 		ERRORS 		Log only failed statement events
#
# 		NONE 			Do not log statement events 		
#
# 		NOTE:
# 			At server startup, any explicit value given for audit_log_statement_policy may be overridden if audit_log_policy is also specified,
# 			as described earlier.
#
# ) audit_log_strategy
#
# 		Property 					Value
# 		Cmd line: 					--audit-log-strategy=value
# 		Introduced: 				8.0.11
# 		System var: 				audit_log_strategy
# 		Scope: 						Global
# 		Dynamic: 					No
# 		SET_VAR Hint: 				No
# 		Type: 						Enumeration
# 		DEfault: 					ASYNCHRONOUS
# 		Valid: 						ASYNCHRONOUS, PERFORMANCE, SEMISYNCHRONOUS, SYNCHRONOUS
#
# 		The logging method used by the audit log plugin. These strategy values are permitted:
#
# 			Asynchronous: Log asynchronously. Wait for space in the output buffer.
#
# 			Performance: Log asynchronously. Drop requests for which there is insufficient space in the output buffer.
#
# 			Semisynchronous: Log synchronously. Permit caching by the operating system.
#
# 			Synchronous: Log synchronously. Call sync() after each request.
#
# AUDIT LOG STATUS VARIABLES
#
# If the audit log plugin is enabled, it exposes several status variables that provide operational information.
# These variables are available for legacy mode audit filtering and JSON mode audit filtering:
#
# 		) Audit_log_current_size
# 		
# 			The size of the current audit log file. The value increases when an event is written to the log and is reset ot 0 when the log is rotated.
#
# 		) Audit_log_event_max_drop_size
# 	
# 			The size of the largest dropped event in performance logging mode. #
# 
# 		) Audit_log_events
#
# 			The number of events handled by the audit log plugin, whether or not they were written to the log based on filtering policy
#
# 		) Audit_log_events_filtered
#
# 			The numbenr of events handled by the audit log plugin that were filtered (not written to the log) based on filtering policy
#
# 		) Audit_log_events_lost
#
# 			The number of events lost in performance logging mode because an event was larger than the available audit log buffer space.
# 			This value may be useful for assessing how to set audit_log_buffer_size to size the buffer for performance mode.
#
# 		) Audit_log_events_written
#
# 			The number of events written to the audit log.
#
# 		) Audit_log_total_size
#
# 			The total size of events written to all audit log files. 
# 			Unlike Audit_log_current_size, the value of Audit_log_total_size increases even when the log is rotated.
#
# 		) Audit_log_write_waits
#
# 			The number of times an event had to wait for space in teh audit log buffer in asynchronously logging mode.
# 
#
# AUDIT LOG RESTRICTIONS
#
# MysQL Enterprise audit is subject to these general restrictions:
#
# 		) Only SQL statements are logged. Changes made by no-SQL APIs, such as memcached, Node.JS and the NDB API are not logged.
#
# 		) Only top-level statements are logged, not statements within stored programs such as triggers or stored procedures.
#
# 		) Contents of files referenced by statements such as LOAD_DATA_INFILE are not logged.
#
# NDB CLUSTER -> It is possible to use MySQL Enterprise Audit with MySQL NDB cluster, subject to the following conditions:
#
# 		) All changes to be logged must be done using the SQL interface.
# 			Changes using no-SQL interfaces, such as those provided by the NDB API, memcached, or ClusterJ, are not logged.
#
# 		) The plugin must be installed on each MySQl server that is used to execute SQL on the cluster.
#
# 		) Audit plugin data must be aggreggated amongst all MySQL servers used with the cluster.
# 			This aggreggation is the responsibility of the application or user.
#
# MySQL ENTERPRISE FIREWALL
#
# MySQL Enterprise Edition includes MySQL Enterprise Firewall, an application-level firewall that enables datbase 
# admins to permit or deny SQL statements execution based on matching against whitelists or accepted statement patterns.
#
# This helps harden the MySQL server against attackers such as SQL injections or attempts to exploit applicaitons by using
# them outside of their legitimate query workload characteristics.
#
# Each MySQL account registered with the firewall has its own statement whitelist, enabling protection to be tailored
# per account.
#
# For a given account, the firewall can operate in recording, protecting or detecting mode, for training
# in the accepted statement patterns, active protection against unacceptable statements, or passive detection of unacceptable
# statements.
#
# This figure illustreates how the firewall processes incoming statements in each mode:
#
# MySQL ENTERPRISE FIREWALL OPERATIONS
#
#
#
#
# Receive SQL from client >>>>>>>>>>>>>> Digest into parser tokens >>>>>> Firewall
# 																						  				V 					OFF
# 											Store SQL Digest    <<<<<<<<<<<<<<Check user Firewall Mode >>>>>>		 
#  							in Firewall Whitelist			Recording  				V 							V
# 													V												V 							V
# 													V 					Yes						V  						V
# 													V<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<< In Whitelist?     		V	
#												   V 												V 							V
# 													V 												V No 						V
# 													V 												V 							V
# 													V 											Firewall Alert 			V
# 													V 											to Error Log 				V
# 													V	 											V	 						V
# 													V 			Detect							V 							V
# 													<<<<<<<<<<<<<<<<<<<<<<<<<<<<< Detect or Protect Mode 		V
# 													V 												V 							V
# 													V											Protect >> Reject 		V
# 													V 														 					V
# 													Execute SQL <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
#
# 
#
# The following sections describe the components of MYSQL Enterprise Firewall, discuss how ot install it and use it,
# and provide reference info for its components.
#
# MySQL ENTERPRISE FIREWALL COMPONENTS
#
# MySQL Enterprise Firewall is based on a plugin library that implements these components:
#
# 		) A server-side plugin named MySQL_FIREWALL examines SQL statements before htey execute,
# 			and based on it's in-memory cache, renders a decision whether to execute or reject each statement.
#
# 		) Server-side plugins named MySQL_FIREWALL_USERS and MYSQL_FIREWALL_WHITELIST implement INFORMATION_SCHEMA tables that provide
# 			views into the firewall data cache.
#
# 		) System tables named firewall_users and firewall_whitelist in the mysql databse provide persistent storage of firewall data.
#
# 		) Stored procedures named sp_set_firewall_mode() and sp_reload_firewall_rules() performs tasks such as registering
# 			MySQl accounts with the firewall, establishing their operational mode, and managing transfer of firewall data
# 			between the cache and the underlying system tables.
#
# 		) A user of user-defined functions provide an SQL-level API for lower-level tasks such as syncrhonizing the cahce 
# 			with the underlying system tables.
#
# 		) System variables enable firewall configuration and status variables provide runtime operational information.
#
# 		) FIREWALL_ADMIN and FIREWALL_USER privileges enables users to administer firewall rules for any user, and their own firewall rules, respectively.
#
# INSTALLING OR UNINSTALLING MySQL ENTERPRISE FIREWALL
#
# MySQL Enterprise Firewall installation is a one-time operaiton that installs the components described earlier.
#
# Installation can be pformed using a grpahical interface or manually:
#
# 		) On Windows MySQL isntaller includes an option to enable MySQL Enterpise Firewall for you.
#
# 		) MySQL WOrkbench 6.3.4 >= can install MySQL Enterprise Firewall, enable or disable an installed firewall,
# 			or uninstall the firewall..
#
# 		) Manual MYSQL enterprise firewall installation involves running a script located in the share directory
# 			of your MySQL installation.
#
# 		NOTE: 
# 			If installed, MySQL Enterprise FIrewall involves some minimal overhead, even when disabled.
# 			To avoid this overhead, do not install lest you intend to use it.
#
# 		Note:
# 			MySQL Enteprise Firewall does not work together with the query cache.
# 			IF the query cache is enabled, disable it before installing the firewall.
#
# INSTALLING MYSQL ENTERPRISE FIREWALL
#
# If MySQL Enterprise Firewall is already installed from an older version of MysQl, uninstall it.
#
# The installation script is in the share directory of the MySQL installation.
#
# win_install_firewall.sql for Windows based, linux_install_firewall.sql for Linux based.
#
# The installation script creates stored procedures in the default database, so choose a database to use.
# Then run the script as follows, naming the chosen databse on the cmdl ine.
#
# The example here uses hte mysql database and the Linux installation script.
#
# Make hte appropriate substitution for your system.
#
# mysql -u root -p mysql < linux_install_firewall.sql
# Enter password: (enter password here)
#
# INstalling MysQL ENterprise Firewall either using a graphical interface or manually should enable the firewall.
# To verify that, connect to the server and execute this statement:
#
# SHOW GLOBAL VARIABLES LIKE 'mysql_firewall_mode';
# +-----------------------------+
# | Variable_name      | Value  |
# +-----------------------------+
# | Mysql_firewall_mode| ON 	  |
# +-----------------------------+
#
# UNINSTALLING MYSQL ENTERPRISE FIREWALL
#
# MySQL Enteprise Firewall can be uninstalled using MySQL workbench or manually.
#
# To uninstall MySQl Enterprise Firewall using MysQL workbench 6.3.4 or higehr, see respective place.
#
# To uninstall MySQL Enterprise firewall manually, exceute the following statements.
# it is assumed that the stored procedures were created in the MySQL databse.
#
# Adjust the DROP_PROCEDURE statements appropriately if the procedures were created
# in a different DB.
#
# DROP TABLE mysql.firewall_whitelist;
# DROP TABLE mysql.firewall_users;
#
# UNINSTALL PLUGIN mysql_firewall;
# UNINSTALL PLUGIN mysql_firewall_whitelist;
# UNINSTALL PLUGIN mysql_firewall_users;
#
# DROP FUNCTION set_firewall_mode;
# DROP FUNCTION normalize_statement;
# DROP FUNCTION read_firewall_whitelist;
#
# DROP FUNCTION read_firewall_users;
# DROP FUNCTION mysql_firewall_flush_status;
#
# DROP PROCEDURE mysql.sp_set_firewall_mode;
# DROP PROCEDURE mysql.sp_reload_firewall_rules 
#
# USING MYSQL ENTERPRISE FIREWALL
#
# Before using MYSQL Enterprise Firewall, install it according to the instructions previously.
#
# Also, MySQL Enterprise Firewall does not work together with the query cache; disable the query cache
# if it is enabled.
#
# THis section describes how to configure MySQL Enterprise Firewall using SQL statements.
# Alternatively, the workbench provides a UI for it.
#
# To enable or disable the firewall, set the mysql_firewall_mode system variable.
#
# by default, this variable is enabled when the firewall is installed.
# To control the install firewall state explicitly, you can set the variable at server startup.
#
# Fo rexample, to enable the firewall in an option file, use these lines:
#
# 	[mysqld]
# 	mysql_firewall_mode=ON
#
# It is also possible to disalbe or enable the firewall at runtime:
#
# 	SET GLOBAL mysql_firewall_mode = OFF;
# 	SET GLOBAL mysql_firewall_mode = ON;
#
# In addition to the global on/off firewall mode, each account registered with the firewall has its own operational mode.
#
# For an account in recording mode, the firewall learns an applications "fingerprint", that is, the acceptable
# statement patterns that taken together - form a whitelist.
#
# After training, switch the firewall to protecting mode to harden MySQL against access by statements that deviate from
# the fingerprint.
#
# For additional training, switch the firewall back to recording mode as necessary to update the
# whitelist with new statement patterns.
#
# An instrusion-detection mode is avialable that writes supsicious statements ot hte error log but does not deny access.
#
# The firewall maintains whitelist rules on a per-account basis, enabling implementation of protection strats such as these:
#
# 	) For an applicaiton that has unique protection requirements, configure it to use an account that is not used for any other purpose.
#
# 	) For applications that are related and share protection requirements, configure them as group to use the same account.
#
# Firewall operations is based on conversion of SQL statements to normalized digest form.
# Firewall digests are like the statement digest used by the Performance Schema (mroe on that later).
#
# However, unlike the Performance Schema, the relevant digest-related system variable is max_digest_length.
#
# For a connection from a registered account, the firewall converts each incoming statement to normalized form
# and processes it accoring to the account mode:
#
# 	) IN recording mode, the firewall adds the normalized statement to the account whitelist rules.
#
# 	) In protection mode, the firewall compares the normalized statement to the account whitelist rules.
#
# 		If there is a match, teh statement passes and the server continues to process it.
#
# 		Otherwise, the server rejects the statement and returns an error to the client.
#
# 		The firewall also writes the rejected statement to the erorr log if the mysql_firewall_trace system
# 		variable is enabled.
#
# 	) IN detecting mode, the firewall matches statements as in protecting mode, but writes nonmatching
# 		statements ot the error log without denying access.
#
# accounts that have a mode of OFF or are not registered with the firewall are ignored by it.
#
# TO protect an account using MySQL Enterprise FIrewall,, follow these steps:
#
# 1. Register an account and put it in recording mode.
#
# 2. Connect to the MySQL server using the registered acc and execute statements otb e learned.
# 		This establishes the account whitelist of accepted statements.
#
# 3. Switch the registered account to protecting mode.
#
# THe following examples shows how to reigster an account with the firewall, use the firewall to learn acceptable
# statements for that account and protect the account against execution of unacceptable statements.
#
# The example account, 'fwuser'@'localhost' is for use by an application that accesses tables in the sakila DB.
#
# NOTE:
#
# 		THe user and host parts of the account name are quoted separately for statements such as CREATE_USER
# 		and GRANT, whereas to specify an account for use with a firewall component, name it as a single quoted
# 		string 'fwuser@localhost'
#
# 		The convention for naming accounts as a single quoted string for firewall components means that you cannot
# 		use accounst that have embedded @ chars in the user name.
#
# Perform the step in the following procedure as an ADMIN priv acc, except those designated for execution by the acc registered
# with the firewall.
#
# The default DB should be sakila, for statements executed using the registered account.
#
# 1. IF called for, create teh acc to be protected (choose an appropriate pW), and grant privs for the saila DB:
#
# 		CREATE USER 'fwuser'@'localhost' IDENTIFIED BY 'fWp@3sw0rd';
# 		GRANT ALL on sakila.* to 'fwuser'@'localhost';
#
# 2. use the sp_set_firewall_mode() stored procedure to register the account with the firewall and place it in recording mode.
# 		(If the procedure is located in a database other than MySQL - adjust the statement accordingly):
#
# 		CALL mysql.sp_set_firewall_mode('fwuser@lcoalhost', 'RECORDING');
#
# 		During the course of its execution, the stored procedure invokes firewall user-defiend functions, which may produce output of their own.
#
# 3. Using the registered account, connect to the server, then execute some statements that are legitimate for it:
#
# 		SELECT first_name, last_name FROM customer WHERE customer_id = 1;
# 		UPDATE rental SET return_date = NOW() WHERE rental_id = 1;
# 		SELECT get_customer_balance(1, NOW());
#
# The firewall converts the statements to digest form and records them in the account whitelist.
#
# NOTE:
# 		uNtil the account executes statements in recording mode, its whitelist is empty.
# 		Which is equvialent to "deny all".
#
# 		IF switched to protective mode, the account will be effectively prohibited from executing statements..
#
# 4. At this point, the user and whitelist information is cached and can be seen in the firewall INFORMATION_SCHEMA tables:
#
# 		SELECT MODE FROM INFORMATION_SCHEMA.MYSQL_FIREWALL_USERS
# 		WHERE USERHOST = 'fwuser@localhost';
# 		+-------------+
# 		| MODE 		  |
# 		+-------------+
# 		| RECORDING   |
# 		+-------------+
#
# 		SELECT RULE FROM INFORMATION_SCHEMA.MYSQL_FIREWALL_WHITELIST
# 		WHERE USERHOST = 'fwuser@localhost';
#
# 		+-------------------------------------------------------------------------------+
# 		| RULE 																								  |
#  	+-------------------------------------------------------------------------------+
# 		| SELECT `fire_name`,  `last_name` FROM `customer` WHERE `customer_id` = ? 	  |
# 		| SELECT `get_customer_balance` ( ? , NOW ( ) ) 										  |
# 		| UPDATE `rental` SET `return_date` = NOW ( ) WHERE `rental_id` = ? 				  |
# 		| SELECT @@`version_comment` LIMIT ? 														  |
# 		+-------------------------------------------------------------------------------+
#
# NOTE:
#
# 		The @@version_comment rule comes from a statement sent automatically by the mysql client when
# 		you connect to the server as the registered user.
#
# 		IT is important to train teh firewall under conditions matching application use.
#
# 		For example, a given MySQL connector might send statements to the server at teh beginning
# 		of a connection to determine server characteristics and capabilities.
#
# 		IF an application normally is used through taht connector, train the firewall that way, too.
#
# 		That enables those initail statements to become part of the whitelist for the account
# 		associated with the application.
#
# 5. Use the stored procedure to switch the registered user to protecting mode:
#
# 		CALL mysql.sp_set_firewall_mode('fwuser@localhost', 'PROTECTING');
#
# 		IMPORTANT:
#
# 				Switching the account out of RECORDING mode synchronizes its firewall cache data
# 				to the underlying mysql system database for persistent storage.
#
# 				If you do not switch the mode for a user who is being recored, the cached whitelist
# 				data is not written to the system tables and will be lost when the server is restarted.
#
# 6. Using the registered account, execute some acceptable and unacceptable statements.

# 		The firewall matches each one against the account whitelist and accepts or rejects it.
#
# 		This statement is not identical to a training statement, but produces the same normalized statement as one of them,
# 		so the firewall accepts it:
#
# 			SELECT first_name, last_name FROM customer WHERE customer_id = '48';
# 			+-----------------------+
# 			| first_name | last_name|
# 			+-----------------------+
# 			| ANN 		 | EVANS 	|
# 			+-----------------------+
#
# 		These statements do not match anything in the whitelist and each results in an error:
#
# 			SELECT first_name, last_name FROM customer WHERE customer_id = 1 OR TRUE;
# 			ERROR 1045 (28000): Statement was blocked by Firewall
#
# 			SHOW TABLES LIKE 'customer%';
# 			ERROR 1045 (28000): Statement was blocked by Firewall
#
# 			TRUNCATE TABLE mysql.slow_log;
# 			ERROR 1045 (28000): Statement was blocked by Firewall
#
# 		The firewall also writes the rejected statements to the error log if the mysql_firewall_trace 
# 		system variable is enabled.
#
# 		For example:
#
# 			[Note] PLugin MYSQL_FIREWALL reported:
# 			'ACCESS DENIED for fwuser@localhost. Reason: No match in whitelist.
# 			Statement: TRUNCATE TABLE `mysql`.`slow_log`'
#
# 		You can use these log messages in your efforts to identify the source of attacks.
#
# 7. You can log nonmatching statements as supsicious without denying access.
# 		To do this, put the account in intrusion-detecting mode:
#
# 			CALL mysql.sp_set_firewall_mode('fwuser@localhost', 'DETECTING');
#
# 8. Using the registered account, connect to the server, then execute a statement that does not match
# 		the whitelist:
#
# 		SHOW TABLES LIKE 'customer%';
# 		+-----------------------------+
# 		| Tables_in_sakila (customer%)|
# 		+-----------------------------+
# 		| customer 							|
# 		| customer_list 					|
# 		+-----------------------------+
#
# 		In detecting mode, the firewall permits the nonmatching statement to execute but writes a message
# 		to the error log:
#
# 		[Note] Plugin MYSQL_FIREWALL reported:
# 		'SUSPICIOUS STATEMENT from 'fwuser@localhost'. Reason: No match in whtielist.
# 		Statement: SHOW TABLES LIKE ? '
#
# 9. To assess firewall activity, examine its status variables:
#
# 		SHOW GLOBAL STATUS LIKE 'Firewall%';
#		+-----------------------------------+
# 		| Variable_name 				| Value 	|
# 		+-----------------------------------+
# 		| Firewall_access_denied 	 | 3 		|
# 		| Firewall_access_granted 	 | 4 		|
# 		| Firewall_access_suspicious| 1 		|
# 		| Firewall_cached_entries 	 | 4 		|
# 		+-----------------------------------+
#
# 		The variable indicates the number of statements rejected, accepted, logged as supicious, and added to the cache, respectively.
#
# 		The Firewall_access_granted count is 4 - because of the @@version_comment statement sent by the MySQL client each 
# 		time you use it to connect as the registered user, plus the SHOW_TABLES statement that was not blocked in DETECTING mode.
#
# SHould additional training for an account be necessary, switch it to recording mode again, then back to protecting mode
# after executing statements to be added to the whitelist.
#
# MySQL ENTERPRISE FIREWALL REFERENCE
#
# MySQL ENTERPRISE FIREWALL TABLES
#
# MySQL Enterprise Firewall maintains account and whitelist information.
#
# It uses INFORMATION_SCHEMA tables to provide views into cached data, and tables in teh mysql system database to  		
# store this data in persistent form.
#
# When enabled, the firewall bases its operational decisions on the cached data.
#
# The INFORMATION_SCHEMA tables are accessible by anyone.
#
# The MysQL tables can be accessed only by users with privileges for that database. 		
#
# The INFORMATION_SCHEMA:MYSQL_FIREWALL_USERS and mysql.firewall_users table list registered firewall
# accounts and their operational modes.
#
# The tables have these columns:
#  
# 		) USERHOST
#
# 			An account registered with the firewall.
#
# 			Each account has the format user_name@host_name and represents actual user and host names as authenticated
# 			by the server.											
#
# 			Patterns and netmasks should not be used when registering users.
#
# 		) MODE
#
# 			The current firewall operation mode for the account.
#
# 			The permitted mode values are OFF, DETECTING, PROTECTING, RECORDING and RESET.
#
# 			For details about their meanings, see the description of sp_set_firewall_mode()
#
# The INFORMATION_SCHEMA.MYSQL_FIREWALL_WHITELIST and mysql.firewall_whitelist tables list 
# registered firewall accounts and their whitelists.
#
# The tables have these columns:
#
# 		) USERHOST
#
# 			An account registered with the firewall. The format is the same as for the user account tables.
#
# 		) RULE
#
# 			A normalized statement indicating an acceptable statement pattern for teh account. An accounte whitelist is the union of its rules.
#
# 		) ID
#
# 			An integer column that is a primary key for the table. This was added in 8.0.12
#
# MYSQL ENTERPRISE FIREWALL PROCEDURES AND FUNCTIONS
#
# MySQL Enterprise Firewall has stored procedures that perform tasks such as registering
# MySQL accounts with the firewall, establishing their operational mode and managing transfer of
# firewall data between the cache and the underlying system tables. 
#
# It also has a set of user-defiend functions (UDFs) that provides an SQL-level API for low level
# tasks such as synchronizing the cache with the underlying system tables.
#
# Under normal operation, the stored procedures implemetn the user interface.
# The UDFs are invoked by the stored procedures, not directly by users.
#
# To invoke a stored procedure when the default database is not hte database that contains
# the procedure, qualify the procedure name with hte database name.,
#
# For example:
#
# 		CALL mysql.sp_set_firewall_mode(user, mode);
#
# The following list describes each firewall stored procedure and UDF:
#
# 		) sp_reload_firewall_rules(user)
#
# 			This stored procedure uses firewall UDFs to reset a registered account and reload the
# 			in-memory rules for it from the rules stored in the mysql.firewall_whitelist table.
#
# 			This procedure provides control over firewall operation for individual accounts.
#
# 			The user argument names the affected account, as as tring in user_name@host_name format.
#
# 			Example:
#
# 				CALL mysql.sp_reload_firewall_rules('fwuser@localhost');
#
# 			WARNING:
#
# 				This procedure sets the account mode to RESET, which clears the account whitelist and sets it
# 				mode to OFF.
#
# 				If the account mode was not OFF prior to the sp_reload_firewall_rules() call, use sp_set_firewall_mode()
# 				to restore its previous mode after reloading the rules.
#
# 				For example, if the account was in PROTECTING mode, that is no longer true after calling
# 				sp_reload_firewall_rules() and you must set it to PROTECTING again explicitly.
#
# 		) sp_set_firewall_mode(user,mode)
#
# 			THis stored procedure registers a MySQL account with hte firewall and establishes its operational mode.
#
# 			The procedure also invokes firewall UDFs as necessary to transfer firewall data between the cache
# 			and the underlying system tables.
#
# 			THis procedure may be called even if the mysql_firewall_mode system variable is OFF, although
# 			setting the mode for an account has no operational effect while the firewall is disabled.
#
# 			THe user argument names the affected account, as a string in user_name@host_name format.
#
# 			The mode is hte operational mode for the user, as a string. These mode values are permitted:
#
# 				) OFF: Disables the firewall for the account
#
# 				) DETECTING: Intrusion-detecting mode: Write suspicious (nonmatching) statements to the error log but do not deny access.
#
# 				) PROTECTING: Protect the account by matching incoming statements against the account whitelist.
#
# 				) RECORDING: Training mode: Record acceptable statements for the account.
#
# 								Incoming statements that do not immediately fail with a syntax error are recorded to become part
# 								of the account whitelist rules.
#
# 				) RESET: Clear the account whitelist and set the account mode to OFF.
#
# Switching the mode for an account to any mode but RECORDING synchronizes the firewall cache data to the underlying
# mysql system database for persistent storage.
#
# Switching the mode from OFF to RECORDING reloads the whitelist from the mysql.firewall_whitelist table into the cache.
#
# If an account has an empty whitelist, setting its mode to PROTECTING produces an error message that is returned
# in a result set, but not an SQL error:
#
# 		CALL mysql.sp_set_firewall_mode('a@b', 'PROTECTING');
# 		+------------------------------------------------------------------------+
# 		| set_firewall_mode(arg_userhost, arg_mode) 			 							 |
# 		+------------------------------------------------------------------------+
# 		| ERROR: Protecting mode requested for a@b but the whitelist is empty.   |
# 		+------------------------------------------------------------------------+
#
# 		1 row in set (0.02 sec)
#
# 		Query OK, 0 rows affected (0.02 sec)
#
# ) mysql_firewall_flush_status()
#
# 		This UDF resets several firewall status variables to 0:
#
# 			Firewall_access_denied
# 			Firewall_access_granted
# 			Firewall_access_suspicious
#
# 		Example:
#
# 			SELECT mysql_firewall_flush_status();
#
# ) normalize_statement(stmt)
#
# 		This UDF normalizes an SQL statement into the digest form used for whitelist rules.
#
# 		Example:
#
# 			SELECT normalize_statement('SELECT * FROM t1 WHERE c1 > 2');
#
# ) read_firewall_users(user, mode)
#
# 		This aggreggate UDF updates the firewall user cache through a SELECT statement on the 
# 		mysql.firewall_users table.
#
# 		Example:
#
# 			SELECT read_firewall_users('fwusers@localhost', 'RECORDING')
# 			FROM mysql.firewall_users;
#
# ) read_firewall_whitelist(user, rule)
#
# 		THis aggreggate UDF updates the recorded statement cache through a SELECT statement on the
# 		mysql.firewall_whitelist table.
#
# 		Example:
#
# 			SELECT read_firewall_whitelist('fwuser@localhost', 'RECORDING')
# 			FROM mysql.firewall_whitelist;
#
# ) set_firewall_mode(user, mode)
#
# 		This UDF manages the user cache and establishes the user operational mode.
#
# 		Example:
#
# 				SELECT set_firewall_mode('fwuser@localhost', 'RECORDING');
#
# MYSQL ENTERPRISE FIREWALL SYSTEM VARIABLES
#
# MySQL Enterprise Firewall supports the following system variables.
# Use them to configure firewall operation.
#
# These variables are unavailable unless the FW is installed.
#
# 	) mysql_firewall_mode
#
# 		Property 					Value
# 		Cmd line: 					--mysql-firewall-mode={OFF|ON}
# 		Introduced: 				8.0.11
# 		Sys Var: 					mysql_firewall_mode
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Boolean
# 		Default: 					ON
#
# 		Whether MySQL Enterprise Firewall is enabled (the default) or disabled.
#
# ) mysql_firewall_trace
#
# 		Property 					Value
# 		Cmd line: 					--mysql-firewall-trace={OFF|ON}
# 		INtroduced: 				8.0.11
# 		Sys var: 					mysql_firewall_trace
# 		Scope: 						Global
# 		Dynamic: 					Yes
# 		SET_VAR Hint: 				No
# 		Type: 						Boolean
# 		Default: 					OFF
#
# 		Whether the MySQL Enterprise Firewall Trace is enabled or disabled (the default).
#
# 		WHen mysql_firewall_trace is enabled, for PROTECTING mode, the firewall writes
# 		rejected statements to the error log.
#
# MYSQL ENTERPRISE FIREWALL STATUS VARIABLES
#
# MySQL ENterprise Firewall supports hte following status variables.
#
# Use them to obtain information about firewall operational status.
# THese variables are unavailabel unless hte firewall is installed.
#
# Firewall status variables are set to 0 whenever the MYSQL_FIREWALL plugin is installed
# or the server is started.
#
# Many of them are reset to zero by the mysql_firewall_flush_status UDF.
#
# ) Firewall_access_denied
#
# 		The number of statements rejected by MySQL Enterprise Firewall
#
# ) Firewall_access_granted
#
# 		The number of statements accepted by MySQL Enterprise Firewall
#
# ) Firewall_access_suspicious
#
# 		Number of statements logged by the MySQl Enterprise Firewall as Suspicious for users who are in DETECTING mode.
#
# ) Firewall_cached_entries
#
# 		The number of statements recorded by MySQL Enterprise Firewall, including duplicates.
#
# MySQL ENTERPRISE DATA MASKING AND DE-IDENTIFICATION
#
# NOTE:
#
# 		MySQL Enterprise Data Masking and De-Identification is an extension included in MySQL Enterprise Edition.
#
# As of MySQL 8.0.13, MySQL Enterprise Edition provides data masking and de-identification capabilities:
#
# 		) Transformation of existing data to mask it and remove identifying characteristics, such as changing
# 			all digits of a credit card number but the last four to 'X' Chars.
#
# 		) Generation of random data, such as email addresses and payment card numbers.
#
# The way that applications use these capabilities depends on the purpose for which the data will be used
# and who will access it:
#
# 		) Applications that use sensitive data may protect it by performing data masking and permiting use
# 			of partially masked data for client identification.
#
# 			Example: A call center may ask for clients to provide their last four social security number digits.
#
# 		) Applications that require properly formatted data, but not necessarily the original data, can synthesize sample data.
#
# 			Example: An application developer who is testing data validators but has no access to original data may synthesize
#  					random data with the same format.
#
# Example 1:
#
# 		Medical research facilities can hold patient data that comprises a mix of personal and medical data.
# 		This may include genetic sequences (long strings), test results stored in JSON format, and other data types.
#
# 		Although the data may be used mostly by automated analysis software, access to genome data or test results
# 		of particular patients is still possible.
#
# 		In such cases, data masking should be used to render this information not personally identifiable.
#
# Example 2:
#
# 		A credit card processor company provides a set of services using sensitive data, such as:
#
# 			) Processing a large number of financial transactions per second
#
# 			) Storing a large amount of transaction-related data.
#
# 			) Protecting transaction-related data with strict requirements for personal data.
#
# 			) Handling client complaints about transactions using reversible or partially masked data.
#
# A typical transaction may include many types of sensitive information, including:
#
# 		) Credit card number
#
# 		) Transaction type and amount
#
# 		) Merchant type
#
# 		) Transaction cryptogram (to confirm transaction legitimacy)
#
# 		) Geolocation of GPS-equipped terminal (for fraud detection)
#
# Those types of information may then be joined within a bank or other card-issuing financial institution
# with client personal data, such as:
#
# 		) Full cient name (either person or company)
#
# 		) Address
#
# 		) Date of birth
#
# 		) Social Security number
#
# 		) Email address.
#
# 		) Phone number
#
# Various employee roles within both the card processing company and the financial institution require access
# to that data.
#
# Some of these roles may require access only to masked data.
#
# Other roles may require access to the original data on a case-to-case basis, which is recorded in audit logs.
#
# Masking and de-identification are core to regulatory compliance, so MySQL Enterprise Data Masking and De-identificaiton
# can help application developers satisfy privacy requirements:
#
# 		) PCI - DSS: Payment Card Data
#
# 		) HIPAA: Privacy of Health Data, Heqlth Information Technology for Economic and Clinical Health Act (HITECH Act)
#
# 		) EU General Data Protection Directive (GDPR): Protection of Personal Data
#
# 		) Data Protection Act (UK): Protection of Personal Data
#
# 		) Sarbanes Oxley, GLBA, The USA Patriot Act, Identity Theft and Assumption Deterrence Act of 1998.
#
# 		) FERPA - Student Data, NASD, CA SB1386 and AB 1950,, State Data Protection Laws, Basel II
#
# THe following sections describe the components of MySQL Enterprise Data Masking and De-Identification,
# discuss how to install and use it, and provide reference information for its components.
#
# MySQL Enterprise DATA MASKING AND DE-IDENTIFICATION COMPONENTS
#
# MySQL Enterprise Data Masking and De-Identification is based on a plugin library that implements these components:
#
# 		) A server-side plugin named data_masking
#
# 		) A set of user-defined functions (UDFs) provides an SQL-level API for performing masking 
# 			and de-identification operations.
#
# 			Some of these functions require the SUPER privilege.
#
# INSTALLING OR UNINSTALLING MySQL ENTERPRISE DATA MASKING AND DE-IDENTIFICATION
#
# This section describes how to install or uninstall MySQL Enterprise Data Masking and De-Identification,
# which is implemented as a plugin library file containing a plugin and user-defined functions (UDFs).
#
# To be usable by the server, the plugin library file must be located in the MySQL plugin directory
# (the directory named by the plugin_dir system variable).
#
# If necessary, configure the plugin directory location by setting the value of plugin_dir at server startup.
#
# The plugin library file base name is data_masking. The file name suffix differs per platform (for example,
# .so for UNIX based systems, .dll for Windows)
#
# To install the MySQL Enterprise Data Masking and De-Identification plugin and UDFs, use the INSTALL_PLUGIN and
# CREATE_FUNCTION statements (adjust the .so suffix for your platform as called for):
#
# INSTALL PLUGIN data_masking SONAME 'data_masking.so';
# CREATE FUNCTION gen_blacklist RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_dictionary RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_dictionary_drop RETURNS STRING SONAME 'data_masking.so';
# 
# CREATE FUNCTION gen_dictionary_load RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_range RETURNS INTEGER SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_rnd_email RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_rng_pan RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_rnd_ssn RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION gen_rnd_us_phone RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION mask_inner RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION mask_outer RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION mask_pan RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION mask_pan_relaxed RETURNS STRING SONAME 'data_masking.so';
#
# CREATE FUNCTION mask_ssn RETURNS STRING SONAME 'data_masking.so';
#
# If the plugin and UDFs are used on a master replication server, install them on all slave 
# servers as well to avoid replication problems.
#
# Once installed as just described, the plugin and UDFs remain installed until uninstalled.
# To remove them, use the UNINSTALL_PLUGIN and DROP_FUNCTION statements:
#
# UNINSTALL PLUGIN data_masking;
# DROP FUNCTION gen_blacklist;
# DROP FUNCTION gen_dictionary;
# DROP FUNCTION get_dictionary_drop;
#
# DROP FUNCTION gen_dictionary_load;
# DROP FUNCTION gen_range;
# DROP FUNCTION gen_rnd_email;
# 
# DROP FUNCTION gen_rnd_pan;
# DROP FUNCTION gen_rnd_ssn;
# DROP FUNCTION gen_rnd_us_phone;
#
# DROP FUNCTION mask_inner;
# DROP FUNCTION mask_outer;
# DROP FUNCTION mask_pan;
#
# DROP FUNCTION mask_pan_relaxed;
# DROP FUNCTION mask_ssn;
#
# USING MySQL ENTERPRISE DATA MASKING AND DE-IDENTIFICATION
#
# before using MySQL Enterprise Data Masking and De-identification, install it.
#
# To use MySQL Enterprise Data Masking and De-Identification in applications, invoke the
# functions that are appropriate for the operations you wish to perform.
#
# For detailed function desc., see later.
#
# This section demonstrates how ot use the functions to carry out some representative
# tasks.
#
# It first presents an overview of the available functions, followed by some examples of
# how the functions might be used in real-world context.
#
# MASKING DATA TO REMOVE IDENTIFYING CHARACTERISTICS
#
# MySQL provides general-purpose masking functions that mask arbitrary strings, and special-purpose masking functions
# that mask specific types of values.
#
# GENERAL-PURPOSE MASKING FUNCTIONS
#
# mask_inner() and mask_outer() are general-purpose functions that mask parts of arbitrary strings based
# on positions within the string:
#
# 		) mask_inner() masks the interior of its string argument, leaving the ends unmasked.
# 			Other arguments specify the sizes of the unmasked ends.
#
# 			SELECT mask_inner('This is a string', 5, 1); #Leave 5 first and last 1 unmasked
# 			+------------------------------------------+
# 			| mask_inner('This is a string', 5, 1) 	 |
# 			+------------------------------------------+
# 			| This XXXXXXXXXXXXXXg 						 	 |
# 			+------------------------------------------+
#
# 			SELECT mask_inner('This is a string', 1, 5); #leave first and  5 last unmasked
# 	
# 			+------------------------------------------+
# 			| mask_inner('This is a string', 1, 5) 	 |
# 			+------------------------------------------+
# 			| Txxxxxxxxxxxxxxxxxxtring 					 |
# 			+------------------------------------------+
#
# 		) mask_outer() does the reverse, masking the ends of its string argument, leaving the interior unmasked.
# 			Other arguments specify the sizes of the masked ends.
#
# 			SELECT mask_outer('This is a string', 5, 1); #Mask first 5 and last
# 			+-------------------------------------------+
# 			| mask_outer('This is a string', 5, 1) 	  |
# 			+-------------------------------------------+
# 			| XXXXXXis a strinX 								  |
# 			+-------------------------------------------+
#
# 			SELECT mask_outer('This is a string', 1, 5); #Mask first and 5 last
# 			+-------------------------------------------+
# 			| mask_outer('This is a string', 1, 5) 	  |
# 			+-------------------------------------------+
# 			| Xhis is a sXXXXX 								  |
# 			+-------------------------------------------+
#
# By default, mask_inner() and mask_outer() use 'X' as the masking character, but permit an optional
# masking-character argument:
#
# 			SELECT mask_inner('This is a string', 5, 1, '*'); #Mask with * char instead
# 			+------------------------------------------------+
# 			| mask_inner('This is a string', 5, 1, '*') 		 |
# 			+------------------------------------------------+
# 			| This ****************g 								 |
# 			+------------------------------------------------+
#
# 			SELECT mask_outer('This is a string', 5, 1, '#');
# 			+------------------------------------------------+
# 			| mask_outer('This is a string', 5, 1, '#') 		 |
# 			+------------------------------------------------+
# 			| #####is a strin# 										 |
# 			+------------------------------------------------+
#
# SPECIAL-PURPOSE MASKING FUNCTIONS
#
# Other masking functions expect a string argument representing a specific type of value and mask
# it to remove identifying characteristics.
#
# NOTE:
#
# 		The examples here supply function arguments using the random value generation functions that return the
# 		appropriate type of value.
#
# 		More about generation functions later.
#
# PAYMENT CARD PRIMARY ACCOUNT NUMBER MASKING.
#
# Masking functions provide strict and relaxed masking of Primary Account Numbers.
#
# 		) mask_pan() masks all but the last four digits of the number:
#
# 			SELECT mask_pan(gen_rnd_pan());
# 			+-------------------------------+
# 			| mask_pan(gen_rnd_pan()) 		  |
# 			+-------------------------------+
# 			| XXXXXXXXXXXXXXXXXX2461 		  |
# 			+-------------------------------+
#
# 		) mask_pan_relaxed() is similar but does not mask the first six digits that indicate the payment card issuer unmasked:
#
# 			SELECT mask_pan_relaxed(gen_rnd_pan());
# 			+--------------------------------+
# 			| mask_pan_relaxed(gen_rnd_pan())|
# 			+--------------------------------+
# 			| 770630XXXXXXXX0807 				|
# 			+--------------------------------+
#
# U.S. SOCIAL SECURITY NUMBER MASKING.
#
# mask_ssn() masks all but the last four digits of the number:
#
# 		SELECT mask_ssn(gen_rnd_ssn());
# 		+----------------------------------+
# 		| mask_ssn(gen_rnd_ssn()) 			  |
# 		+----------------------------------+
# 		| XXX-XX-1723 							  |
# 		+----------------------------------+
#
# GENERATING RANDOM DATA WITH SPECIFIC CHARACTERISTICS
#
# Several functions generate random values. These values can be used for testing,
# simulation and so forth.
#
# gen_range() returns a random integer selected from a given range:
#
# 		SELECT gen_range(1, 10);
# 		+-----------------------+
# 		| gen_range(1, 10) 		|
# 		+-----------------------+
# 		| 						6 		|
# 		+-----------------------+
#
# gen_rnd_email() returns a random email address in the example.com domain:
#
# 		SELECT gen_rnd_email();
# 		+--------------------------+
# 		| gen_rnd_email() 	  		|
# 		+--------------------------+
# 		|ayxnq.xmkpvvy@example.com |
# 		+--------------------------+
#
# gen_rnd_pan() returns a payment card Primary ACcount Number:
#
# 		SELECT gen_rnd_pan();
#
# (The gen_rnd_pan() function result is not shown, because its return values should be used only for
# testing, not for publication. It cannot be guaranteed that the number is not assigned to a legitimate payment account)
#
# gen_rnd_ssn() returns a random U.S. Social Security number with the first and second parts each chosen
# from a range not used for legitimate numbers:
#
# 		SELECT gen_rnd_ssn();
# 		+-------------------+
# 		| gen_rnd_ssn() 	  |
# 		+-------------------+
# 		| 912-45-1615 		  |
# 		+-------------------+
#
# gen_rnd_us_phone() returns a random U.S. phone number in the 555 area code not used for legitimate numbers:
#
# 		SELECT gen_rnd_us_phone();
# 		+-------------------------+
# 		| gen_rnd_us_phone() 	  |
# 		+-------------------------+
# 		| 1-555-747-5627 			  |
# 		+-------------------------+
#
# GENERATING RANDOM DATA USING DICTIONARIES
#
# MySQL Enterprise Data Masking and De-identification enables dictionaries to be used as sources of random values.
# To use a dictionary, it must first be loaded from a file and given a name.
#
# Each loaded dictionary becomes part of the dictionary registry.
#
# Items then can be selected from registered dictionaries and used as random values or as 
# replacements for other values.
#
# A valid dictionary file has these characteristics:
#
# 		) The file contents are plain text, one term per line.
#
# 		) Empty lines are ignored.
#
# 		) The file must contain at least one term.
#
# Suppose that a file named de_cities.txt contains these city names in Germany:
#
# 	Berlin
# 	Munich
# 	Bremen
#
# Also suppose that a file named us_cities.txt contains these city names in the U.S:
#
# 	Chicago
# 	Houston
# 	Phoenix
# 	El Paso
# 	Detroit
#
# Assume that the secure_file_priv system variable is set to /usr/local/mysql/mysql-files.
#
# IN that case, copy the dictionary files to that directory so that the MySQL server can access them.
#
# Then use gen_dictionary_load() to load the dictionaries into the dictionary registry and assign
# them names: 		
#
# SELECT gen_dictionary_load('/usr/local/mysql/mysql-files/de_cities.txt', 'DE_Cities');
# +------------------------------------------------------------------------------------+
# | gen_dictionary_load('/usr/local/mysql/mysql-files/de_cities.txt', 'DE_Cities') 		|
# +------------------------------------------------------------------------------------+
# | Dictionary load success 																				|
# +------------------------------------------------------------------------------------+
#
# SELECT gen_dictionary_load('/usr/local/mysql/mysql-files/us_cities.txt', 'US_Cities');
# +------------------------------------------------------------------------------------+
# | gen_dictionary_load('/usr/local/mysql/mysql-files/us_cities.txt', 'US_Cities') 	   |
# +------------------------------------------------------------------------------------+
# | Dictionary load success 																				|
# +------------------------------------------------------------------------------------+
#
# To select a random term from a dictionary, use gen_dictionary():
#
# 	SELECT gen_dictionary('DE_Cities');
# 	+----------------------------------+
# 	| gen_dictionary('DE_Cities') 	  |
# 	+----------------------------------+
# 	| Berlin 								  |
#  +----------------------------------+
#
#  SELECT gen_dictionary('US_Cities');
# 	+-----------------------------------+
# 	| gen_dictionary('US_Cities') 		|
# 	+-----------------------------------+
# 	| Phoenix 									|
# 	+-----------------------------------+
#
# To select a random term from multiple dictionaries, randomly select one of the dictionaries,
# then select a term from it:
#
# SELECT gen_dictionary(ELT(gen_range(1,2), 'DE_Cities', 'US_Cities'));
# +--------------------------------------------------------------------+
# | gen_dictionary(ELT(gen_range(1,2), 'DE_Cities', 'US_Cities')) 	  |
# +--------------------------------------------------------------------+
# | Detroit 																			  |
# +--------------------------------------------------------------------+
#
# SELECT gen_dictionary(ELT(gen_range(1,2), 'DE_Cities', 'US_Cities'));
# +--------------------------------------------------------------------+
# | gen_dictionary(ELT(gen_range(1,2), 'DE_Cities', 'US_Cities')) 	  |
# +--------------------------------------------------------------------+
# | Bremen 																				  |
# +--------------------------------------------------------------------+
#
# The gen_blacklist() function enables a term from one dictionary to be replaced by a term from
# another dictionary, which effects masking by substitution.
#
# Its arguments are the term to replace, the dictionary in which the term appears, and the dictionary
# from which to choose a replacement.
#
# For example, to substitute a U.S. city for a German city, or vice versa, use gen_blacklist() like this:
#
# 		SELECT gen_blacklist('Munich', 'DE_Cities', 'US_Cities');
# 		+------------------------------------------------------------+
# 		| gen_blacklist('Munich', 'DE_Cities', 'US_Cities') 			 |
# 		+------------------------------------------------------------+
# 		| Houston 																	 |
# 		+------------------------------------------------------------+
#
# 		SELECT gen_blacklist('El Paso', 'US_Cities', 'DE_Cities'); 
# 		+------------------------------------------------------------+
# 		| gen_blacklist('El Paso', 'US_Cities', 'DE_Cities') 			 |
# 		+------------------------------------------------------------+
# 		| Bremen 																	 |
# 		+------------------------------------------------------------+
#
# If the term to replace is not in the first dictionary, gen_blacklist() returns it unchanged:
#
# 		SELECT gen_blacklist('Moscow', 'DE_Cities', 'US_Cities'); 	
# 		+------------------------------------------------------------+
# 		| gen_blacklist('Moscow', 'DE_Cities', 'US_Cities') 			 |
# 		+------------------------------------------------------------+
# 		| Moscow 																	 |
# 		+------------------------------------------------------------+
#
# USING MASKED DATA FOR CUSTOMER IDENTIFICATION
#
# At customer-service call centers, one common identity verification technique is to ask customers
# to provide their last four Social Security number (SSN) digits.
#
# For example, a customer might say her name is Joanna Bond and that her last four SSN digits are 0007.
#
# Suppose that a customer table containing customer records has these columns:
#
#		) id: Customer ID number.
#
# 		) first_name: Customer first name.
#
# 		) last_name: Customer last name.
#
# 		) ssn: Customer Social Security number.
#
# The application used by customer-service representatives to check the customer SSN might execute a query like this:
#
# 		SELECT id, ssn
# 		FROM customer
# 		WHERE first_name = 'Joanna' AND last_name = 'Bond';
# 		+----+------------------+
# 		| id | ssn 					|
# 		+----+------------------+
# 		|786 | 906-39-0007 		|
# 		+----+------------------+
#
# However, that exposes the SSN to the customer-service representative, who has no need to see anything but the last
# 4 digits.
#
# Instead, the application can use this query to display only the masked SSN:
#
# 		SELECT id, mask_ssn(CONVERT(ssn USING binary))
# 		FROM customer
# 		WHERE first_name = 'Joanna' AND last_name = 'Bond';
# 		+----+---------------------------------------------+
# 		| id | mask_ssn(CONVERT(ssn USING binary)) 			|
# 		+----+---------------------------------------------+
# 		|786 | XXX-XX-0007 											|
# 		+----+---------------------------------------------+
#
# Now the representative sees only what is necessary, and customer privacy is preserved.
#
# Why was the CONVERT() function used for the argument to mask_ssn()?
#
# Because mask_ssn() requires an argument of length 11, and because UDFs treat string arguments
# as binary strings, with one byte par char.
#
# Thus, even though ssn is defined as VARCHAR(11), if the ssn column has a multibyte character set,
# it appears ot be longer than 11 bytes when passed to a UDF, and an error occurs.
#
# Converting the value to a binary string ensures that hte UDF sees an argument of length 11.
#
# A similar technique may be needed for other data masking functions when string arguments do
# not have a single-byte character set.
#
# CREATING VIEWS THAT DISPLAY MASKED DATA
#
# If masked data from a table is used for multiple queries, it may be convenient to define a view that
# produces masked data.
#
# That way, applications can select from the view without performing masking in individual queries.
#
# For example, a masking view on the customer table from the previous section can be defined like this:
#
# 		CREATE VIEW masked_customer AS
# 		SELECT id, first_name, last_name, mask_ssn(CONVERT(ssn USING binary)) AS ssn
# 		FROM customer;
#
# Then the query to look up a customer becomes simpler but still returns masked data:
#
# 		SELECT id, ssn
# 		FROM masked_customer
# 		WHERE first_name = 'Joanna' AND last_name = 'Bond';
# 		+----+---------------------+
# 		| id | ssn 						|
# 		+----+---------------------+
# 		|786 | XXX-XX-0007 			|
# 		+----+---------------------+
#
# MySQL ENTERPRISE DATA MASKING AND DE-IDENTIFICATION USER-DEFINED FUNCTION REFERENCE
#
# The MySQL Enterprise Data Masking and De-Identification plugin library includes several user-defined
# (UDFs), which may be grouped into these categories:
#
# 		) Data Masking Functions
#
# 		) Random Data Generation Functions
#
# 		) Random Data Dictionary-Based Functions
#
# These UDF's treat string arguments as binary strings, which means they are implicitly case sensitive.
# In addition, string UDF return values are binary strings.
#
# If a string return value should be in a different character set, convert it.
# 
# The following example shows how to convert the result of gen_rnd_email() to the utf8mb4 character set:
#
# 		SET @email = CONVERT(gen_rnd_email() USING utf8mb4);
#
# It may also be necessary to convertt string arguments.
#
# DATA MASKING FUNCTIONS
#
# Each function in this section performs a masking operation on its string argument and returns the masked result.
#
# 		) mask_inner(str, margin1, margin2 [, mask char])
#
# 			Masks the interior part of a string, leaving the ends untouched, and returns the result.
#
# 			An optional masking character can be specified.
#
# 				) Str: The string to mask.
#
# 				) margin1: A nonnegative integer that specifies the number of characters on the left end of the string to remain unmasked.
# 								If 0, no left end chars remain unmasked.
#
# 				) margin2: A nonnegative integer that specifies the number of characters on teh right end of the string to remain unmasked.
# 								If 0, no right end chars remain unmasked.
#
# 				) mask_char: (Optional) The single character to use for masking. The default is 'X', if mask_char is not given.
#
# 								Because UDF string arguments are treated as binary strings, the masking character must be a single-byte character.
# 								Attempts to use a multibyte character produce an error.
#
# Return value:
#
# The masked string or NULL if either margin is negative.
#
# If the sum of the margin values is larger than the argument length, no masking occurs
# and the argument is returned unchanged.
#
# Example:
#
# 		SELECT mask_inner('abcdef', 1, 2), mask_inner('abcdef', 0, 5);
# 		+-----------------------------+------------------------------+
# 		| mask_inner('abcdef', 1, 2) 	| mask_inner('abcdef', 0, 5) 	 |
# 		+-----------------------------+------------------------------+
# 		| aXXXef 							| Xbcdef 							 |
# 		+-----------------------------+------------------------------+
#
# 		SELECT mask_inner('abcdef', 1, 2, '*'), mask_inner('abcdef', 0, 5, '#');
# 		+---------------------------------+------------------------------+
# 		| mask_inner('abcdef', 1, 2, '*') | mask_inner('abcdef',0,5,'#') |
# 		+---------------------------------+------------------------------+
# 		| a***ef 								 | #bcdef 							  |
# 		+---------------------------------+------------------------------+
#
# ) mask_outer(str, margin1, margin2 [, mask char])
#
# 		Masks the left and right ends of a string, leaving the interor unmasked, and returns the result.
# 		An optional masking character can be specified.
#
# 		arguments:
#
# 			) str: The string to mask
#
# 			) margin1: A nonnegative integer that specifies the number of characters on the left end of the string to mask.
# 							If the value is 0, no left end characters are masked.
#
# 			) margin2: A nonnegative integer that specifies the number of characters on the right end of the string to mask.
# 							If the value is 0, no right end chars are masked.
#
# 			) mask_char: (Optional) The single character to use for masking. Default is 'X' if mask_char is not given.
#
# 				Because UDF string arguments are treated as binary strings, the masking character must be a single-byte character.
# 				Attempts to use a multibyte character produce an error.
#
# 	Return value:
#
# 	The masked string, or NULL if either margin is negative.
#
# 	If the sum of the margin values is larger than the argument length, the entire argument is masked.
#
# 	Example:
#
# 		SELECT mask_outer('abcdef', 1, 2), mask_outer('abcdef', 0, 5);
# 		+-----------------------------+-------------------------------+
# 		| mask_outer('abcdef', 1, 2)  | mask_outer('abcdef', 0, 5) 	  |
# 		+-----------------------------+-------------------------------+
# 		| XbcdXX 							| aXXXXX 							  |
# 		+-----------------------------+-------------------------------+
#
# 		SELECT mask_outer('abcdef', 1, 2, '*'), mask_outer('abcdef', 0, 5, '#');
# 		+---------------------------------+--------------------------------+
# 		| mask_outer('abcdef', 1, 2, '*') | mask_outer('abcdef', 0, 5, '#' |
# 		+---------------------------------+--------------------------------+
# 		| *bcd** 								 | a##### 								 |
# 		+---------------------------------+--------------------------------+
#
# ) mask_pan(str)
#
# 		Masks a payment card Primary Account Number and returns the number with all but the last four digits
# 		replaced by 'X' characters.
#
# 		Arguments:
#
# 			) str: The string to mask. The string must be a suitable length for the Primary Account Number, but is not otherwise checked.
#
# 		Return value:
#
# 		The masked payment number as a string. If the argument is shorter than required, it is returned unchanged.
#
# 		Example:
#
# 			SELECT mask_pan(gen_rng_pan());
# 			+------------------------------+
# 			| mask_pan(gen_rnd_pan()) 		 |
# 			+------------------------------+
# 			| XXXXXXXXXXXXXXXXXXX9102 		 |
# 			+------------------------------+
#
# 			SELECT mask_pan(gen_rnd_pan(19));
# 			+------------------------------+
# 			| mask_pan(gen_rnd_pan(19)) 	 |
# 			+------------------------------+
# 			| XXXXXXXXXXXXXXXXXXX8268 		 |
# 			+------------------------------+
#
# 			SELECT mask_pan('a*Z');
# 			+----------------------+
# 			| mask_pan('a*Z') 	  |
# 			+----------------------+
# 			| a*Z 					  |
# 			+----------------------+
#
# ) mask_pan_relaxed(str)
#
# 		Masks a payment card Primary Account Number and returns the number with all but the first six and last four digits
# 		replaced by 'X' characters.
#
# 		the first six digits indicate the payment card issuer.
#
# 		Arguments:
#
# 			) str: The string to mask. The string must be a suitable length for the Primary Account Number, but is not otherwise checked.
#
# 		Return value:
#
# 			The masked payment number as a string. If the argument is shorter than required, it is returned unchanged.
#
# 		Example:
#
# 			SELECT mask_pan_relaxed(gen_rnd_pan());
# 			+--------------------------------------+
# 			| mask_pan_relaxed(gen_rnd_pan()) 		|
# 			+--------------------------------------+
# 			| 551279xxxxxxxxxxxxxx3108 				|
# 			+--------------------------------------+
#
# 			SELECT mask_pan_relaxed(gen_rnd_pan(19));
# 			+--------------------------------------+
# 			| mask_pan_relaxed(gen_rnd_pan(19)) 	|
# 			+--------------------------------------+
# 			| 462634XXXXXXXXXXXXXX6739 				|
# 			+--------------------------------------+
# 		
# 			SELECT mask_pan_relaxed('a*Z');
# 			+------------------------------+
# 			| mask_pan_relaxed('a*Z') 		 |
# 			+------------------------------+
# 			| a*Z 								 |
# 			+------------------------------+
#
# 	) mask_ssn(str)
#
# 		Masks a U.S. Social Security number and returns the number with all but the last four digits replaced by 'X' characters.
#
# 		Arguments:
#
# 			) str: The string to mask. The string must be 11 chars long, but is not otherwise checked.
#
# 		Return value:
#
# 		The masked Social Security number as a string, or NULL if the argument is not the correct length.
#
# 		Example:
#
# 		SELECT mask_ssn('909-63-6922'), mask_ssn('abcdefghijk');
# 		+----------------------------+--------------------------+
# 		| mask_ssn('909-63-6922') 	  | mask_ssn('abcdefghijk')  |
# 		+----------------------------+--------------------------+
# 		| XXX-XX-6922 					  | XXX-XX-hijk 			     |
# 		+----------------------------+--------------------------+
#
# 		SELECT mask_ssn('909');
# 		+---------------------+
# 		| mask_ssn('909') 	 |
# 		+---------------------+
# 		| NULL 					 |
# 		+---------------------+
#
# RANDOM DATA GENERATION FUNCTIONS
#
# The functions in this section generate random values for different types of data.
#
# When possible, generated values have characteristics reserved for demonstration or test values,
# to avoid having them mistaken for legitimate data.
#
# For example, gen_rnd_us_phone() returns a U.S. phone number that uses the 555 area code, which is not
# assigned to phone numbers in actual use.
#
# INdividual function descriptions describe any exceptions to this principle.
#
# 		) gen_range(lower, upper)
#
# 			Generates a random number chosen from a specified range.
#
# 			Arguments:
#
# 				) lower: An integer that specifies the lower boundary of the range.
#
# 				) upper: An integer that specifies the upper boundary of the range, which must not be less than the lower boundary.
#
# 			Return value:
#
# 			A random integer in the range from lower to upper, inclusive or NULL if the upper argument is less than lower.
#
# 			Example:
#
# 				SELECT gen_range(100, 200), gen_range(-1000, -800);
# 				+------------------------+-------------------------+
# 				| gen_range(100,200) 	 | gen_range(-1000, -800)  |
# 				+------------------------+-------------------------+
# 				| 					177 		 | 						-917  |
# 				+------------------------+-------------------------+
##
# 				SELECT gen_range(1, 0);
# 				+----------------------+
# 				| gen_range(1, 0) 	  |
# 				+----------------------+
# 				| 					NULL    |
# 				+----------------------+
#
# 		) gen_rnd_email()
#
# 			Generates a random email address in the example.com domain.
#
# 			Arguments: None.
#
# 			Return value: A random email address as a string.
#
# 			Example:
#
# 				SELECT gen_rnd_email();
# 				+--------------------------+
# 				| gen_rnd_email() 			|
# 				+--------------------------+
# 				| ijocv.mwvhhuf@example.com|
# 				+--------------------------+
#
# 		) gen_rnd_pan([size])
#
# 			Generates a random payment card Primary Account Number.
# 			The number passes the Luhn check (an algorithm that performs a checksum verification against 
# 														a check digit)
#
# 			WARNING:
#
# 				Values returned from gen_rnd_pan() should be used only for test purposes, and are not suitable for publication.
# 				There is no way to guarantee that a given return value is not assigned to a legitimate payment account.
#
# 				Should it be necessary to publish a gen_rnd_pan() result, consider masking it with mask_pan() or mask_pan_relaxed()
#
# 			Argumnents:
#
# 				)size: (Optional) An integer that specifies the size of the result. The default is 16 if size is not given.
# 							If given, size must be an integer in the range from 12 to 19.
#
# 			Return value:
#
# 			A random payment number as a string, or NULL if a size argument outside the permitted range is given.
#
# 			Example:
#
# 				SELECT mask_pan(gen_rnd_pan());
# 				+------------------------------+
# 				| mask_pan(gen_rnd_pan()) 		 |
# 				+------------------------------+
# 				| XXXXXXXXXXXXXXXXX5805 		 |
# 				+------------------------------+
#
# 				SELECT mask_pan(gen_rnd_pan(19));
# 				+------------------------------+
# 				| mask_pan(gen_rnd_pan(19)) 	 |
# 				+------------------------------+
# 				| XXXXXXXXXXXXXXXXXX5067 		 |
# 				+------------------------------+
#
# 				SELECT mask_pan_relaxed(gen_rnd_pan());
# 				+-----------------------------------+
# 				| mask_pan_relaxed(gen_rnd_pan())	|
# 				+-----------------------------------+
# 				| 398403XXXXXXXXXXX9547 				|
# 				+-----------------------------------+
#
# 				SELECT mask_pan_relaxed(gen_rnd_pan(19));
# 				+-----------------------------------+
# 				| mask_pan_relaxed(gen_rnd_pan(19)) |
# 				+-----------------------------------+
# 				| 578416XXXXXXXXXXX6509 				|
# 				+-----------------------------------+
#
# 				SELECT gen_rnd_pan(11), gen_rnd_pan(20);
# 				+-----------------+----------------+
# 				| gen_rnd_pan(11) | gen_rnd_pan(20)|
# 				+-----------------+----------------+
# 				| NULL 				| NULL 			  |
# 				+-----------------+----------------+
#
# ) gen_rnd_ssn()
#
# 		Generates a random U.S. Social Security number in AAA-BB-CCCC format.
#
# 		The AAA part is greater than 900 and the BB part is less than 70, which are characteristics
# 		not used for legitimate Social Security numbers:
#
# 		Arguments: None.
#
# 		Return value: A random Social Security number as a string.
#
# 		Example:
#
# 			SELECT gen_rnd_ssn();
# 			+--------------------+
# 			| gen_rnd_ssn() 		|
# 			+--------------------+
# 			| 951-26-0058 			|
# 			+--------------------+
#
# ) gen_rnd_us_phone()
#
# 		Generates a random U.S. phone number in 1-555-AAA-BBBB format.
# 		The 555 area code is not used for legitimate phone numbers.
#
# 		Arguments: None
#
# 		Return value: A random U.S phone number as a string.
#
# 		Example:
#
# 			SELECT gen_rnd_us_phone();
# 			+-------------------------+
# 			| gen_rnd_us_phone() 	  |
# 			+-------------------------+
# 			| 1-555-682-5423 			  |
# 			+-------------------------+
#
# RANDOM DATA DICTIONARY-BASED FUNCTIONS
#
# The functions in this section manipulate dictionaries of terms and perform generation and masking operations
# based on them.
#
# Some of these functions require the SUPER privilege.
#
# When a dictionary is loaded, it becomes part of the dictionary registry and is assigned a name to be used by other
# dictionary functions.
#
# Dictionaries are loaded from plain text files containing one term per line.
#
# Empty lines are ignored.
#
# To be valid, a dictionary file must contain at least one nonempty line.
#
# ) gen_blacklist(str, dictionary name, replacement dictionary name)
#
# 		Replaces a term present in one dictionary with a term from a second dictionary and returns the replacement term.
#
# 		This masks the original term by substitution.
#
# 		Arguments:
#
# 			) str: A string that indicates the term to replace.
#
# 			) dictionary_name: A string that names the dictionary containing the term to replace.
#
# 			) replacement_dictionary_name: A string that names the dictionary from which to choose the replacement term.
#
# 		Return value:
#
# 		a string randomly chosen from replacement_dictionary_name as a replacement for str, or str if it does not appear in dictionary_name,
# 		or NULL if either dictionary name is not in the dictionary registry.
#
# 		If the term to replace appears in both dictionaries, it is possible for the return value to be the same term.
#
# 		Example:
#
# 			SELECT gen_blacklist('Berlin', 'DE_Cities', 'US_Cities');
# 			+--------------------------------------------------------+
# 			| gen_blacklist('Berlin', 'DE_Cities', 'US_Cities') 		|
# 			+--------------------------------------------------------+
# 			| Phoenix 																|
# 			+--------------------------------------------------------+
#
# ) gen_dictionary(dictionary name)
#
# 		Returns a random term from a dictionary.
#
# 		Arguments:
#
# 			) dictionary_name: A string that names the dictionary from which to choose the term.
#
# 		Return value:
#
# 			a random term from teh dictionary as a string, or NULL if the dictionary name is not in the dictionary
# 			registry.
#
# 		Example:
#
# 			SELECT gen_dictionary('mydict');
# 			+--------------------------------+
# 			| gen_dictionary('mydict') 		|
# 			+--------------------------------+
# 			| My term 								|
# 			+--------------------------------+
#
# 			SELECT gen_dictionary('no-such-dict');
# 			+------------------------------------+
# 			| gen_dictionary('no-such-dict') 	 |
# 			+------------------------------------+
# 			| NULL 										 |
# 			+------------------------------------+
#
# ) gen_dictionary_drop(dictionary_name)
#
# 		Removes a dictionary from the dictionary registry.
#
# 		This function requires the SUPER privilege.
#
# 		Arguments:
#
# 			) dictionary_name: A string that names the dictionary to remove from the dictionary registry.
#
# 		Return values:
#
# 			a string that indicates whether the drop operation succeeded.
# 			Dictionary removed indicates success.
#
# 			Dictionary removal error indicates failure.
#
# 			Example:
#
# 				SELECT gen_dictionary_drop('mydict');
# 				+------------------------------------------------+
# 				| gen_dictionary_drop('mydict') 						 |
# 				+------------------------------------------------+
# 				| Dictionary removed 									 |
# 				+------------------------------------------------+
#
# 				SELECT gen_dictionary_drop('no-such-dict');
# 				+------------------------------------------------+
# 				| gen_dictionary_drop('no-such-dict') 				 |
# 				+------------------------------------------------+
# 				| Dictionary removal error 							 |
# 				+------------------------------------------------+
#
# ) gen_dictionary_load(dictionary path, dictionary name)
#
# 		Loads a file into the dictionary registry and assigns the dictionary a name to be used with other functions
# 		that require a dictionary name argument.
#
# 		This function requires the SUPER privilege.
#
# 		IMPORTANT: Dictionaries are not persistent. Any dictionary used by applications must be loaded for each server startup.
#
# 		Once loaded into the registry, a dictionary is used as is, even if the underlying directory file changes.
#
# 		To reload a dictionary, first drop it with gen_dictionary_drop(), then load it again with
# 		with gen_dictionary_load()
#
# 		Arguments:
#
# 			) Dictionary_path: a string that specifies the path name of the dictionary file.
#
# 			) Dictionary_name: A string that provides a name for the dictionary.
#
# 		Return value:
#
# 		a string that indicates whether the load operation succeeded.
#
# 		Dictionary load success indicates success.
#
# 		Dictionary load error indicates failure.
#
# 		Dictionary load failure can occur for several reasons, including:
#
# 			 ) A dictionary with the given name is already loaded.
#
# 			) The dictionary file is not found
#
# 			) The dictionary file contains no terms
#
# 			) THe secure_file_priv system variable is set and teh dictionary file is not located in the directory named by the variable.
#
# 		Example:
#
# 			SELECT gen_dictionary_load('/usr/local/mysql/mysql-files/mydict', 'mydict');
# 			+---------------------------------------------------------------------------+
# 			| gen_dictionary_load('/usr/local/mysql/mysql-files/mydict', 'mydict') 		 |
# 			+---------------------------------------------------------------------------+
# 			| Dictionary load success 																	 |
# 			+---------------------------------------------------------------------------+
#
# 			SELECT gen_dictionary_load('/dev/null', 'null');
# 			+------------------------------------------------+
# 			| gen_dictionary_load('/dev/null', 'null') 		 |
# 			+------------------------------------------------+
# 			| Dictionary load error 								 |
# 			+------------------------------------------------+
#
# FIPS SUPPORT
#
# MySQL supports FIPS mode, if compiled using OpenSSL, and an OpenSSL library and FIPS Object Module are available at runtime.
#
# FIPS mode on the server side applies to cryptographic operations performed by the server.
#
# This includes replication (master/slave and Group Replication) and X Plugin,
# which run within the server.
#
# FIPS mode also applies to attempts by clients to connect to the server.
#
# FIPS OVERVIEW
#
# Federal Information Processing Standards 140-2 (FIPS 140-2) describes a security standard
# that can be required by Federal (US Government) agencies for cryptographic modules used
# to protect sensitive or valuable information.
#
# To be considered acceptable for such Federal Use, a cryptographic module must be certified
# for FIPS 140-2.
#
# If a system intended to protect sensitive data lacks the proper FIPS 140-2 certificate, Federal
# agencies cannot purchase it.
#
# Products such as OpenSSL can be used in FIPS mode, although the OpenSSL library itself is not validated
# for FIPS.
#
# Instead, the OpenSSL library is used with the OpenSSL FIPS Object Module to enable OpenSSL based apps to operate in FIPS mode.
#
# IMPORTANT: FIPS mode imposes conditions on cryptographic operations such as restrictions on acceptable encryption
# algorithms or requirements for longer key lengths.
#
# For OpenSSL, the exact FIPS behavior depends on the OpenSSL version. For details, refer to the OpenSSL FIPS user guide.
#
# SYSTEM REQUIREMENTS FOR FIPS MODE IN MYSQL
#
# For MySQL to support FIPS mode, these system requirements must be satisfied:
#
# 		) At build time, MySQl must be compiled using OpenSSL. FIPS mode cannot be used in MySQL if compilation uses a different SSL lib.
#
# 		) at runtime, the OpenSSL library and OpenSSL FIPS Object Module must be available as shared (dynamically linked) objects.
# 			It is possible to build statically linked OpenSSL objects, but MysQL will not use them.
#
# FIPS mode has been tested for MySQL on EL7, but may work on other systems.
#
# If your platform or OS provides the OpenSSL FIPS Object Module, you can use it.
#
# Otherwise, you can build the OpenSSL library and FIPS Object MOdule from source.
#
# Use the instructions in the OpenSSL FIPS User Guide (more later)
#
# CONFIGURING FIPS MODE in MySQL
#
# MySQL enables control of FIPS mode on the server side and the client side:
#
# 		) The ssl_fips_mode system variable controls whether the server operates in FIPS mode.
#
# 		) The --ssl-fips-mode client option controls whether a given MySQL client operates in FIPS mode.
#
# The ssl_fips_mode system variable and --ssl-fips-mode client option permit these values:
#
# 		) OFF : Disables FIPS mode.
#
# 		) ON : Enables FIPS mode.
#
# 		) STRICT : Enables "strict" FIPS mode.
#
# On the server side, numeric ssl_fips_mode values of 0, 1, 2 are equivalent to OFF, ON and STRICT.
#
# IMPORTANT:
#
# 		In general, STRICT imposes more restrictions than ON, But MySQL itself has no FIPS-specific code other than
# 		to specify to OpenSSL the FIPS mode value.
#
# 		The exact behavior of FIPS mode for ON or STRICT depends on the OpenSSL version.
#
# 		For details, refer to the OpenSSL FIPS USer guide.
#
# NOTE:
#
# 		If the OpenSSL FIPS Object Module is not available, the only permitted value for ssl_fips_mode
# 		and --ssl-fips-mode is OFF.
#
# 		an error occurs for attempts to set the FIPS mode to a different value.
#
# FIPS Mode on the server side applies to cryptographic operations performed by the server.
# This includes replication (master/slave and Group Replication) and X plugin, which run within the server.
#
# FIPS mode also applies to attempts by clients to connect to the server.
#
# WHen enabled, on either the client or server side, it restricts which of the supported encryption
# ciphers can be chosen.
#
# However, enabling FIPS mode does not require that an encrypted connection must be used, or that user
# credentials must be encrypted.
#
# For example, if FIPS mode is enabled, stronger cryptographic algorithms are required.
#
# IN particular, MD5 is restricted, so trying to establish an encrypted connection using an
# encryption cipher such as RC4-MD5 does not work.
#
# But there is nothing about FIPS mode that prevents establishing an uencrypted connection.
#
# (To do that, you can use the REQUIRE clause for CREATE_USER or ALTER_USER for specific user accounts,
# or set the require_secure_transport system variable to affect all accounts).
#
# BACKUP AND RECOVERY
#
# It is important to back up your databases so that you can recover your data and be up and running again in case
# problems occur.
#
# Such as system crashes, hardware failures or users deleting data by mistake.
#
# Backups are also essential as a safeguard before upgrading a MySQL installation, and they can be used to transfer
# a MySQL installation to another system or to set up replication slave servers.
#
# MySQL offers a variety of backup strats from which you can choose the methods that best suti
# the requirements for your installation:
#
# This chapter discusses several backup and recovery topics with which you should be familiar:
#
# 		) Types of Backups -> Logical versus physical, full versus incremental, and so froth.
#
# 		) Methods for creating backups.
#
# 		) Recovery methods, including point-in-time recovery
#
# 		) Backup scheduling, compression and encryption
#
# 		) Table maintenance, to enable recovery of corrupt tables
#
# ADDITIONAL RESOURCES
#
# Resources related to backup or to maintaining data availability include the following:
#
# 		) Customers of MySQL Enterprise Edition can use MysQL Enterprise Backup product for backups.
# 			For an overview of this, see later.
#
# 		) Details for mysqldump can be found earlier.
#
# 		) The syntax of the SQL statements described here is given later.
#
# 		) For additional information about InnoDB backup procedures, see later.
#
# 		) Replication enables you to maintain identical data on multiple servers.
#
# 			This has several benefits, such as eanbling client query load to be distributed
# 			over servers, availability of data even if a given server is taken offline or fails
#
# 			and the ability to make backups with no impact on the master by using a slave server. See more later.
#
# 		) MysQL InnoDB cluster is a collection of products that work together to provide a high availability solution.
#
# 			A group of MySQL servers can be configured to create a cluster using MySQL Shell.
#
# 			The cluster of servers has a single master, called the primary, which acts as the read-write master.
#
# 			Multiple secondary servers are replicas of the master.
#
# 			A minimum of three servers are required to create a high availability cluster.
# 			A client application is connected to the primary via MySQL Router.
#
# 			If the primary fails, a secondary is automatically promoted to the role of primary,
# 			and MySQL Router routes requests to the new primary.
#
# 		) NDB Cluster provides a high-availability, high-redundancy version of MySQL adapted for the distributed
# 			computing environment.
#
# 			See more later.
#
# BACKUP AND RECOVERY TYPES
#
# Physical (RAW) vs. Logical Backups
#
# Physical backups consists of raw copies of the directories and files that store database contents.
#
# This type of backup is suitable for large, important databases that need to be recovered quickly
# when problems occur.
#
# Logical backups save information represented as logical database structure (CREATE_DATABASE, CREATE_TABLE statements)
# and content (INSERT statements or delimited text files).
#
# This type of backup is suitable for smaller amounts of data, where you might edit the values or table structure,
# or recreate the data on a different machine architechture.
#
# Physical backup methods have these characteristics:
#
# 		) The backup consists of exact copies of database directories and files.
#
# 			Typically this is a copy of all or part of the MySQL data directory.
#
# 		) Physical backup methods are faster than logical because they involve only file copying without conversion.
#
# 		) Output is more compact than for logical backup.
#
# 		) Because backup speed and compactness are important for busy, important DBs, The MySQL Enterprise Backup product
# 			performs physical backups.
#
# 			For an overview of the MySQL Enterprise Backup product, see later.
#
# 		) Backup and restore granularity ranges from the level of the entire data directory down to
# 			the level of individual files.
#
# 			This may or may not provide for table-level granularity, depending on storage engine.
#
# 			For example, InnoDB tables can each be in a separate file, or share file storage with other
# 			InnoDB tables; each MyISAM table corresponds uniquely to a set of files.
#
# 		) In addition to Databases, the backup can include any related files such as log or configuration files.
#
# 		) Data from MEMORY tables is tricky to back up this way because their contents are not stored on disk.
# 			(The MySQL Enterprise Backup product has a feature where you can retrieve data from MEMORY tables during a backup)
#
# 		) Backups are portable only to other machines that have identical or similar hardware characteristics.
#
# 		) Backups can be performed while the MySQL server is not running.
#
# 			If the server is running, it is necessary to perform appropriate locking so that the server
# 			does not change DB contents during the backup.
#
# 			MySQL Enterprise Backup does this locking automatically for tables that require it.
#
# 		) Physical backup tools include the mysqlbackup of MySQL Enterprise Backup for InnoDB or any other tables,
# 			or file system-level commands (such as cp, scp, tar, rsync) for MyISAM tables.
#
# 		) For restore:
#
# 			) MySQL Enterprise Backup restores InnoDB and other tables that it backed up.
#
# 			) ndb_restore restores NDB tables.
#
# 			) Files copied at the file system level can be copied back to the original locations with file system commands.
#
# Logical backup methods have these characteristics:
#
# 		) The backup is done by querying the MySQL server to obtain DB structure and content information.
#
# 		) Backup is slower than physical methods because the server must access DB information and convert it to logical format.
# 			If the output is written on the client side, the server must also send it to the backup program.
#
# 		) Output is larger than for physical backup, particularly when saved in text format.
#
# 		) Backup and restore granularity is available at the server level (all databases), database level 
# 			(all tables in a particular DB), or table level.
#
# 			This is true regardless of storage engine.
#
# 		) The backup does not include log or configuration files, or other database-related files that are not part of databases.
#
# 		) Backups stored in logical format are machine independent and highly portable.
#
# 		) Logical backups are performed with the MySQL server running. The server is not taken offline.
#
# 		) Logical backup tools include the mysqldump program and the SELECT_..._INTO_OUTFILE statement.
#
# 			These work for any storage engine, even MEMORY.
#
# 		) To restore logical backups, SQL-format dump files can be processed using the mysql client.
#
# 			TO load delimited-text files, use the LOAD_DATA_INFILE statement or the mysqlimport client.
#
# ONLINE VERSUS OFFLINE BACKUPS
#
# Online backups take place while the MySQL is running so that the DB information can be obtained from the server.
# Offline backups tkae place while the server is stopped.
#
# This distinction can also be described as "hot" vs "cold" backups; a "warm" backup is one where the server
# remains running but locked against modifying data while you access database files externally.
#
# Online backup methods have these characteristics:
#
# 		) The backup is less intrusive to other clients, which can connect to the MySQL server during the backup
# 			and may be able to access data depending on what operations they need to perform.
#
# 		) Care must be taken to impose appropriate locking so that data modifications do not take place that would 
# 			compromise backup integrity.
#
# 			The MySQL Enterprise Backup product does such locking automatically.
#
# Offline backup methods have these characteristics:
#
# 		) Clients can be affected adversely because the server is unavailable during backup.
#
# 			For that reason, such backups are often taken from a replication slave server that
# 			can be taken offline without harming availability.
#
# 		) The backup procedure is simpler because there is no possibility of interference from client activity.
#
# A similar distinction between online and offline applies for recovery operations, and similar characteristics apply.
#
# However, it is more likely that clients will be affected for online recovery than for online backup because recovery
# requires stronger locking.
#
# During backup, clients might be able to read data while it is being backed up.
#
# Recovery modifies data and does not just read it, so clients must be prevented from accessing data while it
# is being restored.
#
# LOCAL VERSUS REMOTE BACKUPS
#
# A local backup is performed on the same host where the MySQL server runs, whereas remote backup is
# done from a different host.
#
# For some types of backups, the backup can be initiated from a remote host even if the output is written
# locally on the server host.
#
# 		) mysqldump can connect to local or remote servers. For SQL output (CREATE and INSERT statements),
# 			local or remote dumps can be done and generate output on the client.
#
# 			For delimited text output (with the --tab option), data files are created on the server host.
#
# 		) SELECT_..._INTO_OUTFILE can be initiated from a local or remote client host, but the output file is created on the server host.
#
# 		) Physical backup methods typically are initiated locally on the MysQL server host so taht the server can be taken offline,
# 			although the destination for copied files might be remote.
# 		
#
# SNAPSHOT BACKUPS
#
# Some file system implementations enable "snapshots" to be taken.
#
# these provide logical copies of the file system at a given point in time, without requiring a physical
# copy of the entire file system.
#
# (For example, the implementation may use copy-on-write techniques so that only parts of the file system modified
# 	after the snapshot time need be copied)
#
# MySQL itself does not provide the capability of taking file system snapshots.
#
# IT is available through third-party solutions suhc as Veritas, LVM or ZFS.
#
# FULL VERSUS INCREMENTAL BACKUPS
#
# A full backup includes all data managed by a MySQL server at a given point in time.
#
# An incremental backup consists of the changes made to the data during a given time
# span (from one time point to another)
#
# Mysql has different ways of performing full backups, such as those described earlier
# in this section.
#
# INcremental backups are made possible by enabling the server's Binary log, which the server
# used to record data changes.
#
# FULL VERSUS POINT IN TIME (INCREMENTAL) RECOVERY
#
# A full recovery restores all data from a full backup.
#
# This restores the server instance to the state that it had when the backup was made.
#
# If that sate is not sufficiently currently, a full recovery can be followed by recovery
# of incremental backups made since the full backup, to bring hte server to a more up-to-date state.
#
# Incremental recovery is recovery of changes made during a given time span.
# This is also called point-in-time recovery, because it makes a server's state current up to
# a given time.
#
# Point in time recovery is based on the binary log and typically follows a full recovery from the
# backup files that restores the server to its state when the backup was made.
#
# Then the data changes written in the binary log files are applied as incremental recovery to redo data
# modifications and bring the server up to the desired point in time.
#
# TABLE MAINTENANCE
#
# Data integrity can be compromised if tables become corrupt.
#
# For InnoDB tables, this is not a typical issue. For programs to check MyISAM
# tables and repair them if problems are found, see earlier.
#
# BACKUP SCHEDULING, COMPRESSION AND ENCRYPTION
#
# Backup scheduling is valuable for automating backup procedures.
#
# Compression of backup output reduces space requirements, and encryption of
# the output provides better security against unauthorized access of backed-up data.
#
# MySQL itself does not provide these capabilities.
#
# The MySQL Enterprise Backup product can compress InnoDB backups,
# and compress or encryption of backup output can be acheived by using file system utilities.
#
# Other third-party solutions may be available.
#
# DATABASE BACKUP METHODS
#
# This section summarizes some general methods for making backups.
#
# MAKING A HOT BACKUP WITH MYSQL ENTERPRISE BACKUP
#
# Customers of MySQL Enterprise Edition can use the MySQL Enterprise Backup product to
# do physical backups of entire instances or selected DBs, tables or both.
#
# This product includes features for incremental and compressed backups.
#
# Backing up the physical database files makes restoring much faster than logical techniques
# such as the mysqldump command.
#
# InnoDB tables are copied using a hot backup mechanism.
#
# (ideally, the InnoDB tables should represent a substansial majority of the data)
#
# Tables from other storage engines are copied using a warm backup mechanism.
#
# More on this later.
#
# MAKING BACKUPS WITH MYSQLDUMP
#
# The mysqldump program can make backups. It can back up all kinds of tables.
#
# For InnoDB tables, it is possible to perform an online backup that takes no locks on tables using the
# --single-transaction option to mysqldump. More on this later.
#
# MAKING BACKUPS BY COPYING TABLE FILES
#
# MyISAM tables can be backed up by copying table files (*.MYD, *MYI files, and associated *.sdi files)
# To get a consistent backup, stop the server or lock and flush the relevant tables:
#
# 		FLUSH TABLES tbl_list WITH READ LOCK;
#
# You need only a read lock; this enables other clients to continue to query the tables while you are making
# a copy of the files in the database directory.
#
# The flush is needed to ensure that all active index pages are written to disk before you start the backup.
# See more on this later.
#
# You can also create a binary backup simply by copying the table files, as long as the server is not updating
# anything.
#
# (But note that hte file copying methods od not work if your DB contains InnoDB tables. Also, even if the server
# is not actively updating data, InnoDB may still have modified data cached in memory and not flushed to disk.)
#
# FOr an example of this backup method, see later.
#
# MAKING DELIMITED-TEXT FILE BACKUPS
#
# To create a text file containing a table's data, you can use SELECT_*_INTO_OUTFILE_'file_name'_FROM_table_name.
#
# The file is created on the MySQL server host, not the client host.
#
# FOr this statement,, the output file cannot already exist, because permitrting files to be overwritten
# constitutes security risks.
#
# This method works for any kind of data file, but saves only the table data, not the table structure.
#
# ANother way to create text data files (along with files containing CREATE_TABLE statements for hte backed up tables)
# is to use mysqldump with the --tab option.
#
# See more on this , later.
#
# To reload a delimited-text data file, use LOAD_DATA_INFILE or mysqlimport
#
# MAKING INCREMENTAL BACKUPS BY ENABLING THE BINARY LOG
#
# MySQL supports incremental backups.
#
# You must start the server with the --log-bin option to enable binary logging.
#
# The binary log files provide you with the information you need to replicate changes to the DB that
# are made subsequent to the point at which you performed a backup.
#
# At the moment you want to make a incremental backup (containing all changes that happened since the last full
# or incremental backup), you should rotate the binary log by using FLUSH_LOGS.
#
# THis done, you need to copy to the backup location all binary logs which range from the one 
# of the moment of the last full or incremental backup to the last one.
#
# These binary logs are the incremental backup; at restore time, you apply them as explained later.
#
# The next time you do a full backup, also rotate the binary log using FLUSH_LOGS or mysqldump --flush-logs
#
# MAKING BACKUPS USING REPLICATION SLAVES
#
# If you have performance problems with your master server while making backups, one strategy that cna help
# is to set up replication and perform backups on the slave rather than on the master.
#
# See more on this later.
#
# IF you are backing up a slave replication server, you should back up its master info and relay log info repositories (more later),
# when you back up the slave's DB, regardless of the backup method you choose.
#
# This information is always needed to resume replication after you restore the slave's data.
#
# If your slave is replicating LOAD_DATA_INFILE statements, you should also back up any SQL_LOAD-*
# files that exist in the directory that the slave uses for this purpose.
#
# The slave needs these files to resume replication of any interuppted LOAD_DATA_INFILE operations.
#
# The location of this directory is the value of the --slave-load-tmpdir option.
#
# IF the server was not started with that option, the directory location is the value of the tmpdir system variable.
#
# RECOVERING CORRUPT TABLES
#
# IF you have to restore MyISAM tables that have become corrupt, try to recover them using
# REPAIR_TABLE or myisamchk -r first.
#
# That should work for the most part.
#
# If it fails, see later.
#
# MAKING BACKUPS USING A FILE SYSTEM SNAPSHOT
#
# If you are using a Veritas file system, you can make a backup like this:
#
# 	1. From a client program, execute FLUSH_TABLES_WITH_READ_LOCK
#
# 	2. From another shell, execute mount vxfs snapshot
#
# 	3. From the first client,, execute UNLOCK_TABLES
#
# 	4. Copy files from the snapshot
#
# 	.5 Unmount the snapshot
#
# Similar snaphot capacities ma yeb avialable in other file systems, such as LVM or ZFS.
#
# EXAMPLE BACKUP AND RECOVERY STRATEGY
#
# This section disscuses a procedure for performing backups taht enables you to recover the data
# after several types of crashes:
#
# 		) Operating System crash
#
# 		) Power failure
#
# 		) File system carsh
#
# 		) Hardware problem (hard drive, motherboard, and so forth)
#
# THe example commands do not include options such as --user and --password for the mysqldump and mysql client programs.
# You should include such options as necessary to enable client programs to connect to the MySQL server.
#
# ASsume that data is stoed in teh InnoDB storage engine, which has support or transactions and automatic crash recovery.
# Assume also that the MySQL is under load at hte time of the crash.
#
# If it were not, no recovery would ever be needed.
#
# FOr cases of operating system crashes or power failures, we can assume that the MySQL disk data is available after a restart.
#
# The INnoDB files might not contain consistent data due to the crash, but InnoDB reads its logs and finds in them
# the list of pending committed and non committed transactions that have not been flushed to the data files.
#
# InnoDB automatically rolls back those transactions that were not committed, and flushes to its data files
# those that were committed.
#
# Information about this recovery process is conveyed to the user through the MySQL error log.
#
# The following is an example log excerpt:
#
# 	InnoDB: Database was not shut down normally.
# 	InnoDB: Starting recovery from log files...
# 	InnoDB: Starting log scan based on checkpoint at
# 	InnoDB: log sequence number 0 13674004
# 	InnoDB: Doing recovery: scanned up to log sequence number 0 13739520
# 	InnoDB: etc.
# 	InnoDB: 1 uncommitted transaction(s) which must be rolled back
# 	InnoDB: Starting rollback of uncommitted transactions
# 	InnoDB: Rolling back trx no 16745
# 	InnoDB: Rolling back of trx no 16745 completed
# 	InnoDB: Rollback of uncomitted transactions completed
# 	InnoDB: Starting an apply batch of log records to the database.
# 	InnoDB: Apply batch completed
# 	InnoDB: Started
# 	mysqld: ready for connections
#
# For the case of file system crashes or hardware problems, we can assume that hte MySQL disk data is NOT available after a restart.
#
# THis means that MySQL fails to start successfully because some blocks of disk data are no longer readable.
#
# IN this case, it is necessary to reformat the disk, install a new one, or otherwise correct the underlying
# problem.
#
# Then it is necessary to recover our MySQL data from backups, which means that backups must
# already have been made.
#
# To make sure that is the case, design and implement a backup policy.
#
# ESTABLISHING A BACKUP POLICY
#
# To be useful, backups must be scheduled regularly.
#
# A full backup (a snapshot of the data at a point in time) can be done in MySQL with several tools.
#
# For example, MySQL Enterprise Backup can perform a physical backup of an entire instance, with optimizations
# to minimize overhead and avoid disruption when backing up InnoDB data files:
# 
# mysqldump provides online logical backups. THis discussion uses mysqldump.
#
# Assume that we make a full backup of all our InnoDB tables in all databases using the following
# command on Sundat at 1 p.m., when load is low:
#
# 		mysqldump --all-databases --master-data --single-transactions > backup_sunday_1_PM.sql
#
# The resulting .sql file produced by mysqldump contains a set of SQL INSERT statements that can be used 
# to reload the dumped tables at a later time.
#
# THis backup operation acquires a global read lock on all tables at the beginning of the dump
# (using FLUSH_TABLES_WITH_READ_LOCK).
#
# As soon as this lock has been acquired, the binary log coordinates are read and the lock is released.
#
# If long updating statements are running when the FLUSH statement is issued, the backup operation
# may stall until those statements finish.
#
# After that, the dump becomes lock-free and does not disturb reads and writes on the tables.
#
# It was assumed earliar the the tables to back up are InnoDB tables, so --single-transaction uses
# a consistent read and guarantees that data seen by mysqldump does not change.
#
# (Changes made by other clients to InnoDB tables are not seen by the mysqldump process)
#
# If the backup operation includes nontransactional tables, consistency requires that htey do not
# change during the backup.
#
# For example, for the MyISAM tables in the mysql database, there must be no administrative changes to
# MySQL accounts during the backup.
#
# Full backups are necessary, but it is not always convenient to create them.
# They produce large backup files and take time to generate.
#
# They are not optimal in the sense that each successive full backup includes all data, even that
# part that has not changed since the previous full backup.
#
# IT is more efficient to make an initial full backup and then to make incremental backups.
#
# The incremental backups are smaller and take less time to produce.
# The tradeoff is that, at recovery time, you cannot restore your data just by reloading the full backup.
#
# You must also process the incremental backups to recover the incremental changes.
#
# TO make incremental backups, we need to save the incremental changes.
#
# In MySQL, these changes are represented in the binary log, so the MySQL server should always be
# started with the --log-bin option to enable that log.
#
# With binary logging enabled, teh server writes the data change into a file while it updates data.
#
# Looking at hte data directory of a MySQL server that was started with the --log-bin option and
# that has been running for some days, we find these MySQL binary log files:
#
# -rw-rw---- 1 guilhem guilhem  	1277324 Nov 10 23:59 gbichot2-bin.000001
# -rw-rw---- 1 guilhem guilhem 			4 Nov 10 23:59 gbichot2-bin.000002
# |
# V etc, until last is Index
#
# 
# Each time it restarts, the MySQL server creates a new binary log file using the next number
# in the sequence.
#
# While the server is running, you can also tell it to close the current binary log file
# and begin a new one manually by issuing a FLUSH_LOGS SQL statement or with a mysqladmin flush-logs command.
#
# Mysqldump also has an option to flush the logs.
#
# The .index file in the data directory contains the list of all MySQL binary logs in the directory.
#
# The MySQL binary logs are important for recovery because they form the set of incremental backups.
#
# If you make sure to flush the logs when you make your full backup, the binary log files created
# afterwards contain all the data changes made since the backup.
#
# Let's modify the previous mysqldump command a bit so that it flushes the MySQL binary logs
# at the moment of the full backup, and so that the dump file contains the name of the
# new current binary log:
#
# mysqldump --single-transaction --flush-logs --master-data=2 \
#  --all-databases > backup_sunday_1_PM.sql
#
# After executing this command, the data directory contains a new binary log file,
# gbichot2-bin.000007,, because the --flush-logs option causes the server to flush its
# logs.
#
# The --master-data option causes mysqldump to write binary log information to its output,
# so the resulting .sql dump file includes these lines:
#
# 	-- Position to start replication or point-in-time recovery from
# 	-- CHANGE MASTER TO MASTER_LOG_FILE='gbichot2-bin.000007',MASTER_LOG_POS=4;
#
# Because the MySQldump command made a full backup, those lines mean two things:
#
#		) The dump file contains all changes made before nay changes written to the gbichot2-bin.000007 binary log file or higher
#
#	 	) All data changes logged after the backup are not present in the dump file, but are present in the gbichot2-bin.000007 binary log file or higher.
#
# On Monday at 1 p.m, we can create an incremental backup by flushing the logs to begin a new binary log file.
#
# For example, executing a mysqladmin flush-logs command creates gbichot2-bin.000008 
#
# All changes between the Sunday 1 p.m full backup and Monday 1 p.m will be in the gbichot2-bin.000007 file.
#
# This incremental backup is important ,so it is a good idea to copyt it to a safe place.
#
# (For example, back it up on tape or DVD, or copy it to another machine).
#
# On Tuesday 1 p.m, excute another mysqladmin flush-logs command.
#
# all Changes between the Monday 1 p.m and Tuesday 1 p.m, will be in teh gbicht2-bin.000008 file
# (which also should be copied somewhere safe)
#
# THe MySQL binary logs take up disk space. To free up space, purge them from time ot time.
#
# One way to do this is by deleting the binary logs that are no longer needed, such as when
# we make a full backup:
#
# 		mysqldump --single-transaction --flush-logs --master-data=2 \
# 			--all-databases --delete-master-logs > backup_sunday_1_PM.sql
#
# NOTE:
#
# 		Deleting the MYSQL binary logs with mysqldump --delete-master-logs can be dangerous if your server is
# 		a replication master server, because slave servers might not fully have processed the contents
# 		of the binary log.
#
# 		The description for the PURGE_BINARY_LOGS statement explains what hsould be verified before deleting
# 		the MySQL binary logs.
#
# More on purging binary logs later.
#
# USING BACKUPS FOR RECOVERY
#
# Now suppose that we have a catastrophic crash on Wednesday at 8 a.m, taht requires recovery from backups.
#
# TO recover, first we restore the last full backup we have (the one from Sunday 1 p.m.)
#
# The full backup file is just a set of SQL statements, so restoring it is very easy:
#
# 		mysql < backup_sunday_1_PM.sql
#
# At this point, the data is restored to its state as of Sunday 1 p.m..
#
# TO restore the changes made since then, we must use incremental backups.
#
# That is, the gbichot2-bin.000007 and gbichot2-bin.000008 binary log files.
#
# Fetch the files if neceesary from where you ahve them, and then process their contents as follows:
#
# 		mysqlbinlog gbichot2-bin.000007 gbichot2-bin.000008 | mysql
#
# We now have recover the data to its state as of Tuesday 1 p.m, but still are missing teh changes
# from that date to the date of the crash.
#
# To not lose them, we would have needed to have the MySQL server store its MySQL binary logs
# into a safe location (RAID disks, SAN, etc.) different from the place where it stores its data files,
# so taht htese logs were not on the destroyed disk.
#
# (That is, we can start the server with a --log-bin option that specifies a location on a different
# physical device from the one on which the data directory resides.
#
# That way, the logs are safe even if the device contianing the directory is lost)
#
# If we had done this, we would have the gbichot2-bin.000009 file (and any subsequent files) at hand,
# and we could apply them using mysqlbinlog and mysql to restore the most recent data changes with no
# loss up to hte moment of the crash:
#
# 		mysqlbinlog gbichot-bin.0000009 ... | mysql
#
# For more information about mysqlbinlog to process binary log files, see later.
#
# BACKUP STRATEGY SUMMARY
#
# IN case of an operating system crash or power fialure, InnoDB does all the job of recovering the data.
# but to make sure that you can sleep well, observe the following guidelines:
#
# 		) Always run the MySQL server with the --log-bin option, or even --log-bin=log_name, where the log file name
# 			is located on some safe media different from the drive on which the data directory is located.
#
# 			If you have such safe media, this technique can also be good for disk load balancing (which results in a performaance improvement)
#
# 		) Make periodic full backups, using the mysqldump command shown earlier, that makes an online, nonblocking backup.
#
# 		) Make periodic incremental backups by flushing the logs with FLUSH_LOGS or mysqladmin flush-logs
#
# USING MYSQLDUMP FOR BACKUPS
#
# This section describes how to use mysqldump to produce dump files, and how to reload dump files.
# A dump file can be used in several ways:
#
# 	) As a backup to enable data recovery in case of data loss.
#
# 	) As a source of data for setting up replication slaves
#
# 	) As a source of data for experimentation:
#
# 		) To make a copy of a database that you can use without changing the original data.
#
# 		) TO test potentional upgrade incompatibilities
#
# mysqldump produces two types of output, depending on whether the --tab option is given:
#
# 	) Without --tab, mysqldump writes SQL statements to the standard output.
#
# 		This output consists of CREATE statements to create dumped objects (databases, tables, stored routines,
# 		and so forth) and INSERT statements to load data into tables.
#
# 		The output can be saved in a file and reloaded later using mysql to recreate the dumped objects.
#
# 		Options are available to modify the format of the SQL statements, and to control which objects are dumped.
#
# 	) With --tab, mysqldump produces two output files for each dumped table.
#
# 		The server writes one file as tab-delimited text, one line per table row.
# 		This file is named tbl_name.txt in the output directory.
#
# 		The server also sends a CREATE_TABLE statement for the table to mysqldump, which writes
# 		it as a file named tbl_name.sql in the output directory.
#
# DUMPING DATA IN SQL FORMAT WITH MYSQLDUMP
#
# This section describes how ot use mysqldump to create SQL-format dump files.
#
# For information about reloading such dump files, see later.
#
# By default, mysqldump writes information as SQL statements to the standard output.
# You can save the output in a file:
#
# 		mysqldump [arguments] > file_name
#
# TO dump all databases, invoke mysqldump with the --all-databases option:
#
# 		mysqldump --all-databases > dump.sql
#
# To dump only specific databases, name them on teh command line and use the --databases option:
#
# 		mysqldump --databases db1 db2 db3 > dump.sql
#
# The --databases option causes all names on the cmd line to be treated as DB names.
# WIthout htis option, mysqldump treats the first name as a DB name and the following as table names.
#
# WIth --all-databases or --databases, mysqldump writes CREATE_DATABASE and USE statements prior ot hte dump
# output for each databse.
#
# This ensures that when the dump file is reloaded, it creates each database if it does not exist and makes it hte default DB,
# so DB contents are loaded into the same database from which they came.
#
# If you want to cause the dump file to force a drop of each database before recreating it, use the --add-drop-database option
# as well.
#
# IN this scase, mysqldump writes a DROP_DATABASE statement preceding to the CREATE_DATABASE statement.
#
# To dump a single database, name it on teh command line:
#
# mysqldump --databases test > dump.sql
#
# In the single-database case, it is permissible to omit the --databases option:
#
# 		mysqldump test > dump.sql
#
# The difference between the two preceding commands is that without --databases, the dump output
# contains no CREATE_DATABASE or USE statements.
#
# This has several implications:
#
# 	) WHen you reload the dump file, you must specify a default DB name so that the server knows which DB to reload
#
# 	) For reloading, you can specify a DB name different from the original name, which enables you to reload the data
# 		into a different DB.
#
# 	) If the database to be reloade does not exist, you must create it first.
#
# 	) Because the output will contain no CREATE_DATABASE statement, the --add-drop-database option has no effect.
# 		If you use it, it produces no DROP_DATABASE statement.
#
# To dump only specific tables from a database, name them on the command line following the DB name:
#
# 		mysqldump test t1 t3 t7 > dump.sql
#
# RELOADING SQL-FORMAT BACKUPS
#
# To reload a dump file written by mysqldump that consists of SQL statements, use it as input to the mysql client.
#
# If the dump file was created by mysqldump with the --all-databases, or --databases option, it contains
# CREATE_DATABASE and USE statements and it is not necessary to specify a Default DB into which to load the data:
#
# 		mysql < dump.sql
#
# Alternatively, from within mysql, ,use a source command:
#
# 		source dump.sql
#
# If the file is a single-database dump not containing CREATE_DATABASE and USE statements, create the database first (if necessary):
#
# 		mysqladmin create  db1
#
# Then specify the database name when you load the dump file:
#
# 		mysql db1 < dump.sql
#
# Alternatively, from within mysql, create the database, select it as the default database, and load the dump file:
#
# 		CREATE DATABASE IF NOT EXISTS db1;
# 		USE db1;
# 		source dump.sql
#
# NOTE:
#
# 		For Windows Powershell users: Because the "<" char is reserved for future use in PowerHSelll, an alternative paproach is
# 		required, such as using quotes cmd.exe /c "mysql < dump.sql"
#
# DUMPING DATA IN DELIMIETED-TEXT FORMAT WITH MYSQLDUMP
#
# This section describes how to use mysqldump to create delimieted-text dump files.
# For information about reloading such dump files, see later.
#
# If you invoke mysqldump with the --tab=dir_name option, it uses dir_name as the output directory
# and dumps tables individually in that directory using two files for each table.
#
# The table name is the base name for these files. FOr a table named t1, the files are named t1.sql and t1.txt 
#
# The .sql file contains a CREATE TABLE statement for the table.
#
# The .txt file contains the table data, one line per table row
#
# The following command dumps the contents of the db1 database to files in the /tmp database:
#
# mysqldump --tab=/tmp db1
#
# The .txt files containing table data are written by the server, so they are owned by the system account used
# for running the server.
#
# The server uses SELECT_..._INTO_OUTFILE to write the files, so you must have the FILE privilege to perform this operation,
# and an error occurs if a given .txt file already exists.
#
# The server sends the CREATE definitions for dumped tables to mysqldump, which writes them to .sql files.
# These files therefore are owned by the user who executes mysqldump.
#
# It is best that --tab be used only for dumping a local server.
#
# If you use it with a remote server, the --tab directory must exist on both the local and remote hosts, and the
# .txt files will be written by the server in teh remote directory (on the server host), whereas the .sql files
# will be written by mysqldump in the local directory (on the client host).
#
# For mysqldump --tab, the server by default writes table data to .txt files one line per row with tabs between
# column values, no quotation marks around column values, and newlines as the line terminator.
#
# (These are the same defaults as for SELECT_..._INTO_OUTFILE)
#
# To enable data files to be written using a different format, mysqldump supports these options:
#
# 		) --fields-terminated-by=str
#
# 				The string for separating column values (default: tab)
#
# 		) --fields-enclosed-by=char
#
# 				The character within which to enclose column values (default: no character)
#
# 		) --fields-optionally-enclosed-by=char
#
# 				The character within which to enclose non-numeric column values (default: no character)
#
# 		) --fields-escaped-by=char
#
# 				The character for escaping special characters (default: no escaping)
#
# 		) --lines-terminated-by=str
#
# 				The line-termination string (default: newline)
#
# Depending on the value you specify for any of these options, it might be necessary on the command
# line to quote or escape the value appropriately for your command interpreter.
#
# Alternatively, specify the value using hex notation. Suppose that you want mysqldump to quote
# column values within double quotation marks.
#
# To do so, specify double quote as the value for the --fields-enclosed-by option.
#
# But this character is often special to command interpreters and msut be treated specially.
# 
# For example, on Unix, you must quote the quote notation:
#
# 		--fields-enclosed-by='"'
#
# Or, you can define it in hexadecimal
#
# 		--fields-enclosed-by=0x22
#
# It is common to use several of the data-formatting options together.
# For example, to dump tables in comma-separated values format with lines terminated by carriage return
# /newline pairs (\r\n), use this command on a single line:
#
# 		mysqldump --tab=/tmp --fields-terminated-by=, --fields-enclosed-by='"' --lines-terminated-by=0x0d0a db1
#
# Should you use any of the data-formatting options to dump table data, you will need to specify the same
# format when you reload data files later, to ensure proper interpretaion of the file contents.
#
# RELOADING DELIMITED-TEXT FORMAT BACKUPS
#
# For backups produced with mysqldump --tab, each table is represented in the output directory by an .sql file
# containing the CREATE_TABLE statement for the table, and a .txt file containing the table data.
#
# To reload a table, first change location into the output directory. Then process the .sql file with
# mysql to create an empty table and process the .txt file to load the data into the table:
#
# 		mysql db1 < t1.sql
# 		mysqlimport db1 t1.txt
#
# An alternetive to using mysqlimport to load the data file is to use the LOAD_DATA_INFILE statement
# from within the mysql client:
#
# 		USE db1;
# 		LOAD DATA INFILE 't1.txt' INTO TABLE t1;
#
# If you used any data-formatting options with mysqldump when you initially dumped the table,
# you must use the same options with mysqlimport or LOAD_DATA_INFILE to ensure proper interpretation
# of the data file contents:
#
# mysqlimport --fields-terminated-by=, --fields-enclosed-by="'" --lines-terminated-by=0x0d0a db1 t1.txt
#
# OR
#
# USE db1;
# LOAD DATA INFILE 't1.txt' INTO TABLE t1 FIELDS TERMINATED BY ','
# FIELDS ENCLOSED BY '"' LINES TERMINATED BY '\r\n';
#
# MYSQLDUMP TIPS
#
# This section surveys techniques that enable you to use mysqldump to solve specific problems:
#
# 		) How to make a copy of a Database
#
# 		) How to copy a database from one server to another
#
# 		) How to dump stored programs (stored procedures and functions, triggers and events)
#
# 		) How to dump definitions and data separately 
#
# MAKING A COPY OF A DATABASE
#
# mysqldump db1 > dump.sql
# mysqladmin create db2
# mysql db2 < dump.sql
#
# Do not use --databases on the mysqldump command line because that causes USE db1 to be included in the dump file,
# which overrides the effect of naming db2 on the mysql command line.
#
# COPY A DATABASE FROM ONE SERVER TO ANOTHER
#
# On Server 1:
#
# 		mysqldump --databases db1 > dump.sql
#
# Copy the dump file from Server 1 to Server 2.
#
# On Server 2:
#
# 		mysql < dump.sql
#
# Use of --databases with the mysqldump command line causes the dump file to include CREATE_DATABASE
# and USE statements that create the database if it does exist and make it the default database for
# the reloaded data.
#
# Alternatively, you can omit --databases from the mysqldump command.
#
# Then you will need to create the database on server 2 (if necessary) and specify it
# as the default database when you reload the dump file.
#
# On Server 1:
#
# 		mysqldump db1 > dump.sql
#
# On Server 2:
#
# 		mysqladmin create db1
# 		mysql db1 < dump.sql
#
# You can specify a different database name in this case, so omitting --databases from the mysqldump
# command enables you to dump data from one database and load it into another.
#
# DUMPING STORED PROGRAMS
#
# Several options control how mysqldump handles stored programs (stored procedures and functions, triggers and events):
#
# 		) --events: Dump Event Scheduler events
#
# 		) --routines: Dump stored procedures and functions
#
# 		) --triggers: Dump triggers for tables
#
# The --triggers option is enabled by default so that when tables are dumped, they are accompanied
# by any triggers they have.
#
# The other options are disabled by default and must be specified explicitly to dump the corresponding objects.
#
# To disable any of these options explicitly, use its skip form: --skip-events, --skip-routines or --skip-triggers.
#
# DUMPING TABLE DEFINITIONS AND CONTENT SEPARATELY
#
# The --no-data option tells mysqldump not to dump table data, resulting in the udmp file containg only statements
# to create the tables.
#
# Conversely, teh --no-create-info option tells mysqldump to suppress CREATE statements from the output, so that
# the dump file contains only table data.
#
# For example, to dump table definitions and data separately for the test database, use these commands:
#
# 		mysqldump --no-data test > dump-defs.sql
# 		mysqldump --no-create-info test > dump-data.sql
#
# For a definition-only dump, add the --routines and --events options to also include stored routine and event definitions:
#
# 		mysqldump --no-data --routines --events test > dump-defs.sql
#
# USING MYSQLDUMP TO TEST FOR UPGRADE INCOMPATIBILITIES
#
# When contemplating a MySQL upgrade, it is prudent to install the newer version separately from your current product version.
#
# Then you can dump the database and database object definitions from the production server and load them into
# the new server to verify that they are handled proeprly.
#
# (This is also useful for testing downgrades)
#
# On the production server:
#
# 		mysqldump --all-databases --no-data --routines --events > dump-defs.sql
#
# On the upgraded server:
#
# 		mysql < dump-defs.sql
#
# Because the dump file does not contain table data, it can be processed quickly.
#
# This enables you to spot potentional incompatibilities without waiting for lengthy
# data-loading operations.
#
# Look for warnings or errors while the dump file is being processed.
#
# After you have verified that the definitions are handled properly, dump the data 
# and try to load it into the upgraded server.
#
# On the production server:
#
# 		mysqldump --all-databases --no-create-info > dump-data.sql
#
# On the upgraded server:
#
# mysql < dump-data.sql
#
# Now check the table contents and run some test queries.
#
# POINT-IN-TIME (INCREMENTAL) RECOVERY USING THE BINARY LOG
#
# Point-in-time recovery refers to recovery of data changes made since a given point in time.
#
# Typically, this type of recovery is performed after restoring a full backup that brings
# the server to its state as of the time that the backup was made.
#
# (The full backup can be made in several ways, such as those listed earlier)
#
# Point-in-time recovery then brings the server up to date incrementally from the time of the
# full backup to a more recent time.
#
# NOTE:
#
# 		Many of the examples here use the mysql client to process binary log output produced by mysqlbinlog.
#
# 		If your binary log contains \0 (null) characters, that output cannot be parsed by mysql unless you
# 		invoke it with the --binary-mode option. 
#
# Point-in-time recovery is based on these principles:
#
# 		) The source of information for point-in-time recovery is the set of incremental backups represented
# 			by the binary log files generated subsequent to the full backup operaiton.
#
# 			Therefore, the server must be started with the --log-bin option to enable binary logging
#
# 			To restore data from the binary log, you must know the name and location of the current binary log files.
#
# 			By default, the server creates binary log files in the data directory, but a path name can be
# 			specified with the --log-bin option to place the files in a different location.  		
# 
#  		To see a listing of all binary log files, use this statement:
#
# 				SHOW BINARY LOGS;
#
# 			To determine the name of the current binary log file, issue the following statement:
#
# 				SHOW MASTER STATUS;
#
# 		) The mysqlbinlog utility converts the events in the binary log files from binary format to text so that they can be
# 			executed or viewed.
#
# 			mysqlbinlog has options for selecting sections of the binary log based on event times or position of events within the log.
#
# 		) Executing events from the binary log causes the data modifications they represent to be redone.
#
# 			This enables recovery of data changes for a given span of time.
#  		To execute events from the binary log, process mysqlbinlog output using the mysql client:
#
# 			mysqlbinlog binlog_files | mysql -u root -p
#
# 		) Viewing log contents can be useful when you need to determine event times or positions to select partial
# 			log contents prior to executing events.
#
# 			To view events from the log, send mysqlbinlog output into a paging program:
#
# 			mysqlbinlog binlog_files | more
#
# 			Alternatively, save the output in a file and view the file in a text editor:
#
# 			mysqlbinlog binlog_files > tmpfile
# 			--- edit tmpfile ---
#
# 		) Saving the output in a file is useful as a preliminary to executing the log contents with certain events
# 			removed, such as an accidental DROP_DATABASE.
#
# 			You can delete from the file any statements not to be executed before executing its contents.
# 			After editing the file, execute the contents as follows:
#
# 				mysql -u root -p < tmpfile
#
# If you have more than one binary log to execute on the MySQL server, the safe method is to process them all
# using a single connection to the server.
#
# Here is an example that demonstrates what may be unsafe:
#
# mysqlbinlog binlog.000001 | mysql -u root -p # dangerous to write to 2 separate connections
# mysqlbinlog binlog.000002 | mysql -u root -p # ^
#
# Processing binary logs this way using different connections to the server causes problems if the first
# log file contains a CREATE_TEMPORARY_TABLE statement and the second log contains a statement that uses the
# temporary table.
#
# When the first connection terminates, the server drops the temporary table.
#
# WHen the second mysql process attempts to access it, it will be attempting to referencing a unknown table.
#
# To avoid problems like this, use a single ceonnection to execute the contents of all binary logs that you want
# to process.
#
# Here is one way to do so:
#
# 		mysqlbinlog binlog.000001 binlog.000002 | mysql -u root -p
#
# Another approach is to write all the logs to a single file and then process the file:
#
# 		mysqlbinlog binlog.000001 > /tmp/statements.sql
# 		mysqlbinlog binlog.000002 >> /tmp/statements.sql
# 		mysql -u root -p -e "source /tmp/statements.sql"
#
# When writing to a dump file while reading back from a binary log containing GTIDS (more later on global transaction identifiers),
# use the --skip-gtids option with mysqlbinlog like this:
#
# 		mysqlbinlog --skip-gtids binlog.000001 > /tmp/dump.sql
# 		mysqlbinlog --skip-gtids binlog.000002 >> /tmp/dump.sql
# 		mysql -u root -p -e "source /tmp/dump.sql"
#
# POINT IN TIME RECOVERY USING EVENT TIMES
#
# To indicate the start and end times for recovery, specify the --start-datetime and --stop-datetime options
# for mysqlbinlog, in DATETIME format.
#
# As an example, suppose that exactly at 10:00 a.m on April 20, 2005 - a SQL statement was executed that deleted
# a large table.
#
# To restore the table and data, you could restore the previous nights backup, and then execute the following command:
#
# 		mysqlbinlog --stop-datetime="2005-04-20 9:59:59" \
# 			/var/log/mysql/bin.123456 | mysql -u root -p
#
# This command recovers all of the data up until the date and time given by the --stop-datetime option.
#
# If you did not detect the errorneous SQL statement that was entered until hours later,
# you will probably also want to recover the activity that occured afterwards.
#
# Based on this, you could run mysqlbinlog again with a start date and time, like so:
#
# 		mysqlbinlog --start-datetime="2005-04-20 10:01:00" \
# 			/var/log/mysql/bin.123456 | mysql -u root -p
#
# In this command, the SQL statements logged from 10:01 a.m. on will be re-executed.
#
# The combination of restoring the previous night's dump file and the two mysqlbinlog
# commands, restore everything up until one second before 10:00 a.m, and everything from 10:01 a.m on.
#
# To use this method of point-in-time recovery, you should examine the log to be sure of the exact
# times to specify for the commands.
#
# To display the log file contents without executing them, use this command:
#
# 		mysqlbinlog /var/log/mysql/bin.123456 > /tmp/mysql_restore.sql
#
# Then open the /tmp/mysql_restore.sql file with a text editor to examine it.
#
# Excluding specific changes by specifying times for mysqlbinlog does not work well if multiple
# statements executed at the same time as the one to be excluded.
#
# POINT-IN-TIME RECOVERY USING EVENT POSITIONS
#
# Instead of specifying dates and times, the --start-position and --stop-position options for mysqlbinlog
# can be used for specifying log positions.
#
# They work the same as the start and stop date options, except that you specify log position numbers rather
# than dates.
#
# Using positions may enable you to be more precise about which part of the log to recover, especially if many
# transactions occurred around the same time as a damaging SQL statement.
#
# To determine the position numbers, run mysqlbinlog for a range of times near the time when the unwanted
# transaction was executed, but redirect the results to a text file for examination.
#
# This can be done like so:
#
# 		mysqlbinlog --start-datetime="2005-04-20 9:55:00" \
# 			--stop-datetime="2005-04-20 10:05:00" \
# 			/var/log/mysql/bin.123456 > /tmp/mysql_restore.sql
#
# This command creates a small text file in the /tmp directory that contains the SQL statements
# around the time that the deleterious SQL statement was executed.
#
# Open this file with a text editor and look for the statement that you do not want to repeat.
#
# Determine the positions in the binary log for stopping and resuming the recovery and make
# note of them.
#
# Positions are labeled as log_pos followed by a number.
#
# After restoring the previous backup file, use the position number to process the binary log file.
# For example, you would use commands something like these:
#
# 		mysqlbinlog --stop-position=368312 /var/log/mysql/bin.123456 \
# 			| mysql -u root -p
#		mysqlbinlog --start-position=368315 /var/log/mysql/bin.123456 \
# 			| mysql -u root -p
#
# The first command recovers all the transactions up until the stop position given.
#
# The second command recovers all transactions from the starting position given until the
# end of the binary log.
#
# Because the output of mysqlbinlog includes SET TIMESTAMP statements before each SQL statement recorded,
# the recovered data and related MySQL logs will reflect the original times at which the transactions
# were executed.
#
# MyISAM TABLE MAINTENANCE AND CRASH RECOVERY
#
# This section discusses how to use myisamchk to check or repair MyISAM tables (tables that have .MYD and .MYI files for
# storing data and indexes)
#
# For general myisamchk background, see earlier.
#
# Other table-repair information can be found earlier.
#
# You can use myisamchk to check, repair or optimize database tables.
#
# The following sections describes how to perform these operations and how to set up a table
# maintenance schedule.
#
# For information about using myisamchk to get information about your tables, see earlier.
#
# Even though table repair with myisamchk is quite secure, it is always a good idea to make a backup
# before doing a repair or any maintenance operation that could make a lot of changes to a table.
#
# myisamchk operations that affect indexes can cause MyISAM FULLTEXT indexes to be rebuilt with
# full-text parameters that are incompatible with the values used by the MySQL server.
#
# To avoid this problem, see earlier.
#
# MyISAM table maintenance can also be done using the SQL statements that perform operations
# similar to what myisamchk can do:
#
# 		) To check MyISAM tables, use CHECK_TABLE
#
# 		) To repair MyISAM tables, use REPAIR_TABLE
#
# 		) To optimize MyISAM tables, use OPTIMIZE_TABLE
#
# 		) To analyze MyISAM tables, use ANALYZE_TABLE
#
# For additional information about these statements, see later.
#
# These statements can be used directly or by means of the mysqlcheck client program.
#
# One advantage of these statements over myisamchk is that the server does all the work.
#
# With myisamchk, you must make sure that the server does not use the tables at the same time
# so that there is no unwanted interaction between myisamchk and the server.
#
# USING MYISAMCHK FOR CRASH RECOVERY
#
# This section describes how to check for and deal with data corruption in MySQL databases.
# If your tables become corrupted frequently, you should try to find the reason why. 
#
# For an explonation of how MyISAM tables can become corrupted, see later.
#
# If you run mysqld with external locking disabled (which is the default), you cannot reliably use 
# myisamchk to check a table when mysqld is using the same table.
#
# If you can be certain that no one will access the tables through mysqld while you run
# myisamchk, you only have to execute mysqladmin flush-tables before you start checking the tables.
#
# If you cannot guarantee this, you must stop mysqld while you check the tables.
#
# If you run myisamchk to check tables that mysqld is updating at the same time,
# you may get a warning that a table is corrupt even when it is not.
#
# If the server is run with external locking enabled, you can use myisamchk to check tables at any time.
#
# IN this case, if the server tries to update a table that myisamchk is using, the server will wait 
# for myisamchk to finish before it continues.
#
# If you use myisamchk to repair or optimize tables, you must always ensure that the mysqld server is
# not using the table (this also applies if external locking is disabled).
#
# If you do not stop mysqld, you should at least do a mysqladmin flush-tables before you run myisamchk.
# Your tables may become corrupted if the server and myisamchk access the tables simultaneously.
#
# When performing a crash recovery, it is important to understand that each MyISAM table tbl_name in
# a database corresponds to the three files in the database directory shown in teh following table.
#
# FIle 					Purpose
#
# tbl_name.MYD 		Data file
# tbl_name.MYI 		index file
#
# Each of these three file types is subject to corruption in various ways, but problems occur most often
# in data files and index files.
#
# myisamchk works by creating a copy of the .MYD data file row by row.
#
# It ends the repair stage by removing the old .MYD file and renaming the new file to the original file
# name.
#
# If you use --quick, myisamchk does not create a temporary .MYD file, but instead assumes that the .MYD file
# is correct and generates only a new index file without touching the .MYD file.
#
# This is safe, because myisamchk automatically detects whether the .MYD file is corrupt and aborts the repair
# if it is.
#
# You can also specify the --quick option twice to myisamchk.
#
# In this case, myisamchk does not abort on some errors (such as duplicate-key errors) but instead
# tries to resolve them by modifying the .MYD file.
#
# Normally, the use of two --quick options is useful only if you have too little free disk space to perform
# a normal repair.
#
# In this case, you should at least make a backup of the table before running myisamchk.
#
# HOW TO CHECK MYISAM TABLES FOR ERRORS
#
# To check a MyISAM table, use the following commands:
#
# 	) myisamchk tbl_name
#
# 		This finds most errors. What it cannot find is corruption that involves ONLY the data file (unusual).
# 		If you want to check a table, you should normally run myisamchk without options or with the -s (silent) option.
#
# 	) myisamchk -m tbl_name
#
# 		This finds most errors. First checks all index entries for errors and then reads through all rows.
#
# 		It calculates a checksum for all key values in the rows and verifies that the checksum matches
# 		the checksum for the keys in the index tree.
#
# 	) myisamchk -e tbl_name
#
# 		This does a complete and throrough check of all data (-e means "extended").
#
# 		It does a check-read of every key for each row to verify that they indeed point to the
# 		correct row.
#
# 		This may take a long time for a large table that has many indexes.
#
# 		Normally, myisamchk stops after the first error it finds.
#
# 		If you want to obtain more information, add the -v (verbose) option. This causes myisamchk to keep going, up to a max of 20 errors.
#
# 	) myisamchk -e -i tbl_name
#
# 		Like extensive, but the -i is to print additional statistical information.
#
# In most cases, a simple myisamchk command with no arguments other than the table name is sufficient
# to check a table.
#
# HOW TO REPAIR MYISAM TABLES
#
# The discussion in this section describes how to use myisamchk on MyISAM tables (extensions .MYI and .MYD)
#
# You can also use the CHECK_TABLE and REPAIR_TABLE statements to check and repair MyISAM tables.
# See later for more info.
#
# Symptoms of corrupted tables include queries that abort unexpectedly and observable errors such as these:
#
# 		) Can't find file tbl_name.MYI (Errorcode: nnn)
#
# 		) unexpected end of file
#
# 		) Record file is crashed
#
# 		) Got error nnn from table handler
#
# To get more information about the error, run perror nnn, where nnn is the error number.
#
# The following example shows how to use perror to find the meanings for the most common error
# numbers that indicate a problem with a table:
#
# 		perror 126 127 132 134 135 136 141 144 145
# 		MySQL error code 126 = Index file is crashed
# 		MySQL error code 127 = record-file is crashed
# 		MySQL error code 132 = Old database file
# 		MySQL error code 134 = Record was already deleted (or record file crashed)
#
# 		MySQL error code 135 = No more room in record file
# 		MySQL error code 136 = No more room in index file
# 		MySQL error code 141 = Duplicate unique key or constraint on write or update
# 		MySQL error code 144 = Table is crashed and last repair failed
# 		MySQL error code 145 = Table was marked as crashed and should be repaired
#
# Note that error 135 (no more room in record file) and error 136 (no more room in index file) are not errors
# that can be fixed by a simple repair.
#
# In this case, you must use ALTER_TABLE to increase the MAX_ROWS and AVG_ROW_LENGTH table option values:
#
# 		ALTER TABLE tbl_name MAX_ROWS=xxx AVG_ROW_LENGTH=yyy;
#
# If you do not know the current table option values, use SHOW_CREATE_TABLE.
#
# For the other errors, you must repair your tables. myisamchk can usually detect and fix most problems
# that occur.
#
# The repair process involves up to three stages, described here.
#
# Before you begin, you should change location to the database directory and check the permissions
# of the table files.
#
# On Unix, make sure that they are readable by the user that mysqld runs as (and to you, because you need
# to access the files you are checking).
#
# If it turns out you need to modify files, they must also be writable by you.
#
# This section is for cases where a table check fails (such as those described earlier), or you want
# to use the extended features that myisamchk provides.
#
# The myisamchk options used for table maintenance are described earlier.
#
# Note that when you do mysqladmin shutdown on a remote server, the mysqld server is still available
# for a while after mysqladmin returns, until all statement-processing has stopped and all index
# changes have been flushed to disk.
#
# STAGE 1: Checking your tables
#
# Run myisamchk *.MYI or myisamchk -e *.MYI if you have more time. Use the -s (silent) option to suppress uncalled for information.
#
# If the mysqld server is stopped, you should use the --update-state option to tell myisamchk to mark the table as "checked".
#
# You have to repair only those tables for which myisamchk announces an error. for such tables, go to step 2.
#
# If you get unexpected errors when checking (such as out of memory errors), or if myisamchk crashes, go to Stage 3.
#
# STAGE 2: Easy safe repair
#
# First, try myisamchk -r -q tbl_name (-r -q means "quick recovery mode"):
#
# This attempts to repair the index file without touching the data file. 
#
# If the data file contains everything that it should and the delete links
#  point at the correct locations within the data file, this should work - and teh table is fixed.
#
# Thus, you can go to the next table.
#
# Otherwise, use the following procedure:
#
# 		1. Make a backup of the data file before continuing.
#
# 		2. Use myisamchk -r tbl_name (-r means "recovery mode"). This removes incorrect rows and deleted rows from teh data file and reconstructs the index file.
#
# 		3. If the preceding steps fail, use myisamchk --safe-recover tbl_name.
#
# 			Safe recovery mode uses an old recovery method that handles a few cases that regular recovery mode
# 			mode does not (but is slower).
# 
# 			NOTE:
# 				If you want a repair operation to go much faster, you should set the values of the sort_buffer_size and key_buffer_size variables each to about
# 				25% of your available memory when running myisamchk.
#
# 			If you get unexpected errors when repairing (such as out of memory errors), or if myisamchk crashes, go to Stage 3.
#
# STAGE 3: Difficult Repair
#
# You should reach this stage only if the first 16 kb block in the index file is destroyed or contains incorrect information,
# 	or if the index file is missing.
#
# In this case, it is necessary to create a new index file.
#
# Do as follows:
#
# 		1. Move the data to a safe place.
#
# 		2. Use the table desc. file to create new (empty) data and index files:
#
# 				mysql db_name
#
# 				SET autocommit=1;
# 				TRUNCATE TABLE tbl_name;
# 				quit
#
# 		3. Copy the old data file back onto the newly created data file.
# 			(Do not just move the old file back onto the new file. You want to retain a copy in case something goes wrong)
#
# 			IMPORTANT:
#
# 				If you are using replication, you should stop it prior to performing the above procedure, since it involves
# 				file system operations, and these are not logged by MySQL.
#
# 	Go back to Stage 2. myisamchk -r -q should work (This should not be an endless loop)
#
# You can also use the REPAIR TABLE tbl_name USE_FRM SQL statement, which performs the whole procedure automatically.
#
# There is also no possibility of unwanted interaction between a utility and the server, because the server does all
# the work when you use REPAIR_TABLE. More on REPAIR_TABLE later.
#
# MyISAM TABLE OPTIMIZATION
#
# To coalesce fragmented rows and eliminate wasted space that results from deleting or updating rows, run myisamchk in recovery mode:
#
# 		myisamchk -r tbl_name
#
# You can optimize a table in the same way by using the OPTIMIZE_TABLE SQL statement.
#
# OPTIMIZE_TABLE does a table repair and a key analysis, and also sorts the index tree so that
# key lookups are faster.
#
# There is also no possibility of unwanted interaction between a utility and the server, because the server
# does all the work when you use OPTIMIZE_TABLE. More on this later.
#
# myisamchk has a number of other options that you can use to improve the performance of a table:
#
# 		) --analyze or -a: Perform key distribution analysis. This improves join performance by enabling the join optimizer
# 									to better choose the order in which to join the tables and which indexes it should use.
#
# 		) --sort-index or -S: Sort the index blocks. This optimizes seeks and makes table scans that use indexes faster.
#
# 		) --sort-records=index_num or -R index_num: Sort data rows according to a given index. This makes your data much more
# 																	localized and may speed up range-based SELECT and ORDER BY operations that use this index.
#
# For a full description of all available options, see earlier.
#
# SETTING UP A MYISAM TABLE MAINTENANCE SCHEDULE
#
# It is a good idea to perform table checks on a regular basis rather than waiting for problems to occur.
# One way to check and repair MyISAM tables is with the CHECK_TABLE and REPAIR_TABLE statements. See later.
#
# Another way to check tables is to use myisamchk. For maintenance purposes, you can use myisamchk -s.
# THe -s (silent) causes myisamchk to run in silent mode, printing messages only when errors occur.
#
# It is also a good idea to enable automatic MyISAM table checking.
#
# For example, whenever the machine has done a restart in the middle of an update, you usually need to check
# each table that could have been affected before it is used further.
#
# (These are "expected crashed tables")
#
# To cause the server to check MyISAM tables automatically, start it with the --myisam-recover-options
# option. See earlier.
#
# You should also check your tables regularly during normal system operation.
# For example, you can run a cron job to check important tables once a week, using
# a line like this in a crontab file:
#
# 		35 0 * * 0 /path/to/myisamchk --fast --silent /path/to/datadir/*/*.MYI
#
# THis prints out information about crashed tables so that you can examine and repair them as called for.
#
# To start with, execute myisamchk -s each night on all tables that have been updated during the last 24 hours.
# AS you see that problems occur infrequently, you can back off the checking frequency to once a week or so.
#
# Normally, MySQL tables need little maintenance. If you are performing many updates to MyISAM tables with
# dynamic-sized rows (tables with VARCHAR, BLOB or TEXT columns)
#
# or have tables with many deleted rows you may want to defragment/reclaim space from the tables
# from time to time.
#
# You can do this by using OPTIMIZE_TABLE on the tables in question.
#
# Alternatively, if you can stop the mysqld server for a while, change location into the data directory
# and use this command while the server is stopped:
#
# 		myisamchk -r -s --sort-index --myisam_sort_buffer_size=16M */*.MYI
#
# OPTIMIZATION
#
# This chapter explains how to optimize MySQL performance and provides examples.
#
# Optimization involves configuring, tuning and measuring performance, at several levels.
#
# Depending on your job role (developer, DBA or a combination), you might optimize at the level of individual
# SQL statements, entire applications, a single DB server or multiple networked DB servers.
#
# Sometimes you can be proactive and plan in advance for performance, while other times you might troubleshoot
# a configuration or code issue after a problem occurs.
#
# Optimizing CPU and memory usage can also improve scalability, allowing the DB to handle more load without
# slowing down.
#
# OPTIMIZATION OVERVIEW
#
# Database performance depends on several factors at the DB level, such as tables, queries and configuration settings.
#
# These software constructs result in CPU and I/O operations at the hardware level, which you must minimize and make
# as efficient as possible.
#
# As you work on DB performance, you start by learning the high-level rules and guidelines for the software side,
# and measuring performance using wall-clock time.
#
# As you get better, you learn m,ore about what happens internally, and start measuring things like CPU cycles and I/O operations.
#
# Typical users aim to get the best DB performance out of their existing software and hardware configurations.
#
# Advanced users look for oppurtounities to improve MySQL itself, or develop their own storage engines and hardware
# applicances to expand the MySQL ecosystem.
#
# OPTIMIZING AT THE DATABASE LEVEL
#
# The most important factor in making a database application fast is its basic design:
#
# 		) Are the tables structured properly? In particular, do the columns have the right data types and does each
# 			table have the appropriate columns for the type of work?
#
# 			For example, applications that perform frequent updates often have many tables with few columns,
# 			while applications that analyze large amounts of data often have few tables with many columns.
#
# 		) Are the right indexes in place to make queries efficient?
#
# 		) Are you using the appropriate storage engine for each table, and taking advantage of the strengths
# 			and features of each storage engine you use?
#
# 			In particular, the choice of a transactional engine such as InnoDB or a nontransactional one such as MyISAM
# 			can be very important for performance and scalability.
#
# 			NOTE:
#
# 				InnoDB is the default storage engine for new tables. In practice, the advanced InnoDB performance
# 				features mean that InnoDB tables often outperform the simpler MyISAM tables, esp. for a busy DB.
#
# 		) Does each table use an appropriate row format?
#
# 			This choice also depends on the storage engine used for the table. 
#
# 			IN particular, compressed tables use less disk space and so require less disk
# 			I/O to read and write the data.
#
# 			Compression is available for all kinds of workloads with InnoDB tables, and for read-only MyISAM tables.
#
# 		) Does the application use an appropriate locking strategy?
#
# 			For example, by allowing shared access when possible so that database operations can
# 			run concurrently, and requesting exclusive access when appropriate so that critical operations
# 			get top priority.
#
# 			Again, the choice of storage engine is significant.
#
# 			The InnoDB storage engine handles most locking issues without involvement from you, allowing
# 			for better concurrency in the database and reducing the amount of experimentation and tuning for
# 			your code.
#
# 		) Are all memory areas used for caching sized correctly?
#
# 			That is, large enough to hold frequently accessed data, but not so large that they overload
# 			physical memory and cause paging.
#
# 			The main memory areas to configure are the InnoDB buffer pool and the MyISAM key cache.
#
# OPTIMIZING AT THE HARDWARE LEVEL
#
# Any database application eventually hits hardware limits as the DB becomes more and more busy.
#
# A DBA must evaluate whether it is possible to tune the application or reconfigure the server to
# avoid these bottlenecks, or whether more hardware resources are required.
#
# System bottlenecks typically arise from these sources:
#
# 		) Disk seeks. It takes time for the disk to find a piece of data.
#
# 		With modern disks, the mean time for this is usually lower than 10ms, so we can in theory
# 		do about 100 seeks a second.
#
# 		this time improves slowly with new disks and is very hard to optimize for a single table.
#
# 		The way to optimize seek time is to distribute the data onto more than one disk.
#
# 		) Disk reading and writing.
#
# 			When the disk is at the correct position, we need to read or write the data.
#
# 			With modern disks, one disk delivers at least 10-20MB/s throughput.
#
# 			this is easier to optimize than seeks, because you can read in parallel from multiple disks.
#
# 		) CPU cycles. When the data is in main memory, we must process it to get our result.
#
# 			Having large tables compared to the amount of memory is the most common limit factor.
#
# 			But with small tables, speed is usually not the problem.
#
# 		) Memory bandwidth. When the CPU needs more data than can fit in the CPU cache, the main memory bandwidth
# 			becomes a bottleneck.
#
# 			This is an uncommon bottleneck for most systems, but one to be aware of.
#
# BALANCING PORTABILITY AND PERFORMANCE
#
# To use performance-oriented SQL extensions in a portable MySQL program, you can wrap
# MySQL-specific keywords in a statement within /*! or */ comment delimiters.
#
# Other SQL servers ignore the command keywords. More on comments later.
#
# OPTIMIZING SQL STATEMENTS
#
# The core logic of a database application is performed through SQL statements, whether issued directly through
# an interpreter or submitted behind the scenes through an API.
#
# The tuning guidelines in this section helps to speed up all kinds of MySQL applications.
#
# The guidelines cover SQL operations that read and write data, the behind-the-scenes overhead for
# SQL operations in general, and operations used in specific scenarios such as database monitoring.
#
# OPTIMIZING SELECT STATEMENTS
#
# Queries, in teh form of SELECT statements, perform all teh lookup operations in the DB.
#
# Tuning these statements is a top priority, whether to achieve sub-second response times for dynamic web pages,
# or to chop hours off the time to generate huge overnight reports.
#
# Besides SELECT statements, the tuning techniques for queries also apply to constructs such as CREATE_TABLE---AS_SELECT,
# INSERT_INTO---SELECT, and WHERE clauses in DELETE statements.
#
# Those statements have additional performance considerations because they combine write operations with the read-oriented
# query operations.
#
# NDB Cluster supports a join pushdown optimization whereby a qualifying join is sent in its entirety to NDB Cluster data nodes,
# where it can be distributed among them and executed in parallel.
#
# For more information about this optimization, see Conditions for NDB pushdown joins.
#
# The main consideration for optimizing queries are:
#
# 		) To make a slow SELECT_---_WHERE query faster, the first thing to check is whether you can add an index.
#
# 			Set up indexes on columns used in the WHERE clause, to speed up evaluation, filtering and the final retrieval of results.
#
# 			To avoid wasted disk space, construct a small set of indexes that speed up many related queries used in your
# 			application.
#
# 			Indexes are especially important for queries that reference different tables, using features such as joins and foreign keys.
# 			You can use the EXPLAIN statement to determine which indexes are used for a SELECT.
#
# 			See more later on indexes and EXPLAIN optimizations.
#
# 		) Isolate and tune any part of the query, such as a function call, that takes excessive time.
#
# 			Depending on how the query is structured, a function could be called once for every row in
# 			in the result set, or even once for every row in the table, greatly magnifying any inefficiency.
#
# 		) Minimize the number of full table scans in your queries, particularly for big tables.
#
# 		) Keep table statistics up to date by using the ANALYZE_TABLE statement periodically, so the optimizer
# 			has the information needed to construct an efficient execution plan.
#
# 		) Learn the tuning techniques, indexing techniques and configuration parameters that are specific to the storage
# 			engine for each table.
#
# 			Both InnoDB and MyISAM have sets of guidelines for enabling and sustaining high performance in queries.
#
# 			MOre details on InnoDB Queries and MyISAM queries, later.
#
# 		) You can optimize single-query transactions for InnoDB tables, using the technique outlayed later in optimizing InnoDB Read-Only transactions
#
# 		) Avoid transforming the query in ways that make it hard to understand, especially if the optimizer does some of the same transformations automatically.
#
# 		) If a performance issue is not easily solved by one of the basic guidelines, investigate the internal details of the specific Query
# 			by reading the EXPLAIN plan and adjusting your indexes, WHERE clauses, join clauses, and so on.
#
# 			(When you reach a certain level of expertise, reading the EXPLAIN plan might be your first step for every query)
#
# 		) Adjust the size and properties of the memory areas that MySQL uses for caching.
#
# 			With efficient use of the InnoDB buffer pool, MyISAM key cache and the MysQL query cache,
# 			repeated queries run faster because the results are retrieved from memory the second and subsequent times.
#
# 		) Even for a query that runs fast using the cache memory areas, you might still optimize further so that they require
# 			less cache memory, making your application more scalable.
#
# 			Scalability means that your application can handle more simultaneous users, large requests, and so on, without
# 			experiencing a big drop in performance.
#
# 		) Deal with locking issues, where the speed of your query might be affected by other sesisons accessing the tables
# 			at the same time.
#
# WHERE CLAUSE OPTIMIZATION
#
# This section discusses optimizations that can be made for processing WHERE Clauses.
#
# The examples use SELECT statements, but the same optimizations apply for WHERE clauses in DELETE
# and UPDATE statements.
#
# NOTE:
# 		BEcause work on the MySQL optimizer is ongoing, not all of the optimizations that MySQL performs are documented here.
#
# You might be tempted to rewrite your queries to make arithemtic operations faster, while sacrificing readability.
# 
# Because MySQL does similar optimizations automatically, you can often avoid this work, and leave the query in a
# more understandable and maintainable form.
#
# Some of the optimizations performed by MySQL follow:
#
# 		) Removal of unnecessary parantheses:
#
# 			((a AND b) AND c OR ((a AND b) AND (c AND d))))
#
# 				Becomes
#
#
# 			(a AND b AND c) OR (a AND b AND c AND d)
#
# 		) Constant folding
#
# 			(a<b AND b=c) AND a=5
#
# 				Becomes
#
# 			b>5 AND b=c AND a=5
#
# 		) Constant condition removal (needed because of constant folding):
#
# 			(B>=5 AND B=5) OR (B=6 AND 5=5) OR (B=7 AND 5=6)
# 			
# 				Becomes
#
# 			B=5 OR B=6
#
# 		) Constant expressions used by indexes are evaluated only once.
#
# 		) COUNT(*) on a single tab without a WHERE is retrieved directly from the table information for MyISAM and MEMORY tables.
# 			This is also done for any NOT NULL expression when used with only one table.
#
# 		) Early detection of invalid constant expressions. MySQL quickly detects that some SELECT statements are impossible and returns no rows.
#
# 		) HAVING is merged with WHERE if you do not use GROUP BY or aggreggate functions (COUNT(), MIN() and so on)
#
# 		) For each table in a join, a simpler WHERE is constructed to get a faster WHERE evaluation for the table and also to skip
# 			rows as soon as possible.
#
# 		) All constant tables are read first before any other tables in the query. A constant table is any of the following:
#
# 			) An empty table or a table with one row.
#
# 			) A table that is used with a WHERE clause on a PRIMARY KEY or a UNIQUE index, where all index parts are compared to
# 				constant expressions and are defined as NOT NULL.
#
# 			All of the following tables are used as constant tables:
#
# 				SELECT * FROM t WHERE primary_key=1;
# 				SELECT * FROM t1,t2
# 					WHERE t1.primary_key=1 AND t2.primary_key=t1.id;
#
# 		) The best join combination for joining the tables is found by trying all possibilities.
#
# 			If all columns in ORDER BY and GROUP BY clauses come from the same table, that table is
# 			preferred first when joining.
#
# 		) If there is an ORDER BY clause and a different GROUP BY clause, or if the ORDER BY or GROUP BY
# 			contains columns from tables other than the first table in the join queue, a temporary table is created.  			
#
# 		) If you use the SQL_SMALL_RESULT modifier, MySQL uses an in-memory temporary table.
#
# 		) Each table index is queried, and the best index is used unless the optimizer believes that it is more efficient
# 			to use a table scan.
#
# 			At one time, a scan was used based on whether the best index spanned more than 30% of the table, but a fixed
# 			% no longer determines the choice between using an index or a scan.
#
# 			The optimizer now is more complex and bases its estimate on additional factors such as table size, number of rows,
# 			and I/O block size.
#
# 		) In some cases, MySQL can read rows from the index without even consulting the data file.
#
# 			If all columns used from the index are numeric, only the index tree is used to resolve the query.
#
# 		) Before each row is output, those that do not match the HAVING clause are skipped.
#
# Some examples of queries that are very fast:
#
# 		SELECT COUNT(*) FROM tbl_name;
#
# 		SELECT MIN(key_part1), MAX(key_part1) FROM tbl_name;
#
# 		SELECT MAX(key_part2) FROM tbl_name WHERE key_part1=constant;
#
# 		SELECT_---_FROM tbl_name ORDER BY key_part1, key_part2,___ LIMIT 10;
#
# 		SELECT_---_FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ___ LIMIT 10;
#
# MySQL resolves the following queries using only the index tree, assuming that the indexed columns
# are numeric:
#
# 		SELECT key_part1, key_part2 FROM tbl_name WHERE key_part1=val;
#
# 		SELECT COUNT(*) FROM tbl_name WHERE key_part1=val1 AND key_part2=val2;
#
# 		SELECT key_part2 FROM tbl_name GROUP BY key_part1;
#
# The following queries use indexing to retrieve the rows in sorted order without a separate sorting pass:
#
# 		SELECT_---_FROM tbl_name ORDER BY key_part1, key_part2, ---;
#
# 		SELECT_---_FROM tbl_name ORDER BY key_part1 DESC, key_part2 DESC, ---;
#
# 	Note: The --- are the triple dots, synonym for "etc.", i cannot write the triple dots in this document due to unnessecary querying.
#
# RANGE OPTIMIZATION
#
# The range access method uses a single index to retrieve a subset of table rows that are contained within
# one or several index value intervals.
#
# It can be used for single-part or multi-part index. The following section describes conditions under which
# the optimizer uses range access.
#
# 	) Range Access Method for Single-part indexes
#
# 	) Range ACcess Method for Multiple-part indexes
#
# 	) Equality Range Optimization of Many-Valued Comparisons
#
# 	) Skin Scan Range Access Method
#
# 	) Range Optimization of Row Constructor Expressions
#
# 	) Limiting Memory Use for Range Optimization
#
# RANGE ACCESS METHOD FOR SINGLE-PART INDEXES
#
# For a single-part index, index value intervals can be conveniently represented by corresponding conditions in the
# WHERE clause, denoted as range conditions rather than "intervals".
#
# The definition of a range condition for a single-part index is as follows:
#
# 		) For both BTREE and HASH indexes, comparisons of a key part with a constant value is a range condition when using the
# 			=, <=>, IN(), IS_NULL, or IS_NOT_NULL operators.
#
# 		) Additionally, for BTREE indexes, comparisons of a key part with a constant value is a range condition when using
# 			the >, <, >=, <=, BETWEEN, !=, or <> operators, or LIKE comparisons if the argument to LIKE is a 
# 			constant string that does not start with a wildcard character.
#
# 		) for all index types, multiple range conditions combined with OR or AND form a range condition.
#
# "Constant value" in the preceding descriptions means one of the following:
#
# 		) A constant from the query string
#
# 		) A column of a const or system table from teh same join
#
# 		) The result of an uncorrelated subquery
#
# 		) Any expression composed entirely from subexpressions of the preceding types.
#
# Here are some examples of Queries with range conditions in the WHERE clause:
#
# 		SELECT * FROM t1
# 			WHERE key_col > 1
# 			AND key_col < 10;
#
# 		SELECT * FROM t1
# 			WHERE key_col = 1
# 			OR key_col IN (15,18,20);
#
# 		SELECT * FROM t1
# 			WHERE key_col LIKE 'ab%'
# 			OR key_col BETWEEN 'bar' AND 'foo';
#
# Some nonconstant values may be converted to constants during the optimizer constant propagation phase.
#
# MySQl tries to extract the range conditions from the WHERE clause for each of the possible indexes.
#
# During the extraction process, conditions that cannot be used for constructing the range condition are dropped,
# conditions that produce overlapping ranges are combined, and conditions that produce empty ranges are removed.
#
# Consider the following statement, where key1 is an indexed column and nonkey is not indexed:
#
# 		SELECT * FROM t1 WHERE
# 			(key1 < 'abc' AND (key1 LIKE 'abcde%' OR key1 LIKE '%b')) OR
# 			(key1 < 'bar' AND nonkey = 4) OR
# 			(key1 < 'uux' AND key1 > 'z');
#
# The extraction process for key key1 is as follows:
#
# 		1. Start with the original WHERE clause:
#
# 			(key1 < 'abc' AND (key1 LIKE 'abcde%' OR key1 LIKE '%b')) OR
# 			(key1 < 'bar' AND nonkey = 4) OR
# 			(key1 < 'uux' AND key1 > 'z')
#
# 		2. Remove nonkey = 4 and key1 LIKE '%b' because they cannot be used for a range scan.
#
# 			The correct way to remove them is to replace them with TRUE, so that we do not miss any matching rows
# 			when doing the range scan.
#
# 			Replacing them with TRUE yields:
#
# 				(key1 < 'abc' AND (key1 LIKE 'abcde%' OR TRUE)) OR
# 				(key1 < 'bar' AND TRUE) OR
# 				(key1 < 'uux' AND key1 > 'z')
#
# 		3. Collapse conditions that are always true or false:
#
# 				(key1 LIKE 'abcde%' OR TRUE) is always true
#
# 				(key1 < 'uux' AND key1 > 'z') is always false
#
# 			Replacing these conditions with constants yields:
#
# 				(key1 < 'abc' AND TRUE) OR (key1 < 'bar' AND TRUE) OR (FALSE)
#
# 			Removing unnecessary TRUE and FALSE constants yields:
#
# 				(key1 < 'abc') OR (key1 < 'bar')
#
# 		4. Combining overlapping intervals into one yields the final condition to be used for hte range scan:
#
# 			(key1 < 'bar')
#
# In general (and as demonstrated by the preceding example), the condition used for a range scan is less restrictive
# than the WHERE clause.
#
# Mysql performs an additional check to filter out rows that satisfy the range condition but not the full WHERE clause.
#
# The range condition extraction algorithm can handle nested AND/OR constructs of arbitrary depth, and its output does
# not depend on the order in which conditions appear in WHERE clause.
#
# MySQL does not support merging multiple ranges for the range access method for spatial indexes.
#
# To work around this limitation, you can use a UNION with identical SELECT statements, except that
# you put each spatial predicate in a different SELECT.
#
# RANGE ACCESS METHOD FOR MULTIPLE-PART INDEXES
#
# Range conditions on a multiple-part index are an extension of range conditions for a single-part index.
#
# A range condition on a multiple-part index restricts index rows to lie within one or several key tuple intervals. 
#
# Key tuple intervals are defined over a set of key tuples, using ordering from the index.
#
# For example, consider a multiple-part index defined as key1(key_part1, key_part2, key_part3), and the following
# set of key tuples listed in key order:
#
# 		key_part1 		key_part2 		key_part3
# 			NULL 				1 					'abc'
# 			NULL 				1 					'xyz'
# 			NULL 				2 					'foo'
# 			1 					1 					'abc'
# 			1 					1 					'xyz'
# 			1 					2 					'abc'
# 			2 					1 					'aaa'
#
# The condition key_part1 = 1 defines this inteval:
#
# (1, -inf, -inf) <= (key_part1, key_part2, key_part3) < (1, +inf, +inf)
#
# The interval converts the 4th and 5th and 6th tuples in the preceding data set and can be used by the range
# access method.
#
# By contrast, the condition key_part3 = 'abc' does not define a single interval and cannot be used by the range access method.
#
# The following descriptions indicate how range conditions work for multiple-part indexes in greater detail.
#
# 		) For HASH indexes, each interval containing identical values can be used.
#
# 		This means that the interval can be produced only for conditions in the following form:
#
# 			key_part1 cmp const1
# 		AND key_part2.cmp const2
# 		AND ---
# 		AND key_partN cmp constN
#
# Here, const1, const2, --- are constants, cmp is one of the =,<=>, or IS_NULL comparison operators, and the conditions
# cover all index parts.
#
# (That is, there are N conditions, one for each part of an N-part index). For example, the following is a range condition
# for a three-part HASH index:
#
# 		key_part1 = 1 AND key_part2 IS NULL AND key_part3 = 'foo'
#
# FOr the definition of what is considered to be a constant, see Range Access Methods ofr Single-part indexes.
#
# ) For a BTREE index, an interval might be usable for conditions combined with AND, where each condition compares a key part with a 
# 		constant value using =, <=>, IS_NULL, >, <, >=, <=, !=, <>, BETWEEN, or LIKE_'pattern' (where 'pattern' does not start with a %).
#
# 	An interval can be used as long as it is possible to determine a single key tuple containing all rows that match the condition
# 	(or two intervals if <> or != is used)
#
# 	The optimizer attempts ot use additional key parts to determine the interval as long as the comparison operator is =, <=>, or IS_NULL.
# 	If the operator is >, <, >=, <=, !=, <>, BETWEEN or LIKE, the optimizer uses it but considers no more key parts.
#
# 	For the following expression, the optimizer uses = from the first comparison.
#
# 	It also uses >= from the second comparison but considers no further key pats and does not use the htird comparison
# 	for interval construction:
#
# 		key_part1 = 'foo' AND key_part2 >= 10 and key_part3 > 10
#
# 	The single interval is:
#
# 		('foo',10,-inf) < (key_part1, key_part2, key_part3) < ('foo',+inf,+inf)
#
# 	It is possible that the created interval contains more rows than the intiail condition.
#
# 	For example, the preceding interval includes the value ('foo', 11, 0) which does not satisfy the original condition.
#
# ) If conditions that cover sets of rows contained within intervals are combined with OR, they form a condition taht covers
# 		a set of rows contained within the union of their intervals.
#
# 		If the conditions are combined with AND, they form a condition that covers a set of rows contained within the intersection
# 		of their intervals.
#
# 		For example, for this condition on a two-part index:
#
# 			(key_part1 = 1 AND key_part2 < 2) OR (key_part1 > 5)
#
# 		The intervals are:
#
# 			(1, -inf) < (key_part1, key_part2) < (1,2)
# 			(5, -inf) < (key_part1, key_part2)
#
# 		IN this example, the interval of the first line uses one key part for the left bound and two key parts for the right bound.
#
# 		The interval on the second line uses only one key part.
#
# 		The key_len column in the EXPLAIN output indicates the max length of the key prefixed used.
#
# 		In some cases, key_len may indicate that a key part was used, but that might be not what you would expect.
#
# 		SUppose that key_part1 and key_part2 can be NULL.
#
# 		THen the key_len column displays two key part lengths for the following condition:
#
# 			key_part1 >= 1 AND key_part2 < 2
#
# 		But in fact, the condition is converted to this:
#
# 			key_part1 >= 1 AND key_part2 IS NOT NULL
#
# 		For a description of how optimizations are performed to combine or eliminate intervals for range conditions on a single-part index,
# 		see Range Access method for Single-part indexes.
#
# 		Analogous steps are perforemd for range conditions on multiple-part indexes.
#
# EQUALITY RANGE OPTIMIZATION OF MANY-VALUED COMPARISONS
#
# Consider these expressions, where col_name is an indexed column:
#
# 		col_name IN(val1, ---, valN)
# 		col_name = val1 OR --- OR col_name = valN
#
# Each expression is true if col_name is equal to any of several values.
#
# These comparisons are equality range comparisons (where the "range" is a single value).
# The optimizer estimates the cost of reading qualifying rows for equality range comparisons as follows:
#
# 		) If there is a unique index on col_name, the row estimate for each range is 1 because at most one row can ahve the given value
#
# 		) Otherwise, any index on col_name is a nonunique and the optimizer can estimate the row count for eaach range using dives into
# 			the index or index statistics.
#
# With index dives, the optimizer makes a dive at each end of a range and uses the number of rows in the range as the estimate.
#
# FOr example, the expression col_name IN (10, 20, 30) has three equality ranges and teh optimizer makes two dives per range to generate a row estimate.
#
# Each pair of dives yields an estimate of the number of rows that have the given value.
#
# Index dives provide accurate row estimates, but as the number of comparison values in the expression increases, the optimizer
# takes longer to genrate a row estimate.
#
# Use of index statitics is elss accurate than index dives but permits faster row estimation for large value lists.
#
# The eq_range_index_dive_limit system variable enables you to configure the number of values at which the optimizer switches
# from one row estimation strategy to the other.
#
# To permit use of index dives for comparisons of up to N equality ranges, set eq_range_index_dive_limit to N + 1.
#
# To disable use of statistics and always use index dives regardless of N, set eq_range_index_dive_limit to 0.
#
# TO update table index statistics for best estimates, use ANALYZE_TABLE
#
# Prior to MysQL 8.0, there is no way of skipping that use of index dives to estimate index usefulness, except by using the eq_range_index_dive_limit system variable.
#
# In > 8.0, index dive skipping is possible for queries that satisfy all of these conditions:
#
# 		) The query is for a single table, not a join on multiple tables.
#
# 		) A single-index FORCE INDEX index hint is present. 
#
# 			The idea is that if index use is forced, there is nothing to be gained from the additional
# 			overhead of performing dives into the index.
#
# 		) The index is nonunique and not a FULLTEXT index.
#
# 		) No subquery is present.
#
# 		) No DISTINCT, GROUP BY or ORDER BY clause is present.
#
# For EXPLAIN_FOR_CONNECTION, the output changes as follows if index dives are skipped:
#
# 		) For traditional output, the rows and filtered values are NULL.
#
# 		) For JSON output, rows_examined_per_scan and rows_produced_per_join do not appear, skip_index_dive_due_to_force is true, and cost calculations
# 			are not accurate.
#
# Without FOR CONNECTION, EXPLAIN output does not change when index dives are skipped.
#
# After execution of a query for which index dives are skipped, the corrsponding row in the INFORMATION_SCHEMA.OPTIMIZER_TRACE table
# contains an index_dives_for_range_access value of skipped_due_to_force_index
#
# SKIP SCAN RANGE ACCESS METHOD
#
# Consider the following scenario:
#
# 		CREATE TABLE t1 (f1 INT NOT NULL, f2 INT NOT NULL, PRIMARY KEY(f1, f2));
# 		INSERT INTO t1 VALUES
# 			(1,1), (1,2), (1,3), (1,4), (1,5),
# 			(2,1), (2,2), (2,3), (2,4), (2,5);
#
# 		INSERT INTO t1 SELECT f1, f2 + 5 FROM t1;
# 		INSERT INTO t1 SELECT f1, f2 + 10 FROM t1;
# 		INSERT INTO t1 SELECT f1, f2 + 20 FROM t1;
#
# 		INSERT INTO t1 SELECT f1, f2 + 40 FROM t1;
#
# 		ANALYZE TABLE t1;
#
# 		EXPLAIN SELECT f1, f2 FROM t1 WHERE f2 > 40;
#
# To execute this query, MySQL can choose an index scan to fetch all rows (the index includes all columns to be selected),
# then apply the f2 > 40 condition from the WHERE clause to produce the final result set.
#
# A range scan is more efficient than a full index scan, but cannot be used in this case because there is no condition
# on f1, the first index column.
#
# However, as of MySQL 8.0.13, the optimizer can perform multiple range scans, one for each value of 1, using a method
# called Skip Scan that is similar to Loose Index Scan (see later under GROUP BY optimization)
#
# 	1. Skip between distinct values of the first index part, f1 (the index prefix)
#
# 	2. Perform a subrange scan on eahc distinct prefix value for the f2 > 40 condition on the remaining index part.
#
# For the data set shown earlier, the algorithm operates like this:
#
# 	1. Get the first distinct value of the first key part (f1 = 1)
#
# 	2. Construct the range based on the first and second key parts (f1 = 1 AND f2 > 40)
#
# 	3. Perform a range scan
#
# 	4. Get the next distinct value of the key first part (f1 = 2)
#
# 	5. Construct the range based on the first and second key parts (f1 = 2 AND f2 > 40)
#
# 	6. Perform a range scan
#
# Using this strategy decreases the number of accessed rows because MySQL skips the rows that do not qualify
# for each constructed range.
#
# THe SKip Scan method is applicable under the following conditions:
#
# ) Table T has at least one compound index with key parts of the form ([A_1, ---, A_k,] B_1, ---, B_m, C[,D_1,---,D_n])
#
# Key parts A and D may be empty, but B and C must be nonempty.
#
# ) The query references onl one table
#
# ) The query does not use GROUP BY or DISTINCT
#
# ) The query references only columns in teh index
#
# ) The predicates on A_1, ---, A_k must be equality predicates and they must be constants. This includes the IN() operator.
#
# ) The query must be a conjunctive query; that is, an AND of OR conditions: (cond1(key_part1) OR cond2(key_part1)) AND (cond1(key_part2) OR ---) AND ---
#
# ) There must be a range condition on C
#
# ) Conditions on D columns are permitted. Conditions on D must be in conjunction with the range condition on C.
#
# Use of Skip Scan is indicated in EXPLAIN output as follows:
#
# 		) Using index for skip scan in the Extra column indicates that hte loose index Skip Scan access method is used.
#
# 		) If teh index can be used for Skip Scan, the index should be visible in the possible_keys column.
#
# Use of SKip scan is indicated in the optimizer trace output by a "skip scan" element of this form:
#
# "skip_scan_range": {
# 		"type": "skip_scan",
# 		"index": index_used_for_skip_scan,
# 		"key_parts_used_for_access": [key_parts_used_for_access],
# 		"range": [range]
# }
#
# You may also see a "best_skip_scan_summary" element.
#
# If Skip Scan is chosen as the best range access variant, a "chosen_range_access_summary" is written.
# If SKip Scan is chosen as the overall best access method, a "best_access_path" element is present.
#
# Use of Skip Scan is subject to the value of the skip_scan flag of the optimizer_switch system variable.
#
# More later in regards to Switchable Optimizations.
#
# By default, this flag is on. To disable it, set skip_scan to off.
#
# In addition to using the optimizer_switch system variable to control optimizer use of Skip Scan session-wide,
# MySQL supports optimizer hints to influence the optimizer on a per-statement basis. 
#
# More on optimizer hints later.
#
# RANGE OPTIMIZATION OF ROW CONSTRUCTOR EXPRESSIONS
#
# The optimizer is able to apply the range scan access method to queries of this form:
#
# 		SELECT --- FROM t1 WHERE ( col_1, col_2 ) IN (( 'a', 'b' ), ( 'c', 'd' ));
#
# Previously, for range scans to be used, it was necessary to write the query as:
#
# 		SELECT --- FROM t1 WHERE ( col_1 = 'a' AND col_2 = 'b' ) OR ( col_1 = 'c' AND col_2 = 'd');
#
# For the optimizer to use a range scan, queries must satisfy these conditions:
#
# 		) Only IN() predicates are used, not NOT_IN()
#
# 		) On the left side of the IN() predicate, the row constructor contains only column references.
#
# 		) On the right side of the IN() predicate, row constructors contain only runtime constants, which are either
# 			literals or local column references that are bound to constants during execution.
#
# 		) On the right side of the IN() predicate, there is more than one row constructor.
# 		
# For more information about the optimizer and row constructors, see later under ROW CONSTRUCTOR EXPRESSION OPTIMIZATION
#
# LIMIT MEMORY USE FOR RANGE OPTIMIZATION
#
# TO control the memory available to the range optimizer, use teh range_optimizer_max_mem_size system variable.
#
# ) A value of 0 means "no limit"
#
# ) With a value of > 0, the optimizer tracks the memory consumed when considering the range access method.
#
# 		IF the specified limit is about to be exceeded, the range access method is abandoned and other methods,
# 		including a full table scan, are considered instead.
#
# 		This could be less optimal.
#
# 		If this happens, the following warning occurs (where N is the current range_optimizer_max_mem_size value):
#
# 			Warning 3170 Memory capacity of N bytes for 'range_optimizer_max_mem_size' exceeded.
# 							 Range optimization was not done for this query.
#
# ) For UPDATE and DELETE statements, if the optimizer falls back to a full table scan and the sql_safe_updates system variable
# 		is enabled, an error occurs rather than a warning, because in effect - no key is used to determine which rows to modify.
#
# 		For more information, see earlier.
#
# For individual queries that exceed the available range optimization memory and for which the optimizer falls back
# to less optimal plans, increasing the range_optimizer_max_mem_size value may improve performance.
#
# To estimate the amount of memory needed to process a range expression, use these guidelines:
#
# 		) For a simple query such as the following, where there is one candidate key for the range access method,
# 			each predicate combined with OR uses approximately 230 bytes:
#
# 			SELECT COUNT(*) FROM t
# 			WHERE a=1 OR a=2 OR a=3 OR --- a=N;
#
# 		) Similarly for a query such as the following, each predicate combined with AND uses approximately 125 bytes:
#
# 			SELECT COUNT(*) FROM t
# 			WHERE a=1 AND b=1 AND c=1 --- N;
#
# 		) For a query with IN() predicates:
#
# 			SELECT COUNT(*) FROM t
# 			WHERE a IN (1,2, ---, M) AND b IN (1,2, ---, N);
#
# 			Each literal value in an IN() list countsas a predicate combined with OR.
#
# 			If there are two IN() lists, the number of predicates combined with OR is the product of the number of
# 			literal values in each list.
#
# 			Thus, the number of predicates combined with OR in the preceding case is M x N
#
# INDEX MERGE OPTIMIZATION
#
# The Index Merge access method retrieves rows with multiple range scans and merges their results into one.
#
# This access method merges index scans from a single table only, not scans across multiple tables.
#
# The merge can produce unions, intersections, or unions-of-intersections of its underlying scans.
#
# Example queries for which Index Merge may be used:
#
# 		SELECT * FROM tbl_name WHERE key1 = 10 OR key2 = 20;
#
# 		SELECT * FROM tbl_name
# 			WHERE (key1 = 10 OR key2 = 20) AND non_key = 30;
#
# 		SELECT * FROM t1, t2
# 			WHERE (t1.key1 IN (1,2) OR t1.key2 LIKE 'value%')
# 			AND t2.key1 = t1.some_col;
#
# 		SELECT * FROM t1, t2
# 			WHERE t1.key1 = 1
# 			AND (t2.key1 = t1.some_col OR t2.key2 = t1.some_col2);
#
# Note:
#
# 		The Index Merge optimization algorithm ahs the following limitations:
#
# 			) If your query has a complex WHERE clause with deep AND/OR nesting and MySQL does not choose
# 				the optimal plan, try distributing terms using the following identity transformations:
#
# 				(x AND y) OR z => (x OR z) AND (y OR z)
# 				(x OR y) AND z => (x AND z) OR (y AND z)
#
# 			) Index Merge is not applicable to full-text indexes.
#
# In EXPLAIN output, the Index Merge method appears as index_merge in the type column.
#
# In this case, the key column contains a list of indexes used, and key_len contains
# a list of the longest key parts of those indexes.
#
# The Index Merge access method has several algorithms, which are displayed in the Extra field of EXPLAIN output:
#
# 		) Using intersect(---)
#
# 		) Using union(---)
#
# 		) Using sort_union(---)
#
# The following sections describe these algorithms in greater detail.
#
# THe optimizer chooses between different possible Index Merge algorithms and other access
# methods based on cost estimates of the various available options. 
#
# INDEX MERGE INTERSECTION ACCESS ALGORITHM
#
# This access algorithm is applicable where a WHERE clause is converted to several range conditions
# on different keys combined with AND and each condition is one of the following:
#
# 		) An N-part expression of this form, where the index has exactly N parts (that is, all index parts are covered):
#
# 			key_part1 = const1 AND key_part2 = const2 --- AND key_partN = constN
#
# 		) Any range condition over the primary key of an InnoDB table.
#
# Examples:
#
# 		SELECT * FROM innodb_table
# 			WHERE primary_key < 10 AND key_col1 = 20;
#
# 		SELECT * FROM tbl_name
# 			WHERE key1_part1 = 1 AND key1_part2 = 2 AND key2 = 2;
#
# The Index Merge intersection algorithm performs simultaneous scans on all used indexes and produces
# the intersection of row sequences that it receives from the merged index scans.
#
# If all columns used in teh query are covered by the used indexes, full table rows are not retreived 
# (EXPLAIN output contains Using index in Extra field in this case).
#
# Here is an example of such a query:
#
# 		SELECT COUNT(*) FROM t1 WHERE key1 = 1 AND key2 = 1;
#
# If the used indexes do not cover all columns used in the query, full rows are retrieved only
# when the range conditions for all used keys are satisfied.
#
# If one of the merged conditions is a condition over the primary key of an InnoDB table, it is not 
# used for row retrieval, but is used to filter out rows retrieved using other
# conditions.
#
# INDEX MERGE UNION ACCESS ALGORITHM
#
# The criteria for this algorithm are similar to those for the Index Merge intersection algorithm.
#
# The aplgorithm is applicable where the tables WHERE clause is converted to several range conditions
# on different keys combined with OR, and each condition is one of the following:
#
# 		) An N-part expression of this form, where the index has exactly N parts (that is, all index parts are covered):
#
# 			key_part1 = const1 AND key_part2 = const2 --- AND key_partN = constN
#
# 		) Any range condition over a primary key of an InnoDB table
#
# 		) A condition for which the Index Merge intersection algorithm is applicable
#
# Examples:
#
# 		SELECT * FROM t1
# 			WHERE key1 = 1 OR key2 = 2 OR key3 = 3;
#
# 		SELECT * FROM innodb_table
# 			WHERE (key1 = 1 AND key2 = 2)
# 				OR (key3 = 'foo' AND key4 = 'bar') AND key5 = 5;
#
# INDEX MERGE SORT-UNION ACCESS ALGORITHM
#
# This access algorithm is applicable when the WHERE Clause is converted to several range conditions
# combined by OR, but the Index Merge union algorithm is not applicable.
#
# Example:
#
# 		SELECT * FROM tbl_name
# 			WHERE key_col1 < 10 OR key_col2 < 20;
#
# 		SELECT * FROM tbl_name
# 			WHERE (key_col1 > 10 OR key_col2 = 20) AND nonkey_col = 30;
#
# The difference between the sort-union algorithm and the union algorithm is that the sort-algorithm must first
# fetch row IDs for all rows and sort them before returning any rows.
#
# INFLUENCING INDEX MERGE OPTIMIZATION
#
# Use of Index Merge is subject to the value of the index_merge, index_merge_intersection,
# index_merge_union, and index_merge_sort_union flags of the optimizer_switch system variable.
#
# More on this later.
#
# By default, all those flags are on.
#
# To enable only certain algorithms, set index_merge to off, and enable only such of the others as should be permitted.
#
# In addition to using the optimizer_switch system variable to control optimizer use of the Index Merge algorithm
# session-wide, MySQL supports optimizer hints to influence the optimizer on a per-statement basis.
#
# See more under Optimizer Hints sections.
#
# ENGINE CONDITION PUSHDOWN OPTIMIZATION
#
# This optimization improves the efficiency of direct comparisons between a nonindexed column and a constant.
# In such cases, the condition is "pushed down" to the storage engine for evaluation.
#
# This optimization can be used only by the NDB storage engine.
#
# NOTE:
#
# 		The NDB storage engine is currently not available in MySQL 8.0.
#
# 		If you are interested in using NDB cluster, see MySQL NDB Cluster 7.5 and NDB cluster
# 		7.6, which provides information about MySQL cluster NDB 7.5 (based on MySQL 5.7, but containing
# 		the latest improvements and fixes for the NDBCLUSTER storage engine)
#
# INDEX CONDITION PUSHDOWN OPTIMIZATION
#
# Index Condition Pushdown (ICP) is an optimization for the case where MySQL retrieves rows from a table using an index.
#
# Without ICR, the storage engine traverses the index to locate rows in teh base table and returns them to the MySQL
# server which evaluates the WHERE condition for the rows.
#
# WIth ICP enabled, and if parts of the WHERE condition can be evaluated by using only columns from the index,
# teh MySQL server pushes this part of the WHERE condition down to the storage engine.
#
# The storage engine then evaluates the pushed index condition by using the index entry and only if this is satisfied,
#  is the row read from the table.
#
# ICP can reduce the number of times the storage engine must access the base table and the number of times the
# MySQL server must access the storage engine.
#
# Applicability of the Index Condition Pushdown optimization is subject to these conditions:
#
# ) ICP is used for the range, ref, eq_ref, and ref_or_null access methods, when there is a need to access full table rows.
#
# ) ICP can be used for InnoDB and MyISAM tables, including partitioned InnoDB and MyISAM tables.
#
# ) For InnoDB tables, ICP is used only for secondary indexes.
#
# 		The goal of ICP is to reduce the number of full-row reads and thereby reduce number of I/O operations.
#
# 		For InnoDB clustered indexes, the complete record is already read into the InnoDB buffer.
#
# 		Using ICp in this case does not reduce the I/O.
#
# ) ICP is not supported with secondary indexes created on virtual generated columns. InnoDB supports secondary indexes
# 		on virtual generated columns.
#
# ) Conditions that refer to subqueries cannot be pushed down
#
# ) COndition taht refer to stored functions cannot be pushed down. Storage engines cannot invoke stored functions.
#
# ) Triggered conditions cannot be pushed down. (For information about triggered conditions, see Optimizing Subqueries with the EXISTS Strategy)
#
# To understand how this optimization works, first consider how an index scan proceeds when Index Condition Pushdown is not used:
#
#  	1. Get hte next row, first by reading the index tuple and then by using the index tuple to locate and read the full table row.
#
# 		2. Test the part of the WHERE condition that applies to this table. Accept or Reject the row based on the test result.
#
# Using Index Condition Pushdown, the scan proceeds like this insteaqd:
#
# 		1. Get hte next row's index tuple (but not the full table row)
#
# 		2. Test the part of the WHERE condition that applies to this table and can be checked using only indexed columns.
# 			If the condition is not satisfied, proceed to the index tuple for the next row.
#
# 		3. If the condition is satisfied, use the index tuple to locate and read the full table row.
#
# 		4. Test the remaining part of the WHERE condition that applies to this table. Accept or reject the row based on teh test result.
#
# EXPLAIN output shows Using index condition in teh Extra column when Index Condition Pushdown is used.
# It does not show Using Index because that does not apply when the full table rows must be read.
#
# Suppose that a table contains information about people and their addresses and that the table has an index defined as INDEX
# (zipcode, lastname, firstname).
#
# If we know a person's zipcode value but are not sure about the last name, we can search like this:
#
# 		SELECT * FROM people
# 			WHERE zipcode='95054'
# 			AND lastname LIKE '%etrunia%'
# 			AND address LIKE '%Main Street%';
#
# MySQL cna use the index to scan through people with zipcode='9504'
#
# THe second part (lastname lIKE '%etrunia%') cannot be used to limit the number of rows that must be scanned,
# so without Index Condition Pushdown, this query must retrieve full table rows for all people who have zipcode '95054'
#
# With Index Condition Pushdown, MySQL checks the lastname LIKE '%etrunia%' part before reading the full table row.
# This avoids reading full rows corresponding to index tuples that match the zipcode condition but not the lastname condition.
#
# Index Condition Pushdown is enabled by default. It can be controlled with the optimizer_switch system variable by setting the
# index_condition_pushdown flag:
#
# 		SET optimizer_switch = 'index_condition_pushdown=off';
# 		SET optimizer_siwtch = 'index_condition_pushdown=on';
#
# See later in Switchable Optimizations for more.
#
# NESTED-LOOP JOIN ALGORITHMS
#
# MySQL executes joins between tables using a nested-loop algorithm or variations on it.
#
# NESTED-LOOP JOIN ALGORITHM
#
# A simple nested-loop join (NLJ) algorithm reads rows from the first table in a loop one at a time,
# passing each row to a nested loop that processes teh next table in the join.
#
# This process is repeated as many times as there remains tables to be joined.
#
# Assume that a join between three tables t1, t2 and t3 is to be executed using the following join types:
#
# 	Table 	JOin Type
# 	t1 		range
# 	t2 		ref
# 	t3 		ALL
#
# If a simple NLJ algorithm is used, the join is processed like this:
#
# for each row in t1 matching range {
# 		for each row in t2 matching reference key {
# 			for each row in t3 {
# 				if row satisfies join conditions, send to client
# 			}
# 		}
# }
#
# Because the NLJ Algorithm passes rows one at a time from outer loops to inner loops, it typically reads
# tables processed in the inner loops many times.
#
# Block Nested-Loop Join Algorithm
#
# A Block Nested-Loop (BNL) join algorithm uses buffering of rows read in outer loops to reduce the number of 
# times that tables in inner loops must be read.
#
# For example, if 10 rows are read into a buffer and teh buffer is passed to the next inner loop,.
# each row read in teh inner loop can be compared against 10 rows in the buffer.
#
# This reduces by an order of magnitude the number of times the inner table must be read.
#
# MySQL join buffering has these characteristics:
#
# 		) Join buffering can be used when the join is of type ALL or index (in other words, when no possible keys can be used, and a full scan
# 			is done, of either the data or index rows, respectively), or range.
#
# 			Use of buffering is also applicable to outer joins, as described in BLOCK NESTED_LOOP AND BATCHED KEY ACCESS JOINS
#
# 		) A join buffer is never allocated for the first nonconstant table, even if it would be of type ALL or index.
#
# 		) Only columns of interest to a join are stored in its join buffer, not whole rows.
#
# 		) The join_buffer_size system variable determines the size of each join buffer used to process a query.
#
# 		) One buffer is allocated for each join that can be buffered, so a given query might be processed using multiple join buffers.
#
# 		) A join buffer is allocated prior to executing the join and freed after the query is done.
#
# For the example join described previously for the NLJ algorithm (without buffering), the join is done as follows using join buffering:
#
# 		for each row in t1 matching range {
# 			for each row in t2 matching reference key {
# 				store used columns from t1, t2 in join buffer
# 				if buffer is full {
# 					for each row in t3 {
# 						for each t1, t2 combination in join buffer {
# 							if row satisfies join conditions, send to client
# 						}
# 					}
# 					empty join buffer
# 				}
# 			}
# 		}
# 		
# 		if buffer is not empty {
# 			for each row in t3 {
# 				for each t1, t2 combination in join buffer {
# 					if row satisfies join conditions, send to client
# 				}
# 			}
# 		}
#
# If S is the size of each stored t1, t2 combination in the join buffer and C is the number of combinations in teh buffer,
# the number of times table t3 is scanned is:
#
# 	(S * C)/join_buffer_size + 1
#
# The number of t3 scans decereases  as the value of join_buffer_size increases, up to the point when join_buffer_size
# is large enough to hold all previous row combinations.
#
# At that point, no speed is gained by making it larger.
#
# NESTED JOIN OPTIMIZATION
#
# The syntax for expressing joins permits nested joins. The following discussion refers to joins syntax described later.
#
# The syntax of table_factor is extended in comparison with the SQL standard.
# The latter accepts only table_reference, not a list of them inside a pair of paranthesis.
#
# This is a conservative extension if we consider each comma in a list of table_referneces items as equivalent
# to an inner join.
#
# For example:
#
# 		SELECT * FROM t1 LEFT JOIN (t2, t3, t4)
# 								ON (t2.a=t1.a AND t3.b=t1.b AND t4.c=t1.c)
#
# is equvialent to:
#
# 		SELECT * FROM t1 LEFT JOIN (t2 CROSS JOIN t3 CROSS JOIN t4)
# 								ON (t2.a=t1.a AND t3.b=t1.b AND t4.c=t1.c)
#
# In MySQL, CROSS JOIN is syntatically equivalen to INNER JOIN, they can replace each other.
#
# In stnadard SQL, they are not equivalent, INNER JOIN is used with an ON clause; CROSS JOIN is used otherwise.
#
# In general, parathenses can be ignored in join expressions containing only inner join operations.
# Consider this join expression:
#
# t1 LEFT JOIN (t2 LEFT JOIN t3 ON t2.b=t3.b OR t2.b IS NULL) ON t1.a=t2.a
#
# After removing parathenses and grouping operations to the left, that join expression transforms
# into this expression:
#
# (t1 LEFT JOIN t2 ON t1.a=t2.a) LEFT JOIN t3 ON t2.b=t3.b OR t2.b IS NULL
#
# Yet, the two expressions are not equivalent. To see this, suppose that the tables t1, t2, and t3 have the
# following state:
#
# 		) Table t1 contains rows (1), (2)
#
# 		) Table t2 contains row (1, 101)
# 		
# 		) Table t3 contains row (101)
#
# In this case, teh first expression returns a result set including the rows (1, 1, 101, 101), (2, NULL, NULL, NULL), whereas the
# second expression returns the rows (1, 1, 101, 101), (2,NULL,NULL,101):
#
# SELECT FROM t1 LEFT JOIN (t2 LEFT JOIN t3 on t2.b=t3.b OR t2.b IS NULL) ON t1.a=t2.a;
# +-------------------------------+
# | a 		| 	a 		| 	b	| b 	 |
# +-------------------------------+
# | 		1  | 		1 	| 101 | 101  |
# | 		2 	| 	NULL 	| NULL| 101  |
# +-------------------------------+
#
# In the following example, an outer join operation is used together with an inner join operation:
#
# t1 LEFT JOIN (t2, t3) ON t1.a=t2.a
#
# That expression cannot be transformed into the following:
#
# t1 LEFT JOIN t2 ON t1.a=t2.a, t3
#
# FOr the given table states, the two expressions return different sets of rows:
#
# SELECT * FROM t1 LEFT JOIN (t2, t3) ON t1.a=t2.a;
# +-----------------------------------------------+
# | 	a 		| 		a 		| 		b 			|		b    |
# +-----------------------------------------------+
# | 	1 		| 		1 		| 	101 			| 101 	  |
# |	2 		| 		NULL 	| 	NULL 			| NULL 	  |
# +-----------------------------------------------+
#
# SELECT * FROM t1 LEFT JOIN t2 ON t1.a=t2.a, t3;
# +-----------------------------------------+
# | a 		| a 			| 		b 		| 		b |
# +-----------------------------------------+
# | 1 		| 1 			| 101 		| 101   |
# | 2 		| NULL 		| NULL 		| 101   |
# +-----------------------------------------+
#
# Therefore, If we omit parantheses in a join expression with outer join expressions, we might change the result set
# for the original expression.
#
# More exactly, we cannot ignore parantheses in the right operand of the left outer join operation and in teh left operand
# of a right join operation.
#
# IN other words, we cannot ignore parantheses for the inner table expressions of outer join operations.
# Parantheses for the other operand (operand for the outer table) can be ignored.
#
# The following Expression:
#
# (t1,t2) LEFT JOIN t3 ON P(t2.b,t3.b)
#
# Is equivalent to this expression for any tables t1,t2,t3 and any condition P over attributes t2.b and t3.b:
#
# t1, t2 LEFT JOIN t3 ON P(t2.b, t3.b)
#
# WHenevr the order of execution of join operations in a join expression (join_table) is not from left to right,
# we talk about nested joins. 
#
# Consider the following queries:
#
#  SELECT * FROM t1 LEFT JOIN (t2 LEFT JOIN t3 ON t2.b=t3.b) ON t1.a=t2.a WHERE t1.a > 1
#
# 	SELECT * FROM t1 LEFT JOIN (t2, t3) ON t1.a=t2.a WHERE (t2.b=t3.b OR t2.b IS NULL) AND t1.a > 1
#
# Those queries are considered to contain these nested joins:
#
# t2 LEFT JOIN t3 ON t2.b=t3.b
# t2, t3
#
# In the first query, the nested join is formed with a left join operation. In teh second query, it is formed with an inner join operation.
#
# In the first query, the parentheses can be omitted: The grammatical structure of the join expression will dictate the same order
# of execution for join operations.
#
# For the second query, the parentheses cannot be omitted, although the join expression here can be interpreted unambigiously without them.
#
# In our extended syntax, the parentheses in (t2, t3) of the second query are required, although theoretically the query could
# be parsed without them:
#
# We still would have unambiguous syntactical structure for the query because LEFT JOIN and ON play the role of the left
# and right delimiters for the expression (t2, t3).
#
# The preceding examples demonstrate these points:
#
# 	) For join expressions involving only inner joins (and not outer joins), parantheses can be removed and joins evaluated left to right.
# 		In fact, tables can be evaluated in any order.
#
# 	) The same is not true, in general, for outer joins or for outer joins mixed with inner joins. Removal of parentheses may change the result.
#
# Queries with nested outer joins are executed in the same pipeline manner as queries with inner joins.
#
# More exactly, a variation of the nested-loop join algorithm is exploited.
#
# Recall the algorithm by which the nested-loop join executes a query (see more earlier)
#
# Suppose that a join query over 3 tables T1, T2, T3 has this form:
#
# SELECT * FROM T1 INNER JOIN T2 ON P1(T1,T2)
# 						 INNER JOIN T3 ON P2(T2,T3)
# 	 WHERE P(T1,T2,T3)
#
# Here, P1(T1,T2) and P2(T3,T3) are some join conditions (on expressions), whereas P(T1,T2,T3) is a condition
# over columns of tables T1,T2,T3.
#
# The nested-loop join algorithm would execute this query in the following manner.
#
# FOR EACH row t1 in T1 {
# 		FOR EACH row t2 in T2 such that P1(t1,t2) {
# 			FOR EACH row t3 in T3 such that P2(t2,t3) {
# 				IF P(t1,t2,t3) {
# 					t:=t1||t2||t3; OUTPUT t;
# 				}
# 			}
# 		}
# 	}
#
# The notation t1||t2||t3 indicates a row constructed by concatenating the columns of rows t1, t2 and t3.
# In some of the following examples, NULL where a table name appears means a row in which NULL is used for each column
# of that table.
#
# For example, t1||t2||NULL indicates a row constructed by concatenating the columns of rows t1 and t2,
# and NULL for each column of t3. Such a row is said to be NULL-complemented.
#
# Now consider a query with nested outer joins:
#
# 	SELECT * FROM T1 LEFT JOIN
# 						(T2 LEFT JOIN T3 ON P2(T2,T3))
# 						ON P1(T1,T2)
# 	 	WHERE P(T1,T2,T3)
#
# For this query, modify the nested-loop pattern to obtain:
#
# 	FOR each row t1 in T1 {
# 		BOOL f1:=FALSE;
# 		FOR each row t2 in T2 such that P1(t1,t2) {
# 			BOOL f2:=FALSE;
# 			FOR each row t3 in T3 such that P2(t2,t3) {
# 				IF P(t1,t2,t3) {
# 					t:=t1||t2||t3; OUTPUT t;
# 				}
# 				f2=TRUE;
# 				f1=TRUE;
# 			}
# 			IF (!f2) {
# 				IF P(t1,t2,NULL) {
# 					t:=t1||t2||NULL; OUTPUT t;
# 				}
# 				f1=TRUE;
# 			}
# 		}
# 		IF (!f1) {
# 			IF P(t1,NULL,NULL) {
# 				t:=t1||NULL||NULL; OUTPUT t;
# 			}
# 		}
# 	}
#
# In general, for any nested loop for the first inner table in an outer join operation, a flag is introduced that is turned off
# before the loop and is checked after the loop.
#
# The flag, is turned on when for the current row from the outer table a match from the table representing the inner operand
# is found.
#
# If at the end of the loop cycle the flag is still off, no match has been found for the current row of the outer table.
#
# IN this case, the row is complemented by NULL values for the columns of the inner tables.
#
# The result row is passed to the final check for the output or into the next nested loop, but only if the row satisfies the join
# condition of all embedded outer joins.
#
# In the example, the outer join table expressed by the following expression is embedded:
#
# 		(T2 LEFT JOIN T3 ON P2(T2,T3))
#
# For the query with inner joins, the optimizer could choose a different order of nested loops, such as this one:
#
# 		FOR each row t3 in T3 {
# 			FOR each row t2 in T2 such that P2(t2,t3) {
# 				FOR each row t1 in T1 such that P1(t1,t2) {
# 					IF P(t1,t2,t3) {
# 						t:=t1||t2||t3; OUTPUT t;
# 					}
# 				}
# 			}
# 		}
#
# For queries with outer joins, the optimizer can choose only such an order where loops for outer tables precede
# loops for inner tables.
#
# Thus, for our query with outer joins, only one nesting order is possible.
#
# For the following query, the optimizer evaluates two different nestings.
# In both nestings, T1 must be processed in the outer loop because it is used in an outer join.
#
# T2 and T3 are used in an inner join, so that join must be processed in the inner loop.
# However, because the join is an inner join, T2 and T3 can be processed in either order.
#
# SELECT * T1 LEFT JOIN (T2,T3) ON P1(T1,T2) AND P2(T1,T3)
# 		WHERE P(T1,T2,T3)
#
# One nesting evluates T2, then T3:
#
# 		FOR each row t1 in T1 {
# 			BOOL f1:=FALSE;
# 			FOR each row t2 in T2 such that P1(t1,t2) {
# 				FOR each row t3 in T3 such that P2(t1,t3) {
# 					IF P(t1,t2,t3) {
# 						t:=t1||t2||t3; OUTPUT t;
# 					}
# 					f1:=TRUE
# 				}
# 			}
# 			IF (!f1) {
# 				IF P(t1,NULL,NULL) {
# 					t:=t1||NULL||NULL; OUTPUT t;
# 				}
# 			}
# 		}
#
# The other nesting evaluates T3, then T2:
#
# 		FOR each row t1 in T1 {
# 			BOOL f1:=FALSE;
# 			FOR each row t3 in T3 such that P2(t1,t3) {
# 				FOR each row t2 in T2 such that P1(t1,t2) {
# 					IF P(t1,t2,t3) {
# 						t:=t1||t2||t3; OUTPUT t;
# 					}
# 					f1:=TRUE
# 				}
# 			}
# 			IF (!f1) {
# 				IF P(t1,NULL,NULL) {
# 					t:=t1||NULL||NULL; OUTPUT t;
# 				}
# 			}
# 		}
#
# When discussing the nested-loop algorithm for inner joins, we omitted some details whose impact
# on the performance of query execution may be huge.
#
# We did not mentioned so-called "Pushed down" conditions. Suppose that our WHERE condition P(T1,T2,T3) can be
# represented by a conjunctive formula:
#
# P(T1,T2,T2) = C1(T1) AND C2(T2) AND C3(T3)
#
# In this case, MySQl actually uses the following nested-loop algorithm for the execution of the query
# with inner joins:
#
# 		FOR each row t1 in T1 such that C1(t1) {
# 			FOR each row t2 in T2 such that P1(t1,t2) AND C2(t2) {
# 				FOR each row t3 in T3 such that P2(t2,t3) AND C3(t3) {
# 					IF P(t1,t2,t3) {
# 						t:=t1||t2||t3; OUTPUT t;
# 					}
# 				}
# 			}
# 		}
#
# You see that each of the conjuncts C1(T1), C2(T2), C3(T3) are pushed out for the most inner loop to the
# most outer loop where it can be evaluated.
#
# If C1(T1) is a very restrictive condition, this condition pushdown may greatly reduce te number of rows
# from table T1 passed to the inner loops.
#
# As a result, the execution time for the query may improve immensely.
#
# For a query with outer joins, the WHERE condition is to be checked only after it has been found that the
# current row from the outer table has a match in the inner tables.
#
# Thus, the optimization of pushing conditions out of the inner nested loops cannot be applied directly
# to queries with outer joins.
#
# Here we must introduce conditional pushed-down predicates guarded by the flags that are turned on
# when a match has been encountered.
#
# Recall this example with outer joins:
#
# 		P(T1,T2,T3)=C1(T1) AND C(T2) AND C3(T3)
#
# For that example, the nested-loop algorithm using guarded pushed-down conditions looks like this:
#
# 		FOR each row t1 in T1 such that C1(t1) {
# 			BOOL f1:=FALSE;
# 			FOR each row t2 in T2
# 					such that P1(t1,t2) AND (f1?C2(t2):TRUE) {
# 				BOOL f2:=FALSE;
# 				FOR each row t3 in T3
# 						such that P2(t2,t3) AND (f1&&f2?C3(t3):TRUE) {
# 					IF (f1&&f2?TRUE:(C2(t2) AND C3(t3))) {
# 						t:=t1||t2||t3; OUTPUT t;
# 					}
# 					f2=TRUE;
# 					f1=TRUE;
# 				}
# 				IF (!f2) {
# 					IF (f1?TRUE:C2(t2) && P(t1,t2,NULL)) {
# 						t:=t1||t2||NULL; OUTPUT t;
# 					}
# 					f1=TRUE;
# 				}
# 			}
# 			IF (!f1 && P(t1, NULL, NULL)) {
# 				t:=t1||NULL||NULL; OUTPUT t;
# 			}
# 		}
#
# In general, pushed-down predicates can be extracted from join conditions such as P1(T1,T2) and P(T2,T3).
#
# In this case, a pushed-down predicate is guarded also by a flag that prevents checking the predicate
# for the NULL-complemented row generated by the corresponding outer join operation.
#
# Access by key from one inner table to another in the same nested join is prohibited if it is induced
# by a predicate from the WHERE condition.
#
# OUTER JOIN OPTIMIZATION
#
# Outer joins include LEFT JOIN and RIGHT JOIN
#
# MySQL implements an A LEFT JOIN B join_condition as follows:
#
# 		) Table B is set to depend on table A and all tables on which A depends
#
# 		) Table A is set to depend on all tables (except B) that are used in the LEFT JOIN condition.
#
# 		) The LEFT JOIN condition is used to decide how to retrieve rows from table B (In other words, any condition in the WHERE clause is not used)
#
# 		) All standard join optimizations are performed, with the exception that a table is always read after all tables on which it depends.
# 			If there is a circular dependency, an error occurs.
#
# 		) All standard WHERE optimizations are performed.
#
# 		) If there is a row in A that matches the WHERE clause, but there is no row in B that matches the ON condition, an extra B row is generated
# 			with all columns set to NULL.
#
# 		) If you use LEFT JOIN to find rows that do not exist in some table and you have the following test: col_name is NULL in the WHERE part,
# 			where col_name is a column that is declared as NOT NULL, MySQL stops searching for more rows (for a particular key combination) after
# 			it has found one row that matches the LEFT JOIN condition.
#
# The RIGHT JOIN implementation is analogous to that of LEFT JOIN with the table roles reversed.
# Right joins are converted to equivalent left joins, as described later.
#
# For a LEFT JOIN, if the WHERE condition is always false for the generated NULL row, the LEFT JOIN is changed to an inner join.
# For example, the WHERE clause would be false in the following query if t2.column1 were NULL:
#
# 		SELECT * FROM t1 LEFT JOIN t2 ON (column1) WHERE t2.column2=5;
#
# Therefore, it is safe to convert the query to an inner join:
#
# 		SELECT * FROM t1, t2 WHERE t2.column2=5 AND t1.column1=t2.column1;
#
# Now the optimizer can use table t2 before table t1 if doing so would result in a better query plan.
# To provide a hint about the table join order, use optimizer hints; see later.
#
# Alternatively, use STRAIGHT_JOIN; see later.
#
# However, STRAIGHT_JOIN may prevent indexes from being used because it disables semi-join transformations.
# See later.
#
# OUTER JOIN SIMPLIFICATION
#
# Table expressions in the FROM clause of a query are simplified in many cases.
#
# At the parser stage, queries with right outer join operations are converted to equivalent queries containing
# only left join operations.
#
# In the general case, the conversion is performed such that this right join:
#
# 		(T1, ---) RIGHT JOIN (T2, ---) ON P(T1, ---, T2, ---)
#
# Becomes this equivalent left join:
#
# 		(T2, ---) LEFT JOIN (T1, ---) ON P(T1, ---, T2, ---)
#
# ALl inner join expressions of the form T1 INNER JOIN T2 ON P(T1,T2) are replaced by the list
# T1,T2,P(T1,T2) being joined as a conjunct to the WHERE condition (or to the join condition of the embedding join, if there is any)
#
# When the optimizer evaluates plans for outer join operations, it takes into consideration only plans where,
# for each such operation, the outer tables are accessed before the inner tables.
#
# The optimizer choices are limited because only such plans enable outer joins to be executed using the nested-loop algorithm.
#
# Consider a query of this form, where R(T2) greatly narrows the number of matching rows from table t2:
#
# 		SELECT * T1 LEFT JOIN T2 ON P1(T1,T2)
# 			WHERE P(T1,T2) AND R(T2)
#
# If the query is executed as written, the optimizer has no choice but to access the less-restricted table T1
# before the more-restricted table T2, which may produce a very inefficient execution plan.
#
# Instead, MySQL converts the query to a query with no outer join operation if the WHERE condition is 
# null-rejected.
#
# (That is, it converts the outer join to an inner join)
#
# A condition is said to be null-rejected for an outer join operation if it evaluates to FALSE
# or UNKNOWN for any NULL-complemented row generated for the operation.
#
# Thus, for this outer join:
#
# 		T1 LEFT JOIN T2 ON T1.A=T2.A
#
# Conditions such as these are null-rejected because they cannot be true for any NULL-complemented row
# (with T2 columns set to NULL):
#
# 		T2.B IS NOT NULL
# 		T2.B > 3
# 		T2.C <= T1.C
# 		T2.B < 2 OR T2.C > 1
#
# Conditions such as these are not null-rejected because they might be true for a NULL-complemented row:
#
# 		T2.B IS NULL
# 		T1.B < 3 OR T2.B IS NOT NULL
# 		T1.B < 3 OR T2.B > 3
#
# The general rules for checking whether a condition is null-rejected for an outer join operation are simple:
#
# 	) It is of the form A IS NOT NULL, where A is an attribute of any of the inner tables
#
# 	) It is a predicate containing a reference to an inner table that evaluates to UNKNOWN when one of its arguments
# 		is NULL
#
# 	) It is a conjunction a null-rejected condition as a conjunct
#
# 	) It is a disjunction of null-rejected conditions
#
# A condition can be null-rejected for one outer join operation in a query and not null-rejected for another.
#
# In this query,the WHERE condition is null-rejected for the second outer join operation but is not null-rejected
# for the first one:
#
# 		SELECT * FROM T1 LEFT JOIN T2 ON T2.A=T1.A
# 							  LEFT JOIN T3 ON T3.B=T1.B
# 			WHERE T3.C > 0
#
# If the WHERE condition is null-rejected for an outer join operation in a query, the outer join operation is replaced
# by an inner join operation.
#
# For example, in the preceding query, the second outer join is null-rejected and can be replaced by an inner join:
#
# 		SELECT * FROM T1 LEFT JOIN T2 ON T2.A=T1.A
# 								INNER JOIN T3 ON T3.B=T1.B
# 			WHERE T3.C > 0
#
# For the original query, the optimizer evaluates only plans compatible with the single table-access order
# T1,T2,T3.
#
# For the rewritten query, it aditionally considers the access order T3,T1,T2
#
# A conversion of one outer join operation may trigger a conversion of another. Thus, the query:
#
# 		SELECT * FROM T1 LEFT JOIN T2 ON T2.A=T1.A
# 							  LEFT JOIN T3 ON T3.B=T2.B
# 			WHERE T3.C > 0
#
# Is first converted to the query:
#
# 		SELECT * FROM T1 LEFT JOIN T2 ON T2.A=T1.A
# 								INNER JOIN T3 ON T3.B=T2.B
# 			WHERE T3.C > 0
#
# Which is equivalent to the query:
#
# 		SELECT * FROM (T1 LEFT JOIN T2 ON T2.A=T1.A), T3
# 			WHERE T3.C > 0 AND T3.B=T2.B
#
# The remaining outer join operation can also be replaced by an inner join because
# the condition T3.B=T2.B is null-rejected.
#
# This results in a query with no outer joins at all:
#
# 		SELECT * FROM (T1 INNER JOIN T2 ON T2.A=T1.A), T3
# 			WHERE T3.C > 0 AND T3.B=T2.B
#
# Sometimes the optimizer succeeds in replacing an embedded outer join operation, but cannot
# convert the embedding outer join.
#
# The following query:
#
# 		SELECT * FROM T1 LEFT JOIN
# 							(T2 LEFT JOIN T3 ON T3.B=T2.B)
# 							ON T2.A=T1.A
# 			WHERE T3.C > 0
#
# Is converted to:
#
# 		SELECT * FROM T1 LEFT JOIN
# 							(T2 INNER JOIN T3 ON T3.B=T2.B)
# 							ON T2.A=T1.A
# 			WHERE T3.C > 0
#
# That can be rewritten only to the form still containing the embedding outer join operation:
#
# 		SELECT * FROM T1 LEFT JOIN
# 							(T2,T3)
# 							ON (T2.A=T1.A AND T3.B=T2.B)
# 			WHERE T3.C > 0
#
# Any attempt to convert an embedded outer join operation in a query must take into account the
# join condition for the embedding outer join together with the WHERE condition.
#
# In this query, the WHERE condition is not null-rejected for the embedded outer join,
# but the join condition of the embedding outer join T2.A=T1.A AND T3.C=T1.C is null-rejected:
#
# 		SELECT * FROM T1 LEFT JOIN
# 							(T2 LEFT JOIN T3 ON T3.B=T2.B)
# 							ON T2.A=T1.A AND T3.C=T1.C
# 			WHERE T3.D > 0 OR T1.D > 0
#
# Consequently, the query can be converted to:
#
# 		SELECT * FROM T1 LEFT JOIN
# 								(T2,T3)
# 								ON T2.A=T1.A AND T3.C=T1.C AND T3.B=T2.B
# 			WHERE T3.D > 0 OR T1.D > 0
#
# MULTI-RANGE READ OPTIMIZATION
#
# Reading rows using a range scan on a secondary index can result in many random disk accesses to the
# base table when the table is large and not stored in the storage engine's cache.
#
# With the Disk-Sweep Multi-Range Read (MRR) optimization, MySQL tries to reduce the number
# of random disk access for range scans by first scanning the index only and collecting the keys for the
# relevant rows.
#
# Then the keys are sorted and finally the rows are retrieved from the base table using the order
# of the primary key.
#
# The motivation for Disk-sweep MRR is to reduce the number of random disk accesses and instead achieve
# a more sequential scan of the base table data.
#
# The Multi-Range Read optimization provides these benefits:
#
# 		) MRR enables data rows to be accessed sequentially rather than in random order, based on index tuples.
#
# 			The server obtains a set of index tuples that satisfy the query conditions, sorts them according
# 			to data row ID order, and uses the sorted tuples to retrieve data rows in order.
#
# 			This makes data access more efficient and less expensive.
#
# 		) MRR enables batch processing of requests for key access for operations that require access to data rows
# 			through index tuples, such as range index scans and equi-joins that use an index for the join attribute.
#
# 			MRR iterates over a sequence of index ranges to obtain qualifying index tuples.
#
# 			As these results accumulate, they are used to access the corresponding data rows.
# 			It is not necessary to acquire all index tuples before starting to read data rows.
#
# THe MRR optimization is not supported with secondary indexes created on virtual generated columns.
# InnoDB supports secondary indexes on virtual generated columns.
#
# The following scenarios illustrate when MRR optimization can be advantageous:
#
# SCENARIO A: MRR can be used for InnoDB and MyISAM tables for index range scans and equi-join operations.
#
# 		1. A portion of the index tuples are accumulated in a buffer.
#
# 		2. The tuples in the buffer are sorted by their data row ID.
#
# 		3. Data rows are accessed according to the sorted index tuple sequence.
#
# SCENARIO B: MRR can be used for NDB tables for multiple-range index scans or when performing
# 					an equi-join by an attribute.
#
# 		1. A portion of ranges, possibly single-key ranges, is accumulated in a buffer on the central node where
# 				the query is submitted.
#
# 		2. The ranges are sent to the execution nodes that access data rows.
#
# 		3. The accessed rows are packed into packages and sent back to the central node.
#
# 		4. The received packages with data rows are placed in a buffer.
#
# 		5. Data rows are read from the buffer.
#
# When MRR is used, the Extra column in EXPLAIN output shows Using MRR.
#
# InnoDB and MyISAM do not use MRR if full table rows need not be accessed to produce the query result.
#
# This is the case if results can be produced entirely on the basis on information in the index tuples (through a covering index); 
# MRR provides no benefit.
#
# Two optimizer_switch system variable flags provide an interface to the use of MRR optimization.
# The mrr flag controls whether MRR is enabled.
#
# If mrr is enabled (on), the mrr_cost_based flag controls whether the optimizer attempts to make
# a cost-based choice between using and not using MRR (on) or uses MRR whenever possible (off).
#
# By default, mrr is on and mrr_cost_based is on. More later.
#
# For MRR, a storage engine uses the value of the read_rnd_buffer_size system variable as a guideline
# for how much memory it can allocate for its buffer.
#
# The engine uses up to read_rnd_buffer_size bytes and determines the number of ranges to process in a single pass.
#
# BLOCK NESTED-LOOP AND BATCHED KEY ACCESS JOINS
#
# In MySQL, a Batched Key Access (BKA) join algorithm is available that uses both index access to the joined
# table and a join buffer.
#
# The BKA algorithm supports inner join, outer join, and semi-join operations, including nested outer joins.
# Benefits of BKA include improved join performance due to more efficient table scanning.
#
# Also, the Block Nested-Loop (BNL) join algorithm previously used only for inner joins is extended
# and can be employed for outer join and semi-join operations, including nested outer joins.
#
# The following section discuss the join buffer management that underlies the extension of the original
# BNL algorithm, the extended BNL algorithm, and the BKA algorithm.
#
# For information about semi-join strategies, see later.
#
# JOIN BUFFER MANAGEMENT FOR BLOCK NESTED-LOOP AND BATCHED KEY ACCESS ALGORITHMS
#
# MySQL can employ join buffers to execute not only inner joins without index access to the
# inner table, but also outer joins and semi-joins that appear after subquery flattening.
#
# Moreover, a join buffer can be effectively used when there is an index access to the inner table.
#
# The join buffer management code slightly more effectively utilizes join buffer space when storing
# the values of the interesting row columns: No additional bytes are allocated in buffers for a row
# column if its value is NULL, and the minimum number of bytes is allocated for any value
# of the VARCHAR type.
#
# The code supports two types of buffers, regular and incremental.
#
# Suppose that join buffer B1 is employed to join tables t1 and t2 and the result
# of this operation is joined with table t3 using join buffer B2:
#
# 		) A regular join buffer contains columns from each join operand. If B2 is a regular join buffer,
# 			each row r put into B2 is composed of the columns of a row r1 from B1 and the interesting columns
# 			of a matching row r2 from table tb3.
#
# 		) An incremental join buffer contains only columns from rows of the table produced by the second join operand.
# 			That is, it is incremental to a row from the first operand buffer.
#
# 			If B2 is an incremental join buffer, it contains the interesting columns of the row r2 together with a link
# 			to the row r1 from B1.
#
# Incremental join buffers are always incremental relative to a join buffer from an earlier join operation,
# so the buffer from the first join operation is always a regular buffer.
#
# In the example just given, the buffer B1 used to join tables t1 and t2 must be a regular buffer.
#
# Each row of the incremental buffer used for a join operation contains only the interesting columns
# of a row from the table to be joined.
#
# These columns are augmented with a reference to the interesting columns of the matched row from the
# table produced by the first join operand.
#
# Several rows in the incremental buffer can refer to the same row r whose columns are stored in the
# previous join buffers insofar as all these rows match row r.
#
# Incremental buffers enable less frequent copying of columns from buffers used for previous join operations.
#
# This provides a savings in buffer space because in general case a row produced by the first join operand
# can be matched by several rows produced by the second join operand.
#
# It is unnesseary to make several copies of a row from the first operand.
#
# Incremental buffers also provide a savings in processing time due to the reduction in copying time.
#
# The block_nested_loop and batched_key_access flags of the optimizer_switch system variable control how
# the optimizer uses the Block Nested-Loop and Batched Key Access join algorithms.
#
# By default, block_nested_loop is on and batched_key_access is off.
#
# Optimizer hints may also be applied.
#
# More on this and Switchable Optimizations, later.
#
# For info about semi-join operations, more on that later.
#
# BLOCK NESTED-LOOP ALGORITHM FOR OUTER JOINS AND SEMI-JOINS
#
# The original implementation of the MySQL BNL algorithm is extended to support outer join and semi-join operations.
#
# When these operations are executed with a join buffer, each row put into the buffer is supplied with a match flag.
#
# If an outer join operation is executed using a join buffer, each row of the table produced by the second
# operand is checked for a match against each row in the join buffer.
#
# When a match is found, a new extended row is formed (the original row plus columns from the second operand)
# and sent for further extensions by the remaining join operations.
#
# In addition, the match flag of the matched row in the buffer is enabled.
#
# After all rows of the table to be joined have been examined, the join buffer is scanned.
#
# Each row from the buffer that does not have its match flag enabled is extended by NULL complements
# (NULL values for each column in the second operand) and sent for further extensions by the remaining
# join operations.
#
# The block_nested_loop flag of the optimizer_switch System variable controls how the optimizer uses the
# Block Nested-Loop algorithm. By default, block_nested_loop is on.
#
# More on this later, in tandem with Optimizer hints.
#
# In EXPLAIN output, use of BNL for a table is signified when the Extra value contains Using join buffer
# (Block Nested Loop) and the type value is ALL, index or range.
#
# For info about semi-join strats, more later.
#
# BATCHED KEY ACCESS JOINS
#
# MySQL implements a method of joining tables called the Batched Key Access (BKA) join algorithm.
# BKA can be applied when there is an index access to the table produced by the second
# join operand.
#
# Like the BNL join algorithm, the BKA join algorithm employs a join buffer to accumulate the interesting
# columns of the rows produced by the first operand of the join operation.
#
# Then the BKA algorithm builds keys to access the table to be joined for all rows in the buffer
# and submits these keys in a batch to the database engine for index lookups.
#
# The keys are submitted to the engine through the Multi-Range Read (MRR) interface.
#
# After submission of the keys, the MRR engine functions perform lookups in the index in an optimal
# way, fetching the rows of the joined table found by these keys and starts feeding the
# BKA join algorithm with matching rows.
#
# Each matching row is coupled with a reference to a row in the join buffer.
#
# When BKA is used, the value of join_buffer_size defines how large the batch of keys is in each request
# to the storage engine.
#
# The larger the buffer, the more sequential access will be to the right hand table of a join operation,
# which can significantly improve performance.
#
# For BKA to be used, the batched_key_access flag of the optimizer_switch system variable must be set to on.
# BKA uses MRR, so the mrr flag must also be on.
#
# Currently, the cost estimation for MRR is too pessimistic. Hence, it is also nessecary for mrr_cost_based
# to be off for BKA to be used.
#
# The following settings enable BKA:
#
# SET optimizer_switch='mrr=on,mrr_cost_based=off,batched_key_access=on';
#
# There are two scenarios by which MRR functions execute:
#
# 		) The first scenario is used for conventional disk-based storage engines such as InnoDB and MyISAM.
#
# 			For these engines, usually the keys for all rows from the join buffer are submitted to the MRR interface
# 			at once.
#
# 			Engine-specific MRR functions perform index lookups for the submitted keys, get row IDs (or pimary keys)
# 			from them, and then fetch rows for all these selected row IDs one by one by request from BKA algorithm.
#
# 			Every row is returned with an association reference that enables access to the matched row in the join buffer.
# 			The rows are fetched by the MRR functions in an optimal way:
#
# 			They are fetched in the row ID (primary key) order.
#
# 			This improves performance because reads are in disk order rather than random order.
#
# 		) The second scenario is used for remote storage engines such as NDB.
#
# 			A package of keys for a portion of rows from the join buffer, together with their
# 			associations, is sent by a MySQL Server (SQL node) to MySQL Cluster data nodes.
#
# 			IN return, the SQL nodes receive a package (or several packages) of matching rows
# 			coupled with corresponding associations.
#
# 			The BKA join algorithm takes these rows and builds new joined rows.
#
# 			Then a new set of keys is sent to the data nodes and the rows from the returned packages
# 			are used to build new joined rows.
#
# 			The process continues until the last keys from the join buffer are sent to the data nodes,
# 			and the SQL node has received and joined all rows matching these keys.
#
# 			This improves performance because fewer key-bearing packages sent by the SQL node to the
# 			data nodes means fewer round trips between it and the data nodes to perform the join operation.
#
# With the first scenario, a portion of the join buffer is reserved to store row IDs (primary keys) selected by
# index lookups and passed as a parameter to the MRR functions.
#
# There is no special buffer to store keys built for rows from the join buffer. Instead, a function that builds
# the key for the next row in the buffer is passed as a parameter to the MRR functions.
#
# In EXPLAIN output, use of BKA for a table is signified when the Extra value contains Using join buffer (Batched Key Access)
# and the type value is ref or eq_ref.
#
# OPTIMIZER HINTS FOR BLOCK NESTED-LOOP AND BATCHED KEY ACCESS ALGORITHMS
#
# In addition to using the optimizer_switch system variable to control optimizer use of the BNL and BKA 
# algorithms session-wide,, MySQL supports optimizer hints to influence the optimizer on a per-statement basis.
#
# More on this later.
#
# To use a BNL or BKA hint to enable join buffering for any inner table of an outer join, join buffering must be enabled
# for all inner tables of the outer join.
#
# CONDITION FILTERING
#
# In join processing, prefix rows are those rows passed from one table in a join to the next.
#
# In general, the optimizer attempts to put tables with low prefix counts early in the join order
# to keep the number of row combinations from increasing rapidly.
#
# To the extent that the optimizer can use information about conditions on rows selected from one table
# and passed to the next, the more accurately it can compute row estimates and choose the best execution plan.
#
# Without condition filtering, the prefix row count for a table is based on the estimated number of rows selected
# by the WHERE clause according to whichever access method the optimizer chooses.
#
# Condition filtering enables the optimizer to use other relevant conditions in the WHERE clause not taken into
# account by the access method, and thus improve its prefix row count estimates.
#
# For example, even though there might be an index-based access method that can be used to select rows from
# the current table in a join, there might also be additional conditions for the table in the WHERE clause that
# can filter (further restrict) the estimate for qualifying rows passed to the next table.
#
# A condition contributes to the filtering estimates only if:
#
# 		) It refers to the current table.
#
# 		) It depends on a constant value or values from earlier tables in the join sequence.
#
# 		) It was not already taken into account by the access method.
#
# In EXPLAIN output, the rows column indicates the row estimate for the chosen access method,
# and the filtered column reflects the effect of condition filtering.
#
# Filtered values are expressed as percentages. The max  value is 100, which means no filtering
# of rows occurred.
#
# Values decreasing from 100 indicate increasing amounts of filtering.
#
# The prefix row count (the number of rows estimated to be passed from the current table in a join
# to the enxt) is the product of the rows and filtered values.
#
# that is, the prefix row count is the estimated row count, reduced by the estimated filtering effect.
# For example, if rows is 1000 and filtered is 20%, condition filtering reduces the esitmated row count
# of 1000 to a prefix row count of 1000 * 20% (1000 * .2) = 200
# 
# Consider the following query:
#
# 		SELECT * 
# 				FROM employee JOIN department ON employee.dept_no = department.dept_no
# 				WHERE employee.first_name='John'
# 				AND employee.hire_date BETWEEN '2018-01-01' AND '2018-06-01';
#
# Suppose that the data set has these characteristics:
#
# 		) The employee table has 1024 rows.
#
# 		) The department table has 12 rows.
#
# 		) Both tables have an index of dept_no
#
# 		) The employee table has an index on first_name
#
# 		) 8 Rows satisfy this condition on employee.first_name:
#
# 			employee.first_name = 'John'
#
# 		) 150 rows satisfy this condition on employee.hire_date:
#
# 			employee.hire_date BETWEEN '2018-01-01' AND '2018-06-01'
#
# 		) 1 row satisfies both conditions:
#
# 			employee.first_name = 'John'
# 			AND employee.hire_date BETWEEN '2018-01-01' AND '2018-06-01'
#
# Without condition filtering, EXPLAIN produces output like this:
#
# 		+---+--------------------+---------------------+------------------------------+------------------+------------+------+------------------+
# 		|id | table 				 | type 					  | possible_keys 					| key 				 | ref 					| rows 	| filtered|
# 		+---------------------------------------------------------------------------------------------------------------------------------------+
# 		| 1 | employee 			 | ref 					  | name, h_date, dept 				| name 				 | const 				| 8 		| 100.00  |
# 		| 1 | department 			 | eq_ref 				  | PRIMARY 							| PRIMARY 			 | dept_no 				| 1 		| 100.00  |
# 		+---------------------------------------------------------------------------------------------------------------------------------------+
#
# For employee, teh access method on the name index picks up the 8 rows that match a name of 'John'.
#
# No filtering is done (filtered is 100%), so all rows are prefix rows for the next table:
# 		The prefix row count is rows x filtered = 8 x 100% = 8
#
# With condition filtering, the optimizer additionaly takes into account conditions from the WHERE clause not taken into account by the
# access method.
#
# In this case, the optimizer uses heuristics to estimate a filtering effect of 16.31% for the BETWEEN condition on 
# employee.hire_date 
#
# As a result, EXPLAIN produces output like this:
#
# 		+---+------------------+---------------------+----------------------------------+-----------------+------------------+---------+---------------+
# 		|id | table 			  | type 					| possible_keys 	   | key 		  | ref 				  | rows 				| filtered 					  |
# 		+---+------------------+---------------------+--------------------+-------------+-----------------+------------------+-------------------------+
# 		|1  | employee 		  | ref 						| name, h_date, dept	|	name 		  | const 			  | 8 					| 16.31 						  |
# 		|1  | department 		  | eq_ref 					| PRIMARY 			   | PRIMARY 	  | dept_no 		  | 1 					| 100.00 					  |
# 		+----------------------------------------------------------------------------------------------------------------------------------------------+
#
# Now the prefix row count is rows * filtered = 8 * 16.31 = 1.3, which more closely reflects the actual data set.
#
# Normally, the optimizer does not calcualate the condition filtering effect (prefix row count reduction) for the last joined table
# because there is no next table to pass rows to.
#
# An exception occurs for EXPLAIN: To provide more information, the filtering effect is calculated for all joined tables, including the last one.
#
# To control whether the optimizer considers additional filtering conditions, use the condition_fanout_filter flag of the optimizer_switch system
# variable (see later)
#
# This flag is enabled by default but can be disabled to suppress condition filtering (for example, if a particular query is found to yield better
# performance without it)
#
# If the optimizer overestimates the effect of condition filtering, performance may be worse than if condition filtering is not used.
# In such cases, these tehcniques help:
#
# 		) If a column is not indexed, index it so that the optimizer has some information about the distribution of column values and can improve its row estimates.
#
# 		) SImilarly, if no column histogram information is available, generate a histogram (see more later)
#
# 		) Change the join order. Ways to accomplish this includes join-order optimizer hints (see later), STRAIGHT_JOIN immediately following the
# 			SELECT, and the STRAIGHT_JOIN join operator.
#
# 		) Disable condition filtering for the session:
#
# 			SET optimizer_switch = 'condition_fanout_filter=off';
#
# 		Or, for a given query, using an optimizer hint:
#
# 			SELECT /*+ SET_VAR(optimizer_switch = 'condition_fanout_filter=off') */
#
# IS NULL OPTIMIZATION
#
# MySQL can perform the same optimization on col_name IS_NULL that it can use for col_name = constant_value.
# FOr example, MySQL can use indexes and ranges to search for NULL with IS_NULL.
#
# Examples:
#
# 		SELECT * FROM tbl_name WHERE key_col IS NULL;
#
# 		SELECT * FROM tbl_name WHERE key_col <=> NULL;
#
# 		SELECT * FROM tbl_name 
# 			WHERE key_col=const1 OR key_col=const2 OR key_col IS NULL;
#
# If a WHERE clause includes a col_name IS_NULL condition for a column that is declared as NOT NULL, that expression is optimized away.
#
# This optimization does not occur in cases where the column might produce NULL anyway; for example, if it comes from a table on
# the right side of a LEFT JOIN.
#
# MySQL can also optimize the combination col_name = expr OR col_name IS NULL, a form that is common in resolved subqueries.
#
# EXPLAIN shows ref_or_null when this optimization is used.
#
# THis optimization can handle one IS_NULL for any key part.
#
# Some examples of queries that are optimized, assuming that there is an index on columns a and b of table t2:
#
# 		SELECT * FROM t1 WHERE t1.a=expr OR t1.a IS NULL;
#
# 		SELECT * FROM t1, t2 WHERE t1.a=t2.a OR t2.a IS NULL;
#
# 		SELECT * FROM t1, t2
# 			WHERE (t1.a=t2.a OR t2.a IS NULL) AND t2.b=t1.b;
#
# 		SELECT * FROM t1, t2
# 			WHERE t1.a=t2.a AND (t2.b=t1.b OR t2.b IS NULL);
#
# 		SELECT * FROM t1, t2
# 			WHERE (t1.a=t2.a AND t2.a IS NULL AND ---)
# 			OR (t1.a=t2.a AND t2.a IS NULL AND ---);
#
# ref_or_null works by first doing a read on the reference key, and then a separate search for rows
# with a NULL key value.
#
# THe optimization can handle only one IS_NULL level.
#
# IN the following query, MYSQL uses key lookups only on the expression (t1.a=t2.a AND t2.a IS NULL) and is not
# able to use the key part on b:
#
# 		SELECT * FROM t1, t2
# 			WHERE (t1.a=t2.a AND t2.a IS NULL)
# 			OR (t1.b=t2.b AND t2.b IS NULL);
#
# ORDER BY OPTIMIZATION
#
# This section describes when MySQL can use an index to satisfy an ORDER BY clause, the filesort
# operation used when an index cannot be used and execution plan information available
# from the optimizer about ORDER BY.
#
# An ORDER BY with and without LIMIT may return rows in different orders, as discussed later.
#
# USE OF INDEXES TO SATISFY ORDER BY
#
# In some cases, MYSQL may use an index to satisfy an ORDER BY clause and avoid the extra sorting
# involved in performing a filesort operation.
#
# The index may also be used even if the ORDER BY does not match the index exactly,
# as long as all unused portions of the index and all extra ORDER BY columns are constants in
# the WHERE clause.
#
# If the index does not contain all columns accessed by the query, the index is used only if index access
# is cheaper than other access methods.
#
# Assuming that there is an index on (key_part1, key_part2), the following queries may use the index
# to resolve the ORDER BY part.
#
# Whether the optimizer actually does so depends on whether reading the index is more efficient than a table
# scan if columns not in the index must also be read.
#
# 		) In this query, teh index on (key_part1, key_part2) enables the optimizer to avoid sorting:
#
# 			SELECT * FROM t1
# 				ORDER BY key_part1, key_part2;
#
# 			However, the query uses SELECT *, which may select more columns than key_part1 and key_part2.
#
# 			In that case, scanning an entire index and looking up table rows to find columns not in the index
# 			may be more expensive than scanning the table and sorting the results.
#
# 			If so, the optimizer probably will not use the index.
#
# 			If SELECT * selects only the index columns, the index will be used and sorting avoided.
#
# 			If t1 is an InnoDB table, the table primary key is implicitly part of the index, and the index can be used to
# 			resolve the ORDER BY for this query:
#
# 				SELECT pk, key_part1, key_part2 FROM t1
# 					ORDER BY key_part1, key_part2;
#
# 		) In this query, key_part1 is constant, so all rows accessed through the index are in key_part2 order,
# 			and an index on (key_part1, key_part2) avoids sorting if the WHERE clause is selective enough
# 			to make an index range scan cheaper than a table scan:
#
# 			SELECT * FROM t1
# 				WHERE key_part1 = constant
# 				ORDER BY key_part2;
#
# 		) In the next two queries, whether the index is used similar to the same queries without DESC shown prev.:
#
# 			SELECT * FROM t1
# 				ORDER BY key_part1 DESC, key_part2 DESC;
#
# 			SELECT * FROM t1
# 				WHERE key_part1 = constant
# 				ORDER BY key_part2 DESC;
#
# 		) Two columns in an ORDER BY can sort in the same direction (both ASC or both DESC), or in opposite directions (one ASC, one DESC).
#
# 			A condition for index use is that the index must have the same homoegeneity, but need not have the same actual direction.
#
# 			If a query mixes ASC and DESC, the optimizer can use an index on the columns if the index also uses corresponding
# 			mixed ascending and descending columns:
#
# 				SELECT * FROM t1
# 					ORDER BY key_part1 DESC, key_part2 ASC;
#
# 			The optimizer can use an index on (key_part1, key_part2) if key_part1 is desc and key_part2 is asc.
# 			It can also use an index on those columns (with a backward scan) if key_part1 is asc and key_part2 is desc.
#
# 			More on this later.
#
# 		) In the next two queries, key_part1 is compared to a constant. The index will be used if the WHERE clause is
# 			selective enough to make an index range scan cheaper than a table scan:
#
# 				SELECT * FROM t1
# 					WHERE key_part1 > constant
# 					ORDER BY key_part1 ASC;
#
# 				SELECT * FROM t1
# 					WHERE key_part1 < constant
# 					ORDER BY key_part1 DESC;
#
# 		) In the next query, teh ORDER BY does not name key_part1, but all rows selected have a constant key_part1 value,
# 			so the index can still be used:
#
# 				SELECT * FROM t1
# 					WHERE key_part1 = constant1 AND key_part2 > constant2
# 					ORDER BY key_part2;
#
# 			In some cases, MySQL cannot use indexes to resolve the ORDER BY, although it may still use indexes to find the rows that
# 			match the WHERE clause.
#
# 			Examples:
#
# 				) The query uses ORDER BY on different indexes:
#
# 					SELECT * FROM t1 ORDER BY key1, key2;
#
# 				) The query uses ORDER BY on nonconsecutive parts of an index:
#
# 					SELECT * FROM t1 WHERE key2=constant ORDER BY key1_part1, key1_part3;
#
# 				) The index used to fetch the rows differs from the one used in the ORDER BY:
#
# 					SELECT * FROM t1 WHERE key2=constant ORDER BY key1;
#
# 				) The query uses ORDER BY with an expression that includes terms other than the index column name:
#
# 					SELECT * FROM t1 ORDER BY ABS(key);
# 					SELECT * FROM t1 ORDER BY -key;
#
# 				) The query joins many tables, and the columns in the ORDER BY are not all from the first nonconstant table that is used
# 					to retrieve rows.
#
# 					(This is the first table in the EXPLAIN output that does not have a const join type)
#
# 				) The query has a different ORDER BY and GROUP BY expressions.
#
# 				) There is an index on only a prefix of a column named in the ORDER BY clause.
#
# 					IN this case, the index cannot be used to fully resolve the sort order.
#
# 					For example, if only the first 10 bytes of CHAR(20) column are indexed, the index cannot
# 					distinguish values past the 10th byte and a filesort is needed.
#
# 				) The index does not store rows in order. For example, this is true for a HASH index in a MEMORY table.
#
# Availability of an index for sorting may be affected by the use of column aliases.
#
# Suppose that the column t1.a is indexed.
#
# In this statement, the name of the column in the select list is a.
#
# It refers to t1.a, as does the reference to a in teh ORDER BY, so the index
# on t1.a can be used:
#
# 	SELECT a FROM t1 ORDER BY a;
#
# In this statement, the name of the column in the select list is also a, but it is the alias name.
#
# It refers to ABS(a), as does the reference to a in the ORDER BY, so the index on t1.a cannot be used:

# SELECT ABS(a) AS a FROM t1 ORDER BY a;
#
# In the following statemnet, the ORDER BY refers to a name that is not hte name of a column in the select list.
#
# But there is a column in t1 named a, so the ORDER BY refers to t1.a and the index on t1.a can be used.
# (The resulting sort order may be completely different from the order for ABS(a), of course)
#
# SELECT ABS(a) AS b FROM t1 ORDER BY a;
#
# < 5.7, GROUP BY sorted implicitly under certain conditions.
#
# Howver, in >= 8.0, that no longer occurs, so specifying ORDER BY NULL at the end to suppress implicit
# sorting (as was doine previously), is no longer called for.
#
# However, query results may differ from previous MySQL versions.
#
# To produce a given sort order, provide an ORDER BY clause.
#
# USE OF FILESORT TO SATISFY ORDER BY
#
# If an index cannot be used to satisfy an ORDER BY clause, MySQL performs a filesort operation that
# reads table rows and sorts them.
#
# A filesort constitutes an extra sorting phase in query execution.
#
# To obtain memory for filtersort operations, as of 8.0.12, the optimizer allocates memory buffers
# incrementally as needed, up to the size indicated by the sort_buffer_size system variable, rather than
# allocating a fixed amount of sort_buffer_size bytes up front, as was done pre 8.0.12
#
# This enables users to set sort_buffer_size to large values to speed up large sorts, without concern
# for excessive memory use for small sorts.
#
# (This benefit may not occur for multiple concurrent sorts on WIndows, which has a weak multithreaded malloc)
#
# A filesort operation uses temporary disk files as nessecary if the result is set too large to fit in memory.
#
# Some types of queries are particularly suited to completely in-memory filesort operations.
#
# For example, the optimizer can use filesort to efficiently handle in memory, without temporary files, the ORDER BY
# operation for queries (and subqueries) of the following form:
#
# 		SELECT_---_FROM single_table ___ ORDER BY non_index_column [DESC] LIMIT [M,]N;
#
# SUch queries are common in web applications that display only a few rows from a larger result set.
# Examples:
#
# 		SELECT col1, --- FROM t1 --- ORDER BY name LIMIT 10;
# 		SELECT col1, --- FROM t1 --- ORDER BY RAND() LIMIT 15;
#
# INFLUENCING ORDER BY OPTIMIZATION
#
# For slow ORDER BY queries for which filesort is not used, try lowering the max_length_for_sort_data system variable
# to a value that is appropriate to trigger a filesort.
#
# (a symptom of setting the value of this variable too hgih is a combination of high disk activity and low CPU activity)
# 
# To increase ORDER BY speed, check whether you can get MySQL to use indexes rather than an extra sorting phase.
# If this is not possible, try the following strategies:
#
# 		) Increase the sort_buffer_size variable value.
#
# 			Ideally, the value should be large enough for the entire result set to fit in the sort buffer
# 			(to avoid writes to disk and merge passes)
#
# 			Take into account that hte size of column values stored in the sort buffer is affected by the
# 			max_sort_length system variable value.
#
# 			For example, if tuples store values of long string columns and you increase the value of max_sort_length
# 			, the size of sort buffer tuples increases as well and may require you to increase sort_buffer_size
#
# 			To monitor the number of merge passes (to merge temporary files), check the Sort_merge_passes status variable.
#
# 		) increase the read_rnd_buffer_size variable value so that more rows are read at a time.
#
# 		) Change the tmpdir system variable to point to a dedicated file system with large amounts of free space.
#
# 			The variable value can list several paths that are used in round-robin fashion; you cna use this feature
# 			to spread the load across several directories.
#
# 			Separate the paths by colon characters (:) on UNIX and semicolon chars on Windows (;).
#
# 			The paths should name directories in file systems located on different physical disks, not different partitions on the same disk.
#
# ORDER BY EXECUTION PLAN INFORMATION AVAILABLE
#
# With EXPLAIN (more later), you can check whether MySQL can use indexes to resolve an ORDER BY clause:
#
# 		) If the Extra column of EXPLAIN output does not contain Using filesort, the index is used and a filesort is not performed.
#
# 		) If the Extra column of EXPLAIN output contains Using filesort, the index is not used and a filesort is performed.
#
# In addition, if a filesort is performed, optimizer trace output includes a filesort_summary block.
# For example:
#
# 		"filesort_summary": {
# 			"rows": 100,
# 			"examined_rows": 100,
# 			"number_of_tmp_files": 0,
# 			"peak_memory_used": 25192,
# 			"sort_mode": "<sort_key, packed_additional_fields>"
# 		}
#
# peak_memory_used indicates the maximum memory used at any one time during the sort.
#
# This is a value up to but not nessecarily as large as the value of the sort_buffer_size system variable.
# Prior to 8.0.12, the output shows sort_buffer_size instead, indicating the value of sort_buffer_size.
#
# < 8.0.12, optimizer always allocates sort_buffer_size bytes for the sort buffer.
#
# >= 8.0.12, the optimizer allocates sort-buffer memory incrementally, beginning with
# a small amount and adding more as necessary, up to sort_buffer_size bytes)
#
# The sort_mode value provides information about the contents of tuples in the sort buffer:
#
# 		) <sort_key, rowid>: This indicates that sort buffer tuples are pairs that contain the sort key value and row ID
# 									of the original table row. Tuples are sorted by sort key value and the row ID is used to read the row from the table.
#
# 		) <sort_key, additional_fields>: This indicates that sort buffer tuples contain the sort key value and columns referenced by the query.
#
# 													Tuples are sorted by sort key value nad column values are read directly from the tuple.
#
# 		) <sort_key, packed_additional_fields>: Like the previous variant, but the additional columns are packed tightly together instead of using
# 																a fixed-length encoding.
#
# EXPLAIN does not distinguish whether the optimizer does or does not perform a filesort in memory.
# Use of an in-memory filesort can be seen in optimizer trace output.
#
# Look for filesort_priority_queue_optimization. For info about the optimizer trace, see later.
#
# GROUP BY OPTIMIZATION
#
# The most general way to satisfy a GROUP BY clause is to scan the whole table and create a new temporary table
# where all rows from each group are consecutive and then use this temporary table to discover groups and apply
# aggregate functions (if any).
#
# In some cases, MySQL is able to do much better than that and avoid creation of temp tables by using index access.
#
# The most important preconditions for using indexes for GROUP BY are that all GROUP BY columns reference attributes
# from the same index, and that the index stores its keys in order (as is true, for example, for a BTREE index, but not for a HASH index).
#
# Whether use of temporary tables can be replaced by index access also depends on which parts of an index are used in a query,
# the conditions specified for these parts, and the selected aggregate functions.
#
# There are two ways to execute a GROUP BY query through index access, as detailed in teh following sections.
#
# The first method applies the grouping operation together with all range predicates (if any).
# The second method first performs a range scan, and then groups the resulting tuples.
#
# Loose index scan can also be used in the absence of GROUP BY under some conditions. More on this later.
#
# LOOSE INDEX SCAN
#
# The most efficient way to process GROUP BY is when an index is used to directly retrieve the grouping columns.
#
# With this access method, MySQL uses the property of some index types that the keys are ordered
# (for example, BTREE).
#
# This property enables use of lookup groups in an index without having to consider all keys in the index
# that satisfy all WHERE conditions.
#
# This access method considers only a fraction of the keys in an index, so it is called a Loose Index Scan.
#
# When there is no WHERE clause, a Loose Index Scan reads as many keys as the numebr of groups, which may be
# much smaller than that of all keys.
#
# If the WHERE clause contains range predicates (see the discussion of the range join type later),
# a Loose Index Scan looks up the first key of each group that satisfies the range conditions and again
# reads the smallest possible number of keys.
#
# This is possible under the following conditions:
#
# 		) The query is over a single table
#
# 		) The  GROUP BY names only columns that form a leftmost prefix of the index and no other columns.
#
# 			(If, instead of GROUP BY, the query has a DISTINCT clause, all distinct attributes refer to columns that
# 				form a leftmost prefix of the index)
#
# 			For example, if a table t1 has an index on (c1, c2, c3), Loose Index Scan is applicable if the query
# 			has GROUP BY c1,c 2.
#
# 			It is not applicable if the query has GROUP BY c2, c3 (the columns are not a leftmost prefix), or GROUP BY c1, c2, c4 (c4 is not in the index)
#
# 		) The only aggregate functions used in the select list (if any) are MIN() and MAX(), and all of them refer
# 			to the same column.
#
# 			The column must be in the index and must immediately follow the columns in the GROUP BY.
#
# 		) ANy other parts of the index than those from the GROUP BY referenced in teh query must be constants (that is, they must
# 			be referenced in equalities with constants), except for the argument of MIN() or MAX() functions.
#
# 		) For columns in the index, full column values must be indexed, not just a prefix.
#
# 			for example, with c1 VARCHAR(20), INDEX (c1(10)), the index uses only a prefix of c1 values
# 			and cannot be used for Loose Index Scan
#
# If Loose Index Scan is applicable to a query, the EXPLAIN output shows Using index for group-by in the Extra column.
#
# Assume that there is an index idx(c1, c2, c3) on table t1(c1, c2, c3, c4).
#
# The Loose Index Scan access method can be used for the following queries:
#
# 		SELECT c1, c2 FROM t1 GROUP BY c1, c2;
# 		SELECT DISTINCT c1, c2 FROM t1;
# 		SELECT c1, MIN(c2) FROM t1 GROUP BY c1;
# 
# 		SELECT c1, c2 FROM t1 WHERE c1 < const GROUP BY c1, c2;
# 		SELECT MAX(c3), MIN(c3), c1, c2 FROM t1 WHERE c2 > const GROUP BY c1, c2;
#
# 		SELECT c2 FROM t1 WHERE c1 < const GROUP BY c1, c2;
# 		SELECT c1, c2 FROM t1 WHERE c3 = const GROUP BY c1, c2;
#
# The following queries cannot be executed with this quick select method, for the reasons given:
#
# 		) There are aggregate functions other than MIN() or MAX():
#
# 			SELECT c1, SUM(c2) FROM t1 GROUP BY c1;
#
# 		) The columns in the GROUP BY clause do not form a leftmost prefix of the index:
#
# 			SELECT c1, c2 FROM t1 GROUP BY c2, c3;
#
# 		) The query refers to a part of a key that comes after the GROUP BY part, and for which there is no equality with a constant:
#
# 			SELECT c1, c3 FROM t1 GROUP BY c1, c2;
#
# 			Were the query to include WHERE c3 = const, Loose Index Scan could be used.
#
# The Loose Index Scan access method can be applied to other forms of aggregate function references in teh select list,
# in addition to the MIN() and MAX() references already supported:
#
# 		) AVG(DISTINCT), SUM(DISTINCT), and COUNT(DISTINCT) are supported.
#
# 			AVG(DISTINCT) and SUM(DISTINCT) takes a single argument.
#
# 			COUNT(DISTINCT) can have more than once column argument.
#
# 		) There must be no GROUP BY or DISTINCT clause in the query
#
# 		) The Loose Index Scan limitations described previously still apply.
#
# Assume that there is an index idx(c1,c2,c3) on table t1(c1,c2,c3,c4).
#
# The Loose Index Scan access method can be used for the following queries:
#
# 		SELECT COUNT(DISTINCT c1), SUM(DISTINCT c1) FROM t1;
#
# 		SELECT COUNT(DISTINCT c1, c2), COUNT(DISTINCT c2, c1) FROM t1;
#
# TIGHT INDEX SCAN
#
# A Tight Index Scan may be either a full index scan or a range index scan, depending on the query conditions.
#
# When the conditions for a Loose Index Scan are not met, it still may be possible to avoid creation of temporary
# tables for GROUP BY queries.
#
# If there are range conditions in teh WHERE Clause, this method reads only the keys that satisfy these conditions.
#
# Otherwise, it performs an index scan.
#
# Because this method reads all keys in each range defined by the WHERE clause, or scans the whole index if there
# are no range conditions, it is called a Tight Index Scan.
#
# With a tight index scan, the grouping operation is performed only after all keys that satisfy the range conditions
# have been found.
#
# For this method to work, it is sufficient that there be a constant equality condition for all columns in a query referring
# to parts of the key coming before or in between parts of the GROUP BY key.
#
# The constants from the equality conditions fill in any "gaps" in the search keys so that it is possible to form complete
# prefixes of the index.
#
# These index prefixes then can be used for index lookups.
#
# If the GROUP BY result requires sorting, and it is possible to form search keys that are prefixes of the index,
# MySQL also avoids extra sorting operations because searching with prefixes in an ordered index already retrieves
# all the keys in order.
#
# Assume that htere is an index idx(c1,c2,c3) on table t1(c1,c2,c3,c4).
#
# The following queries do not work with the Loose Index Scan access method described 
# previously, but still work with the Tight Index Scan access method.
#
# 		) There is a gap in the GROUP BY, but it is covered by the condition c2 = 'a'
#
# 			SELECT c1, c2, c3 FROM t1 WHERE c2 = 'a' GROUP BY c1, c3;
#
# 		) The GROUP BY does not begin with the first part of the key, but there is a condition that provides 
# 			a constant for that part:
#
# 			SELECT c1, c2, c3 FROM t1 WHERE c1 = 'a' GROUP BY c2, c3;
#
# DISTINCT OPTIMIZATION
#
# DISTINCT combined with ORDER BY needs a temporary table in many cases.
#
# Because DISTINCT may use GROUP BY, learn how MySQL works with columns in ORDER BY or HAVING clauses
# that are not part of the selected columns.
#
# See later, in MySQL handling of GROUP BY.
#
# In most cases, a DISTINCT clause can be considered as a special case of GROUP BY.
# For example, the following two queries are equivalent:
#
# 		SELECT DISTINCT c1, c2, c3 FROM t1
# 		WHERE c1 > const;
#
# 		SELECT c1, c2, c3 FROM t1
# 		WHERE c1 > const GROUP BY c1, c2, c3;
#
# Due to this equivalence, the optimizations applicable to GROUP BY queries can also be applied to queries with a DISTINCT
# clause.
#
# Thus, for more details on the optimization possibilities for DISTINCT queries, see group by optimization.
#
# When combining LIMIT row_count with DISTINCT, MySQL stops as soon as it finds row_count unique rows.
#
# If you do not use columns from all tables named in a query, MySQL stops scanning any unused tables as soon
# as it finds the first match.
#
# In the following case, assuming that t1 is used before t2 (which you can check with EXPLAIN), MySQL stops reading
# from t2 (for any particular row in t1) when it finds the first row in t2:
#
# 		SELECT DISTINCT t1.a FROM t1, t2 WHERE t1.a=t2.a;
#
# LIMIT QUERY OPTIMIZATION
#
# If you need only a specified number of rows from a result set, use a LIMIT clause in the query, rather than fetching
# the whole result set and throwing away the extra data.
#
# MySQL sometimes optimizes a query that has a LIMIT row_count clause and no HAVING clause:
#
# 		) If you select only a few rows with LIMIT, MySQL uses indexes in some cases when normally it would prefer to do a full table scan.
#
# 		) If you combine LIMIT row_count with ORDER BY, MySQL stops sorting as soon as it has found the first row_count rows of the sorted result,
# 			rather than sorting the entire result.
#
# 			If ordering is done by using an index, this is very fast.
#
# 			If a filesort must be done, all rows that match the query without the LIMIT clause are selected,
# 			and most or all of them are sorted, before the first row_count are found.
#
# 			After the intial rows have been found, MySQL does not sort any remainder of the result set.
#
# 			One manifestation of this behavior is that an ORDER BY query with and without LIMIT may return rows in different order,
# 			as described later in this section.
#
# 		) If you combine LIMIT row_count with DISTINCT, MySQL stops as soon as it finds row_count unique rows.
#
# 		) In some cases, a GROUP BY can be resolved by reading the index in order (or doing a sort on the index), then calculating
# 			summaries until the index value changes.
#
# 			In this case, LIMIT row_count does not calculate any unnecessary GROUP BY values.
#
# 		) As soon as MySQL has sent the required number of rows to the client, it aborts the query unless you are using SQL_CALC_FOUND_ROWS.
#
# 			In that case, the number of rows can be retrieved with SELECT FOUND_ROWS(). More later, on INFORMATION FUNCTIONS.
#
# 		) LIMIT 0 quickly returns an empty set.
#
# 			This can be useful for checking the validity of a query.
#
# 			It can also be employed to obtain the types of the result columns within applications that use a MYSQL API that makes
# 			result set metadata available.
#
# 			With the mysql client program, you can use the --column-type-info option to display result column types.
#
# 		) If the server uses temporary tables to resolve a query, it uses the LIMIT row_count clause to calculate how much space is required.
#
# 		) If an index is not used for ORDER BY but a LIMIT clause is also present, the optimizer may be able to avoid using a merge file
# 			and sort the rows in memory using an in-memory filesort operation
#
# If multiple rows have identical values in teh ORDER BY columns, the server is free to return those rows in any order,
# and may do so differently depending on the overall execution plan.
#
# In other words, the sort order of those rows is nondeterministic with respect to the nonordered columns.
#
# One factor that affects the execution plan is LIMIT, so an ORDER BY query with and without LIMIT may return rows
# in different orders.
#
# Consider this query,, which is sorted by the category column but nondeterministic with respect to the id and rating columns:
#
# 		SELECT * FROM ratings ORDER BY category;
# 		+----+-------------+--------------+
# 		| id | category 	 | rating 		 |
# 		+----+-------------+--------------+
# 		| 1  | 			1 	 | 		4.5 	 |
# 		| 5  | 			1 	 | 		3.2 	 |
# 		| 3  | 			2 	 | 		3.7 	 |
# 		| 4  | 			2 	 | 		3.5 	 |
# 		| 6  | 			2 	 | 		3.5 	 |
# 		| 2  | 			3   | 		5.0 	 |
# 		| 7  | 			3 	 | 		2.7 	 |
# 		+----+-------------+--------------+
#
# Including LIMIT may affect order of rows within each category value.
#
# For example, this is a valid query result:
#
# SELECT * FROM ratings ORDER BY category LIMIT 5;
# +----+----------+--------+
# | id | category | rating |
# +----+----------+--------+
# | 1  | 		1  | 	4.5   |
# | 5  | 		1 	|  3.2 	|
# | 4  | 		2  |  3.5 	|
# | 3  | 		2  |  3.7   |
# | 6  |  		2  |  3.5 	|
# +----+----------+--------+
#
# In each case, the rows sorted by the ORDER BY column, which is all that is required by the SQL standard.
#
# If it is important to ensure that hte same row order with and without LIMIT, include additional columns in the ORDER BY clause to make the
# order deterministic.
#
# For example, if id values are unique, you can make rows for a given category value appear in id order by sorting like this:
#
# SELECT * FROM ratings ORDER BY category, id;
# +----+---------------+--------+
# | id | category 	  | rating |
# +----+---------------+--------+
# | 1  | 			1 	  |  4.5   |
# | 5  | 			1 	  |  3.2   |
# | 3  | 			2 	  |  3.7   |
# | 4  | 			2    |  3.5   |
# | 6  | 			2    |  3.5   |
# | 2  | 			3 	  |  5.0   |
# | 7  | 			3    |  2.7   |
# +----+---------------+--------+
#
# SELECT * FROM ratings ORDER BY category, id LIMIT 5;
#
# +---+----------------+--------+
# |id | category 		  | rating |
# +---+----------------+--------+
# | 1 | 			1 		  |  4.5   |
# | 5 | 			1 		  |  3.2   |
# | 3 | 			2 		  |  3.7   |
# | 4 | 			2 		  |  3.5   |
# | 6 | 			2 		  |  3.5   |
# +---+----------------+--------+
#
# FUNCTION CALL OPTIMIZATION
#
# MySQL functions are tagged internally as determnistic or nondeterministic.
#
# A function is nondeterministic if, given fixed values for its arguments - it can return different results for different invocations.
#
# Examples of nondeterministic functions: RAND, UUID()
#
# If a function is tagged nondeterministic, a reference to it in a WHERE clause is evaluated for every row (when selecting from one table)
# or by combination of rows (when selecting from a multiple-table join)
#
# MySQL also determines when to evaluate functions based on types of arguments, whether the arguments are table columns
# or constant values.
#
# A deterministic function that takes a table column as argument must be evaluated whenever that column changes value.
#
# Nondeterministic functions may affect query performance.
#
# FOr example, some optimizations may not be available, or more locking might be required.
#
# The following discussion uses RAND() but applies to other nondeterministic functions as well:
#
# SUppose that a table t has this definition:
#
# 		CREATE TABLE t (id INT NOT NULL PRIMARY KEY, col_a VARCHAR(100));
#
# Consider these two queries:
#
# 		SELECT * FROM t WHERE id = POW(1,2);
# 		SELECT * FROM t WHERE id = FLOOR(1 + RAN() * 49);
#
# Both queries appear to use a primary key lookup because of the equality comparisons against the primary key, but that is true only for the first one:
#
# 		) The first query always produces a maxium of one row because POW() with constant args is a constant value and is used for index lookup.
#
# 		) The second query contains an expression that uses the nondeterministic function RAND(), which is not constant in teh query but in fact has
# 			a new value for every row of table t.
#
# 			Consequently, the query reads every row of the table, evaluates the predicate for each row, and outputs all rows for which the primary key
# 			matches the random value.
#
# 			This might be 0, 1, or multiple rows - depending on the ID column values and the reuslt of RAND().
#
# The effects of nondeterminism are not limited to SELECT statements. 
# This UPDATE statement uses a nondeterministic function to select rows to be modified:
#
# 		UPDATE t SET col_a = some_expr WHERE id = FLOOR(1 + RAND() * 49);
#
# Presumably, the intent is to update at most a single row for which the primary key matches the expression.
#
# However, it might update  randomly many, due to afformentioned RNG.
#
# The behavior just described has implications for performance and replication:
#
# 		) Because a nondeterministic function does not produce a constant value, the optimizer cannot use strategies
# 			that might otherwise be applicable, such as index lookups.
#
# 			THe result may be a table scan.
#
# 		) InnoDB might escalate to a range-key lock rather than taking a single row lock for one matching row.
#
# 		) Updates that do not execute determinsitically are unsafe for replication.
#
# The difficulties stem form the fact that hte RAND() fuinction is evaluated once for every row in the table.
#
# To avoid multiple function evaluations, use one of these techniques:
#
# 		) Move the expression containing the nondeterministic function to a separate statement, saving the value in a variable.
#
# 			In the original statement, replace the expression with a reference to the variable, which the optimizer can treat
# 			as a constant value:
#
# 			SET @keyval = FLOOR(1 + RAND() * 49);
# 			UPDATE t SET col_a = some_expr WHERE id = @keyval;
#
# 		) Assign the random value to a variable in a derived table.
#
# 			This technique causes the variable to be assigned a value, once, prior to its use in the comparison in the WHERE clause:
#
# 			UPDATE /*+ NO_MERGE(dt) */ t, (SELECT FLOOR(1 + RAND() * 49) AS r) AS dt
# 			SET col_a = some_expr WHERE id = dt.r;
#
# AS mentioned previously, a nondeterministic expression in the WHERE clause might prevent oiptimization and result in a table scan.
#
# However, it may be possible to partially optimize the WHERE clause if other expressions are deterministic.
# For example:
#
# 		SELECT * FROM t WHERE partial_key=5 AND some_column=RAND();
#
# If the optimizer cna use partial_key to reduce the set of rows selected, RAND() is executed fewer times,
# which diminishes the effect of nondeterminism on optimization.
#
# WINDOW FUNCTION OPTIMIZATION
#
# Window functions affect the strategies the optimizer considers:
#
# 		) Derived table merging for a subquery is disabled if the subquery has window functions. The subquery is always materialized.
#
# 		) Semi-joins are not applicable to Window function optimization because semi-joins apply to subqueries in WHERE and JOIN_---_ON,
# 			which cannot contain window functions.
#
# 		) The optimizer processes multiple windows that have the same ordering requirements in sequence, so sorting can be skipped for windows following the first one.
#
# 		) The optimizer makes no attempt to merge windows that could be evaluated in a single step;
#
# 			For example, when multiple OVER clauses contain identical WINDOW definitions.
#
# 			THe workaround is to define the window in a WINDOW clause and refer to the window name in the OVER clauses.
#
# An aggregate function not used as a window function is aggregated in the outermost possible query.
#
# For example, in thsi query, MySQL sees that COUNT(t1.b) is something that cannot exist in the outer query,
# because of its placement in teh WHERE clause:
#
# 		SELECT * FROM t1 WHERE t1.a = (SELECT COUNT(t1.b) FROM t2);
#
# Conseuqently, MySQL aggregates inside the subquery, treating t1.b as a constant and returning the count of rows of t2.
#
# Replacing WHERE with HAVING results in an error:
#
# SELECT * FROM t1 HAVING t1.a = (SELECT COUNT(t1.b) FROM t2);
# ERROR 1140 (42000): In aggregated query without GROUP BY, expression #1
# of SELECT list contains nonaggregated column 'test.t1.a';
#
# This is incompatible with sql_mode=only_full_group_by
#
# The error occurs because COUNT(t1.b) can exist in teh HAVING, and so make the outer query aggregated.
#
# WIndow functions (including aggregated functions used as window functions), do not have the preceding complexity.
#
# They always aggregate in the subquery where they are written, never in the outer query.
#
# Window functions evaluation may be affected by the value of the windowing_use_high_precision system variable,
# which determines whether to compute window operations without loss of precision.
#
# By default, window_use_high_precision is enabled.
#
# FOr some moving frame aggregates, teh inverse aggregate function can be applied to remove values from the aggregate.
# This can improve performance but possibly with a loss of precision.
#
# FOr example, adding a very small floating-point vlaue to a very large value causes the small value to be hidden by the large value.
#
# WHen inverting the large value later, the effect of the small value is lost.
#
# Loss of precision due to inverse aggregation is a factor only for operations on floating point (approx) data types.
#
# For other types, inverse aggregation is safe; this includes DECIMAL, which permits a fractional part but is an exact-value type.
#
# For faster execution, MySQL always uses inverse aggregation when it is safe:
#
# 		) For floating-point values, inverse aggregation is not always safe and might result in loss of precision.
#
# 			The default is to avoid inverse aggregation, which is slower, but preserves precision.
#
# 			If it is permissible to sacrifice safety for speed, windowing_use_high_precision can be disabled
# 			to permit inverse aggregation.
#
# 		) FOr nonfloating-point data types, inverse aggregation is always safe and is used regardless of the windowing_use_high_precision value.
#
# 		) windowing_use_high_precision has no effect on MIN(), and MAX(), which do not use inverse aggregation in any case.
#
# For evaluation of the variance functions STDDEV_POP(), STDDEV_SAMP(), VAR_POP(), VAR_SAMP(), and their synonyms, evaluation can occur
# in optimized mode or default mode.
#
# Optimized mode may produce slightly different results in teh last sig. digits
#
# If such differences are permissible, windowing_use_high_precision can be disabled to permit optimized mode.
#
# For EXPLAIN, windowing executing plan information is too extensive to display in traditional output format.
#
# To see windowing information, use EXPLAIN_FORMAT=JSON and look for the Windowing element.
#
# ROW CONSTRUCTOR EXPRESSION OPTIMIZATION
#
# Row constructors permit simultaneous comparisons of multiple values.
#
# For example, these two statements are semantically equivalent:
#
# 		SELECT * FROM t1 WHERE (column1,column2) = (1,1);
# 		SELECT * FROM t1 WHERE column1 = 1 AND column2 = 1;
#
# In addition, the optimizer handles both expressions the same way.
#
# THe optimizer is less likely to use avaiable indexes if the row constructor columns
# do not cover the prefix of an index.
#
# Consider the following table, which has the primary key on (c1, c2, c3):
#
# 		CREATE TABLE t1 (
# 			c1 INT, c2 INT, c3 INT, c4 CHAR(100),
# 			PRIMARY KEY(c1,c2,c3)
# 		);
#
# In this query, the WHERE clause uses all columns in teh index.
#
# However, the row constructor itself does not cover an index prefix, with the result that the
# optimizer uses only c1(key_len=4, the size of c1):
#
# 		EXPLAIN SELECT * FROM t1
# 		WHERE c1=1 AND (c2,c3) > (1,1)\G
# 		***************** 1. row ************************
# 		
# 							id: 1
# 				select_type: SIMPLE
# 						table: t1
# 				partitions:  NULL
# 						type:  ref
# 			possible_keys:  PRIMARY
# 						key :  PRIMARY
# 					key_len:  4
# 						ref:  const
# 					 rows :  3
# 				Filtered :  100.00
# 				Extra     : Using where
#
# IN such cases,, rewriting the row constructor expression using an equivalent nonconstructor expression may
# result in a more complex index use.
#
# For the given query, the row constructor and equivalent nonconstructor expressions are:
#
# 	(c2, c3) > (1,1)
# 	c2 > 1 OR ((c2 = 1) AND (c3 > 1))
#
# Rewriting the query to use the nonconstructor expression results in the optimizer using all three
# columns in the index (key_len=12):
#
# 		EXPLAIN SELECT * FROM t1
# 		WHERE c1 = 1 AND (c2 > 2 OR ((c2 = 1) AND (c3 > 1)))\G
# 		***************** 1. row 	************************
# 							id: 1
# 				select_type: SIMPLE
# 						table: t1
# 				partitions:  NULL
# 						type:  range
# 			possible_keys:  PRIMARY
# 						key:   PRIMARY
# 					key_len:  12
# 						  ref: NULL
# 						rows:  3
# 					filtered: 100.00
# 					Extra   : Using where
#
# Thus, for better results, avoid mixing row constructors with AND/OR expressions.
#
# Use one or the other.
#
# Under certain conditions, the optimizer can apply the range across method to IN() expressions that have
# row constructor arguments.
#
# See more under range optimization of Row constructor Expressions
#
# AVOIDING FULL TABLE SCANS
#
# THe output from EXPLAIN shows ALL in the type column when MySQL uses a full table scan to resolve a query.
#
# THis usually happens under the following conditions:
#
# 		) The table is so small that it is faster to perform a table scan than to bother with a key lookup.
#
# 			This is common for tables with < 10 rows and a short row length.
#
# 		) There are no usable restrictions in teh ON or WHERE clause for indexed columns.
#
# 		) You are comparing indexed columns with constant values and MySQL has calculated (based on the index tree), 
# 			that the constants cover too large a part of the table and that a table scan would be faster.
#
# 		) You are using a keyy with low cardinality (many rows match the key value) through another column.
#
# 			In this case, MySQL assumes taht by using the key it probably will do many key lookups and that
# 			a table scan would be faster.
#
# For small tables, a table scan often is appropriate and the performance impact is negligble.
#
# For large tables, try the following techniques to avoid having the optimizer incorrectly choose a table scan:
#
# 		) Use ANALYZE TABLE tbl_name to update the key distribs for the scanned table. More on this later.
#
# 		) Use FORCE INDEX for the scanned table to tell MySQL that table scans are very expensive compared to using the given index:
#
# 			SELECT * FROM t1, t2 FORCE INDEX (index_for_column)
# 				WHERE t1.col_name=t2.col_name;
#
# 			See more on Index hints later.
#
# 		) Start mysqld with the --max-seeks-for-key=1000 option or use SET max_seeks_for_key=1000 to tell
# 			the opptimizer to assume that no key scan causes more than 1k key seeks.
#
# 			See server vars since earlier for more info about this.
#
# OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS
#
# The MySQL query optimizer has different strategies available to evaluate subqueries.
#
# For IN( Or =ANY) subqueries, the optimizer has these choices:
#
# 		) Semi-join
#
# 		) Materialization
#
# 		) EXISTS strategy
#
# For NOT IN ( or <>ALL) subqueries, the optimizer has these choices:
#
# 		) Materialization
#
# 		) EXISTS strategy
#
# For derived tables, the optimizer has these choices:
#
# 		) Merge the derived table into the outer query block
#
# 		) Materialize the derived table to an internal temporary table
#
# FOr view references and common tabl exp., the optimizer has the same choices as for derived tables.
#
# The following discussion provides more info about the preceding optimization strategies.
#
# NOTE:
#
# 		A limitation on UPDATE and DELETE statements that uses a subquery to modify a single table
# 		is that the optimizer does not use semi-join or materialization subquery optimizations.
#
# 		As a workaround, try rewriting them as multiple-table UPDATE and DELETE statements that use a join
# 		rather than a subquery.
#
# OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES AND COMMON TABLE EXPRESSIONS WITH SEMI-JOIN TRANSFORMATIONS
#
# The optimizer uses semi-join strategies to improve subquery execution, as described here.
#
# For an inner join between two tables, teh join returns a row from one table as many times as there are 
# matches in the other table.
#
# But for some questions, the only information that matters is whether there is a match, not hte number
# of matches.
#
# Suppose that htere are tables named class and roster, that list classes in a course curriculum and class rosters
# (students enrolled in each class), respectively.
#
# TO list the classes that actually have students enrolled, you could use this join:
#
# 	SELECT class.class_num, class.class_name
# 	FROM class INNER JOIN roster
# 	WHERE class.class_num = roster.class_num;
#
# However, the result lists each class once for each enrolled student.
#
# This is unessecary duplication.
#
# Assuming that class_num is a primary key in the class table, duplication suppression is possible
# by using SELECT_DISTINCT, but it is inefficient to generate all matching rows first to eliminate duplicates later.
#
# THe same duplicate-free result can be obtained by using a subquery:
#
# 		SELECT class_num, class_name
# 		FROM class
# 		WHERE class_num IN (SELECT class_num FROM roster);
#
# HEre, the optimizer can recognize that the IN Clause requires the subquery to return only one instance of each
# class number from the roster table.
#
# In this case, teh query can use a semi-join, that is, an operation that returns only one instnace
# of each row in class that is matched by rows in roster.
#
# Outer join and inner join syntax is permitted in the outer query specification, and table references
# may be base tables, derived tables, view references, or common table expressions.
#
# In MySQL , a subquery must satisfy these criteria to be handled as a semi-join:
#
# 		) It must be an IN (or =ANY) subquery that appears at the top level of the WHERE or ON clause,
# 			possibly as a term in an AND expression.
#
# 			For example:
#
# 				SELECT ---
# 				FROM ot1, ---
# 				WHERE (oe1, ---) IN (SELECT ie1, --- FROM it1, --- WHERE ---);
#
# 			Here, ot_i and it_i represent tables in the outer and inner parts of the uqeyr,
# 			and oe_i and ie_i represent expressions that refer to columns in the outer and inner
# 			tables.
#
# 		) It must be a single SELECT without UNION constructs.
#
# 		) It must not contain a GROUP BY or HAVING clause.
#
# 		) It must not be implicitly grouped (it must contain no aggregate functions)
#
# 		) It must not have ORDER BY with LIMIT
#
# 		) The statement must not use the STRAIGHT_JOIN join type in the outer query
#
# 		) The STRAIGHT_JOIN modifier must noe be present
#
# 		) THe number of outer and inner tables together must be less than the max number of tables permitted in a join
#
# The subquery may be correlated or uncorrelated.
#
# DISTINCT is permitted, as is LIMIT unless ORDER BY is also used.
#
# iF a subquery meets the preceding criteria, MysQL converts it to a semi-join and makes
# a cost-based choice from these strategies:
#
# 		) Convert the subquery to a join, or use table pullout and run the query as an inner join between
# 			subquery tables and outer tables.
#
# 			Table pullout pulls a table out from the subquery to the outer query
#
# 		) Duplicate Weedout: Run the semi-join as if it was a join and remove duplicate records using a temp table
#
# 		) FirsTMatch: When scanning the inner tables for row combinations, and there are multiple instances of a given value group,
# 							choose one rather than returning them all.
#
# 							This "shortcuts" scanning and eliminates production of unessecary rows
#
# 		) LooseScan: Scan a subquery table using an index that enables a single value to be chosen from each subquery's value group
#
# 		) Materialize the subquery into an indexed temporary table that is used to perform a join, where the index is used
# 			to remove duplicates.
#
# 			The index might also be used later for lookups when joining the temporary table with the outer tables;
# 			If not, teh table is scanned.
#
# 			For more information about materialization, see later.
#
# Each of these strategies can be enabled or disabled using the following optimizer_switch system variable flags:
#
# 	) The semijoin flag controls whether semi-joins are used
#
# 	) If semijoin is enabled, teh firstmatch, loosescan, duplicateweedout and materialization flags enable finer control
# 			over hte permitted semi-join strats.
#
# 	) If the duplicateweedout semi-join strategy is disabled, it is not used unless all other applicable stats are also disabled
#
# 	) If duplicatweedout is disabled, on ocassion the optimizer may generate a query plan that is far from optimal.
#
# 		THis occurs due to heuristics pruning during greedy search, which can be avoided by setting optimizer_prune_level=0
#
# THese flags are enabled by default. More later.
#
# The optimizer minimizes differences in handling of views and derived tables.
#
# This affects queries that use the STRAIGHT_JOIN modifier and a view with an IN subquery that
# can be converted to a semi-join.
#
# The following query illustrates this because the change in processing causes a change in trasnformation,
# and thus a different execution strat:
#
# 		CREATE VIEW v AS
# 		SELECT
# 		FROM t1
# 		WHERE a IN (SELECT b
# 						FROM t2);
#
# 		SELECT STRAIGHT_JOIN *
# 		FROM t3 JOIN v ON t3.x = v.a;
#
# The optimizer first looks at hte view and converts the IN subquery to a semi-join, then checks
# whether it is possible to merge the view into the outer query.
#
# BEcause the STRAIGHT_JOIN modifier in the outer query prevents semi-join, the optimizer refuses the merge,
# causing derived table evaluation using a materialzied table.
#
# EXPLAIN output indicates the use of a semi-join strat as follows:
#
# 		) For extended EXPLAIN output, the text displayed by a following SHOW_WARNING shows the rewritten query,
# 			which displays the semi-join structure.
#
# 			From this, you can get an idea about which tables were pulled out of the semi-join.
#
# 			If a subquery was converted to a semi-join, you will see that hte predicate is gone
# 			and its tables and WHERE clause were merged into teh outer query join list
# 			and WHERE Clause.
#
# 		) Temporary table use for Duplicate Weedout is indicated by Start Temporary and End Temporary in the Extra column.
#
# 			tables hat were not pulled out and are in the range of EXPLAIN output rows covered by Start temporary
# 			and End temporary have their rowid in the temp table.
#
# 		) FirstMatch(tbl_name) in the Extra column indicates join shortcutting
#
# 		) LooseScan(m--m) in the extra column indicates use of the LooseScan strat. m and n are key part numbers.
#
# 		) Temp table use for materialization is indicated by rows with a select_type value of MATERIALIZED
# 			and rows with a table value of <subqueryN>
#
# OPTIMIZING SUBQUERIES WITH MATERIALIZATION
#
# The optimizer uses materialization to enable more efficient subquery processing.
#
# Materialization speeds up query execution by generating a subquery result as a temp table,
# normally in memory.
#
# The first time MySQl needs the subquery result, it materializes that result into a temp table.
# Any subsequent time the result is needed, MySQL refers again to the temp table.
#
# THe optimizer may index the table with a hash index to make lookups fast and inexpensive.
#
# The index is unique, which eliminates duplicates and makes the table smaller.
#
# SUbquery materialization uses a in-memory temp table when possible,
# falling back on disk storage if the table becomes too large.
#
# If materialization is not used, the optimizer sometimes rewrites a noncorrelated subquery as a correlated
# subqery.
#
# For example, the following IN subquery is noncorrelated (where_condition involves only columns from t2
# and not t1):
#
# 	SELECT * FROM t1
# 	WHERE t1.a IN (SELECT t2.b FROM t2 WHERE where_condition);
#
# The optimizer might rewrite this as an EXISTS correlated subquery:
#
# SELECT * FROM t1
# WHERE EXISTS (SELECT t2.b FROM t2 WHERE where_condition AND t1.a=t2.b);
#
# Subquery materialization using a temporary table avoids such rewrites and makes it possible
# to execute the subquery only once rather than once per row of the outer query.
#
# For subquery materialization to be used in MySQL, the optimizer_switch system variable materialization
# flag must be enabled.
#
# (see more on this under Switchable Optimizations)
#
# With the materialization flag enabled, materialization applies to subquery predicates that appear anywhere
# (in the select list, WHERE ON, GROUP BY, HAVING or ORDER BY), for predicates that fall into any of these use cases:
#
# 		) The predicate has this form, when no outer expression oe_i or inner expression ie_i is nullable.
# 			N is 1 or larger.
#
# 			(oe_1, oe_2, ---, oe_N) [NOT] IN (SELECT ie_1, i_2, ---, ie_N ---)
#
# 		) The predicate has this form, when there is a single outer expression oe and inner expression ie.
# 			The expression can be nullable.
#
# 			oe [NOT] IN (SELECT ie ---)
#
# 		) The predicate is IN or NOT IN and a result of UNKNOWN (NULL) has the same meaning as a result of FALSE.
#
# The following examples illustrate how the requirement for equivalence of UNKNOWN and FALSE predicate evaluation
# affects whether subquery materialization can be used.
#
# Assume that where_condition involves columns only from t2 and not t1 so that the subquery is noncorrelated.
#
# This query is subject to materialization:
#
# 		SELECT * FROM t1
# 		WHERE t1.a IN (SELECT t2.b FROM t2 WHERE where_condition);
#
# Here, it does not matter whether the IN predicate returns UNKNOWN or FALSE.
# Either way, the row from t1 is not included in the query result
#
# An example where subquery materialization is not used is the following query, where t2.b is a nullable column:
#
# 		SELECT * FROM t1
# 		WHERE (t1.a, t1.b) NOT IN (SELECT t2.a, t2.b FROM t2 WHERE where_condition);
#
# The following restrictions apply to the use of subquery materialization:
#
# 		) The types of the inner and outer expressions must match. 
#
# 			For example, the optimizer might be able to use materialization if both expressions
# 			 are integer or both are decimal, but cannot if one expression is integer and the other is decimal.
#
# 		) The inner expression cannot be a BLOB
#
# use of EXPLAIN with a query provides some indication of whether the optimizer uses subquery materialization.
#
# Compared to query execution that does not use materialization, select_type may change from DEPENDENT SUBQUERY
# to SUBQUERY.
#
# This indicates that, for a subquery that would be executed once per outer row, materialization enables the
# subquery to be executed just once.
#
# In addition, for extended EXPLAIN output, the text displayed by a following SHOW_WARNINGS includes
# materialize and materialized-subquery.
#
# OPTIMIZING DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS
#
# The optimizer can handle derived table references using two strategies:
#
# 		) merge the derived table into the outer query block
#
# 		) Materialize the derived table to an internal temporary table
#
# The optimizer uses the same strategies to handle view references and common table expressions.
#
# Example 1:
#
# 			SELECT * FROM (SELECT * FROM t1) AS derived_t1;
#
# 			With merging, that query is executed similar to:
#
# 			SELECT * FROM t1;
#
# Example 2:
#
# 			SELECT *
# 				FROM t1 JOIN (SELECT t2.f1 FROM t2) AS derived_t2 ON t1.f2=derived_t2.f1
# 				WHERE t1.f1 > 0;
#
# 			With merging, that query is executed similar to:
#
# 			SELECT t1.*, t2.f1
# 				FROM t1 JOIN t2 ON t1.f2=t2.f1
# 				WHERE t1.f1 > 0;
#
# With materialization, derived_t1 and derived_t2 are treated as a separate table within their respective queries.
#
# The optimizer handles derived tables and view references the same way: it avoids unnecessary materializaton whenever
# possible, which enables pushing down conditions from the outer query to derived tables and produces more efficient
# execution plans.
#
# (For mroe on this, see earlier)
#
# If merging would result in an outer query block that references more than 61 base tables, the optimizer chooses materialization
# instead.
#
# The optimizer propagates an ORDER BY clause in a derived table or view reference to the outer query block if these conditions
# are all true:
#
# 		) The outer query is not grouped or aggregated
#
# 		) The outer query does not specify DISTINCT, HAVING or ORDER By
#
# 		) The outer query has this derived table or view reference as the only source in the FROM clause.
#
# Otherwise, the optimizer ignores the ORDER BY clause.
#
# The following means are available to influence whether the optimizer attempts to merge derived tables
# and view references into the outer query block:
#
# 		) The MERGE and NO_MERGE optimizer hints can be used.
#
# 			They apply assuming that no other rule prevents merging. See more under optimizer hints.
#
# 		) Similarly, you can use the derived_merge flag of the optimizer_switch system variable.
# 			More under switchable optimizations.
#
# 			By default, the flag is enabled to permit merging.
#
# 			Disabling the flag prevents merging and avoids ER_UPDATE_TABLE_USED errors.
#
# 			The derived_merge flag also applies to views that contain no ALGORITHM clause.
#
# 			Thus, if an ER_UPDATE_TABLE_USED error occurs for a view reference that uses an 
# 			expression equivalent to the subquery, adding ALGORITHM=TEMPTABLE to the view 
# 			definition prevents merging and takes precedence over the derived_merge value.
#
# 		) It is possible to disable merging by using in the subquery any constructs that prevent merging,
# 			although these are not as explicit in their effect on materialization.
#
# 			Constructs that prevent merging are the same for derived tables, common table expressions,
# 			and view references:
#
# 				) Aggregate functions or window functions (SUM(), MIN(), MAX(), COUNT() and so forth)
#
# 				) DISTINCT
#
# 				) GROUP BY
#
# 				) HAVING
#
# 				) LIMIT
#
# 				) UNION or UNION_ALL
#
# 				) Subqueries in the select list
#
# 				) Assignments to user variables
#
# 				) References only to literal values (in this case, there is no underlying table)
#
# If the optimizer choosses the materialization strategy rather than merging for a derived table,
# it handles the query as follows:
#
# 		) The optimizer postpones derived table materialization until its contents are needed during query execution.
#
# 			This improves performance because delaying materialization may result in not having to do it at all.
#
# 			Consider a query that joins the result of a derived table to another table: 
#
# 				If the optimizer processes that other table first and finds that it returns no rows,
# 				the join need not be carried out further and the optimizer can completely skip materializing
# 				the derived table.
#
# 		) During query execution, the optimizer may add an index to a derived table to speed up row retrieval from it.
#
# Consider the following EXPLAIN statement, for which a subquery appears in the FROM clause of a SELECT query:
#
# 		EXPLAIN SELECT * FROM (SELECT * FROM t1) AS derived_t1;
#
# The optimizer avoids materializing the subquery by delaying it until the result is needed during SELECT
# execution.
#
# IN this case, the query is not executed (because it occurs in an EXPLAIN statement), so the result is never needed.
#
# Even for queries that are executed, delay of subquery materialization may enable the optimizer to avoid
# materialization entirely.
#
# When this happens, query execution is quicker by the time needed to perform materialization.
# Consider the following query, which joins the result of a subquery in the FROM clause to another table:
#
# 		SELECT *
# 			FROM t1 JOIN (SELECT t2.f1 FROM t2) AS derived_t2
# 					  ON t1.f2=derived_t2.f1
# 			WHERE t1.f1 > 0;
#
# If the optimization processes t1 first and the WHERE clause produces an empty result,
# the join must necessarily be empty and the subquery need not be materialized.
#
# For cases when a derived table requires materialization, the optimizer may add an index
# to the materialized table to speed up access to it.
#
# If such an index enables ref access to the table, it can greatly reduce amount of data 
# read during query execution.
#
# Consider the following query:
#
# 		SELECT *
# 			FROM t1 JOIN (SELECT DISTINCT f1 FROM t2) AS derived_t2
# 						ON t1.f1=derived_t2.f1;
#
# The optimizer constructs an index over column f1 from derived_t2 if doing so would enable use of
# ref access for the lowest cost execution plan.
#
# After adding the index, the optimizer can treat the materialized derived table the same as a regular
# table with an index, and it benefits similarly from the generated index.
#
# The overhead of index creation is negligble compared to the cost of query execution without the index.
#
# If ref access would result in higher cost than some other access method, the optimizer creates no index
# and loses nothing.
#
# For optimizer trace output, a merged derived table or view reference is not shown as a node.
#
# Only its underlying tables appear in the top query's plan.
#
# What is true for materialization of derived tables is also true for common table expressions (CTEs).
# In addition, the following considerations pertain specifically to CTEs.
#
# If a CTE is materialized by a query, it is materialized once for the query, even if the query references
# it several times.
#
# A recursive CTE is always materialized.
#
# If a CTE is materialized, the optimizer automatically adds relevant indexes if it estimates that indexing will
# speed up access by the top-level statement to the CTE.
#
# This is similar to automatic indexing of derived tables, except that if the CTE is referenced multiple times,
# the optimizer may create multiple indexes to speed up access by each reference in the most appropriate way.
#
# THe MERGE and NO_MERGE optimizer hints can be applied to CTEs. Each CTE reference in the top-level statement
# can have its own hint, permitting CTE references to be selectively merged or materialized.
#
# The following statement uses hints to indicate that cte1 should be merged and cte2 should be materialized:
#
# 		WITH
# 			cte1 AS (SELECT a, b FROM table1),
# 			cte2 AS (SELECT c, d FROM table2)
# 		SELECT /*+ MERGE(cte1) NO_MERGE(cte2) */ cte1.b ,cte2.d
# 		FROM cte1 JOIN cte2
# 		WHERE cte1.a = cte2.c;
#
# The ALGORITHM clause for CREATE_VIEW does not affect materialization for any WITH clause preceding the SELECT
# statement in the view definition.
#
# Consider this statement:
#
# 		CREATE ALGORITHM={TEMPTABLE|MERGE} VIEW v1 AS WITH --- SELECT ---
#
# The ALGORITHM value affects materialization only of the SELECT, not the WITH clause.
#
# For CTEs, the storage engine used for on-disk internal temp tables cannot be MyISAM.
#
# If internal_tmp_disk_storage_engine=MyISAM, an error occurs for any attempt to materialize a CTE
# using an on-disk temporary table.
#
# As mentioned previously, a CTE, if materialized, is materialized once, even if referneced multiple times.
#
# To indicate one-time materialization, optimizer trace output contains an occurence
# of creating_tmp_table plus one or more occurrences of reusing_tmp_table.
#
# CTEs are similar to derived tables, for which the materialized_from_subquery node follows the reference.
#
# This is true for a CTE that is referenced multiple times, so there is no duplication of materialized_from_subquery
# nodes (which would give the impression that the subquery is executed multiple times, and produce unnecessarily
# verbose output).
#
# Only one reference to the CTE has a complete materialized_from_subquery node with the description
# of its subquery plan.
#
# Other references have a reduced materialized_from_subquery node.
#
# THe same idea applies to EXPLAIN output in TRADITIONAL format; Subqueries for other references
# are not shown.
#
# OPTIMIZING SUBQUERIES WITH THE EXISTS STRATEGY
#
# Certain optimizations are applicable to comparisons that use IN (or =ANY) operator to test subquery results.
#
# This section discusses these optimizations, particularly with regards to the challenges that NULL values present.
#
# THe last part of the discussion suggests how you can help the optimizer.
#
# Consider the following subquery comparison:
#
# 		outer_expr IN (SELECT inner_expr FROM --- WHERE subquery_where)
#
# MySQL evaluates queries "from outside to inside".
#
# That is, it first otbains the values of the outer expression outer_expr, and then runs the subquery and captures the rows
# that it produces.
#
# A very useful optimization is to "inform" the subquery that the only rows of interest are those where
# the inner expression inner_expr is equal to outer_expr.
#
# THis is done by pushing down an appropriate equality into the subquery's WHERE clause to make it more restrictive.
# The converted comparison looks like this:
#
# 		EXISTS (SELECT 1 FROM --- WHERE subquery_where AND outer_expr=inner_expr)
#
# After the conversion, MySQL can use the pushed-down equality to limit the number of rows it must examine
# to evaluate the subquery.
#
# More generally, a comparison of N values to a subquery that returns N-value rows is subject to
# the same conversion.
#
# If oe_i and ie_i represent corresponding outer and inner expression values, this subquery comparison:
#
# 		(oe_1, ---, oe_N) IN
# 			(SELECT ie_1, ---, ie_N FROM --- WHERE subquery_where)
#
# Becomes:
#
# 		EXISTS (SELECT 1 FROM --- WHERE subquery_WHERE
# 										  AND oe_1 = ie_1
# 										  AND ---
# 										  AND oe_N = ie_N)
#
# FOr simplicity, the following discussion assumes a single pair of outer and inner expression values.
#
# The conversion just described has its limitations. It is valid only if we ignore possible NULL values.
# That is, the "Pushdown" strategy works as long as both of tehse conditions are true:
#
# 		) outer_expr and inner_expr CANNOT be NULL
#
# 		) You need not distinguish NULL from FALSE subquery results.
#
# 			If the subquery is a part of an OR or AND expression in the WHERE clause,
# 			MySQL assumes that you do not care.
#
# 			Another instance where the optimizer notices that NULL and FALSE subquery results need not be
# 			distinguished is this construct:
#
# 				--- WHERE outer_expr IN (subquery)
#
# 			IN this case, the WHERE clause rejects the row whether IN (subquery) returns NULL or FALSE
#
# When either or both of those conditions do not hold, optimization is more complex.
#
# Suppose that outer_expr is known to be a non-NULL value but the subquery does not produce a row such that
# outer_expr = inner_expr 
#
# Then outer_expr IN (SELECT ---) evaluates as follows:
#
# 		) NULL, if the SELECT produces any row where inner_expr is NULL
#
# 		) FALSE, if the SELECT produces only non-NULL values or produces nothing
#
# In this situation, the approach of looking for rows with outer_expr = inner_expr is no longer valid.
#
# It is necessary to look for such rows, but if none are found, also look for rows where
# inner_expr is NULL.
#
# Roughly speaking, the subquery can be converted to something like this:
#
# 		EXISTS (SELECT 1 FROM --- WHERE subquery_where AND 
# 					(outer_expr=inner_expr OR inner_expr IS NULL))
#
# THe need to evaluate the extra IS_NULL condition is why MySQL has the ref_or_null access method:
#
# 		EXPLAIN
# 		SELECT outer_expr IN (SELECT t2.maybe_null_key
# 									 FROM t2, t3 WHERE ---)
# 		FROM t1;
#
# 		****************** 1. row *******************************
# 							id: 1
# 				select_type: PRIMARY
# 						table: t1
# 		---
# 		****************** 2. row *******************************
# 							id: 2
# 				select_type: DEPENDENT SUBQUERY
#  					table: t2
# 						 type: ref_or_null
# 			 possible_keys: maybe_null_key
# 						  key: maybe_null_key
# 					key_len : 5
# 						  ref: func
# 						rows : 2
# 					Extra   : Using where; Using index
#
# 	 	---
#
# The unique_subquery and index_subquery subquery-specific access methods also have "or NULL" variants.
#
# The additional OR --- IS NULL condition makes query execution slightly more complicated
# (and some optimizations within the subquery become inapplicable), but generally this is tolerable.
#
# The situation is much worse when outer_expr can be NULL.
#
# According to the SQL interpretation of NULL as "unknown value", NULL IN (SELECT inner_expr ---)
# should evaluate to:
#
# 		) NULL, if the SELECT produces any rows
#
# 		) FALSE, if the SELECT produces no rows
#
# For proper evaluation, it is necessary to be able to check whether the SELECT has produced any rows
# at all, so outer_expr = inner_expr cannot be pushed down into the subquery.
#
# This is a problem because many real world subqueries become very slow unless the equality can be pushed down.
#
# Essentially, there must be different ways to execute the subquery depending on the value of outer_expr
#
# The optimizer chooses SQL compliance over speed, so it accounts for the possibility that outer_expr
# might be NULL.
#
# 		) If outer_expr is NULL, to evaluate the following expression, it is necessary to execute the
# 			SELECT to determine whether it produces any rows:
#
# 			NULL IN (SELECT inner_expr FROM --- WHERE subquery_where)
#
# 			It is necessary to execute the original SELECT here, without any pushed-down equalities
# 			of the kind mentioned previously.
#
# 		) On the other hand, when outer_expr is not NULL, it is absolutely essential that this comparison:
#
# 			outer_expr IN (SELECT inner_expr FROM --- WHERE subquery_where)
#
# 			Be converted to this expression that uses a pushed-down condition:
#
# 			EXISTS (SELECT 1 FROM --- WHERE subquery_where AND outer_expr=inner_expr)
#
# 			Without this conversion, subqueries will be slow.
#
# To solve the dilemma of whether or not to push down conditions ino the subquery, the conditions
# are wrapped within "trigger" functions.
#
# Thus, an expression of the following form:
#
# 		outer_expr IN (SELECT inner_expr FROM --- WHERE subquery_where)
#
# Is converted into:
#
# 		EXISTS (SELECT 1 FROM --- WHERE subquery_where
# 										  AND trigcond(outer_expr=inner_expr))
#
# More generally, if the subquery comparison is based on several pairs of outer and inner
# expressions, the conversion takes this comparison:
#
# 		(oe_1, ---, oe_N) IN (SELECT ie_1, ---, ie_N FROM --- WHERE subquery_where)
#
# And converts it to this expression:
#
# 		EXISTS (SELECT 1 FROM --- WHERE subquery_where
# 										  AND trigcond(oe_1=ie_1)
# 										  AND ---
# 										  AND trigcond(oe_N=ie_N)
# 					)
#
# Each trigcond(X) is a special function that evaluates to the following values:
#
# 		) X when the "linked" outer expression oe_i is not NULL
#
# 		) TRUE when the "linked" outer expression oe_i is NULL
#
# 		NOTE:
# 			Trigger functions are NOT triggers of the kind that you create with CREATE_TRIGGER
#
# Equalities that are wrapped within trigcond() functions are not first class predicates for the query
# optimizer.
#
# Most optimizations cannot deal with predicates that may be turned on and off at query execution time,
# so they assume any trigcond(X) to be an unknown function and ignore it.
#
# Triggered equalities can be used by those optimizations:
#
# 		) Reference optimizations: trigcond(X=Y [OR Y IS NULL]) can be used to construct ref, eq_ref, or ref_or_null table accesses.
#
# 		) Index lookup-based subquery execution engines: trigcond(X=Y) can be used to construct unique_subquery or index_subquery accesses.
#
# 		) Table-condition generator: If the subquery is a join of several tables, the triggered condition is checked as soon as possible.
#
# When the optimizer uses a triggered condition to create some kind of index lookup-based access
# (as for the first two items of the preceding list), it must have a fallback strategy for the case
# when the condition is turned off.
#
# This fallback strategy is always the same: Do a full table scan.
#
# In EXPLAIN output, the fallback shows up as Full scan on NULL key in the Extra column:
#
# 		EXPLAIN SELECT t1.col1,
# 		t1.col1 IN (SELECT t2.key1 FROM t2 WHERE t2.col2=t1.col2) FROM t1\G
# 		********************* 1. row ***********************
#
# 							id: 1
# 				select_type: PRIMARY
# 						table: t1
# 						---
# 		********************* 2. row ************************
#
# 							id: 2
# 				select_type: DEPENDENT SUBQUERY
# 						table: t2
# 						 type: index_subquery
# 			 possible_keys: key1
# 						  key: key1
# 					key_len : 5
# 						  ref: func
# 						 rows: 2
# 					   Extra: Using where; Full scan on NULL key
#
# If you run EXPLAIN followed by SHOW_WARNINGS, you can see the triggered condition:
#
# ******************************** 1. row ******************************
# 			
# 						Level: Note
# 						 Code: 1003
# 					Message : select `test`.`t1`.`col1` AS `col1`,
# 								 <in_optimizer>(`test`.`t1`.`col1`,
# 								 <exists>(<index_lookup>(<cache>(`test`.`t1`.`col1`) in t2
# 								 on key1 checking NULL
# 								 where (`test`.`t2`.`col2` = `test`.`t1`.`col2`) having
# 								 trigcond(<is_not_null_test>(`test`.`t2`.`key1`))))) AS
# 								 `t1.col1 IN (select t2.key1 from t2 where t2.col2=t1.col2)`
# 								 from `test`.`t1`
#
# The use of triggered conditions has some performance implications.
#
# A NULL IN (SELECT ---) expression now may cause a full table scan (which is slow),
# when it previously did not.
#
# This is the price paid for correct results (the goal of the trigger-condition strategy is to
# improve compliance, not speed)
#
# For multiple-table subqueries, execution of NULL IN (SELECT ---) is particularly slow because
# the join optimizer does not optimize for the case where the outer expression is NULL.
#
# It assumes that subquery evaluations with NULL on the left side are very rare, even if
# there are statistics taht indicate otherwise.
#
# On the other hand, if the outer expression might be NULL but never actually is, there is no
# performance penalty.
#
# To help the query optimizer better execute your queries, use these suggestions:
#
# 		) Declare a column as NOT NULL if it really is.
#
# 			This also helps other aspects of the optimizer by simplifying condition testing for the column.
#
# 		) If you need not distinguish a NULL from FALSE subquery result, you can easily avoid
# 			the slow execution path.
#
# 			Replace a comparison that looks like this:
#
# 				outer_expr IN (SELECT inner_expr FROM ---)
#
# 			with this expression:
#
# 				(outer_expr IS NOT NULL) AND (outer_expr IN (SELECT inner_expr FROM ---))
#
# 			Then NULL IN (SELECT ---) is never evaluated because MySQL stops evaluating AND parts as soon
# 			as the expression result is clear.
#
# 			Another possible rewrite:
#
# 				EXISTS (SELECT inner_expr FROM ---
# 						  WHERE inner_expr=outer_expr)
#
# 			This would apply when you need not distinguish NULL from FALSE subquery results, in which case you may actually want EXISTS.
#
# The subquery_materialization_cost_based flag of the optimizer_switch system variable enables
# control over the choice between subquery materialization and IN-to-EXISTS subquery transformations.
#
# OPTIMIZING INFORMATION_SCHEMA QUERIES
#
# Applications that monitor databases may make frequent use of INFORMATION_SCHEMA tables.
# To write queries for these tables most efficiently, use the following general guidelines:
#
# 		) Try to query only INFORMATION_SCHEMA tables that are views on data dictionary tables
#
# 		) Try to query only for static metadata. Selecting columns or using retrieval conditions for dynamic metadata
# 			along with static metadata adds overhead to process the dynamic metadata.
#
# 			NOTE: 
# 				Comparison behavior for database and table names in INFORMATION_SCHEMA queries might differ from
# 				what you expect. See later in USING COLLATION IN INFORMATION SCHEMA SEARCHES
#
# These INFORMATION_SCHEMA tables are implemented as views on data dictionary tables, so queries on them
# retrieve information from the data dictionary:
#
# 		CHARACTER_SETS
# 		COLLATIONS
# 		COLLATION_CHARACTER_SET_APPLICABILITY
# 		COLUMNS
# 		EVENTS
# 		FILES
# 		INNODB_COLUMNS
# 		INNODB_DATAFILES
#
# 		INNODB_FIELDS
# 		INNODB_FOREIGN
# 		INNODB_FOREIGN_COLS
# 		INNODB_INDEXES
#
# 		INNODB_TABLES
#  	INNODB_TABLESPACES
# 		INNODB_TABLESPACES_BRIEF
# 		INNODB_TABLESTATS
#
# 		KEY_COLUMN_USAGE
# 		PARAMETERS
# 		PARTITIONS
# 		REFERENTIAL_CONSTRAINTS
#
# 		RESOURCE_GROUPS
# 		ROUTINES
# 		SCHEMATA
# 		STATISTICS
# 		TABLES
# 
# 		TABLE_CONSTRAINTS
# 		TRIGGERS
# 		VIEWS
# 		VIEW_ROUTINE_USAGE
# 		VIEW_TABLE_USAGE
#
# Some types of values, even for a non-view INFORMATION_SCHEMA table, are
# retrieved by lookups from the data dictionary.
#
# This includes values such as database and table names, table types, and storage engines.
#
# Some INFORMATION_SCHEMA tables contain columns that provide table statitics:
#
# 		STATISTICS.CARDINALITY
# 		TABLES.AUTO_INCREMENT
# 		TABLES.AVG_ROW_LENGTH
# 		TABLES.CHECKSUM
# 
# 		TABLES.CHECK_TIME
# 		TABLES.CREATE_TIME
# 		TABLES.DATA_FREE
# 		TABLES.DATA_LENGTH
#
# 		TABLES.INDEX_LENGTH
# 		TABLES.MAX_DATA_LENGTH
# 		TABLES.TABLE_ROWS
# 		TABLES.UPDATE_TIME
#
# Those columns represent dynamic table metadata; that is, information that changes as table contents change.
#
# By default, MySQL retrieves cached values for those columns from the mysql.index_stats and mysql.table_stats
# dictionary tables when the columns are queried, which is more efficient than retrieving statistics directly
# from the storage engine.
#
# If cached statistics are not available or have expired, MySQL retrieves teh latest statistics
# from the storage engine and caches them in the mysql.index_stats and mysql.table_stats dictionary tables.
#
# Subsequent queries retrieve the cached statistics until the cached statistics expire.
#
# The information_schema_stats_expiry session variable defines the period of time before cached statistics expire.
# The default is 86400 (24 hours), but the time period can be extended to as much as one year.
#
# To update cached values at any time for a given table, use ANALYZE_TABLE
#
# Querying statitics columns does not store or update statistics in the mysql.index_stats and
# mysql.table_stats dictionary table under these circumstances:
#
# 		) When cached statistics have not expired
#
# 		) When information_schema_stats_expiry is set to 0
#
# 		) When the server is started in read_only, super_read_only, transaction_read_only or innodb_read_only mode.
#
# 		) When the query also fetches Performance Schema data
#
# information_schema_stats_expiry is a session variable, and each client session can define its own expiration value.
# Statistics that are retrieved from the storage engine and cached by one session are available to other sessions.
#
# NOTE:
#
# 		If the innodb_read_only system variable is enabled, ANALYZE_TABLE may fail because it cannot update statistics tables
# 		in the data dictionary, which use InnoDB.
#
# 		For ANALYZE_TABLE operations that update the key distribution, failure may occur even if the operation
# 		updates the table itself (for example, if it is a MyISAM table)
#
# 		To obtain the updated distribution statistics, set information_schema_stats_expiry=0
#
# For INFORMATION_SCHEMA tables implemented as views on data dictionary tables, indexes on the underlying
# data dictionary tables permit the optimizer to construct efficient query execution plans.
#
# To see the choices made by the optimizer, use EXPLAIN
#
# To also see the query used by the server to execute an INFORMATION_SCHEMA query,
# use SHOW_WARNINGS immediately following EXPLAIN.
#
# Consider this statement, which identifies collations for the utf8mb4 character set:
#
# 		SELECT COLLATION_NAME
# 		FROM INFORMATION_SCHEMA.COLLATION_CHARACTER_SET_APPLICABILITY
# 		WHERE CHARACTER_SET_NAME = 'utf8mb4';
# 		+--------------------------------------+
# 		| COLLATION_NAME 							   |
# 		+--------------------------------------+
# 		| utf8mb4_general_ci 						|
# 		| utf8mb4_bin 								   |
# 		| utf8mb4_unicode_ci 						|
# 		| utf8mb4_icelandic_ci 					   |
# 		| utf8mb4_latvian_ci 						|
# 		| utf8mb4_romanian_ci 						|
# 		| utf8mb4_slovenian_ci 						|
# 		---
#
# How does the server process that statement? To find out, use EXPLAIN
#
# EXPLAIN SELECT COLLATION_NAME
# FROM INFORMATION_SCHEMA.COLLATION_CHARACTER_SET_APPLICABILITY
# WHERE CHARACTER_SET_NAME = 'utf8mb4'\G
# ********************************* 1. row **************************************
# 		
# 								id: 1 
# 					select_type: SIMPLE
# 							table: cs
# 					partitions : NULL
# 							 type: const
# 				 possible_keys: PRIMARY, name
# 				 			  key: name
# 						key_len : 194
# 							  ref: const
# 							rows : 1
# 						filtered: 100.00
# 							Extra: Using index
# ********************************* 2. row ***************************************
#
# 								id: 1
# 					select_type: SIMPLE
# 							table: col
# 					partitions : NULL
# 							type : ref
# 				 possible_keys: character_set_id
# 				 			  key: character_set_id
# 						 key_len: 8
# 							  ref: const
# 						    rows: 68
# 						filtered: 100.00
# 							Extra: NULL
# 2 rows in set, 1 warning (0.01 sec)
#
# To see the query used to satisfy that statement, use SHOW_WARNINGS:
#
# SHOW WARNINGS\G
# ******************************** 1. row ******************************************
#
# 		Level: Note
# 		Code : 1003
# 	Message : /* select#1 */ select `mysql`.`col`.`name` AS `COLLATION_NAME`
# 				 from `mysql`.`character_sets` `cs`
# 				 join `mysql`.`collations` `col`
# 				 where ((`mysql`.`col`.`character_set_id` = '45')
# 				 and ('utf8mb4' = 'utf8mb4'))
#
# As indicated by SHOW_WARNINGS, the server handles the query on COLLATION_CHARACTER_SET_APPLICABILITY
# as a query on the character_sets and collations data dictionary table in the mysql system database.
#
# OPTIMIZING PERFORMANCE SCHEMA QUERIES
#
# Applicatons that monitor databases may make frequent use of Performance Schema tables.
# To write queries for these tables most efficiently, take advantage of their indexes.
#
# For example, include a WHERE clause that restricts retrieved rows based on comparison
# to specific values in an indexed column.
#
# Most Performance Schema tables have indexes. Tables that do not are those that normally contain
# few rows or are unlikely to be queried frequently.
#
# Performance Schema indexes give the optimizer access to execution plans otehr than full table scans.
#
# These indexes also improve performance for related objects, such as sys schema views that
# use those tables.
#
# To see whether a given Performance Schema table has indexes and what they are, use SHOW_INDEX or
# SHOW_CREATE_TABLE:
#
# 		SHOW INDEX FROM performance_schema.accounts\G
# 		******************************** 1. row ****************************
# 
# 									Table: accounts
# 							Non_unique : 0
# 							 Key_name  : ACCOUNT
# 						Seq_in_index  : 1
# 							Column_name: USER
# 							  Collation: NULL
# 							Cardinality: NULL
# 							  Sub_part : NULL
# 							 	Packed  : NULL
# 								  Null  : YES
# 							Index_type : HASH
# 							 	Comment :
# 						 Index_comment:
#  							Visible : YES
#
# 		******************************** 2. row *****************************
#
# 									Table: accounts
# 							 Non_unique: 0
#  						  Key_name : ACCOUNT
# 						  Seq_in_index: 2
# 							Column_name: HOST
# 							  Collation: NULL
# 							Cardinality: NULL
# 								Sub_part: NULL
# 								  Packed: NULL
# 								    Null: YES
# 							Index_type : HASH
# 								Comment : 
# 						 Index_comment: 
# 								Visible : YES
#
# 		SHOW CREATE TABLE performance_schema.rwlock_instances\G
# 		******************************* 1. row *******************************
# 						
# 									Table: rwlock_instances
# 						  Create Table: CREATE TABLE `rwlock_instances` (
# 							 `NAME` varchar(128) NOT NULL,
# 							 `OBJECT_INSTANCE_BEGIN` bigint(20) unsigned NOT NULL,
# 							 `WRITE_LOCKED_BY_THREAD_ID` bigint(20) unsigned DEFAULT NULL,
# 							 `READ_LOCKED_BY_COUNT` int(10) unsigned NOT NULL,
# 							PRIMARY KEY (`OBJECT_INSTANCE_BEGIN`),
# 							KEY `NAME` (`NAME`),
# 							KEY `WRITE_LOCKED_BY_THREAD_ID` (`WRITE_LOCKED_BY_THREAD_ID`)
# 						) ENGINE=PERFORMANCE_SCHEMA DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci
#
# TO see the execution plan for a Performance Schema query and whether it uses any indexes, use EXPLAIN:
#
# EXPLAIN SELECT * FROM performance_schema.accounts WHERE (USER,HOST) = ('root', 'localhost')\G
# ***************************** 1. row ***************************
#
# 							id: 1
# 				select_type: SIMPLE
# 						table: accounts
# 				 partitions: NULL
# 						type : const
# 			possible_keys : ACCOUNT
# 						 key : ACCOUNT
# 					key_len : 278
# 					     ref: const,const
# 						 rows: 1
# 					filtered: 100.00
# 					Extra   : NULL
#
# The EXPLAIN output indicates that hte optimizer uses the accounts table ACCOUNT index that
# comprises the USER and HOST columns.
#
# Performance Schema indexes are virtual: They are a construct of the Performance Schema storage engine
# and use no memory or disk storage.
#
# The Performance Schema reports index information to the optimizer so that it can construct efficient 
# execution plans.
#
# The Performance Schema in turn uses optimizer information about what to look for (for example, a particular key value)
# , so that it can perform efficient lookups without building actual index structures.
#
# This implementation provides two important benefits:
#
# 		) It entirely avoids the maintenance cost normally incurred for tables that undergo frequent updates.
#
# 		) It reduces at an early stage of query execution the amount of data retrieved.
#
# 			For conditions on the indexed columns, the Performance Schema efficiently returns only
# 			table rows that satisfy the query conditions.
#
# 			Without an index, the Performance Schema would return all rows in the table, requiring that
# 			the optimizer later evaluate the conditions against each row to produce the final result.
#
# Performance Schema indexes are predefined and cannot be dropped, added or altered.
#
# Performance Schema indexes are similar to hash indexes. For example:
#
# 		) They are used only for equality comparisons that use the = or <=> operators.
#
# 		) They are unordered. If a query result must have specific row ordering characteristics, include an ORDER BY clause.
#
# For additional information about hash indexes, see later.
#
# OPTIMIZING DATA CHANGE STATEMENTS
#
# This section explains how to speed up data change statements: INSERT, UPDATE and DELETE.
#
# Traditional OLTP applications and modern web applications typically do many small data change operations,
# where concurrency is vital.
#
# Data analysis and reporting applications typically run data change operations that affect many rows
# at once, where the main consideration is the I/O to write large amounts of data and keep indexes up-to-date.
#
# For inserting and updating large volumes of data (known in teh industry as ETL, or "extract-transform-load"),
# sometimes you use other SQL statements or external commands, that mimic the effects of INSERT, UPDATE and DELETE statements.
#
# OPTIMIZING INSERT STATEMENTS
#
# To optimize insert speed, combine many operations into a single large operation.
#
# Ideally, you make a single connection, send the data for many new rows at once, and
# delay all index updates and consistency checking until the very end.
#
# The time required for inserting a row is determined by the following factors, where the numbers indicate
# approximate proportions:
#
# 		) Connecting: (3)
#
# 		) Sending query to the server: (2)
#
# 		) Parsing query: (2)
#
# 		) Inserting row: (1 * size of row)
#
# 		) Inserting indexes: (1 * number of indexes)
#
# 		) Closing: (1)
#
# This does not take into consideration the initial overhead to open tables, which is done once for each
# concurrently running query.
#
# The size of the table slows down the insertion if indexes by log N, assuming B-tree indexes.
#
# You can use the following methods to speed up inserts:
#
# 		) If you are inserting many rows from the same client at the same time, use INSERT statements with multiple
# 			VALUES lists to insert several rows at a time.
#
# 			This is considerably faster (many times faster in some cases) than using separate single-row INSERT
# 			statements.
#
# 			If you are adding data to a nonempty table, you can tune the bulk_insert_buffer_size variable to make
# 			data insertion even faster. See earlier.
#
# 		) When loading a table from a text file, use LOAD_DATA_INFILE. This is usually 20x faster than using INSERT statements.
# 			More later on the LOAD DATA INFILE syntax.
#
# 		) Take advantage of the fact that columns have default values.
#
# 			Insert values explicitly only when the value to be inserted differs from the default.
# 			THis reduces the parsing that MySQL must do and improves the insert speed.
#
# 		) See more later for bulk inserts in relation to InnoDB and MyISAM tables.
#
# OPTIMIZING UPDATE STATEMENTS
#
# An update statement is optimized like a SELECT query with the additional overhead of a write.
#
# The speed of the write depends on teh amount of data being updated and the number of indexes
# that are updated. Indexes that are not changed do not get updated.
#
# Another way to get fast updates is to delay updates and then do many updates in a row later.
#
# Performing multiple updates togetehr is much quicker than doing one at a time if you lock the table.
#
# For a MyISAM table that uses dynamic row format, updating a row to a longer total length may split the
# row.
#
# If you do this often, it is very important to use OPTIMIZE_TABLE ocassionally. 
#
# See more on the syntax of OPTIMIZE TABLE later.
#
# OPTIMIZING DELETE STATEMENTS
#
# The time required to delete individual rows in a MyISAM table is exactly proportional 
# to the number of indexes.
#
# To delete rows more quickly, you can increase the size of the key cache by increasing the
# key_buffer_size system variable.
#
# To delete all rows from a MyISAM table, TRUNCATE TABLE tbl_name is faster than DELETE FROM tbl_name.
#
# Truncate operations are not transaction-safe; an error occurs when attempting one in the course
# of an active transaction or active table lock.
#
# See more later on TRUNCATE TABLE syntax.
#
# OPTIMIZING DATABASE PRIVILEGES
#
# The more complex your privilege setup, the more overhead applies to all SQL statements.
#
# SImplifying the privileges established by GRANT statements enables MysQL to reduce permission-checking
# overhead when clients execute statements.
#
# For example, if you do not grant any table-level or column-level privileges, the server need not
# ever check the contents of the tables_priv and columns_priv tables.
#
# Similarly, if you place no resource limits on any accounts, the server does not have to
# perform resource counting.
#
# If you have a very high statement-processing load, consider using a simplified grant structure
# to reduce permission-checking overhead.
#
# OTHER OPTIMIZATION TIPS
#
# THis section lists a number of misc tips for improving query processing speed:
#
# 		) If your application makes several DB requests to perform related updates, combining
# 			the statements into a stored routine can help performance.
#
# 			Similarly, if your application computes a single result based on several columns values
# 			or large volumes of data, combining the computation into a UDF (user-defined function)
# 			can help performance.
#
# 			The resulting fast DB operations are then available to be reused by other queries,
# 			applications and even code written in different languages.
#
# 			More on this, USING STORED ROUTINES (PROCEDURES AND FUNCTIONS) and ADDING NEW FUNCTIONALITY TO MYSQL later.
#
# 		) To fix any compression issues that occur with ARCHIVE tables, use OPTIMIZE_TABLE. More later in THE ARCHIVE STORAGE ENGINE
#
# 		) If possible, classify reports as "live" or "statistical", where data needed for statistical reports is created
# 			only from summary tables that are generated periodically from the live data.
#
# 		) If you have data that does not conform well to a rows-and-columns table structure, you can pack
# 			and store data into a BLOB column.
#
# 			In this case, you must provide code in your application to pack and unpack information,
# 			but this might save I/O operations to read and write the sets of related values
#
# 		) With Web servers, store images and other binary assets as files, with the path name stored
# 			in the database rather than the file itself.
#
# 			Most web servers are better at caching files than DB contents, so using files is
# 			generally faster. (Although you must handle backups and storage issues yourself
# 			in this case)
#
# 		) If you need really high speed, look at the low-level MySQL interfaces.
#
# 			For example, by accessing the MySQL InnoDB or MyISAM storage engine directly,
# 			you could get a substansial speed increase compared to using the SQL interface.
#
# 		) Replication can provide a performance benefit for some operations.
#
# 			You can distribute client retrievals among replication servers to
# 			split up the load.
#
# 			To avoid slowing down the master while making backups, you can make
# 			backups using a slave server. More later on REPLICATION.
#
# OPTIMIZATION AND INDEXES
#
# The best way to improve performance of SELECT operations is to create indexes
# on one or more of the columns that are tested in the query.
#
# The index entries act like pointers to the table rows, allowing the query to
# quickly determine which rows match a condition in the WHERE clause, and retrieve
# the other column values for those rows.
#
# All MySQL data types can be indexed.
#
# although it can be tempting to create an index for every possible column used
# in a query, unecessary indexes waste space and time for MySQL to determine which
# indexes to use.
#
# Indexes also add to the cost of inserts, updates and deletes, because each index
# must be updated.
#
# You must find the right balance to achieve fast queries using the optimal set of
# indexes.
#
# HOW MYSQL USES INDEXES
#
# Indexes are used to find rows with specific column values quickly.
#
# Without an index, MySQL must begin with the first row and then read through
# the entire table to find the relevant rows.
#
# The larger the table, the more this costs.
#
# If the table has an index for the columns in question, MySQL can quickly
# determine the position to seek to in the middle of the data file
# without having to look at all the data.
#
# This is much faster than reading every row sequentially.
#
# Most MySQL indexes (PRIMARY KEY, UNIQUE INDEX and FULLTEXT) are stored in B-trees.
# (More on thoose later)
#
# Exceptions: Indexes on spatial data types use R-trees; MEMORY tables also support
# hash indexes; InnoDB uses inverted lists for FULLTEXT indexes.
#
# In general, indexes are used as described in teh following discussion.
#
# Characteristics specific to hash indexes (as used in MEMORY tables) are described
# in a later section, COMPARISON OF B-TREE AND HASH INDEXES
#
# MySQL uses indexes for these operations:
#
# 		) To find the rows matching a WHERE clause quickly.
#
# 		) TO eliminate rows from consideration. If there is a choice between
# 			multiple indexes, MySQL normally uses the index that finds the smallest number of rows.
# 			(The most slective index)
#
# 		) If the table has multiple-column index, any leftmost prefix of the index can be used by
# 			the optimizer to look up rows.
#
# 			For example, if you have a three-column index on (col1, col2, col3), you have indexed 
# 			search capabilities on (col1), (col1, col2), and (col1, col2, col3)
#
# 			For more info on this, it is covered later in MULTIPLE COLUMN INDEXES
#
# 		) TO retrieve rows from other tables when performing joins, MySQL can use indexes
# 			on columns more effectively if they are declared as the same type and size.
#
# 			In this context, VARCHAR and CHAR are considered the same if they are declared
# 			as the same size.
#
# 			For example, VARCHAR(10) and CHAR(10) are the same size, but VARCHAR(10)
# 			and CHAR(15) are not.
#
# 			For comparisons between nonbinary string columns, both columns should use the same
# 			character set.
#
# 			For example, comparing a utf8 column with a latin1 column precludes use of an index.
#
# 			Comparison of dissimilar columns (comparing a string column to a temporal or numeric column,
# 			for example) - may prevent use of indexes if values cannot be compared directly
# 			without conversion.
#
# 			For a given value such as 1 in the numeric column, it might compare equal to any number
# 			of values in the string column such as '1', '1', '00001', or '01.e1'
#
# 			THis rules out use of any indexes for the string column.
#
# 		) To find the MIN() or MAX() value for a specified indexed column key_col.
# 			This is optimized by a preprocessor that checks whether you are using WHERE
# 			key_part_N = constant on all key parts that occur before key_col in the index.
#
# 			In this case, MysQL does a single key lookup for each MIN() or MAX() expression
# 			and replaces it with a constant.
#
# 			If all expressions are replaced with constants, the query returns at once.
#
# 			For example:
#
# 			SELECT MIN(key_part2), MAX(key_part2)
# 				FROM tbl_name WHERE key_part1=10;
#
# 		) To sort or group a table if the sorting or grouping is done on a leftmost prefix
# 			of a usable index (for example, ORDER BY key_part1, key_part2)
#
# 			If all key parts are followed by DESC, the key is read in reverse order.
#
# 			(Or, if the index is a descending index, the key is read in forward order)
#
# 			see earlier optimizations and more later in DESCENDING INDEXES
#
# 		) In some cases, a query can be optimized to retrieve values without consulting the 
# 			data rows. 
#
# 			(An index that provides all the necessary results for a query is called a
# 			covering index).
#
# 			If a query uses from a table only columns that are included in some index,
# 			the selected values can be retrieved from the index tree for greater speed:
#
# 				SELECT key_part3 FROM tbl_name
# 					WHERE key_part1=1;
#
# Indexes are less important for queries on small tables, or big tables where report queries process most
# or all of the rows.
#
# When a query needs to access most of the rows, reading sequentially is faster than working through an index.
#
# Sequential reads minimize disk seeks, even if not all the rows are needed for the query.
#
# SEe more in AVOIDING FULL TABLE SCANS
#
# PRIMARY KEY OPTIMIZATION
#
# The primary key for a table represents the column or set of columns that you use
# in your most vital queries.
#
# It has an associated index, for fast query performance.
#
# Query performance benefits from the NOT NULL optimization, because it cannot include any
# NULL values.
#
# With the InnoDB storage engine, the table data is physically organized to do ultra-fast
# lookups and sorts based on the primary key column or columns.
#
# If your table is big n important, but does not have an obvious column or set of columns
# to use as a primary key, you might create a separate column with auto-increment values to
# use as the primary key.
#
# These unique IDs can serve as pointers to corresponding rows in other tables when you
# join tables using foreign keys.
#
# SPATIAL INDEX OPTIMIZATION
#
# MySQL permits creation of SPATIAL indexes on NOT NULL geometry-valued columns (more later in CREATING SPATIAL INDEXES).
# 
# The optimizer checks the SRID attribute for indexed columns to determine which spatial reference system (SRS)
# to use for comparisons, and uses calculations appropriate to the SRS.
#
# (< 8.0, the optimizer performs comparisons of SPATIAL index values using Cartesian calculations; the result of such
# 	operations are undefined if the column contains values with non-Cartesian SRIDs)
#
# For comparisons to work properly, each column in a SPATIAL index must be SRID-restricted.
#
# That is, the column definition must include an explicit SRID attribute, and all column
# values must have the same SRID.
#
# The optimizer considers SPATIAL indexes only for SRID-restricted columns:
#
# 		) Indexes on columns restricted to a Cartesian SRID enable Cartesian bounding box computations.
#
# 		) Indexes on columns restricted to a geographic SRID enable geographic bounding box computations.
#
# The optimizer ignores SPATIAL indexes on columns that have no SRID attribute (and thus are not SRID-restricted).
# MySQL still maintains such indexes, as follows:
#
# 		) They are updated for table modifications (INSERT, UPDATE, DELETE and so forth).
#
# 			Updates occur as though the index was Cartesian, even though the column might contain
# 			a mix of Cartesian and geographical values.
#
# 		) They exist only for backward compatibility; for example, the ability to perform a dump in MySQL
# 			5.7 and restore in MySQL 8.0.
#
# 			Because SPATIAL indexes on columns that are not SRID-restricted are of no use to the optimizer,
# 			each such column should be modified:
#
# 				) Verify that all values within the column have the same SRID.
#
# 					To determine the SRIDs contained in a geometry column col_name, use
# 					the following query:
#
# 						SELECT DISTINCT ST_SRID(col_name) FROM tbl_name;
#
# 					If the query returns more than one row, the column contains a mix of SRIDs.
# 					In that case, modify its contents so all values have the same SRID.
#
# 				) Redefine the column to have an explicit SRID attribute.
#
# 				) Recreate the SPATIAL index.
#
# FOREIGN KEY OPTIMIZATION
#
# If a table has many columns, and you query many different combinations of columns,
# it might be efficient to split the less-frequently used data into separate tables
# with a few columns each, and relate them back to the main table by duplicating the
# numeric ID column from the main table.
#
# That way, each small table can have a primary key for fast lookups of its data,
# and you can query just the set of columns that you need using a join operation.
#
# Depending on how the data is distributed, the queries might perform less I/O
# and take up less cache memory because the relevant columns are packed together
# on disk.
#
# (To maximize performance, queries try to read as few data blocks as possible
# from disk; tables with only a few columns can fit more rows in each data block.)
#
# COLUMN INDEXES
#
# The most common type of index involves a single column, storing copies of the values from
# that column in a data structure, allowing fast lookups for the rows with the corresponding
# column values.
#
# The B-Tree data structure lets the index quickly find a specific value, a set of values,
# or a range of values, corresponding to operators such as =, >, <, BETWEEN, IN and so on,
# in a WHERE clause.
#
# THe maxium number of indexes per table and maximum index length is defiend per storage engine.
#
# See more in THE INNODB STORAGE ENGINE and ALTERNATIVE STORAGE ENGINES
#
# All storage engines support at least 16 indexes per table and a total index length
# of at least 256 bytes.
#
# Most storage engines have higher limits.
#
# For more info on column indexes, more later in CREATE INDEX SYNTAX
#
# INDEX PREFIXES
#
# With col_name(N) syntax in a index specification for a string column, you can create
# an index that uses only the first N characters of the column.
#
# INdexing only a prefix of column values in this way can make the index file much smaller.
#
# When you index a BLOB or TEXT column, you MUST specify a prefix length for the index.
# For example:
#
# 		CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10)));
#
# Prefixes can be up to  767 bytes long for InnoDB tables that use the REDUNDANT and COMPACT row format.
#
# The prefix length limit is 3072 bytes for InnoDB tables that use the DYNAMIC or COMPRESSED row format.
# For MyISAM tables, the prefix length limit is 1000 bytes.
#
# NOTE:
#
# 		Prefix limits are measured in bytes, whereas the prefix length in CREATE_TABLE, ALTER_TABLE
# 		and CREATE_INDEX statements is interpreted as number of characters for nonbinary string types
# 		(CHAR, VARCHAR, TEXT) and number of bytes for binary string types (BINARY, VARBINARY, BLOB)
#
# 		Take this into account when speicfying a prefix length ofr a nonbinary string column
# 		that uses a multibyte character set.
#
# For additional info about index prefixes, more later in CREATE INDEX SYNTAX
#
# FULLTEXT INDEXES
#
# FULLTEXT indexes are used for full-text searches. Only the InnoDB and MyISAM storage engines
# support FULLTEXT indexes and only for CHAR, VARCHAR, and TEXT columns.
#
# Optimizations are applied to certain kinds of FULLTEXT queries against single InnoDB tables.
# Queries with these characteristics are particularly efficient:
#
# 		) FULLTEXT queries that only return the document ID or the document ID and the search rank.
#
# 		) FULLTEXT queries that sort the matching rows in descending order of score and apply a LIMIT
# 			clause to take the top N matching rows.
#
# 			For this optimization to apply, there must be no WHERE clauses and only a single ORDER BY
# 			clause in desc. order
#
# 		) FULLTEXT queries that retrieve only the COUNT(*) value of rows matching a search term, with no additional
# 			WHERE clauses.
#
# 			Code the WHERE clauses as WHERE MATCH(text) AGAINST ('other_text), without any > 0 comparison operator.
#
# For queries that contain full-text expressions, MySQL evluates those expressions during the optimization
# phase of query execution.
#
# THe optimizer does not just look at full-text expressions and make estimates, it actually evaluates them
# in the process of developing an execution plan.
#
# An implication of this behavior is that EXPLAIN for full-text queries is typically slower
# than for non-full-text queries for which no expression evaluation occurs during the optimization phase.
#
# EXPLAIN for full-text queries may show Select tables optimized away in the Extra column due
# to matching occurring during optimization, in this case, no table access need occur during
# later execution.
#
# SPATIAL INDEXES
#
# You can create indexes on spatial data types.
# MyISAM and InnoDB support R-Tree indexes on spatial types.
#
# Other storage engines use B-trees for indexing spatial types
# (except for ARCHIVE, which does not support spatial type indexing)
#
# INDEXING IN THE MEMORY STORAGE ENGINE
#
# The MEMORY storage engine uses HASH indexes by default, but also supports
# BTREE indexes.
#
# MULTIPLE-COLUMN INDEXES
#
# MySQL can create composite indexes (that is, indexes on multiple columns).
#
# An index may consist of up to 16 columns. For certain data types, you can index a prefix
# of the column (see earlier)
#
# MySQL can use multiple-column indexes fore queries that test all the columns in teh index,
# or queries that test just the first column, the first two columns, the first three
# columns, etc.
#
# IF you specify the columns in the right order in the index definition, a single composite
# index can speed up several kinds of queries on the same table.
#
# A multiple-column index can be considered a sorted array, the rows of which contain values
# that are created by concatenating the values of the indexed columns.
#
# NOTE:
#
# 		As an alternative to a composite index, you can introduce a column that is "hashed" based
# 		on information from other columns.
#
# 		If this column is short, reasonably unique and indexed, it might be faster than a "wide"
# 		index on many columns.
#
# 		In MysQL, it is very easy to use this extra column:
#
# 			SELECT * FROM tbl_name
# 				WHERE hash_col=MD5(CONCAT(val1,val2))
# 				AND col1=val1 AND col2=val2;
#
# SUppose that a table has the following specification:
#
# 		CREATE TABLE test (
# 			id 		INT NOT NULL,
# 			last_name CHAR(30) NOT NULL,
# 			first_name CHAR(30) NOT NULL,
# 			PRIMARY KEY (id),
# 			INDEX name (last_name, first_name)
# 		);
#
# The name index is an index over the last name and first name columns.
#
# The index can be used for lookups in queries that specifies values in a known range for 			
# combinations of last_name and first_name values.
#
# It can also be used for queries that specify just a last name value because the column
# is a leftmost prefix of the index (as described later here).
#
# Therefore, teh name index is used for lookups in the following queries:
#
# 		SELECT * FROM test WHERE last_name='Widenius';
#
# 		SELECT * FROM test
#			WHERE last_name='Widenius' AND first_name='Michael';
#
# 		SELECT * FROM test
# 			WHERE last_name='Widenius'
# 			AND (first_name='Michael' OR first_name='Monty');
#
# 		SELECT * FROM test
# 			WHERE last_name='Widenius'
# 			AND first_name >= 'M' AND first_name < 'N';
#
# However, the name index is NOT used for lookups in the following queries:
#
# 		SELECT * FROM test WHERE first_name='Michael';
#
# 		SELECT * FROM test
# 			WHERE last_name='Widenius' OR first_name='Michael';
#
# Suppose that you issue the following SELECT statement:
#
# 		SELECT * FROM tbl_name
# 			WHERE col1=val1 AND col2=val2;
#
# If a multiple-column index exists on col1 and col2, the appropriate rows can be fetched directly.
#
# If separate single-column indexes exist on col1 and col2, the optimizer attempts to use
# the Index Merge optimization (SEE INDEX MERGE OPTIMIZATION), or attempts to find the most
# restrictive index by deciding which index excludes more rows and using that index to 
# fetch the rows.
#
# If the table has a multiple-column index, any leftmost prefix of the index can be used by the
# optimizer to look up rows.
#
# For example, if you have a three-column index on (col1, col2, col3), you have indexed search
# capabilities on (col1), (col1, col2) and (col1, col2, col3)
#
# MysQL cannot use the index to perform lookups if the columns do not form a leftmost prefix of the index.
# Suppose that you have the SELECT statements shown here:
#
# 		SELECT * FROM tbl_name WHERE col1=val1;
# 		SELECT * FROM tbl_name WHERE col1=val1 AND col2=val2;
#
# 		SELECT * FROM tbl_name WHERE col2=val2;
# 		SELECT * FROM tbl_name WHERE col2=val2 AND col3=val3;
#
# If an index exists on (col1, col2, col3), only the first two queries use the index.
#
# The first and fourth queries do involve indexes columns, but do not use an index to
# perform lookups because (col2) and (col2, col3) are not leftmost prefixes of (col1, col2, col3)
#
# VERIFYING INDEX USAGE
#
# Always check whether all your queries really use the indexes that you have created in the
# tables.
#
# Use the EXPLAIN statement, as described in OPTIMIZING QUERIES WITH EXPLAIN
#
# INNODB AND MYISAM INDEX STATISTICS COLLECTION
#
# Storage engines collect statitics about tables for use by the optimizer.
#
# Table statistics are based on value groups, where a value group
# is a set of rows with the same key prefix value.
#
# For optimizer purposes, an important statistic is the average value group size.
#
# MySQL uses the average value group size in the following ways:
#
# 		) To estimate how many rows must be read for each ref access.
#
# 		) To estimate how many rows a partial join will produce; that is,
# 			the number of rows that an operation of this form will produce:
#
# 				(---) JOIN tbl_name ON tbl_name.key = expr
#
# As the average value group size for an index increases, the index is less useful
# for those two purposes because the average number of rows per lookup increases:
#
# 		For the index to be good for optimization purposes, it is best that each index
# 		value target a small number of rows in the table.
#
# When a given index value yields a large number of rows, the index is less useful and
# MySQL is less likely to use it.
#
# The average value group size is related to the table cardinality, which is the number
# of value groups.
#
# The SHOW_INDEX statement displays a cardinality value based on N/S, where N is the number
# of rows in the table and S is the average value group size.
#
# That ratio yields the approximate number of value groups in the table.
#
# For a join based on the <=> comparison operator, NULL is not treated differently
# from any other value:
#
# 	NULL <=> NULL, just as N <=> N for any other N.
#
# However, for a join based on the operator of =, NULL is different from non-NULL values:
# 
# 		expr1 = expr2 is not true when expr1 or expr2 (or both) are NULL.
#
# This affects ref accesses for comparisons of the form tbl_name.key = expr:
# MySQL will not access the table if the current value of expr is NULL, because the comparison
# cannot be true.
#
# FOr = comparisons, it does not matter how many NULL values are in the table.
#
# For optimizaton purposes, the relevant value is the average size of the non-NULL value
# groups.
#
# However, MySQL does not currently enable that average size to be collected or used.
#
# For InnoDB and MyISAM tables, you have some control over collection of table stats by means
# of the innodb_stats_method and myisam_stats_method system variables, respectively.
#
# These variables have three possible values, which differ as follows:
#
# 		) When the variable is set to nulls_equal, all NULL values are treated as identical
# 			(that is, they all form a single value group)
#
# 			If the NULL value group size is much higher than the average non-NULL value group size,
# 			this method skews the average value group size upwards.
#
# 			This makes index appear to be the optimizer to be less useful than it really is for joins
# 			that look for non-NULL values.
#
# 			Consequently, the nulls_equal method may cause the optimizer not to use the index
# 			for ref accesses when it should.
#
# 		) When the variable is set to nulls_unequal, NULL values are not considered the same.
#
# 			Instead, each NULL value forms a separate value group of size 1.
#
# 			If you have many NULL values, this method skews the avg. value group downwards.
#
# 			If the average non-null value group size is large, counting NULL values each as a 
# 			group size of 1 causes the optimizer to overestimate the value of the index for joins
# 			that look for non-NULL values.
#
# 			Conseuqently, the nulls_unequal method may cause the optimizer to use this index
# 			for ref lookups when other methods may be beter.
#
# 		) When the variable is set to nulls_ignored, NULL values are ignored.
#
# If you tend to use many joins that use <=> rather than =, NULL values are not special
# in comparisons and one NULL is equal to another.
#
# IN this case, nulls_equal is the appropriate statistics method.
#
# The innodb_stats_method system variable has a global value; the myisam_stats_method
# system variable has both global and session values.
#
# Setting the global value affects statistics collection for tables from the corresponding
# storage engine.
#
# Setting the sesison value affects statistics collection only for the current client connection.
#
# THis means that you can force a tables statistics to be regenerated with a given method without
# affecting other clients by setting the session value of myisam_stats_method
#
# To regenerate MyISAM table statistics, you can use any of the following methods:
#
# 		) Execute myisamchk --stats_method=method_name --analyze
#
# 		) Change the table to cause its statistics to go out of date (for example, insert a row
# 			and then delete it), and then set myisam_stats_method and issue an ANALYZE_TABLE statement.
#
# Some caveats regarding the use of innodb_stats_method and myisam_stats_method:
#
# 		) You can force table statistics to be collected explicitly, as just described.
#
# 			However, MysQL may also collect statistics autoamtically.
#
# 			FOr example, if during the course of executing statements for a table, some of
# 			those statements modify teh table, MySQL may collect statistics.
#
# 		(This may occur for bulk inserts or deletes, or some ALTER_TABLE statements, for example)
#
# 			If this happens, the statistics are collected using whatever value innodb_stats_method
# 			or myisam_stats_method has at the time.
#
# 			Thus, if you collect statistics using one method, but the system variable is set to
# 			the other method when a table's statistics are collected automatically later, the other
# 			method will be used.
#
# 		) There is no way to tell which method was used to generate statitics for a given table.
#
# 		) These variables apply only to InnoDB and MyISAM tables.
#
# 			Other storage engines have only one method for collecting table statistics.
# 			Usually it is closer to the nulls_equal method.
#
# COMPARISON OF B-TREE AND HASH INDEXES
#
# Understanding the B-Tree and hash data structures can help predict how different queries perform
# on different storage engines that use these data structures in their indexes, particularly
# for the MEMORY storage engine that lets you choose B-tree or hash indexes.
#
# B-TREE INDEX CHARACTERISTICS
#
# A B-tree index can be used for column comparisons in expressions that use the =, >, >=, <=, or BETWEEN
# operators.
#
# The index also can be used for LIKE comparisons if the argument to LIKE is a constant string that
# does not start with a wildcard character.
#
# For example, the following SELECT statements use indexes:
#
# 		SELECT * FROM tbl_name WHERE key_col LIKE 'Patrick%';
# 		SELECT * FROM tbl_name WHERE key_col LIKE 'Pat%_ck%';
#
# In the first statement, only rows with 'Patrick' <= key_col <= 'Patricl' are considered.
# IN the second statement, only rows with 'Pat' <= key_col 'Pau' are considered.
#
# The following SELECT statements do NOT use indexes:
#
# 		SELECT * FROM tbl_name WHERE key_col LIKE '%Patrick%';
# 		SELECT * FROM tbl_name WHERE key_col LIKE other_col;
#
# IN the first statement, the LIKE value begins with a wildcard char.
# In the second statement, the LIKE value is not a constant.
#
# IF you use --- LIKE '%string%' and string is longer than 3 chars, MySQL uses the Turbo Boyer-Moore algorithm
# to initialize the pattern for the string and then uses this pattern to perform the search more quickly.
#
# A search using col_name IS NULL employs indexes if col_name is indexed.
#
# Any index that does not span all AND levels in the WHERE clause is not used to optimize
# the query.
#
# In other words, to be able to use an index, a prefix of the index must be used in every AND Group.
#
# The following WHERE clauses use indexes:
#
# 		--- WHERE index_part1=1 AND index_part2=2 AND other_column=3
#
# 		/* index = 1 OR index = 2 */
# 	--- WHERE index=1 OR A=10 AND index=2
# 		
# 		/* optimized like "index_part1='hello'" */
# 	--- WHERE index_part1='hello' AND index_part3=5
#
# 		/* Can use index on index1 but not on index2 or index3 */
# 	--- WHERE index1=1 AND index2=2 OR index1=3 AND index3=3;
#
# These where clauses do NOT use indexes:
#
# 		/* index_part1 is not used */
# 		--- WHERE index_part2=1 AND index_part3=2
#
# 		/* Index is not used in both parts of the WHERE clause */
# 		--- WHERE index=1 OR A=10
#
# 		/* No index spans all rows */
# 		--- WHERE index_part1=1 OR index_part2=10
#
# Sometimes MySQL does not use an index, even if one is available.
#
# One circumstance under which this occurs is when the optimizer estimates that using
# the index would require MysQL to access a very large percentage of the orws in the table.
#
# (In this case, a table scan is likely to be much faster, because it requires fewer seeks)
#
# However, if such a query uses LIMIT to retrieve only some of the rows, MysQL uses an index anyway.
# Because it can much more quickly find the few rows to return in the result.
#
# HASH INDEX CHARACTERISTICS
#
# Hash indexes have somewhat different characteristics from those just discussed:
#
# 		) They are used only for equality comparisons that use the = or <=> operators (but they are very fast).
#
# 			They are not used for comparison operators such as < that find a range of values.
#
# 			Systems that rely on this type of single-value lookup are known as "key-value stores",
# 			to use MySQL for such applications, use hash indexes wherever possible.
#
# 		) The optimizer cannot use a hash index to speed up ORDER BY operations. (This type of index cannot be used to search for the next entry in order)
#
# 		) MySQL cannot determine approximately how many rows there are between two values (this is used by the range optimizer to decide which index
# 			to use)
#
# 			This may affect some queries if you change a MyISAM or InnoDB table to a hash-indexed MEMORY table.
#
# 		) Only whole keys can be used to search for a row. (with a B-tree index, any leftmost prefix of the key can be used to find rows).
#
# USE OF INDEX EXTENSIONS
#
# InnoDB automatically extends each secondary index by appending the primary key columns to it.
# Consider this table definition:
#
# 		CREATE TABLE t1 (
# 			i1 INT NOT NULL DEFAULT 0,
# 			i2 INT NOT NULL DEFAULT 0,
# 			d DATE DEFAULT NULL,
# 			PRIMARY KEY (i1, i2),
# 			INDEX k_d (d)
# 		) ENGINE = InnoDB;
#
# This table defines the primary key on columns (i1, i2).
#
# It also defines a secondary index k_d on column (d), but internally, InnoDB extends this index and treats
# it as (d, i1, i2)
#
# THe optimizer takes into account the primary key columns of the extended secondary index when determining
# how and whether to use that index.
#
# This can result in more efficient query execution plans and better performance.
#
# The optimizer can use extended secondary indexes for ref, range, and index_merge index access,
# for Loose Index Scan access, for join and sorting optimization and for MIN()/MAX() optimization.
#
# THe following example shows how execution plans are affected by whether the optimizer uses extended
# secondary indexes.
#
# Suppose that t1 is populated with these rows:
#
# 		INSERT INTO t1 VALUES
# 		(1, 1, '1998-01-01'), (1,2, '1999-01-01'),
# 		etc.
#
# Now consider this query:
#
# 		EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = '2000-01-01'
#
# The optimizer cannot use the primary key in this case because that comprises columns
# (i1, i2) and the query does not refer to i2.
#
# Instead, the optimizer can use the secondary_index k_d on (d), and the execution plan
# depends on whether the extended index is used.
#
# WHen the optimizer does not consider index extensions, it treats the index k_d as only (d).
# EXPLAIN for the query produces this result:
#
# EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = '2000-01-01'\G
# ************************ 1. row ***********************************
#
# 								id: 1
# 					select_type: SIMPLE
# 							table: t1
# 							type : ref
# 				possible_keys : PRIMARY,k_d
# 							  key: k_d
# 					    key_len: 4
#  						  ref: const
# 							rows : 5
# 						  Extra : Using where; Using index
#
# When the optimizer takes index extensions into account, it treats k_d as (d, i1, i2).
#
# In this case, it can use the leftmost index prefix (d, i1) to produce a better execution plan:
#
# EXPLAIN SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = '2000-01-01'\G
# ************************* 1. row **********************************
# 
# 								 id: 1
# 					 select_type: SIMPLE
# 						table    : t1
# 							type  : ref
# 				possible_keys  : PRIMARY, k_d
# 								key: k_d
# 						key_len  : 8
# 							   ref: const, const
# 							  rows: 1
# 							Extra : Using index
#
# In both cases, key indicates that the optimizer will use secondary index k_d but the EXPLAIN
# output shows these improvements from using the extended index:
#
# 		) key_len goes from 4 bytes to 8, indicating that key lookups use column d and i1, not just d
#
# 		) The ref value changes from const to const, const because the key lookup uses two key parts, not one.
#
# 		) The rows count decreased from 5 to 1, indicating that InnoDB should need to examine fewer rows to produce the result.
#
# 		) The Extra value changes from Using where; Using index to Using index.
#
# 			This means that rows can be read using only the index, without consulting
# 			columns in the data row.
#
# Differences in optimizer behavior for use of extended indexes can also be seen with
# SHOW_STATUS:
#
# FLUSH TABLE t1;
# FLUSH STATUS;
# SELECT COUNT(*) FROM t1 WHERE i1 = 3 AND d = '2000-01-01'
# SHOW STATUS LIKE 'handler_read%'
#
# The preceding statements include FLUSH_TABLES and FLUSH_STATUS to flush the table cache and
# clear the status counters.
#
# Without index extensions, SHOW_STATUS produces this result:
#
# 		+-------------------------+------+
# 		| Variable_name 			  | Value|
# 		+-------------------------+------+
# 		| Handler_read_first 	  | 0 	|
# 		| Handler_read_key 		  | 1 	|
# 		| Handler_read_last 		  | 0    |
# 		| Handler_read_next 		  | 5    |
# 		| Handler_read_prev 		  | 0    |
# 		| Handler_read_rnd 		  | 0    |
# 		| Handler_read_rnd_next   | 0    |
#  	+-------------------------+------+
#
# With index extensions, SHOW STATUS produces this result.
#
# The Handler_read_next value decreases from 5 to 1, indicating more efficient use of the index:
#
# 		+-------------------------+-------+
# 		| Variable_name 			  | Value |
# 		+-------------------------+-------+
# 		| Handler_read_first 	  | 0     |
# 		| Handler_read_key 		  | 1 	 |
# 		| Handler_read_last 		  | 0     |
# 		| Handler_read_next 		  | 1     |
# 		| Handler_read_prev 		  | 0     |
# 		| Handler_read_rnd 		  | 0     |
# 		| Handler_read_rnd_next   | 0     |
# 		+-------------------------+-------+
#
# THe use_index_extensions flag of the optimizer_switch system variable permits control over whether the
# optimizer takes the primary key columns into account when determining how to use an InnoDB table's
# secondary indexes.
#
# By default, use_index_extensions is enabled.
#
# TO check whether disable use of index extensions will improve performance, use this statement:
#
# 		SET optimizer_switch = 'use_index_extensions=off';
#
# Use of index extensions by the optimizer is subject to the usual limits on the number of key parts
# in an index (16) and the max key length (3072 bytes)
#
# OPTIMIZER USE OF GENERATED COLUMN INDEXES
#
# MySQL supports indexes on generated columns.
#
# for example:
#
# 		CREATE TABLE t1 (f1 INT, gc INT AS (f1 + 1) STORED, INDEX (gc));
#
# The generated column, gc, is defined as the expression f1 +1.
#
# The column is also indexed and the optimizer can take that index into account during
# execution plan construction.
#
# In the following query, the WHERE clause refers to gc and the optimizer considers whether
# the index on that column yields a more efficient plan:
#
# 		SELECT * FROM t1 WHERE gc > 9;
#
# The optimizer can use indexes on generated columns to generate execution plans, even in teh absence
# of direct references in queries to those columns by name.
#
# This occurs if the WHERE, ORDER BY or GROUP BY clause refers to an expression that matches the definition
# of some indexed generated column.
#
# The following query does not refer directly to gc, but does use an expression that matches the definition of gc:
#
# 		SELECT * FROM t1 WHERE f1 + 1 > 9;
#
# The optimizer recognizes that hte expression f1 + 1 matches the definition of gc and that gc is indexed,
# so it considers that index during execution plan construction.
#
# You can see this using EXPLAIN:
#
# EXPLAIN SELECT * FROM t1 WHERE f1 + 1 > 9\G
# ************************* 1. row ***************************
#
# 						id: 1
# 			select_type: SIMPLE
# 					table: t1
# 			partitions : NULL
# 					type : range
# 		possible_keys : gc
# 					  key: gc
# 				key_len : 5
# 				     ref: NULL
# 				    rows: 1
# 				filtered: 100.00
# 				   Extra: Using index condition
#
# In effect, the optimizer has replaced the expression f1 +1 with the name of the generated column that
# matches the expression.
#
# THis is also apparent in the rewritten query available in teh extended EXPLAIN information displayed
# by SHOW_WARNINGS:
#
# SHOW WARNINGS\G
# *********************** 1. row ***********************
#
# 	 Level: Note
# 	  Code: 1003
# Message: /* select#1 */ select `test`.`t1`.`f1` AS `f1`, `test`.`t1`.`gc`
# 				AS `gc` from `test`.`t1` where (`test`.`t1`.`gc` > 9)
#
# The following restrictions and conditions apply to the optimizer's use of generated column indexes:
#
# 		) For a query expression to match a generated column definition, the expression must be identical
# 			and it must have the same result type.
#
# 			For example, if the generated column expressions f1 + 1, the optimizer will not recognize
# 			a match if the query uses 1 + f1, or if f1 + 1 (an integer exp.) is compared with a string.
#
# 		) The optimization applies to these operators: =, <, <=, >, >=, BETWEEN and IN().
#
# 			For operators other than BETWEEN and IN(), either operand can be replaced by a matching generated column.
#
# 			For BETWEEN and IN(), only the first argument can be replacted by a matching generated column, and the
# 			other arguments must have the same result type.
#
# 			BETWEEN and IN() are not yet supported for comparisons involving JSON values.
#
# 		) The generated column must be defined as an expression that contains at least a function call or one
# 			of the operators mentioned in the preceding item.
#
# 			The expression cannot consist of a simple reference to another column.
#
# 			For example, gc INT AS (f1) STORED consists only of a column reference, so indexes on gc are not
# 			considered.
#
# 		) For comparisons of strings to indexed generated columns that compute a value from a JSON function that
# 			returns a quoted string, JSON_UNQUOTE() is needed in the column definition to remove the extra quotes
# 			from the function value.
#
# 			(For direct comparison of a string to the function result, the JSON comparator handles quote removal,
# 			but this does not occur for index lookups).
#
# 			For example, instead of writing a column definition like this:
#
# 				doc_name TEXT AS (JSON_EXTRACT(jdoc, '$.name')) STORED
#
# 			Write it like this:
#
# 				doc_name TEXT AS (JSON_UNQUOTE(JSON_EXTRACT(jdoc, '$.name'))) STORED
#
# 			With the latter definition, the optimizer can detect a match for both of thse comparisons:
#
# 				--- WHERE JSON_EXTRACT(jdoc, '$.name') = 'some_string' ---
# 				--- WHERE JSON_UNQUOTE(JSON_EXTRACT(jdoc, '$.name')) = 'some_string' ---
#
# 			Without JSON_UNQUOTE() in the column definition, the optimizer detects a match only for the first of those comparisons.
#
# 		) If the optimizer picks the wrong index, an index hint can be used to disable it and force the optimizer
# 			to make a different choice.
#
# INVISIBLE INDEXES
#
# MysQL supports invisible indexes; that is, indexes that are not used by the optimizer.
#
# The feature applies to indexes other than primary keys (either explicit or implicit)
#
# Indexes are visible by default.
#
# TO control Index visibility explicitly for a new index, use a VISIBLE or INVISIBLE keyword
# as part of the index definition for CREATE_TABLE, CREATE_INDEX, or ALTER_TABLE.
#
# 		CREATE TABLE t1 (
# 			i INT,
# 			j INT,
# 			k INT,
# 			INDEX i_idx (i) INVISIBLE
# 		) ENGINE = InnoDB;
# 		CREATE INDEX j_idx ON t1 (j) INVISIBLE;
# 		ALTER TABLE t1 ADD INDEX k_idx (k) INVISIBLE;
#
# To alter the visibility of an existing index, use a VISIBLE or INVISIBLE keyword with the ALTER TABLE --- ALTER INDEX operation:
#
# 		ALTER TABLE t1 ALTER INDEX i_idx INVISIBLE;
# 		ALTER TABLE t1 ALTER INDEX i_idx VISIBLE;
#
# Information about whether an index is visible or invisible is available from the
# INFORMATION_SCHEMA.STATISTICS table or SHOW_INDEX output.
#
# For example:
#
# 		SELECT INDEX_NAME, IS_VISIBLE
# 		FROM INFORMATION_SCHEMA.STATISTICS
# 		WHERE TABLE_SCHEMA = 'db1' AND TABLE_NAME = 't1';
# 		+-----------------------------+
# 		| INDEX_NAME 	| 	IS_VISIBLE  |
# 		+--------------+--------------+
# 		| _idx 			| YES 			|
# 		| j_idx 			| NO 				|
# 		| k_idx 			| NO 				|
# 		+--------------+--------------+
#
# Invisible indexes make it possible to test the effect of removing an index on query performance,
# without making a destructive change that must be undone should the index turn out to be required.
#
# Dropping and re-adding an index can be expensive for a large table, whereas making it invisible and
# visible - are fast in-place operations.
#
# If an index made invisible actually is needed or used by the optimizer,
# there are several ways to notice the effect of its absence on queries for the table:
#
# 		) Errors occur for queries that include index hints that refer to the invisible index
#
# 		) Performance Schema data shows an increase in workload for affected queries.
#
# 		) Queries have different EXPLAIN execution plans.
#
# 		) Queries appear in the slow query log that did not appear there previously.
#
# The use_invisible_indexes flag of the optimizer_switch system variable controls whether the optimizer
# uses invisible indexes for query execution plan construction.
#
# If the flag is off (the default), the optimizer ignores invisible indexes (the same behavior as prior
# to the introduction of this flag).
#
# If the flag is on, invisible indexes remain invisible but the optimizer takes them into account for execution
# plan construction.
#
# Index visibility does not affect index maintenance. For example, an index continues to be updated
# per changes to the table rows, and a unique index prevents insertion of duplicates into a column,
# regardless of whether the index is visible or invisible.
#
# A table with no explicit primary key may still have an effective implicit primary key if it has any UNIQUE
# indexes on NOT NULL.
#
# In this case, the first such index places the same constraint on table rows as an explicit
# primary key and that index cannot be made invisible.
#
# Consider the following table definition:
#
# 		CREATE TABLE t2 (
# 			i INT NOT NULL,
# 			j INT NOT NULL,
# 			UNIQUE j_idx (j)
# 		) ENGINE = InnoDB;
#
# The definition includes no explicit primary key, but hte index on NOT NULL column j places the same
# constraint on rows as a primary key, and cannot be made invisible:
#
# 		ALTER TABLE t2 ALTER INDEX j_idx INVISIBLE;
# 		ERROR 3522 (HY000): A primary key index cannot be invisible.
#
# Now suppose that an explicit primary key is added to the table:
#
# 		ALTER TABLE t2 ADD PRIMARY KEY (i);
#
# The explicit primary key cannot be made invisible.
#
# In addition, the unique key index on j no longer acts as an implicit primary key and
# as a result can be made invisible:
#
# ALTER TABLE t2 ALTER INDEX j_idx INVISIBLE;
# Query OK, 0 rows affected (0.03 sec)
#
# DESCENDING INDEXES
#
# MySQL supports descending indexes: DESC in a index definition is no longer ignored but causes
# storage of key values in desc. order.
#
# Previously, indexes could be scanned in reverse order but at a performance penalty.
#
# A descending index can be scanned in forward order, which is more efficient.
#
# Descending indexes also make it possible for the optimizer to use multiple-column indexes when the
# most efficient scan order mixes ascending order for some columns and descending order for others.
#
# Consider the following table definition, which contains two columns and four two-column index definitions
# for the various combinations of ascending and descending indexes on the columns:
#
# 		CREATE TABLE t (
# 			c1 INT, c2 INT,
# 			INDEX idx1 (c1 ASC, c2 ASC),
# 			INDEX idx2 (c1 ASC, c2 DESC),
# 			INDEX idx3 (c1 DESC, c2 ASC),
# 			INDEX idx4 (c1 DESC, c2 DESC)
# 		);
#
# The table definition results in four distinct indexes.
#
# The optimizer can perform a forward index scan for each of the ORDER BY clauses and
# need not use a filesort operation:
# 
# ORDER BY c1 ASC, c2 ASC -- optimizer can use idx1
# ORDER BY c1 DESC, c2 DESC -- optimizer can use idx4
# ORDER BY c1 ASC, c2 DESC -- Optimizer can use idx2
# ORDER BY c1 DESC, c2 ASC -- optimizer  can use idx3
#
# Use of descending index is subject to these conditions:
#
# 		) Descending index are supported only for the InnoDB storage engine, with these limitations:
#
# 			) Change buffering is not supported for a secondary index if the index contains a descending
# 				index key column or if the primary key includes a descending index column.
#
# 			) The InnoDB SQL parser does not use descending indexes.
#
# 				For InnoDB full-text search, this means that the index required on the FTS_DOC_ID column of the
# 				indexed table cannot be defined as a descending index.
#
# 				For more information, see more later under INNODB FULLTEXT INDEXES
#
# 		) Descending indexes are supported for all data types for which ascending indexes are available.
#
# 		) Descending indexes are supported for ordinary (nongenerated) and genrated columns (both VIRTUAL and STORED)
#
# 		) DISTINCT can use any index containing matching columns, including descending key parts.
#
# 		) Indexes that have descending key parts are not used for MIN()/MAX() optimization of queries that invoke aggregate
# 			functions but do not have a GROUP BY clause.
#
# 		) Descending indexes are supported for BTREE but not HASH indexes. Descending indexes are not supported
# 			for FULLTEXT or SPATIAL indexes.
#
# 			Explicitly specified ASC and DESC designators for HASH, FULLTEXT, and SPATIAL indexes result in an error.
#
# OPTIMIZING DATABASE STRUCTURE
#
# In your role as DB designer, look for the most efficient way to organize your schemas, tables and columns.
# As when tuning application code, you can minimize I/O, keep related items together, and plan ahead
# so that performance stays high as the data volume increases.
#
# Starting with an efficient database design make it easier for team members to write high-performing
# application code, and makes the database likely to endure as applications evolve and are rewritten.
#
# OPTIMIZING DATA SIZE
#
# Design your tables to minimize their space on the disk.
# This can result in huge improvements by reducing the amount of data written to and read from disk.
#
# Smaller tables normally require less main memory while their contents are being actively processed
# during query execution.
#
# Any space reduction for table data also results in smaller indexes that can be processed faster.
#
# MysQL supports many different storage engines (table types) and row formats.
# For each table, you can decide which storage and indexing method to use.
#
# Choosing the proper table format for your application can give you a big performance gain.
#
# See more later in THE INNODB STORAGE ENGINE and ALTERNATIVE STORAGE ENGINES
#
# You can get better performance for a table and minimize storage space by using the techniques
# listed here:
#
# 		) TABLE COLUMNS
#
# 		) ROW FORMAT
#
# 		) INDEXES
#
# 		) JOINS
#
# 		) NORMALIZATION
#
# TABLE COLUMNS
#
# 		) use the most efficient (smallest) data types possible.
#
# 			MySQL has many specialized types that save disk space and memory.
# 			For example, use the smaller integer types if possible to get smaller tables.
#
# 			MEDIUMINT is often better of a choice than INT because MEDIUMINT columns use 25% less space.
#
# 		) Declare columns to be NOT NULL if possible.
#
# 			It makes SQL operations faster, by enabling better use of indexes and eliminating overhead for testing
# 			whether each value is NULL.
#
# 			You also save some storage space, one bit per column.
#
# 			If you really need NULL values in your tables, use them.
# 			Just avoid the default setting that allows NULL values in every column.
#
# ROW FORMAT
#
# 		) InnoDB tables are created using the DYNAMIC row format by default.
# 			To use a row format other than DYNAMIC, configure innodb_default_row_format,
# 			or specify the ROW_FORMAT option explicitly in a CREATE_TABLE or ALTER_TABLE statement.
#
# 			The compact family of row formats, which includes COMPACT, DYNAMIC, and COMPRESSED,
# 			decreases row storage space at the cost of increasing CPU use for some operations.
#
# 			If your workload is a typical one that is limited by cache hit rates and disk speed
# 			it is likely to be faster.
#
# 			If it is a rare case taht is limited by CPU speed, it might be slower.
#
# 			The compact family of row formats also optimizes CHAR column storage when using a 
# 			variable-length character set such as utf8mb3 or utf8mb4.
#
# 			With ROW_FORMAT=REDUNDANT, CHAR(N) occupies N x the max byte length of the char set.
#
# 			Many languages can be written primarly using a single-byte utf8 chars, so a fixed storage
# 			length often wastes space.
#
# 			With the compact family of row formats, InnoDB allocates a variable amount of storage
# 			in teh range of N to N x the max byte length of char set for these columns by stripping trailing spaces.
#
# 			The minimum storage length is N bytes to facilitate in-place updates in typical cases.
#
# 			For more information, see later under THE PHYSICAL ROW STRUCTURE OF AN INNODB TABLE
#
# 		) To minimize space even further by storing table data in compressed form, specify ROW_FORMAT=COMPRESSED
# 			when creating InnoDB tables, or run the myisampack command on an existing MyISAM table.
#
# 			(InnoDB compressed tables are readable and writable, while MyISAM compressed tables are read only)
#
# 		) For MyISAM tables, if you do not have any variable-length columns (VARCHAR, TEXT or BLOB columns),
# 			A fixed-size row foramt is used.
#
# 			This is faster but may waste some space.
#
# 			More later under MyISAM TABLE STORAGE FORMATS.
#
# 			You can hint that you want to have fixed length rows even if you have VARCHAR columns
# 			with the CREATE_TABLE option ROW_FORMAT=FIXED
#
# INDEXES
#
# 		) The primary index of a table should be as short as possible.
#
# 			This makes identification of each row easy and efficient.
#
# 			For InnoDB tables, the primary key columns are duplicated in each secondary
# 			index entry, so a short primary key saves considerable space if you have
# 			many secondary indexes.
#
# 		) Create only the indexes that you need to improve query performance.
#
# 			Indexes are good for retreival, but slow down insert and update operations.
#
# 			If you access a table mostly by searching on a combination of columns,
# 			create a single composite index on them rather than a separate index for each column.
#
# 			The first part of the index should be the column most used.
#
# 			If you ALWAYS use many columns when selecting from the table, the first column in the index
# 			should be the one with the most duplicates to obtain better compression of the index.
#
# 		) If it is very likely that a long string column has a unique prefix on the first number of characters,
# 			it is better to index only this prefix, using MySQL's support for creating an index on the leftmost
# 			part of the column.
#
# 			See more under CREATE INDEX SYNTAX.
#
# 			Shorter indexes are faster, not only because they require less disk space,
# 			but because they also give you more hits in teh index cache, and thus fewer disk seeks.
#
# 			See configuring the server.
#
# JOINS
#
# 		) In some circumstances, it can be beneficial to split into two a table that is scanned very often
#.
# 			This is especially true if it is a dynamic-format table and it is possible to use a 
# 			smaller static format table that can be used to find the relevant rows when scanning the table. 	
#
# 		) Declare columns with identical information in different tables with identical data types, to speed up
# 			joins based on the corresponding columns.
#
# 		) Keep column names simple, so that you can use the same name across different tables and simplify join queries.
# 			For example, in a table named customer, use a column name of name instead of customer_name.
#
# 			To make your names portable to other SQL servers, consider keeping them shorter than 18 chars.
#
# NORMALIZATION
#
# 		) Normally, try to keep all data nonredundant (observing what is referred to in database theory as third normal form).
#
# 			Instead of repeating lengthy values such as names and addresses, assign them unique IDs, repeat these IDs as needed
# 			across multiple smaller tables, and join the tables in queries by referencing the IDs in the join clause.
#
# 		) If speed is more important than disk space and the maintenance costs of keeping multiple copies of data,
# 		for example in a business intelligence scenario where you analyze all the data from large tables,
# 		you can relax the normalization rules, duplicating information or creating summary tables to gain more speed.
#
# OPTIMIZING MYSQL DATA TYPES
#
# OPTIMIZING FOR NUMERIC DATA
#
# 		) For unique IDs or other values that can be represented as either strings or numbers, prefer numeric columns
# 			to string columns.
#
# 			Since large numeric values can be stored in fewer bytes than the corresponding strings, it is faster
# 			and takes less memory to transfer and compare them.
#
# 		) If you are using numeric data, it is faster in many cases to access information from a database (using a live connection)
# 			than to access a text file.
#
# 			Information in the DB is likely to be stored in a more compact format than in the text file,
# 			so accessing involves fewer disk accesses.
#
# 			You can also save code in our application because you can avoid parsing the text file to find line
# 			and column boundaries.
#
# OPTIMIZING FOR CHARACTER AND STRING TYPES
#
#  For character and string columns, follow these guidelines:
#
# 		) Use binary collation order for fast comparison and sort operations,
# 			when you do not need language-specific collation features.
#
# 			You can use the BINARY operators to use binary collation within a particular query.
#
# 		) When comparing values from different columns, declare those columns with the same character
# 			set and collation wherever possible, to avoid string conversions while running the query.
#
# 		) For column values less than 8kb in size, use binary VARCHAR instead of BLOB.
#
# 			The GROUP BY and ORDER BY clauses can generate temporary tables, and these temporary
# 			tables can use the MEMORY storage engine if the original table does not contain any
# 			BLOB columns.
#
# 		) If a table contains string columns such as name and address, but many queries do not retrieve
# 			those columns, consider splitting the string columns into a separate table and using join queries
# 			with a foreign key when necessary.
#
# 			When MySQL retrieves any value from a row, it reads a data block containing all the columns of that row
# 			(and possibly other adjancet rows)
#
# 			Keeping each row small, with only the most frequently used columns, allows more rows to fit in each
# 			data block.
#
# 			Such compact tables reduce disk I/O and memory usage for common queries.
#
# 		) When oyu use a randomly generated value as a primary key in a InnoDB table, prefix it
# 			with an ascending value such as the current date and time if possible.
#
# 			When consecutive primary values are physically stored near each other, InnoDB
# 			can insert and retrieve them faster.
#
# 		) See OPTIMIZING FOR NUMERIC DATA to see why numeric columns are preferable to an equivalent string column.
#
# OPTIMIZING FOR BLOB TYPES
#
# 		) When storing a large blob containing textual data, consider compressing it first.
#
# 			Do not use this technique when the entire table is compresed by InnoDB or MyISAM.
#
# 		) For a table with several columns, to reduce memory requirements for queries that do not use
# 			the BLOB column, consider splitting the BLOB column into a separate table and referencing
# 			it with a join query when needed.
#
# 		) Since the performance requirements to retrieve and display a BLOB value might be very different
# 			from other data types, you could put the BLOB-specific table on a different storage device or
# 			even a separate database instance.
#
# 			For example, to retrieve a BLOB might require a large sequential disk read that is better suited
# 			to a traditional hard drive than to an SSD device.
#
# 		) See OPTIMIZING FOR CHARACTER AND STRING TYPES for reasons why a binary VARCHAR column is sometimes
# 			preferable to an equivalent BLOB column.
#
# 		) Rather than testing for equality against a very long text string, you can store a hash of the column
# 			value in a separate column, index that column, and test the hashed values in queries.
#
# 			(Use the MD5() or CRC32() function to produce the hash value.)
#
# 			Since hash functions can produce duplicate results for different inputs, you still
# 			include a clause AND blob_column = long_string_value in the query to guard against
# 			false matches.
#
# 			The performance benefit comes from the smaller, easily scanned index for the hashed values.
#
# OPTIMIZING FOR MANY TABLES
#
# Some techniques for keeping individual queries fast involve splitting data across many tables.
#
# When the number of tables run into the thousands or even millions, the overhead of dealing with
# all these tables become a new performance consideration.
#
# HOW MYSQL OPENS AND CLOSES TABLES
#
# When you execute a mysqladmin status command, you should see something like this:
#
# 		Uptime: 426 Running threads: 1 Questions: 11082
# 		Reloads: 1 Open tables: 12
#
# The Open tables value of 12 can be somewhat puzzling if you have fewer than 12 tables.
#
# MySQL is multithreaded, so there may be many clients issuing queries for a given table simultaneously.
#
# To minimize the problem with multiple client sessions having different states on the same table,
# the table is opened independently by each concurrent session.
#
# This uses additional memory but normally increaases performance.
#
# With MyISAM tables, one extra file descriptor is required for the data file for each client that
# has the table open. (By contrast, the index file descriptor is shared between all sessions)
#
# The table_open_cache and max_connections system variables affect the maximum number of files the server
# keeps open.
#
# If you increase one or both of these values, you may run up against a limit imposed by your operating system
# on the per-process number of open file descriptors.
#
# Many operating systems permit you to increase the open-files limit, although the method varies widely from
# system to system.
#
# Consult your OS documentation to determine whether it is possible to increaase the limit and how to do so.
#
# table_open_cache is related to max_connections.
#
# For example, for 200 concurrent running connections, specify a table cache size of at least 200 * N,
# where N is the maximum number of tables per join in any of the queries which you execute.
#
# You must also reserve some extra file descriptors for temporary tables and files.
#
# Make sure that your operating system can handle the number of open file descriptors implied by the table_open_cache
# setting.
#
# If table_open_cache is set too high, MySQL may run out of file descriptors and exhibit symptoms such as refusing
# connections or failing to perform queries.
#
# Also take into account that the MyISAM storage engine needs two file descriptors for each unique open table.
#
# To increase the number of file descriptors available to MySQL, use the --open-files-limit startup option to
# mysqld.
#
# SEE MORE UNDER FILE NOT FOUND AND SIMILAR ERRORS.
#
# The cache of open tables is kept at a level of table_open_cache entries. 
# The server autosizes the cache size at startup.
#
# To set the size explicitly, set the table_open_cache system variable at startup.
#
# MySQL may temporarily open more tables than this to execute queries, as described later in this section.
#
# MySQL closes an unused table and removes it from the table cache under the following circumstances:
#
# 		) WHen the cache is full and a thread tries to open a table that is not in the cache
#
# 		) When the cache contains more than table_open_cache entries and a table in the cache is no longer being
# 			used by any threads.
#
# 		) When a table-flushing operation occurs. This happens when someone issues a FLUSH_TABLES statement
# 			or executes a mysqladmin flush-tables or mysqladmin refresh command.
#
# When the table cache fills up, the server uses the following procedure to locate a cache entry to use:
#
# 		) Tables not currently in use are released, beginning with the table least recently used.
#
# 		) If a new table must be opened, but the cache is full and no tables can be released, the cache is temporarily
# 			extended as necessary.
#
# 			When the cache is in a temporary extended state and a table goes from a used to unused state, the table
# 			is closed and released from the cache.
#
# A MyISAM table is opened for each concurrent access.
#
# This means the table needs to be opened twice if two threads access the same table or if a thread
# accesses the table twice in the same query (for example, by joining the table to itself)
#
# Each concurrent open requires an entry in the table cache. 
#
# The first open of any MyISAM table takes two file descriptors: one for the data file and one
# for the index file.
#
# Each additional use of the table takes only one file descriptor for the data file.
#
# The index file descriptor is shared among all threads.
#
# If you are opening a table with the HANDLER tbl_name OPEN statement, a dedicated table object
# is allocated for the thread.
#
# This table object is not shared by other threads and is not closed until the thread calls HANDLER tbl_name CLOSE
# or the thread terminates.
#
# When this happens, the table is put back in the table cache (if the cache is not full), SEE MORE LATER IN THE HANDLER SYNTAX
#
# To determine whether your table cache is too small, check the Opened_tables status variable,
# which indicates the number of table-opening operations since the server started:
#
# 		SHOW GLOBAL STATUS LIKE 'Opened_tables';
# 		+--------------------------------------+
# 		| Variable_name 			| Value 		   |
# 		+--------------------------------------+
# 		| Opened_tables 			| 2741 			|
# 		+--------------------------------------+
#
# If the value is very large or increases rapidly, even when you have not issued
# many FLUSH_TABLES statements, increase the table_open_cache value at server startup.
#
# DISADVANTAGES OF CREATING MANY TABLES IN THE SAME DATABASE
#
# If you have many MyISAM tables in the same database directory, open, close and create operations are slow.
#
# IF you execute SELECT statements on many different tables, there is little overhead when the table cache is full,
# because for every table that has to be opened, another must be closed.
#
# You can reduce this overhead by increasing the number of entries permitted in the table cache.
#
# INTERNAL TEMPORARY TABLE USE IN MYSQL
#
# In some cases, the server creates internal temporary tables while processing statements.
# Users have no direct control over when this occurs.
#
# The server creates temporary tables under conditions such as these:
#
# ) Evaluation of UNION statements, with some exceptions described later.
#
# ) Evaluation of some views, such those that use the TEMPTABLE algorithm, UNION or aggreggation
#
# ) Evaluation of derived  tables (MORE LATER IN DERIVED TABLES)
#
# ) Evaluation of common table expressions (SEE WITH SYNTAX (COMMON TABLE EXPRESSIONS) LATER)
#
# ) Tables created for subquery or semi-join materialization (SEE OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS LATER)
#
# ) Evaluation of statements that contain an ORDER BY clause and a different GROUP BY clause, or for which the
# 		ORDER BY or GROUP BY contains columns from tables other than the first table in the join queue.
#
# ) Evaluation of DISTINCT combined with ORDER BY may require a temporary table
#
# ) For queries that use the SQL_SMALL_RESULT modifier, MySQL uses an in-memory temporary table,
# 		unless the query also contains elements (described later) that require on-disk storage.
#
# ) To evaluate INSERT_---_SELECT statements that select from and insert into the same table, MySQL
# 		creates an internal temporary table to hold the rows from the SELECT, then inserts those
#		rows into the target table. SEE MORE LATER ON INSERT_---_SELECT SYNTAX
#
# ) Evaluation of multiple-table UPDATE statements
#
# ) Evaluation of GROUP_CONCAT() or COUNT(DISTINCT) expressions.
#
# ) Evaluation of window functions (MORE LATER IN WINDOW FUNCTIONS) uses temporary tables as necessary.
#
# To determine whether a statement requires a temporary table, use EXPLAIN and check the Extra column to see
# whether it says Using temporary (SEE UNDER OPTIMIZING WITH EXPLAIN)
#
# EXPLAIN will not nessecarily say Using temporary for derived or materialized temporary tables.
#
# For statements that use window functions, EXPLAIN with FORMAT=JSON always provides information
# about the windowing steps.
#
# If the windowing functions use temporary tables, it is indicated for each step.
#
# When the server creates an internal temporary table (either in memory or on disk),
# it increments the Created_tmp_tables status variable.
#
# If the server creates the table on disk (either initially or by converting an in-memory table),
# it increments the Created_tmp_disk_tables status variable.
#
# Some query conditions prevent the use of an in-memory temporary table, in which case the server
# uses an on-disk table instead:
#
# 		) PResence of a BLOB or TEXT column in teh table.
#
# 			However, the TempTable storage engine, which is the default storage engine for in-memory
# 			internal temporary tables in MySQL 8.0, supports binary large objects as of MySQL 8.0.13
#
# 			More under INTERNAL TEMPORARY TABLE STORAGE ENGINE
#
# 		) Presence of any string column with a maximum length larger than 512 (bytes for binary strings, characters
# 			for nonbinary strings) in the SELECT list, if UNION or UNION ALL is used.
#
# 		) The SHOW_COLUMNS and DESCRIBE statements use BLOB as the type for some columns, thus the temporary table used
# 			for the results is an on-disk table.
#
# The server does not use a temporary table for UNION statements that meet certain qualifications.
#
# Instead, it retains from temporary table creation only the data structures necessary to perform
# result column typecasting.
#
# The table is not fully instansiated and no rows are written to or read from it; rows are sent
# directly to the client.
#
# The result is reduced memory and disk requirements, and smaller delay before the first row is sent to client
# because the server need not wait until the last query block is executed.
#
# EXPLAIN and optimizer trace output reflects this execution strat.
#
# The UNION RESULT query block is not present because that block corresponds to the part that reads from the temporary table.
#
# These conditions qualify a UNION for evaluation without a temporary table:
#
# 	) The union is UNION ALL, not UNION or UNION DISTINCT
#
# 	) There is no global ORDER BY clause
#
# 	) The union is not the top-level query block of an {INSERT | REPLACE} --- SELECT --- statement
#
# INTERNAL TEMPORARY TABLE STORAGE ENGINE
#
# An internal temporary table can be held in memory and processed by the TempTable or MEMORY storage engine,
# or stored on disk by the InnoDB or MyISAM storage engine.
#
# STORAGE ENGINE FOR IN-MEMORY INTERNAL TEMPORARY TABLES
#
# The internal_tmp_mem_storage_engine session variable defines the storage engine for in-memory
# temporary tables.
#
# Permitted values are TempTable (the default) and MEMORY.
#
# The TempTable storage engine provides efficient storage for VARCHAR and VARBINARY columns.
# Storage of other binary large object types is supported qs of 8.0.13
#
# The temptable_max_ram configuration option defines the maximum amount of random access memory
# (RAM) that can be occupied by the TempTable storage engine before it starts allocating space
# from disk in teh form of temporary files that are mapped into memory.
#
# The default temptable_max_ram setting is 1 GIB.
#
# Use of temporary files by the TempTable storage engine as an overflow mechanism for in-memory
# temporary tables is governed by these rules:
#
# ) Temporary files are created in teh directory defined by the tmpdir variable.
#
# ) Temporary files are deleted immediately after they created and opened, and therefore do not
# 		remain visible in the tmpdir directory.
#
# 		The space occupied by temporary files is held by the operating system while temporary files are open.
# 		
# 		The space is reclaimed when temporary files are closed by the TempTable storage engine,
# 		or when the mysqld process is shut down.
#
# ) Data is never moved between RAM and temporary files, within RAM or between temporary files.
#
# ) New data is stored in RAM if space becomes available within the limit defined by temptable_max_ram.
# 		Otherwise, new data is stored in temporary files.
#
# ) If space becomes avaialble in RAM after some of the data for a table is written to temporary files,
# 		it is possible for the remaining table data to be stored in RAM.
#
# The memory/temptable/physical_ram and memory/temptable/physical_disk Performance Schema instruments can
# be used to monitor TempTable space allocation from memory and disk.
#
# memory/temptable/physical_ram reports the amount of allocated RAM.
#
# memory/temptable/physical_disk reports the amount of space allocated from disk.
#
# If the physical_disk instrument reports a value other than 0, the temptable_max_ram threshold
# was reached at some point.
#
# Data can be queried in Performance Schema memory summary tables such as memory_summary_global_by_event_name.
#
# SEE MOATER LATER UNDER MEMORY SUMMARY TABLES
#
# WHen using the MEMORY storage engine for in-memory temporary tables, MySQL automatically converts an in-memory
# temporary table to an on-disk table if it becomes too large.
#
# The maxium size for in-memory temporary tables is defined by the tmp_table_size or max_heap_table_size value,
# whichever is smaller.
#
# This differs from MEMORY tables explicitly created with CREATE_TABLE.
#
# FOr such tables, only the max_heap_table_size variable determines how large a table can grow,
# and there is no conversion to on-disk format.
#
# STORAGE ENGINE FOR ON-DISK INTERNAL TEMPORARY TABLES
#
# The internal_tmp_disk_storage_engine variable defines the storage engine the server uses to manage on-disk
# internal temporary tables.
#
# Permitted values are INNODB (default) and MyISAM.
#
# For common table expressions (CTEs), the storage engine used for on-disk internal temporary tables cannot be MyISAM.
#
# If internal_tmp_disk_storage_engine=MYISAM, an error occurs for any attempt to materialize a  CTE using
# an on-disk temporary table.
#
# NOTE:
#
# 		When using internal_tmp_disk_storage_engine=INNODB, queries that generate on-disk internal temporary tables
# 		that exceed InnoDB row or column limits returns Row size too large or Too many columns errors.
#
# 		The workaround is to set internal_tmp_disk_storage_engine to MyISAM.
#
# INTERNAL TEMPORARY TABLE STORAGE FORMAT
#
# When in-memory internal temporary tables are managed by the TempTable storage engine,
# rows that include VARCHAR columns, VARBINARY columns or other binary large object type
# columns (supported as of 8.0.13) are represented in memory by an array of cells, with each cell
# containing a NULL flag, the data length, and a data pointer.
#
# Column values are placed in consecutive order after the array, in a single region of memory,
# without padding.
#
# Each cell in the array uses 16 bytes of storage. The same storage format applies when the TempTable
# storage engine exceeds the temptable_max_ram limit and starts allocating space from disk in the form
# of temporary files that are mapped into memory.
#
# When in-memory internal temporary tables are managed by the MEMORY storage engine, fixed-length row
# format is used.
#
# VARCHAR and VARBINARY column values are padded to the maximum column length, in effect storing them as
# CHAR and BINARY columns.
#
# On-disk internal temporary tables are managed by the INnoDB or MyISAM storage engine (depending on the 
# internal_tmp_disk_storage_engine setting)
#
# Both engines store internal temporary tables using dynamic-width row format.
#
# Columns take only as much storage as needed, which reduces disk I/O, space requirements, and
# processing time compared to on-disk tables that use fixed-length rows.
#
# When using the MEMORY storage engine, statements can initially create an in-memory internal
# temporary table and then convert it to an on-disk table if the table becomes too large.
#
# In such cases, better performance might be achieved by skipping the conversion and creating
# the internal temporary table on disk to begin with.
#
# THe big_tables variable can be used to force disk storage of internal temporary tables.
#
# OPTIMIZING FOR INNODB TABLES
#
# InnoDB is the storage engine that MySQL customer typically use in production DBs where reliability
# and concurrency are important.
#
# InnoDB is the default storage engine in MySQl. This section explains how to optimize database operations
# for InnoDB tables.
#
# OPTIMIZING STORAGE LAYOUT FOR INNODB TABLES
#
# ) Once your data reaches a stable size, or a growing table has increased by tens or some hundreds of
# 	megabytes, consider using the OPTIMIZE TABLE statement to reorganize the table and compact any wasted space.
#
# 	THe reorganized table require less disk I/O to perform full table scans.
#
# This is a straightforward technique that can improve performance when other techniques such as improving index usage
# or tunning application code are not practical.
#
# 	OPTIMIZE TABLE copies the data part of the table and rebubilds the indexes.
#
# 	The benefits come from improved packing of data within indexes, and reduced
# 	fragmentation within the tablespaces and on disk.
#
# 	The benefits vary depending on the data in each table.
#
# 	You may find that ther are significant gains for some and not for others, or that the gains
# 	decrease over time until you next optimize the table.
#
# 	This operation can be slow if the table is large or if the indexes being rebuilt do not fit
# 	into the buffer pool.
#
# 	The first run after adding a lot of data to a table is often much slower than later runs.
#
# ) In InnoDB, having a long PRIMARY KEY (either single column with a lengthy value, or several columns
# 		that form a long composite value) wastes a lot of disk space.
#
# 		The primary key value for a row is duplicated in all the secondary index records that point to
# 		the same row. (SEE MORE UNDER CLUSTERED AND SECONDARY INDEXES)
#
# 		Create an AUTO_INCREMENT column as the primary key if your primary key is long, or index
# 		a prefix of a long VARCHAR column instead of the entire column.
#
# ) Use the VARCHAR data type instead of CHAR to store variable-length strings or for columns
# 		with many NULL values.
#
# 		A CHAR(N) column always takes N characters to store data, even if the string is shorter
# 		or its value is NULL.
#
# 		Smaller tables fit better in the buffer pool and reduce disk I/O
#
# 		WHen using COMPACT row format (the default InnoDB format) and variable-length character sets,
# 		such as utf8 or sjis, CHAR(N) columns occupy a variable amount of space, but still at least
# 		N bytes.
#
# ) For tables that are big, or contain lots of repetitive text or numeric data,
# 		consider using COMPRESSED row format.
#
# 		Less disk I/O is required to bring data into the buffer pool, or to perform
# 		full table scans.
#
# 		Before making a permanent decision, measure the amount of compression you can achieve
# 		by using COMPRESSED versus COMPACT row format.
#
# OPTIMIZING INNODB TRANSACTION MANAGEMENT
#
# To optimize InnoDB transaction processing, find the ideal balance between the performance overhead of
# transactional features and the workload of your server.
#
# For example, an application might encounter performance issues if it commits thousands of times per second,
# and different performance issues if it commits only every 2-3 hours.
#
# ) The default MySQL setting AUTOCOMMIT=1 can impose performance limitation on a busy DB server.
#
# 		Where practical, wrap several related data change operations into a single transaction,
# 		by issuing SET AUTOCOMMIT=0 or a START TRANSACTION statement, followed by a COMMIT statement
# 		after making all the changes.
#
# 		InnoDB must flush the log to disk at each transaction commit if that transaction made modifications
# 		to the database.
#
# 		When each change is followed by a commit (as with the default autocommit setting), the I/O throughput
# 		of the storage device puts a cap on the number of potentional operations per second.
#
# ) Alternatively, for transactions that consist only of a single SELECT statement, turning on AUTOCOMMIT
# 		helps InnoDB to recognize read-only transactions and optimize them.
#
# 		SEE OPTIMIZING INNODB READ-ONLY TRANSACTIONS later, for the requirements of this.
#
# ) Avoid performing rollbacks after inserting, updating or deleting huge numbers of rows.
#
# 		If a big transaction is slowing down server performance, rolling it back can make
# 		the problem worse, potentionally taking several times as long to perform as the
# 		original data change operations.
#
# 		Killing the DB process does not help, because the rollback starts again on server startup.
#
# 		To minimize the chance of this issue occurring:
#
# 			 ) Increase the size of the buffer pool so that all data change changes can be cached rather
#				than immediately written to disk.
#
# 			) Set innodb_change_buffering=all so that update and delete operations are buffered in addition to inserts.
#
# 			) Consider issuing COMMIT statements periodically during the big data change operation,
# 			possibly breaking a single delete or update into multiple statements that operate
# 			on smaller number of rows.
#
# 		To get rid of a runaway rollback once it occurs, increase the buffer pool so that the rollback
# 		becomes CPU-bound and runs fast, or kill the server and restart with innodb_force_recovery=3,
# 		as explained in INNODB RECOVERY 
#
# 		The issue is expected to be infrequent with the defualt setting innodb_change_buffering=all, which 
# 		allows update and delete operations to be cached in memory, making them faster to perform in
# 		the first place, and also faster to roll back if needed.
#
# 		Make sure to use this parameter setting on servers that process long-running transactions
# 		with many inserts, updates or deletes.
#
# ) If you can afford the loss of some of the latest committed transactions if a crash occurs,
# 		you can set the innodb_flush_log_at_trx_commit parameter to 0.
#
# 		InnoDB tries to flush the log once per second anyway, although the flush is not guaranteed.
#
# ) WHen rows are modified or deleted, the rows and associated undo logs are not physically removed immediately,
# 		or even immediately after the transaction commits.
#
# 		The old data is preserved until transactions that started earlier or concurrently are finished,
# 		so that those transactions can access the previous state of modified or deleted rows.
#
# 		Thus, a long-running transaction can prevent InnoDB from purging data that was changed by a different transactions.
#
# ) When rows are modified or deleted with a long-running transaction, other transactions using
# 		the READ_COMMITTED and REPEATABLE_READ isolation levels have to do more work to reconstruct the
# 		older data if they read those same rows.
#
# ) When a long running transaction modifies a table, queries against that table from other transactions
# 		do not make use of the covering index technique.
#
# 		Queries that normally could retrieve all the results columns from a secondary index,
# 		instead look up the appropriate values from the table data.
#
# 		If secondary index pages are found to have a PAGE_MAX_TRX_ID that is too new, or if records
# 		in the secondary index are delete-marked, InnoDB may need to look up records using a clustered index.
#
# OPTIMIZING INNODB READ-ONLY TRANSACTIONS
#
# InnoDB can avoid the overhead associated with setting up the transaction ID (TRX_ID field)
# for transactions that are known to be read-only.
#
# A transaction ID is only needed for a transaction that might perform write operations or locking
# reads such as SELECT_---_FOR UPDATE.
#
# Eliminating unecessary transaction IDs reduces the size of internal data structures that are
# consulted each time a query or data change statement constructs a read view.
#
# INNODB detects read-only transactions when:
#
# 		) The transaction is started with the START_TRANSACTION_READ_ONLY statement.
#
# 			IN this case, attempting to make changes to the database (for InnoDB, MyISAM or other
# 			types of tables) causes an error, and the transaction continues in read-only state:
#
# 				ERROR 1792 (25006): Cannot execute statement in a READ ONLY transaction
#
# 			You can still make changes to session-specific temporary tables in a read-only transaction,
# 			or issue locking queries for them, because those changes and locks are not visible to
# 			any other transaction.
#
# 		) The autocommit setting is turned on, so that the transaction is guaranteeed to be a single statement,
# 			and the single statement making up the transaction is a "Non-locking" SELECT statement.
#
# 			That is, a SELECT that does not use a FOR UPDATE or LOCK IN SHARED MODE clause.
#
# 		) The transaction is started without the READ ONLY option, but on updates or statements that explicitly
# 			locks have been executed yet.
#
# 			Until updats or explicit locks are required, a transaction stays in read-only mode.
#
# THus, for a read-intensive application such as a report generator,  you can tune a sequence of InnoDB
# queries by grouping them inside START_TRANSACTION_READ_ONLY and COMMIT, or by turning on the autocommit
# setting before running the SELECT statements, or simply by avoiding any data change statements interspersed
# with the queries.
#
# For information about START_TRANSACTION and autocommit, see later under START TRANSACTION, COMMIT, AND ROLLBACK SYNTAX
#
# NOTE:
#
# 		Transactions that qualify as auto-commit, non-locking and read-only (AC-NL-RO) are kept out of certain internal
# 		InnoDB data structures and are therefore not listed in SHOW_ENGINE_INNODB_STATUS output.
#
# OPTIMIZING INNODB REDO LOGGING
#
# Consider the following guidelines for optimizing redo logging:
#
# 		) Make your redo files big, even as big as the buffer pool.
#
# 			When InnoDB has written the redo log files full, it must write the modified contents of the buffer
# 			pool to disk in a checkpoint.
#
# 			Small redo log files cause many unecessary disk writes.
#
# 			Although historically big redo log files caused lengthy recovery times, recovery is now
# 			much faster and you can confidently use large redo log files.
#
# 			The size and number of redo log files are configured using the innodb_log_file_size and innodb_log_files_in_group
# 			 configuration options.
#
# 			For information about modifying an existing redo log file configuration, see CHANGING THE NUMBER OR SIZE OF REDO LOG FILES.
#
# 		) Consider increasing the size of the log buffer.
#
# 			A large log buffer enables large transactions to run without a need to write the log to disk before the transactions
# 			commit.
#
# 			Thus, if you have transactions that update, insert, or delete many rows, making the log buffer large saves disk i/O.
#
# 			Log buffer size is configured using the innodb_log_buffer_size configuration option, which can be configured
# 			dynamically in 8.0
#
# 		) Configure the innodb_log_write_ahead_size configuration option to avoid "read-on-write".
#
# 			This option defines the write-ahead block size for the redo log.
#
# 			Set innodb_log_write_ahead_size to match the operating system or file system cache block size.
#
# 			Read-on-write occurs when redo log blocks are not entirely cached to the operating system
# 			or file system due to a mismatch between write-ahead block size for the redo log and operating system
# 			or file system cache block size.
# 
# 			Valid values for innodb_log_write_ahead_size are multiples of the InnoDB log file block size (2^n).
# 			The minimum value is the InnoDB log file block size (512)
#
# 			Write-ahead does not occur when the minimum value if specified.
#
# 			THe maxium value is equal to the innodb_page_size value.
#
# 			If you specify a value for innodb_log_write_ahead_size that is larger than the innodb_page_size
# 			value, the innodb_log_write_ahead_size setting is truncated to the innodb_page_size value.
#
# 			Setting the innodb_log_write_ahead_size value too low in relation to the operating system or file system
# 			cache block size results in read-on-write.
#
# 			Setting the value too high may have a slight impact on fsync performance for log file writes due to several
# 			blocks being written at once.
#
# 		) Optimize the use of spin delay by user threads waiting for flushed redo.
#
# 			Spin delay helps reduce latency. 
# 
# 			During periods of low concurrency, reducing latency may be less of a priority, and avoiding the use of spin delay during these periods may reduce
# 			energy consumption.
#
# 			During periods of high concurrency, you may want to avoid expending processing power on spin delay
# 			so that it can be used for other work.
#
# 			The following system variables permit setting high and low watermark values that define boundaries for the use of spin delay:
#
# 				) innodb_log_wait_for_flush_spin_hwm: Defines the maximum average log flush time beyond which user threads no longer spin while
# 						waiting for flushed redo.
#
# 					The default is 400 microseconds.
#
# 				) innodb_log_spin_cpu_abs_lwm: Defines the minimum amount of CPU usage below which user threads no longer spin while waiting
# 						for flushed redo.
#
# 						The value is expressed as a sum of CPU core usage.
#
# 						For example, the default value of 80 is 80% of a single CPU core.
#
# 						On a system with a multi-core processor, a value of 150 represents 100% usage of one cpu core plus50% usage of a second CPU core.
#
# 				) innodb_log_spin_cpu_pct_hwm: Defines the maximum amount of CPU usage above which user threads no longer spin while waiting for flushed redo.
#
# 						The value is expressed as a percentage of the combined total processing power of all CPU cores.
#
# 						The default value is 50%. For example, 100% usage of two cpu cores is 50% of the combined CPU processing power on a server with 4 CPU cores.
#
# 						The innodb_log_spin_cpu_pct_hwm configuration option respects processor affinity.
#
# 						For example, if a server has 48 cores but the mysqld process is pinned to only 4 CPU cores, the other 44 CPU cores are ignored.
#
# BULK DATA LOADING FOR INNODB TABLES
#
# These performance tips supplement the general guidelines for fast inserts in OPTIMIZING INSERT STATEMENTS.
#
# ) WHen importing data into InnoDB, turn off autocommit mode, because it performs a log flush to disk for every insert.
#
# 		To disable autocommit during your import operation, surround it with SET_autocommit and COMMIT statements:
#
# 			SET autocommit=0;
# 			___ SQL import statements ___
# 			COMMIT;
#
# 		The mysqldump option --opt creates dump files that are fast to import into an INnoDB table,
# 		even without wrapping them with the SET_autocommit and COMMIT statements.
#
# ) If you have UNIQUE constraints on secondary keys, you can speed up table imports by temporarily
# 		turning off the uniqueness checks during the import session:
#
# 			SET unique_checks=0;
# 			___ SQL import statements ___
# 			SET unique_checks=1;
#
# 		For big tables, this saves a lot of disk I/O because InnoDB can use its change buffer to write secondary
# 		index records in a batch.
#
# 		Be certain that hte data contains no duplicate keys.
#
# ) If you have FOREIGN KEY constraints in your tables, you can speed up table imports by turning off the foreign key
# 	checks for the duration of the import session:
#
# 		SET foreign_key_checks=0;
# 		___ SQL import statements ___
# 		SET foriegn_key_checks=1;
#
# 		For big tables, this can save a lot of disk I/O
#
# ) Using the multiple-row INSERT syntax to reduce communication overhead between the client and the server
# 		if you need to insert many rows:
#
# 		INSERT INTO yourtable VALUES (1,2), (5,5), ---;
#
# 		This tip is valid for inserts into any table, not just InnoDB tables.
#
# ) When doing bulk inserts into tables with auto-increment columns, set innodb_autoinc_lock_mode to 2
# 		(interleaved) instead of 1 (consecutive).
#
# 		see AUTO_INCREMENT HANDLING IN INNODB for details
#
# ) When performing bulk inserts, it is faster to insert rows in PRIMARY KEY order.
#
# 	 InnoDB tables use a clustered index, which makes it relativily fast to use data in the order of the PRIMARY KEY.
#
# 	 Performing bulk inserts in PRIMARY KEY order is particularly important for tables taht do not fit entirely
# 	 within the buffer pool.
#
# ) For optimal performance when loading data into an InnoDB FULLTEXT index, follow this set of steps:
#
# 		a. Define a column FTS_DOC_ID at table creation time, of type BIGINT UNSIGNED NOT NULL, with a unique
# 			index named FTS_DOC_ID_INDEX.
#
# 			For example:
#
# 			CREATE TABLE t1 (
# 			FTS_DOC_ID BIGINT unsigned NOT NULL AUTO_INCREMENT,
# 			title varchar(255) NOT NULL DEFAULT '',
# 			text mediumtext NOT NULL,
# 			PRIMARY KEY (`FTS_DOC_ID`)
# 			) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
#
# 			CREATE UNIQUE INDEX FTS_DOC_ID_INDEX on t1(FTS_DOC_ID);
#
# 		b. Load the data into the tabe
#
# 		c. Create the FULLTEXT index after the data is loaded.
#
# 			NOTE:
#
# 				When adding  FTS_DOC_ID column at table creation time, ensure that the FTS_DOC_ID column
# 				is updated when the FULLTEXT indexed column is updated, as the FTS_DOC_ID must increase
# 				monotonically with each INSERT or UPDATE.
#
# 				If you choose not to add the FTS_DOC_ID at table creation time and have InnoDB manage DOC IDs
# 				for you, InnoDB will add the FTS_DOC_ID as a hidden column with the next CREATE_FULLTEXT_INDEX call.
#
# 				This approach, however, requires a table rebuild which will impact performance.
#
# OPTIMIZING INNODB QUERIES
#
# To turn queries for InnoDB tables, create an appropriate set of indexes on each table.
#
# See HOW MYSQL USES INDEXES for details.
#
# Follow these guidelines for InnoDB indexes:
#
# 		) Because each InnoDB table has a primary key (whether you request one or not), specify a set
# 			of primary key columns for each table, columns that are used in the most important and 
# 			time-critical queries.
#
# 		) Do not specify too many or too long columns in the primary key, because these column values are
# 			duplicated in each secondary index.
#
# 			When an index contains unnecessary data, the I/O to read this data and memory to cache it
# 			reduce the performance and scalability of the server.
#
# 		) Do not create a separate secondary index for each column, because each query can only make use of one index.
#
# 			Indexes on rarely tested columns or columns with only a few different values might not be 
# 			helpful for any queries. 
#
# 			If you have many queries for the same table, testing different combinations of columns, try to
# 			create a small number of concatenated indexes rather than a large number of single-column indexes.
#
# 			If an index contains all the columns needed for the result set (known as a covering index)
# 			, the query might be able to avoid reading the table data at all.
#
# 		) If an indexed column cannot contain any NULL values, declare it as NOT NULL when you create the table.
#
# 			The optimizer can better determine which index is most effective to use for a query, when it knows
# 			whether each column contains NULL values. 	
#
# 		) You can optimize single-query transactions for InnoDB tables, using the technique in OPTIMZING INNODB READ-ONLY TRANSACTIONS
#
# OPTIMIZING INNODB DDL OPERATIONS
#
# ) Many DDL operations on tables and indexes (CREATE, ALTER and DROP statements) can be performed online.
#
# 		See INNODB AND ONLINE DDL for details.
#
# ) Online DDL support for adding secondary indexes means that you can generally speed up the process of creating
# 		and loading a table and associated indexes by creating the table without secondary indexes, then adding
# 		secondary indexes after the data is loaded.
#
# ) Use TRUNCATE_TABLE to empty a table, not DELETE FROM tbl_name.
#
# 		Foreign key constraints can make a TRUNCATE statement work like a regular DELETE statement,
# 		in which case a sequence of commands like DROP_TABLE and CREATE_TABLE might be fastest.
#
# ) Because the primary key is integral to the storage layout of each InnoDB table, and changing
# 		the definition of the primary key involves organizing the whole table,
# 		always set up the primary key as part of the CREATE_TABLE statement, and plan ahead so
# 		that you do not need to ALTER or DROP the primary key afterwards.
#
# OPTIMIZING INNODB DISK I/O
#
# If you follow best practices for database design and tuning techniques for SQL operations,
# but your database is still slow due to heavy disk I/O activity, consider these disk I/O optimizations.
#
# If the Unix top tool or the Windows Task Manager show that the CPU usage percentage with your workload
# is < than 70%, your workload is probably disk-bound.
#
# ) Increase buffer pool size
#
# 		When table data is cached in teh InnoDB buffer pool, it can be accessed repeatedly by queries
# 		without requiring any disk I/O.
#
# 		Specify the size of the buffer pool with the innodb_buffer_pool_size option.
#
# 		This memory are is important enough that it is typically recommended that innodb_buffer_pool_size
# 		is configured to 50 to 75 % of the system memory.
#
# 		For more info, see HOW MYSQL USES MEMORY
#
# ) Adjust the flush method
#
# 		In some versions of GNU/Linux and UNIX, flushing files to disk with the Unix fsync() call
# 		(which InnoDB uses by default) and similar methods is surprisingly slow.
#
# 		If database write performance is an issue, conduct benchmarks with the innodb_flush_method 
# 		parameter set to O_DSYNC
#
# ) Configure a threshold size for the write buffer.
#
# 		By default, when InnoDB creates a new data file, such as a new log file or tablespace file,
# 		it flushes the contents of the write buffer to disk only after the file is fully written,
# 		which can cause a large amount of disk write activity to occur at once.
#
# 		To force smaller, periodic flushes, use innodb_fsync_threshold (introduced in MySQL 8.0.13)
# 		to define a threshold size for the write buffer, in bytes.
#
# 		The contents of the write buffer are flushed to disk when the threshold size is reached.
#
# 		The default value of 0 forces the default behavior.
#
# 		Specifying a write buffer threshold size to force smaller, periodic flushes may be beneficial
# 		in cases where multiple MySQL instances use the same storage devices.
#
# 		For example, creating a new MySQL instance and its associated data files could cause large surges
# 		of disk write activity, impeding the performance of other MySQL instances that use
# 		the same storage devices.
#
# 		Configuring a write buffer threshold size helps avoid such surges in disk write activity.
#
# ) Use a noop or deadline I/O scheduler with native AIO on Linux
#
# 		InnoDB uses the asynchronous I/O subsystem (native AIO) on Linux to perform read-ahead and
# 		write requests for data file pages.
#
# 		This behavior is controlled by the innodb_use_native_aio configuration option, which is enabled
# 		by default.
#
# 		With native AIO, the type of I/O scheduler has greater influence on I/O performance.
#
# 		Generally, noop and deadline I/O schedulers are recommended.
#
# 		Conduct benchmarks to determine which I/O scheduler provides the best results for your
# 		workload and environment. For more information, see later under USING ASYNCHRONOUS I/O ON LINUX
#
# ) Use direct I/O on Solaris 10 for x86_64 architechture
#
# 		When using the InnoDB storage engine on Solaris 10 for x86_64 architechture (AMD Opteron), use direct I/O
# 		for InnoDB-related files to avoid degradation of InnoDB performance.
#
# 		TO use direct I/O for an entire UFS file system used for storing InnoDB-related files, mount it with
# 		the forcedirectio option; see mount_ufs(1M)
#
# 		(The default on Solaris 10/x86_64 is NOT to use this option)
#
# 		To apply direct I/O only to InnoDB file operations rather than the whole file system,
# 		set innodb_flush_method_=O_DIRECT
#
# 		With this setting, InnoDB calls directio() instead of fcntl() for I/O to data files
# 		(not for I/O to log files)
#
# ) Use raw storage for data and log files with Solaris >= 2.6
#
# 		When using the InnoDB storage engine with a large innodb_buffer_pool_size value on any
# 		release of Solaris >= 2.6 and any platform (sparc/x86/x64/amd64), conduct benchmarks
# 		with InnoDB data files and log files on raw devices or on separate direct I/O UFS file systems,
# 		using the forcedirectio mount option described as prev.
#
# 		(it is necessary to use the mount option rather than setting innodb_flush_method if you want
# 		direct I/O for the log files)
#
# 		Users of the Veritas file system VxFS should use the convosync=direct mount option
#
# 		Do not place other MySQL data files, such as those for MyISAM tables, on a direct I/O file system.
#
# 		Executables or libraries MUST NOT be placed on a direct I/O file system.
#
# ) Use additional storage devices
#
# 		Additional storage devices could be used to set up a RAID configuration.
#
# 		For related information, see OPTIMIZING DISK I/O
#
# 		Alternatively, InnoDB tablespace data files and log files can be placed on  different
# 		physical disks.
# 			
# 		For more info, read under:
#
# 			 ) INNODB STARTUP CONFIGURATION
#
# 			) CREATING A TABLESPACE OUTSIDE OF THE DATA DIRECTORY
#
# 			) CREATING A GENERAL TABLESPACE
#
# 			) MOVING OR COPYING INNODB TABLES
#
# ) Consider non-rotational storage
#
# 		Non-rotational storage generally provides better performance for random I/O operations;
# 		and rotational storage for sequential I/O operations.
#
# 		When distributing data and log files across rotational and non-rotational storage devices,
# 		consider the type of I/O operations that are predominantly performed on each file.
#
# 		Random I/O-oriented files typically include file-per-table and general tablespace data files,
# 		undo tablespaces files and temporary tablespace files.
#
# 		Sequential I/O-oriented files include InnoDB system tablespace files (due to doublewrite buffering
# 		and change buffering) and log files such as binary log files and redo log files.
#
# 		Review settings for the following configuration options when using non-rotational storage:
#
# 			) innodb_checksum_algorithm
#
# 				The crc32 option uses a faster checksum algorithm and is recommended for fast storage systems.
#
# 			) innodb_flush_neighbors
#
# 				This option optimizes I/O for rotational storage devices. Disable it for non-rotational storage
# 				or a mix of rotational and non-rotational storage.
#
# 				It is disabled by default.
#
# 			) innodb_io_capacity
#
# 				The default setting of 200 is generally sufficient for lower-end non-rotational storage device.
#
# 				For higher-end, bus-attached devices, consider a higher setting such as 1000.
#
# 			) innodb_io_capacity_max
#
# 				the default value of 2000 is intended for workloads that use non-rotational storage.
#
# 				For a high-end, bus-attached non-rotational storage device, consider a higher setting
# 				such as 2500.
#
# 			) innodb_log_compressed_pages
#
# 				If redo logs are on non-rotational storage, consider disabling this option to reduce logging.
# 				See DISABLE LOGGING OF COMPRESSED PAGES.
#
# 			) innodb_log_file_size
#
# 				If redo logs are on non-rotational storage, configure this option to maximize caching and write combining.
#
# 			) innodb_page_size
#
# 				Consider using a page size that matches the internal sector size of the disk.
#
# 				Early-generation SSD devices often have a 4kb sector size.
#
# 				SOme newer devices have a 16kb sector size.
#
# 				The default InnoDB page size is 16kb. Keeping the page size close to the storage device
# 				block size minimizes the amount of unchanged data that is rewritten to disk.
#
# 			) binlog_row_image
#
# 				If binary logs are on non-rotational storage and all tables have primary keys, consider setting this
# 				option to minimal to reduce logging.
#
# Ensure that TRIM support is enabled for your OS. It is typically enabled by default.
#
# ) Increase I/O capacity to avoid backlogs
#
# 	If throughput drops periodically because of InnoDB checkpoints operations, consider increasing the value
# 	of the innodb_io_capacity configuration option:
#
# 	Higher values cause more frequent flushing, avoiding the backlog of work that can cause dips in throughput.
#
# ) Lower I/O capacity if flushing does not fall behind
#
# 	If the system is not falling behind with InnoDB flushing operations, consider lowering the value of
# 	the innodb_io_capacity configuration option:
#
# 	Typically, you keep this option value as low as practical, but not so low that it causes periodic
# 	drops in throughput as mentioned in the preceding point.
#
# 	In a typical scenario where you could lower the option value, you might see a combination like this
# 	in the output from SHOW_ENGINE_INNODB_STATUS:
#
# 		) History list length low, below a few thousand
#
# 		) Insert buffer merges close to rows inserted
#
# 		) Modified pages in buffer pool consistently well below innodb_max_dirty_pages_pct of the buffer pool.
#
# 			(Measure at a time when the server is not doing bulk inserts; it is normal during bulk inserts for the
# 			modified pages percentage to rise significantly.)
#
# 		) Log sequence number - last checkpoint is at less than 7/8 or ideally less than 6/8 of the total size of the InnoDB log files.
#
# ) Store system tablespace files on Fusion-io devices
#
# 	You can take advantage of a doublewrite buffer-related I/O optimization by storing system tablespace files
# ("ibdata files") on Fusion-io devices that support atomic writes.
#
# IN this case, doublewrite buffer (innodb_doublewrite) is automatically disabled and Fusion-io atomic writes are used
# for all data files.
#
# This feature is only supported on Fusion-io hardware and is only enabled for Fusion-io NVMFS on Linux.
# To take full advantage of this feature, an innodb_flush_method setting of O_DIRECT is recommended.
#
# NOTE:
#
# 		BEcause the doublewrite buffer setting is global, doublewrite buffering is also disabled for data files residing
# 		on non-Fusion-io hardware.
#
# ) Disable logging for compressed pages
#
# 		WHen using the InnoDB table compression feature, images of re-compressed pages are written to the redo log
# 		when changes are made to compressed data.
#
# 		This behavior is controlled by innodb_log_compressed_pages, which is enabled by default to prevent corruption
# 		that can occur if a different version of the zlib compression algorithm is used during recovery.
#
# 		If you are certain that the zlib version will not change, disable innodb_log_compressed_pages to reduce redo log
# 		generation for workloads that modify compressed data.
#
# OPTIMIZING INNODB CONFIGURATION VARIABLES
#
# Different settings work best for servers with light, predictable loads, versus servers that are running
# near full capacity all the time, or that experience spikes of high activity.
#
# Because the InnoDB storage engine performs many of its optimizations automatically, many performance
# tuning tasks involve monitoring to ensure that the database is performing well, and changing configuration
# options when performance drops.
#
# See INNODB INTEGRATION WITH MYSQL PERFORMANCE SCHEMA for more info about detailed InnoDB performance monitoring.
#
# The main configuration steps you can perform include:
#
# 		) Controlling the type of data change operations for which InnoDB buffers the changed data,
# 			to avoid frequent small disk writes.
#
# 			See CONFIGURING CHANGE BUFFERING.
#
# 			Because the default is to buffer all types of data change operations, only change this setting
# 			if you need to reduce the amount of buffering.
#
# 		) Turning the adaptive hash indexing feature on and off using the innodb_adaptive_hash_index option.
# 			See ADAPTIVE HASH INDEX later, for more info.
# 			 
# 			You might change this setting during periods of unusual activity, then restore it to its original setting.
#
# 		) Setting a limit on the number of concurrent threads that InnoDB processes, if context switching is a bottleneck.
# 			See CONFIGURING THREAD CONCURRENCY FOR INNODB for more info
#
# 		) Controlling the amount of prefetching that InnoDB does with its read-ahead operations.
#
# 			WHen the system has unused I/O capacity, more read-ahead can improve the performance of queries.
# 			
# 			Too much read-ahead can cause periodic drops in performance on a heavily loaded system.
# 			See CONFIGURING INNODB BUFFER POOL PREFETCHING (READ-AHEAD) later, for more info.
#
# 		) Increasing the number of background threads for read or write operations, if you have a high-end
# 			I/O subsystem that is not fully utilized by the default values.
#
# 			See CONFIGURING THE NUMBER OF BACKGROUND INNODB I/O THREADS later for more.
#
# 		) Controlling how much I/O InnoDB performs in the background.
#
# 			See CONFIGURING THE INNODB MASTER THREAD I/O RATE, later, for more info:
#
# 			You might scale back this setting if you observe periodic drops in performance.
#
# 		) Controlling the algorithm that determines when InnoDB performs certain types of
# 			background writes. SEE CONFIGURING INNODB BUFFER POOL FLUSHING later, for more info.
#
# 			The algorithm works for some type of workloads but not others, so might turn off this setting if you
# 			observe periodic drops in performance.
#
# 		) Taking advantage of multicore processors and their cache memory configuration, to minimize delays
# 			in context switching. SEE CONFIGURING SPIN LOCK POLLING later, for more.
#
# 		) Preventing one-time operations such as table scans from interfering with the frequently accessed data
# 			stored in the InnoDB buffer cache. See MAKING THE BUFFER POOL SCAN RESISTANT later, for more info.
#
# 		) Adjusting log files to a size that makes sense for reliability and crash recovery.
#
# 			InnoDB log files have often been kept small to avoid long startup times after a crash.
# 			Optimizations introduced in MySQL 5.5 speed up certain steps of the crash recovery process.
#
# 			In particular, scanning the redo log and applying the redo log are faster due to improved
# 			algorithms for memory management.
#
# 			If you have kept your log files artificially small to avoid long startup times, you can now
# 			consider increasing log file size to reduce the I/O that occurs due to recycling of redo log records.
#
# 		) Configuring the size and number of instances for the InnoDB buffer pool, especially important for systems
# 			with multi-gigabyte buffer pools. see CONFIGURING MULTIPLE BUFFER POOL INSTACES for more info, later.
#
# 		) Increasing the maxium number of concurrent transactions, which dramatically improves scalability for the
# 			busiest databases. see UNDO LOGS later, for more info.
#
# 		) Moving purge operations (a type of garbage collection) into a background thread.
# 			See CONFIGURING INNODB PURGE SCHEDULING, later, for more info.
#
# 			To effectively measure the results of this setting, tune the other I/O-related and thread-related
# 			configuration settings first.
#
# 		) Reducing the amount of switching that InnoDB does between concurrent threads, so that SQL operations
# 			on a busy server do not queue up and form a "traffic jam".
#
# 			Set a value for the innodb_thread_concurrency option, up to a approximately 32 for a high-powered
# 			modern system.
#
# 			Increase the value for the innodb_concurrency_tickets option, typically to 5000 or so.
#
# 			This combination of options sets a cap on the number of threads that InnoDB process at any one time,
# 			and allows each thread to do substansial work before being swapped out, so that the number
# 			of waiting threads stays low and operations can complete without excessive context switching.
#
# OPTIMIZING INNODB FOR SYSTEMS WITH MANY TABLES
#
# ) If you have configured non-persistent optimizer statistics (a non-default configuration),
# 	InnoDB computes index cardinality values for a table the first time that table is accessed after
# 	startup, instead of storing such values in teh table.
#
# 	This step can take significant time on systems that partition the data into many tables.
#
# 	Since this overhead only applies to the initial table open operation, to "warm up" a table
#  for later use, access it immediately after startup by issuing a statement such as SELECT
# 	1 FROM tbl_name LIMIT 1.
#
# 	Optimizer statistics are persisted to disk by default, enabled by the innodb_stats_persistent
# 	configuration option.
#
# 	For information about persistent optimizer statistics, see CONFIGURING PERSISTENT OPTIMIZER STATISTICS PARAMETERS later on.
# 
# OPTIMIZING FOR MYISAM TABLES
#
# The MyISAM storage engine performs best with read-mostly data or with low-concurrency operations,
# because table locks limit the ability to perform simultaneous updates.
#
# In MYSQL, InnoDB is the default storage engine rather than MyISAM.
#
# OPTIMIZING MYISAM QUERIES
#
# Some general tips for speeding up queries on MyISAM tables:
#
# 		) To help MySQL better optimize queries, use ANALYZE_TABLE or run myisamchk --analyze on a table after it has been
# 			loaded with data.
#
# 			This updates a value for each index part that indicates the average number of rows that have the same value.
#
# 			(For unique indexes, this is always 1)
#
# 			MySQL uses this to decide which index to choose when you join two tables based on a nonconstant expression.
#
# 			You can check the result from the table analysis by using SHOW INDEX FROM tbl_name and exmaining
# 			the Cardinality 
#
# 			myisamchk --description --verbose shows index distribution information.
#
# 		) To sort an index and data according to an index, use myisamchk --sort-index --sort-records=1
# 			(assuming that you want to sort on index 1)
#
# 			This is a good way to make queries faster if you have a unique index from which  you want to read all
# 			rows in order according to the index.
#
# 			The first time you sort a large table this way, it may take a long time.
#
# 		) Try to avoid complex SELECT queries on MyISAM tables that are updated frequently, to avoid problems
# 			with table locking that occur due to contention between readers and writers.
#
# 		) MyISAM supports concurrent inserts: If a table has no free blocks in the middle of the data file, you can INSERT
# 			new rows into it at the same time that other threads are reading from the table.
#
# 			If it is important to be able to do this, consider using the table in ways that avoid deleting rows.
#
# 			Another possibility is to run OPTIMIZE_TABLE to defragment the table after you have deleted
# 			a lot of rows from it.
#
# 			This behavior is altered by setting the concurrent_insert variable.
#
# 			You can force new rows to be appended (and therefore permit concurrent inserts), even in tables
# 			that have deleted rows. See CONCURRENT INSERTS for more.
#
# 		) For MyISAM tables that change frequently, try to avoid all variable-length columns (VARCHAR, BLOB and TEXT)
#
# 			The table uses dynamic row format if it includes even a single variable-length column.
#
# 			See ALTERNATIVE STORAGE ENGINES for more.
#
# 		) It is normally not useful to split a table into different tables just because the rows become large.
#
# 			In accessing a row, the biggest performance hit is the disk seek needed to find the first byte of the row.
# 			After finding the data, most modern disks can read the entire row fast enough for most applications.
#
# 			The only cases where splitting up a table makes an appreciable difference is if it is a MyISAM table
# 			using dynamic row format that you can change to a fixed row size, or if you very often need
# 			to scan the table but do not need most of the columns.
#
# 			See ALTERNATIVE STORAGE ENGINES, later.
#
# 		) Use ALTER TABLE --- ORDER BY expr1, expr2, --- if you usually retrieve rows in expr1, expr2, --- order.
#
# 			By using this option after extensive changes to the table, you may be able to get
# 			higher performance.
#
# 		) If you often need to calculate results such as counts based on information from a lot of rows,
# 			it may be preferable to introduce a new table and update the counter in real time.
#
# 			An update of the following form is very fast:
#
# 				UPDATE tbl_name SET count_col=count_col+1 WHERE key_col=constant;
#
# 			This is very important when you use MySQL storage engines such as MyISAM that has only table-level locking
# 			(multiple readers with single writers)
#
# 			This also gives better performance with most database systems, because the row locking manager in this case
# 			has less to do.
#
# 		) Use OPTIMIZE TABLE periodically to avoid fragmentation with dynamic-format MyISAM tables. See MYISAM TABLE STORAGE FORMATS for more info.
#
# 		) Declaring a MyISAM table with the DELAY_KEY_WRITE=1 table option makes index updates faster because they are not flushed
# 			to disk until the table is closed.
#
# 			The downside is that if something kills the server while such a table is open, you must ensure that the table is okay
# 			by running the server with the --myisam-recover-options option, or by running myisamchk before restarting the server.
#
# 			(However, even in this case, you should not lose anything by using DELAY_KEY_WRITE, because
# 			the key information can always be generated from teh data rows)
#
# 		) Strings are automatically prefix- and end-space compressed in MyISAM indexes. See CREATE INDEX SYNTAX for more.
#
# 		) You can increase performance by caching queries or answers in your application and then executing many
# 			inserts or updates together.
#
# 			Locking the table during this operation ensures that the index cache is only flushed once after all updates.
#
# BULK DATA LOADING FOR MYISAM TABLES
#
# These performance tips supplement the general guidelines for fast inserts in OPTIMIZING INSERT STATEMENTS discussed earlier
#
# ) For a MyISAM table, you can use concurrent inserts to add rows at the same time that SELECT statements are running,
# 		if there are no deleted rows in middle of the data file.
#
# 		see CONCURRENT INSERTS for more.
#
# ) With some extra work, it is possible to make LOAD_DATA_FILE run even faster for a MyISAM table when the tables has 
# 		many indexes.
#
# 		Use the following procedure:
#
# 			a. Execute a FLUSH TABLES statement or a mysqladmin flush-tables command
#
# 			b. Use myisamchk --keys-used=0 -rq /path/to/db/tbl_name to remove all use of indexes for the table.
#
# 			c. Insert data into the table with LOAD_DATA_INFILE. This does not update any indexes and therefore is very fast.
#
# 			d. If you intend only to read from the table in the future, use myisampack to compress it. See COMPRESSED TABLE CHARACTERISTICS for more.
#
# 			e. Re-create the indexes with myisamchk -rq /path/to/db/tbl_name
#
# 				This creates the index tree in memory before writing it to disk, which is much faster than
# 				updating the index during LOAD_DATA_INFILE because it avoids lots of disk seeks.
#
# 				The resulting index tree is also perfectly balanced.
#
# 			f. Execute a FLUSH_TABLES statement or a mysqladmin flush-tables command
#
# LOAD_DATA_INFILE performs the preceding optimization automatically if the MyISAM table into which
# you insert data is empty.
#
# The main difference between automatic optimization and using the procedure explicitly is that you can
# let myisamchk allocate much more temporary memory for the index creation than you might want the server to allocate
# for index re-creation when it executes the LOAD_DATA_INFILE statement.
#
# You can also disable or enable the nonunique indexes for a MyISAM table by using the following statements
# rather than myisamchk.
#
# If you use these statements, you can skip the FLUSH_TABLES operations:
#
# 		ALTER TABLE tbl_name DISABLE KEYS;
# 		ALTER TABLE tbl_name ENABLE KEYS;
#
# ) To speed up INSERT operations that are performed with multiple statements for nontransactional tables,
# 	lock your tables:
#
# 		LOCK TABLES a WRITE;
# 		INSERT INTO a VALUES (1,23), (2,34), (4,33), ---;
# 		INSERT INTO a VALUES (8, 26), (6,29);
# 		---
# 		UNLOCK TABLES;
#
# THis benefits performance because the index buffer is flushed to disk only once, after all INSERT
# statements have completed.
#
# Normally, there would be as many index buffer flushes as there are INSERT statements.
# Explicit locking statements are not needed if you can insert all rows with a single INSERT.
#
# Locking also lowers the total time for multiple-connection tests, although the maximum wait time
# for individual connections might go up because they wait for locks.
#
# Suppose that five clients attempts to perform inserts simultaneously as follows:
#
# 		) Connection 1 does 1000 inserts
#
# 		) Connection 2,3 and 4 do 1 insert
#
# 		) Connection 5 does 1000 inserts
#
# If you do not use locking, connection 2,3 and 4 finishes before 1 and 5.
#
# If you use locking, connections 2,3, 4 probably do not finish before 1 or 5, but the total time
# should be about 40% faster
#
# INSERT, UPDATE and DELETE operations are very fast in MySQL, but you can obtain better overall
# performance by adding locks around everything that does more than about five successive inserts or updates.
#
# If you do very many successive inserts, you could do a LOCK_TABLES followed by an UNLOCK_TABLES once in
# while (each 1000 rows or so) to permit other threads to access table.
#
# This would still result in a nice performance gain.
#
# INSERT is still much slower for loading data than LOAD_DATA_INFILE, even when using the strategies just outlined.
#
# ) To increase performance for MyISAM tables, for both LOAD_DATA_INFILE and INSERT, enlarge the key cache
# 	by increasing the key_buffer_size system variable.
#
# For more info, see CONFIGURING THE SERVER.
#
# OPTIMIZING REPAIR TABLE STATEMENTS
#
# REPAIR_TABLE for MyISAM tables is similar to using myisamchk for repair operations, and some of the same performance optimizations apply.
#
# 		) myisamchk has variables that control memory allocation. You may be able to improve its performance by setting these variables.
# 			See MYISAMCHK MEMORY USAGE earlier.
#
# 		) For REPAIR_TABLE, the same principle applies, but because the repair is done by the server, you set server system variables
# 			instead of myisamchk variables.
#
# 			Also, in addition to setting memory-allocation variables, increasing the myisam_max_sort_file_Size system variable
# 			increases the likelihood that the repair will use the faster filesort method and avoid the slower repair by key cache method.
#
# 			Set the variable to the maximum file size for your system, after checking to be sure that htere is enough free space
# 			to hold a copy of the table files.
#
# 			The free space must be available in the file system containing the original table files.
#
# Suppose that a myisamchk table-repair operation is done using the following options to 
# set its memory-allocation variables:
#
# 		--key_buffer_size=128M --myisam_sort_buffer_size=256M
# 		--read_buffer_size=64M --write_buffer_size=64M
#
# Some of those myisamchk variables correspond to server system variables:
#
# 	myisamchk Variable 		System variable
#
# 	key_buffer_size 			key_buffer_size
# 	myisam_sort_buffer_Size myisam_sort_buffer_size 			
# 	read_buffer_size 			read_buffer_size
# 	write_buffer_size 		None
#
# Each of the server system variables can be set at runtime, and some of them (myisam_sort_buffer_Size, read_buffer_Size) have a 
# session value in addition to a global value.
#
# Setting a session value limits the effect of the change to your current session and does not affect other users.
#
# Changing a global-only variable (key_buffer_size, myisam_max_sort_file_size) affects other users as well.
#
# For key_buffer_size, you must take into account that the buffer is shared with those users.
#
# For example, if you set the myisamchk key_buffer_size variable to 128 mb, you could set the corresponding key_buffer_size
# system variable larger than that (if it is not already set larger), to permit key buffer use by activity in other sessions.
#
# However, changing the global key buffer size invalidates the buffer, causing increased disk I/O and slowdown for other
# sessions.
#
# An alternative that avoids this problem is to use a separate key cache, assign to it the indexes from the table to be repaired,
# and deallocate it when the repair is complete.
#
# See MULTIPLE KEY CACHES for more info.
#
# Based on the preceding remarks, a REPAIR_TABLE operation can be done as follows to use settings similar to the
# myisamchk command.
#
# Here a separate 128MB key buffer is allocated and the file system is assumed to permit a file size 
# of at least 100gb.
#
# SET SESSION myisam_sort_buffer_size = 256*1024*1024;
# SET SESSION read_buffer_size = 64*1024*1024;
#
# SET GLOBAL myisam_max_sort_file_size = 100*1024*1024*1024;
# SET GLOBAL repair_cache.key_buffer_size = 128*1024*1024;
#
# CACHE INDEX tbl_name IN repair_cache;
# LOAD INDEX INTO CACHE tbl_name;
# REPAIR TABLE tbl_name;
# SET GLOBAL repair_cache.key_buffer_size = 0;
#
# If you intend to change a global variable but want to do so only for the duration of a REPAIR_TABLE operation to minimally
# affect other users, save its value in a user variable and restore it afterwards.
#
# FOr example:
#
# SET @old_myisam_sort_buffer_size = @@GLOBAL.myisam_max_sort_file_size;
# SET GLOBAL myisam_max_sort_file_size = 100*1024*1024*1024;
# REPAIR TABLE tbl_name;
# SET GLOBAL myisam_max_sort_buffer_size = @old_myisam_max_sort_file_size;
#
# The system variables that affect REPAIR_TABLE can be set globally at server startup if you want the values to be in effect by default.
# 
# FOr example, add these lines to the server my.cnf file:
#
# 		[mysqld]
# 		myisam_sort_buffer_size=256M
# 		key_buffer_size=1G
# 		myisam_max_sort_file_size=100G
#
# These settings do not include read_buffer.size
#
# Setting read_buffer_size globally to a large value does so for all sessions and can cause performance
# to suffer due to excessive memory allocation for a server with many simultaneous sessions.
#
# OPTIMIZING FOR MEMORY TABLES
#
# Consider using MEMORY tables for noncritical data that is accessed often, and is read-only or rarely updated.
#
# Benchmark your application against equivalent InnoDB or MyISAM tables under a realistic workload, to confirm
# that any additional performance is worth the risk of losing data, or the overhead of copying data from a 
# disk-based table at application start.
#
# For best performance with MEMORY tables, examine the kinds of queries against each table, and specify the type
# to use for each associated index, either a B-Tree index or a hash index.
#
# On the CREATE_INDEX statement, use the clause USING BTREE or USING HASH.
#
# B-tree indexes are fast for queries that do greater than or less than comparisons through
# operators such as > or BETWEEN.
#
# Hash indexes are only fast for queries that look up single values through the = operator, or a restricted
# set of values through the IN operator.
#
# FOr why USING BTREE is often a better choice than the default USING HASH, see AVOIDING FULL TABLE SCANS previously.
#
# For implementation details on different types of MEMORY indexes, see earlier, COMPARISON OF B-TREE AND HASH INDEXES
#
# UNDERSTANDING THE QUERY EXECUTION PLAN
#
# Depending On the details of your tables, columns, indexes and conditions in your WHERE clause,
# the MySQL optimizer considers many techniques to efficiently perform the lookups involved in an
# SQL query.
#
# A query on a huge table can be performed without reading all the rows;
#
# A join involving several tables can be performed without comparing every combination of rows.
#
# The set of operations that hte optimizer chooses to perform the most efficient query is called
# "the query execution plan", also known as the EXPLAIN plan.
#
# Your goal is to recognize the aspects of the EXPLAIN plan that indicate a query is optimized well,
# and to learn the SQL syntax and indexing techniques to improve the plan, if possible.
#
# OPTIMIZING QUERIES WITH EXPLAIN
#
# THe EXPLAIN statement provides information about how MySQL executes statements:
#
# 		) EXPLAIN works with SELECT, DELETE, INSERT, REPLACE and UPDATE statements.
#
# 		) When EXPLAIN is used with an explainable statement, MySQL displays information from the optimizer about
# 			the statement execution plan.
#
# 			That is, MySQL explains how it would process the statement, including information about how tables
# 			are joined and in which order.
#
# 			For information about using EXPLAIN to obtain execution plan information, see EXPLAIN OUTPUT FORMAT
#
# 		) When EXPLAIN is used with FOR CONNECTION connection_id rather than an explainable statement, it displays
# 			the execution plan for the statement executing in teh named connection.
#
# 			See OBTAINING EXECUTION PLAN INFORMATION FOR A NAMED CONNECTION
#
# 		) For SELECT statements, EXPLAIN produces additional execution plan information that can be displayed
# 			using SHOW_WARNINGS.
#
# 			See EXTENDED EXPLAIN OUTPUT FORMAT for more info.
#
# 		) EXPLAIN is useful for examining queries involving partitioned tables.
#
# 			See OBTAINING INFORMATION ABOUT PARTITIONS for more info
#
# 		) The FORMAT options can be used to select the output format.
#
# 			TRADITIONAL presents the output in tabular format.
#
# 			This is the default if not FORMAT option is present.
#
# 			JSON Format displays the information in JSON format.
#
# With the help of EXPLAIN, you can see where you should add indexes to tables so that the statement executes
# faster by using indexes to find rows.
#
# YOu can also use EXPLAIN to check whether the optimizer joins the tables in an optimal order.
#
# To give a hint to the optimizer to use a join order corresponding to the order in which the
# tables are named in a SELECT statement, begin the statement with SELECT STRAIGHT_JOIN rather than just select.
#
# See SELECT SYNTAX for more.
#
# However, STRAIGHT_JOIN may prevent indexes from being used because it disables semi-join transformations.
#
# See OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES and COMMON TABLE EXPRESSIONS WITH SEMI-JOIN TRANSFORMATIONS.
#
# The optimizer trace may sometimes provide information complementary to that of EXPLAIn.
#
# However, the optimizer trace format and content are subject to change betwen versions.
#
# For details, see MYSQL INTERNALS: TRACING THE OPTIMIZER
#
# If you ahve a problem with indexes not being used when you believe that they should be, run ANALYZE_TABLE
# to update table statistics, such as cardinality of keys, that can affect the choices the optimizer makes.
#
# See ANALYZE TABLE syntax for more.
#
# NOTE:
#
# 		EXPLAIN can also be used to obtain information about the columns in a table.
#
# 		EXPLAIN tbl_name is synonymous with DESCRIBE tbl_name and SHOW COLUMNS FROM tbL_name.
#
# 		For more info, see DESCRIBE syntax and SHOW COLUMNS syntax
#
# EXPLAIN OUTPUT FORMAT
#
# THe explain statement provides information about how MySQL executes statements.
#
# EXPLAIN works with SELECT, DELETE, INSERT, REPLACE and UPDATE statements.
#
# EXPLAIN returns a row of information for each table used in the SELECT statement.
#
# It lists the tbales in the output in teh order that MySQL would read them while
# processing the statement.
#
# MySQL resolves all joins using a nested-loop join method.
#
# THis means that MySQL reads a row from the first table, and then finds a matching row
# in the second table, teh third table, and so on.
#
# When all tables are processed, MySQL outputs the selected columns and backtracks through
# the table list until a table is found for which there are more matching rows.
#
# The next row is read from this table and the process continues with the next table.
#
# NOTE:
#
# 		mySQL Workbench has a Visual Explain capability that provides a visual representation of EXPLAIN output.
# 		See TUTORIAL: USING EXPLAIN TO IMPROVE QUERY PERFORMANCE
#
# EXPLAIN OUTPUT COLUMNS
#
# This section describes the output columns produced by EXPLAIN.
# Later sections provide additional information about the type and Extra columns.
#
# Each output row from EXPLAIN provides information about one table.
#
# Each row contains the values summarized in EXPLAIN IN OUTPUT COLUMNS, and described in
# more detail in the following table.
#
# Column names are shown in teh table's first column; the second column provides the
# equivalent property name shown in the output when FORMAT=JSON is used.
#
# EXPLAIN OUTPUT COLUMNS
#
# Column 				JSON name 				Meaning
#
# id 						select_id 				The SELECT identifier
# select_type 			None 						The SELECT type
#
# table 					table_name 				The table for the output row
# partitions 			partitions 				The matching partitions
#
# type 					access_type 			The join type
# Possible_keys 		possible_keys 			The possible indexes to choose
#
# key 					key 						The index actually chosen
# key_len 				key_length 				The length of the chosen key
#
# ref 					ref 						The columns compared to the index
# rows 					rows 						Estimate of rows to be examined
#
# filtered 				Filtered 				Percentage of rows filtered by table condition
# Extra 					None 						Additional information
#
# NOTE:
#
# 		The JSON properties which are NULL are not displayed in JSON-formatted EXPLAIN output.
#
# ) id(JSON name: select_id)
#
# 		THe SELECT modified.
#
# 		This is the sequential number of the SELECT within the query.
#
# 		The value can be NULL if the row refers to the union result of other rows.
#
# 		In this case, the table column shows a value like <union M,N> to indicate that the
# 		rows refers to the union of the rows with ID values of M and N.
#
# ) select_type (JSON name: None)
#
# 		The type of SELECT, which can be any of those shown in the following table.
#
# 		A JSON-formatted EXPLAIN exposes the SELECT type as a property of a query_block
# 		unless it is SIMPLE or PRIMARY.
#
# 		The JSON names (where applicable) are also shown in the table.
#
# 		select_type Value 				JSON name 					Meaning
#
# 		SIMPLE 								None 							Simple SELECT (not using UNION or subqueries)
#
# 		PRIMARY 								None 							Outermost SELECT
#
# 		UNION 								None 							Second or later SELECT statement in a UNION
#
# 		DEPENDENT UNION 					dependent (True) 			Second or later SELECT statement in a UNION, dependant on outer query
#
# 		UNION RESULT 						union_result 				Result of a UNION
#
# 		SUBQUERY 							None 							First SELECT in subquery
#
# 		DEPENDANT SUBQUERY 				dependent (True) 			First SELECT in subquery, dependant on outer query
#
# 		DERIVED 								None 								Derived table
#
# 		MATERIALIZED 						materialized_from_subquery Materialized subquery
#
# 		UNCACHABLE SUBQUERY 				cacheable(false) 			A subquery for which the result cannot be cached and must be re-evaluated for each row of the outer query
#
# 		UNCACHABLE UNION 					cacheable(false) 			The second or later select in a UNION that belongs to an uncachable subquery (see above)
#
# DEPENDENT typically signifies the use of a correlated subquery. See CORRELATED SUBQUERIES later, for more info.
#
# DEPENDENT SUBQUERY evaluation differs from UNCACHABLE SUBQUERY evaluation.
#
# For DEPENDENT SUBQUERY, the subquery is re-evaluated only once for each set of different values of the variables from its outer context.
# FOr UNCACHABLE SUBQUERY, the subquery is re-evaluated for each row of the otuer context.
#
# When you specify FORMAT=JSON with EXPLAIN, the output has no single property directly equivalent to
# select_type; the query_block property corresponds to a given SELECT.
#
# Properties equivalent to the most of the SELECT subquery types just shown are available (en example being Materialized_from_subquery
# for MATERIALIZED) and are displayed when appropriate.
#
# There are no JSON equivalents for SIMPLE or PRIMARY.
#
# The select_type value for non-SELECT statements display the statement type for affected tables.
#
# For example, select_type is DELETED for DELETE statements.
#
# ) table (JSON name: table_name)
#
# The name of the table to which the row of output refers. This can also be one of the following values:
#
#		 ) <unionM,N>: The row refers to the union of the rows with id values of M and N
#
# 		) <derivedN>: The row refers to the derived table result for the row with an id value of N.
# 					A derived table may result, for example, from a subquery in the FROM clause.
#
# 		) <subqueryN>: The row refers to the result of a materialized subquery for the row with an id value of N.
# 						See OPTIMIZING SUBQUERIES WITH MATERIALIZATION
#
# ) partitions (JSON name:partitions)
#
# 		The partitions from which records would be matched by the query.
# 		The value is NULL for nonpartitioned tables. See OBTAINING INFORMATION ABOUT PARTITIONS for more.
#
# ) type (JSON name: access_type)
#
# 		The join type. For descriptions of the different types, see EXPLAIN Join Types.
#
# ) possible_keys (JSON name: possible_keys)
#
# 		The possible_keys column indicates the indexes from which MySQL can choose to find the rows in this table.
# 		Note that this column is totally independent of the order of the tables as displayed in the output from EXPLAIN.
#
# 		That means that some of the keys in possible_keys might not be usable in practice with the generated table order.
#
# 		If this column is NULL (or undefined in JSON-formatted output), there are no relevant indexes.
#
# 		In this case, you may be able to improve the performance of  your query by examining the WHERE clause
# 		to check whether it refers to some column or columns that would be suitable for indexing.
#
# 		If so, create an appropriate index and check the query with EXPLAIN again. See ALTER TABLE SYNTAX for more info.
#
# 		To see what indexes a table has, use SHOW INDEX FROM tbl_name.
#
# ) key (JSON name: key)
#
# 		The key column indicates the key (index) that MySQL actually decided to use.
# 		If MySQL decided to use one of the possible_keys indexes to look up rows, that index is listed as the key value.
#
# 		It is possible that key will name an index that is not present in the possible_keys value.
#
# 		This can happen if none of the possible_keys indexes are suitable for looking up rows, but all the columns
# 		selected by the query are columns of some other index.
#
# 		That is, the named index covers the selected columns, so although it is not used to determine
# 		which rows to retrieve, an index scan is more efficient than a data row scan.
#
# 		For InnoDB, a secondary index might cover the selected columns even if the query also selects the
# 		primary key because InnoDB stores the primary key value with each secondary index.
#
# 		If key is NULL, MySQL found no index to use for executing the query more efficiently.
#
# 		To force mySQL to use or ignore an index listed in the possible_keys column, use FORCE INDEX,
# 		USE INDEX, or IGNORE INDEX in your query.
#
# 		See INDEX HINTS for more info.
#
# 		For MyISAM tables, running ANALYZE_TABLE helps the optimizer choose better indexes.
#
# 		For MyISAM tables, myisamchk --analyze does the same.
#
# 		See ANALYZE TABLE SYNTAX and MyISAM TABLE MAINTENANCE AND CRASH RECOVERY
#
# ) key_len (JSON name: key_length)
#
# 		The key_len column indicates the length of the key that MySQL decided to use.
#
# 		The value of key_len enables you to determine how many parts of a multiple-part key
# 		MySQL actually uses. If the key column says NULL, the len_len column also says NULL.
#
# 		Due to the key storage format, the key length is one greater for a column that can be
# 		NULL than for a NOT NULL column.
#
# ) ref (JSON name: ref)
#
# 		The ref column shows which columns or constants are compared to the index named in the key column 
# 		to select rows from the table.
#
# 		If the value is func, the value used is the result of some function.
#
# 		To see which function, use SHOW_WARNINGS following EXPLAIN to see the extended
# 		EXPLAIN output.
#
#  	The function might actually be an operator such as an arithmetic operator.
#
# ) rows (JSON name: rows)
#
#		The rows column indicates the number of rows MySQL believes it must examine to execute the query.
#
# 		For InnoDB tables, this number is an estimate, and may not always be exact.
#
# ) filtered (JSON name: filtered)
#
# 		The filtered column indicates an estimated percentage of table rows that will be filtered
# 		by the table condition.
#
# 		The maximum value is 100, which means no filtering of rows occurred.
#
# 		Values decreasing from 100 indicate increasing amounts of filtering.
#
# 		Rows shows the estimated number of rows examined and rows * filtered shows hte
# 		number of rows that will be joined with the following table.
#
# 		For example, if rows is 1000 and filtered is 50.00 (50%), the number of rows
# 		to be joined with the following table is 1000 x 50% = 500
#
# ) Extra (JSON name: none)
#
# 		This column contains additional information about how MySQL resolves the query.
#
# 		For descriptions of the different values, see EXPLAIN under EXTRA INFORMATION.
#
# 		There is no single JSON property corresponding to the Extra column; however, values
# 		that can occur in this column are exposed as JSON properties, or as the text of
# 		the message property.
#
# EXPLAIN JOIN TYPES
#
# The type column of EXPLAIN output describes how tables are joined.
#
# In JSON-formatted output, these are found as values of the access_type property.
#
# The following list describes the join types, ordered from the best type to the worst:
#
# 		) system
#
# 			The table has only one row (= system table). This is a special case of the const join type.
#
# 		) const
#
# 			The table has at most one matching row, which is read at the start of the query.
#
# 			Because there is only one row, values from the column in this row can be regarded as
# 			constants by the rest of the optimizer.
#
# 			const tables are very fast because they are read only once.
#
# 			const is used when you compare all parts of a PRIMARY KEY or UNIQUE index to constant values.
#
# 			In the following queries, tbl_name can be used as a const table:
#
# 				SELECT * FROM tbl_name WHERE primary_key=1;
#
# 				SELECT * FROM tbl_name
# 					WHERE primary_key_part1=1 AND primary_key_part2=2;
#
# 		) eq_ref
#
# 			One row is read from this table for each combination of rows from the previous tables.
#
# 			Other than the system and const types, this is the best possible join type.
#
# 			It is used when all parts of an index are used by the join and the index is a PRIMARY
# 			KEY or UNIQUE NOT NULL index.
#
# 			eq_ref can be used for indexed columns that are compared using the = operator.
#
# 			The comparison value can be a constant or an expression that uses columns from tables
# 			that are read before this table.
#
# 			In the following examples, MySQL can use an eq_ref join to process ref_table:
#
# 				SELECT * FROM ref_table,other_table
# 					WHERE ref_table.key_column=other_table.column;
#
# 				SELECT * FROM ref_table, other_table
# 					WHERE ref_table.key_column_part1=other_table.column
# 					AND ref_table.key_column_part2=1;
#
# 		) ref
#
# 			All rows with matching index values are read from this table for each combination of rows from
# 			the previous tables.
#
# 			ref is used if the join uses only a leftmost prefix of the key or if the key is not a PRIMARY KEY
# 			or UNIQUE index (in other words, if the join cannot select a single row based on the key value)
#
# 			If the key is used matches only a few rows, this is a good join type.
#
# 			ref can be used for indexed columns that are compared using the = or <=> operator.
# 			In the following examples, MySQL can use a ref join to process ref_table:
#
# 				SELECT * FROM ref_table WHERE key_column=expr;
#
# 				SELECT * FROM ref_table,other_table
# 					WHERE ref_table.key_column=other_table.column;
#
# 				SELECT * FROM ref_table,other_table
# 					WHERE ref_table.key_column_part1=other_table.column
# 					AND ref_table.key_column_part2=1;
#
# 		) fulltext
#
# 			The join is performed using a FULLTEXT index.
#
# 		) ref_or_null
#
# 			This join type is like ref, but with the addition that MySQL does an extra search for
# 			rows that contain NULL values.
#
# 			This join type optimization is used most often in resolving subqueries.
#
# 			In the following examples, MySQL can use a ref_or_null join to process ref_table:
#
# 				SELECT * FROM ref_table
# 					WHERE key_column=expr OR key_column IS NULL;
#
# 			See IS NULL OPTIMIZATION for more
#
# 		) index_merge
#
# 			This join type indicates that the Index Merge optimization is used. In this case, the key column
# 			in the output row contains a list of indexes used, and key_len contains a list of the
# 			longest key parts of the indexes used.
#
# 			For more information, See INDEX MERGE OPTIMIZATION for more info
#
# 		) unique_subquery
#
# 			This type replaces eq_ref for some IN subqueries of the following form:
#
# 				value IN (SELECT primary_key FROM single_table WHERE some_expr)
#
# 			unique_subquery is just an index lookup function that replaces the subquery completely for better efficiency.
#
# 		) index_subquery
#
# 			This join type is similar to unique_subquery.
# 			It replaces IN subqueries, but it works for nonunique indexes in subqueries of the following form:
#
# 				value IN (SELECT key_column FROM single_table WHERE some_expr)
#
# 		) range
#
# 			Only rows that are in a given range are retrieved, using an index to select the rows.
#
# 			The key column in the output row indicates which index is used.
#
# 			The key_len contains the longest key part that was used.
# 			The ref column is NULL for this type.
#
# 			range can be used when a key column is compared to a constant using any of the
# 			=, <>, >, <=, IS_NULL, <=>, BETWEEN, LIKE or IN() operators:
#
# 				SELECT * FROM tbl_name
# 					WHERE key_column = 10;
#
# 				SELECT * FROM tbl_name
# 					WHERE key_column BETWEEN 10 AND 20;
#
# 				SELECT * FROM tbl_name
# 					WHERE key_column IN (10,20,30);
#
# 				SELECT * FROM tbl_name
# 					WHERE key_part1 = 10 AND key_part2 IN (10, 20, 30);
#
# 		) index
#
# 			The index join type is the same as ALL, except that the index tree is scanned. This occurs two ways:
#
# 				) If the index is covering index for queries and can be used to satisfy all data required from the table,
# 					only the index tree is scanned.
#
# 					In this case, the Extra column says Using index.
#
# 					An index-only scan usually is faster than ALL because the size of the index usually is smaller than the table data.
#
# 				) A full table scan is performed used reads from the index to look up data rows in index order.
#
# 					Uses index does not appear in the Extra column.
#
# 			MySQL can use this join type when the query uses only columns that are part of a single index.
#
# 		) ALL
#
# 			A full table scan is done for each combination of rows from the previous tables.
#
# 			This is normally not good if the table is the first table not marked const, and usually
# 			very bad in other cases.
#
# 			Normally, you can avoid ALL by adding indexes that enable row retrieval from the table based
# 			on constant values or column values from earlier tables.
#
# EXPLAIN EXTRA INFORMATION
#
# The Extra column of EXPLAIN output contains additional information about how MySQL resolves the query.
#
# The following list explains the values that can appear in this column.
#
# Each item also indicates for JSON-formatted output which property displays the Extra value.
#
# For some of these, there is a specific property.
#
# The others display as the text of the message property.
#
# If you want to make your queries as fast as possible, look out for Extra column values of Using
# filesort and Using temporary, or, in JSON-formatted EXPLAIN output, for using_filesort and using_temporary_table
# properties equal to true.
#
# 		) Child of 'table' pushed join@1 (JSON: message text)
#
# 			This table is referenced as the child of table in a join that can be pushed down to the NDB kernel.
#
# 			applies only in NDB Cluster, when pushed-down joins are enabled.

# 			See the description of the ndb_join_pushdown server system variable for more info and examples.
#
# 		) const row not found (JSON property: const_row_not_found)
#
# 			For a query such as SELECT --- FROM tbl_name, the table was empty.
#
# 		) Deleting all rows (JSON property: message)
#
# 			For DELETE, some storage engines (such as MyISAM) support a handler method that removes all
# 			table rows in a simple and a fast way.
#
# 			This Extra value is displayed if the engine uses this optimization.
#
# 		) Distinct (JSON property: distinct)
#
# 			MySQL is looking for distinct values, so it stops searching for more rows for the current row combination
# 			after it has found the first matching row.
#
# 		) FirstMatch (tbl_name) (JSON property: first_match)
#
# 			The semi-join FirstMatch join shortcutting strategy is used for tbl_name.
#
# 		) Full scan on NULL key (JSON property: message)
#
# 			This occurs for subquery optimization as a fallback strategy when the optimizer cannot use an index-lookup access method.
#
# 		) Impossible HAVING (JSON property: message)
#
# 			The HAVING clause is always false and cannot select any rows.
#
# 		) Impossible WHERE (JSON property: message)
#
# 			The WHERE clause is always false and cannot select any rows.
#
# 		) Impossible WHERE noticed after reading const tables (JSON property: message)
#
#  		MySQL has read all const (and system) tables and notice that the WHERE clause is always false.
#
# 		) LooseScan(m--n) (JSON property: message)
#
# 			The semi-join LooseScan strategy is used, m and n are key part numbers.
#
# 		) No matching min/max row (JSON property: message)
#
# 			No row satisfies the condition for a query such as SELECT MIN(---) FROM --- WHERE condition.
#
# 		) No matching row in const table (JSON property: message)
#
# 			For a query with a join, there was an empty table or a table with no rows satisfying a unique index condition.
#
# 		) No matching rows after partition pruning (JSON property: message)
#
# 			For DELETE or UPDATE, the optimizer found nothing to delete or update after partition pruning.
# 			It is similar in meaning to Impossible WHERE for SELECT statements.
#
# 		) No tables used (JSON property: message)
#
# 			The query has no FROM clause, or has a FROM DUAL clause.
#
# 			For INSERT or REPLACE statements, EXPLAIN displays this value when there is no SELECT part.
#
# 			For example, it appears for EXPLAIN INSERTS INTO t VALUES(10) because that is equivalent to
# 			to EXPLAIN INSERT INTO t SELECT 10 FROM DUAL.
#
# 		) Not exists (JSON property: message)
#
# 			MySQL was able to do a LEFT JOIN optimization on the query and does not examine more rows in this table
# 			for the previous row combination after it finds one row that matches the LEFT JOIN criteria.
#
# 			Here is an example of the type of query that can be optimized this way:
#
# 				SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id
# 					WHERE t2.id IS NULL;
#
# 			Assume that t2.id is defined as NOT NULL. In this case, MySQL scans t1 and looks up the rows
# 			in t2 using the values of t1.id
#
# 			If MySQL finds a matching row in t2, it knows that t2.id can never be NULL, and does not scan
# 			through the rest of the rows in t2 that have teh same id value.
#
# 			In other words, for reach row in t1, MySQL needs to do only a single lookup in t2, regardless
# 			of how many rows actually match in t2.
#
# 		) Plan isn't ready yet (JSON property: none)
#
# 			This value occurs with EXPLAIN_FOR_CONNECTION when the optimizer has not finished creating the
# 			execution plan for the statement executing in the named connection.
#
# 			If execution plan output comprises multiple lines, any or all of them could have this Extra
# 			value, depending on the progress of teh optimizer in determining the full execution plan.
#
# 		) Range checked for each record (index map: N) (JSON property: message)
#
# 			MySQL found no good index to use, but found that some of indexes might be used
# 			after column values from preceding tables are known.
#
# 			For each row combination in the preceding tables, MySQL checks whether it is possible to
# 			use a range or index_merge access method to retrieve rows.
#
# 			This is not very fast, but is faster than performing a join with no index at all.
#
# 			The applicability criteria are as described in RANGE OPTIMIZATION and INDEX MERGE OPTIMIZATION
# 			with the exception that all column values for the preceding table are known and considered to be
# 			constants.
#
# 			Indexes are numbered beginning with 1, in the same order as shown by SHOW_INDEX for the table.
#
# 			The index map value N is a bitmask value that indicates which indexes are candidates.
#
# 			For example, a value of 0x19 (binary 11001) means that indexes 1,4, and 5 will be considered.
#
# 		) Recursive (JSON property: recursive)
#
# 			This indicates that the row applies to the recursive SELECT part of a recursive common table
# 			expression.
#
# 			See WITH SYNTAX (COMMON TABLE EXPRESSIONS) for more info
#
# 		) Scanned N databases (JSON property: message)
#
# 			This indicates how many directory scans the server performs when processing a query
# 			for INFORMATION_SCHEMA tables, as described in OPTIMIZING INFORMATION_SCHEMA QUERIES.
#
# 			The value can be 0,1 or ALL.
#
# 		) Select tables optimized away (JSON property: message)
#
# 			The optimizer determined 1) that at most one row should be returned, and 2) that to produce this row,
# 			a deterministic set of rows must be read.
#
# 			When the rows to be read can be read during the optimization phase (for example, by reading index rows),
# 			there is no need to read any tables during query execution.
#
# 			The first condition is fullfilled when the query is implicitly grouped (contains an aggregate function but
# 			no GROUP BY clause)
#
# 			The second condition is fullfilled when one row lookup is performed per index used.
#
# 			The number of indexes read determines the number of rows to read.
#
# 			Consider the following implicitly grouped query:
#
# 				SELECT MIN(c1), MIN(c2) FROM t1;
#
# 			Suppose that MIN(c1) can be retrieved by reading one index row and MIN(c2) can be retrieved
# 			by reading one row from a different index.
#
# 			That is, for each column c1 and c2, there exists an index where the column is the first
# 			column of the index.
#
# 			In this case, one row is returned, produced by reading two deterministic rows.
#
# 			This Extra value does not occur if the rows to read are not deterministic.
# 			Consider this query:
#
# 				SELECT MIN(c2) FROM t1 WHERE c1 <= 10;
#
# 			SUppose that (c1, c2) is a covering index.
# 			Using this index, all rows with c1 <= 10 must be scanned to find the minimum c2 value.
#
# 			By contrast, consider this query:
#
# 				SELECT MIN(c2) FROM t1 WHERE c1 = 10;
#
# 			In this case, the first index row with c1 = 10 contains the minimum c2 value.
#
# 			Only one row must be read to produce the returend row.
#
# 			For storage engines that maintain an exact row count per table (such as MyISAM, but not InnoDB),
# 			this Extra value can occur for COUNT(*) queries for which the WHERE clause is missing or always
# 			true and there is no GROUP BY clause.
#
# 			(This is an instance of an implicitly grouped query where the storage engine influences whether a
# 				determinsitc number of rows can be read)
#
# 		) Skip_open_table, Open_frm_only, Open_full_table (JSON property: message)
#
# 			These values indicate file-opening optimizations that apply to queries for INFORMATION_SCHEMA tables.
#
# 				) Skip_open_table: Table files do not need to be opened. The information is already a vailable from the data dictionary.
#
# 				) Open_frm_only: Only the data dictionary need be read for table information.
#
# 				) Open_full_table: Unoptimized information lookup. Table information must be read from the data dictionary and by reading table files.
#
# 		) Start temporary, End temporary (JSON property: message)
#
# 			This indicates temporary table use for the semi-join Duplicate Weedout Strategy
#
# 		) unique row not found (JSON property: message)
#
# 			For a query such as SELECT_---_FROM tbl_name, no rows satisfy the condition for a UNIQUE index or PRIMARY KEY on the table.
#
# 		) Using filesort (JSON property: using_filesort)
#
# 			MySQL must do an extra pass to find out how to retrieve the rows in sorted order.
#
# 			The sort is done by going through all rows according to the join type and storing
# 			the sort key and pointer to the row for all rows that match the WHERE clause.
#
# 			The keys then are sorted and the rows are retrieved in sorted order.
#
# 			See ORDER BY OPTIMIZATION
#
# 		) Using index (JSON property: using_index)
#
# 			The column information is retrieved from the table using only information in the index
# 			tree without having to do an additional seek to read the actual row.
#
# 			This strategy can be used when the query uses only columns that are part of a single index.
#
# 			For InnoDB tables that have a user-defined clustered index, that index can be used even when
# 			Using index is absent from the Extra column.
#
# 			This is the case if type is index and key is PRIMARY.
#
# 		) Using index condition (JSON property: using_index_condition)
#
# 			Tables are read by accessing index tuples and testing them first to determine whether
# 			to read full table rows.
#
# 			In this way, index information is used to defer ("Push down") reading full table rows
# 			unless it is necessary.
#
# 			See INDEX CONDITION PUSHDOWN OPTIMIZATION
#
# 		) Using index for group-by (JSON property: using_index_for_group_by)
#
# 			Similar to the Using index table access method, Using index for group-by indicates
# 			that MySQL found an index that can be used to retrieve all columns of a GROUP BY or DISTINCT
# 			query without any extra disk access to the actual table.
#
# 			Additionally, the index is used in the most efficient way so that for each group,
# 			only a few index entries are. See GROUP BY OPTIMIZATION for more info.
#
# 		) Using index for skip scan (JSON property: using_index_for_skip_scan)
#
# 			Indicates that the Skip Scan access method is used. See SKIP SCAN RANGE ACCESS METHOD.
#
# 		) Using join buffer (Block Nested Loop), Using join buffer (Batched Key Access)
# 			(JSON property: using_join_buffer)
#
# 			Tables from earlier joins are read in portions into the join buffer, and then their rows
# 			are used from the buffer to perform the join with the current table.
#
# 			(Block Nested Loop) indicates use of the Block Nested-Loop algorithm and (Batched Key Access)
# 			indicates use of the Batched Key Access algorithm.
#
# 			That is, the keys from the table on the preceding line of the EXPLAIN ouput will be buffered,
# 			and the matching rows will be fetched in batches from the table represented by the line
# 			in which Using join buffer appears.
#
# 			In JSON-formatted output, the value of using_join_buffer is always either one of Block Nested
# 			Loop or Batched Key Access.
#
# 		) Using MRR (JSON property: message)
#
# 			Tables are read using the Multi-Range Read optimization strategy. See MULTI-RANGE READ OPTIMIZATION, for more info.
#
# 		) Using sort_union(---), Using union(---), Using intersect (---) (JSON property: message)
#
# 			These indicate the particular algorithm showing how index scans are merged for the index_merge join type.
#
# 			See INDEX MERGE OPTIMIZATION for more info.
#
# 		) Using temporary(JSON property: using_temporary_table)
#
# 			To resolve the query, MySQL needs to create a temporary table to hold the result.
#
# 			This typically happens if the query contains GROUP BY and ORDER BY clauses that list
# 			columns differently.
#
# 		) Using where (JSON property: attached_condition)
#
# 			A WHERE clause is used to restrict which rows to match against the next table or send to the client.
#
# 			Unless you specifically intend to fetch or examine all rows from the table,
# 			you may have something wrong in your query if the Extra value is not Using where
# 			and the table join type is ALL or index.
#
# 			Using where has no direct counterpart in JSON-formatted output; teh attached_condition
# 			property contains any WHERE condition used.
#
# 		) Using where with pushed condition (JSON property: message)
#
# 			This item applies to NDB tables only.
#
# 			It means that NDB Cluster is using the Condition Pushdown optimization to improve
# 			the efficiency of a direct comparison between a nonindexed column and a constant.
#
# 			In such cases, the condition is "pushed down" to the cluster's data nodes and is evaluated
# 			on all data nodes simultaneously.
#
# 			This eliminates the need to send nonmatching rows over the network, and can speed up
# 			such queries by a factor of 5 to 10 times over cases where Condition Pushdown could be
# 			but is not used.
#
# 			For more info, see ENGINE CONDITION PUSHDOWN OPTIMIZATION.
#
# 		) Zero limit (JSON property: message)
#
# 			The query had a LIMIT 0 clause and cannot select any rows.
#
# EXPLAIN OUTPUT INTERPRETATION
#
# You can get a good indication of how good a join is by taking the product of the values in the rows
# column of the EXPLAIN output.
#
# This should tell you roughly how many rows MySQL must examine to execute the query.
#
# If you restrict queries with the max_join_size system variable, this row product also is used to
# determine which multiple-table SELECT statements to execute and which to abort.
#
# See earlier, in relation to Configuring the  Server.
#
# The following example shows how a multiple-table join can be optimized progressively based on the
# information provided by EXPLAIN.
#
# Suppose that you have the SELECT statement shown here and that you plan to examine it using EXPLAIN:
#
# 		EXPLAIN SELECT tt.TicketNumber, tt.TimeIn,
# 							tt.ProjectReference, tt.EstimatedShipDate,
# 							tt.ActualShipDate, tt.ClientID,
# 							tt.ServiceCodes, tt.RepetitiveID,
# 							tt.CurrentProcess, tt.CurrentDPPerson,
# 							tt.RecordVolume, tt.DPPrinted, et.COUNTRY,
# 							et_1.COUNTRY, do.CUSTNAME
# 					FROM tt, et, et AS et_1 do
# 					WHERE tt.SubmitTime IS NULL
# 						AND tt.ActualPC = et.EMPLOYID
# 						AND tt.AssignedPC = et_1.EMPLOYID
# 						AND tt.ClientID = do.CUSTNMBR;
#
# For this example, make the following assumptions:
#
# 		) The columns being compared have been declared as follows:
#
# 			Table 			Column 					Data Type
# 			tt 				ActualPC 				CHAR(10)
# 			tt 				AssignedPC 				CHAR(10)
# 			tt 				ClientID 				CHAR(10)
# 			et 				EMPLOYID 				CHAR(15)
# 			do 				CUSTNMBR 				CHAR(15)
#
# 		) The tables have the following indexes
#
# 			Table 			Index
# 			tt 				ActualPC
# 			tt 				AssignedPC
# 			tt 				ClientID
# 			et 				EMPLOYID (primary key)
# 			do 				CUSTNMBR (primary key)
#
# 		) The tt.ActualPC values are not evenly distributed.
#
# Initially, before any optimizations have been performed, the EXPLAIN statement produces the following information:
#
# 	table 	Type 		Possible_keys 		key 		key_len 		ref 		rows 		Extra
# 	et 		ALL 		PRIMARY 				NULL 		NULL 			NULL 		74
# 	do 		ALL 		PRIMARY 				NULL 		NULL 			NULL 		2135
# 	et_1 		ALL 		PRIMARY 				NULL 		NULL 			NULL 		74
#
#  tt 		ALL 		AssignedPC, 		NULL 		NULL 			NULL 		3872
# 							ClientID,
# 							ActualPC 			 				
# 				Range checked for each record (index map: 0x23)
#
# Because type is ALL for each table, this output indicates that MySQL is generating a Cartesian product
# of all the tables;
#
# That is, every combination of rows.
#
# This takes quite a long time, because the product of the number of rows in each table must be examined.
#
# For the case at hand, this product is 74 x 2135 x 73 x 3872 = about 45 mil rows.
#
# If the tables were bigger, you can only imagine the growth.
#
# One problem here is that MySQL can use indexes on columns more efficiently if they are
# declared as the same type and size.
#
# In this context, VARCHAR and CHAR are considered the same if they are declared as the same size.
#
# tt.ActualPC is declared as CHAR(10) and et.EMPLOYID is CHAR(15), so there is a length mismatch.
#
# To fix this disparity between column lengths, use ALTER_TABLE to lengthen ActualPC from 10 characters
# to 15 characters:
#
# 		ALTER TABLE tt MODIFY ActualPC VARCHAR(15);
#
# Now tt.ActualPC and et.EMPLOYID are both VARCHAR(15).
#
# Executing the EXPLAIN statement again produces this result:
#
# 		table type 			possible_keys 	key 		key_len 		ref 		rows 		Extra
# 		tt 	ALL 			AssignedPC, 	NULL 		NULL 			NULL 		3872 		Using 
# 								ClientID, 															where
# 								ActualPC
# 		do 	ALL 			PRIMARY 			NULL 		NULL 			NULL 		2135
#				Range checked for each record (index map: 0x1)
# 		et_1 	ALL 			PRIMARY 			NULL 		NULL 			NULL 		74
# 				Range checked for each record (index map: 0x1)
# 		et 	eq_ref 		PRIMARY 			PRIMARY 	15  			tt.ActualPC 1
#
# This is not perfect, but better.
#
# The product of the rows values is less by a factor of 74. This version executes in a couple of seconds.
#
# A second alternation can be to eliminate the column length mismatches for the tt.AssignedPC = et_1.EMPLOYID
# and tt.ClientID = do.CUSTNMBR comparisons:
#
# 		ALTER TABLE tt MODIFY AssignedPC VARCHAR(15),
# 							MODIFY ClientID  	VARCHAR(15);
#
# After that modification, EXPLAIN produces the output shown here:
#
# 		table type 			possible_keys 	key 		key_len 		ref 				rows 		Extra
# 		et 	ALL 			PRIMARY 			NULL 		NULL 			NULL 				74
# 		tt 	ref 			AssignedPC, 	ActualPC 15 			et.EMPLOYID 	52 		Using
# 								ClientID, 																	where
# 								ActualPC
# 		et_1 	eq_ref 		PRIMARY 			PRIMARY 	15 			tt.AssignedPC 	1
# 		do  	eq_ref 		PRIMARY 			PRIMARY  15 			tt.ClientID 	1
#
# At this point, the query is optimized almost as well as possible.
#
# The remaining problem, is that by default MySQL assumes that values in the tt.ActualPC column are evenly
# distributed.
#
# That is not the case for the tt.table.
#
# Fortunately, it is easy to tell MySQL to analyze the key distrib:
#
# 		ANALYZE TABLE tt;
#
# With the additional index information, the join is perfect and EXPLAIN produces this result:
#
# 		table type 			possible_keys 	key 		key_len 		ref 				rows 		Extra
# 		tt 	ALL 			AssignedPC 		NULL 		NULL 			NULL 				3872 		Using
# 								ClientID, 																	where
# 								ActualPC
# 		et 	eq_ref 		PRIMARY 			PRIMARY 	15 			tt.ActualPC  	1
# 		et_1 	eq_ref 		PRIMARY 			PRIMARY  15 			tt.AssignedPC 	1 
# 		do 	eq_ref 		PRIMARY 			PRIMARY 	15 			tt.ClientID 	1
#
# The rows column in the output from EXPLAIN is an educated guess from the MySQL join optimizer.
#
# Check whether the numbers are even close to the truth by comparing the rows products with
# the actual number of rows that the query runs.
#
# If then umbers are quite different, you might get better performance by using STRAIGHT_JOIN
# in your SELECT statement and trying to list the tables in a different order in the FROM clause.
#
# (However, STRAIGHT_JOIN may prevent indexes from being used because it disables semi-join transformations.
# See OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIOSN WITH SEMI-JOIN TRANSFORMATIONS
#
# IT is possible in some cases to execute statements that modify data when EXPLAIN_SELECT is used
# with a subquery.

# For more info about this, see DERIVED TABLES, later.
#
# EXTENDED EXPLAIN OUTPUT FORMAT
#
# The EXPLAIN statement produces extra ("extended") information that is not part of EXPLAIN
# output but can be viewed by issuing a SHOW WARNINGS statement following EXPLAIN.
#
# As of MySQL 8.0.12, extended information is available for SELECT, DELETE, INSERT, REPLACE and UPDATE statements.
#
# Prior to 8.0.12, extended info is only available for SELECT statements.
#
# The Message value in show_warnings output displays how the optimizer qualifies table and column
# names in the SELECT statement, what hte SELECT looks like after the application of rewriting
# and optimization rules, and possibly other notes about the optimizaiton process.
#
# The extended information displayable with a SHOW_WARNINGS statement following EXPLAIN is produced only
# for SELECT statements.
#
# SHOW_WARNINGS displays an empty result for other explainable statements. (DELETE, INSERT, REPLACE and UPDATE)
#
# Here is an example of extended EXPLAIN output:
#
# 		EXPLAIN SELECT t1.a, t1.a IN (SELECT t2.a FROM t2) FROM t1\G
# 		******************** 1. row *********************
#
# 							id: 1
# 				select_type: PRIMARY
# 						table: t1
# 						 type: index
# 			possible_keys : NULL
# 						  key: PRIMARY
# 					key_len : 4
# 						  ref: NULL
# 						rows : 4
# 				filtered   : 100.00
# 						Extra: Using index
#
# 		******************* 2. row **********************
# 		
# 							id: 2
# 				select_type: SUBQUERY
# 						table: t2
# 						 type: index
# 			 possible_keys: a
# 						  key: a
# 					key_len : 5
# 					 	  ref: NULL
# 						rows : 3
# 				filtered   : 100.00
# 					Extra   : Using index
# 		2 rows in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		****************** 1. row **************************
# 		
# 		Level: 	Note
# 		 Code: 	1003
# 	  Message:  /* select#1 */ select `test`.`t1`.`a` AS `a`,
# 					<in_optimizer>(`test`.`t1`.`a`, `test`.`t1`.`a` in
# 					( <materialize> (/* select#2 */ select `test`.`t2`.`a`
# 					from `test`.`t2` where 1 having 1 ),
# 					<primary_index_lookup>(`test`.`t1`.`a` in
# 					<temporary_table> on <auto_key>
# 					where ((`test`.`t1`.`a` = `materialized-subquery`.`a`))))) AS `t1.a`
# 					IN (SELECT t2.a FROM t2)` from `test`.`t1`
# 		1 row in set (0.00 sec)
#
# Because the statement displayed by SHOW_WARNINGS may contain special markers to provide info
# about query rewriting or optimizer actions, the statement is not necessarily valid SQL
# and is not intended to be executed.
#
# The output may also include rows with Message values that provide additional non-SQL explanatory
# notes about actions taken by the optimizer.
#
# The following list describes special markers that can appear in the extended output displayed
# by SHOW_WARNINGS:
#
# 		) <auto_key>
#
# 			An automatically generated key for a temporary table
#
# 		) <cache>(expr)
#
# 			The expression (such as scalar subquery) is executed once and the resulting value is saved
# 			in memory for later use.
#
# 			For results consisting of multiple values, a temporary table may be created and you will
# 			see <temporary table> instead.
#
# 		) <exists>(query fragment)
#
# 			THe subquery predicate is converted to an EXISTS predicate and the subquery is transformed
# 			so that it can be used together with the EXISTS predicate.
#
# 		) <in_optimizer>(query fragment)
#
# 			This is an internal optimizer object with no user significance
#
# 		) <index_lookup> (query fragment)
#
# 			The query fragment is processed using an index lookup to find qualifying rows
#
# 		) <if>(condition, expr1, expr2)
#
# 			If the condition is true, evaluate to expr1, otherwise expr2
#
# 		) <is_not_null_test>(expr)
#
# 			A test to verify that the expression does not evaluate to NULL
#
# 		) <materialize>(query fragment)
#
# 			Subquery materialization is used.
#
# 		) `materialized-subquery`.col_name
#
# 			A reference to the column col_name in an internal temporary table materialized to hold the result from evaluating a subquery.
#
# 		) <primary_index_lookup>(query fragment)
#
# 			The query fragment is processed using a primary key lookup to find qualifying rows
#
# 		) <ref_null_helper>(expr)
# 
# 			This is an internal otpimizer object with no user significance
#
# 		) /* SELECT#N */ select_stmt
#
# 			The SELECT is associated with the row in non-extended EXPLAIN output that has an id value of N.
#
# 		) outer_tables semi join (inner_tables)
#
# 			A semi-join operation.
#
# 			inner_tables shows the tables that were not pulled out. 
#
# 			See OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES AND COMMON TABLE EXPRESSIONS WITH SEMI-JOIN TRANSFORMATIONS.
#
# 		) <temporary table>
#
# 			This represents an internal temporary table created to cache an intermediate result.
#
# When some tables are of const or system type, expressions involving columns from these tables
# are evaluated early by the optimizer and are not part of the displayed statement.
#
# However, with FORMAT=JSON, some const table accesses are displayed as ref access
# that uses a const value.
#
# OBTAINING EXECUTION PLAN INFORMATION FOR A NAMED CONNECTION
#
# To obtain the execution plan for an explainable statement executing in a named connection,
# use this statement:
#
# 		EXPLAIN [options] FOR CONNECTION connection_id;
#
# EXPLAIN_FOR_CONNECTION returns the EXPLAIN information that is currently being used to
# execute a query in a given connection.
#
# Because of changes to data (and supporting statistics) it may produce a different result from
# running EXPLAIN on the equivalent query text.
#
# This difference in behavior can be useful in diagnosing more transient performance problems.
#
# FOr example, if you are running a statement in one session that is taking a long time to complete,
# using EXPLAIN_FOR_CONNECTION in another session may yield useful information about the cause of the delay.
#
# connection_id is the connection identifier, as obtained from the INFORMATION_SCHEMA.PROCESSLIST table or
# the SHOW_PROCESSLIST statement.
#
# If you have the PROCESS privilege, you can specify the identifier for any connection.
#
# Otherwise, you can specify the identifier only for your own connections.
#
# If the named connection is not executing a statement, the result is empty.
#
# Otherwise, EXPLAIN FOR CONNECTION applies only if the statement being executed in teh
# named connection is explainable.
#
# THis includes SELECT, DELETE, INSERT, REPLACE and UPDATE.
#
# (However, EXPLAIN FOR CONNECTION does not work for prepared statements, even prepared
# statements of those types.)
#
# If the named connection is executing an explainable statement, the output is what  you would
# obtain by using EXPLAIN on the statement itself.
#
# If the named connection is executing a statement that is not explainable, an error occurs.
#
# For example, you cannot name the connection identifier for your current session because EXPLAIN
# is not explainable:
#
# SELECT CONNECTION_ID();
# +----------------------------+
# | CONNECTION_ID() 				 |
# +----------------------------+
# | 					373 		    |
# +----------------------------+
# 1 row in set (0.00 sec)
#
# EXPLAIN FOR CONNECTION 373;
# ERROR 1889 (HY000): EXPLAIN FOR CONNECTION command is not supported
# only for SELECT/UPDATE/INSERT/DELETE/REPLACE
#
# The Com_explain_other status variable indicates the number of EXPLAIN_FOR_CONNECTION
# statements executed.
#
# ESTIMATING QUERY PERFORMANCE
#
# In most cases, you can estimate query performance by counting disk seeks.
#
# For small tables, you can usually find a row in one disk seek (because the index is probably
# cached)
#
# For bigger tables, you can estimate that, using B-TREE indexes, you need this many seeks to find
# a row:
#
# log(row_count) / log(index_block_length / 3 * 2 / (index_length + data_pointer_length)) + 1
#
# In MYSQL an index block is usually 1024 bytes and the data pointer is usually four bytes.
#
# For a 500,000-row table with a key value length of three bytes (the size of MEDIUMINT),
# the formula indicates:
#
# 		log(500,000)/log(1024/3*2/(3+4)) + 1 = 4 seeks
#
# This index would require storage of about 500,000 * 7 * 3/2=5.2MB, assuming a
# typical index buffer fill ratio of 2/3), so you probably have much of the index
# in memory and so need only one or two calls to read data to find the row.
#
# For writes, however, you need four seek requests to find where to place a new index value and
# normally two seeks to update the index and write the row.
#
# The preceding discussion does not mean that your application pperformance slowly degenerated
# by LOG N.
#
# As long as everything is cached by the OS or the MySQL server, things become only marginally
# slower as the tables get bigger.
#
# After the data gets too big to be cached, things start to go much slower until your applications
# are bound only by disk seeks
#
# (which increases by LOG N)
#
# To avoid this, increase the key cache size as the data grows.
#
# For MyISAM tables, the key cache is controlled by the key_buffer_size system variable.
#
# CONTROLLING THE QUERY OPTIMIZER
#
# MySQL provides optimizer control through system variables that affect how query plans are evaluated,
# switchable optimizations, optimizer and index hints, and the optimizer cost model.
#
# The server also maintains statistics about column values, although the optimizer does not
# yet use this information.
#
# CTRONLLING QUERY PLAN EVOLUTION
#
# The task of the query optimizer is to find an optimal plan for executing an SQL query.
#
# Because the difference in performance between "good" and "bad" plans can be orders of
# magnitudes (that is, seconds vs hours or even days), most query optimizers, include that of MySQL,
# perform a more or less exhaustive search for na optimal plan amongst all possible query evaluation plans.
#
# For join queries, the number of possible plans investigated by the MySQL optimizer grows exponentionally
# with the number of tables referenced in a query.
#
# For small number of tables (typically less than 7 to 10) this is not a problem.
#
# However, when large queries are submitted, the time spent in query optimization may easily
# become the major bottleneck in the server's performance.
#
# a more flexible method for query optimization enabvles the user to control how exhaustive
# the optimizer is in its search for an optimal query evaluation plan.
#
# The general idea is that the fewer plans that are investigated by the optimizer, the less time
# it spends in compiling a query.
#
# On the other hand, because the optimizer skips some plans, it may miss finding an optimal plan.
#
# The behavior of the optimizer with respect to the number of plans it evaluates can be controlled
# using two system variables:
#
# 		) The optimizer_prune_level variable tells the optimizer to skip certain plans based on
# 			estimates of the number of rows accessed for each table.
#
# 			Our experience shows that this kind of "educated guess" rarely misses optimal plans, and
# 			may dramatically reduce query compilation times.
#
# 			That is why this option is on (optimizer_prune_level=1) by default.
#
# 			However, if oyu believe that hte optimizer missed a better query plan, this option can be
# 			switched off (optimizer_prune_level=0) with the risk that query compilation
# 			may take much longer.
#
# 			Note that, even with the use of this heuristic, the optimizer still explores a
# 			roughly exponentional number of plans.
#
# 		) The optimizer_search_depth variable tells how far into the "future" of each incomplete
# 			plan the optimizer should look to evaluate whether it should be expanded further.
#
# 			Smaller values of optimizer_search_depth may result in orders of magnitudes smaller query
# 			compilation times.
#
# 			For example, queries with 12, 13 or more tables may easily require hours or even days
# 			to compile, if optimizer_search_depth is close to the number of tables in teh query.
#
# 			At the same time, if compiled with optimizer_saerch_depth equal to 3 or 4, the optimizer
# 			may compile in less than a minute for the same query.
#
# 			If you are unsure of what a reasonable value is for optimizer_search_depth,
# 			this variable can be set to 0 to tell the optimizer to determine the value automatically.
#
# OPTIMIZER HINTS
#
# 		One means of control over optimizer strategies is to set the optimizer_Switch system variable 
# 		(See SWITCHABLE OPTIMIZATIONS).
#
# 		Changes to this variable affect execution of all subsequent queries; to affect one query differently
# 		from another, it is necessary to change optimizer_switch before each one.
#
# 		Another way to control the optimizeri s by using optimizer hints, which can be specified within
# 		individual statements.
#
# 		BEcause optijmizer hints apoply on a per-statement basis,s they provide finer control over
# 		statement execution plans than can be achieved using optimizer_switch.
#
# 		For example, you can enable an optimization for one table in a statement and disable the
# 		optimization for a different table.
#
# 		Hints within a statement take precedence over optimizer_switch flags.
#
# 		Examples:
#
# 			SELECT /*+ NO_RANGE_OPTIMIZATION(t3 PRIMARY, f2_idx) */ f1
# 				FROM t3 WHERE f1 > 30 and f1 < 33;
# 			SELECT /*+ BKA(t1) NO_BKA(t2) */ * FROM t1 INNER JOIN t2 WHERE ---;
#
# 			SELECT /*+ NO_ICP(t1, t2) */ * FROM t1 INNER JOIN t2 WHERE ---;
# 			SELECT /*+ SEMIJOIN(FIRSTMATCH, LOOSESCAN) */ * FROM t1 ---;
#
# 			EXPLAIN SELECT /*+ NO_ICP(t1) */ * FROM t1 WHERE ---;
# 			SELECT /*+ MERGE(dt) */ * FROM (SELECT * FROM t1) AS dt;
# 		
# 			INSERT /*+ SET_VAR(foreign_key_checks=OFF) */ INTO t2 VALUES(2);
#
# Optimizer hints described here, differ from index hints described in INDEX HINTS.
#
# Optimizer and index hints may be used separately or together.
#
# OPTIMIZER HINT OVERVIEW
#
# Optimizer hints apply at different scope levels:
#
# 		) Global: The hint affects the entire statement
#
# 		) Query block: The hint affects a particular query block within a statement
#
# 		) table-level: The hint affects a particular table within a query block
#
# 		) Index-level: The hint affects a particular index within a table
#
# The following table summarizes teh available optimizer hints, the optimizer strategies they affect,
# and the scope or scopes at which they apply.
#
# More details are given later.
#
# OPTIMIZER HINTS AVAILABLE
#
# HINT NAME 						DESC 																	Applicable Scopes
#
# BKA, NO_BKA 				Affects Batched Key Access join processing 			Query block, table
# 
# BNL, NO_BNL 				Affects Block Nested-Loop join processing 			Query block, table
#
# INDEX_MERGE, 			Affects Index Merge optimization 						Table, Index
# NO_INDEX_MERGE
#
# JOIN_FIXED_ORDER 		Use table order specified in FROM clause 				Query block 
# 								for join order
#
# JOIN_ORDER 				Use table order specified in hint for join order 	Query block
#
# JOIN_PREFIX 				Use tabel order specified in hint for first  		Query BLock 
# 								tables of join order 
#
# JOIN_SUFFIX 				use tabel order specified in hint for last 			Query block
# 								tables of join order
#
# MAX_EXECUTION_TIME 	Limits statement execution time 							Global
#
# MERGE, NO_MERGE 		Affects derived table/view merging into 				Table 
# 								outer query block
#
# MRR, NO_MRR 				Affects Multi-Range Read Optimization 					Table, index
#
# NO_ICP 					affects index condition pushdown optimization 		Table, index
#
# NO_RANGE_OPTIMIZATION Affects range optimization 								Table, index
#
# QB_NAME 					Assigns name to query block 								Query block
#
# RESOURCE_GROUP 			Set resource group during statement execution 		Global
#
# SEMIJOIN, NO_SEMIJOIN Affects semi-join strategies 								Query block
#
# SKIP_SCAN, NO_SKIP_SCAN Affects Skip Scan optimization 						table, index
#
# SET_VAR 					Set variable during statement execution 				Global
#
# SUBQUERY 					Affects materialization, IN-to-EXISTS subquery 		Query block
# 								strategies
#
# Disabling an optimization prevents the optimizer from using it.
#
# Enabling an optimization means the optimizer is free to use the strategy if it applies
# to statement execution, not that hte optimizer necessarily will use it.
#
# OPTIMIZER HINT SYNTAX
#
# MySQL supports comments in SQL statements as described in COMMENT SYNTAX later.
#
# Optimizer hints must be specified within /*+ --- */ comments
#
# That is, optimnizer hints use a variant of /* --- */ C-style comment syntax, with a + char
# following the /* comment opening sequence. Examples:
#
# /*+ BKA(t1) */
# /*+ BNL(t1, t2) */
# /*+ NO_RANGE_OPTIMIZATION(t4 PRIMARY) */
# /*+ QB_NAME(qb2) */
#
# Whitespace is permitted after the + character.
#
# The parser recognizes optimizer hints comments after the intial keyword of SELECt, UPDATE,
# INSERT, REPLACE and DELETE statements.
#
# Hints are permitted in thse contexts:
#
# 		) The beginning of query and data change statements:
#
# 			SELECT /*+ --- */ ---
# 			INSERT /*+ --- */ ---
# 			REPLACE /+ --- */ ---
# 			UPDATE /*+ --- */ ---
# 			DELETE /*+ --- */ ---
#
# 		) At the beginning of query blocks
#
# 			(SELECT /*+ --- */ --- )
# 			(SELECT --- ) UNION (SELECT /*+ --- */ --- )
# 			(SELECT /*+ --- */ --- ) UNION (SELECT /*+ --- */ --- )
#
# 			UPDATE --- WHERE x IN (SELECT /*+ --- */ ---)
# 			INSERT --- SELECT /*+ --- */ ---
#
# 		) In hintable statements prefaced by EXPLAIN. For example:
#
# 			EXPLAIN SELECT /*+ --- */ ---
# 			EXPLAIN UPDATE --- WHERE x in (SELECT /*+ --- */ ---)
#
# 			The impliation is that you can use EXPLAIN to see how optimizer hints affect execution plans.
# 			Use SHOW_WARNINGS immediately after EXPLAIN to see how hints are used.
#
# 			The extended EXPLAIN output displayed by a following SHOW_WARNINGS indicates which
# 			hints were used.
#
# 			Ignored hints are not displayed.
#
# A hint comment may contain multiple hints, but a query block cannot contain multiple hint comments.
# This is valid:
#
# 		SELECT /*+ BNL(t1) BKA(t2) */ ---
#
# But this is invalid:
#
# 		SELECT /*+ BNL(t1) */ /* BKA(t2) */ ---
#
# When a hint comment contains multiple hints, the possibility of duplicates and conflicts exists.
#
# The following general guidelines apply.
#
# For specific hint types, additional rules may apply, as indicated in teh hint descriptions.
#
# 		) Duplicate hints: For a hint such as /*+ MRR(idx1) MRR(idx1) */, MySQL uses the first hint and issues a warning about the duplicate hint
#
# 		) Conflicting hints: FOr a hint such as /*+ MRR(idx1) NO_MRR(idx1) */, MysQL uses the first hint and issues a warning about the second conflicting hint
#
# Query block names are identifiers and follow the usual rules about what names are valid and how to quote them.
# (See SCHEMA OBJECT NAMES for more info)
#
# Hint names, query block names and strategy names are not case sensitive.
#
# References to table and index names follow the usual identifier case sensitivity rules
# (see IDENTIFIER CASE SENSITIVITY)
#
# JOIN-ORDER OPTIMIZER HINTS
#
# Joint-order hints affect the order in which the optimizer joins tables.
#
# Syntax of the JOIN_FIXED_ORDER hint:
#
# 		hint_name([@query_block_name])
#
# Syntax of other join-order hints:
#
# 		hint_name([@query_block_name] tbl_name [, tbl_name] ---)
# 		hint_name(tbl_name[@query_block_name] [, tbl_name[@query_block_name]] ---)
#
# The syntax refers to these terms:
#
# 		) hint_name: These hint names are permitted:
#
# 			) JOIN_FIXED_ORDER: Force the optimizer to join tables using the order in which they appear in the FROM clause.
# 										This is the same as specifying SELECT STRAIGHT_JOIN.
#
# 			) JOIN_ORDER: Instruct the optimizer to join tables using the specified table order.
#
# 								The hint applies to the named tables.
#
# 								The optimizer may place tables that are not named anywhere in the join order, including between specified tables.
#
# 			) JOIN_PREFIX: Instruct the optimizer to join tables using the specified table order for the first tables of the join execution plan.
# 		
# 								The hint applies to the named tables.
#
# 								The optimizer places all other tables after the named tables.
#
# 			) JOIN_SUFFIX: Instruct the optimizer to join tables using the specified table order for the last tables of the join execution plan.
# 								
# 								The hint applies to the named tables.
#
# 								The optimizer places all other tables before the named tables.
#
# 		) tbl_name: The name of a table used in the statement.
#
# 						A hint that names tables applies to all tables that it names.
#
# 						The JOIN_FIXED_ORDER hint names no tables and applies to all tables in the FROM
# 						clause of the query block in which it occurs.
#
# 						If a table has an alias, hints must refer to the alias, not the table name.
#
# 						Table names in hints cannot be qualified with schema names.
#
# 		) query_block_name:
#
# 						The query block to which the hint applies.
#
# 						If the hint includes no leading @query_block_name, the hint applies to 
# 						the query block in which it occurs.
#
# 						For tbl_name@query_block_name syntax, the hint applies to the named table
# 						in the named query block.
#
# 						To assign a name to a query block, see OPTIMIZER HINTS FOR NAMING QUERY BLOCKS
#
# Example:
#
# 		SELECT
# 		/*+ JOIN_PREFIX(t2, t5@subq2, t4@subq1)
# 			 JOIN_ORDER(t4@subq1, t3)
# 			 JOIN_SUFFIX(t1)  */
# 		COUNT(*) FROM t1 JOIN t2 JOIN t3
# 					  WHERE t1.f1 IN (SELECT /*+ QB_NAME(subq1) */ f1 FROM t4)
# 						AND t2.f1  IN (SELECT /*+ QB_NAME(subq2) */ f1 FROM t5);
#
# Hints control the behavior of semi-join tables that are merged to the outer query block.
#
# If subqueries subq1 and subq2 are converted to semi-joins, tables t4@subq1 and t5@subq2 are merged
# to the outer query block.
#
# In this case, the hint specified in the outer query block controls the behavior of t4@subq1, t5@subq2 tables.
#
# The optimizer resolves join-order hints according to these principles:
#
# 		) Multiple hint instances
#
# 			Only one JOIN_PREFIX and JOIN_SUFFIX hint of each type are applied.
#
# 			ANy later hints of the same type are ignored with a warning.
#
# 			JOIN_ORDER can be specified several times.
#
# 			Examples:
#
# 				/*+ JOIN_PREFIX(t1) JOIN_PREFIX(t2) */
#
# 			The second JOIN_PREFIX hint is ignored with a warning.
#
# 				/*+ JOIN_PREFIX(t1) JOIN_SUFFIX(t2) */
#
# 			Both hints are applicable. No warning occurs.
#
# 				/* JOIN_ORDER(t1, t2) JOIN_ORDER(t2, t3) */
#
# 			Both hints are applicable. No warning occurs.
#
# 		) Conflicting hints
#
# 			In some cases hints can conflict, such as when JOIN_ORDER and JOIN_PREFIX have table
# 			orders that are impossible to apply at the same time:
#
# 				SELECT /*+ JOIN_ORDER(t1, t2) JOIN_PREFIX(t2, t1) */ --- FROM t1, t2;
#
# 			In this case, the first specified hint is applied and subsequent conflicting hints
# 			are ignored with no warning.
#
# 			A valid hint that is impossible to apply is silently ignored with no warning.
#
# 		) Ignored hints
#
# 			A hint is ignored if a table specified in the hint has circular dependency
#
# 			Example:
#
# 				/*+ JOIN_ORDER(t1, t2) JOIN_PREFIX(t2, t1) */
#
# 			The JOIN_ORDER hint sets table t2 dependent on t1.
#
# 			The JOIN_PREFIX hint is ignored because table t1 cannot be dependant on t2.
#
# 			Ignored hints are not displayed in extended EXPLAIN output.
#
# 		) Interaction with  const tables
#
# 			The MySQL optimizer places const tables first in the join order, and the position of
# 			a const table cannot be affected by hints.
#
# 			References to const tables in join-order hints are ignored, although the hint
# 			is still applicable.
#
# 			For example, these are equivalent:
#
# 				JOIN_ORDER(t1, const_tbl, t2)
# 				JOIN_ORDER(t1, t2)
#
# 			Accepted hints shown in extended EXPLAIN output include const tables as they were specified.
#
# 		) Interaction with types of join operations
#
# 			MySQL supports several type of joins:
#
# 				LEFT, RIGHT, INNER, CROSS, STRAIGHT_JOIN.
#
# 			A hint that conflicts with the specified type of join is ignored with no warning.
#
# 			Example:
#
# 				SELECT /*+ JOIN_PREFIX(t1, t2) */FROM t2 LEFT JOIN t1;
#
# 			Here a conflict occurs between the requested join order in the hint and the order
# 			required by the LEFT JOIN.
#
# 			The hint is ignored with no warning.
#
# TABLE-LEVEL OPTIMIZER HINTS
#
# Table-level hints affect:
#
# 		) Use of the Block Nested-Loop (BNL) and Batched Key Access (BKA) join-processing algorithms
# 			(see BLOCKED NESTED-LOOP AND BATCHED KEY ACCESS JOINS)
#
# 		) Whether derived tables, view references or common table expressions should be merged into the
# 			outer query block, or materialized using an internal temporary table.
#
# These hint types apply to specific tables, or all tables in a query block.
#
# Syntax of table-level hints:
#
# 		hint_name([@query_block_name] [tbl_name [, tbl_name] ---])
# 		hint_name([tbl_name@query_block_name [, tbl_name@query_block_name] ---])
#
# The syntax refers to these terms:
#
# 		) hint_name: These hint names are permitted:
#
# 			) BKA, NO_BKA: Enable or disable BKA for the specified tables.
#
# 			) BNL, NO_BNL: Enable or disable BNL for the specified tables.
#
# 			) MERGE, NO_MERGE: Enable merging for the specified tables, view references or common table expressions; or disable
# 									merging and use materialization instead.
#
# 			NOTE:
#
# 				To use a BNL or BKA hint to enable join buffer for any inner table of an outer join,
# 				join buffering must be enabled for all inner tables of the outer join.
#
# 		) tbl_name: The name of a table used in the statement.
#
# 			The hint applies to all tables that it names. 
#
# 			If the hint names no tables, it applies to all tables of the query block in which it occurs.
#
# 			If a table has an alias, hints must refer to the alias, not the table name.
#
# 			Table names in hints cannot be qualified with schema names.
#
# 		) query_block_name: The query block to which the hint applies.
#
# 			If the hint includes no leading @query_block_name, the hint applies to the query
# 			block in which it occurs.
#
# 			For tbl_name@query_block_name syntax, the hint applies to the named table in the named query block.
#
# 			To assign a name to a query block, see OPTIMIZER HINTS FOR NAMING QUERY BLOCKS.
#
# 	Examples:
#
# 		SELECT /*+ NO_BKA(t1, t2) */ t1 * FROM t1 INNER JOIN t2 INNER JOIN t3;
# 		SELECT /*+ NO_BNL() BKA(t1) */ t1 * FROM t1 INNER JOIN t2 INNER JOIN t3;
# 		SELECT /*+ NO_MERGE(dt) */ * FROM (SELECT * FROM t1) AS dt;
#
# A table-level hint applies to tables that receives records from previous tables,
# not sender tables.
#
# Consider this statement:
#
# 		SELECT /*+ BNL(t2) */ FROM t1, t2;
#
# If the optimizer chooses to process t1 first, it applies a Block Nested-Loop join to t2 by buffering
# the rows from t1 before starting to read from t2.
#
# If the optimizer instead chooses to process t2 first, the hint has no effect because
# t2 is a sender table.
#
# For the MERGE and NO_MERGE hints, these precedence rules apply:
#
# 		) A hint takes precedence over any optimizer heuristic that is not a technical constraint.
# 			(If providing a hint as a suggestion has no effect, the optimizer has a reason for ignoring it)
#
# 		) A hint takes precedence over the derived_merge flag of the optimizer_switch system variable.
#
# 		) For view references, an ALGORITHM={MERGE|TEMPTABLE} clause in teh view definition takes precedence 
# 			over a hint specified in the query referencing the view.
#
# INDEX-LEVEL OPTIMIZER HINTS
#
# Index-level hints affect which index-processing strategies the optimizer uses for particular tables or indexes.
#
# These hint types affect use of Index Condition Pushdown (ICP), Multi-Range Read (MRR), Index Merge, and 
# range optimizations.
#
# SEE OPTIMIZING SELECT STATEMENTS.
#
# Syntax of index-level hints:
#
# 		hint_name([@query_block_name] tbl_name [index_name [, index_name] ---])
# 		hint_name(tbl_name@query_block_name [index_name [, index_name] ---])
#
# The syntax refers to these terms:
#
# 		) Hint_name: These hint names are permitted:
#
# 			) INDEX_MERGE, NO_INDEX_MERGE: Enable or disable the Index Merge access method for the specified
# 				table or indexes.
#
# 				For information about this access method, see INDEX MERGE OPTIMIZATION.
#
# 				These hints apply to all three Index Merge algorithms.
#
# 				The INDEX_MERGE hint forces the optimizer to use Index Merge for the specified
# 				table using the specified set of indexes.
#
# 				If no index is specified, the optimizer considers all possible index combinations
# 				and selects the least expensive one.
#
# 				The hint may be ignored if the index combination is inapplicable to the given statement.
#
# 				The NO_INDEX_MERGE hint disables Index Merge combinations that involve any of the specified indexes.
#
# 				If the hint specifies no indexes, Index Merge is not permitted for the table.
#
# 			) MRR, NO_MRR: Enable or disable MRR for the specified table or indexes.
#
# 				MRR hints apply only to InnoDB and MyISAM tables.
#
# 				For information about this access method, see MULTI-RANGE READ OPTIMIZATION
#
# 			) NO_ICP: Disable ICP for the specified table or indexes.
#
# 				By default, ICP is a candidate optimization strategy, so there is no hint
# 				for enabling it.
#
# 				For information about this access method, see INDEX CONDITION PUSHDOWN OPTIMIZATION
#
# 			) NO_RANGE_OPTIMIZATION:
#
# 				Disable index range access for the specified table or indexes.
#
# 				This hint also disables Index Merge and Loose Index Scan for the table or indexes.
#
# 				By default, range access is a candidate optimization strategy, so there is no hint for enabling it.
#
# 				This hint may be useful when the number of ranges may be high and range optimization would require many resources.
#
# 			) SKIP_SCAN, NO_SKIP_SCAN:
#
# 				Enable or disable the Skip Scan access method for the specified table or indexes.
#
# 				For information about this access method, see SKIP SCAN RANGE ACCESS METHOD.
#
# 				These hints are available as of MySQL 8.0.13
#
# 				The SKIP_SCAN hint forces the optimizer to use Skip Scan for the specified table using
# 				the specified set of indexes.
#
# 				If no index is specified, the optimizer considers all possible indexes and selects the
# 				least expensive one.
#
# 				The hint may be ignored if the index is inapplicable to the given statement.
#
# 				The NO_SKIP_SCAN hint disables Skin Scan for the specified indexes.
#
# 				If the hint specifies no indexes, Skip Scan is not permitted for the table.
#
# 			) tbl_name: The table to which the hint applies
#
# 			) index_name: The name of an index in the named table.
#
# 				The hint applies to all indexes that it names. If the hint names no indexes,
# 				it applies to all indexes in teh table.
#
# 				To refer to a primary key, use the name PRIMARY.
#
# 				To see the index names for a table, use SHOW_INDEX.
#
# 			) query_block_name: The query block to which the hint applies.
#
# 				If the hint includes no leading @query_block_name, the hint applies
# 				to the query block in which it occurs.
#
# 				For tbl_name@query_block_name syntax, the hint applies to the named table
# 				in teh named query block.
#
# 				To assign a name to a query block, see OPTIMIZER HINTS FOR NAMING QUERY BLOCKS.
#
# Examples:
#
# SELECT /*+ INDEX_MERGE(t1 f3, PRIMARY) */ f2 FROM t1
# 	WHERE f1 = 'o' AND f2 = f3 AND f3 <= 4;
#
# SELECT /*+ MRR(t1) */ * FROM t1 WHERE f2 <= 3 AND 3 <= f3;
#
# SELECT /*+ NO_RANGE_OPTIMIZATION(t3 PRIMARY, f2_idx) */ f1
# 		FROM t3 WHERE f1 > 30 AND f1 < 33;
#
# INSERT INTO t3(f1, f2, f3)
# 		(SELECT /*+ NO_ICP(t2) */ t2.f1, t2.f2, t2.f3 FROM t1, t2
# 		WHERE t1.f1=t2.f1 AND t2.f2 BETWEEN t1.f1
# 		AND t1.f2 AND t2.f2 + 1 >= t1.f1 + 1);
#
# SELECT /*+ SKIP_SCAN(t1 PRIMARY) */ f1, f2
# 	FROM t1 WHERE f2 > 40;
#
# The following examples use the Index Merge hints, but other index-level
# hints follow the same principles regarding hint ignoring and precedence
# of optimizer hints in relation to the optimizer_switch system variable or index hints.
#
# Assume that table t1 has columns a,b,c and d and that indexes named i_a, i_b and i_c exist
# on a, b and c, respectively:
#
# 		SELECT /*+ INDEX_MERGE(t1 i_a, i_b, i_c)*/ * FROM t1
# 			WHERE a = 1 AND b = 2 AND c = 3 AND d = 4;
#
# Index Merge is used for (i_a, i_b, i_c) in this case.
#
# 		SELECT /*+ INDEX_MERGE(t1 i_a, i_b, i_c)*/ * FROM t1
# 			WHERE b = 1 AND c = 2 AND d = 3;
#
# Index merge is used for (i_b, i_c) in this case
#
# /*+ INDEX_MERGE(t1 i_a, i_b) NO_INDEX_MERGE(t1 i_b) */
#
# NO_INDEX_MERGE is ignored because there is a preceding hint for the same table.
#
# 
# /*+ NO_INDEX_MERGE(t1 i_a, i_b) INDEX_MERGE(t1 i_b) */
#
# INDEX_MERGE is ignored because there is a preceding hint for the same table.
#
# For the INDEX_MERGE and NO_INDEX_MERGE optimizer hints, these precedence rules apply:
#
# 		) If an optimizer hint is specified and is applicable, it takes precedence over the Index Merge-related flags of the optimizer_switch system variable.
#
# 			SET optimizer_switch='index_merge_intersection=off';
# 			SELECT /*+ INDEX_MERGE(t1 i_b, i_c) */ * FROM t1
# 			WHERE b = 1 AND c = 2 AND d = 3;
#
# 		) The hint takes precedence over optimizer_switch. Index merge is used for (i_b, i_c) in this case.
#
# 			SET optimizer_switch='index_merge_intersection=on';
# 			SELECT /*+ INDEX_MERGE(t1 i_b) */ * FROM t1
# 			WHERE b = 1 AND c = 2 AND d = 3;
#
# 		) The hint specifies only one index, so it is inapplicable, and the optimizer_switch flag(on) applies.
# 			Index Merge is used if the optimizer assesses it to be cost efficient.
#
# 			SET optimizer_switch='index_merge_intersection=off';
# 			SELECT /*+ INDEX_MERGE(t1 i_b) */ * FROM t1
# 			WHERE b = 1 AND c = 2 AND d = 3;
#
# 		) The hint specifies only one index, so it is inapplicable, and the optimizer_switch(off) applies. Index merge is not used.
#
# ) The USE INDEX, FORCE INDEX, and IGNORE INDEX hints have higher priority than the INDEX_MERGE and NO_INDEX_MERGE optimizer hints.
#
# 		) /*+ INDEX_MERGE(t1 i_a, i_b, i_c) */ --- IGNORE INDEX i_a
#
# 			IGNORE INDEX takes precedence over INDEX_MERGE, so index i_a is excluded from the possible ranges for Index Merge.
#
# 		) /*+ NO_INDEX_MERGE(t1 i_a, i_b) */ --- FORCE INDEX i_a, i_b
#
# 			Index Merge is disallowed for i_a, i_b because of FORCE INDEX, but the optimizer is forced to use either i_a or i_b for range or ref access.
# 			There are no conflicts. Both hints are applicable.
#
# 		) If an IGNORE INDEX hint names multiple indexes, those indexes are unavailable for Index Merge
#
# 		) The FORCE INDEX and USE INDEX hints make only the named indexes to be available for Index Merge.
#
# 			SELECT /*+ INDEX_MERGE(t1 i_a, i_b, i_c) */ a FROM t1
# 			FORCE INDEX (i_a, i_b) WHERE c = 'h' AND a = 2 AND b = 'b';
#
# 			The Index Merge intersection access algorithm is used for (i_a, i_b).
#
# 			The same is true if FORCE INDEX is changed to USE INDEX
#
# SUBQUERY OPTIMIZER HINTS
#
# Subquery hints affect whether to use semi-join transformations and which semi-join strategies
# to permit, and, when semi-joins are not used, whether to use subquery materialization or IN-to-EXISTS transformations.
#
# For more information about these optimizations, see OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES AND COMMON TABLE EXPRESSIONS for more info.
#
# Syntax of hints that affect semi-join strategies:
#
# 		hint_name([@query_block_name] [strategy [, strategy] ---])
#
# The syntax refers to these terms:
#
# 		) hint_name: These hint names are permitted:
#
# 				) SEMIJOIN, NO_SEMIJOIN: Enable or disable the named semi-join strats.
#
# 		) Strategy: A semi-join strategy to be enabled or disabled.
#
# 						These strategy names are permitted: DUPSWEEDOUT, FIRSTMATCH, LOOSESCAN, MATERIALIZATION.
#
# 						For SEMIJOIN hints, if no strategies are named, semi-join is used if possible based on the strategies
# 						enabled according to the optimizer_switch system variable.
#
# 						If strategies are named but inapplicable for the statement, DUPSWEEDOUT is used.
#
# 						For NO_SEMIJOIN hints, if no strategies are named, semi-join is not used.
#
# 						If strategies are named that rule out all applicable strategies for the statement,
# 						DUPSWEEDOUT is used.
#
# IF one subquery is nested within another and both are merged into a semi-join of an outer query,
# any specifications of semi-join strategies for the innermost query are ignored.
#
# SEMIJOIN and NO_SEMIJOIN hints can still be used to enable or disable semi-join transformations
# for such nested subqueries.
#
# If DUPSWEEDOUT is disabled, on occasion the optimizer may generate a query plan that is far from optimal.
#
# This occurs due to heuristic pruning during greedy search, which can be avoided by setting optimizer_prune_level=0
#
# Examples:
#
# 		SELECT /*+ NO_SEMIJOIN(@subq1 FIRSTMATCH, LOOSESCAN) */ * FROM t2
# 			WHERE t2.a IN (SELECT /*+ QB_NAME(subq1) */ a FROM t3);
#
# 		SELECT /*+ SEMIJOIN(@subq1 MATERIALIZATION, DUPSWEEDOUT) */ * FROM t2
# 			WHERE t2.a IN (SELECT /*+ QB_NAME(subq1) */ a FROM t3);
#
# Syntax of hints that affect whether to use subquery materialization or IN-to-EXISTS transformations:
#
# 		SUBQUERY([@query_block_name] strategy)
#
# The hint name is always SUBQUERY.
#
# For SUBQUERY hints, these strategy values are permitted: INTOEXISTS, MATERIALIZATION.
#
# Examples:
#
# 		SELECT id, a IN (SELECT /*+ SUBQUERY(MATERIALIZATION */ a FROM t1) FROM t2;
# 		SELECT * FROM t2 WHERE t2.a IN (SELECT /*+ SUBQUERY(INTOEXISTS */ a FROM t1);
#
# For semi-join and SUBQUERY hints, a leading @query_block_name specifies teh query block
# to which the hint applies.
#
# If the hint includes no leading @query_block_name, the hint applies to the query block
# in which it occurs.
#
# To assign a name to a query block, see OPTIMIZER HINTS FOR NAMING QUERY BLOCKS.
#
# If a hint comment contains multiple subquery hints, the first is used.
#
# If there are other following hints of that type, they produce a warning.
#
# Following hints of other types are silently ignored.
#
# STATEMENT EXECUTION TIME OPTIMIZER HINTS
#
# The MAX_EXECUTION_TIME hint is permitted only for SELECT statements.
#
# It places a limit n(a timeout value in miliseconds) on how long a statement is permitted to execute before
# the server terminates it:
#
# 		MAX_EXECUTION_TIME(N)
#
# Examples with a timeout of 1 second (1000 miliseconds):
#
# 		SELECT /*+ MAX_EXECUTION_TIME(1000) */ * FROM t1 INNER JOIN t2 WHERE ---
#
# The MAX_EXECUTION_TIME(N) hint sets a statement execution timeout of N miliseconds.
#
# If this option is absent or N is 0, the statement timeout established by the max_execution_time system variable applies.
#
# The MAX_EXECUTION_TIME hint is applicable as follows:
#
# 		) For statements with multiple SELECT keywords,, such as unions or statements with subqueries, MAX_EXECUTION_TIME
# 			applies to the entire statement and must appear after the first SELECT.
#
# 		) It applies to read-only SELECT statements. Statements that are not read only are those that invoke a stored function that modifies data as a side effect.
#
# 		) It does not apply to SELECT statements in stored programs and is ignored.
#
# VARIABLE-SETTING HINT SYNTAX
#
# The SET_VAR hint sets the session value of a system variable temporarily (for the duration of a single statement).
# Examples:
#
# 		SELECT /*+ SET_VAR(sort_buffer_size = 16M) */ name FROM people ORDER BY name;
# 		INSERT /*+ SET_VAR(foreign_key_checks=OFF) */ INTO t2 VALUES(2);
# 		SELECT /*+ SET_VAR(optimizer_switch = 'mrr_cost_based=off') */ 1;
#
# Syntax of the SET_VAR hint:
#
# 		SET_VAR(var_name = value)
#
# var_name names a system variable that has a session value (although not all such variables can be named, as explained later).
# value is the value to assign to the variable; the value must be a scalar.
#
# SET_VAR makes a temporary variable change, as demonstrated by these statements:
#
# 		SELECT @@unique_checks;
# 		+---------------------+
# 		| @@unique_checks 	 |
# 		+---------------------+
# 		| 						1   |
# 		+---------------------+
#
# 		SELECT /* SET_VAR(unique_checks=OFF) */ @@unique_checks;
# 		+---------------------+
# 		| @@unique_checks 	 |
# 		+---------------------+
# 		| 						0   |
# 		+---------------------+
#
# 		SELECT @@unique_checks;
# 		+---------------------+
# 		| @@unique_checks 	 |
# 		+---------------------+
# 		| 						1   |
# 		+---------------------+
#
# With SET_VAR, there is no need to save and restore the variable value.
#
# This enables you to replace multiple statements by a single statement.
# Consider this sequence of statements:
#
# 		SET @saved_val = @@SESSION.var_name;
# 		SET @@SESSION.var_name = value;
# 		SELECT ---
# 		SET @@SESSION.var_name = @saved_val;
#
# The sequence can be replaced by this single statement:
#
# 		SELECT /*+ SET_VAR(var_name = value) ---
#
# Standalone SET statements permit any of these syntaxes for naming session variables:
#
# 		SET SESSION var_name = value;
# 		SET @@SESSION.var_name = value;
# 		SET @@.var_name = value;
#
# Because the SET_VAR hint applies only to session variables, session scope is implicit,
# and SESSION @@SESSION., and @@ are neither needed nor permitted.
#
# Including explicit session-indicator syntax results in the SET_VAR hint being ignored
# with a warning.
#
# Not all session variables are permitted for use with SET_VAR.
#
# individual system variable descriptions indicate whether each variable is hintable.
#
# You can also check a system variable at runtime by attempting to use it with SET_VAR.
# If the variable is not hintable, a warning occurs:
#
# 		SELECT /*+ SET_VAR(collation_server = 'utf8') */ 1;
# 		+---+
# 		| 1 |
# 		+---+
# 		| 1 |
# 		+---+
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		***************** 1. row ******************
# 		
# 			Level: Warning
# 			 Code: 4537
# 		 Message: Variable 'collation_server' cannot be set using SET_VAR hint.
#
# SET_VAR syntax permits setting only a single variable, but multiple hints cna be given to set multiple variables:
#
# 		SELECT /*+ SET_VAR(optimizer_switch = 'mrr_cost_based=off')
# 					  SET_VAR(max_heap_table_size = 1G) */ 1;
#
# If several hints with the same variable name appear in the same statement, the first one is
# applied and the others are ignored with a warning:
#
# 		SELECT /*+ SET_VAR(max_heap_table_size = 1G)
# 					  SET_VAR(max_heap_table_size = 3G) */ 1;
#
# In this case, the second hint is ignored with a warning that it is conflicting.
#
# A SET_VAR hint is ignored with a warning if no system variable has the specified
# name or the variable value is incorrect:
#
# 		SELECT /*+ SET_VAR(max_size = 1G) */ 1;
# 		SELECT /*+ SET_VAR(optimizer_switch = 'mrr_cost_based=yes') */ 1;
#
# For the first statement, there is no max_size variable.
#
# For the second statement, mrr_cost_flag takes values of on or off, so attempting to set "yes" is incorrect.
#
# In each case, the hint is ignored with a warning.
#
# The  SET_VAR hint is permitted only at the statement level.
#
# If used in a subquery, the hint is ignored with a warning.
#
# Slave servers ignore SET_VAR hints in replicated statements to avoid the potential for security issues.
#
# RESOURCE GROUP HINT SYNTAX
#
# The RESOURCE_GROUP optimizer hint is used for resource group management (see more under RESOURCE GROUPS).
#
# This hint assigns the thread that executes a statement to the named resource group temporarily (for the
# duration of the statement).
#
# It requires the RESOURCE_GROUP_ADMIN or RESOURCE_GROUP_USER privilege.
#
# Examples:
#
# 		SELECT /*+ RESOURCE_GROUP(USR_default) */ name FROM people ORDER BY name;
# 		INSERT /*+ RESOURCE_GROUP(Batch */ INTO t2 VALUES(2);
#
# Syntax of the RESOURCE_GROUP hint:
#
# 		RESOURCE_GROUP(group_name)
#
# group_name indicates the resource group to which the thread should be assigned
# for the duration of statement execution.
#
# If the group is nonexistent, a warning occurs and the hint is ignored.
#
# The RESOURCE_GROUP hint must appear after the initial statement keyword (SELECT, INSERT, REPLACE, UPDATE or DELETE)
#
# An alternative to RESOURCE_GROUP is the SET_RESOURCE_GROUP statement, which nontemporarily assigns threads
# to a resource group.
#
# See SET RESOURCE GROUP SYNTAX for more info.
#
# OPTIMIZER HINTS FOR NAMING QUERY BLOCKS
#
# Table-level, index-level and subquery optimizer hints permit specific query blocks
# to be named as part of their argument syntax.
#
# To create these names, use the QB_NAME hint, which assigns a name to the query block
# in which it occurs:
#
# 		QB_NAME(name)
#
# QB_NAME hints can be used to make explicit in a clear way which query blocks other hints apply to.
#
# They also permit all non-query block name hints to be specified within a single hint comment
# for easier understanding of complex statements.
#
# Consider teh following statement:
#
# 	SELECT ---
# 		FROM (SELECT ---
# 		FROM (SELECT --- FROM ---)) ---
#
# QB_NAME hints assign names to query blocks in the statement:
#
# 	SELECT /*+ QB_NAME(qb1) */ ---
# 		FROM (SELECT /*+ QB_NAME(qb2) */ ---
# 		FROM (SELECT /*+ QB_NAME(qb3) */ --- FROM ---)) ---
#
# Then other hints can use those names to refer to the appropriate query blocks:
#
# 	SELECT /*+ QB_NAME(qb1) MRR(@qb1 t1) BKA(@qb2) NO_MRR(@qb3t1 idx1, id2) */ ---
# 		FROM (SELECT /*+ QB_NAME(qb2) */ ---
# 		FROM (SELECT /*+ QB_NAME(qb3) */ --- FROM ---))---
#
# The resulting effect is as follows:
#
# 		) MRR(@qb1_t1) applies to table t1 in query block qb1
#
# 		) BKA(@qb2) applies to query block qb2
#
# 		) NO_MRR(@qb3_t1_idx1, id2) applies to indexes idx1 and idx2 in table t1 in query block qb3.
#
# Query block names are identifiers and follow the usual rules about what names are valid and how to quote them.
# (See more later under SCHEMA OBJECT NAMES)
#
# For example a query block name that contains spaces must be quoted, which can be done using backticks:
#
# 		SELECT /*+ BKA(@`my hint name`) */ ---
# 			FROM (SELECT /*+ QB_NAME(`my hint name`)` */ ---) --- 			
# 
# If the ANSI_QUOTES SQL mode is enabled, it is also possible to quote query block names
# within double quotation marks:
#
# 		SELECT /*+ BKA(@"my hint name") */ ---
# 			FROM (SELECT /*+ QB_NAME("my hint name") */ ---) ---
#
# SWITCHABLE OPTIMIZATIONS
#
# The optimizer_switch system variable enables control over optimizer behavior.
#
# Its value is a set of flags, each of which has a value of on or Off to indicate whether the
# corresponding optimizer behavior is enabled or disabled.
#
# This variable has global and session values and can be changed at runtime.
#
# The global default can be set at server startup.
#
# To see the current set of optimizer flags, select the variable value:
#
# 		SELECT @@optimizer_switch\G
# 		********************** 1. row ************************
# 		@@optimizer_switch: index_merge=on,index_merge_union=on,
# 								  index_merge_sort_union=on,
# 								  index_merge_intersection=on,
# 								  engine_condition_pushdown=on,
# 								  index_condition_pushdown=on,
# 								  mrr=on,mrr_cost_based=on,
# 								  block_nested_loop=on, batched_key_access=off,
# 								  
# 								  materialization=on, semijoin=on, loosescan=on,
# 								  firstmatch=on,duplicateweedout=on,
# 								  subquery_materialization_cost_based=on,
# 								  use_index_extensions=on,
# 								  condition_fanout_filter=on,derived_merge=on,
# 								  use_invisible_indexes=off,skip_scan=on
#
# To change the value of optimizer_switch, assign a value consisting of a comma-separated
# list of one or more commands:
#
# SET [GLOBAL|SESSION] optimizer_switch='command[,command] ---';
#
# Each command value should have one of the forms shown in the following table.
#
# Command Syntax 					Meaning
#
# default 					Reset every optimization to its default value
#
# opt_name=default 		Set the named optimization to its default value
#
# opt_name=off 			Disable the named optimization
#
# opt_name=on 				Enable the named optimization
#
# The order of commands in the value does not matter, although the default command is
# executed first if present.
#
# Setting an opt_name flag to default sets it to whichever of on or off is its default value.
# Specifying any given opt_name more than once in the value is not permitted and causes an error.
#
# Any errors in the value cause the assignment to fail with an error, leaving the value
# of optimizer_switch unchanged.
#
# The following list describes the permissible opt_name flag names, grouped by optimization strategy:
#
# 		) Batched Key Access Flags
#
# 			) batched_key_access (default off)
#
# 				Controls use of BKA join algorithm
#
# 			For batched_key_access to have any effect when set to on, the mrr flag must also be on.
# 			Currently, the cost estimation for MRR is too pessimistic.
#
# 			Hence, it is also necessary for mrr_cost_based to be off for BKA to be used.
#
# 			For more info, see BLOCK NESTED-LOOP AND BATCHED KEY ACCESS JOINS
#
# 		) Block Nested-Loop Flags
#
# 			) block_nested_loop (default on)
#
# 				Controls use of BNL join algorithm
#
# 			For more information, see BLOCK NESTED-LOOP AND BATCHED KEY ACCESS JOINS"
#
# 		) Condition Filtering Flags
#
# 			) condition_fanout_filter (default on)
#
# 				Controls use of condition filtering
#
# 			For more information, see CONDITION FILTERING
#
# 		) Derived Table Merging Flags
#
# 			) derived_merge (default on)
#
# 				Controls merging of derived tables and views into outer query block
#
# 			The derived_merge flag controls whether the optimizer attempts to merge derived tables,
# 			view references, and common table expressions into the outer query block, assuming that
# 			no other rule prevents merging.
#
# 			For example, an ALGORITHM directive for a view takes precedence over the derived_merge setting.
# 			By default, the flag is on to enable merging.
#
# 			For more info, read OPTIMIZING DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS
#
# 		) Engine Condition Pushdown Flags
#
# 			) engine_condition_pushdown (default on)
#
# 				Controls engine condition pushdown
#
# 			For more information, see ENGINE CONDITION PUSHDOWN OPTIMIZATION
#
# 		) Index Condition Pushdown Flags
#
# 			) index_condition_pushdown (default on)
#
# 				Controls index condition pushdown
#
# 			See INDEX CONDITION PUSHDOWN OPTIMIZATION
#
# 		) Index Extensions Flags
#
# 			) use_index_extensions (default on)
#
# 				Controls use of index extensions
#
# 			For more information, see USE OF INDEX EXTENSIONS
#
# 		) Index Merge Flags
#
# 			) index_merge (default on)
#
# 				Controls all Index Merge optimizations
#
# 			) index_merge_intersection (default on)
#
# 				Controls the Index Merge Intersection Access optimization.
#
# 			) index_merge_sort_union (default on)
#
# 				Controls the Index Merge Sort-Union Access optimization
#
# 			) index_merge_union (default on)
#
# 				Controls the Index Merge Union Access optimization
#
# 			For more info, see INDEX MERGE OPTIMIZATION
#
# 		) Index Visibility Flags
#
# 			) use_invisible_indexes (default off)
#
# 				Controls use of invisible indexes
#
# 			For more information, see Invisible Indexes
#
# 		) Multi-Range Read Flags
#
# 			) mrr (default on)
#
# 				Controls the Multi-Range Read strategy.
#
# 			) mrr_cost_based (default on)
#
# 				Controls use of cost-based MRR if mrr=on
#
# 			For more info, see MULTI-RANGE READ OPTIMIZATION
#
# 		) Skip Scan Flags
#
# 			) skip_scan (default on)
#
# 				Controls use of Skip Scan access method.
#
# 			For more information, see SKIP SCAN RANGE ACCESS METHOD.
#
# 		) Semi-Join Flags
#
# 			) semijoin (default on)
#
# 				Controls all semi-join strategies
#
# 			) duplicateweedout (default on)
#
# 				Controls the semi-join Duplicate Weedout strategy
#
# 			) firstmatch (default on)
#
# 				Controls the semi-join FirstMatch strategy
#
# 			) loosescan (default on)
#
# 				Controls the semi-join LooseScan strategy (not to be confused with Loose Index Scan for GROUP BY)
#
# 			The semijoin, firstmatch, loosescan and duplicateweedout flags enable control over semi-join strategies.
#
# 			The semijoin flag controls whether semi-joins are used.
#
# 			If it is set to on, teh firstmatch and loosescan flags enable finer control over the permitted semi-join strategies.
#
# 			If the duplicateweedout semi-join strategy is disabled, it is not used unless all other applicable strategies are also disabled.
#
# 			If semijoin and materialization are both on, semi-joins also use materialization where applicable. These flags are on by default.
#
# 			For more information, see OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES, AND COMMON TABLE EXPRESSIONS WITH SEMI-JOIN TRANSFORMATION.
#
# 		) Subquery Materialization Flags
#
# 			) materialization (default on)
#
# 				Controls materialization (including semi-join materialization)
#
# 			) subquery_materialization_cost_based (default on)
#
# 				Use cost-based materialization choice.
#
# 			The materialization flag controls whether subquery materialization is used.
#
# 			If semijoin and materialization are both on, semi-joins also use materialization
# 			where applicable.
#
# 			These flags are on by default.
#
# 			The subquery_materialization_cost_based flag enables control over the choice between subquery materialization
# 			and IN-to-EXISTS subquery transformation.
#
# 			if the flag is on (the default), the optimizer performs a cost-based choice between subquery-materialization
# 			and IN-to-EXISTS subquery transformation if either method could be used.
#
# 			if the flag is off, the optimizer chooses subquery materialization over IN-to-EXISTS subquery transformation.
#
# 			For more information, see OPTIMIZING SUBQUERIES, DERIVED TABLES, VIEW REFERENCES AND COMMON TABLE EXPRESSIONS
#
# When you asssign a value to optimizer_switch, flags that are not mentioned keep their current value.
#
# THis makes it possible to enable or disable specific optimizer behaviors in a single statement without affecting
# other behaviors.
#
# The statement does not depends on what other optimizer flags exist and what their values are.
#
# Suppose that all Index Merge optimizations are enabled:
#
# 			SELECT @@optimizer_switch\G
# 			********************** 1. row *********************
# 			@@optimizer_switch: index_merge=on,index_merge_union=on,
# 									  index_merge_sort_union=on,
# 									  index_merge_intersection=on,
# 									  engine_condition_pushdown=on,
# 									  index_condition_pushdown=on,
# 									  mrr=on, mrr_cost_based=on,
#
# 									  block_nested_loop=on, batched_key_access=off,
# 									  materialization=on, semijoin=on, loosescan=on,
# 									  firstmatch=on, subquery_materialization_cost_based=on,
# 									  use_index_extensions=on, condition_fanout_filter=on
#
# If the server is using the Index Merge Union or Index Merge Sort-Union access methods for certain
# queries and you want to check whether the optimizer will perform better without them, set the variable like this:
#
# 			SET optimizer_switch='index_merge_union=off,index_merge_sort_union=off';
#
# 			SELECT @@optimizer_switch\G
# 			*********************** 1. row ********************
# 			@@optimizer_switch: index_merge=on, index_merge_union=off,
# 									  index_merge_sort_union=off,
# 									  index_merge_intersection=on,
# 									  engine_condition_pushdown=on,
# 									  index_condition_pushdown=on,
# 									  mrr=on,mrr_cost_based=on,
#
# 									  block_nested_loop=on, batched_key_access=off,
# 									  materialization=on,semijoin=on,loosescan=on,
# 									  firstmatch=on,
# 									  subquery_materialization_cost_based=on,
# 									  use_index_extensions=on,
# 									  condition_fanout_filter=on
#
# INDEX HINTS
#
# Index hints gives the optimizer information about how to choose indexes during query processing.
# Index hints, described here, differ from optimizer hints, described in OPTIMIZER HINTS.
#
# Index and optimizer hints may be used separately or together.
#
# Index hints apply only to SELECT statements. 
# (They are accepted by the parser for UPDATE statements but are ignored and have no effect)
# 		
# Index hints are specified following a table name. 
# (For the general syntax for specifying tables in a SELECT statement, see JOIN SYNTAX for more info)
#
# The syntax for referring to an individual table, including index hints, looks like this:
#
# 		tbl_name [[AS] alias] [index_hint_list]
#
# 		index_hint_list:
# 			index_hint [index_hint] ---
#
# 		index_hint:
# 			USE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] ([index_list])
# 		 | IGNORE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] (index_list)
# 		 | FORCE {INDEX|KEY}
# 				[FOR {JOIN|ORDER BY|GROUP BY}] (index_list)
#
# 		index_list:
# 			index_name [, index_name] ---
#
# The USE INDEX (index_list) hint tells MySQL to use only one of the named indexes to find rows in the table.
# The alternative syntax IGNORE INDEX (index_list)  tells MySQL to not use some particular index or indexes.
#
# These hints are useful if EXPLAIN shows that MySQL is using the wrong index from the list of possible indexes.
#
# The FORCE INDEX hint acts like USE INDEX (index_list), with the addition that a table scan is assumed to be
# VERY expensive.
#
# In other words, a table scan is used only if there is no way to use one of the named indexes to find rows
# in the table.
#
# Each hint requires index names, not column names. To refer to a primary key, use the name PRIMARY.
# To see the index names for a table, use the SHOW_INDEX statement or the INFORMATION_SCHEMA.STATISTICS table.
#
# An index_name value need not be a full index name. It can be unambiguous prefix of an index name.
# If a prefix is ambiguous, an error occurs.
#
# Examples:
#
# 		SELECT * FROM table1 USE INDEX (col1_index, col2_index)
# 			WHERE col1=1 AND col2=2 AND col3=3;
#
# 		SELECT * FROM table1 IGNORE INDEX (col3_index)
# 			WHERE col1=1 AND col2=2 AND col3=3;
#
# The syntax for index hints has the following characteristics:
#
# 		) It is syntactically valid to omit index_list for USE_INDEX, which means "use no indexes".
#
# 			Omitting index_list for FORCE_INDEX or IGNORE INDEX is a syntax error.
#
# 		) You can specify the scope of an index hint by adding a FOR clause to the hint.
#
# 			This provides more fine-grained control over optimizer selection of an execution plan for
# 			various phases of query processing. 
#
# 			To affect only the indexes used when MySQL decides how to find rows in the table and how
# 			to process joins, use FOR JOIN.
#
# 			To influence index usage for sorting or grouping rows, use FOR ORDER BY or FOR GROUP BY.
#
# 		) You can specify multiple index hints:
#
# 				SELECT * FROM t1 USE INDEX (i1) IGNORE INDEX FOR ORDER BY (i2) ORDER BY a;
#
# 			It is not an error to name the same index in several hints (even with the same hint):
#
# 				SELECT * FROM t1 USE INDEX (i1) USE INDEX (i1,i1);
#
# 			However, it is an error to mix USE INDEX and FORCE INDEX for the same table:
#
# 				SELECT * FROM t1 USE INDEX FOR JOIN (i1) FORCE INDEX FOR JOIN (i2);
#
# If an index hint includes no FOR clause, the scope of the hint is to apply to all parts
# of the statement.
#
# For example, this hint:
#
# 		IGNORE INDEX (i1)
#
# is equivalent to this combination of hints:
#
# 		IGNORE INDEX FOR JOIN (i1)
# 		IGNORE INDEX FOR ORDER BY (i1)
# 		IGNORE INDEX FOR GROUP BY (i1)
#
# In MySQL 5.0, hint scope with no FOR clause was to apply only to row retrieval.
#
# To cause the server to use this older behavior when no FOR clause is present, enable
# the old system variable at server startup.
#
# Take care about enabling this variable in a replication setup.
#
# With statement-based binary logging, having different modes for the master and slaves
# might lead to replication errors.
#
# WHen index hints are processed, they are collected in a single list by type (USE, FORCE, IGNORE)
# and by scope (FOR JOIN, FOR ORDER BY, FOR GROUP BY)
#
# For example:
#
# 		SELECT * FROM t1
# 			USE INDEX () IGNORE INDEX (i2) USE INDEX (i1) USE INDEX (i2);
#
# Is equivalent to:
#
# 		SELECT * FROM t1
# 			USE INDEX (i1,i2) IGNORE INDEX (i2);
#
# The index hints then are applied for each scope in the following order:
#
# 		1. {USE|FORCE} INDEX is applied if present. (If not, the optimizer-determined set of indexes is used)
#
# 		2. IGNORE INDEX is applied over the result of the previous step
#
# 			For example, the following two queries are equivalent:
#
# 				SELECT * FROM t1 USE INDEX (i1) IGNORE INDEX (i2) USE INDEX (i2);
#
# 				SELECT * FROM t1 USE INDEX (i1);
#
# For FULLTEXT searches, index hints work as follows:
#
# 		) For natural language mode searches, index hints are silently ignored.
#
# 			For example, IGNORE INDEX(i1) is ignored with no warning and the index is still used.
#
# 		) For boolean mode searches, index hints with FOR ORDER BY or FOR GROUP BY are silently ignored.
#
# 			Index hints with FOR JOIN or no FOR modifier are honored.
#
# 			In contrast to how hints apply for non-FULLTEXT searches, the hint is used for all phases
# 			of query execution (finding rows and retrieval, grouping and ordering)
#
# 			This is true even if the hint is given for a non-FULLTEXT index.
#
# 			For example, the following two queries are equivalent:
#
# 				SELECT * FROM t
# 					USE INDEX (index1)
# 					IGNORE INDEX (index1) FOR ORDER BY
# 					IGNORE INDEX (index1) FOR GROUP BY
# 					WHERE --- IN BOOLEAN MODE ---
#
# 				SELECT * FROM t
# 					USE INDEX (index1)
# 					WHERE --- IN BOOLEAN MODE ---
#
# THE OPTIMIZER COST MODEL
#
# To generate execution plans, the optimizer uses a cost model that is based on estimates
# of the cost of various operations that occur during query execution.
#
# The optimizer has a set of compiled-in default "cost constants" available to it to make
# decisions regarding execution plans.
#
# The optimizer also has a database of cost estimates to use during execution plan construction.
#
# These estimates are stored in the server_cost and engine_cost tables in the mysql system
# database and are configurable at any time.
#
# The intent of these tables is to make it possible to easily adjust the cost estimates that the
# optimizer uses when it attempts to arrive at query execution plans.
#
# COST MODEL GENERAL OPERATION
#
# The configurable optimizer cost model works like this:
#
# 		) The server reads the cost model tables into memory at startup and uses the in-memory values at runtime.
#
# 			Any non-NULL cost estimate specified in the tables takes precedence over the corresponding compiled-in
# 			default  cost constant.
#
# 			Any NULL estimate indicates to the optimizer to use the compiled-in default.
#
# 		) At runtime, the server may reread the cost tables. This occurs when a storage engine is dynamically
# 			loaded or when a FLUSH_OPTIMIZER_COSTS statement is executed.
#
# 		) Cost tables enable server administrators to easily adjust cost estimates by changing entries in the tables.
#
# 			It is also easy to revert to a default by setting an entry's cost to NULL.
#
# 			The optimizer uses the in-memory cost values, so changes to the tables should be followed by FLUSH_OPTIMIZER_COSTS
# 			to take effect.
#
# 		) The in-memory cost estimates that are current when a client sessions begins apply throughout that session until it ends.
#
# 			In particular, if the server rereads the cost tables, any changed estimates apply only to subsequently started sessions.
#
# 			Existing sessions are unaffected.
#
# 		) Cost tables are specific to a given server instance. The server does not replicate cost table changes to replication slaves.
#
# THE COST MODEL DATABASE
#
# the optimizer cost model database consists of two tables in the mysql system database that contain cost
# estimate information for operations that occur during query execution:
#
# 		) server_cost : Optimizer cost estimates for general server operations
#
# 		) engine_cost : Optimizer cost estimates for operations specific to particular storage engines
#
# The server_cost table contains these columns:
#
# 		) cost_name
#
# 			The name of a cost estimate used in the cost model.
#
# 			The name is not case-sensitive. If the server does not recognize the cost name
# 			when it reads this tables, it writes a warning to the error log.
#
# 		) cost_value
#
# 			The cost estimate value. If the value is non-NULL, the server uses it as the cost.
# 			Otherwise, it uses the default estimate (the compiled-in value).
#
# 			DBAs can change a cost estimate by updating this column.
#
# 			If the server finds that the cost value is invalid (nonpositive) when it reads this table,
# 			it writes a warning to the error log.
#
# 			To override a default cost estimate (for an entry that specifies NULL), set the cost to
# 			a non-NULL value.
#
# 			To revert to the default, set the value to NULL.
#
# 			Then execute FLUSH_OPTIMIZER_COSTS to tell the server to reread the cost tables.
#
# 		) last_update
#
# 			The time of the last row update.
#
# 		) comment
#
# 			A descriptive comment associated with the cost estimate.
#
# 			DBAs can use this column to provide information about why a cost estimate row stores a particular value.
#
# 		) default_value
#
# 			The default (compiled-in) value for the cost estimate.
#
# 			This column is a read-only generated column that retains its value even if the associated
# 			cost estimate is changed.
#
# 			For rows added to the table at runtime, the value of this column is NULL.
#
# The primary key for the server_cost table is the cost_name column, so it is not possible to create multiple
# entries for any cost estimate.
#
# The server recognizes these cost_name values for the server_cost table:
#
# 		) disk_temptable_create_cost, disk_temptable_row_cost
#
# 			The cost estimates for internally created temporary table stored in a disk-based storage engine
# 			(either InnoDB or MyISAM)
#
# 			Increasing these values increases the cost estimate of using internal temporary tables and makes
# 			the optimizer prefer query plans with less use of them.
#
# 			For information about such tables, see INTERNAL TEMPORARY TABLE USE IN MYSQL.
#
# 			The larger default value for these disk parameters compared to the default values for the
# 			corresponding memory parameters (memory_temptable_create_cost, memory_temptable_row_cost)
# 			reflects the greater cost of processing disk-based tables.
#
# 		) key_compare_cost
#
# 			The cost of comparing record keys. Increasing this value causes a query plan that compares
# 			many keys to become more expensive.
#
# 			For example, a query plan that performs a filesort becomes relativily more expensive compared to
# 			a query plan that avoids sorting by using an index.
#
# 		) memory_temptable_create_cost, memory_temptable_row_cost
#
# 			The cost estimates for internally created temporary tables stored in the MEMORY storage engine.
#
# 			Increasing these values increases the cost estimate of using internal temporary tables
# 			and makes the optimizer prefer query plans with less use of them.
#
# 			For information about such tables, see INTERNAL TEMPORARY TABLE USE IN MYSQL
#
# 			The smaller default  values for these memory parameters compared to the default values for the corresponding
# 			disk parameters (disk_temptable_create_cost, disk_temptable_row_cost) reflects the lesser cost of processing
# 			memory-based tables.
#
# 		) row_evaluate_cost
#
# 			The cost of evaluating record conditions. Increasing this value causes a query plan that examines
# 			rows to become more expensive compared to a query plan that examines fewer rows.
#
# 			For example, a table scan becomes relativily more expensive compared to a range scan that reads fewer rows.
#
# The engine_cost table contains these columns:
#
# 		) engine_name
#
# 			The name of the storage engine to which this cost estimate applies.
# 			The name is not case-sensitive.
#
# 			If the value is default, it applies to all storage engines that have no
# 			named entry of their own.
#
# 			If the server does not recognize the engine name when it reads this table, it writes a warning to the error log
#
# 		) device_type
#
# 			The device type to which this cost estimate applies.
#
# 			The column is intended for specifying different cost estimates for different
# 			storage device types, such as hard disk drives versus solid state drives.
#
# 			Currently, this information is not used and 0 is the only permitted value.
#
# 		) cost_name
#
# 			Same as in the server_cost table.
#
# 		) cost_value
#
# 			Same as in the server_cost table.
#
# 		) last_update
#
# 			Same as in the server_cost table.
#
# 		) comment
#
# 			Same as in the server_cost table
#
# 		) default_value
#
# 			The default (compiled-in) value for the cost estimate.
#
# 			This column is read-only column that retains its value even if the associated
# 			cost estimate is changed.
#
# 			For rows added to the table at runtime, the value of this column is NULL, with the
# 			exception that if the row has the same cost_name value as one of the original rows,
# 			the default value column will have the same value as that row.
#
# The primary key for the engine_cost table is a tuple comprising the (cost_name, engine_name, device_type)
# columns, so it is not possible to create multiple entries for any combination of values in those columns.
#
# The server recognizes these cost_name values for the engine_cost table:
#
# 		) io_block_read_cost
#
# 			The cost of reading an index or data block from disk.
#
# 			Increasing this value causes a query plan that reads many disk blocks to become more expensive compared to
# 			a query plan that reads fewer disk blocks.
#
# 			For example, a table scan becomes relatively more expensive compared to a range scan that reads fewer blocks.
#
# 		) memory_block_read_cost
#
# 			Similar to io_block_read_cost, but represents the cost of reading an index or data block from an in-memory database buffer.
#
# If the io_block_read_cost and memory_block_read_cost values differ, the execution plan may change between
# two runs of the same query.
#
# Suppose that the cost for memory access is less than the cost for disk access.
#
# In that case, at server startup before data has been read into the buffer pool, you may
# get a different plan than after the query has been run because then the data will be in memory.
#
# MAKING CHANGES TO THE COST MODEL DATABASE
#
# For DBAs who wish to change the cost model parameters from their defaults, try doubling
# or halving the value and measuring the effect.
#
# Changes to the io_block_read_cost and memory_block_read_cost parameters are most likely to
# yield worthwhile results.
#
# These parameter values enable cost models for data access methods to take into account the costs
# of reading information from different sources; that is, the cost of reading information from disk
# versus reading information already in a memory buffer.
#
# For example, all other things being equal, setting io_block_read_cost to a value larger than
# memory_block_read_cost causes the optimizer to prefer query plans that read information already
# held in memory to plans that must read from disk.
#
# This example shows how to change the default value for io_block_read_cost:
#
# 		UPDATE mysql.engine_cost
# 			SET cost_value = 2.0
# 			WHERE cost_name = 'io_block_read_cost';
# 		FLUSH OPTIMIZER_COSTS;
#
# This example show how to change the value of io_block_read_cost only for the InnoDB storage engine:
#
# 		INSERT INTO mysql.engine_cost
# 			VALUES ('InnoDB', 0, 'io_block_read_cost', 3.0,
# 			CURRENT_TIMESTAMP, 'Using a slower disk for InnoDB');
# 		FLUSH OPTIMIZER_COSTS;
#
# OPTIMIZER STATISTICS
#
# The column_statistics data dictionary table stores histogram statistics about column values,
# for use by the optimizer in constructing query execution plans.
#
# To perform histogram management, use the ANALYZE_TABLE statement; see ANALYZE TABLE SYNTAX for more
#
# The column_statistics table has these characteristics:
#
# 		) The table contains statistics for columns of all data types except geometry types (spatial data) and JSON.
#
# 		) The table is persistent so that column stats need not be created each time the server starts.
#
# 		) The server performs updates to the table; users do not.
#
# The column_statistics table is not directly accessible by users because it is part of the data dictionary.
#
# Histogram information is available using INFORMATION_SCHEMA.COLUMN_STATISTICS, which is implemented as a view
# on the data dictionary table.
#
# COLUMN_STATISTICS has these columns:
#
# 		) SCHEMA_NAME, TABLE_NAME, COLUMN_NAME: The names of the schema, table, and column for which the stats apply.
#
# 		) HISTOGRAM: A JSON value describing the column stats, stored as a histogram.
#
# Column histograms contain buckets for parts of the range of values stored in the column.
# Histograms are JSON objects to permit flexibility in the representation of column stats.
#
# Here is a sample histogram object:
#
# 		{
# 			"buckets": [
# 				[
# 					1,
# 					0,33---
# 				],
# 				[
# 					2,
# 					0,66---
# 				],
# 				[
# 					3,
# 					1,
# 				]
# 			],
# 			"null-values": 0,
# 			"last-udpated": "2017-03-24 13:32:40.00000";
# 			"sampling-rate": 1,
# 			"histogram-type": "singleton",
# 			"number-of-buckets-specified": 128,
# 			"data-type": "int",
# 			"collation-id": 8
# 		}
#
# histogram objects have these keys:
#
# 		) buckets: The histogram buckets. Bucket structure depends on the histogram type.
#
# 			For singleton histograms, buckets contain two values:
#
#  			) Value 1: The value for the bucket. The type depends on the column data type.
#
# 				) Value 2: A double representing the cumulative frequency for the value.
#
# 							For example, .25 and .75 indicate that 25% and 75% of the values in the columns are less
# 							than or equal to the bucket value.
#
# 			For equi-height histograms, buckets contain four values:
#
# 				) Values 1,2: The Lower and upper inclusive values for the bucket.
# 									The type depends on the column data type.
#
# 				) Value 3: A double representing the cumulative frequency for the value.
#
# 							For example, .25 and .75 indicates that 25% and 75% of the values in the columns are less
# 							than or equal to the bucket upper value. 				
#
#				) Value 4: The number of distinct values in the range from the bucket lower value to its upper value.
#
# 		) null-values: A number between 0.0 and 1.0 indicating the fraction of column values that are SQL NULL values. If 0, the column contains no NULL values.
#
# 		) last-updated: When the histogram was generated, as a UTC value in YYYY-MM-DD HH:MM:SS.hhmmss format.
#
# 		) sampling-rate: a number between 0.0 and 1.0 indicating the fraction of data that was sampled to create the histogram.
#
# 							A value of 1 means that all of the data was read (no sampling)
#
# 		) histogram-type: The histogram type:
# 	
# 			) singleton: One bucket represents one single value in teh column.
#
# 							This histogram type is created when the number of distinct values in the column
# 							is less than or equal to the number of buckets specified in the ANALYZE_TABLE 
# 							statement that generate the histogram.
#
# 			) equi-height: One bucket represents a range of values.
#
# 							This histogram type is created when the number of distinct values in the column is
# 							greater than the number of buckets specified in the ANALYZE_TABLE statement that generated
# 							the histogram.
#
# 		) number-of-buckets-specified: The number of buckets specified in the ANALYZE_TABLE statement that generated the histogram.
#
# 		) data-type: The type of data this histogram contains.
#
# 						This is needed when reading and parsing histograms from persistent storage into memory.
# 						The value is one int, uint (unsigned integer), double, decimal, datetime or string (includes character and binary strings)
#
# 		) collation-id: The collation ID for the histogram data.
#
# 						It is mostly meaningful when the data-type value is string.
# 						Values corresponding to ID column values in the INFORMATION_SCHEMA.COLLATIONS table.
#
# To extract particular values from the histogram objects, you can use JSON operations.
# For example:
#
# 		SELECT
# 			TABLE_NAME, COLUMN_NAME,
# 			HISTOGRAM->>'$."data-type"' AS 'data-type',
# 			JSON_LENGTH(HISTOGRAM->>'$."buckets"') AS 'bucket-count'
# 		FROM INFORMATION_SCHEMA.COLUMN_STATISTICS;
#
# 	+-----------------+---------------+--------------+--------------+
# 	| TABLE_NAME 		| COLUMN_NAME   | data-type    | bucket-count |
# 	+-----------------+---------------+--------------+--------------+
# 	| country 	 		| Population 	  | int 			  | 			226 |
#  | city 		 		| Population 	  | int 			  | 		  1024 |
# 	| countrylanguage | Language 		  | string 		  | 			457 |
# 	+-----------------+----------------+--------------+-------------+
#
# The optimizer uses histogram statistics, if applicable, for columns of any data type for which
# statistics are collected.
#
# The optimizer applies histogram statistics to determine row estimates based on the 
# selectivity (filtering effect) of column value comparisons against constant values.
#
# Predicates of these forms qualify for histogram use:
#
# 		col_name = constant
# 		col_name <> constant
# 		col_name != constant
# 		col_name > constant
#
# 		col_name < constant
# 		col_name >= constant
# 		col_name <= constant
#
# 		col_name IS NULL
# 		col_name IS NOT NULL
# 		col_name BETWEEN constant AND constant
# 
# 		col_name NOT BETWEEN constant AND constant
# 		col_name IN (constant[, constant] ---)
# 		col_name NOT IN (constant[, constant] ---)
#
# For example, these statements contain predicates that qualify for histogram use:
#
# 		SELECT * FROM orders WHERE amount BETWEEN 100.0 AND 300.0;
# 		SELECT * FROM tbl WHERE col1 = 15 AND col2 > 100;
#
# The requirement for comparison against a constant value includes functions that are
# constant, such as ABS() and FLOOR():
#
# 		SELECT * FROM tbl WHERE col1 < ABS(-34);
#
# Histogram stats are useful primarily for nonindexed columns.
#
# Adding an index to a column for which histogram stats are applicable
# might also help the optimizer make row estimates.
#
# The tradeoffs are:
#
# 		) An index must be updated when table data is modified.
#
# 		) A histogram is created or updated only on demand, so it adds no overhead when table data is modified.
# 		
# 			On the other hand, the stats become progressively more out of date when table modifications occur,
# 			until the next time they are updated.
#
# The optimizer prefers range optimizer row estimates to those obtained from histogram stats.
#
# If the optimizer determines that the range optimizer applies, it does not use histogram stats.
#
# For columns that are indexed, row estimates can be obtained for equality comparisons using index dives
# (see RANGE OPTIMIZATION)
#
# In this case, histogram stats are not necessarily useful because index dives can yield better estimates.
#
# In some cases, use of histogram stats may not improve query execution; for example, if the stats are
# out of date.
#
# To check whether this is the case, use ANALYZE TABLE to regenerate the histogram stats, then run the query again.
#
# Alternatively, to disable histogram stats, use ANALYZE_TABLE to drop them.
#
# A different method of disabling histogram stats is to turn off the condition_fanout_filter flag
# of the optimizer_switch system variable (although this may disable other optimizations as well):
#
# 		SET optimizer_switch='condition_fanout_filter=off';
#
# If histogram stats are used, the resulting effect is visible using EXPLAIN.
#
# Consider the following query, where no index is available for column col1:
#
# SELECT * FROM t1 WHERE col1 < 24;
#
# If histogram stats indicate that 57% of the rows in t1 satisfy the col1 < 24 predicate,
# filtering can occur even in the absence of an index, and EXPLAIN shows 57.00 in the filtered column.
#
# BUFFERING AND CACHING
#
# MySQL uses several strategies that cache information in memory buffers to increase performance.
#
# InnoDB BUFFER POOL OPTIMIZATION
#
# InnoDB maintains a storage area called the buffer pool for caching data and indexes in memory.
#
# Knowing how the InnoDB buffer pool works, and taking advantage of it to keep frequently accessed
# data in memory, is an important aspect of MySQL tuning.
#
# For an explanation of the inner workings of the InnoDB buffer pool, an overview of its LRU replacement algorithm,
# and general configuration information, see BUFFER POOL.
#
# For additional InnoDB buffer pool configuration and tuning information, see these sections:
#
# 	) CONFIGURING INNODB BUFFER POOL PREFETCHING (READ-AHEAD)
#
# 	) CONFIGURING INNODB BUFFER POOL FLUSHING
#
# 	) MAKING THE BUFFER POOL SCAN RESISTANT
#
# 	) CONFIGURING MULTIPLE BUFFER POOL INSTANCES
#
# 	) SAVING AND RESTORING THE BUFFER POOL STATE
#
# 	) FINE-TUNING INNODB BUFFER POOL FLUSHING
#
# 	) CONFIGURING INNODB BUFFER POOL SIZE
#
# THE MYISAM KEY CACHE
#
# To minimize disk I/O, the MyISAM storage engine exploits a strategy that is used by many DB management
# systems.
#
# It employs a cache mechanism to keep the most frequently accessed table blocks in memory:
#
# 		) For index blocks, a special structure called the key cache (or key buffer) is maintained.
# 			The structure contains a number of block buffers where the most-used index blocks are placed.
#
# 		) For data blocks, MYSQL uses no special cache. Instead it relies on the native operating system file system cache.
#
# This section first describes the basic operation of the MyISAM key cache.
#
# Then it discusses features that improve key cache performance and that enables you
# to better control cache operation:
#
# 		) Multiple sessions can access the cache concurrently.
#
# 		) You can set up multiple key caches and assign table indexes to specific caches.
#
# To control the size of the key cache, use the key_buffer_size system variable.
#
# If this variable is set equal to 0, no key cache is used.
#
# The key cache also is not used if the key_buffer_size value is too small to allocate
# the minimal number of block buffers (8).
#
# When the key cache is not operational, index files are accessed using only the native file system
# buffering provided by the operating system.
#
# (In other words, table index blocks are accessed using the same strategy as that employed for table data blocks)
#
# An index block is a contigous unit of access to the MyISAM index files.
#
# Usually the size of an index block is equal to the size of nodes of the index B-TREE.
#
# (Indexes are represented on disk using a B-tree data structure. Nodes at the bottom of the 
# tree are leaf nodes.
#
# Nodes above the leaf nodes are nonleaf nodes)
#
# All block buffers in a key cache structure are the same size.
#
# This size can be equal to, greater than, or less than size of a table index block. 
# Usually once these two values is a multiple of the other.
#
# When data from any table index block must be accessed, the server first checks whether it is
# available in some block buffer of the key cache.
#
# If it is, the server accesses data in the key cache rather than on disk.
#
# That is, it reads from the cache or writes into it rather than reading from or writing to disk.
#
# Otherwise, the server chooses a cache block buffer containing a different table index block (or blocks)
# and replaces the data there by a copy of required table index block.
#
# As soon as the new index block is in the cache, the index data can be accessed.
#
# If it happens that a block selected for replacement has been modified, the block is
# considered "dirty". In this case, prior to being replaced, its contents are flushed
# to the table index from which it came.
#
# Usually, the server follows an LRU (Least Recently Used) strategy.
#
# When choosing a block for replacement, it selects the least recently used index block.
# To make this choice easier, the key cache module maintains all used blocks in a special list
# (LRU chain) ordered by time of use.
#
# When a block is accessed, it is the most recently used and is placed at the end of the list.
#
# WHen blocks need to be replaced, blocks at the beginning of the list are the least recently
# used and become the first candidates for eviction.
#
# The InnoDB storage engine also uses an LRU algorithm, to manage its buffer pool.
# See BUFFER POOL for more, later.
#
# SHARED KEY CACHE ACCESS
#
# Threads can access key cache buffers simultaneously, subject to the following conditions:
#
# 		) A buffer that is not being updated can be accessed by multiple sessions.
#
# 		) A buffer that is being updated causes sessions that need to use it to wait until the update is complete.
#
# 		) Multiple sessions can initiate requests that result in cache block replacements, as long as they do
# 			not interfere with each other (that is, as long as they need different index blocks, and thus cause
# 			different cache blocks to be replaced)
#
# Shared access to the key cache enables the server to improve throughput significantly.
#
# MULTIPLE KEY CACHES
#
# Shared access to the key cache improves performance but does not eliminate contention among sessions entirely.
#
# They still compete for control structures that manage access to the key cache buffers.
#
# To reduce key cache access contention further, MySQL also provides multiple key caches.
# This feature enables you to assign different table indexes to different key caches.
#
# Where there are multiple key caches, the server must know which cache to use when processing
# queries for a given MyISAM table.
#
# By default, all MyISAM table indexes are cached in the default key cache.
#
# To assign table indexes to a specific key cache, use the CACHE_INDEX statement (See more under CACHE INDEX SYNTAX later).
#
# For example, the following statement assigns indexes from the tables t1, t2, and t3 to the key cache
# named hot_cache:
#
# 		CACHE INDEX t1, t2, t3 IN hot_cache;
# 		+-----------+--------------------+-------------+----------+
# 		| Table 		| Op 						| Msg_type 	  | Msg_text |
# 		+-----------+--------------------+-------------+----------+
# 		| test.t1   | assign_to_keycache | status 	  | OK 	    |
# 		| test.t2   | assign_to_keycache | status 	  | OK 	    |
# 	   | test.t3   | assign_to_keycache | status 	  | OK 		 |
# 		+-----------+--------------------+-------------+----------+
#
# The key cache referred to in a CACHE_INDEX statement can be created by setting its size with a SET_GLOBAL
# parameter setting statement or by using server startup options.
#
# 		SET GLOBAL keycache1.key_buffer_size=128*1024;
# 
# To destroy a key cache, set its size to zero:
#
# 		SET GLOBAL keycache1.key_buffer_size=0;
#
# You cannot destroy the default key cache.
# Any attempt to do this is ignored:
#
# 		SET GLOBAL key_buffer_size = 0;
#
# 		SHOW VARIABLES LIKE 'key_buffer_size';
# 		+-------------------------+-------------+
# 		| Variable_name 			  | Value 		 |
# 		+-------------------------+-------------+
# 		| key_buffer_size 		  | 8384512 	 |
# 		+-------------------------+-------------+
#
# Key cache variables are structured system variables that have a name and components.
#
# For keycache1.key_buffer_size, keycache1 is the cache variable name and key_buffer_size
# is the cache component.
#
# See STRUCTURED SYSTEM VARIABLES for more info, in regards to syntax used for structured key cache system vars.
#
# By default, table indexes are assigned to the main (default) key cache created at the server startup.
# When a key cache is destroyed, all indexes assigned to it are reassigned to the default key cache.
#
# For a busy server, you can use a strategy that involves three key caches:
#
# 		) A "hot" key cache that takes up 20% of the space allocated for all key caches. Use this for tables that are heavily used for searches but that are not updated.
#
# 		) A "cold" key cache that takes up 20% of the space allocated for all key caches. Use this cache for medium-sized, intensively modified tables, such as temporary tables.
#
# 		) A "warm" key cache that takes up 60% of the key cache space. Employ this as the default key cache, to be used by default for all other tables.
#
# One reason the use of three key caches is beneficial is that access to one key cache structure does not access to the others.
#
# Statements that access tables assigned to one cache do not compete with statements that access tables assigned to
# another cache.
#
# Performance gains occur for other reasons as well:
#
# 		) The hot cache is used only for retrieval queries, so its contents are never modified.
#
# 			Consequently, whenever an index block needs to be pulled in from disk, the 
# 			contents of the cache block chosen for replacement need not be flushed first.
#
# 		) For an index assigned to the hot cache, if there are no queries requiring an index scan,
# 			there is a high probability that the index blocks corresponding to nonleaf nodes of the
# 			index B-Tree remain in the cache.
#
# 		) An update operation most frequently executed for temporary tables is performed much faster
# 			when the updated node is in the cache and need not be read in from a disk first.
#
# 			If the size of the indexes of the temporary tables are comparable with the size of cold key cache,
# 			the probability is very high that the updated node is in the cache.
#
# The CACHE_INDEX statement sets up an association between a table and a key cache, but the association
# is lost each time the server restarts.
#
# If you want the association to take effect each time the server starts, one way to accomplish this is to
# use an option file:
#
# 		Include variable settings that configure your key caches, and an init-file option that names
# 		a file containing CACHE_INDEX statements to be executed.
#
# 		For example:
#
# 		key_buffer_size = 4G
# 		hot_cache.key_buffer_size = 2G
# 		cold_cache.key_buffer_size = 2G
# 		init_file=/path/to/data-directory/mysqld_init.sql
#
# The statements in mysqld_init.sql are executed each time the server starts.
#
# The file should contain one SQL statement per line.
# The following example assigns several tables each to hot_cache and cold_cache:
#
# 		CACHE INDEX db1.t1, db1.t2, db2.t3 IN hot_cache
# 		CACHE INDEX db1.t4, db2.t5, db2.t6 IN cold_cache
#
# MIDPOINT INSERTION STRATEGY
#
# By default, the key cache management system uses a simple LRU strategy for choosing key
# cache blocks to be evicted, but it also supports a more sophisticated method called the midpoint
# insertion strategy.
#
# When using the midpoint insertion strategy, the LRU chain is divided into two parts:
#
# 		a hot sublist and a warm sublist.
#
# The division point between two parts is not fixed, but the key cache management system
# takes care that the warm part is not "too short", always containing at least key_cache_division_limit percent
# of the key cache blocks.
#
# key_cache_division_limit is a component of structured key cache variables, so its value is a parameter
# that can be set per cache.
#
# When an index block is read from a table into the key cache, it is placed at the end of the warm sublist.
#
# After a certain number of hits (accesses of the block), it is promoted to the hot sublist.
#
# At present, the number of hits required to promote a block (3) is the same for all index blocks.
#
# A block promoted into the hot sublist is placed at the end of the list.
#
# The block then circulates within this sublist. IF the block stays at the beginning of the sublist
# for a long enough time, it is demoted to the warm sublist.
#
# This time is determined by the value of the key_cache_age_threshold component of the key cache.
#
# The threshold value perscribes that, for a key cache containing N blocks, the block at the beginning
# of the hot sublist not accessed within the last N * key_cache_age_threshold / 100 hits is to be moved
# to the beginning of the warm sublist.
#
# The midpoint insertion strategy enables you to keep more-valued blocks away in the  cache.
#
# If you prefer to use the plain LRU strategy, leave the key_cache_division_limit value set
# to its default of 100.
#
# The midpoint insertion strategy helps to improve performance when execution of a query that requires
# an index scan effectively pushes out of the cache all the index blocks corresponding to valuable
# high-level B-tree nodes.
#
# To avoid this, you must use a midpoint insertion strategy with the key_cache_division_limit set to much
# less than 100.
#
# Then valuable frequently hit nodes are preserved in teh hot sublist during an index scan operation as well.
#
# INDEX PRELOADING
#
# If there are enough blocks in a key cache to hold blocks of an entire index, or at least the blocks corresponding
# to its nonleaf nodes, it makes sense to preload the key cache with index blocks before starting to use it.
#
# Preloading enables you to put the table index blocks into a key cache buffer in teh most efficient way:
# 
# By reading the index blocks from disk sequentially.
#
# Without preloading, the blocks are still placed into the key cache as needed by queries.
#
# Although the blocks will stay in the cache, because there are enough buffers for all of them,
# they are fetched from disk in random order, and not sequentially.
#
# To preload an index into a cache, use the LOAD_INDEX_INTO_CACHE statement.
#
# For example, the following statement preloads nodes (index blocks) of indexes of the tables
# t1 and t2:
#
# 		LOAD INDEX INTO CACHE t1, t2 IGNORE LEAVES;
# 		+-----------+--------------+----------+------------+
# 		| Table 	   | Op 		  		| Msg_type | Msg_text   |
# 		+-----------+--------------+----------+------------+
# 		| test.t1 	| preload_keys | status   | OK 		   |
# 		| test.t2 	| preload_keys | status   | OK 			|
# 		+-----------+--------------+----------+------------+
#
# The IGNORE LEAVES modifier causes only blocks for the nonlead nodes of the index to be preloaded.
#
# Thus, the statement shown preloads all index blocks from t1, but only blocks for the nonleaf
# nodes from t2.
#
# If an index has been assigned to a key cache using a CACHE_INDEX statement, preloading places
# index blocks into that cache.
#
# Otherwise, the index is loaded into the default key cache.
#
# KEY CACHE BLOCK SIZE
#
# It is possible to specify the size of the block buffers for an individual key cache using
# the key_cache_block_size variable.
#
# This permits tuning of the performance of I/O operations for index files.
#
# The best performance for I/O operations is achieved when the size of read buffers
# is equal to the size of the native operating system I/O buffers.
#
# But setting the size of key nodes equal to the size of the I/O buffer does not always
# ensure the best overall performance.
#
# When reading the big leaf nodes, the server pulls in a lot of unecessary data, effectively
# preventing reading other leaf nodes.
#
# To control the size of blocks in the .MYI index file of MyISAM tables, use the --myisam-block-size
# option at server startup.
#
# RESTRUCTURING A KEY CACHE
#
# A key cache can be restructured at any time by updating its parameter values.
# for example:
#
# 		SET GLOBAL cold_cache.key_buffer_size=4*1024*1024;
#
# If you assign to either the key_buffer_size or key_cache_block_size key cache component 
# a value that differs from the component's current value, the server destroys the cache's old structure
# and creates a new one based on the new values.
#
# If the cache contains any dirty blocks, the server saves them to disk before destroying and 
# re-creating the cache.
#
# Restructuring does not occur if you change other key cache parameters.
#
# When restructuring a key cache, the server first flushes the contents of any dirty buffers to disk.
#
# After that, the cache contents become unavailable. However, restructuring does not
# block queries that need to use indexes assigned to the cache.
#
# INstead, the server directly accesses the table indexes using native file system caching.
#
# File system caching is not as efficient as using a key cache, so although queries execute,
# a slowdown can be anticipated.
#
# After the cache has been restructured, it becomes available again for caching indexes assigned
# to it, and the use of file system  caching for the indexes ceases.
#
# CACHING OF PREPARED STATEMENTS AND STORED PROGRAMS
#
# For certain statements that a client might execute multiple times during a session, the server converts
# the statement to an internal structure and caches that structure to be used during execution.
#
# Caching enables the server to perform more efficiently because it avoids the overhead of reconverting
# the statement should it be needed again during the session.
#
# Conversion and caching occurs for these statements:
#
# 		) Prepared statements, both those processed at the SQL level (using the PREPARE statement) and those
# 			processed using the binary client/server protocol (using the mysql_stmt_prepare() C API function)
#
# 			The max_prepared_stmt_count system variable controls the total number of statements the server caches.
#
# 			(The sum of the number of prepared statements across all sessions)
#
# 		) Stored programs (stored procedures and functions, triggers, and events).
#
# 			In this case, teh server converts and caches the entire program body.
#
# 			The stored_program_cache system variable indicates the approximate number of stored
# 			programs the server caches per session.
#
# The server maintains caches for prepared statements and stored programs on a per-session basis.
#
# Statements cached for one session are not accessible to other sessions. When a session ends,
# the server discards any statements cached for it.
#
# When the server uses a cached internal statement structure, it must take care taht the structure does not
# go out of date.
#
# Metadata changes can occur for an object used by the statement, causing a mismatch between the current
# object definition and the definition as represented in the internal statement structure.
#
# Metadata changes occur for DDL statements such as those that create drop, alter, rename or truncate tables,
# or that analyze, optimize or repair tables.
#
# Table content changes (for example, with INSERT or UPDATE) do not change metadata, nor do SELECT statements.
#
# Here is an illustration of the problem, Suppose that a client prepares this statement:
#
# 		PREPARE s1 FROM 'SELECT * FROM t1';
#
# The SELECT * expands in teh internal structure to the list of columns in the table.
#
# If the set of columns in the table is modified with ALTER TABLE, the prepared statement goes otu of date.
#
# If the server does not detect this change the next time the client executes s1, the prepared statement returns incorrect results.
#
# To avoid problems caused by metadata changes to tables or views referred to by the prepared statement, the server
# detects these changes and automatically prepares the statement when it is next executed.
#
# That is, the server reparses the statement and rebuilds the internal structure.
#
# Reparsing also occurs after referenced tables or views are flushed from the table definition cache,
# either implicitly to make room for new entries in the cache, or explicitly due to FLUSH_TABLES.
#
# Similarly, if changes occur to objects used by a stored program, the server reparses affected statements
# within the program.
#
# The server also detects metadata changes for objects in expressions. These might be used in statements specific
# to stored programs, such as DECLARE CURSOR or flow-control statements such as IF, CASE, and RETURN.
#
# To avoid reparsing entire stored programs, the server reparses affected statements or expressions within a program
# 	only as needed.
#
# 	Examples:
#
# 		) Suppose that metadata for a table or view is changed. Reparsing occurs for a SELECT * that accesses the table or view,
# 			but not for a SELECT * that does not access the table or view.
#
# 		) When a statement is affected, the server reparses it only partially if possible. Consider this CASE statement:
#
# 			CASE case_expr 
# 				WHEN when_expr1 ---
# 				WHEN when_expr2 ---
# 				WHEN when_expr3 ---
# 				---
# 			END CASE
#
# 		If a metadata change affects only WHEN when_expr3, that expression is reparsed.
# 		case_expr and the other WHEN expressions are not reparsed.
#
# Reparsing uses the default DB and SQL mode that were in effect for the original conversion to internal form.
#
# The server attempts reparsing up to three times. An error occurs if all attempts fail.
#
# Reparsing is automatic, but to the extent that it occurs, diminishes prepared statements and stored program
# performance.
#
# For prepared statements, the Com_stmt_reprepare status variable tracks the number of repreparations.
#
# OPTIMIZING LOCKING OPERATIONS
#
# MySQL manages contention for table contents using locking:
#
# 		) Internal locking is performed within the MySQL server itself to manage contention for table contents by multiple threads.
#
# 			This type of locking is internal because it is performed entirely by the server, and involves no other programs.
#
# 			See INTERNAL LOCKING METHODS, later.
#
# 		) External locking occurs when the server and other programs lock MyISAM table files to coordinate among themselves
# 			which program can access the tables at which time.
#
# 			See EXTERNAL LOCKING, later.
#
# INTERNAL LOCKING METHODS
#
# This section discusses internal locking; that is, locking performed within the MySQL server itself to manage
# contention for table contents by multiple sessions.
#
# This type of locking is internal because it is performed entirely by the server and involves no other programs.
#
# For locking performed on MYSQL files by other programs, see EXTERNAL LOCKING.
#
# 		) Row-level Locking
#
# 		) Table-Level Locking
#
# 		) Choosing the Type of Locking
#
# ROW-LEVEL LOCKING
#
# MySQL uses row-level locking for InnoDB tables to support simultaneous write access by multiple sessions,
# making them suitable for multi-user, highly concurrent and OLTP applications.
#
# To avoid deadlocks when performing multiple concurrent write operations on a single InnoDB tables,
# acquire necessary locks at the start of the transaction by issuing a SELECT --- FOR UPDATE statement
# for each group of rows expected to be modified, even if the data changes come later in teh transaction.
#
# If transactions modify or lock more than one table, issue the applicable statements in the same order
# within each transaction.
#
# Deadlocks affect performance rather than representing a serious error, because InnoDB automatically detects
# deadlock conditions by default and rolls back one of the affected transactions.
#
# On high concurrency systems, deadlock detection can cause a slowdown when numerous threads wait for the same lock.
#
# At times, it may be more efficient to disable deadlock detection and rely on the innodb_lock_wait_timeout setting
# for transaction rollback when a deadlock occurs.
#
# Deadlock detection can be disabled using the innodb_deadlock_detect configuration option.
#
# Advantages of row-level locking:
#
# 		) Fewer lock conflicts when different sessions access different rows.
#
# 		) Fewer changes for rollbacks.
#
# 		) Possible to lock a single row for a long time
#
# TABLE-LEVEL LOCKING
#
# MySQL uses table-level locking for MyISAM, MEMORY and MERGE tables, permitting only one session to update
# those tables at a time.
#
# This locking level makes these storage engines more suitable for read-only, read-mostly or single-user applications.
#
# These storage engines avoid deadlocks by always requesting all needed locks at once at the beginning 
# of a query and always locking the tables in teh same order.
#
# The tradeoff is that this strategy reduces concurrency; other sessions that want to modify the table must wait
# until the current data change statement finishes.
#
# Advantages of table-level locking:
#
# 		) Relativily little memory required (row locking requires memory per row or group of rows locked)
#
# 		) Fast when used on a large part of the tables because only a single lock is involved.
#
# 		) Fast if you often do GROUP BY operations on a large part of the data or must scan the entire table frequently.
#
# MySQL grants table write locks as follows:
#
# 		1. If there are no locks on teh table, put a write lock on it.
#
# 		2. Otherwise, put the lock request in the write lock queue.
#
# MySQL grants table read locks as follows:
#
# 		1. If there are no write locks on the table, put a read lock on it.
#
# 		2. Otherwise, put the lock request in the read lock queue.
#
# Table updates are given higher priority than table retrievals.
#
# Therefore, when a lock is released, the lock is made available to the requests
# in the write lock queue and then to the requests in teh read lock queue.
#
# This ensures that updates to a table are not "starved" even when there is
# heavy SELECT activity for the table.
#
# However, if there are many updates for a table, SELECT statements wait until there
# are no more updates.
#
# For information on altering the priority of reads and writes, see TABLE LOCKING ISSUES.
#
# You can analyze the table lock contention on your system by checking the Table_locks_immediate
# and Table_locks_waited status variables, which indicate the number of times that
# requests for table locks could be granted immediately and the number that had to
# wait, respectively:
#
# 		SHOW STATUS LIKE 'Table%';
# 		+-------------------------------+----------+
# 		| Variable_name 					  |   Value  |
# 		+-------------------------------+----------+
# 		| Table_locks_immediate 		  | 1151552  |
# 		| Table_locks_waited 			  | 15324 	 |
# 		+-------------------------------+----------+
#
# The Performance Schema lock tables also provide locking information. See PERFORMANCE SCHEMA LOCK TABLES, later.
#
# The MyISAM storage engine supports concurrent inserts to reduce contention between readers and writers
# for a given table: 
#
# If a MyISAM table has no free blocks in the middle of hte data file, rows are always
# inserted at the end of the data file.
#
# In this case, you can freely mix concurrent INSERT and SELECT statements for a MyISAM table without locks.
#
# That is, you can insert rows into a MyISAM table at the same time other clients are reading from it.
#
# Holes can result from rows having been deleted from or updated in the middle of the table.
#
# if there are holes, concurrent inserts are disabled but are enabled again automatically when all
# holes have been filled with new data.
#
# To control this behavior, use the concurrent_insert system variable. See CONCURRENT INSERTS.
#
# If you acquire a table lock explicitly with LOCK_TABLES, you can request a READ LOCAL lock rather than
# a READ lock to enable other sessions to perform concurrent inserts while you have the table locked.
#
# To perform many INSERT and SELECT operations on a table t1 when concurrent inserts are not possible,
# you can insert rows into a temporary table temp_t1 and update the real table with the rows
# from the temporary table:
#
# 		LOCK TABLES t1 WRITE, temp_t1 WRITE;
# 		INSERT INTO t1 SELECT * FROM temp_t1;
# 		DELETE FROM temp_t1;
# 		UNLOCK TABLES;
#
# CHOOSING THE TYPE OF LOCKING
#
# Generally, table locks are superior to row-level locks in the following cases:
#
# 		) Most statements for the table are reads.
#
# 		) Statements for the table are a mix of reads and writes, where writes are updates or deletes for a single
# 			row that can be fetched with one key read:
#
# 			UPDATE tbl_name SET column=value WHERE unique_key_col=key_value;
# 			DELETE FROM tbl_name WHERE unique_key_col=key_value;
#
# 		) SELECT combined with concurrent INSERT statements, and very few UPDATE or DELETE statements.
#
# 		) Many scans or GROUP BY operations on the entire table without any writers.
#
# With higher-level locks, you can more easily tune applications by supporting locks of different types,
# because the lock overhead is less than for row-level locks.
#
# Options other than row-level locking:
#
# 		) Versioning (Such as that used in MySQL for concurrent inserts) where it is possible to have one writer at the same time
# 			as many readers.
#
# 			This means that the database or table supports different views for the data depending on when access begins.
#
# 			Other common terms for this are "time travel", "copy on write", or "copy on demand"
#
# 		) Copy on demand is in many cases superior to row-level locking. However, in the worst case - it can use much more memory
# 			than using normal locks.
#
# 		) Instead of using row-level locks, you can employ application-level locks, such as those provided by
# 			GET_LOCK() and RELEASE_LOCK() in MySQL.
#
# 			These are advisory locks, so they work only with applications that cooperate with each other.
#
# 			See more, under LOCKING FUNCTIONS.
#
# TABLE LOCKING ISSUES
#
# InnoDB tables use row-level locking so that multiple sessions and applications can read from and
# write to the same table simultaneously, without making each other wait or producing inconsistent results.
#
# For this storage engine, avoid using the LOCK_TABLES statement, because it does not offer any extra
# protection, but instead reduces concurrency.
#
# The automatic row-level locking makes these tables suitable for your busiest database with your most
# important data, whilst also simplifying application logic since you do not need to lock and unlock tables.
#
# Consequently, the InnoDB storage engine is the default in MySQL.
#
# MySQL uses table locking (instead of page, row or column locking) for all storage engines except InnoDB.
#
# The locking operations themselves do not have much overhead. But because only one session can write to a table
# at any one time, for best performance with these other storage engines, use them primarily for tables that
# are queried often and rarely inserted into or updated.
#
# PERFORMANCE CONSIDERATIONS FAVORING InnoDB
#
# When choosing whether to create a table using InnoDB or a different storage engine, keep in mind
# the following disadvantages of table locking:
#
# 		) Table locking enables many sessions to read from a table at the same time, but if a session
# 			wants to write to a table, it must first get exclusive access, meaning it might have to
# 			wait for other sessions to finish with the table first.
#
# 			During the update, all other sessions that want to access this particular table must wait
# 			until the update is done.
#
# 		) Table locking causes problems when a session is waiting because the disk is full and free
# 			space needs to become available before the session can proceed.
#
# 			In this case, all sessions that want to access the problem table are also put in
# 			a waiting state until more disk space is made available.
#
# 		) A SELECT statement that takes a long time to run prevents other sessions from updating the table
# 			in the meantime, making the other sessions appear slow or unresponsive.
#
# 			While a session is waiting to get exclusive access to the table for updates, other sessions that
# 			issue SELECT statements will queue up behind it, reducing concurrency even for read-only sessions.
#
# WORKAROUNDS FOR LOCKING PERFORMANCE ISSUES
#
# The following items describe some ways to avoid or reduce contention caused by table locking:
#
# 		) Consider switching the table to the InnoDB storage engine, either using CREATE TABLE --- ENGINE=INNODB
# 			during setup, or using ALTER TABLE --- ENGINE=INNODB for an existing table.
#
# 			See THE INNODB STORAGE ENGINE for more details about this storage engine.
#
# 		) Optimize SELECT statements to run faster so that they lock tables for a shorter time.
#
# 			You might have to create some summary tables to do this.
#
# 		) Start mysqld with --low-priority-updates.
#
# 			 For storage engines that use only table-level locking (such as MyISAM, MEMORY and MERGE),
# 			 this gives all statements that update (modify) a table lower priority than SELECT statements.
#
# 			 In this case, the second SELECT statement in the preceding scenario would execute before
# 	   	 the UPDATE statement, and would not wait for the first SELECT To finish.
#
# 		) To specify that all updates issued in a specific connection should be done with low priority, set the low_priority_updates
# 			server system variable to 1.
#
# 		) To give a specific INSERT, UPDATE or DELETE statement lower priority, use the LOW_PRIORITY attribute.
#
# 		) To give a specific SELECT statement higher priority, use the HIGH_PRIORITY attribute. See SELECT SYNTAX for more info.
#
# 		) Start mysqld with a low value for the max_write_lock_count system variable to force MySQL to temporarily elevate
# 			the priority of all SELECT statements that are waiting for a table after a specific number of inserts to the table occur.
#
# 			THis permits READ locks after a certain number of WRITE locks.
#
# 		) If you have problems with INSERT combined with SELECT, consider switching to MyISAM tables, which support
# 			concurrent SELECT and INSERT statements. (see CONCURRENT INSERTS, for more info, later)
#
# 		) If you have problems with mixed SELECT and DELETE statements, the LIMIT option to DELETE may help. See more under, DELETE SYNTAX, later.
#
# 		) Using SQL_BUFFER_RESULT with SELECT statements can help to make the duration of the table locks shorter. See SELECT SYNTAX, later.
#
# 		) Splitting tables contents into separate tables may help, by allowing queries to run against columns in one table,
# 			while updates are confined to columns in a different table.
#
# 		) You could change the locking code in mysys/thr_lock.c to use a single queue. In this case, write locks and read locks would have
# 			the same priority, which might help some applications.
#
# CONCURRENT INSERTS
#
# The MyISAM storage engine supports concurrent inserts to reduce contention betwen readers and writers for a given table:
#
# If a MyISAM table has no holes in the data file (deleted rows in the middle), an INSERT statement can be executed to add
# rows to the end of the table at the same time that SELECT statements are reading rows from the table.
#
# If there are multiple INSERT statements, they are queued and performed in sequence, concurrently with the SELECT statements.
#
# The results of a concurrent INSERT may not be visible instantly.
#
# The concurrent_insert system variable can be set to modify the concurrent-insert processing.
#
# By default, the variable is set to AUTO (or 1) and concurrent inserts are handled as just described.
#
# If concurrent_insert is set to NEVER (or 0), concurrent inserts are disabled. If the variable is set to ALWAYS (or 2),
# concurrent inserts at the end of the table are permitted even for tables that have deleted rows.
#
# See also the description of the concurrent_insert system variable.
#
# If you are using the binary log, concurrent inserts are converted to normal inserts for CREATE --- SELECT
# or INSERT --- SELECT statements.
#
# This is done to ensure that you can re-create an exact copy of your tables by applying the log during a backup
# operation.
#
# See THE BINARY LOG, for more information.
#
# In addition, for those statements a read lock is placed on the selected-from table such that inserts
# into that table are blocked.
#
# The effect is that concurrent inserts for that table must wait as well.
#
# With LOAD_DATA_INFILE, if you specify CONCURRENT with a MyISAM table that satisfies the condition
# for concurrent inserts (taht is, it contains no free blocks in the middle), other sessions can retrieve
# data from the table while LOAD_DATA is executing.
#
# Use of the CONCURRENT option affects the performance of LOAD_DATA a bit, even if no other
# session is using the table at the same time.
#
# If you specify HIGH_PRIORITY, it overrides the effect of the --low-priority-updates option if the server
# was started with that option. It also causes concurrent inserts not to be used.
#
# For LOCK_TABLE, the difference between READ LOCAL and READ is that READ LOCAL permits nonconflicting INSERT
# statements (concurrent inserts) to execute while the lock is held.
#
# However, this cannot be used if you are going to manipulate the database using processes external to the 
# server while you hold the lock.
#
# METADATA LOCKING
#
# MySQL uses metadata locking to manage concurrent access to database objects and to ensure data consistency.
# Metadata locking applies not just to tables, but also to schemas, stored programs (procedures, functions, triggers and scheduled events)
# and tablespaces.
#
# The Performance Schema metadata_locks table exposes metadata lock information, which can be useful for seeing
# which session hold locks, are blocked waiting for lock, and so forth.
#
# For details, see THE METADATA_LOCKS TABLE later.
#
# Metadata locking does involve some overhead, which increases as query volume increases.
#
# Metadata contention increases the more the multiple queries attempt ot access the same objects.
#
# Metadata locking is not a replacement for the table definition cache, and its mutexes and locks differ
# from the LOCK_open mutex. The following discussion provides some information about how metadata locking works.
#
# METADATA LOCK ACQUISITION
#
# If there are multiple waiters for a given lock, the highest-priority lock request is satisfied first, with
# an exception related to the max_write_lock_count system variable.
#
# Write lock requests have higher priority than read lock requests.
#
# However, if max_write_lock_count is set to some low value (say, 10), read lock requests may be preferred
# over pending write lock requests if the read lock requests have already been pqssed over in favor of 10 write
# lock requests.
#
# Normally, this behavior does not occur because max_write_lock_count by default has a very large value.
#
# Statements acquire metdata locks one by one, not simultaenously, and lock acquisition occurs in name order:
#
# 		) This RENAME TABLE statement renames tbla to something else, and renames tblc to tbla:
#
# 				RENAME TABLE tbla TO tbld, tblc TO tbla;
#
# 			The statement acquires metadata locks, in order, on tbla, tblc and tbld (because tbld follows tblc in name order).
#
# 		) This slightly different statement also renames tbla to something else, and renames tblc to tbla:
#
# 				RENAME TABLE tbla TO tblb, tblc TO tbla
#
# 			In this case, the statement acquires metadata locks in order, on tbla, tblb and tblc (because tblb precedes tblc in name order).
#
# Both statements acquire locks on tbla and tblc, in that order, but differ in whether the lock on the remaining table
# name is acquired before or after tblc.
#
# Metadata lock acquisition order can make a difference in operation outcome when multiple transactions execute concurrently,
# as the following example illustrates.
#
# Begin with two tables x and x_new that have identical structure. Three clients issue statements that involve these tables:
#
# 		Client 1:
#
# 			LOCK TABLE x WRITE, x_new WRITE;
#
# 		The statement requests and acquires write locks in name order on x and x_new
#
# 		Client 2:
#
# 			INSERT INTO x VALUES(1);
#
# 		The statement requests and blocks waiting for a write lock on x.
#
# 		Client 3:
#
# 			RENAME TABLE x TO x_old, x_new TO x;
#
# 		The statement requests exclusive locks in name order on x, x_new and x_old but blocks waiting for the lock on x.
#
# 		Client 1:
#
# 			UNLOCK TABLES
#
# The staetment releases the write locks on x and x_new. 
#
# The exclusive lock request for x by Client 3 has higher priority than the write lock request by Client 2,
# so Client 3 acquires its lock on x, then also on x_new and x_old, performs the renaming, and releases its locks.
#
# Client 2 then acquires its lock on x, performs the insert and releases its lock.
#
# Lock acquisition order results in the RENAME_TABLE executing before the INSERT.
#
# The x into which the insert occurs is the table that was named x_new when Client 2
# issued the insert and was renamed to x by Client 3:
#
# 		SELECT * FROM x;
# 		+-----------------+
# 		| i 					|
# 		+-----------------+
# 		| 1 					|
# 		+-----------------+
#
# 		SELECT * FROM x_old;
# 		Empty set (0.01 sec)
#
# Now begin instead with tables named x and new_x that have identical structure.
# Again, three clients issue statements that involve these tables:
#
# 		Client 1:
#
# 			LOCK TABLE x WRITE, new_x WRITE;
#
# 		The statement requests and acquires write locks in name order on new_x and x.
#
# 		Client 2:
#
# 			INSERT INTO x VALUES(1);
#
# 		The statement requests and blocks waiting for a write lock on x.
#
# 		Client 3:
#
# 			RENAME TABLE x TO old_x, new_x TO x;
#
# 		The statement requests exclusive locks in name order on new_x, old_x and x, but blocks waiting
# 		for the lock on new_x.
#
# 		Client 1:
#
# 		UNLOCK TABLES;
#
# The statements releases the write locks on x and new_x.
#
# FOr x, the only pending request is by Client 2, so CLient 2 acquires its lock,
# performs the insert and releases the lock.
#
# FOr new_x, the only pending request is by Client 3, which is permitted to acquire that lock
# (and also the lock on old_x).
#
# The rename operation still blocks for the lock on x until the Client 2 insert finishes and releases
# its lock.
#
# Then client 3 acquires the lock on X, performs the rename, and releases its lock.
#
# In this case, lock acquisition order results in the INSERT executing before the RENAME_TABLE.
# The x into which the insert occurs is the original x, now renamed old_x by the rename operation:
#
# SELECT * FROM x;
# Empty set (0.01 sec)
#
# SELECT * FROM old_x;
# +----------+
# | i 		 |
# +----------+
# | 1 		 |
# +----------+
#
# If order of lock acquisition in concurrent statements makes a difference to an application
# in operation outcome, as in the preceding example, you may be able to adjust the table names
# to affect the order of lock acquisition.
#
# Metadata locks are extended, as necessary, to tables by a foreign key constraint to prevent conflicting
# DML and DDL operations from executing concurrently on the related tables.
#
# When updating a parent table,, a metadata lock is taken on the child table while updating foreign key
# metadata.
#
# Foreign key metadata is owned by the child table.
#
# METADATA LOCK RELEASE
#
# To ensure transaction serializability, the server must not permit one session to perform a data
# definition language (DDL) statement on a table that is used in an uncompleted explicitly or implicitly
# started transaction in another session.
#
# The server achieves this by acquiring metadata locks on tables used within a transaction and
# deferring release of those locks until the transaction ends.
#
# A metadata lock on a table prevents changes to the table's structure.
#
# This locking approach has the implication that a table that is being used by a transaction
# within one session cannot be used in DDL statements by other sessions until the transaction ends.
#
# This principle applies not only to transactional tables, but also to nontransactional tables.
#
# Suppose that a session begins a transaction that uses transactional table t and nontransactional
# table nt as follows:
#
# 		START TRANSACTION;
# 		SELECT * FROM t;
# 		SELECT * FROM nt;
#
# The server holds metadata locks on both t and nt until the transaction ends.
#
# If another session attempts a DDL or write lock operation on either table,
# it blocks unitl metadata lock releases at transaciton end.
#
# For example, a second session blocks if it attempts any of these operations:
#
# 		DROP TABLE t;
# 		ALTER TABLE t ---;
# 		DROP TABLE nt;
# 		ALTER TABLE nt ---;
# 		LOCK TABLE t --- WRITE;
#
# The same behavior applies for the LOCK_TABLES_---_READ.
#
# That is, explicitly or implicitly started transactions that update any table 
# (transactional or nontransactional) will block and be blocked by LOCK TABLES --- READ for taht table.
#
# If the server acquires metadata locks for a statement that is syntatically valid but fails during execution,
# it does not release the locks early.
#
# Lock release is still deferred to the end of the transaction because the failed statement is written to the 
# binary log and locks protect log consistency.
#
# In autocommit mode, each statement is in effect a complete transaction, so metadata locks acquired for the
# statement are held only to the end of the statement.
#
# Metadata locks acquired during a PREPARE statement are releasesed once the statement has been prepared, even if
# preparation occurs within a multiple-statement transaction.
#
# As of MySQL 8.0.13, for XA transactions in PREPARED state, metadata locks are maintained across client disconnects
# and server restarts, until XA_COMMIT or XA_ROLLBACK is executed.
#
# EXTERNAL LOCKING
#
# External locking is the use of file system locking to manage contention for MyISAM database tables by multiple processes.
#
# External locking is used in situations where a single process such as the MySQL server cannot be assumed to be hte
# only process that requires access to tables.
#
# Here are some examples:
#
# 		) If you run multiple servers that use the same DB directory (not recommended), each server must have external locking enabled.
#
# 		) If you use myisamchk to perform table maintenance operations on MyISAM tables, you must either ensure that hte sever
# 			is not running, or that hte server has external locking enabled so that it locks table files as necessary to coordinate with 
# 			myisamchk for access to the tables.
#
# 			The same is true for use of myisampack to pack MyISAM tables.
#
# 			If the server is run with external locking enabled, you can use myisamchk at any time for read operations
# 			such as checking tables.
#
# 			In this case, if the server tries to update a table that myisamchk is using, the server will wait for myisamchk to finish
# 			before it continues.
#
# 			If you use myisamchk for write operations such as repairing or optimizing tables, or if you use myisampack to pack tables,
# 			you must always ensure that hte mysqld server is not using the table.
#
# 			If you do not stop mysqld, at least do a mysqladmin flush-tables before you run myisamchk.
#
# 			Your tables MAY BECOME CORRUPTED if the server and myisamchk access the tables simultaneously.
#
# With external locking in effect, each process that requires access to a table acquires a file system lock
# for the table files before proceeding to access the table.
#
# If all necessary locks cannot be acquired, the process is blocked from accessing the table until the locks
# can be obtained (after the process that currently holds the locks release them)
#
# Exernal locking affects server performance because the server must sometimes wait for other proceses before it can
# access tables.
#
# External locking is unecessary if you run a single server to access a given data directory (which is the usual case),
# and if no other programs such as mysaicmhk need to modify tables while the server is running.
#
# If you only READ tables with other programs, external locking is not required, although myisamchk might report warnings
# if the server changes tables while myisamchk is reading them.
#
# With external locking disabled, to use myisamchk, you must either stop the server while myisamchk or else lock and
# flush the tables before running myisamchk.
#
# (SEe SYSTEM FACTORS, later)
#
# To avoid this requirement, use the CHECK_TABLE and REPAIR_TABLE staements to check and repair myISAM tables.
#
# For mysqld, external locking is controlled by the value of the skip_external_locking system variable.
#
# When this variable is enabled, external locking is disabled and vice versa.
#
# External locking is disabled by default.
#
# Use of external locking can be controlled at server startup by using the --external-locking or --skip-external-locking option.
#
# If you do use external locking option to enable updates to MyISAM tables from many MySQL processes,
# do not start the server with the --delay-key-write=ALL option or use the DELAY_KEY_WRITE=1 table option
# for any shared tables.
#
# Otherwise, index corruption can occur.
#
# The easiest way to satisfy this condition is to always use --external-locking together with --delay-key-write=OFF.
# (This is not done by default because in many setups it is useful to have a mixture of the preceding options)
#
# OPTIMIZING THE MYSQL SERVER
#
# This section discusses optimization techniques for the database server, primarily dealing with
# system configuration rather than tuning SQL statements.
#
# The information in this section is appropriate for DBAs who want ot ensure perofrmance and scalability
# across the servers they manage; for devs constructing installation scripts that include setting up
# the DB.
#
# And people running MySQL themselves for development, testing and so on, who want to mqximize their own productivity.
#
# OPTIMIZING DISK I/O
#
# This section describes ways to configure storage devices when you can devote more and faster storage hardware to the DB server.
#   
# For information about optimizing an InnoDB configuration to improve I/O performance, see OPTIMIZING INNODB DISK I/O
#
#	 ) Disk seeks are a huge performance bottleneck.
# 
# 		This problem becomes more apparent when the amount of data starts to grow so large that effective caching
# 		becomes impossible.
#
# 		For large DBs where you access mroe or less randomly,m you can be sure that oyu need at least one disk seek
# 		to read and a couple of disk seeks to write things.
#
# 		To minimize this problem, use disks with low seek times.
#
# 	) iNcrease the number of available disk spindles (and thereby reduce the seek overhead) by either symlinking files to different
# 		disks or striping the disks:
#
# 			) Using symbolic links
#
# 				This means that, for MyISAM tables, you symlink the index file and data files from their usual location
# 				in teh data directory to another disk (that may also be striped)
#
# 				This makes both the seek and read times better, assuming that hte disk is not used for otherp urposes as well.
#
# 				See more, under USING SYMBOLIC LINKS, later.
#
# 				Symbolic links are not supported for use with InnoDB tables. However, it is possible to place InnoDB
# 				data and log files on different physical disks.
#
# 				For more information, see OPTIMIZING INNODB DISK I/O, earlier.
#
# 			) Striping
#
# 				Striping means that you have many disks and put the first block on the first disk, second block on the second disk,
# 				and the N-th block on the N-th disk (N % number_of_disks) disk, and so on.
#
# 				This means if your normal data size is less than the stripe size (or pefectly aligned), you get much better performance.
#
# 				Striping is very dependant on operating system and the stripe size, so benchmark your application with different stripe sizes.
#
# 				See USING YOUR OWN BENCHMARKS later.
#
# 				The speed difference for striping is very dependant on the parameters.
#
# 				Depending on how you set the striping parameters and number of disks, you may get
# 				differences measured in orders of magnitude.
#
# 				You have to choose to optimize for random or sequential access.
#
# 		) For reliability, you may want to use RAID 0+1 (striping plus mirroring), but in this case, you need 2 x N drives
# 			of data.
#
# 			This is probably the best option if you have the money for it.
#
# 			However, you may get some volume-management software to handle it effectively.
#
# 		) A good option is to vary the RAID level according to how critical a type of data is.
#
# 			For example, store semi-important data that can be regenerated on a RAID 0 disk, but
# 			store really important data such as host information and logs on a RAID 0+1 or RAID N disk.
#
# 			RAID N can be a problem if you have many writes, due to the time required to update the parity bits.
#
# 		) You can also set the parameters for the file system that the database uses:
#
# 			If you do not need to know when files were last accessed (which is not really useful on a database server),
# 			you can mount your file systems with the -o noatime option.
#
# 			That skips updates to the last access time in inodes on the file system, which avoids some disk seeks.
#
# 			On many operating systems, you can set a file system to be updated asynchronously by mounting it with
# 			the -o async option.
#
# 			If  your computer is reasonably stable, this should give you better performance without sacrificing too much
# 			reliability (This flag is on by default on Linux)
#
# USING NFS WITH MYSQL
#
# Caution is advised when considering using NFS with MySQL. Potential issues, which vary by operating system and NFS
# version, include:
#
# 		) MySQL data and log files placed on NFS volumes becoming locked and unavailable for use.
#
# 			Locking issues may occur in cases where multiple instances of MySQL access the same data directory or where
# 			MySQL is shut down improperly due to a power outage, for example.
#
# 			NFS version 4 addresses underlying locking issues with the introduction of advisory and lease-based locking.
# 			However, sharing a data directory among MySQL instances is not recommended.
#
# 		) Data inconsistencies introduced due to messages received out of order or lost network traffic.
#
# 			To avoid this issue, use TCP with hard and intr mount options.
#
# 		) Maximum file size limitations. NFS Version 2 clients can only access the lowest 2GB of a file (signed 32 bit offset).
# 			NFS version 3 clients support larger files (up to 64 bit offsets). 
#
# 			The maximum supported file size also depends on the local file system of the NFS server.
#
# Using NFS within a professional SAN environment or other storage system tends to offer greater reliability
# than using NFS outside of such an environment.
#
# However, NFS within a SAN environment may be slower than directly attached or bus-attached non-rotational storage.
#
# If you choose to use NFS, NFS Version 4 or later is recommended, as is testing your NFS setup
# thoroughly before deploying into a production environment.
#
# USING SYMBOLIC LINKS
#
# You can move databases or tables from the database directory to other locations and replace them with
# symbolic links to the new locations.
#
# You might want to do this, for example, to move a database to a file system with more free space or increase
# the speed of your system by spreading your tables to different disks.
#
# For InnoDB tables, using the DATA DIRECTORY clause on the CREATE_TABLE statement instead of symbolic links,
# as explained in CREATING A TABLESPACE OUTSIDE OF THE DATA DIRECTORY.
#
# This new feature is a supported, cross-platform technique.
#
# The recommended way to do this is to symlink entire database directories to a different disk.
#
# Symlink MyISAM tables only as a last resort only.
#
# To determine the location of your data directory, use this statement:
#
# 		SHOW VARIABLE LIKE 'datadir';
#
# USING SYMBOLIC LINKS FOR DATABASES ON UNIX
#
# On Unix, the way to symlink a database is first to create a directory on some disk where
# you have free space and then to create a soft link to it from the MySQL data directory.
#
# 		mkdir /dr1/databases/test
# 		ln -s /dr1/databases/test /path/to/datadir
#
# MySQL does not support linking one directory to multiple databases.
#
# Replacing a database directory with a symbolic link works as long as you do not make a symbolic link
# between databases.
#
# Suppose that you have a database db1 under the MySQL data directory, and then make a symlink db2 that
# points to db1:
#
# 		cd /path/to/datadir
# 		ln -s db1 db2
#
# The result is that, for any table tbl_a in db1, there also appears to be a table tbl_a in db2.
#
# If one client updates db1.tbl_a and another client updates db2.tbl_a, problems may occur.
#
# USING SYMBOLIC LINKS FOR MYISAM TABLES ON UNIX
#
# Note:
#
# 		Symbolic link supports as described here, along with the --symbolic-links option that controls it,
# 		is deprecated and will be removed in a future version of MySQL.
#
# 		In addition, the option is disabled by default.
#
# Symlinks are fully supported only for MyISAM tables.
#
# For files used by tables for other storage engines, you may get strange problems if you try to use
# symbolic links.
#
# For InnoDB tables, use the alternative technique explained in CREATING A TABLESPACE OUTSIDE OF THE DATA DIRECTORY instead.
#
# Do not use symlink tables on systems that do not have a fully operational realpath() call.
# (Linux and Solaris support realpath())
#
# To determine whether your system supports symbolic links, check the value of the have_symlink system variable
# using this statement:
#
# 		SHOW VARIABLES LIKE 'have_symlink';
#
# The handling of symbolic links for MyISAM tables works as follows:
#
# 		) In the data directory, you always have the data (.MYD) file and the index (.MYI) file.
# 			The data file and index file can be moved elsewhere and replaced in the data directory by symlinks.
#
# 		) You can symlink the data file and the index file independently to different directories.
#
# 		) To instruct a running MySQL server to perform the symlinking, use the DATA DIRECTORY and INDEX DIRECTORY
# 			options to CREATE_TABLE.
#
# 			See CREATE TABLE SYNTAX later.
#
# 			Alternatively, if mysqld is not running, symlinking can be accomplished manually using ln -s from the cmd line.
#
# 			NOTE:
#
# 				The path used with either or both of the DATA DIRECTORY and INDEX DIRECTORY options may not include the
# 				MySQL data directory. (Bug #32167)
#
# 		) myisamchk does not replace a symlink with the data file or index file.
#
# 			It works directly on the file to which the symlink points.
#
# 			Any temporary files are created in the directory where the data file or index file is located.
#
# 			The same is true for the ALTER_TABLE, OPTIMIZE_TABLE and REPAIR_TABLE statements.
#
# 			NOTE:
#
# 				When you drop a table that is using symlinks, both the symlink and the file to which the symlink points are dropped.
# 				This is an extremely good reason not to run mysqld as the system root or permit system users to have write access
# 				to the MySQL database directories.
#
# 		) If you rename a table with ALTER_TABLE_---_RENAME or RENAME_TABLE and you do not move the table to anotehr database,
# 		the symlinks in the database directory are renamed to teh new names and teh data file and index file are renamed accordingly.
#
# 		) If you use ALTER_TABLE_---_RENAME or RENAME_TABLE to move a table to another database, the table is moved to the other
# 			database directory.
#
# 			If the table name changed, the symlinks in the new database directory are renamed to the new names and the data file
# 			and index files are renamed accordingly.
#
# 		) If you are not using symlinks, start mysqld with the --skip-symbolic-links option to ensure that no one can use
# 			mysqld to drop or rename a file outside of the data directory.
#
# These table symlink operations are not supported:
#
# 		) ALTER_TABLE ignores the DATA DIRECTORY and INDEX DIRECTORY table options.
#
# USING SYMBOLIC LINKS FOR DATABASES ON WINDOWS
#
# On Windows, symbolic links can be used for database directories.
#
# This enables you to put a database directory at a different location (for example,
# on a different disk) by setting up a symbolic link to it.
#
# Use of database symlinks on Windows is similar to their use on Unix, although the procedure
# for setting up the link differs.
#
# Suppose that you want to place the database directory for a database named mydb at D:\data\mydb
#
# To do this, create a symbolic link in the MySQL data directory that points to D:\data\mydb
#
# However, before creating the symbolic link, make sure that the D:\data\mydb directory exists
# by creating it if necessary.
#
# If you already have a database directory named mydb in the data directory, move it to D:\data
#
# Otherwise, the symbolic link will be ineffective.
#
# To avoid problems, make sure that hte server is not running when you move teh database directory.
#
# On Windows, you can create a symlink using the mklink command. This command requires admin privs.
#
# 1. Change location into the data directory:
#
# 			cd \path\to\datadir
#
# 2. In the data directory, create a symlink named mydb that points to the location of the database directory:
#
# 			mklink /d mydb D:\data\mydb
#
# After this, all tables created in teh database mydb are created in D:\data\mydb
#
# OPTIMIZING MEMORY USAGE
#
# HOW MYSQL USES MEMORY
#
# MySQL allocates buffers and caches to improve performance of database operations.
#
# The default configuration is designed to permit a MySQL server to start on a virtual machine
# that has approx 512 MB of RAM.
#
# You can improve MySQLs performance by increasing the values of certain cache and buffer-related
# system variables.
#
# You can also modify the default configuration to run MySQL on systems with limited memory.
#
# The following list describes some of the ways that MySQL uses memory. Where applicable, relevant
# system variables are referenced.
#
# Some items are storage engine or feature specific.
#
# 		) The InnoDB buffer pool is a memory area that holds cached InnoDB data for tables, indexes, and other
# 			auxiliary buffers.
#
# 			For efficiency of high-volume read operations, the buffer pool is divided into pages that can
# 			potentially hold multiple rows.
#
# 			For efficiency of cache management, the buffer pool is implemented as a linked list of pages;
# 			Data that is rarely used is aged out of the cache, using a variation of the LRU algorithm.
#
# 			For more info on this, see later under BUFFER POOL.
#
# 			The size of the buffer pool is important for system performance:
#
# 				) InnoDB allocates memory for the entire buffer pool at server startup, using malloc() operations.
#
# 					The innodb_buffer_pool_size system variable defines the buffer pool size.
#
# 					Typically, a recommended innodb_buffer_pool_size value is 50 to 75 percent of system memory.
#
# 					innodb_buffer_pool_size can be configured dynamically, while the server is running.
#
# 					For more information, see CONFIGURING INNODB BUFFER POOL SIZE
#
# 				) On systems with a large amount of memory, you can improve concurrency by dividing the buffer
# 					into multiple buffer pool instances.
#
# 					The innodb_buffer_pool_instances system variable defines the number of buffer pool instances.
#
# 				) A buffer pool that is too small may cause excessive churning as pages are flushed from the buffer pool
# 					only to be required again a short itme later.
#
# 				) A buffer pool that is too large may cause swapping due to competition for memory.
#
# 		) The storage engine interface enables the optimizer to provide information about the size of the
# 			record buffer to be used for scans that the optimizer estimates will read multiple rows.
#
# 			The buffer size can vary based on the size of the estimate.
#
# 			InnoDB uses this variable-size buffering capability to take advantage of row prefetching,
# 			and to reduce the overhead of latching and B-tree navigation.
#
# 		) All threads share the MyISAM key buffer. The key_buffer_size system variable determines its size.
#
# 			For each MyISAM table the server opens, the index file is opened once; the data file is opened
# 			once for each concurrently running thread that accesses the table.
#
# 			For each concurrent thread, a table structure, column structures for each column, and a buffer size
# 			of size 3 * N are allocated (where N is the maximum row length, not counting BLOB columns)
#
# 			A BLOB column requires five to eight bytes plus the length of the BLOB data.
#
# 			The MyISAM storage engine maintains one extra row buffer for internal use.
#
# 		) The myisam use mmap system variable can be set to 1 to enable memory-mapping for all MyISAM tables
#
# 		) If an internal in-memory temporary table becomes too large (as determined using the tmp_table_size and
# 			max_heap_table_size system variables), MySQL automatically converts the table from in-memory
# 			to on-disk format.
#
# 			On-disk temporary tables use the storage engine defined by the internal tmp disk storage engine system
# 			variable.
#
# 			You can increase the permissible temporary table size as described in INTERNAL TEMPORARY TABLE USE IN MYSQL
#
# 			For MEMORY tables explicitly created with CREATE_TABLE, only the max_heap_table_size system variables determines
# 			how large a table can grow, and there is no conversion to on-disk format.
#
# 		) The MySQL Performance Schema is a feature for monitoring MySQL server execution at a low level.
#
# 			The Performance Schema dynamically allocates memory incrementally, scaling its memory use to actual server load,
# 			instead of allocating required memory during server startup.
#
# 			Once memory is allocated, it is not freed until the server is restarted.
#
# 			For more information, see THE PERFORMANCE SCHEMA MEMORY-ALLOCATION MODEL
#
# 		) Each thread that hte server uses to manage client connections requires some thread-specific space.
#
# 			The following list indicates these and which system variables control their size:
#
# 				) A stack (Thread stack)
#
# 				) A connection buffer (net buffer length)
#
# 				) A result buffer (net buffer length)
#
# 			The connection buffer and result buffer each begin with a size equal to net_buffer_length bytes,
# 			but are dynamically enlarged up to max_allowed_packet byte as needed.
#
# 			The result buffer shrinks to net_buffer_length bytes after each SQL statement.
#
# 			While a statement is running, a copy of the current statement string is also allocated.
#
# 			Each connection thread uses memory for computing statement digests.
#
# 			The server allocates max_digest_length bytes per session.
#
# 			See PERFORMANCE SCHEMA STATEMENT DIGEST AND SAMPLING later, for more info.
#
# 		) All threads share the same base memory.
#
# 		) When a thread is no longer needed, the memory allocated to it is released and returned
# 			to the system unless the thread goes back into the thread cache.
#
# 			IN that case, the memory remains allocated.
#
# 		) Each request that performs a sequential scan of a table allocates a read buffer. The read_buffer_size
# 			System variable determines the buffer size.
#
# 		) When reading rows in an arbitrary sequence (for example, following a sort), a random-read buffer may be
# 			allocated to avoid disk seeks.
#
# 			The read_rnd_buffer_size system variable determines the buffer size.
#
# 		) All joins are executed in a single pass, and most joins can be done without even using a temporary table.
#
# 			Most temporary tables are memory-based hash tables.
#
# 			Temporary tables with a large row length (calculated as the sum of all column lengths) or that contain BLOB
# 			columns are stored on disk.
#
# 		) Most requests that perform a sort allocate a sort buffer and zero to two temporary files depending on
# 			the result size.
#
# 			WHERE MYSQL STORES TEMPORARY FILES
#
# 		) ALmost all parsing and calculating is done in thread-local and reusable memory pools.
#
# 			No memory overhead is needed for small items, thus avoiding the normal slow memory allocation
# 			and freeing.
#
# 			Memory is allocated only for unexpected large strings.
#
# 		) For each table having BLOB columns, a buffer is enlarged dynamically to read in larger BLOB
# 			values.
#
# 			If you scan a table, the buffer grows as large as the largest BLOB value.
#
# 		) MySQL requires memory and descriptors for the table cache.
#
# 			Handle structures for all in-use tables are saved in the table cache and managed
# 			as "First in, First out" (FIFO)
#
# 			The table_open_cache system variable defines the intial table cache size. See HOW MYSQL OPENS AND CLOSES TABLES.
#
# 			MySQL also requires memory for the table definition cache. The table_definition_cache system variables defines
# 			the number of  table definitions that can be stored in teh table definition cache.
#
# 			If you use a large number of tables, you can create a large table definition cache to speed up
# 			the opening of tables.
#
# 			The table definition cache takes less space and does not use file descriptors, unlike the table cache.
#
# 		) A FLUSH_TABLES statement or mysqladmin flush-tables command closes all tables that are not in use at once
# 			and marks all in-use tables to be closed when the currently executing thread finishes.
#
# 			This effectively frees most in-use memory.
#
# 			FLUSH_TABLES does not return until all tables have been closed.
#
# 		) The server caches information in memory as a result of GRANT, CREATE_USER, CREATE_SERVER and INSTALL_PLUGIN
# 			statements.
#
# 			This memory is not released by the corresponding REVOKE, DROP_USER, DROP_SERVER and UNINSTALL PLUGIN statements,
# 			so for a server that executes many instances of the statements that cause caching, there will be an increase
# 			in memory use.
#
# 			This cached memory can be freed with FLUSH_PRIVILEGES.
#
# 		) In a replication topology, the following settings affect memory usage, and can be adjusted as required:
#
# 				) The max_allowed_packet system variable on a replication master limits the maxium message size that
# 					the master sends to its slaves for processing.
#
# 					This setting defaults to 64M.
#
# 				) The slave_pending_jobs_size_max system variable on a multi-threaded slave sets the maximum amount of memory
# 					that is made available for holding messages awaiting processing.
#
# 					This setting defaults to 128M.
#
# 					The memory is only allocated when needed, but it might be used if your replication topology handles
# 					large transactions sometimes.
#
# 					It is a soft limit, and larger transactions can be processed.
#
# 				) The rpl_read_size system variable on a replication master or slave controls the minimum amount of data in
# 					bytes that is read from the binary log files and relay log files.
#
# 					THe default is 8192 bytes. A buffer the size of this value is allocated for each thread
# 					that reads from the binary log and relay log files, including dump threads on masters
# 					and coordinator threads on slaves.
#
# 				) THe binlog_transaction_dependency_history_size system variable limits the number of rows hashes
# 					held as in-memory history.
#
# 				) The max_binlog_cache_Size system variable specifies the upper limit of memory usage by an individual transaction.
#
# 				) The max_binlog_stmt_cache_size system variable specifies the upper limit of memory usage by the statement cache.
#
# ps and other system status programs may report that mysqld uses a lot of memory.
#
# THis may be caused by thread stacks on differnet memory addresses.
# For example, the Solaris version of ps counts the unused memory between stacks as used memory.
#
# To verify this, check available swap with swap -s. We test mysqld with several memory-leakage
# detectors (both commercial/open source),so there should not be any memory leaks.
#
# MONITORING MYSQL MEMORY USAGE
#
# The following example demonstrates how ot use Performance SChema and Sys schema to monitor MySQL memory usage.
#
# Most Performance Schema memory instrumentation is disabled by default.
#
# Instruments can be enabled by updating the ENABLED column of the Performance Schema
# setup_instruments table.
#
# Memory instruments have names in teh form of memory/code_area/instrument_name, where code_area
# is a value such as sql or innodb, and instrument_name is the instrument detail.
#
# 1. To view available MySQL memory instruments, query the Performance Schema setup_instruments table.
#
# 		The following query returns hundreds of memory instruments for all code areas:
#
# 			SELECT * FROM performance_schema.setup_instruments
# 			WHERE NAME LIKE '%memory%';
#
# 		YOu can narrow results by specifying a code area. For example, you can limit results to InnoDB
# 		memory instruments by specifying innodb as the code area.
#
# 			SELECT * FROM performance_schema.setup_instruments
# 			WHERE NAME LIKE '%memory/innodb%';
# 			+---------------------------------------------------+------------+---------+
# 			| NAME 															 | ENABLED 	  | TIMED   |
# 			+---------------------------------------------------+------------+---------+
# 			| memory/innodb/adaptive_hash_index 					 | NO 		  | NO 	   |
# 			| memory/innodb/buf_buf_pool 								 | NO 		  | NO      |
# 		   | memory/innodb/dict_stats_bg_recalc_pool_t 			 | NO 		  | NO 	   |
# 			| memory/innodb/dict_stats_index_map_t 				 | NO 		  | NO 	   |
# 			| memory/innodb/dict_stats_n_diff_on_level 			 | NO 		  | NO 		|
# 			| memory/innodb/other 										 | NO 		  | NO 	   |
# 			| memory/innodb/row_log_buf 								 | NO 		  | NO 	   |
# 			| memory/innodb/row_merge_sort 							 | NO 		  | NO 	   |
# 			| memory/innodb/std 											 | NO 		  | NO      |
# 			| memory/innodb/trx_sys_t::rw_trx_ids 				    | NO 		  | NO 	   |
# 			---
#
# Depending on your MySQL installation, code areas may include performance_schema, sql, client,
# innodb, myisam, csv, memory, blackhole, archive, partition and others.
#
# 2. To enable memory instruments, add a performance-schema-instrument rule to your MySQL configuration
# 		file.
#
# 		For example, to enable all memory instruments, add this rule to your configuration file and restart
# 		the server:
#
# 			performance-schema-instrument='memory/%=COUNTED'
#
# 		NOTE:
#
# 			Enabling memory instruments at startup ensures that memory allocations that occur at startup are counted.
#
# 		After restarting the server, the ENABLED column of the Performance Schema setup_instruments
# 		table should report YES for memory instruments that you enabled.
#
# 		The TIMED column in the setup_instruments table is ignored for memory instruments because
# 		memory operations are not timed.
#
# 		SELECT * FROM performance_schema.setup_instruments 
# 		WHERE NAME LIKE '%memory/innodb%';
# 		+------------------------------------------------------+---------------+-----------+
# 		| NAME 																 | ENABLED 		  | TIMED 	  |
# 		+------------------------------------------------------+---------------+-----------+
# 		| memory/innodb/adaptive_hash_index 						 | NO 			  | NO 	     |
# 		| memory/innodb/buf_buf_pool 									 | NO 			  | NO 		  |
# 		| memory/innodb/dict_stats_bg_recalc_pool_t 				 | NO 			  | NO 		  |
# 		| memory/innodb/dict_stats_index_map_t 					 | NO 			  | NO 	     |
# 		| memory/innodb/dict_stats_n_diff_on_level 				 | NO 			  | NO 		  |
# 		| memory/innodb/other 											 | NO 			  | NO 		  |
# 		| memory/innodb/row_log_buf 									 | NO 			  | NO 		  |
# 		| memory/innodb/row_merge_sort 								 | NO 			  | NO 		  |
# 		| memory/innodb/std 												 | NO 			  | NO 		  |
# 		| memory/innodb/trx_sys_t::rw_trx_ids 						 | NO 			  | NO 		  |
# 		---
#
# 3. Query memory instrument data.
#
# 		In this example, memory instrument data is queried in the Performance Schema memory_summary_global_by_event_name table,
# 		which summarizes data by EVENT_NAME.
#
# 		The EVENT_NAME is the name of the instrument.
#
# 		The following query returns memory data for the InnoDB buffer pool.
#
# 		For column descriptions, see MEMORY SUMMARY TABLES for more info.
#
# 		SELECT * FROM performance_schema.memory_summary_global_by_event_name
# 		WHERE EVENT_NAME LIKE 'memory/innodb/buf_buf_pool'\G
# 						EVENT_NAME: memory/innodb/buf_buf_pool
# 					  COUNT_ALLOC: 1
# 				 		COUNT_FREE: 0
# 	SUM_NUMBER_OF_BYTES_ALLOC: 137428992
# 	 SUM_NUMBER_OF_BYTES_FREE: 0
# 				LOW_COUNT_USED  : 0
# 			CURRENT_COUNT_USED : 1
# 				HIGH_COUNT_USED : 1
# 	 LOW_NUMBER_OF_BYTES_USED: 0
#CURRENT_NUMBER_OF_BYTES_USED: 137428992
#  HIGH_NUMBER_OF_BYTES_USED: 13748992
#
# The same underlying data can be queried using the sys schema memory_global_by_current_bytes table,
# which shows current memory usage within the server globally, broken down by allocation type:
#
# 		SELECT * FROM sys.memory_global_by_current_bytes
# 		WHERE event_name LIKE 'memory/innodb/buf_buf_pool'\G
# 		************************ 1. row ************************
# 				event_name: memory/innodb/buf_buf_pool
# 			current_count: 1
# 			current_alloc: 131.06 MiB
# 	  current_avg_alloc: 131.06 MiB
# 				high_count: 1
# 				high_alloc: 131.06 MiB
# 		  high_avg_alloc: 131.06 MiB
#
# This sys schema query aggregates currently allocated memory (current_alloc) by code area:
#
# 		SELECT SUBSTRING_INDEX(event_name, '/', 2) AS
# 		code_area, sys.format_bytes(SUM(current_alloc))
# 		AS current_alloc
# 		FROM sys.x$memory_global_by_current_bytes
# 		GROUP BY SUBSTRING_INDEX(event_name, '/', 2)
# 		ORDER BY SUM(current_alloc) DESC;
#
# 		+--------------------------------+----------------+
# 		| code_area 							| current_alloc  |
# 		+--------------------------------+----------------+
# 		| memory/innodb 						| 843.24 MiB 	  |
# 		| memory/performance_schema 		| 81.29 MiB 	  |
# 		| memory/mysys 						| 8.20 MiB 		  |
# 		| memory/sql 							| 2.47 MiB 		  |
# 		| memory/memory 						| 174.01 KiB 	  |
# 		| memory/myisam 						| 46.53 KiB 	  |
# 		| memory/blackhole 					| 512 bytes 	  |
# 		| memory/federated 					| 512 bytes 	  |
# 		| memory/csv 							| 512 bytes 	  |
# 		| memory/vio 							| 496 bytes 	  |
# 		+--------------------------------+----------------+
#
# For more information about sys schema, see CHAPTER 27, MySQL SYS SCHEMA, more later
#
# ENABLING LARGE PAGE SUPPORT
#
# Some hardware/operating systme architechture support memory pages greater than the default (usually 4kb).
# The actual implementation of this support depends on the underlying hardware and operating system.
#
# Applications that perform a lot of memory accesses may obtain performance improvements by using large
# pages due to redued Translation Lookaside Buffer (TLB) misses.
#
# In MySQL, large pages can be used by InnoDB, to allocate memory for its buffer pool and additional memory pool.
#
# Standard use of large pages in MySQL attempts to use the largest size supported, up to 4MB.
#
# Under Solaris, a "super large pages" feature enables uses of pages up to 256MB.
#
# THis feature is available for recent SPARC platforms. It can be enabled or disabled by
# using the --super-large-pages or --skip-super-large-pages option.
#
# MySQL also supports the Linux implementation of large page support (which is called HugeTLB in Linux)
#
# Before large pages can be used on Linux, the kernel must be enabled to support them and it is necessary
# to configure the HugeTLB memory pool.
#
# For reference, the HugeTLB API is documented in teh Documentation/vm/hugetlbpage.txt file of your Linux sources.
#
# The kernel for some recent systems such as Read Hat Enterprises Linux appear to have the large pages
# feature enabled by default.
#
# TO check whether this is true for your kernel, use the following command and look for output lines containing "Huge".
#
# 		cat /proc/meminfo | grep -i huge
# 		HugePages_Total: 		0
# 		HugePages_Free: 		0
# 		HugePages_Rsvd: 		0
# 		HugePages_Surp: 		0
# 		Hugepagesize: 		4096 kb
#
# The nonempty command output indicates that large page support is present, but the zero values indicate
# that no pages are configured for use.
#
# If your kernel needs to be reconfigured to support large pages, consult the hugetlbpage.txt file for instructions.
#
# Assuming that your Linux kernel has large page support enabled, configure it for use by MySQL using the following commands.
#
# Normally, you put these in an rc file or equivalent startup file that is executed during the system boot sequence,
# so that hte commands execute each time the system starts.
#
# The commands should execute early in the boot sequence, before the MySQL server starts.
#
# Be sure to change the allocation numbers and the group number as appropriate for your system.
#
# 		# Set the number of pages to be used.
# 		# Each page is normally 2MB, so a value of 20 = 40MB.
# 		# This command actually allocates memory, so this much
# 		# memory must be avaialable.
# 		echo 20 > /proc/sys/vm/nr_hugepages
#
# 		# Set the group number that is permitted to access this
# 		# memory (102 in this case). The mysql user must be a member of this group.
# 		echo 102 > /proc/sys/vm/hugetlb_shm_group
#
# 		# INcrease the amount of shmem permitted per segment
# 		# (12G in this case)
# 		echo 1560281088 > /proc/sys/kernel/shmmax
#
# 		# Increase total amount of shared memory. The value
# 		# is the number of pages. At 4kb/page, 4194304 = 16GB
# 		echo 4194304 > /proc/sys/kernel/shmall
#
# For MySQL usage, you normally want the value of shmmax to be close to the value of shmall.
#
# To verify the large page configuration, check /proc/meminfo again as described previously.
# Now you should see some nonzero values:
#
# 		cat /proc/meminfo | grep -i huge
# 		HugePages_Total: 		20
# 		HugePages_Free: 		20
# 		HugePages_Rsvd: 		 0
# 		HugePages_Surp: 	 	 0
# 		Hugepagesize: 		 4096 kB
#
# THe final step to make use of the hugetlb_shm_group is to give the mysql user an "unlimited" value for the
# memlock limit.
#
# This can be done either by editing /etc/security/limits.conf or by adding the following command to your
# mysqld_safe script:
#
# 		ulimit -1 unlimited
#
# Adding the ulimit command to mysqld_safe causes the root user to set the memlock limit to unlimited
# before switching to the mysql user.
#
# (This assumes that mysqld_safe is started by root)
#
# large page support in MySQL is disabled by default.
# To enable it, start the server with the --large-pages option.
#
# For example, you can use the following lines in the server my.cnf file:
#
# 		[mysqld]
# 		large-pages
#
# With this option, InnoDB uses large pages automatically for its buffer pool and additional memory pool.
#
# If InnoDB cannot do this, it falls back to use of traditional memory and writes a warning to the
# error log: Warning : Using conventional memory pool
#
# To verify that large pages are being used, check /proc/meminfo again:
#
# 		cat /proc/meminfo | grep -i huge
# 		HugePages_Total: 			20
# 		HugePages_Free: 			20
# 		HugePages_Rsvd: 			 2
# 		HugePages_Surp: 			 0
# 		Hugepagesize: 	 		 4096 kB
#
# OPTIMIZING NETWORK USE
#
# HOW MYSQL HANDLES CLIENT CONNECTIONS
#
# THis section describes aspects of how the MySQL server manages client connections.
#
# 		) Network Interfaces and Connection Manager Threads
#
# 		) Client Connection Thread Management
#
# 		) Connection Volume Management
#
# 		) Administrative Connection Management
#
# NETWORK INTERFACES AND CONNECTION MANAGER THREADS
#
# The server is capable of listening for client connections on multiple network interfaces.
#
# Connection manager threads handle client connection requests on the network interfaces
# that the server listens to:
#
# 		) On all platforms, one manager thread handles TCP/IP connection requests
#
# 		) On Unix, the same manager thread also handles Unix socket file connection requests
#
# 		) On Windows, a manager thread handles shared-memory connection requests, and another handles named-pipe connection requests.
#
# 		) On all platforms, an additional network interface may be enabled to accept administrative TCP/IP connection requests.
#
# 			This interface can use the manager thread that handles "ordinary" TCP/IP requests, or a separate thread.
#
# The server does not create threads to handle interfaces that it does not listen to.
#
# For example, a Windows Server that does not have support for named-pipe connections
# enabled does not create a thread to handle them.
#
# CLIENT CONNECTION THREAD MANAGEMENT
#
# Connection manager threads associate each client connection with a thread dedicated to it that handles
# authentication and request processing for that connection.
#
# Manager threads create a new thread when necessary but try to avoid doing so by consulting the thread cache
# first to see whether it contains a thread that can be used for the connection.
#
# When a connection ends, its thread is returned ot the thread cache if the cache is not full.
#
# In this connection thread model, there are as many threads as there are clients currently connected, which has some
# disadvantages when server workload must scale to handle large numbers of connections.
#
# For example, thread creation and disposal becomes expensive. Also, each thread requires server and kernel resources,
# such as stack space.
#
# To accommodate a large number of simultaneous connections, the stack size per thread must be kept small, leading to
# a situation where it is either too small or the server consumes large amounts of memory.
#
# Exhaustion of other resources can occur as well, and scheduling overhead can become significant.
#
# MySQL Enterprise Edition includes a thread pool plugin that provides an alternative thread-handling model designed to
# reduce overhead and improve performance.
#
# It implements a thread pool taht increases server performance by efficiently managing statement execution threads
# for large numbers of client connections.
#
# See MYSQL ENTERPRISE THREAD POOL for more info.
#
# To control and monitor how the server manages threads that handle client connections, several system and
# status variables are relevant.
#
# See SERVER SYSTEM VARIABLES and SERVER STATUS VARIABLES, for more info.
#
# The thread_cache_size system variable determines the thread cache size.
#
# By default, the server autosizes the value at startup, but it can be set explicitly
# to override this default.
#
# A value of 0 disables caching, which causes a thread to be set up for each new connection
# and disposed of when the connection terminates.
#
# To enable N inactive connection threads to be cached, set thread_cache_size to N at server
# startup or at runtime.
#
# A connection thread becomes inactive when the client connection with which it was associated terminates.
#
# To monitor the number of threads in the cache and how many threads have been created because a thread
# could not be taken from the cache, check the Threads_cached and Threads_created status variables.
#
# When the thread stack is too small, this limits the complexity of the SQL statements which the server
# can handle, the recursion depth of stored procedures, and other memory-consuming actions.
#
# To set a stack size of N bytes for each thread, start the server with thread_stack set to N at server startup.
#
# CONNECTION VOLUME MANAGEMENT
#
# To control the maximum number of clients the server permits to connect simultaneously, set the
# max_connections system variable at server startup or at runtime.
#
# It may be necessary to increase max_connections if more clients attempt to connect simultaneously
# then the server is configured to handle.
#
# See TOO MANY CONNECTIONS, SECTION B.5.2.6 later for more info.
#
# Mysqld actually permits max_connections + 1 client connections.
#
# The extra connection is reserved for use by accounts that have the CONNECTION_ADMIN
# or SUPER privilege.
#
# BY granting the privilege to admins and not to normal users (who should not need it),
# an admin can connect to the server and use SHOW_PROCESSLIST to diagnose problems even
# if the maximum number of unprivileged clients are connected.
#
# See SHOW PROCESSLIST SYNTAX for more info, later.
#
# (The server also permits administrative connections on a dedicated interface. See ADMINISTRATIVE CONNECTION MANAGEMENT)
#
# If the server refuses a connection because the max_connections limit is reached, it increments the
# Connection_errors_max_connections status variable.
#
# The maximum number of connections MySQL supports (that is, the maximum value to which max_connections can be set)
# depends on several factors:
#
# 		) The quality of the thread library on a given platform
#
# 		) The amount of RAM available
#
# 		) The amount of RAM is used for each connection
#
# 		) The workload from each connection
#
# 		) The desired response time
#
# 		) The number of file descriptors available
#
# Linux or Solaris should be able to support at least 500 to 1000 simultaneous connections routinely
# and as many as 10,000 connections if you have many gigabytes of RAM available and the workload
# from each is low or the response time target undemanding.
#
# Increasing the max_connections value increases the number of file descriptors that mysqld requires.
#
# IF the required number of descriptors are not available, the server reduces the value
# of max_connections.
#
# For comments on file descriptor limits, see HOW MYSQL OPENS AND CLOSES TABLES, for more info.
#
# Increasing --open-files-limit may be necessary, which may also require raising the operating system
# limit on how many file descriptors can be used by MySQL.
#
# Consult your operating system documentation to determine whether it is possible to increase the limit
# and how to do so.
#
# See SECTION B.5.2.17, "FILE NOT FOUND AND SIMILAR ERRORS" for more information.
#
# ADMINISTRATIVE CONNECTION MANAGEMENT
#
# As of MySQL 8.0.14, the server permits a TCP/IP port to be configured specifically
# for administrative connections.
#
# This provides an alternative to the single administrative connection that is permitted
# on the network interfaces used for ordinary connections even when max_connections connections
# are already established.
#
# See CONNECTION VOLUME MANAGEMENT
#
# The administrative network interface has these characteristics:
#
# 		) The interfaceis available only if the admin_address system variable is set at startup to indicate
# 			the IP address for the administrative interface.
#
# 			If no admin_address value is specified, the server maintains no administrative interface.
#
# 		) The admin_port system varaible specifies the interface TCP/IP port number (default 33062)
#
# 		) There is no limit on the number of administrative connections
#
# 		) Connections are permitted only by users who have the SERVICE_CONNECTION_ADMIN privilege.
#
# The create_admin_listener_thread system variable enables DBAs to choose at startup whether the administrative
# interface is implemented using the listener thread used for ordinary connections, or has its own separate thread.
#
# The default is to implement the administrative interface using the listener thread used for ordinary
# connections.
#
# DNS LOOKUP OPTIMIZATION AND THE HOST CACHE
#
# The MySQL server maintains a host cache in memory that contains information about clients: IP address,
# host name, and error information.
#
# The Performance Schema host_cache table exposes the contents of the host cache so that it can be examined
# using SELECT statements.
#
# This may help you diagnose the cuase of connection problems.
#
# See THE HOST_CACHE TABLE for more info, later.
#
# Note:
#
# 		The server uses the host cache only for nonlocal TCP connections.
#
# 		IT does not use the cache for TCP connections established using a loopback interface
# 		address (for example, 127.0.0.1 or ::1) or for connections established using a Unix socket
# 		file, named pipe or shared memory.
#
# HOST CACHE OPERATION
#
# The server uses the host cache for several purposes:
#
# 		) By caching the results of IP-to-host name lookups, the server avoids doing a Domain Name System (DNS) lookup
# 			for each client connection.
#
# 			Instead, for a given host, it needs to perform a lookup only for the first connection from that host.
#
# 		) The cache contains information about errors that occur during the connection process.
#
# 			Some errors are considered "blocking". If too many of these occur successively from a given host
# 			without a successful connection, the server blocks further connections from that host.
#
# 			The max_connect_errors system variable determines the permitted number of successive errors before
# 			blocking occurs.
#
# 			See HOST 'HOST_NAME' IS BLOCKED SECTION B.5.2.5 later for more info.
#
# For each new client connection, the server uses the client IP address to check whether the client host name
# is in the host cache.
#
# If so, the server refuses or continues to process the connection request depending on whether or not
# the host is blocked.
#
# If the host is not in the cache, the server attempts to resolve the host name.
#
# First, it resolves the IP address to a host name and resolves that host name back to an IP address.
#
# Then it compares the result to the original IP address to ensure that they are the same.
#
# The server stores information about the result of this operation in teh host cache.
# If the cache is full, the least recently used entry is discarded.
#
# The server handles entries in the host cache like this:
#
# 		1. When the first TCP client connection reaches the server from a given IP address, a new cache
# 			entry is created to record the client IP, host name and client lookup validation flag.
#
# 			Initially, the host name is set ot NULL and the flag is false.
#
# 			This entry is also used for subsequent client TCP connections from the same original IP.
#
# 		2. If the validation flag for the client IP entry is false, the server attempts an IP-to-host name-to-IP DNS
# 			resolution.
#
# 			If thati s successful, the host name is updated with the resolved host name and the validation flag is set to true.
#
# 			If resolution is unsuccessful, the action taken depends on whether the error is permanent or transient.
# 			For permanent failures, the host name remains NULL and the validation flag is set to true.
#
# 			For transient failures, the host name and validation flag remain unchanged.
 #			(In this case, another DNS resolution attempt occurs the next time a client connects from this IP)
 #
 # 	3. If an error occurs while processing an incoming client connection from a given IP address, the server 
 # 			updates the corresponding error counters in the entry for that IP.
 #
 # 		For a description of the errors recorded, see SECTION 26.12.17.1 "THE HOST_CACHE TABLE"
 #
 # The server performs host name resolution using the gethostbyaddr() and gethostbyname() system cals.
 #
 # To unblock blocked hosts, flush the host cache by executing a FLUSH HOSTS statement, a TRUNCATE_TABLE statement
 # that truncates the Performance Schema host_cache table or a mysqladmin flush-hosts command.
 #
 # FLUSH_HOSTS and mysqladmin flush-hosts require the RELOAD Privilege. TRUNCATE_TABLE requires the DROP privilege
 # for the host_cache table.
 #
 # It is possible for a blocked host to become unblocked even without flushing the host cache if activity from other
 # hosts has occurred since the last connection attempt from the blocked host.
 #
 # This can occur because the server discard the least recently used entry to make room for a new entry if the 
 # cache is full when a connection arrives from a client IP not in the cache.
 #
 # IF the discard entry is for a blocked host, that host becomes unblocked.
 #
 # Some connection errors are not associated with TCP connections, occur very early in the connection process
 # (even ebfore an IP address is known) or are not specific to any particular IP address (such as out-of-memory conditions).
 #
 # For information about these errors, check the Connection_errors_xxx status variables.
 # See SECTION 5.1.10, SERVER STATUS VARIABLES for more information.
 #
 # HOST CACHE CONFIGURATION
 #
 # The host cache is enabled by default.
 #
 # The host_cache_size system variable controls its size, as well as the size of the
 # Performance Schema host_cache table that exposes the cache contents.
 #
 # The cache size can be set at server startup and changed at runtime.
 #
 # For example, to set the size to 100 at startup, put these lines in the server my.cnf
 # file:
 #
 # 		[mysqld]
 # 		host_cache_size=200
 #
 # To change the size to 300 at runtime, do this:
 #
 # 		SET GLOBAL host_cache_size=300;
 #
 # Setting host_cache_size to 0, either at server startup or at runtime, disables the host cache.
 # With the cache disabled, the server performs a DNS lookup every time a client connects.
 #
 # Changing the cache size at runtime causes an implicit FLUSH_HOSTS operation that clears the host cache,
 # truncates the host_cache table, and unblocks any blocked hosts.
 #
 # Using the --skip-host-cache option is similar to setting the host_cache_size system variable to 0, but
 # host_cache_size is more flexible, because it can also be used to resize, enable and disable the host cache at runtime,
 # not just at server startup.
 #
 # Starting the server with --skip-host-cache does not prevent changes to hte value of host_cache_size,
 # but such changes have no effect and the cache is not re-enabled even if host_cache_size is set
 # larger than 0 at runtime.
 #
 # To disable DNS host name lookups, start the server with the --skip-name-resolve option.
 #
 # IN this case, the server uses only IP addresses and not host names to match connecting hosts
 # to rows in the MySQL grant tables.
 #
 # Only accounts specified in those tables using IP addresses can be used.
 #
 # (A client may not be able to connect if no account exists that specifies the client IP address)
 #
 # IF you have a very slow DNS and many hosts, you might be able to improve the performance either by disabling DNS lookups
 # with --skip-name-resolve or by increasing the value of host_cache_size to make the host cache larger.
 #
 # To disallow TCP/IP connections entirely, start the server with the --skip-networking option.
 #
 # RESOURCE GROUPS
 #
 # MySQL supports creation and management of resource groups, and permits assigning threads running
 # within the server to particular groups so that threads execute according to the resources available
 # to the group.
 #
 # Group attributes enable control over its resources, to enable or restrict resource consumption by threads
 # in the group.
 #
 # DBAs can modify these attributes as appropriate for different workloads.
 #
 # Currently, CPU time is a managable resource, reprented by the concept of "virtual CPU" as a term that
 # includes CPU cores, hyperthreads, hardware threads, and so forth.
 #
 # THe server determines at startup how many virtual CPUs are available, and database administrators
 # with appropriate privileges can associate these CPUs with resource groups and assign threads
 # to groups.
 #
 # For example, to manage execution or batch jobs that need not execute with high priority, a DBA can
 # create a Batch resource group, and adjust its priority up or down depending on how busy the server is.
 #
 # (Perhaps batch jobs assigned to the group should run at lower priority during the day and at higher
 # priority during the night)
 #
 # The DBA can also adjust the set of CPUs available to the group. Groups can be enabled or disabled 
 # to control whether threads are assignable to them.
 #
 # The following sections describe aspects of resource group use in MySQL:
 #
 # ) Resource Group COmponents
 #
 # ) Resource Group Attributes
 #
 # ) Resource Group Management 
 #
 # ) Resource Group Replication
 #
 # ) Resource Group Restrictions 
 #
 # IMPORTANT:
 #
 # On some platforms or MySQL server configurations, resource groups are unavailable or have limitations.
 # In particular, Linux systems might require a manual step for some installation methods.
 #
 # For details, see RESOURCE GROUP RESTRICTIONS for more info.
 #
 # RESOURCE GROUP COMPONENTS
 #
 # These capabilities provide the SQL interface for resource group management in MySQL:
 #
 # 	) SQL statements enables creating, altering and dropping resouce groups and enable assigning
 # 		threads to resource groups.
 #
 # 		An optimizer hint enables assigning individual statements to resource groups.
 #
 # 	) Resource group privileges provide control over which users can perform resource group operations.
 #
 # 	) The INFORMATION_SCHEMA.RESOURCE_GROUPS table exposes information about resource group
 # 		definitions and the Performance Schema threads table shows the resource group assignment for each thread.
 #
 # 	) Status variables provide execution counts for each management SQL statement.
 #
 # RESOURCE GROUP ATTRIBTUES
 #
 # Resource groups have attributes that define the group.
 # All attributes can be set at group creation time.
 #
 # Some attributes are fixed at creation time; others can be modified any time thereafter.
 #
 # These attributes are defined at resource group creation time and cannot be modified:
 #
 # 	) Each group has a name. Resource group names are identifiers like table and column names,
 # 		and need not be quoted in SQL statements unless they contain special characters or are reserved words.
 #
 # 		Group names are not case sensitive and may be up to 64 characters long.
 #
 # 	) Each group has a type, which is either SYSTEM or USER.
 #
 # 		The resource group type affects the range of priority values assignable to the group,
 # 		as described later.
 #
 # 		This attribute together with the differences in permitted priorities enables system
 # 		threads to be identified so as to protect them from contention for CPU resources against
 # 		user threads.
 #
 # 		System and user threads correspond to background and foreground threads as listed in the Performance Schema threads table.
 #
 # These attributes are defined at resource group creation time and can be modified an time thereafter:
 #
 # 	) The CPU affinity is the set of virtual CPUs the resource group can use. An affinity can be any
 # 		nonempty subset of the available CPUs.
 #
 # 		If a group has no affinity, it can use all available CPUs.
 #
 # 	) The thread priority is the execution priority for threads assigned to the resource group.
 # 		Priority values range from -20 (highest prio) to 19 (lowest prio)
 #
 # 		The default prio is 0, forb oth system and user groups.
 #
 # 		System groups are permitted a higher priority than user groups, ensuring that user threads
 # 		never have a higher prio than system threads:
 #
 # 			) For system resource groups, the permitted priority range is -20 to 0.
 #
 # 			) For user resource groups, the permitted priority range is 0 to 19.
 #
 #		) Each group can be enabled or disabled, affording administrators control over thread assignments.
 #
 # 		Threads can be assigned only to enabled groups.
 #
 # RESOURCE GROUP MANAGEMENT
 #
 # By default, there is one system group and one user group, named SYS_default and USR_default, respectively.
 # These default groups cannot be dropped and their attributes cannot be modified.
 #
 # Each default group has no CPU affinity and priority 0.
 #
 # Newly created system and user threads are assigned to the SYS_default and USR_default groups, respectively.
 #
 # For user-defined resource groups, all attributes are assigned at group creation time.
 #
 # After a group has been created, its attributes can be modified, with the exception of the name
 # and typpe attributes.
 #
 # To create and manage user-defined resource groups, use these SQL statements:
 #
 # 	) CREATE_RESOURCE_GROUP creates a new group. See SECTION 13.7.2.2, "CREATE RESOURCE GROUP syntax" for more info.
 #
 # 	) ALTER_RESOURCE_GROUP modifies an existing group. See SECTION 13.7.2.1, "ALTER RESOURCE GROUP Syntax" for more info.
 #
 # 	) DROP_RESOURCE_GROUP drops an existing group. See SECTION 13.7.2.3, "DROP RESOURCE GROUP Syntax" for more info.
 #
 # Those statements require the RESOURCE_GROUP_ADMIN privilege.
 #
 # To manage resource group assignments, use these capabilities:
 #
 # 	) SET_RESOURCE_GROUP assigns threads to a group. See SECTION 13.7.2.4, "SET RESOURCE GROUP Syntax" for more info.
 #
 # 	) The RESOURCE_GROUP optimizer hints assigns individual statements to a group. See Section 8.9.2, "OPTIMIZER HINTS" for more info.
 #
 # Those operations require the RESOURCE_GROUP_ADMIN or RESOURCE_GROUP_USER privilege.
 #
 # Resource group definitions are stored in the resource_groups data dictionary table so that
 # groups perssist across server restarts.
 #
 # Because resource_groups is part of the data dictionary, it is not directly accessible by users.
 #
 # Resource group information is available using the INFORMATION_SCHEMA.RESOURCE_GROUPS table,
 # which is implemented as a view on the data dictionary table.
 #
 # See Section 25.21, "THE INFORMATION_SCHEMA RESOURCE_GROUPS TABLE" for more info.
 #
 # Initially, the RESOURCE_GROUPS table has these rows describing the default groups:
 #
 # 		SELECT * FROM INFORMATION_SCHEMA.RESOURCE_GROUPS\G
 # 		************************* 1. row **********************
 # 			RESOURCE_GROUP_NAME: USR_default
 # 			RESOURCE_GROUP_TYPE: USER
 # 		RESOURCE_GROUP_ENABLED: 1
 # 						VCPU_IDS  : 0-3
 # 				THREAD_PRIORITY : 0
 # 		************************* 2. row **********************
 # 			RESOURCE_GROUP_NAME: SYS_default
 # 			RESOURCE_GROUP_TYPE: SYSTEM
 # 		RESOURCE_GROUP_ENABLED: 1
 # 						VCPU_IDS  : 0-3
 # 				THREAD_PRIORITY : 0
 #
 # The THREAD_PRIORITY values are 0, indicating the default priority.
 #
 # The VCPU_IDS values show a range comprising all available CPUs.
 #
 # For the default groups, the displayed value varies depending on the system
 # on which the MySQL server runs.
 #
 # Earlier discussion mentioned a scenario involving a resource group named Batch
 # to manage execution of batch jobs that need not execute with high priority.
 #
 # To create such a group, use a statement similar to this:
 #
 # CREATE RESOURCE GROUP Batch
 # 	TYPE = USER
 # 	VCPU = 2-3 				-- assumes a system with at least 4 CPUs
 # 	THREAD_PRIORITY = 10;
 #
 # To verify that the resource group was created as expected, check the RESOURCE_GROUPS table:
 #
 # 	SELECT * FROM INFORMATION_SCHEMA.RESOURCE_GROUPS WHERE RESOURCE_GROUP_NAME = 'Batch'\G
 # 	******************************** 1. row ***********************
 # 		RESOURCE_GROUP_NAME: Batch
 # 		RESOURCE_GROUP_TYPE: USER
 # 	RESOURCE_GROUP_ENABLED: 1
 # 					VCPU_IDS  : 2-3
 # 			THREAD_PRIORITY : 10
 #
 # If the THREAD_PRIORITY value is 0 rather than 10, check whether your platform or system configuration
 # limits the resource group capability.
 #
 # See RESOURCE GROUP RESTRICTIONS for more information.
 #
 # To assign a thread to the Batch group, do this:
 #
 # 		SET RESOURCE GROUP Batch FOR thread_id;
 #
 # Thereafter, statements in the named thread execute with Batch group resources.
 #
 # If a session's own current thread should be in the Batch group, execute this statement
 # within the session:
 #
 # 	SET RESOURCE GROUP Batch;
 #
 # Thereafter, statements in the session execute with Batch group resources.
 #
 # To execute a single statement using the Batch group, use the RESOURCE_GROUP optimizer hint:
 #
 # 	INSERT /*+ RESOURCE_GROUP(Batch) */ INTO t2 VALUES(2);
 #
 # Threads assigned to the Batch group execute with its resources, which can be modified as desired:
 #
 # 	) For times when the system is highly loaded, decreases the number of CPUs assigned to the group,
 # 		lower its priority or (as shown) both:
 #
 # 		ALTER RESOURCE GROUP Batch
 # 			VCPU = 3
 # 			THREAD_PRIORITY = 19;
 #
 # 	) For times when the system is lightly loaded, increase the number of CPUs assigned to the group, raise its priority, or, as shown, both:
 #
 # 		ALTER RESOURCE GROUP Batch
 # 			VCPU = 0-3
 # 			THREAD_PRIORITY = 0;
 #
 # RESOURCE GROUP REPLICATION
 #
 # Resource group management is local to the server on which it occurs.
 #
 # Resource group SQL statements and modifications to the resouce_groups data dictionary
 # table are not written to the binary log and are not replicated.  
#
# RESOURCE GROUP RESTRICTIONS
#
# On some platforms or MySQL Server configurations, resource groups are unavailable or have limitations:
#
# 		) Resource groups are unavailable if the thread pool plugin is installed.
#
# 		) Resource groups are unavailable on macOS, which provides no API for binding CPUs to a thread.
#
# 		) On FreeBSD and Solaris, resource group thread priorities are ignored.
#
# 			(Effectively, all threads run at priority 0).
#
# 			Attempts to change priorities result in a warning:
#
# 			ALTER RESOURCE GROUPS abc THREAD_PRIORIY = 10;
# 			Query OK, 0 rows affected, 1 warning (0.18 sec)
#
# 			SHOW WARNINGS;
# 			+--------------+-----------+-----------------------------------------------------------------+
# 			| Level 			| Code 		| Message 																			|
# 			+--------------+-----------+-----------------------------------------------------------------+
# 			| Warning 		| 4560 	   | Attribute thread_priority is ignored (using default value) 	   |
# 			+--------------+-----------+-----------------------------------------------------------------+
#
# 		) On Linux, resource groups thread priorities are ignored unless the CAP_SYS_NICE capability is set.
#
# 			Granting CAP_SYS_NICE capability to a process enables a range of privileges; consult external resources for that.
#
# 			Be careful when enabling this capability.
#
# 			On Linux platforms using systemd and kernel support for Ambient Capabilities (Linux 4.3 or newer), the recommended
# 			way to enable CAP_SYS_NICE capability is to modify the MySQL service file and leave the mysqld binary unmodified.
#
# 			To adjust the service file for MySQL, use this procedure:
#
# 				a. Run the appropraite command for your platform:
#
# 					> Oracle Linux, Red Hat and Fedora systems:
#
# 						sudo systemctl edit mysqld
#
# 					> SUSE, Ubuntu, and Debian systems:
#
# 						sudo systemctl edit mysql
#
# 				b. Using an editor, add the following text to the service file:
#
# 					[Service]
# 					AmbientCapabilities=CAP_SYS_NICE
#
# 				c. Restart the MySQL Service.
#
# 			If you cannot enable the CAP_SYS_NICE capability as just described, it can be set manually using
# 			the setcap command, specifying the path name to the mysqld executable (this requires sudo access).
#
# 			You can check the capabilities using getcap. For example:
#
# 				sudo set cap_sys_nice+ep /path/to/mysqld
# 				getcap /path/to/mysqld
# 				/path/to/mysqld = cap_sys_nice+ep
#
# 			As a safety measure, restrict execution of the mysqld binary to the root user and users with mysql group membership:
#
# 				sudo chown root:mysql /path/to/mysqld
# 				sudo chmod 0750 /path/to/mysqld
#
# 			IMPORTANT:
#
# 				If manual use of setcap is required, it must be performed after each reinstall.
#
# 		) on Windows, threads run at one of five thread priority levels.
#
# 			The resource group thread priority range of -20 to 19 maps onto those levels
# 			as indicated in the following table.
#
# 			Resource Group Thread Priority on Windows
#
# 			Priority Range 					WINDOWS PRIORITY LEVEL
#
# 			-20 to -10 							THREAD_PRIORITY_HIGHEST
# 			-9 to -1 							THREAD_PRIORITY_ABOVE_NORMAL
#
# 			0 										THREAD_PRIORITY_NORMAL
#
# 			1 to 10 								THREAD_PRIORITY_BELOW_NORMAL
# 			11 to 19 							THREAD_PRIORITY_LOWEST
#
# MEASURING PERFORMANCE (BENCHMARKING)
#
# To measure performance, consider the following factors:
#
# 		) Whether you are measuring the speed of a single operation on a quiet system, or how a set of operations
# 			(a "workload") works over a period of time.
#
# 			With simple tests, you usually test how changing one aspect (a configuration setting, the set of indexes
# 			on a table, the SQL clauses in a query) affects performance.
#
# 			Benchmarks are typically long-running and elaborate performance tests, where the results
# 			could dictate high-level choices such as hardware and storage configuration, or how soon to
# 			upgrade to a new MySQL version.
#
# 		) For benchmarking, sometimes you must simulate a heavy database worklaod to get an accurate picture.
#
# 		) Performance can vary depending on so many different facotrs that a difference of a few percentage
# 			points might not be a decisive victory.
#
# 			THe results might shift the oppposite way when you test in a different environment.
#
# 		) Certain MYSQL features help or do not help performance depending on the workload.
#
# 			For completeness, always test performance with those features turned on and 
# 			turned off.
#
# 			The most important feature to try with each workload is the adaptive hash index for InnoDB tables.
#
# This section progresses from simple and direct measurement techniques that a single dev can do,
# to more complicated ones that require additional expertise to perform and interpret hte results.
#
# MEASURING THE SPEED OF EXPRESSIONS AND FUNCTIONS
#
# To measure the speed of a specific MySQL expression or function, invoke the BENCHMARK() function
# using the mysql client program.
#
# its syntax is BENCHMARK(loop count, expression).
#
# The return value is always zero, but mysql prints a line displaying approximately how long
# the statement took to execute.
#
# For example:
#
# 		SELECT BENCHMARK(1000000,1+1);
# 		+----------------------------+
# 		| BENCHMARK(1000000,1+1) 	  |
# 		+----------------------------+
# 		| 							0 		  |
# 		+----------------------------+
# 		1 row in set (0.32 sec)
#
# This result for instance, was done with a Pentium II 400 MHz system.
# It shows that MySQL can perform 1 mil simple addition expresisons in 0.32 on that system.
#
# The built-in MySQL functions are typically highly optimized, but there may be
# some exceptions.
#
# BENCHMARK() is an excellent tool for finding out if some function is a problem for your queries.
#
# USING YOUR OWN BENCHMARKS
#
# Benchmark your application and database to find out where the bottlenecks are.
#
# After fixing one bottleneck (or by replacing it with a "dummy" module), you can proceed
# to identify the next bottleneck.
#
# Even if the overall performance for your application currently is acceptable, you should
# at least make a plan for each bottleneck and decide how to solve if someday you 
# really need that extra performance.
#
# A free benchmark suite is the OPen Source Database Benchmark, available at -> <link>
#
# It is very common for a problem to occur only when hte system is very heavily loaded.
#
# We have had many customers who contact us when they have a (tested) system in production,
# and have encountered load problems.
#
# IN most cases, performance problems turn out ot be due to issues of basic DB design
# (for example, table scans are not good under high load) or problems with the OS or libraries.
#
# Most of the time, these problems would be much easier to fix if the systems were not
# already in production.
#
# To avoid problems like this, benchmark your whole application under hte worst possible load:
#
# 		) The mysqlslap program can be helpful for simulating a high load produced by multiple clients issuing queries
# 			simultaneously.
#
# 			See mysqlslap - LOAD EMULATION CLIENT for more info.
#
# 		) You can also try benchmarking packages such as SysBench and DBT2, available at _> Links.
#
# These programs or packages can bring a system to its knees, so be sure to use them only on your
# development systems.
#
# MEASURING PERFORMANCE WITH PERFORMANCE_SCHEMA
#
# You can query the tables in the performance_schema database to see real-time
# information about the performance characteristics of your server and the application it is
# running.
#
# See CHAPTER 26, MYSQL PERFORMANCE SCHEMA for details.
#
# EXAMINING THREAD INFORMATION
#
# When you are attempting to ascertain what your MysQL server is doing, it can be helpful to
# examine the process list, which is the set of threads currently executing within
# the server.
#
# Process list information is available from these sources:
#
# 		) The SHOW [FULL] PROCESSLIST statement: More under SHOW PROCESSLIST SYNTAX Section 13.7.6.29
#
# 		) The SHOW_PROFILE statement: Section 13.7.6.31, "SHOW PROFILES Syntax"
#
# 		) The INFORMATION_SCHEMA PROCESSLIST table: Section 25.18, "The INFORMATION_SCHEMA PROCESSLIST Table"
#
# 		) The mysqladmin processlist command: Section 4.5.2, MYSQLADMIN - CLIENT FOR ADMINISTERING A MYSQL SERVER
#
# 		) The Performance Schema threads table, stage tables, and lock tables: See 26.12.17, PERFORMANCE SCHEMA MISCELLANEOUS TABLES,
# 			SECTION 26.12.5 "PERFORMANCE SCHEMA STAGE EVENT TABLES", SECTION 26.12.12 "PERFORMANCE SCHEMA LOCK TABLES" for more info.
#
# Access to threads does not require a mutex and has a minimal impact on server performance.
#
# INFORMATION_SCHEMA.PROCESSLIST and SHOW_PROCESSLIST have negative performance consequences
# because they require a mutex.
#
# threads also shows information about background threads, which INFORMATION_SCHEMA.PROCESSLIST
# and SHOW_PROCESSLIST do not. 
#
# This means that threads can be used to monitor activity the other thread information
# sources cannot.
#
# YOu can always view information about your own threads. To view information about threads being executed for other
# accounts, you must have the PROCESS privilege.
#
# Each process list entry contains several pieces of information:
#
# 		) ID is the connection identifier for the client associated with the thread.
#
# 		) User and Host indicate the account associated with the htread.
#
# 		) db is the default daatbase for the thread, or NULL if none is selected.
#
# 		) Command and State indicate what the thread is doing.
#
# 			Most states correspond to very quick operations. If a thread stays in a given state
# 			for many seconds, there might be a problem that needs to be investigated.
#
# 		) Time indicates how long the thread has been in its current state.
#
# 			The thread's notion of hte current time may be altered in some cases:
#
# 			The thread can change the time with SET_TIMESTAMP = value.
#
# 			For a thread running on a slave that is processing events from the master,
# 			the thread time is set ot the time found in the events and thus reflects
# 			current time on the master and not hte slave.
#
# 		) Info contains the text of the statement being executed by the thread, or NULL if it is not executing one.
# 			By default, this value contains only the first 100 characters of the statement.
#
# 			TO see the complete statements, use SHOW_FULL_PROCESSLIST.
#
# 		) The sys schema processlist view, which presents information from the Performance Schema threads
# 			table in a more accessible format, see:
#
# 			Section 27.4.3.22 "THE PROCESSLIST AND x$processlist VIEWS"
#
# 		) The sys schema session view, which presents information about user sessions (like the sys schema processlist view, but with
# 			background processes filtered out):
#
# 			Section 27.4.3.33 "The session and x$session Views"
#
# The following sections list hte possible Command values, and State values grouped by category.
# The meaning of some of these values is self-evident.
#
# For others, additional description is provided.
#
# THREAD COMMAND VALUES
#
# A thread can have any of the following Command values:
#
# 		) Binlog Dump
#
# 			This is a thread on a master server for sending binary log contents to a slave server
#
# 		) Change user
#
# 			The thread is executing a change-user operation
#
# 		) Close stmt
#
# 			The thread is closing a prepared statement
#
# 		) Connect
#
# 			A replication slave is connected to its master
#
# 		) Connect Out
#
# 			A replication slave is connecting to its master.
#
# 		) Create DB
#
# 			The thread is executing a create-database operation.
#
# 		) Daemon
#
# 			This thread is internal to the server, not a thread that services a client connection
#
# 		) Debug
#
# 			The thread is generating debugging information
#
# 		) Delayed insert
#
# 			The thread is a delayed-insert handler
#
# 		) Drop DB
#
# 			The thread is executing a drop-database operation
#
# 		) Error
#
# 		) Execute
#
# 			The thread is executing a prepared statement
#
# 		) Fetch
#
# 			The threadi s fetching the results from executing a prepared statement.
#
# 		) Field List
#
# 			The thread is retrieving information for table columns
#
# 		) Init DB
#
# 			The thread is selecting a default database.
#
# 		) Kill
#
# 			The thread is killing another thread.
#
# 		) Long Data
#
# 			The thread is retrieving long data in the result of executing a prepared statement.
#
# 		) Ping
#
# 			The thread is handling a server-ping request
#
# 		) Prepare
#
# 			The thread is preparing a prepared statement.
#
# 		) Processlist
#
# 			The thread is producing informaiton about server threads.
#
# 		) Query
#
# 			The thread is executing a statement
#
# 		) Quit
#
# 			The thread is terminating
#
# 		) Refresh
#
# 			The thread is flsuhing tables, logs or caches, or resetting status variable or replication
# 			server information.
#
# 		) Register Slave
#
# 			The thread is registering a slave server.
#
# 		) Reset stmt
#
# 			The thread is resetting a prepared statement.
#
# 		) Set option
#
# 			The thread is setting or resetting a client statement execution option
#
# 		) Shutdown
#
# 			The thread is shutting down the server
#
# 		) Sleep
#
# 			The thread is waiting for the client sto send a new statement to it
#
# 		) Statistics
#
# 			The thread is producing server-status information
#
# 		) Table DUmp
#
# 			The thread is sending table contents to a slave server.
#
# 		) Time
#
# 			Unused
#
# GENERAL THREAD STATES
#
# The following list describes thread State values that are associated with general query processing
# and not more specialized activities such as replication.
#
# Many of these are useful only for finding bugs in the server.
#
# 		) After create
#
# 			This occurs when the thread creates a table (including internal temporary tables), at the end of
# 			the function that creates the table:
#
# 			This state is used even if the table could not be created due to some error.
#
# 		) Analyzing
#
# 			The thread is calculating a MyISAM table key distrib (for example, for ANALYZE_TABLE)
#
# 		) Checking permissions
#
# 			The thread is checking whether hte server has the required privileges to execute the statement
#
# 		) Checking table
#
# 			The thread is performing a table check operation
#
# 		) cleaning up
#
# 			The thread has processed one command and is prepared to free memory and reset certain state variables.
#
# 		) closing tables
#
# 			The thread is flushing the changed table data to disk and closing the used tables.
# 			THis should be a fast operation.
#
# 			If not, verify that you do not have a full disk and that hte disk is not in very heavy use.
#
# 		) converting HEAP to ondisk
#
# 			The thread is converting an internal temporary table from a MEMORY table to an on-disk table.
#
# 		) copy to tmp table
#
# 			The thread is processing an ALTER_TABLE statement.
#
# 			This state occurs after the table with the new structure has been created, but before
# 			rows are copied into it.
#
# 			For a thread in this state, the Performance Schema can be used to obtain about hte progress
# 			of the copy operation.
#
# 			See SECTION 26.12.5 "Performance Schema Stage Event Tables"
#
# 		) Copying to group table
#
# 			If a statemnet has different ORDER BY and GROUP BY criteria, the rows are sorted by group and
# 			copied to a temporary table.
#
# 		) Copying to tmp table
#
# 			The server is copying to a temporary table in memory.
#
# 		) Altering table
#
# 			The server is in the process of executing an in-place ALTER_TABLE
#
# 		) Copying to tmp table on disk
#
# 			The server is copying to a temporary table on disk.
# 			The temporary result set has become too large (see SECTION 8.4.4 "INTERNAL TEMPORARY TABLE USE IN MYSQL")
#
# 			Consequently, the thread is changing the temporary table from in-memory to disk-based format to save memory.
#
# 		) Creating index
#
# 			The thread is processing ALTER TABLE --- ENABLE KEYS for a MyISAM table.
#
# 		) Creating sort index
#
# 			The thread is processing a SELECT that is resolving using an internal temporary table.
#
# 		) creating table
#
# 			The thread is creating a table. This includes creation of temporary tables.
#
# 		) Creating tmp table
#
# 			The thread is creating a temporary table in memory or on disk.
#
# 			If the table is created in memory, but later is converted to an on-disk table,
# 			the state during that operationg will be Copying to tmp table on disk.
#
# 		) comitting alter table to storage engine
#
# 			The server has finished an in-place ALTER TABLE and is committing the result.
#
# 		) deleting from main table
#
# 			The server is executing the first part of a multiple-table delete.
#
# 			It is deleting only from the first table, and saving columns and offsets to be used
# 			for deleting from the other (reference) tables.
#
# 		) deleting from reference table
#
# 			The server is executing the second part of a multiple-table delete and deleting the matched rows
# 			from the other tables.
#
# 		) discard_or_import_tablespace
#
# 			The thread is processing an ALTER TABLE --- DISCARD TABLESPACE or ALTER TABLE --- IMPORT TABLESPACE
# 			statement.
#
# 		) end
#
# 			THis occurs at the end but before the cleanup of ALTER_TABLE, CREATE_VIEW, DELETE, INSERT, SELECT or UPDATE statements.
#
# 		) executing
#
# 			The thread has beung executing a statement
#
# 		) Execution of init_command
#
# 			The thread is executing statements in the value of the init_command system variable.
#
# 		) freeing items
#
# 			The thread has executed a command. This state is usually follwoed by cleaning up.
#
# 		) FULLTEXT initialization
#
# 			The server is preparing to perform a natural-langauge full-text search
#
# 		) init
#
# 			This occurs before the intiialization of ALTER_TABLE, DELETE, INSERT, SELECT or UPDATE statements.
# 			Actions taken by the server in this state include flushing the binary log and the InnoDB log.
#
# 			For the end state, the following operations could be happening:
#
# 				) Writing an event ot the binary log
#
# 				) Freeing memory buffers, including for blobs
#
# 		) Killed
#
# 			Someone has sent a KILL statement to the thread and it should abort next time it checks the kill flag.
#
# 			The flag is checked in each major loop in MySQL, but in some cases it might still take a short time
# 			for the thread to die.
#
# 			If the thread is locked by some other thread, the kill takes effect as soon as the other thread releases its lock.
#
# 		) Locking system tables
#
# 			The thread is trying to lock a system table (for example, a time zone or log table)
#
# 		) logging slow query
#
# 			The thread is writing a statement to the slow-query log.
#
# 		) login
#
# 			The intial state for a connection thread until the client has been
# 			authenticated successfully.
#
# 		) manage keys
#
# 			The server is enabling or disabling a table index.
#
# 		) NULL
#
# 			This state is used for the SHOW_PROCESSLIST state.
#
# 		) Opening system tables
#
# 			The thread is trying to open a system table (for example, a time zone or log table)
#
# 		) Opening tables
#
# 			THe thread is trying to open a table. 
#
# 			This hsould be a very fast procedure, unless something prevents opening.
#
# 			For example, an ALTER_TABLE or a LOCK_TABLE statement can prevent opening
# 			a table until the statement is finished.
#
# 			It is also worth checking that your table_open_cache value is large enough.
#
# 			For system tables, the Opening system tables state is used instead.
#
# 		) optimizing
#
# 			The server is performing initial optimizations for a query.
#
# 		) preparing
#
# 			This state occurs during query optimization.
#
# 		) Purging old relay logs
#
# 			The thread is removing unneeded relay log files.
#
# 		) query end
#
# 			This state occurs after processing a query but before the freeing items state.
#
# 		) Receiving from client
#
# 			The server is reading a packet from the client.
#
# 		) Removing duplicates
#
# 			The query was using SELECT_DISTINCT in such a way that MySQL could not optimize away
# 			the distinct operation at an early stage.
#
# 			Because of this, MySQL requires an extra stage to remove all duplicated rows
# 			before sending the result to the client.
#
# 		) removing tmp table
#
# 			The thread is removing an internal temporary table after processing a SELECT statement.
# 			This state is not used if no temporary table was created.
#
# 		) rename
#
# 			The thread is renaming a table
#
# 		) Rename result table
#
# 			The thread is processing an ALTER_TABLE statement, has created the new table, and is
# 			renaming it to replace the original table.
#
# 		) Reopen tables
#
# 			The thread got a lock for the table, but noticed after getting the lock that
# 			the underlying table structure changed.
#
# 			It has freed the lock, closed the table, and is trying to reopen it.
#
# 		) Repair by sorting
#
# 			The repair code is using a sort of create indexes.
#
# 		) preparing for alter table
#
# 			The server is preparing to execute an in-place ALTER_TABLE
#
# 		) Repair done
#
# 			The thread has completed a multithreaded repair for a myISAM table.
#
# 		) Repair with keycache
#
# 			THe repair code is using creating keys one by one through the key cache.
# 			THis is much slower than Repair by sorting.
#
# 		) Rolling back
#
# 			The thread is rolling back a transaction.
#
# 		) Saving State
#
# 			For MyISAM table operations such as repair or analysis, the thread
# 			is saving the new table state to the .MYI file header.
#
# 			States includes informaiton such as number of rows, the AUTO_INCREMENT counter,
# 			and key distribs.
#
# 		) Searching rows for update
#
# 			The thread is doing a first phase to find all matching rows before updating them.
# 			
# 			This has ot be done if the UPDATE is changing the index that is used to find the
# 			involved rows.
#
# 		) Sending data
#
# 			THe thread is reading and processing rows for a SELECT statement, and sending data to the client.
#
# 			Because operations occurring during this state tend to perform large amounts of disk
# 			access (reads), it is often the longest-running state over the lifetime of a given query.
#
# 		) Sending to client
#
# 			The server is writing a pcket ot hte client.
#
# 		) Setup
#
# 			The thread is beginning an ALTER_TABLE operation.
#
# 		) Sorting for group
#
# 			The thread is doing a sort to satisfy a GROUP BY.
#
# 		) Sorting for order
#
# 			The thread is doing a sort to satisfy an ORDER BY.
#
# 		) Sorting index
#
# 			The thread is sorting index pages for more efficient accessing during a MyISAM table optimization operation.
#
# 		) Sorting result
#
# 			For a SELECT statement, this is similar to Creating sort index, but for nontemporary tables.
#
# 		) statistics
#
# 			The server is calculating statistics to develop a query execution plan.
#
# 			If a thread is in this state for a long time, the server is probably disk-bound
# 			performing other work.
#
# 		) System lock
#
# 			The thread has called mysql_lock_tables() and the thread state has not been updated since.
#
# 			This is a very general state that cna occur for many reasons.
#
# 			FOr example, the thread is going to request or is waiting for an internal or external system lock for the table.
#
# 			THis can occur when InnoDB waits for a table-level lock during execution of LOCK_TABLES.
#
# 			IF this state is being caused by requests for external locks and you are not using multiple mysqld servers
# 			that are accessing the same MyISAM tables, you can disable external system locks with the --skip-external-locking option.
#
# 			However, external locking is disabled by default, so it is likely that htis option will ahve no effect.
#
# 			For SHOW_PROFILE, this state means the thread is requesting the lock (not waiting for it)
#
# 			For system tables, the Locking system tables state is used instead.
#
# 		) update
#
# 			The thread is getting ready to start updating the table.
#
# 		) Updating
#
# 			The thread is searching for rows to update and is updating them.
#
# 		) Updating main table
#
# 			The server is executing the first part of a multiple-table update. It is updating only
# 			and saving columns and offsets to be used for updating the other (reference) tables.
#
# 		) updating reference tables
#
# 			The server is executing the second part of a multiple-table update and updating the matched rows
# 			from the other tables.
#
# 		) User lock
#
# 			The thread is going to request or is waiting for an advisory lock requested with a GET_LOCK() call.
# 			For SHOW_PROFILE, this state means the thread is requesting the lock (not waiting for it)
#
# 		) User sleep
#
# 			The thread has invoked a SLEEP() call
#
# 		) Waiting for commit lock
#
# 			FLUSH TABLES WITH READ LOCK is waiting for a commit lock.
#
# 		) Waiting for global read lock
#
# 			FLUSH TABLES WITH READ LOCK is waiting for a global read lock or the global read only system variable is being set.
#
# 		) Waiting for tables
#
# 			The thread got a notification that the underlying structure for a table has changed and it needs
# 			to reopen the table to get the new structure.
#
# 			However, to reopen the table, it must wait until all other threads have closed the table in question.
#
# 			This notification takes place if another thread has used FLUSH_TABLES or one of the following statements
# 			on the table in question:
#
# 			FLUSH TABLES tbl_name, ALTER TABLE, RENAME TABLE, REPAIR TABLE, ANALYZE TABLE or OPTIMIZE TABLE
#
# 		) Waiting for table flush
#
# 			The thread is executing FLUSH TABLES and is waiting for all threads to close their tables,
# 			or the thread got a notification that the underlying structure for a table has changed and
# 			it needs to reopen the table to get the new structure.
#
# 			However, to reopen the table, it must wait until all other threads have closed the table
# 			in question.
#
# 			This notification takes place if another thread has used FLUSH TABLES or one of the following
# 			statements on the table in question:
#
# 			FLUSH TABLES tbl_name, ALTER_TABLE, RENAME_TABLE, REPAIR_TABLE, ANALYZE_TABLE or OPTIMIZE_TABLE.
#
# 		) Waiting for lock_type lock
#
# 			The server is waiting to acquire a THR_LOCK lock or a lock from the metadata locking subsystem,
# 			where lock_type indicates the type of lock.
#
# 			This state indicates a wait for a THR_LOCK:
#
# 				) Waiting for table level lock
#
# 			These states indicate a wait for a metadata lock:
#
# 				) Waiting for event metadata lock
#
# 				) Waiting for global read lock
#
# 				) Waiting for schema metadata lock
#
# 				) Waiting for stored function metadata lock
#
# 				) Waiting for stored procedure metadata lock
#
# 				) Waiting for table metadata lock
#
# 				) Waiting for trigger metadata lock
#
# 			For information about table lock indicators, see 8.11.1, "INTERNAL LOCKING METHODS"
#
# 			For information about metadata locking, see Section 8.11.4, "Metadata Locking"
#
# 			To see which locks are blocking lock requests, use the Performance Schema lock tables
# 			described in Section 26.12.12 "PERFORMANCE SCHEMA LOCK TABLES"
#
# 		) Waiting on cond
#
# 			A generic state in which the thread is waiting for a condition to become true.
# 			No specific state information is available.
#
# 		) Writing to net
#
# 			The server is writing a packet to the network.
#
# REPLICATION MASTER THREAD STATES
#
# The following list shows the most common states you may see in the State column for the
# master's Binlog Dump thread.
#
# If you see no Binlog Dump threads on a master server, this means that replication is not
# running; that is, that no slaves are currently connected.
#
# 		) Finished reading one binlog; switching to next binlog
#
# 			The thread has finished reading a binary log file and is opening the next one to send to the slave.
#
# 		) Master has sent all binlog to slave; waiting for more updates
#
# 			The thread has read all remaining updates from the binary logs and sent them to the slave.
#
# 			The thread is now idle, waiting for new events to appear in the binary log resulting
# 			from new updates occurring on the master.
#
# 		) Sending binlog event to slave
#
# 			Binary log consists of events, where an event is usually an update plus some other information.
#
# 			The thread has read an event from the binary log and is now sending it to the slave.
#
# 		) Waiting to finalize termination
#
# 			A very brief state that occurs as the thread is stopping.
#
# REPLICATION SLAVE I/O THREAD STATES
#
# The following list shows the most common states you see in the State column for a slave server I/O thread.
#
# This state also appears in the Slave_IO_State column displayed by SHOW_SLAVE_STATUS, so you can get
# a good view of what is happening by using that statement.
#
# 		) Checking master version
#
# 			A state that occurs very briefly, after the connection to the master is established.
#
# 		) Connecting to master
#
# 			The thread is attempting to connect to the master
#
# 		) Queuing master event to the relay log
#
# 			The thread has read an event and is copying it to the relay log so that the SQL thread can process it.
#
# 		) Reconnecting after a failed binlog dump request
#
# 			The thread is trying to reconnect to the master.
#
# 		) Reconnecting after a failed master event read
#
# 			The thread is trying to reconnect to the master.
#
# 			When connection is established again, the state becomes Waiting for master to send event.
#
# 		) Registering slave on master
#
# 			A state that occurs very briefly after the connection to the master is established.
#
# 		) Requesting binlog dump
#
# 			A state that occurs very briefly, after the connection to the master is established.
#
# 			The thread sends to the master a request for the contents of its binary logs,
# 			starting from the requested binary log file name and position.
#
# 		) Waiting for its turn to commit
#
# 			A state that occurs when the slave thread is waiting for older worker threads to commit if
# 			slave_preserve_commit_order is enabled.
#
# 		) Waiting for master to  send event
#
# 			The thread has connected to the master and is waiting for binary log events to arrive.
#
# 			This can last for a long time if the master is idle.
#
# 			If the wait lasts for slave_net_timeout seconds, a timeout occurs.
#
# 			At that point, the thread considers the connection to be broken and makes an attempt to reconnect.
#
# 		) Waiting for master update
#
# 			The initial state before Connecting to master.
#
# 		) Waiting for slave mutex on exit
#
# 			A state that occurs briefly as the thread is stopping.
#
# 		) Waiting for the slave SQL thread to free enough relay log space
#
# 			You are using a nonzero relay_log_space_limit value, and the relay logs have grown
# 			large enough that their combined sized exceeds this value.
#
# 			The I/O thread is waiting until the SQL thread frees enough space by processing relay log contents
# 			so that it can delete some relay log files.
#
# 		) Waiting to reconnect after a failed binlog dump request
#
# 			If the binary log dump request failed (due to disconnection), the thread goes into this state
# 			while it sleeps, then tries to reconnect periodically.
#
# 			The interval between retries can be specified using the CHANGE_MASTER_TO statement.
#
# 		) Waiting to reconnect after a failed master event read
#
# 			An error occurred while reading (due to disconnection). 
#
# 			The thread is sleeping for the number of seconds set by the CHANGE_MASTER_TO statement
# 			(default to 60) before attempting to reconnect.
#
# REPLICATION SLAVE SQL THREAD STATES
#
# The following list shows the most common states you may see in the State column for a slave server SQL thread:
#
# 		) Killing SLave
#
# 			The thread is processing a STOP SLAVE statement
#
# 		) Making temporary file (append) before replaying LOAD DATA INFILE
#
# 			The thread is executing a LOAD_DATA_INFILE statement and is appending the data to a temporary file
# 			containing the data from which the slave will read rows.
#
# 		) Making temporary file (create) before replaying LOAD DATA INFILE
#
# 			The thread is executing a LOAD_DATA_INFILE statement and is creating a temporary file containing
# 			the data from which the slave will read rows.
#
# 			This state can only be encountered if the original LOAD_DATA_INFILE statement was logged by a master
# 			running a version of MySQL lower than 5.0.3
#
# 		) Reading event from the relay log
#
# 			The thread has read an event from the relay log so that the event can be processed.
#
# 		) Slave has read all relay log; waiting for more updates
#
# 			The thread has processed all events in the relay log files, and is not waiting for the
# 			I/O thread to write new events to the relay log.
#
# 		) Waiting for an event from Coordinator
#
# 			Using the multithreaded slave (slave_parallel worker is greater than 1), one of the slave worker
# 			threads is waiting for an event from the coordinator thread.
#
# 		) Waiting for slave mutex on exit
#
# 			A very brief state that occurs as the thread is stopping.
#
# 		) Waiting for Slave Workers to free pending events
#
# 			This waiting action occurs when the total size of events being processed by Workers exceeds
# 			the size of the slave_pending_jobs_size_max system variable.
#
# 			The Coordinator resumes scheduling when the size drops below this limit.
#
# 			This state occurs only when slave_parallel_workers is set greater than 0.
#
# 		) Waiting for the next event in relay log
#
# 			The intial state before Reading event from the relay log.
#
# 		) Waiting until MASTER_DELAY seconds after master executed event
#
# 			The SQL thread has read an event but is waiting for the slave delay to lapse.
# 			This delay is set with the MASTER_DELAY option of CHANGE_MASTER_TO.
#
# The Info column for the SQL thread may also show the text of a statement.
#
# This indicates that the thread has read an event from the relay log, extracted the statement
# from it, and may be executing it.
#
# REPLICATION SLAVE CONNECTION THREAD STATES
#
# These thread states occur on a replication slave but are associated with connection threads,
# not with the I/O or SQL threads.
#
# 		) Changing master
#
# 			The thread is processing a CHANGE_MASTER_TO statement
#
# 		) Killing slave
#
# 			The thread is processing a STOP SLAVE statement
#
# 		) Opening master dump table
#
# 			This state occurs after Creating table from master dump
#
# 		) Reading master dump table data
#
# 			This state occurs after Opening master dump table
#
# 		) Rebuilding the index on master dump table
#
# 			THis state occurs after Reading master dump table data.
#
# NDB CLUSTER THREAD STATES
#
# ) Committing events to binlog
#
# ) Opening mysql.ndb_apply_status
#
# ) Processing events
#
# 		The thread is processing events for binary logging
#
# ) Processing events from schema table
#
# 		The thread is doing the work of schema replication
#
# ) Shutting down
#
# ) Syncing ndb table schema operation and binlog
#
# 		This is used to have a correct binary log of schema operations for NDB
#
# ) Waiting for allowed to take ndbcluster global schema lock
#
# 		The thread is waiting for permission to take a global schema lock
#
# ) Waiting for event from ndbcluster
#
# 		The server is acting as an SQL node in an NDB cluster, and is connected to a cluster management node.
#
# ) Waiting for first event from ndbcluster
#
# ) Waiting for ndbcluster binlog update to reach current position
#
# ) Waiting for ndbcluster global schema lock
#
# 		The thread is waiting for a global schema lock held by another thread to be released.
#
# ) Waiting for ndbcluster to start
#
# ) Waiting for schema epoch
#
# 		The thread is waiting for a schema epoch (that is, a global checkpoint)
#
# EVENT SCHEDULER THREAD STATES
#
# These states occur for the Event Scheduler thread, threads that are created to execute scheduled events, or threads that
# terminate the scheduler.
#
# ) Clearing
#
# 		The scheduler thread or a thread that was executing an event is terminating and is about to end.
#
# ) Initialized
#
# 		The scheduler thread or a thread that will execute an event has been initialized.
#
# ) Waiting for next activation
#
# 		The scheduler has a nonempty event queue but the next activation is in the future.
#
# ) Waiting for scheduler to stop
#
# 		The thread issued SET GLOBAL event_scheduler=OFF and is waiting for the scheduler to stop.
#
# ) Waiting on empty queue
#
# 		The scheduler's event queue is empty and it is sleeping.
#
# LANGUAGE STRUCTURE
#
# This chapter discusses the rules for writing the following elements of SQL statements when using MySQL:
#
# 		) Literal values such as strings and numbers
#
# 		) Identifiers such as database, table and column names
#
# 		) Keywords and reserved words
#
# 		) User-defined and system variables
#
# 		) Comments
#
# LITERAL VALUES
#
# This section describes how to write literal values in MYSQL.
# These include strings, numbers, hexadecimal and bit values, boolean values and NULL.
#
# The section also covers various nuances that you may encounter when dealing with these basic types
# in MySQL.
#
# STRING LITERALS
#
# A string is a sequence of bytes of characters, enclosed within either single quote (') or double
# quote (") characters.
#
# Examples:
#
# 		'a string'
# 		"another string"
#
# Quoted strings placed next to each other are concatenated to a single string.
#
# The following lines are equivalent:
#
# 		'a string'
# 		'a' ' ' 'string'
#
# If the ANSI_QUOTES SQL mode is enabled, string literals can be quoted only within single
# quotation marks because a string quoted within double quotation marks is interpreted as an identifier.
#
# A binary string is a string of bytes. Every binary string has a character set and collation named binary.
#
# A nonbinary string is a string of characters.
#
# It has a character set other than binary and a collation that is compatible with the character set.
#
# For both types of strings, comparisons are based on the numeric values of the string unit.
# For binary strings, the unit is the byte; Comparisons using numeric byte values.
#
# FOr nonbinary strings, the unit is the character and some character sets support multibyte characters;
# comparisons use numeric character code values.
#
# Character code ordering is a function of the string collation.
#
# (For more information, See SECTION 10.8.5 "THE BINARY COLLATION COMPARED TO _BIN COLLATIONS")
#
# A character string literal may have an optional character set introducer and COLLATE clause,
# to designate it as a string that uses a particular character set and collation:
#
# 		[_charset_name]'string' [COLLATE collation_name]
#
# Examples:
#
# 		SELECT _latin1'string';
# 		SELECT _binary'string';
# 		SELECT _utf8'string' COLLATE utf8_danish_ci;
#
# You can use N'literal' (or n'literal') to create a string in the national character set.
# These statements are equivalent:
#
# 		SELECT N'some text';
# 		SELECT n'some text';
# 		SELECT _utf8'some text';
#
# For information about these forms of string syntax, See SECTION 10.3.7, "THE NATIONAL CHARACTER SET", and SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# Within a string, certain sequences have special meaning unless the NO_BACKSLASH_ESCAPES SQL mode is enabled.
# Each of these sequences begins with a backslash (\), known as the escape character.
#
# MySQL recognizes the escape sequences shown soon.
#
# For all other escape sequences, backslash is ignored.
# That is, the escaped character is interpreted as if it was not escaped.
#
# For example, \x is just x. These sequences are case-sensitive.
#
# For example, \b is interpreted as Backspace, but \B is interpted as B.
#
# Escape processing is done according to the character set indicated by the character_set_connection
# system variable.
#
# This is true even for strings that are preceded by an introducer that indicates a different character set,
# as discussed in SECTION 10.3.6, "CHARACTER STRING LITERAL CHARACTER SET AND COLLATION"
#
# SPECIAL CHARACTER ESCAPE SEQUENCES
#
# Escape Sequence 	Character Represented by Sequence
#
# 	\0 					 An ASCII NUL (X'00') character
#  \' 					 A single quote (') character
#
#  \" 					A double quote (") character
#  \b 					A backspace character
#
# 	\n 					A newline (linefeed) character
# 	\r 					A carriage return character
#  \t 					A tab character
#
# 	\Z 					ASCII 26 (Control+Z); see note following the table
# 	\\ 					A backslash (\) character
# 	\% 					A % character; see note following the table
# 	\_ 					A _ character; see note following the table
#
# The ASCII 26 character can be encoded as \Z to enable you to work around the problem that ASCII 26
# stands for EOF on Windows.
#
# ASCII 26 within a file causes problems if you try to use mysql db_name < file_name
#
# The \% and \_ sequences are used to search for literal instances of % and _ in pattern-matching
# contexts where they would otherwise be interpreted as wildcard characters.
#
# See the description of the LIKE operator in SECTION 12.5.1 "STRING COMPARISON FUNCTIONS"
#
# If you use \% or \_ outside of pattern-matching contexts, they evaluate to the strings \% and \_, not % and _
#
# There are several ways to include quote characters within a string:
#
# 		) A ' inside a string quoted with ' may be written as ''
#
# 		) A " inside a string quoted with " may be written as ""
#
# 		) Precede the quote character by an escape character (\)
#
# 		) A ' inside a string quoted with " needs no special treatment and need not be 
# 			doubled or escaped.
#
# 			In the same way, " inside a string quoted with ' needs no special treatment.
#
# The following SELECT statements demonstrate how quoting and escaping work:
#
# 		SELECT 'hello', '"hello"', '""hello""', 'hel''lo', '\'hello';
# 		+--------+----------+------------+---------+-----------+
# 		| hello  | "hello"  | ""hello""  | hel'lo  | 'hello    |
# 		+--------+----------+------------+---------+-----------+
#
# 		SELECT "hello", "'hello'", "''hello''", "hel""lo", "\"hello";
# 		+--------+----------+------------+---------+-----------+
# 		| hello  | 'hello'  | ''hello''  | hel"lo  | "hello 	 |
# 		+--------+----------+------------+---------+-----------+
#
# 
# 		SELECT 'This\nIs\nFour\nLines';
# 		+----------------+
# 		| This 			  |
# 		| Is 				  |
# 		| Four 			  |
# 		| Lines 			  |
# 		+----------------+
#
# 		SELECT 'disappearing\ backslash';
# 		+------------------------+
# 		| disappearing backslash |
#  	+------------------------+
#
# To insert binary data into a string column (such as a BLOB column), you should represent certain characters by
# escape sequences.
#
# Backslash (\) and the quote character used to quote the string must be escaped.
#
# In certain client environments, it may also be necessary to escape NULL or Control+Z.
#
# The mysql client truncates quoted strings containing NUL characters if they are not escaped,
# and Control+Z may be taken for EOF on Windows if not escaped.
#
# For the escape sequences that represent each of these characters, see Special Character Escape Sequences.
#
# When writing application programs, any string that might contain any of these special characters
# must be properly escaped before the string is used as a data value in an SQL statement that is
# sent to the MySQL server.
#
# You can do this in two ways:
#
# 		) Process the string with a function that escapes the special characters.
#
# 			In a C program, you can use the mysql_real_escape_string_quote() C API function
# 			to escape characters.
#
# 			See SECTION 28.7.7.56 "MYSQL_REAL_ESCAPE_STRING_QUOTE()"
#
# 			Within SQL statements that construct other SQL statements, you can use the
# 			QUOTE() function.
#
# 			The Perl DBI interface provides a quote method to convert special characters
# 			to the proper escape sequences.
#
# 			See SECTION 28.9, "MYSQL PERL API"
#
# 			Other language interfaces may provide a similar capability.
#
# 		) As an alternative to explicitly escaping special characters, many MySQL APIs provide
# 			a placeholder capability that enables you to insert special markers into a statement string,
# 			and then bind data values to them when you issue the statement.
#
# 			In this case, the API takes care of escaping special characters in the values for you.
#
# NUMERIC LITERALS
#
# Number literals include exact-value (integer and DECIMAL) literals and approximate value (floating point) literals.
#
# Integers are represented as a sequence of digits. Numbers may include . as a decimal separator.
#
# NUmbers may be preceded by - or + to indicate a negative or positive values, respectively.
#
# Numbers represented in scientific notation with a mantissa and exponent are approximate-value numbers.
#
# Exact-value numeric literals have an integer part or fractional part, or both.
#
# They may be signed. Examples 1, .2, 3.4, -5, -6.78, +9.10
#
# Approximate-value numeric literals are represented in scientific notation with a mantissa and exponent.
# Either or both partys may be signed. Examples:
#
# 1.2E3, 1.2E-3, -1.2E3, -1.2E-3
#
# Tow numbers that look similar may be treated differently. For example, 2.34 is an exact-value (fixed point)
# number, whereas 2.34E0 is an approximate value (floating point numbers)
#
# The DECIMAL data type is a fixed-point type and calculations are exact.
#
# In MySQL, the DECIMAL type has several synonyms: NUMERIC, DEC, FIXED.
#
# The integer types also are exact-value types.
#
# For more info about exact value calculations, see SECTION 12.24 "PRECISION MATH"
#
# The FLOAT and DOUBLE data types are floating-point types and calculations are approximate.
# In MySQL, types that are synonymous with FLOAT or DOUBLE are DOUBLE PRECISION and REAL.
#
# An integer may be used in a floating-point context; it is interpreted as the equivalent
# floating-point number.
#
# DATE AND TIME LITERALS
#
# Date and time values can be represented in several formats, such as quoted strings or as numbers,
# depending on the exact type of the value and other factors.
#
# For example, in contexts where MySQL expects a date, it interprets any of '2015-07-21',
# '20150721' and 20150721 as a date.
#
# This section describes the acceptable formats for date and time literals.
#
# For more information about the temporal data types, such as the range of permitted values,
# consult these sections:
#
# 		) SECTION 11.1.2, "DATE AND TIME TYPE OVERVIEW"
#
# 		) SECTION 11.3, "DATE AND TIME TYPES"
#
# Standard SQL and ODBC Date and Time Literals.
# Standard SQL permits temporal literals to be specified using a type keyword
# and a string.
#
# The space between the keyword and string is optional.
#
# 		DATE 'str'
# 		TIME 'str'
# 		TIMESTAMP 'str'
#
# MySQL recognizes those constructions and also the corresponding ODBC syntax:
#
# 		{ d 'str' }
# 		{ t 'str' }
# 		{ ts 'str' }
#
# MySQL uses the type keyword and these constructions produce DATE, TIME and DATETIME values, respectively, including
# a trailing fractional seconds part if specified.
#
# The TIMESTAMP syntax produces a DATETIME value in MySQL because DATETIME has a range that
# more closely corresponds to the standard SQL TIMESTAMP type, which has a year range from
# 0001 to 9999.
#
# (The MySQL TIMESTAMP year range is 1970 to 2038)
#
# String and Numeric Literals in Date and Time Context. MySQL recognizes DATE values in these formats:
#
# 		) As a string in either 'YYYY-MM-DD' or 'YY-MM-DD' format. A "relaxed" syntax is permitted:
#
# 			Any punctuation character may be used as the delimiter between date parts.
#
# 			For example, '2012-12-31', '2012/12/31', '2012^12^31' and '2012@12@31' are equivalent.
#
# 		) As a string with no delimiters in either 'YYYYMMDD' or 'YYMMDD' format, provided that the string
# 			makes sense as a date.
#
# 			For example, '20070523' and '070523' are interpreted as '2007-05-23', but '071332' is illegal
# 			(it has nonsensical month and day parts) and becomes '0000-00-00'
#
# 		) As a number in either YYYYMMDD or YYMMDD format, provided that the number makes sense as a date.
# 			For example, 19830905 and 830905 are interpreted as '1983-09-05'
#
# MySQL recognizes DATETIME and TIMESTAMP values in these formats:
#
# 		) As a string in either 'YYYY-MM-DD HH:MM:SS' or 'YY-MM-DD HH:MM:SS' format.
#
# 			A "relaxed" syntax is permitted here, too:
#
# 				Any punctuation character may be used as the delimiter between date parts
# 				or times parts.
#
# 				For example, '2012-12-31 11:30:45', '2012^12^31 11+30+45', '2012/12/31 11*30*45'
# 				and '2012@12@31 11^30^45' are equivalent.
#
# 				The only delimiter recognized between a date and time part and a fractional second part
# 				is the decimal point.
#
# 				The date and time parts can be separated by T rather than a space. For example, '2012-12-31 11:30:45'
# 				'2012-12-31T11:30:45' are equivalent.
#
# 		) As a string with no delimiters in either 'YYYYMMDDHHMMSS' or 'YYMMDDHHMMSS' format, provided that the string
# 			makes sense as a date.
#
# 			For example '20070523091528' and '070523091528' are interpreted as '2007-05-23 09:15:28', but the other is illegal,
# 			(Due to violation on minute part) and becomes '0000-00-00 00:00:00'
#
# 		) As a number in either YYYYMMDDHHMMSS or YYMMDDHHMMSS format, provided that the number makes sense as a date.
#
# 			For example, 19830905132800 and 830905132800 are both interpreted as:
#
# 				'1983-09-05 13:28:00'
#
# A DATETIME or TIMESTAMP value can include a trailing fractional second part in up to microseconds (6 digits) precision.
#
# The fractional part should always be separated from the rest of the time by a decimal point;
# No other fractional seconds delimiter is recognized.
#
# For information about fractional seconds support in MySQL, see SECTION 11.3.6, "FRACTIONAL SECONDS IN TIME VALUES"
#
# Dates containing two-digit year values are ambiguous because teh century is unknown.
#
# MySQL interprets two-digit year values using these rules:
#
# 		) year values in the range 70-99 are converted to 1970-1999
#
# 		) Year values in the range 00-69 are converted to 2000-2069
#
# See also SECTION 11.3.8, "TWO-DIGIT YEARS IN DATES"
#
# For values specified as strings that include date part delimiters, it is unnecessary to specify
# two digits for month or day values that are less than 10.
#
# '2015-6-9' is the same as '2015-06-09'.
#
# Similarly, for values specified as strings that include time part delimiters, it is unnecessary
# to specify two digits for hour, minute or second values that are less than 10.
#
# '2015-10-30 1:2:3' is the same as '2015-10-30 01:02:03'
#
# Values specified as numbers should be 6, 8, 12 or 14 digits long.
#
# If a number is 8 or 14 digits long, it is assumed to be in YYYYMMDD or YYYYMMDDHHMMSS format and
# that the year is given by the first 4 digits.
#
# If the number is 6 or 12 digits long, it is assumed to be in YYMMDD or YYMMDDHHMMSS format and
# that hte year is given by the first 2 digits.
#
# Numbers that are not one of these lengths are interpreted as though padded with leading zeros to
# the closest length.
#
# Values specified as nondelimited strings are interpreted according to their length.
# For a string 8 or 14 characters long, the year is assumed to be given by the first 4 characters.
#
# Otherwise, the year is assumed to be given by the first 2 characters.
#
# The string is interpreted from left to right to find year, month, day, hour, minute and
# second values, for as many parts as are present in the string.
#
# This means you should not use strings that have fewer than 6 characters.
#
# For example, if you specify '9903', thinking that represents March, 1999, MySQL converts
# it to the "zero" date value.
#
# This occurs because the year and month values are 99 and 03, but the day part is
# completely missing.
#
# However, you can explicitly specify a value of zero to represent missing month or day parts.
# For example, to insert the value '1999-03-00', use '990300'
#
# MySQL recognizes TIME values in these formats:
#
# 		) As a string in 'D HH:MM:SS' format. You can also use one of the following "relaxed" syntaxes:
#
# 			'HH:MM:SS', 'HH:MM', 'D HH:MM', 'D HH' or 'SS'
#
# 			Here D is day, it can range from 0 to 34
#
# 		) As a string with no delimiters in 'HHMMSS' format, provided that it makes sense as a time.
#
# 			For example, '101112' is understood as '10:11:12', but '109712' is illegal (it has a nonsensical
# 			minute part) and becomes '00:00:00'
#
# 		) As a number in HHMMSS format, provided that it makes sense as a time.
#
# 			For example, 101112 is understood as '10:11:12'
#
# 			The following alternative formats are also understood: SS, MMSS, or HHMMSS
#
# A trailing fractional seconds part is recognized in the 'D HH:MM:SS.fraction', 'HH:MM:SS.fraction' and
# HHMMSS.fraction time formats, where fraction is the fractional part in up to microseconds (6 digits) precision.
#
# The fractional part should always be separated from the rest of the time by a decimal point, no other
# fractional seconds delimiter is recognized.
#
# For information about fractional seconds support in MySQL, see 11.3.6 "FRACTIONAL SECONDS IN TIME VALUES"
#
# For TIME values specified as strings that include a time part delimiter, it is unnecessary to specify
# two digits for hours, minutes or seconds values that are less than 10.
#
# '8:3:2' is the same as '08:03:02'
#
# HEXADECIMAL LITERALS
#
# Hexadecimal literal values are written using X'val' or 0xval notation, where val contains
# hexadecimal digits (0..9, A..F)
#
# Lettercase of the digits and of any leading X does not matter.
#
# A leading 0x is case-sensitive and cannot be written as 0X
#
# Legal hexaecimal literals:
#
# 		X'01AF'
# 		X'01af'
# 		x'01AF'
# 		x'01af'
# 		0x01AF
# 		0x01af
#
# Illegal hexadecimal literals:
#
# 		X'0G' (G is not a hexadecimal digit)
# 		0X01AF (0X must be written as 0x)
#
# Values written using X'val' notation must contain en even number of digits or a syntax error occurs.
# To correct the problem, pad the value with a leading zero:
#
# 		SET @s = X'FFF';
# 		ERROR 1064 (42000): You have an error in your SQL syntax;
# 		check the manual that corresponds to your MySQL server
# 		version for the right syntax to use near 'X'FFF''
#
# 		SET @s = X'0FFF';
# 		QUery OK, 0 rwos affected (0.00 sec)
#
# Values written using 0xval notation that contain an odd number of digits are treated as having
# an extra leading 0.
#
# For example, 0xaaa is interpreted as 0x0aaa
#
# By default, a hexadecimal literal is a binary string, where each pair of hexadecimal digits represent a character:
#
# 		SELECT X'4D7953514C', CHARSET(X'4D7953514C');
# 		+-------------------+------------------------+
# 		| X'4D7953514C' 	  | CHARSET(X'4D7953514C') |
# 		+-------------------+------------------------+
# 		| MySQL 				  | binary 					   |
# 		+-------------------+------------------------+
#
# 		SELECT 0x5461626c65, CHARSET(0x5461626c65);
# 		+-------------------+------------------------+
# 		| 0x5461626c65 	  | CHARSET(0x5461626c65 	|
# 		+-------------------+------------------------+
# 		| Table 			  	  | binary 						|
# 		+-------------------+------------------------+
#
# A hexadecimal literal may have an optional character set introducer and COLLATE clause,
# to designate it as a string that uses a particular character set and collation:
#
# 		[_charset_name] X'val' [COLLATE collation_name]
#
# Examples:
#
# 		SELECT _latin1 X'4D7953514C';
# 		SELECT _utf8 0x4D7953514C COLLATE utf8_danish_ci;
#
# The examples use X'val' notation, but 0xval notation permits introducers as well.
# For information about introducers, see SECTION 10.3.8 "CHARACTER SET INTRODUCERS"
#
# In numeric contexts, MySQL treats a hexadecimal literal like a BIGINT(64-bit integer)
#
# To ensure numeric treatment of a hexadecimal literal, use it in numeric context.
# Ways to do this include adding 0 or using CAST(--- AS UNSIGNED)
#
# For example, a hexadecimal literal assigned to a user-defined variable is a binary string
# by default.
#
# To assign the value as a number, use it in numeric context:
#
# 		SET @v1 = X'41';
# 		SET @v2 = X'41'+0;
# 		SET @v3 = CAST(X'41' AS UNSIGNED);
# 		SELECT @v1, @v2, @v3;
# 		+--------+---------+----------+
# 		| @v1 	| @v2 	 | @v3 		|
# 		+--------+---------+----------+
# 		| A 		| 65 		 | 65 		|
# 		+--------+---------+----------+
#
# An empty hexadecimal value (X'') evaluates to a zero-length binary string.
# Converted to a number, it produces 0:
#
# 		SELECT CHARSET(X''), LENGTH(X'');
# 		+--------------------+-----------------+
# 		| CHARSET(X'') 		| LENGTH(X'') 	   |
# 		+--------------------+-----------------+
# 		| binary 				| 				0 		|
# 		+--------------------+-----------------+
#
# 		SELECT X''+0;
# 		+------------+
# 		| X''+0 	    |
# 		+------------+
# 		| 0 			 |
# 		+------------+
#
# The X'val' notation is based on standard SQL. The 0x notation is based on ODBC, for which hexadecimal strings
# are often used to supply values for BLOB columns.
#
# To convert a string or a number to a string in hexadecimal format, use teh HEX() function:
#
# 		SELECT HEX('cat');
# 		+-------------------+
# 		| HEX('cat') 		  |
# 		+-------------------+
# 		| 636174  			  |
# 		+-------------------+
#
# 		SELECT X'636174';
# 		+----------------+
# 		| X'636174' 	  |
# 		+----------------+
# 		| cat 			  |
# 		+----------------+
#
# For hexadecimal literals, bit operations are considered numeric context, but bit operations permit numeric
# or binary string arguments in MySQL 8.0 and higher.
#
# To explicitly specify binary string context for hexadecimal literals, use a _binary introducer for at least
# one of the arguments:
#
# 		SET @v1 = X'000D' | X'0BC0';
# 		SET @v2 = _binary X'000D' | X'0BC0';
# 		SELECT HEX(@v1), HEX(@v2);
#
# 		+------------+---------------+
# 		| HEX(@v1) 	 | HEX(@v2) 	  |
# 		+------------+---------------+
# 		| BCD 		 | 0BCD 			  |
# 		+------------+---------------+
#
# The displayed result appears similar for both bit operations, but the result without 
# _binary is a BIGINT, whereas the result with _binary is a binary string.
#
# Due to the difference in result types, the displayed values differ:
#
# High-order 0 digits are not displayed for the numeric result.
#
# BIT-VALUE LITERALS
#
# Bit-value literals are written using b'val' or 0bval notation.
#
# val is a binary value written using zeros and ones.
# Lettercase of any leading b does not matter.
#
# A leading 0b is case sensitive and cannot be written as 0B.
#
# Legal bit value literals:
#
# 		b'01'
# 		B'01'
# 		0b01
#
# Illegal bit-value literals:
#
# 		b'2' 		(2 is not a binary digit)
# 		0b01 		(0B must be written as 0b)
#
# By default, a bit-value literal is a binary string:
#
# 		SELECT b'1000001', CHARSET(b'1000001');
# 		+---------------+----------------------+
# 		| b'1000001' 	 | CHARSET(b'1000001') 	|
# 		+---------------+----------------------+
# 		| A 				 | binary 					|
# 		+---------------+----------------------+
#
# 		SELECT 0b1100001, CHARSET(0b1100001);
# 		+---------------+----------------------+
# 		| 0b1100001 	 | CHARSET(0b1100001)   |
# 		+---------------+----------------------+
# 		| a 				 | binary 				   |
# 		+---------------+----------------------+
#
# A bit-value literal may have an optional character set introducer and COLLATE clause, to designate it
# as a string that uses particular character set and collation:
#
# 		[_charset_name] b'val' [COLLATE collation_name]
#
# Examples:
#
# 		SELECT _latin1 b'1000001';
# 		SELECT _utf8 0b1000001 COLLATE utf8_danish_ci;
#
# The examples use b'val' notation, but 0bval notation permits introducers as well.
#
# For information about introducers, see SECTION 10.3.8 "CHARACTER SET INTRODUCERS"
#
# In numeric contexts, MySQL treats a bit literal like an integer.
# To ensure numeric treatment of a bit literal, use it in numeric context.
#
# Ways to do this include adding 0 or using CAST(--- AS UNSIGNED)
#
# For example, a bit literal assigned to a user-defined variable is a binary string by default.
# To assign the value as a number, use it in numeric context:
#
# 		SET @v1 = b'1100001';
# 		SET @v2 = b'1100001'+0;
# 		SET @v3 = CAST(b'1100001' AS UNSIGNED);
# 		SELECT @v1, @v2, @v3;
# 		+---------+----------+----------+
# 		| @v1 	 | @v2 		| @v3 	  |
# 		+---------+----------+----------+
# 		| a 		 | 97 		| 97 		  |
# 		+---------+----------+----------+
#
# An empty bit value (b'') evaluates to a zero-length binary string.
# Converted to a number, it produces 0:
#
# 		SELECT CHARSET(b''), LENGTH(b'');
# 		+--------------+-----------------+
# 		| CHARSET(b'') | LENGTH(b'') 	   |
# 		+--------------+-----------------+
# 		| binary 		| 0 					|
# 		+--------------+-----------------+
#
# 		SELECT b''+0;
# 		+-------------+
# 		| b''+0 		  |
# 		+-------------+
# 		| 		0 		  |
# 		+-------------+
#
# Bit-value notation is convenient for specifying values to be assigned to BIT columns:
#
# 		CREATE TABLE t (b BIT(8));
# 		INSERT INTO t SET b = b '11111111';
# 		INSERT INTO t SET b = b'1010';
# 		INSERT INTO t SET b = b'0101';
#
# Bit values in result sets are returned as binary values, which may not display well.
#
# To convert a bit value to printable form, use it in numeric context or use a conversion
# function such as BIN() or HEX().
#
# High-order 0 digits are not displayed in the converted value.
#
# 		SELECT b+0, BIN(b), OCT(b), HEX(b) FROM t;
# 		+----------+-------------+------------+-------------+
# 		| b+0 	  | BIN(b) 		 | OCT(b) 	  | HEX(b) 		 |
# 		+----------+-------------+------------+-------------+
# 		| 		255  | 11111111    | 377 		  | FF 			 |
# 		| 		 10  | 1010 		 | 12 		  | A 			 |
# 		| 		  5  | 101 			 | 5 			  | 5 			 |
# 		+----------+-------------+------------+-------------+
#
# For bit literals, bit operations are considered numeric context, but bit operations
# permit numeric or binary string arguments in MySQL >= 8.0.
#
# To explicitly specify binary string context for bit literals, use a _binary introducer
# for at least one of the arguments:
#
# 		SET @v1 = b'000010101' | b'000101010';
# 		SET @v2 = _binary b'000010101' | _binary b'000101010';
# 		SELECT HEX(@v1), HEX(@v2);
# 		+------------+------------+
# 		| HEX(@v1) 	 | HEX(@v2)   |
# 		+------------+------------+
# 		| 3F 			 | 003F 		  |
# 		+------------+------------+
#
# The displayed result appears similar for both bit operations, but the result without _binary is a BIGINT value,
# whereas the result with _binary is a binary string.
#
# Due to the difference in result types, the displayed values differ: High-order 0 digits are not displayed
# for the numeric result.
#
# BOOLEAN LITERALS
#
# The constant TRUE and FALSE evaluate to 1 and 0, respectively.
# The constant names can be written in any lettercase.
#
# 		SELECT TRUE, true, FALSE, false
# 		 		 -> 1, 1, 0 , 0
#
# NULL VALUES
#
# The NULL value means "no data". NULL can be written in any lettercase.
#
# Be aware that the NULL value is different from values such as 0 for numeric types
# or the empty string for string types.
#
# For more information, see SECTION B.5.4.3, "PROBLEMS WITH NULL VALUES"
#
# For text file import or export operations performed with LOAD_DATA_INFILE or
# SELECT_---_INTO_OUTFILE NULL is represented by the \N sequence.
#
# See SECTION 13.2.7, "LOAD DATA INFILE SYNTAX"
#
# For sorting with ORDER BY, NULL values sort before other values for ascending sorts, after other values
# for descending sorts.
#
# SCHEMA OBJECT NAMES
#
# Certain objects within MySQL, include database, table, index, column, alias, view, stored procedure,
# partition, tablespace, resource group and other object names are known as identifiers.
#
# This section describes the permissible syntax for identifiers in MySQL. 
#
# SECTION 9.2.2, "IDENTIFIER CASE SENSITIVITY", describes which types of identifiers are case-sensitive
# and under what conditions.
#
# An identifier may be quoted or unquoted.
#
# If an identifier contains special characters or is a reserved word, you MUST quote it whenever you refer ot it.
# (Exception: A reserved word that follows a period in a qualified name must be an identifier, so it need not be quoted)
#
# Reserved words are listed at SECTION 9.3 "KEYWORDS AND RESERVED WORDS"
#
# Identifiers are converted to Unicode internally.
# They may contain these characters:
#
# 		) Permitted characters in unquoted identifiers:
#
# 			) ASCII: [0-9,a-z,A-Z$_] (basic Latin letters, digits 0-9, dollar, underscore)
#
# 			) Extended: U+0080 -- U+FFFF
#
# 		) Permitted characters in quoted identifiers include the full Unicode Basic Multilingual Plane (BMP), except U+0000:
#
# 			) ASCII: U+0001 -- U+007F
# 
# 			) Extended: U+0080 -- U+FFFF
#
# 		) ASCII NUL (U+0000) and supplementary characters (U+10000 and higher) are not permitted in quoted or unquoted identifiers.
#
# 		) Identifiers may begin with a digit but unless quoted may not consist solely of digits.
#
# 		) Database, table and column names cannot end with space characters
#
# THe identifier quote character is the backtick (`):
#
# 		SELECT * FROM `select` WHERE `select`.id > 100;
#
# If the ANSI_QUOTES SQL mode is enabled, it is also permissible to quote identifiers within double quotation marks:
#
# 		CREATE TABLE "test" (col INT);
# 		ERROR 1064: You have an error in your SQL syntax ---
# 		SET sql_mode='ANSI_QUOTES';
# 		CREATE TABLE "test" (col INT);
# 		Query OK, 0 rows affected (0.00 sec)
#
# The ANSI_QUOTES mode causes the server to interpret double-quoted strings as identifiers.
#
# Consequently, when this mode is enabled, string literals must be enclosed within single quotation marks.
# They cannot be enclosed within double quotation marks.
#
# The server SQL mode is controlled as described earlier.
#
# Identifier quote characters can be included within an identifier if you quote the identifier.
#
# If the character to be included within the identifier is the same as that used to quote the
# identifier itself, then you need to double the character.
#
# The following statement creates a table named a`b that contains a column named c"d:
#
# 		CREATE TABLE `a``b` (`c"d` INT);
#
# In the select list of a query, a quoted column alias can be specified using identifier
# or string quoting characters:
#
# 		SELECT 1 AS `one`, 2 AS 'two';
# 		+----------+---------+
# 		| one 	  | two 	   |
# 		+----------+---------+
# 		| 1 		  | 2 		|
# 		+----------+---------+
#
# Elsewhere in the statement, quoted references to the alias must use identifier quoting or the reference
# is treated as a string literal.
#
# IT is recommended that you do not use names that begin with Me or MeN, where M and N are integers.
#
# For example, avoid using 1e as an identifier, because an expression such as 1e+3 is ambiguous.
#
# Depending on context, it might be interpreted as the expression 1e + 3 or as the number 1e+3
#
# Be careful when using MD5() to produce table names because it can produce names in illegal or
# ambiguous formats such as those just described.
#
# A user variable cannot be used directly in an SQL statement as an identifier or as part of an
# identifier.
#
# See SECTION 9.4, "USER-DEFINED VARIABLES", for more information and examples of workarounds.
#
# Special characters in database and table names are encoded in the corresponding file system names
# as described in section 9.2.3, "MAPPING OF IDENTIFIERS TO FILE NAMES"
#
# The following table describes the maximum length for each type of identifier.
#
# 				Identifier Type 							Maximum Length (characters)
#
# 	Database 									64 (NDB storage engine: 63)
#
# 	Table 										64 (NDB storage engine: 63)
#
# 	Column 										64
#
# 	Index 										64
#
# 	Constraint 									64
#
# 	Stored Program 							64
#
# 	View 											64
#
# 	Tablespace 									64
#
# 	Server 										64
#
# 	Log File Group 							64
#
# 	Alias 										256 (see exception following table)
#
# 	Compound Statement Label 				16
#
# 	User-Defined Variable 					64
#
# 	Resource Group 							64
#
# Aliases for column names in CREATE_VIEW statements are checked against the maxium
# column length of 64 characters (not the maximum alias length of 256 characters)
#
# Identifiers are stored using Unicode (UTF-8)
#
# THis applies to identifiers in table definitions and to identifiers stored in the 
# grant tables in the mysql database.
#
# The sizes of the identifier string columns in the grant tables are measured in characters.
#
# You can use multibyte characters without reducing the number of characters permitted for values
# stored in these columns.
#
# As indicated earlier, the permissible Unicode characters are those in the Basic Multilingual Plane (BMP)
#
# Supplementary characters are not permitted.
#
# NDB Cluster imposes a maximum length of 63 characters for names of databases and tables.
# See SECTION 22.1.6.5 "LIMITS ASSOCIATED WITH DATABASE OBJECTS IN NDB CLUSTER"
#
# IDENTIFIER QUALIFIERS
#
# Object names may be unqualified or qualified.
#
# An unqualified name is permitted in contexts where interpretation of the name is unambiguous.
#
# A qualified name includes at least one qualifier to clarify the interpretive context by overriding
# a default context or providing missing context.
#
# For example, this statement creates a table using the unqualified name t1:
#
# 		CREATE TABLE t1 (i INT);
#
# Because t1 includes no qualifier to specify a database, the statement creates the table in the default database.
# If there is no default database, an error occurs.
#
# This statement creates a table using the qualified name db1.t1:
#
# 		CREATE TABLE db1.t1 (i INT);
#
# Because db1.t1 includes a database qualifier db1, the statement creates t1 in the database named db1,
# regardless of the default database.
#
# The qualifier MUST be specified if there is no default database.
#
# THe qualifier MAY be specified if there is a default database, to specify a database different from the
# default, or to make the database explicit if the default is the same as the one specified.
#
# Qualifiers have these characteristics:
#
# 		) An unqualified name consists of a single identifier. A qualified name consists of multiple identifiers.
#
# 		) The components of a multiple-part name must be separated by period (.) characters.
#
# 			The initial parts of a multiple-part name act as qualifiers that affect the context
# 			within which to interpret the final identifier.
#
# 		) The qualifier character is a separate token and need not be contiguous with the associated identifiers.
#
# 			For example, tbl_name.col_name and tbl_name . col_name are equivalent
#
# 		) If any components of a multiple-part name require quoting, quote them individually rather than quoting the name as a whole.
#
# 			For example, write `my-table`.`my-column`, not `my-table.my-column`
#
# 		) A reserved word that follows a period in a qualified name must be an identifier, so in that context it need not be quoted.
#
# The permitted qualifiers for object names depend on the object type:
#
# 		) A database name is fully qualified and takes no qualifier:
#
# 			CREATE DATABASE db1;
#
# 		) A table view, or stored program name may be given a database-name qualifier.
# 			Examples of unqualified and qualified names in CREATE statements:
#
# 			CREATE TABLE mytable ---;
# 			CREATE VIEW myview ---;
# 			CREATE PROCEDURE myproc ---;
# 			CREATE FUNCTION myfunc ---;
# 			CREATE EVENT myevent ---;
#
# 			CREATE TABLE mydb.mytable ---;
# 			CREATE VIEW mydb.myview ---;
# 			CREATE PROCEDURE mydb.myproc ---;
# 			CREATE FUNCTION mydb.myfunc ---;
# 			CREATE EVENT mydb.myevent ---;
#
# 		) A trigger is associated with a table, so any qualifier applies to the table name:
#
# 			CREATE TRIGGER mytrigger --- ON mytable ---;
#
# 			CRAETE TRIGGER mytrigger --- ON mydb.mytable ---;
#
# 		) A column name may be given multiple qualifiers to indicate context in statements that reference it,
# 			as shown in the following table.
#
# 			COLUMN REFERENCE 							MEANING
#
# 			col_name 									Column col_name from whichever table used in the statement contains a column of that name
#
# 			tbl_name.col_name 						Column col_name from table tbl_name of the default database
#
# 			db_name.tbl_name.col_name 				Column col_name from table tbl_name of the database db_name
#
# 			IN other words, a column name may be given a table-name qualifier, which itself may be given a database-name qualifier.
#
# 			Examples of unqualified and qualified column references in SELECT statements:
#
# 				SELECT c1 FROM mytable
# 				WHERE c2 > 100;
#
# 				SELECT mytable.c1 FROM mytable
# 				WHERE mytable.c2 > 100;
#
# 				SELECT mydb.mytable.c1 FROM mydb.mytable
# 				WHERE mydb.mytable.c2 > 100;
#
# YOu need not specify a qualifier for an object reference in a statement unless the unqualified reference is ambiguous.
#
# Suppose that column c1 occurs only in table t1, c2 only in t2 and c in both t1 and t2.
#
# Any unqualified reference to c is ambiguous in a statement that refers to both tables and must be qualified
# as t1.c or t2.c to indicate which table you mean:
#
# 		SELECT c1, c2, t1.c FROM t1 INNER JOIN t2
# 		WHERE t2.c > 100;
#
# SImilarly, to retrieve from a table t in database db1 and from a table t in database db2 in the same statement,
# you must qualify the table references:
#
# FOr references to columns in those tables, qualifiers are required only for column names that appear in both tables.
#
# SUppose that column c1 occurs only in table db1.t, c2 only in db2.t and c in both db1.t and db2.t
#
# In this case, c is ambiguous and must be qualified but c1 and c2 need not be:
#
# 		SELECT c1, c2, db1.t.c FROM db1.t INNER JOIN db2.t
# 		WHERE db2.t.c > 100;
#
# Table aliases enable qualified column references to be written more simply:
#
# 		SELECT c1, c2, t1.c FROM db1.t AS t1 INNER JOIN db2.t AS t2
# 		WHERE t2.c > 100;
#
# IDENTIFIER CASE SENSITIVITY
#
# In MySQL, databases correspond to directories within the data directory. Each table within a DB corresponds to
# at least one file within the DB directory (and possibly more, depending on the storage engine)
#
# Triggers also correspond to files. Consequently, the case sensitivity of the underlying OS plays a part in the
# case sensitivity of database, table and trigger names.
#
# This means such names are not case-sensitive in Windows, but are case-sensitive in most varieties of Unix.
#
# One notable exception is macOS, which is Unix-based but uses a default file system (HFS+) that is not case-sensitive.
#
# However, macOS also supports UFS volumes, which are case-sensitive just as on any Unix.
#
# The lower_case_table_names system variable also affects how the server handles identifier case sensitivity,
# as described later in this section.
#
# NOTE:
#
# 		Although database, table and trigger names are not case sensitive on some platforms, you should not refer
# 		to one of these using different cases within the same statement.
#
# 		The following statement would not work because it refers to a table both as my_table and as MY_TABLE:
#
# 			SELECT * FROM my_table WHERE MY_TABLE.col=1;
#
# COlumn, index, stored routine, event and resource group names are not case-sensitive on any platform, nor are column aliases.
#
# However, names of logfile groups are case-sensitive. This differs from standard SQL.
#
# By default, table aliases are case-sensitive on Unix, but not so on Windows or macOS.
#
# The following statement would not work on Unix, because it refers to the alias both as a and as A:
#
# 		SELECT col_name FROM tbl_name AS a
# 		WHERE a.col_name = 1 OR A.col_name = 2;
#
# however, this statement is permitted on Windows.
#
# To avoid problems caused by such differences, it is best to adopt a consistent convention, such as always
# creating and referring to databases and tables using lowercase names.
#
# This convention is recommended for maxmimum portability and ease of use.
#
# How table and database names are stored on disk and used in MySQL is affected by the lower_case_table_names system variable.
#
# Lower_case_table_names can take the values shown soon.
#
# This variable does NOT affect case sensitivity of trigger identifiers. On Unix, the default value of lower_case_table_names is 0.
#
# On Windows, it is 1. On macOS, it's 2.
#
# lower_case_table_name can only be configured when intializing the server.
# Changing the lower_case_table_names setting after the server is initialized is prohibited.
#
# 	Value 				Meaning
#
# 0 			Table and database names are stored on disk using the lettercase specified in the CREATE_TABLE or CREATE_DATABSE statement.
# 				Name comparisons are case sensitive.
#
# 				You should NOT set this variable to 0 if you are running MySQL on a system that has case-insensitive file names
# 				(Such as Windows or macOS).
#
# 				If you force this variable to 0 with --lower-case-table-names=0 on a case-insensitive file system and access MyISAM
# 				tablenames using different lettercases, and index corruption may result.
#
# 1 			Table names are stored in lowercase on disk and name comparisons are not case-sensitive.
#
# 				MySQL converts all table names to lowercase on storage and lookup.
#
# 				This behavior also applies to database names and table aliases.
#
# 2 			Table and database names are stored on disk using the lettercase specified in the CREATE_TABLE or
# 				CREATE_DATABASE statement, but MySQL converts them to lowercase on lookup.
#
# 				Name comparisons are not case sensitive.
#
# 				This works ONLY on file systems that are not case-sensitive.
#
# 				InnoDB table names and view names are stored in lowercase, as for lower_case_table_names=1
#
# If you are using MySQL on only one platform, you do not normally have to use a lower_case_table_names setting
# other than the default.
#
# However, you may encounter difficulties if you want to transfer tables between platforms that differ in file system
# case sensitivity.
#
# For example, on Unix, you can have two different tables named my_table and MY_TABLE.
#
# But on Windows, these two names are considered identical. To avoid data transfer problems arising from
# lettercase of database or table names, you have two options:
#
# 		) Use lower_case_table_names=1 on all systems. The main disadvantage with this is that when you use SHOW_TABLES
# 			or SHOW_DATABASES, you do not see the names in their original lettercase.
#
# 		) Use lower_case_table_names=0 on Unix and lower_case_table_names=2 on Windows.
#
# 			This preserves the lettercase of database and table names. 
#
# 			The disadvantage of this is that you must ensure that your statements always refer to
# 			your DB and table names with the correct lettercase on WIndows. 
 
 # 		If you transfer yourr statements to UNix, where lettercase is signifgicant,.
 # 		they do not work if the lettercase is incorrect.
 #
 # 		Exception:
 #
 # 			If you are using InnoDB tables and you are trying to avoid these data transfer problems,
 # 			you should use lower_case_table_names=1 on all platforms to force names to be converted to lowercase.
 #
 # object names may be considered duplicates if their uppercase forms are equal according to a binary collation.
 #
 # That is true for names of cursors, conditions, procedures, functions, savepoints, stored routine parameters,
 # stored program local variables, and plugins.
 #
 # It is not true for names of columns, constraints, databases, partitions, statements prepared with PREPARE,
 # tables, triggers, users and user-defined variables.
 #
 # File system case sensitivity can affect searches in string columns of INFORMATION_SCHEMA tables.
 # for more information, see SECTION 10.8.7, "USING COLLATION IN INFORMATION_SCHEMA SEARCHES"
 #
 # MAPPING OF IDENTIFIERS TO FILE NAMES
 #
 # There is a correspondance between database and table identifiers and names in the file system.
 #
 # For the basic structure, MySQL represents each database as a directory in the data directory,
 # and depending upon the storage engine, each table may be represented by one or more files in the
 # appropriate database directory.
 #
 # For the data and index files, the exact representation on disk is storage engine specific.
 #
 # These files may be stored in the database directory, or the information may be stored in a 
 # separate file.
 #
 # InnoDB data is stored in the InnoDB data files.
 #
 # If you are using tablespaces with InnoDB, then the specific tablespace file you create are used
 # instead.
 #
 # ANy character is legal in database or table identifiers, except ASCII NUL (X'00')
 #
 # MysQL encodes any characters that are problematic in the corresponding file system objects
 # when it creates DB directories or table files:
 #
 # 		) Basic latin letters (a--zA--Z), digits (0--9) and underscore (_) are encoded as is.
 #
 # 			Consequently, their case sensitivity directly depends on file system features.
 #
 # 		) All other national letters from alphabets that have uppercase/lowercase mapping are encoded 
 # 			as shown in the following table.
 #
 # 			values in the code range column are USC-2 values.
 #
 # 			Code Range 			Pattern 				Number 			Used 		UNused 		Blocks
 #
 # 			00C0--017F 			[@[0--4][g--z] 	5*20=100 		97 		3 				Latin-1 Supplement + Latin Extended-A
 #
 # 			0370--03FF 			[@[5--9][g--z] 	5*20=100 		88 		12 			Greek and Coptic
 #
 # 			0400--052F 			[@[g--z][0--6] 	20*7=140 		137 		3 				Cyrillic + Cyrillic supplement
 #
 # 			0530--058F 			[@[g--z][7--8] 	20*2=40 			38 		2 				Armenian
 #
 # 			2160--217F 			[@[g--z][9] 		20*1=20 			16 		4 				Number Forms
 #
 # 			0180--02AF 			[@[g--z][a--k] 	20*11=220 		203 		17 			Latin Extended-B + IPA Extensions
 #
 # 			1E00--1EFF 			[@[g--z][l--r] 	20*7=140 		136 		4 				Latin Extended Additional
 #
 # 			1F00--1FFF 			[@[g--z][s--z] 	20*8=160 		144 		16 			Greek extended
 #
 # 			--- --- 				[@][a--f][g--z] 	6*20=120 		0 			120 			RESERVED
 #
 # 			24B6--24E9 			[@][@][a--z] 		26 				26 		0 				Enclosed Alphanumerics
 #
 # 			FF21--FF5A 			[@][a--z][@] 		26 				26 		0 				Halfwidth and Fullwidth forms
 #
 # One of the bytes in the sequence encodes lettercase.
 #
 # For example: LATIN CAPITAL LETTER A WITH GRAVE is encoded as @0G, whereas LATIN SMALL LETTER A WITH GRAVE is encoded as @0g.
 #
 # Here the third byte (G or g) indicates lettercase. (On a case-insensitive file system, both letters will be treated as the same)
 #
 # For some blocks, such as Cyrllilic, the second byte determines lettercase.
 #
 # For other blocks, such as Latin1 Supplement, the third byte determines lettercase.
 #
 # If two bytes in the sequence are letters (as in Greek Extended), the leftmost letter character
 # stands for lettercase.
 #
 # All other letter bytes must be in lowercase.
 #
 # 	) All nonletter characters except underscore (_), as well as letters from alphabets that do not have uppercase/lowercase mapping
 # 		(such as Hebrew) are encoded using hexadecimal representations using lowercase letters for hexadecimal digits a--f:
 #
 # 			0x003F -> @003f
 # 			0xFFFF -> @ffff
 #
 # 		The hexadecimal values correspond to character values in usc2 double-byte character set.
 #
 # On Windows, some names such as nul, prn and aux are encoded by appending @@@ to the name when the server
 # creates the corresponding file or directory.
 #
 # This occurs on all platforms for portability of the corresponding database object between platforms.
 #
 # FUNCTION NAME PARSING AND RESOLUTION
 #
 # MySQL supports built-in (native) functions, user-defined functions (UDFs), and stored functions.
 #
 # This section describes how the server recognizes whether the name of a built-in function is used as
 # a function call or as an identifier, and how the server determines which function to use in cases when
 # functions of different types exists with a given name.
 #
 # BUILT-IN FUNCTION NAME PARSING
 #
 # THe parser uses default rules for parsing names of built-in functions.
 #
 # these rules can be changed by enabling the IGNORE_SPACE SQL mode.
 #
 # When the parser encounters a word that is the name of a built-in function, it must determines whether the
 # name signifies a function call or instead a nonexpression reference to an identifier such as table or column name.
 #
 # For example, in the following statements, the first reference to count is a function call, whereas the second
 # reference is a table name:
 #
 # 		SELECT COUNT(*) FROM mytable;
 # 		CREATE TABLE count (i INT);
 #
 # THe parser should recognize the name of a built-in function as indicating a function call only
 # when parsing what is expected to be an expression.
 #
 # That is, in nonexpression context, function names are permitted as identifiers.
 #
 # However, some built-in functions have special parsing or implementation considerations,
 # so the parser uses the following rules by default to distinguish whether their names are being
 # used as function calls or as identifiers in nonexpression context:
 #
 # 		) To use the name as a function call in an expression, there must be no whitespace between the name and the following ( paranthesis character.
 #
 # 		) Conversely, to use the function name as an identifier, it must not be followed immediately by a paranthesis.
 #
 # The requirement that function calls be written with no whitespace between the name and the parenthesis applies only to
 # the built-in functions that have special considerations.
 #
 # COUNT is one such name.
 #
 # THe sql/lex.h source file lists the names of these special functions for which the following whitepace determines
 # their interpretation:
 #
 # names defined by the SYM_FN() macro in the symbols[] array
 #
 # The following list names teh functions in MySQl >= 8.0 that are affected by the IGNORE_SPACE
 # setting and listed as special in the sql/lex.h source file
 #
 # You may find it easiest to treat the no-whitespace requirement as applying to all function calls:
 #
 # 		) ADDDATE
 #
 # 		) BIT_AND
 #
 # 		) BIT_OR
 #
 # 		) BIT_XOR
 #
 # 		) CAST
 #
 # 		) COUNT
 #
 # 		) CURDATE
 #
 # 		) CURTIME
 #
 # 		) DATE_ADD
 #
 # 		) DATE_SUB
 #
 # 		) EXTRACT
 #
 # 		) GROUP_CONCAT
 #
 # 		) MAX
 #
 # 		) MID
 #
 # 		) MIN
 #
 # 		) NOW
 #
 # 		) POSITION
 #
 # 		) SESSION_USER
 #
 # 		) STD
 #
 # 		) STDDEV
 #
 # 		) STDDEV_POP
 #
 # 		) STDDEV_SAMP
 #
 # 		) SUBDATE
 #
 # 		) SUBSTR
 #
 # 		) SUM
 #
 # 		) SYSDATE
 #
 # 		) SYSTEM_USER
 #
 # 		) TRIM
 #
 # 		) VARIANCE
 #
 # 		) VAR_POP
 #
 # 		) VAR_SAMP
 #
 # For functions not listed as special in sql/lex.h, whitespace does not matter.
 #
 # They are interpreted as function calls only when used in expression context and may be used
 # freely as identifiers otherwise.
 #
 # ASCII is one such name.
 #
 # However, for these nonaffected function names, interpretation may vary in expression context:
 #
 # 		func_name		() 
 #
 # is interpreted as a built-in function if there is one with the given name; if not, func_name 		() is interpreted
 # as a user-defined function or stored function if one exists with that name.
 #
 # The IGNORE_SPACE SQL mode can be used to modify how the parser treats function names that are whitespace-sensitive:
 #
 # 	) With IGNORE_SPACE disabled, the parser interprets the name as a function call when there is no whitespace between
 # 		the name nad the following paranthesis.
 #
 # 		This occurs even when the function name is used in nonexpression context:
 #
 # 			CREATE TABLE count(i INT);
 # 			ERROR 1064 (42000): You have an error in your SQL syntax ---
 # 			near 'count(i INT)'
 #
 # 		To eliminate the error and cause the name to be treated as an identifier, either use whitespace following the name
 # 		or write it as a quoted identifier (or both):
 #
 # 			CREATE TABLE count (i INT);
 # 			CREATE TABLE `count`(i INT);
 # 			CREATE TABLE `count`  (i INT);
#
# 		) WIth IGNORE_SPACE enabled, the parser loosens the requriements that there be no whitespace between the function
# 			name and the following paranthesis.
#
# 			This provides more flexibility in writing function calls.
#
# 		For example, either of the following function calls are legal:
#
# 			SELECT COUNT(*) FROM mytable;
# 			SELECT COUNT (*) FROM mytable;
#
# 		However, enabling IGNORE_SPACE also has the side effect that hte parser treats the affected
# 		function names as reserved words (see SECTION 9.3, "KEYWORDS AND RESERVED WORDS")
#
# 		This means that a space following the name no longer singifies its use as an identifer.
#
# 		The name can be used in function calls with or without following whitespace, but causes a syntax
# 		error in nonexpression context unless it is quoted.
#
# 		For example, with IGNORE_SPACE enabled, both of hte following statements fail
# 		with a syntax error because the parser interprets count as a reserved word:
#
# 			CREATE TABLE count(i INT);
# 			CREATE TABLE count (i INT);
#
# 		To use the function name in nonexpression context, write it as a quoted identifier:
#
# 			CREATE TABLE `count`(i INT);
# 			CREATE TABLE `count` (i INT);
#
# To enable the IGNORE_SPACE SQL mode, use this statement:
#
# 		SET sql_mode = 'IGNORE_SPACE';
#
# IGNORE_SPACE is also enabled by certain other composite modes such as ANSI that include it in their value:
#
# 		SET sql_mode = 'ANSI';
#
# Check Server SQL modes for more info to see which composite mode enables IGNORE_SPACE.
#
# To minimize the dpeendency of SQL code on the IGNORE_SPACE setting, use these guidelines:
#
# 		) Avoid creating UDFs or stored functions that have the same name as a built in function.
#
# 		) Avoid using function names in nonexpression context.
#
# 			For example, these statements use count (one of hte affected function names affected by IGNORE_SPACE)
# 			so they fail with or without whitespace following the name if IGNORE_SPACE is enabled:
#
# 				CREATE TABLE count(i INT);
# 				CREATE TABLE count (i INT);
#
# 			If  you must use a function name in a nonexpression context, write it as a quoted identifier:
#
# 				CREATE TABLE `count`(i INT);
# 				CREATE TABLE `count` (i INT);
#
# FUNCTION NAME RESOLUTION
#
# The following rules describe hwo the server references to function names for function creation and invocation:
#
# 		) Built-in functions and user-defined functions
#
# 			An error occurs if you try to create a UDF with the same name as a built-in function.
#
# 		) Built-in functions and stored functions
#
# 			It is possible to create a stored function with the same name as a built-in function, but to invoke the
# 			stored function it is necessary to qualify it with a schema name.
#
# 			FOr example, if you created a store function named PI in the test schema, invoke it as test.PI()
# 			because the server resolves PI() without a qualifier as a reference to the built-in function.
#
# 			The server generates a warning if the stored function name collides with a built-in function name.
#
# 			The warning can be displayed with SHOW_WARNINGS.
#
# 		) User-defined functions and stored functions
#
# 			USer-defined functions and stored functions share the same namespace, so you cannot create a UDF and a stored function with the same name.
#
# 		The preceding function name resolution rules have implications for upgrading to versions of MySQL that implement new built-in functions:
#
# 			) IF you have already created a user-defined function with a given name and upgrade MySQL to a version that implements
# 				a new built-in function with the same name, the UDF becomes inaccessible.
#
# 				To correct this, use DROP_FUNCTION to drop the UDF and CREATE_FUNCTION to re-create the UDF with a different
# 				nonconflicitng name.
#
# 				Then modify any affected code to use the new name.
#
# 			) If a new version of MysQL implements a built-in function wih the same name as an existing stored function,
# 				you have two choices:
#
# 				Rename the stored function to use a noncflicting name
#
# 				or
#
# 				change calls to the function so that they use a schema qualifier (that is, use schema_name.func_name() syntax)
#
# 				In either case, modify any affected code accordingly.
#
# KEYWORDS AND RESERVED WORDS
#
# Keywords are words that have significance in SQL.
#
# Certain keywords, such as SELECT, DELETE or BIGINT, are reserved and require special treatment for use as identifiers
# such as table and column names.
#
# THis may also be ture for hte name of built-in functions.
#
# Nonreserved keywords are permitted as identifiers without quoting.
#
# Reserved words are permitted as identifiers if you quote them as described in SECTION 9.2 "SCHEMA OBJECT NAMES"
#
# 		CREATE TABLE interval (begin INT, end INT);
# 		ERROR 1064 (42000): You have an error in your SQL synytax ---
# 		near 'interval' (begin INT, end INT)'
#
# BEGIN and END are keywords, but not reserved.

# Thus, their use as identifiers does not require quoting:
# Interval is a reserved keyword and must be quoted to be used as an identifier:
#
# 		CREATE TABLE `interval` (begin INT, end INT);
# 		Query OK, 0 rows affected (0.01 sec)
#
# Exception: A word that follows a period in a qualified name must be an identifier, so it need not be quoted
# even if it is reserved:
#
# 		CREATE TABLE mydb.interval (begin INT, end INT);
# 		Query OK, 0 rows affected (0.01 sec)
#
# Names of built-in functions are permitted as identifiers but may require care to be used as such.
# For example, COUNT is acceptable as a column name.
#
# However, by default, no whitespace is permitted in function invocations between the function name
# and the following ( character.
#
# THis requirement enables the parser to distinguish whether the name is used in a function call
# or in nonfunction context.
#
# For further details on recognition of function names, see SECTION 9.2.4, "FUNCTION NAME PARSING AND RESOLUTION"
#
# The INFORMATION_SCHEMA.KEYWORDS table lists the words considered by MySQL and indicates whether
# tehy are reserved.
#
# See SECTION 25.13 "THE INFORMATION_SCHEMA KEYWORDS TABLE"
#
# MySQL 8.0 KEYWORDS AND RESERVERD WORDS
#
# The following lists shows the keywords and reserverd words in MySQL 8.0, along with the changes
# to individual words from verison to version.
#
# Reservered keywords are marked with (R).
#
# In addition, _FILENAME Is reserved.
#
# At some point, you might upgrade to a higehr version, so it is a good idea to have a look at future
# reserverd words, too.
#
# You can find these in the manuals that cover higher versions of MysQL.
#
# MOst of the reserved words in the list are forbidden by standard SQL as column or table names
# (for example, GROUP)
#
# A few are reserved because MySQL needs them and uses a yacc parser.
#
# -> A
#
# ACCESSIBLE (R)
#
# ACCOUNT
#
# ACTION
#
# ACTIVE; Added in 8.0.14
#
# ADD (R)
#
# ADMIN; Nonreserved in 8.0.12
#
# AFTER
#
# AGAINST
#
# AGGREGATE
#
# ALGORITHM
#
# ALL(R)
#
# ALTER(R)
#
# ALWAYS
#
# ANALYSE; Removed in 8.0.1
#
# ANALYZE(R)
#
# AND(R)
#
# ANY
#
# AS(R)
#
# ASC(R)
#
# ASCII
#
# ASENSITIVE(R)
#
# AT
#
# AUTOEXTEND_SIZE
# 
# AUTO_INCREMENT
#
# AVG
#
# AVG_ROW_LENGTH
#
# -> B
#
# BACKUP
#
# BEFORE(R)
#
# BEGIN
#
# BETWEEN(R)
#
# BIGINT(R)
#
# BINARY(R)
#
# BINLOG
#
# BIT
#
# BLOB(R)
#
# BLOCK
#
# BOOL
#
# BOOLEAN
#
# BOTH(R)
#
# BTREE
#
# BUCKETS; added in 8.0.2
#
# BY (R)
#
# BYTE
#
# -> C
#
# CACHE
#
# CALL(R)
#
# CASCADE (R)
#
# CASCADED 
#
# CASE(R)
#
# CATALOG_NAME
#
# CHAIN
#
# CHANGE(R)
#
# CHANNEL
#
# CHAR(R)
#
# CHARACTER(R)
#
# CHARSET
#
# CHECK(R)
#
# CHECKSUM
#
# CIPHER
#
# CLASS_ORIGIN
#
# CLIENT
#
# CLONE; added in 8.0.3 (nonreserved)
#
# CLOSE
#
# COALESCE
#
# CODE
#
# COLLATE (R)
#
# COLLATION
#
# COLUMNS
#
# COLUMN_FORMAT
#
# COLUMN_NAME
#
# COMMENT
#
# COMMIT
#
# COMMITTED
#
# COMPACT
#
# COMPLETION
#
# COMPONENT
#
# COMPRESSED
#
# COMPRESSION
#
# CONCURRENT
#
# CONDITION(R)
#
# CONNECTION
#
# CONSISTENT
#
# CONSTRAINT(R)
#
# CONSTRAINT_CATALOG
#
# CONSTRAINT_NAME
#
# CONSTRAINT_SCHEMA
#
# CONTAINS
#
# CONTEXT
#
# CONTINUE(R)
#
# CONVERT(R)
#
# CPU
#
# CREATE(R)
#
# CROSS(R)
#
# CUBE(R); Became reserved in 8.0.1
#
# CUME_DIST(R); Added in 8.0.2 (reserved)
#
# CURRENT
#
# CURRENT_DATE(R)
#
# CURRENT_TIME(R)
#
# CURRENT_TIMESTAMP(R)
#
# CURRENT_USER(R)
#
# CURSOR (R)
#
# CURSOR_NAME
#
# DATA
#
# DATABASE (R)
#
# DATABASES (R)
#
# DATAFILE
#
# DATE
#
# DATETIME
#
# DAY
#
# DAY_HOUR(R)
#
# DAY_MICROSECOND(R)
#
# DAY_MINUTE(R)
#
# DAY_SECOND(R)
#
# DEALLOCATE
#
# DEC(R)
#
# DECIMAL(R)
#
# DECLARE(R)
#
# DEFAULT(R)
#
# DEFAULT_AUTH
#
# DEFINER
#
# DEFINITION; added in 8.0.11 (nonreserved)
#
# DELAYED (R)
#
# DELAY_KEY_WRITE
#
# DELETE(R)
#
# DENSE_RANK(R); added in 8.0.2 (reserved)
#
# DESC (R)
#
# DESCRIBE (R)
#
# DESCRIPTION; added in 8.0.11 (nonreserved)
#
# DES_KEY_FILE; removed in 8.0.3
#
# DETERMINISTIC(R)
#
# DIAGNOSTICS
#
# DIRECTORY
#
# DISABLE
#
# DISCARD
#
# DISK
#
# DISTINCT (R)
#
# DISTINCTROW(R)
#
# DIV(R)
#
# DO
#
# DOUBLE(R)
#
# DROP (R)
#
# DUAL (R)
#
# DUMPFILE
#
# DUPLICATE 
#
# DYNAMIC
#
# EACH(R)
#
# ELSE (R)
#
# ELSEIF (R)
#
# EMPTY(R); added in 8.0.4 (reserved)
#
# ENABLE
#
# ENCLOSED(R)
#
# ENCRYPTION
#
# END
#
# ENDS
#
# ENGINE
#
# ENGINES
#
# ENUM
#
# ERROR
#
# ERRORS
#
# ESCAPE
#
# ESCAPED (R)
#
# EVENT
#
# EVENTS
#
# EVERY
#
# EXCEPT (R)
#
# EXCHANGE
#
# EXCLUDE; added in 8.0.2 (nonreserved)
#
# EXECUTE
#
# EXISTS(R)
#
# EXIT(R)
#
# EXPANSION
#
# EXPIRE
#
# EXPLAIN (R)
#
# EXPORT
#
# EXTENDED 
#
# EXTENT_SIZE
#
# FALSE(R)
#
# FAST
#
# FAULTS
#
# FETCH(R)
#
# FIELDS
#
# FILE
#
# FILE_BLOCK_SIZE
#
# FILTER
#
# FIRST
#
# FIRST_VALUE(R); added in 8.0.2 (reserved)
#
# FIXED
#
# FLOAT(R)
#
# FLOAT4(R)
#
# FLOAT8(R)
#
# FLUSH
#
# FOLLOWING; added in 8.0.2 (nonreserved)
#
# FOLLOWS
#
# FOR(R)
#
# FORCE(R)
#
# FOREIGN(R)
#
# FORMAT
#
# FOUND
#
# FROM(R)
#
# FULL
#
# FULLTEXT(R)
#
# FUNCTION(R); became reserved in 8.0.1
#
# GENERAL
#
# GENERATED (R)
#
# GEOMCOLLECTION; added in 8.0.11 (nonreserved)
#
# GEOMETRY
#
# GEOMETRYCOLLECTION
#
# GET(R)
#
# GET_FORMAT
#
# GET_MASTER_PUBLIC_KEY; added in 8.0.11 (nonreserved)
#
# GLOBAL
#
# GRANT(R)
#
# GRANTS
#
# GROUP(R)
#
# GROUPING(R); added in 8.0.1 (reserved)
#
# GROUPS(R); added in 8.0.2 (reserved)
#
# GROUP_REPLICATION
#
# HANDLER
#
# HASH
#
# HAVING(R)
#
# HELP
#
# HIGH_PRIORITY(R)
#
# HISTOGRAM; added in 8.0.2 (nonreserved)
#
# HISTORY; added in 8.0.3 (nonreserved)
#
# HOST
#
# HOSTS
#
# HOUR
#
# HOUR_MICROSECOND(R)
#
# HOUR_MINUTE(R)
#
# HOUR_SECOND(R)
#
# IDENTIFIED
#
# IF(R)
#
# IGNORE(R)
#
# IGNORE_SERVER_IDS
#
# IMPORT
#
# IN(R)
#
# INACTIVE; added in 8.0.14 (nonreserved)
#
# INDEX(R)
#
# INDEXES
#
# INFILE(R)
#
# INITIAL_SIZE
#
# INNER(R)
#
# INOUT(R)
#
# INSENSITIVE(R)
#
# INSERT(R)
#
# INSERT_METHOD
#
# INSTALL
#
# INSTANCE
#
# INT(R)
#
# INT1(R)
#
# INT2(R)
#
# INT3(R)
#
# INT4(R)
#
# INT8(R)
#
# INTEGER(R)
#
# INTERVAL(R)
#
# INTO(R)
#
# INVISIBLE
#
# INVOKER
#
# IO
#
# IO_AFTER_GTIDS(R)
#
# IO_BEFORE_GTIDS(R)
#
# IO_THREAD
#
# IPC
#
# IS(R)
#
# ISOLATION
#
# ISSUER
#
# ITERATE(R)
#
# JOIN(R)
#
# JSON
#
# JSON_TABLE(R); added in 8.0.4 (reserved)
#
# KEY(R)
#
# KEYS(R)
#
# KEY_BLOCK_SIZE
#
# KILL(R)
#
# LAG(R); added  in 8.0.2 (reserved)
#
# LANGUAGE
#
# LAST
#
# LAST_VALUE(R); added in 8.0.2 (reserved)
#
# LATERAL(R); added in 8.0.14 (reserved)
#
# LEAD(R); added in 8.0.2 (reserved)
#
# LEADING(R)
#
# LEAVE(R)
#
# LEAVES
#
# LEFT(R)
#
# LESS
#
# LEVEL
#
# LIKE(R)
#
# LIMIT(R)
#
# LINEAR(R)
#
# LINES(R)
#
# LINESTRING
#
# LIST
#
# LOAD(R)
#
# LOCAL
#
# LOCALTIME(R)
#
# LOCALTIMESTAMP(R)
#
# LOCK(R)
#
# LOCKED; added in 8.0.1 (nonreserved)
#
# LOCKS
#
# LOGFILE
#
# LOGS
#
# LONG(R)
#
# LONGBLOB(R)
#
# LONGTEXT(R)
#
# LOOP(R)
#
# LOW_PRIORITY(R)
#
# MASTER
#
# MASTER_AUTO_POSITION
#
# MASTER_BIND(R)
#
# MASTER_CONNECT_RETRY
#
# MASTER_DELAY
#
# MASTER_HEARTBEAT_PERIOD
#
# MASTER_HOST
#
# MASTER_LOG_FILE
#
# MASTER_LOG_POS
#
# MASTER_PASSWORD
#
# MASTER_PORT
#
# MASTER_PUBLIC_KEY_PATH; added in 8.0.11 (nonreserved)
#
# MASTER_RETRY_COUNT
#
# MASTER_SERVER_ID
#
# MASTER_SSL
#
# MASTER_SSL_CA
#
# MASTER_SSL_CAPATH
#
# MASTER_SSL_CERT
#
# MASTER_SSL_CIPHER
#
# MASTER_SSL_CRL
#
# MASTER_SSL_CRLPATH
#
# MASTER_SSL_KEY
#
# MASTER_SSL_VERIFY_SERVER_CERT(R)
#
# MASTER_TLS_VERSION
#
# MASTER_USER
#
# MATCH(R)
#
# MAXVALUE(R)
#
# MAX_CONNECTIONS_PER_HOUR
#
# MAX_QUERIES_PER_HOUR
#
# MAX_ROWS
#
# MAX_SIZE
#
# MAX_UPDATES_PER_HOUR
#
# MAX_USER_CONNECTIONS
#
# MEDIUM
#
# MEDIUMBLOB(R)
#
# MEDIUMINT(R)
#
# MEDIUMTEXT(R)
#
# MEMORY
#
# MERGE
#
# MESSAGE_TEXT
#
# MICROSECOND
#
# MIDDLEINT(R)
#
# MIGRATE
#
# MINUTE
#
# MINUTE_MICROSECONDS(R)
#
# MINUTE_SECOND(R)
#
# MIN_ROWS
#
# MOD(R)
#
# MODE
#
# MODIFIES(R)
#
# MODIFY
#
# MONTH
#
# MULTILINESTRING
#
# MULTIPOINT
#
# MULTIPOLYGON
#
# MUTEX
#
# MYSQL_ERRNO
#
# NAME
#
# NAMES
#
# NATIONAL
#
# NATURAL(R)
#
# NCHAR
#
# NDB
#
# NDBCLUSTER
#
# NESTED; added in 8.0.4 (nonreserved)
#
# NEVER
#
# NEW
#
# NEXT
#
# NO
#
# NODEGROUP
#
# NONE
#
# NOT(R)
#
# NOWAIT; added in 8.0.1 (nonreserved)
#
# NO_WAIT
#
# NO_WRITE_TO_BINLOG(R)
#
# NTH_VALUE(R); added in 8.0.2 (reserved)
#
# NTILE(R); added in 8.0.2 (reserved)
#
# NULL(R)
#
# NULLS; added in 8.0.2 (nonreserved)
#
# NUMBER
#
# NUMERIC(R)
#
# NVARCHAR
#
# OF(R); added in 8.0.1 (reserved)
#
# OFFSET
#
# OLD; added in 8.0.14 (nonreserved)
#
# ON(R)
#
# ONE
#
# ONLY
#
# OPEN
#
# OPTIMIZE(R)
#
# OPTIMIZER_COSTS(R)
#
# OPTION(R)
#
# OPTIONAL; added in 8.0.13 (nonreserved)
#
# OPTIONALLY (R)
#
# OPTIONS
#
# OR (R)
#
# ORDER (R)
#
# ORDINALITY; added in 8.0.4 (nonreserved)
#
# ORGANIZATION; added in 8.0.11 (nonreserved)
#
# OTHERS; added in 8.0.2 (nonreserved)
#
# OUT(R)
#
# OUTER(R)
#
# OUTFILE(R)
#
# OVER(R); added in 8.0.2 (reserved)
#
# OWNER
#
# PACK_KEYS
#
# PAGE
#
# PARSER
#
# PARTIAL
#
# PARTITION (R)
#
# PARTITIONING
#
# PARTITIONS
#
# PASSWORD
#
# PATH; added in 8.0.4 (nonreserved)
#
# PERCENT_RANK(R); added in 8.0.2 (reserved)
#
# PERSIST(R)
#
# PERSIST_ONLY(R); added in 8.0.2 (reserved)
#
# PHASE
#
# PLUGIN
#
# PLUGINS
#
# PLUGIN_DR
#
# POINT
#
# POLYGON
#
# PORT
#
# PRECEDES
#
# PRECEDING; added in 8.0.2 (nonreserved)
#
# PRECISION (R)
#
# PREPARE
#
# PRESERVE
#
# PREV
#
# PRIMARY(R)
#
# PRIVILEGES
#
# PROCEDURE(R)
#
# PROCESS; added in 8.0.11 (nonreserved)
#
# PROCESSLIST
#
# PROFILE
#
# PROFILES
#
# PROXY
#
# PURGE (R)
#
# QUARTER
#
# QUERY
#
# QUICK
#
# RANGE(R)
#
# RANK(R); added in 8.0.2 (reserved)
#
# READ(R)
#
# READS(R)
#
# READ_ONLY
#
# READ_WRITE(R)
#
# REAL(R)
#
# REBUILD
#
# RECOVER
#
# RECURSIVE(R); added in 8.0.1 (reserved)
#
# REDOFILE; removed in 8.0.3
#
# REDO_BUFFER_SIZE
#
# REDUNDANT
#
# REFERENCE; added in 8.0.11 (nonreserved)
#
# REFERENCES(R)
#
# REGEXP(R)
#
# RELAY
#
# RELAYLOG
#
# RELAY_LOG_FILE
#
# RELAY_LOG_POS
#
# RELAY_THREAD
#
# RELEASE(R)
#
# RELOAD
#
# REMOTE; added in 8.0.3 (nonreserved); removed in 8.0.14
#
# REMOVE
#
# RENAME(R)
#
# REORGANIZE
#
# REPAIR
#
# REPEAT(R)
#
# REPEATABLE
#
# REPLACE(R)
#
# REPLICATE_DO_DB
#
# REPLICATE_DO_TABLE
#
# REPLICATE_IGNORE_DB
#
# REPLICATE_IGNORE_TABLE
#
# REPLICATE_REWRITE_DB
#
# REPLICATE_WILD_DO_TABLE
#
# REPLICATE_WILD_IGNORE_TABLE
#
# REPLICATION
#
# REQUIRE (R)
#
# RESET
#
# RESIGNAL (R)
#
# RESOURCE; added in 8.0.3 (nonreserved)
#
# RESPECT; added in 8.0.2 (nonreserved)
#
# RESTART; added in 8.0.11 (nonreserved)
#
# RESTORE
#
# RESTRICT (R)
#
# RESUME
#
# RETAIN; added in 8.0.14 (nonreserved)
#
# RETURN (R)
#
# RETURNED_SQLSTATE
#
# RETURNS
#
# REUSE; added in 8.0.3 (nonreserved)
#
# REVERSE 
#
# REVOKE (R)
#
# RIGHT(R)
#
# RLIKE(R)
#
# ROLE; became nonreserved in 8.0.1
#
# ROLLBACK
#
# ROLLUP
#
# ROTATE
#
# ROUTINE
#
# ROW(R); became reserved in 8.0.2
#
# ROWS (R); became reserved in 8.0.2
#
# ROW_COUNT
#
# ROW_FORMAT
#
# ROW_NUMBER(R); added in 8.0.2 (reserved)
#
# RTREE
#
# SAVEPOINT
#
# SCHEDULE
#
# SCHEMA(R)
#
# SCHEMAS(R)
#
# SCHEMA_NAME
#
# SECOND
#
# SECONDARY_ENGINE; added in 8.0.13 (nonreserved)
#
# SECONDARY_LOAD; added in 8.0.13 (nonreserved)
#
# SECONDARY_UNLOAD; added in 8.0.13 (nonreserved)
#
# SECOND_MICROSECOND(R)
#
# SECURITY
#
# SELECT(R)
#
# SENSITIVE (R)
#
# SEPARATOR (R)
#
# SERIAL
#
# SERIALIZABLE
#
# SERVER
#
# SESSION
#
# SET(R)
#
# SHARE
#
# SHOW(R)
#
# SHUTDOWN
#
# SIGNAL(R)
#
# SIGNED
#
# SIMPLE
#
# SKIP; added in 8.0.1 (nonreserved)
#
# SLAVE
#
# SLOW
#
# SMALLINT(R)
#
# SNAPSHOT
#
# SOCKET
#
# SOME
#
# SONAME
#
# SOUNDS
#
# SOURCE
#
# SPATIAL(R)
#
# SPECIFIC(R)
#
# SQL(R)
#
# SQLEXCEPTION(R)
#
# SQLSTATE(R)
#
# SQLWARNING(R)
#
# SQL_AFTER_GTIDS
#
# SQL_AFTER_MTS_GAPS
#
# SQL_BEFORE_GTIDS
#
# SQL_BIG_RESULT(R)
#
# SQL_BUFFER_RESULT
#
# SQL_CACHE; removed in 8.0.3
#
# SQL_CALC_FOUND_ROWS(R)
#
# SQL_NO_CACHE
#
# SQL_SMALL_RESULT(R)
#
# SQL_THREAD
#
# SQL_TSI_DAY
#
# SQL_TSI_HOUR
#
# SQL_TSI_MINUTE
#
# SQL_TSI_MONTH
#
# SQL_TSI_QUARTER
#
# SQL_TSI_SECOND
#
# SQL_TSI_WEEK
#
# SQL_TSI_YEAR
#
# SRID; added in 8.0.3 (nonreserved)
#
# SSL(R)
#
# STACKED
#
# START
#
# STARTING (R)
#
# STARTS
#
# STATS_AUTO_RECALC
#
# STATS_PERSISTENT
#
# STATS_SAMPLE_PAGES
#
# STATUS
#
# STOP
#
# STORAGE
#
# STORED(R)
#
# STRAIGHT_JOIN(R)
#
# STRING
#
# SUBCLASS_ORIGIN
#
# SUBJECT
#
# SUBPARTITION
#
# SUBPARTITIONS
#
# SUPER
#
# SUSPEND
#
# SWAPS
#
# SWITCHES
#
# SYSTEM(R); added in 8.0.3 (reserved)
#
# TABLE(R)
#
# TABLES
#
# TABLESPACE
#
# TABLE_CHECKSUM
#
# TABLE_NAME
#
# TEMPORARY
#
# TEMPTABLE
#
# TERMINATED(R)
#
# TEXT
#
# THAN
#
# THEN(R)
#
# THREAD_PRIORITY; added in 8.0.3 (nonreserved)
#
# TIES; added in 8.0.2 (nonreserved)
#
# TIME
#
# TIMESTAMP
#
# TIMESTAMPADD
#
# TIMNESTAMPDIFF
#
# TINYBLOB(R)
#
# TINYINT(R)
#
# TINYTEXT(R)
#
# TO(R)
#
# TRAILING(R)
#
# TRANSACTION
#
# TRIGGER(R)
#
# TRIGGERS
#
# TRUE(R)
#
# TRUNCATE
#
# TYPE
#
# TYPES
#
# UNBOUNDED; added in 8.0.2 (nonreserved)
#
# UNCOMMITTED
#
# UNDEFINED
#
# UNDO(R)
#
# UNDOFILE
#
# UNDO_BUFFER_SIZE
#
# UNICODE
#
# UNINSTALL
#
# UNION (R)
#
# UNIQUE (R)
#
# UNKNOWN
#
# UNLOCK(R)
#
# UNSIGNED(R)
#
# UNTIL
#
# UPDATE(R)
#
# UPGRADE
#
# USAGE(R)
#
# USE(R)
#
# USER
#
# USER_RESOURCES
#
# USE_FRM
#
# USING(R)
#
# UTC_DATE(R)
#
# UTC_TIME(R)
#
# UTC_TIMESTAMP(R)
#
# VALIDATION
#
# VALUE
#
# VALUES(R)
#
# VARBINARY(R)
#
# VARCHAR(R)
#
# VARCHARACTER(R)
#
# VARIABLES
#
# VARYING(R)
#
# VCPU; added in 8.0.3 (nonreserved)
#
# VIEW
#
# VIRTUAL(R)
#
# VISIBLE
#
# WAIT
#
# WARNINGS
#
# WEEK
#
# WEIGHT_STRING
#
# WHEN(R)
#
# WHERE(R)
#
# WHILE(R)
#
# WINDOW(R); added in 8.0.2 (reserved)
#
# WITH(R)
#
# WITHOUT
#
# WORK
#
# WRAPPER
#
# WRITE(R)
#
# X509
#
# XA
#
# XID
#
# XML
#
# XOR(R)
# 
# YEAR
#
# YEAR_MONTH(R)
#
# ZEROFILL(R)
#
# MySQL 8.0 NEW KEYWORDS AND RESERVED WORDS
#
# THe following list shows the keywords and reserved words that are added in MySQL 8.0, compared
# to MySQL 5.7.
#
# Reserved keywords are marked with (R)
#
# ACTIVE
#
# ADMIN
#
# BUCKETS
#
# CLONE

# COMPONENT
#
# CUME_DIST(R)
#
# DEFINITION
#
# DENSE_RANK(R)
#
# DESCRIPTION
#
# EMPTY(R)
#
# EXCEPT(R)
#
# EXCLUDE
#
# FIRST_VALUE(R)
#
# FOLLOWING
#
# GEOMCOLLECTION
#
# GET_MASTER_PUBLIC_KEY
#
# GROUPING(R)
#
# GROUPS(R)
#
# HISTOGRAM
#
# HISTORY
#
# INACTIVE
#
# INVISIBLE
#
# JSON_TABLE(R)
#
# LAG(R)
#
# LAST_VALUE(R)
#
# LATERAL(R)
#
# LEAD(R)
#
# LOCKED
#
# MASTER_PUBLIC_KEY_PATH
#
# NESTED
#
# NOWAIT
#
# NTH_VALUE(R)
#
# NTILE(R)
#
# NULLS
#
# OF(R)
#
# OLD
#
# OPTIONAL
#
# ORDINALITY
#
# ORGANIZATION
#
# OTHERS
#
# OVER(R)
#
# PATH
#
# PERCENT_RANK(R)
#
# PERSIST(R)
#
# PERSIST_ONLY(R)
#
# PRECEDING 
#
# PROCESS
#
# RANK(R)
#
# RECURSIVE(R)
#
# REFERENCE
#
# RESOURCE
#
# RESPECT
#
# RESTART
#
# RETAIN
#
# REUSE
#
# ROLE
#
# ROW_NUMBER(R)
#
# SECONDARY_ENGINE
#
# SECONDARY_LOAD
#
# SECONDARY_UNLOAD
#
# SKIP
#
# SRID
#
# SYSTEM(R)
#
# THREAD_PRIORITY
#
# TIES
#
# UNBOUNDED
#
# VCPU
#
# VISIBLE
#
# WINDOW(R)
#
# MYSQL 8.0 REMOVED KEYWORDS AND RESERVED WORDS
#
# The following lists the keywords and reserverd words that are removed in MySQL 8.0, compared to 5.7
#
# Reserved words are marked with (R)
#
# ANALYSE
#
# DES_KEY_FILE
#
# PARSE_GCOL_EXPR
#
# REDOFILE
#
# SQL_CACHE
#
# USER-DEFINED VARIABLES
#
# You can store a value in a user-defined variable in one statement and refer to it later in another statement.
#
# This enables you to pass values from one statement to another.
#
# User variables are written as @var_name, where the variable name var_name consists of alphanumeric characters, ., _, and $
#
# A user variable name can contain other characters if you quote it as a string or identifier (for example, @'my-var', @"my-var", or @`my-var`)
#
# User-defined variables are session specific. A user variable defined by one client cannot be seen or used by other clients.
# (Exception: A user with access to the Performance Schema user_variables_by_thread table can see all user variables for all sessions)
#
# All variables for a given client session are automatically freed when that client exits.
#
# User variable names are not case-sensitive. Names have a maximum length of 64 characters.
#
# One way to set a user-defined variable is by issuing a SET statement:
#
# 		SET @var_name = expr [, @var_name = expr] ---
#
# For SET, either = or := can be used as the assignment operator.
#
# User variables can be assigned a value from a limited set of data types: integer, decimal, floating-point, binary or nonbinary string, or NULL value.
#
# Assignment of decimal and real values does not preserve the precision of scale of the value.
#
# A value of a type other than one of the permissible types is converted to a permissible type.
# For example, a value having a temporal or spatial data type is converted to a binary string.
#
# A value having the JSON data type is converted to a string with a character set of utf8mb4 and a collation of utf8mb4_bin
#
# If a user variable is assigned a nonbinary (character) string value, it has the same character set and collation
# as the string.
#
# The coercibility of user variables is implicit.
#
# (This is the same coercibility as for table column values)
#
# HExadecimal or bit values assigned to user variables are treated as binary strings.
# To assign a hexadecimal or bit value as a number to a user variable, use it in numeric
# context.
#
# For example, add 0 or use CAST(--- AS UNSIGNED):
#
# 		SET @v1 = X'41';
# 		SET @v2 = X'41'+0;
# 		SET @v3 = CAST(X'41' AS UNSIGNED);
# 		SELECT @v1, @v2, @v3;
#
# 		+---------+----------+----------+
# 		| @v1 	 | @v2 	   | @v3 	  |
# 		+---------+----------+----------+
# 		| A 		 | 65 		| 65 		  |
# 		+---------+----------+----------+
#
# 
# 		SET @v1 = b'1000001';
# 		SET @v2 = b'1000001'+0;
# 		SET @v3 = CAST(b'1000001' AS UNSIGNED);
# 		SELECT @v1, @v2, @v3;
#
# 		+--------+----------+-------------+
# 		| @v1 	| @v2 	  | @v3 			 |
# 		+--------+----------+-------------+
# 		| A 		| 65 		  | 65 			 |
# 		+--------+----------+-------------+
#
# If the value of a user variable is selected in a result set, it is returned ot hte client as a string.
#
# If you refer to a variable that has not been initialized, it has a value of NULL and a type of string.
#
# User variables may be used in most contexts where expressions are permitted.
#
# This does not currently include contexts that explicitly require a literal value, sch as in the
# LIMIT clause of a SELECT statement, or the IGNORE N LINES clause of a LOAD_DATA statement.
#
# Previous releases of MySQL made it possible to assign a value to a user variable in statements
# other than SET.
#
# This functionality is supported in MySQL 8.0 for backward compatbility but is subject to removal
# in a future release of MySQL.
#
# WHen making an assignment in this way, you muse use := as the assignment operator, = is treated as
# a comparison operator in statments other than SET.
#
# The order of evaluation of expressions involving user variables is undefined.
#
# For example, there is no guarantee that SELECT @a, @a:=@a+1 evaluates @a first and then performs the assignment.   
#
# In addition, the default result type of a variable is based on tis type at the beginning of the statement.
#
# THis may have unintended effects if a variable holds a value of one type at the beginning
# of a statement in which it is also assigned a new value of a different type.
#
# To avoid problems with this behavior, either do not assign a value to and read the value of the same variable
# within a single statement, or else set the variable to 0, 0.0 or '' to define its type before you use it.
#
# HAVING, GROUP BY and ORDER BY, when referring to a variable that is assigned a value in the select expression
# list do not owkr as expected because the expression is evaluated on the client and thus can use stale column values
# from a previous row.
#
# User variables are intended to provide data values. They cannot be used directly in an SQL statement as an identifier
# or as part of an identifier, such as in contexts where a table or database name is expected, or as a reserved word such as SELECT.
#
# This is true even if the variable is quoted, as shown in the following example:
#
# 		SELECT c1 FROM t;
# 		+-------+
# 		| c1 	  |
# 		+-------+
# 		| 0 	  |
# 		+-------+
# 		| 1 	  |
# 		+-------+
# 		2 rows in set ( 0.00 sec )
# 		
# 		SET @col = "c1";
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT @col FROM t;
# 		+--------+
# 		| @col 	|
# 		+--------+
# 		| c1 	   |
# 		+--------+
# 		1 row in set (0.00 sec)
#
# 		SELECT `@col` FROM t;
# 		ERROR 1054 (42S22): Unknown column '@col' in 'field list'
#
# 		SET @col = "`c1`";
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT @col FROM t;
# 		+--------+
# 		| @col   |
# 		+--------+
# 		| `c1`	|
# 		+--------+
# 		1 row in set (0.00 sec)
#
# An exception to this principle that user variables cannot be used to provide identifiers, is when you
# are constructing a string for use as a prepared statement to execute later.
#
# In this case, user variables can be used to provide any part of the statement.
# The following example illustrates how this can be done:
#
# 		SET @c = "c1";
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SET @s = CONCAT("SELECT", @c, " FROM t");
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		PREPARE stmt FROM @s;
# 		Query OK, 0 rows affected (0.04 sec)
# 		Statement prepared
#
# 		EXECUTE stmt;
# 		+------+
# 		| c1   |
# 		+------+
# 		| 0 	 |
# 		+------+
# 		| 1 	 |
# 		+------+
# 		2 rows in set (0.00 sec)
#
# 		DEALLOCATE PREPARE stmt;
# 		Query OK, 0 rows affected (0.00 sec)
#
# See SECTION 13.5, "PREPARED SQL STATEMENT SYNTAX" for more information.
#
# A similar technique can be used in application programs to construct SQL statements using
# program variables, as shown here:
#
# <?PHP
# 		$mysqli = new mysqli("localhost", "user", "pass", "test");
#
# 		if( mysqli_connect_errno()) )
# 			die("Connection failed: %s\n", mysql_connect_error());
#
# 		$col = "c1";
#
# 		$query = "SELECT $col FROM t";
#
# 		$result = $mysqli->query($query);
#
# 		while($row = $result->fetch_assoc())
# 		{
# 			echo "<p>" . $row["$col"] . "</p>\n";
# 		}
#
# 		$result->close();
#
# 		$mysqli->close();
# ?>
#
# Assembling SQL like this, can be called Dynamic SQL.
#
# EXPRESSIONS
#
# This section lists the grammar rules that expressions must follow in MySQL and provides additional
# information about the types of terms that may appear in expressions.
#
# EXPRESSION SYNTAX
#
# The following grammar rules define expression syntax in MySQL.
#
# The grammar shown here is based on that given in the sql/sql_yacc.yy file of MySQL
# source distributions.
#
# For additional information about some of the expression terms, see Expression Term Notes.
#
# 		Expr:
# 			expr OR expr
# 		 | expr || expr
# 		 | expr XOR expr
# 		 | expr AND expr
# 		 | expr && expr
# 		 | NOT expr
# 		 | ! expr
# 		 | boolean_primary IS [NOT] {TRUE | FALSE | UNKNOWN}
# 		 | boolean_primary
#
# 		boolean_primary:
# 			boolean_primary IS [NOT] NULL
# 		 | boolean_primary <=> predicate
# 		 | boolean_primary comparison_operator predicate
# 		 | boolean_primary comparison_operator {ALL | ANY} (subquery)
# 		 | predicate
#
# 		comparison_operator: = | >= | > | <= | < | <> | !=
#
# 		predicate:
# 			bit_expr [NOT] IN (subquery)
# 		 | bit_expr [NOT] IN (expr [, expr] ---)
# 		 | bit_expr [NOT] BETWEEN bit_expr AND predicate
# 		 | bit_expr SOUNDS LIKE bit_expr
# 		 | bit_expr [NOT] LIKE simple_expr [ESCAPE simple_expr]
# 		 | bit_expr [NOT] REGEXP bit_expr
# 		 | bit_expr
#
# 		bit_expr:
# 			bit_expr | bit_expr
# 		 | bit_expr & bit_expr
# 		 | bit_expr << bit_expr
# 		 | bit_expr >> bit_expr
# 		 | bit_expr + bit_expr
# 		 | bit_expr - bit_expr
# 		 | bit_expr * bit_expr
# 		 | bit_expr / bit_expr
# 		 | bit_expr DIV bit_expr
# 		 | bit_expr MOD bit_expr
# 		 | bit_expr % bit_expr
# 		 | bit_expr ^ bit_expr 
# 		 | bit_expr + interval_expr
# 		 | bit_expr - interval_expr
# 		 | simple_expr
#
# 		simple_expr:
# 		  literal
# 		| identifier
# 		| function_call
# 		| simple_expr COLLATE collation_name
# 		| param_marker
# 		| variable
# 		| simple_expr || simple_expr
# 		| param_marker
# 		| variable
# 		| simple_expr || simple_expr
# 	   | + simple_expr
# 		| - simple_expr
# 		| ~ simple_expr
# 		| ! simple_expr
# 		| BINARY simple_expr
# 		| (expr [, expr] ---)
# 		| ROW (expr, expr [, expr], ---)
# 		| (subquery)
# 		| EXISTS (subquery)
# 		| {identifier expr}
# 		| match_expr
# 		| case_expr
# 		| interval_expr
#
# For operator precedence, see SECTION 12.3.1, "OPERATOR PRECEDENCE".
#
# The precedence and meaning of some operators depends on the SQL mode:
#
# 		) By default || is a logical OR operator. WIth PIPES_AS_CONCAT enabled, || is string concatenation,
# 			with a precedence between ^ and the unary operators.
#
# 		) By default, ! has a higher precedence than NOT. With HIGH_NOT_PRECEDENCE enabled, ! and NOT have teh same precedence.
#
# EXPRESSION TERM NOTES
#
# For literal value syntax, see SECTION 9.1, "LITERAL VALUES"
#
# For identifier syntax, see SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# Variables can be user variables, system variables, or stored program local
# variables or parameters:
#
# 		) User variables: Section 9.4, "USER-DEFINED VARIABLES"
#
# 		) System variables: Section 5.1.9, "Using System Variables"
#
# 		) Stored program local variables: SECTION 13.6.4.1 "LOCAL VARIABLE DECLARE SYNTAX" 	
#
# 		) Stored program parameters: SECTION 13.1.17 "CREATE PROCEDURE AND CREATE FUNCTION SYNTAX"
#
# param_marker is ? as used in prepared statements for placeholders. See SECTION 13.5.1, "PREPARE SYNTAX"
#
# (subquery) indicates a subquery that returns a single value; that is, a scalar subquery. See SECTION 13.2.11.1, "THE SUBQUERY AS SCALAR OPERAND"
#
# { identifier expr } is ODBC escape syntax and is accepted for ODBC compatibility.
#
# The value is expr. The { and } curly braces in the syntax should be written literally; they are not metasyntax
# as used elsewhere in syntax descriptions.
#
# match_expr indicates a MATCH expression. See SECTION 12.9, "FULL-TEXT SEARCH FUNCTIONS"
#
# case_expr indicates a CASE expression. See SECTION 12.4, "CONTROL FLOW FUNCTIONS"
#
# interval_expr represents a temporal interval. See Temporal Intervals.
#
# TEMPORAL INTERVALS
#
# interval_expr in expressions represents a temporal interval. Intervals have this syntax:
#
# 		INTERVAL expr unit
#
# expr represents a quantity.
#
# Unit represents the unit for interpreting the quantity; it is a specifier such as HOUR,
# DAY or WEEK.
#
# The INTERVAL keyword and the unit specifier are not case sensitive.
#
# The following table shows the expected form of the expr argument for each unit value.
#
# TEMPORAL INTERVAL EXPRESSION AND UNIT ARGUMENTS
#
# UNIT VALUE 			EXPECTED EXPR FORMAT
#
# MICROSECOND 			MICROSECONDS
#
# SECOND 				SECONDS
#
# MINUTE 				MINUTES
#
# HOUR 					HOURS
#
# DAY 					DAYS
#
# WEEK 					WEEKS
#
# MONTH 					MONTHS
#
# QUARTER 				QUARTERS
#
# YEAR 					YEARS
#
# SECOND_MICROSECOND 'SECONDS.MICROSECONDS'
#
# MINUTE_MICROSECOND 'MINUTES:SECONDS.MICROSECONDS'
#
# MINUTE_SECOND 		'MINUTES:SECONDS'
#
# HOUR_MICROSECOND 	'HOURS:MINUTES:SECONDS.MICROSECONDS'
#
# HOUR_SECOND 			'HOURS:MINUTES:SECONDS'
#
# HOUR_MINUTE 			'HOURS:MINUTES'
#
# DAY_MICROSECOND 	'DAYS HOURS:MINUTES:SECONDS.MICROSECONDS'
#
# DAY_SECOND 			'DAYS HOURS:MINUTES:SECONDS'
#
# DAY_MINUTE 			'DAYS HOURS:MINUTES'
#
# DAY_HOUR 				'DAYS HOURS'
#
# YEAR_MONTH 			'YEARS-MONTHS'
#
# MySQL permits any punctuation delimiter in the expr format.
# THose shown in the table ar the suggested delimiters.
#
# Temporal intervals are used for certain functions, such as DATE_ADD() and DATE_SUB():
#
# 		SELECT DATE_ADD('2018-05-01', INTERVAL 1 DAY);
# 			-> '2018-05-02'
#
# 		SELECT DATE_SUB('2018-05-01', INTERVAL 1 YEAR);
# 			-> '2017-05-01'
#
# 		SELECT DATE_ADD('2020-12-31 23:59:59',
# 			-> 			 INTERVAL 1 SECOND);
# 				-> '2021-01-01 00:00:00'
#
# 		SELECT DATE_ADD('2018-12-31 23:59:59',
# 			->				INTERVAL 1 DAY);
# 				-> '2019-01-01 23:59:59'
#
# 		SELECT DATE_ADD('2100-12-31 23:59:59',
# 			-> 			INTERVAL '1:1' MINUTE_SECOND);
# 				-> '2101-01-01 00:01:00'
#
# 		SELECT DATE_SUB('2025-01-01 00:00:00'
# 			->				INTERVAL '1 1:1:1' DAY_SECOND);
# 		 		-> '2024-12-30 22:58:59'
#
# 		SELECT DATE_ADD('1900-01-01 00:00:00',
# 			-> 			INTERVAL '-1 10' DAY_HOUR);
# 				-> '1899-12-30 14:00:00'
#
# 		SELECT DATE_SUB('1998-01-02', INTERVAL 31 DAY);
# 			-> '1997-12-02'
#
# 		SELECT DATE_ADD('1992-12-31 23:59:59.000002',
# 			->			INTERVAL '1.999999' SECOND_MICROSECOND);
# 				-> '1993-01-01 00:00:01.00001'
#
# Temporal arithmetic also can be performed in expressions using INTERVAL together with the + or - operator:
#
# 	date + INTERVAL expr unit
# 	date - INTERVAL expr unit
#
# INTERVAL expr unit is permitted on either side of the + operator if the expression on the other side is a date
# or datetime value.
#
# For the - operator, INTERVAL expr unit is permitted only on the right side, because it makes
# no sense to subtract date or datetime value from an interval.
#
# SELECT '2018-12-31 23:59:59' + INTERVAL 1 SECOND;
# 		-> '2019-01-01 00:00:00'
# SELECT INTERVAL 1 DAY + '2018-12-31';
# 		-> '2019-01-01'
# SELECT '2025-01-01' - INTERVAL 1 SECOND;
# 		-> '2024-12-31 23:59:59'
#
# The EXTRACT() function uses the same kinds of unit specifiers as DATE_ADD() or
# DATE_SUB(), but extracts parts from the date rather than performing date arithmetic:
#
# 		SELECT EXTRACT(YEAR FROM '2019-07-02');
# 			-> 2019
#
# 		SELECT EXTRACT(YEAR_MONTH FROM '2019-07-02 01:02:03');
# 			-> 201907
#
# Temporal intervals can be used in CREATE_EVENT statements:
#
# 		CREATE EVENT myevent
# 			ON SCHEDULE AT CURRENT_TIMESTAMP + INTERVAL 1 HOUR
# 			DO
# 				UPDATE myschema.mytable SET mycol = mycol + 1;
#
# If you specify an interval value that is too short (does not include all the interval parts that would be expected
# from the unit keyword), MySQL assumes that you have left out the leftmost parts of the interval value.
#
# For example, if you specify a unit of DAY_SECOND, the value of expr is expected to have days, hours, minutes and
# seconds parts.
#
# If you specify a value like '1:10', MySQL assumes that the days and hours parts are missing and the value represents
# minutes and seconds.
#
# In other words, '1:10' DAY_SECOND is interpreted in such a way that is equivalent to '1:10' MINUTE_SECOND.
#
# This is analogous to the way that MySQL interprets TIME values as representing elapsed time rather than as
# a time of day.
#
# expr is treated as a string, so be careful if you specify a nonstring value with INTERVAL.
#
# FOr example, with a interval specifier of HOUR_MINUTE, '6/4' is treated as 6 hours, four minutes,
# whereas 6/4 evaluates to 1.5000 and is treated as 1 hour, 5000 minutes:
#
# 		SELECT '6/4', 6/4;
# 			-> 1.5000
#
# 		SELECT DATE_ADD('2019-01-01', INTERVAL '6/4' HOUR_MINUTE);
# 			-> '2019-01-01 06:04:00'
#
# 		SELECT DATE_ADD('2019-01-01', INTERVAL 6/4 HOUR_MINUTE);
# 			-> '2019-01-04 12:20:00'
#
# To ensure interpretation of the interval value as you expect, a CAST() operation may be used.
# To treat 6/4 as 1 hour 5 mins, cast it to a DECIMAL value with a single fractional digit:
#
# 		SELECT CAST(6/4 AS DECIMAL(3,1));
# 			-> 1.5
#
# 		SELECT DATE_ADD('1970-01-01 12:00:00',
# 			->				 INTERVAL CAST(6/4 AS DECIMAL(3,1)) HOUR_MINUTE);
# 				-> '1970-01-01 13:05:00'
#
# If you add or subtract from a date value something that contains a time part,
# the result is automatically converted to a datetime value:
#
# 		SELECT DATE_ADD('2023-01-01', INTERVAL 1 DAY);
# 			-> '2023-01-02'
# 		SELECT DATE_ADD('2023-01-01', INTERVAL 1 HOUR);
# 			-> '2023-01-01 01:00:00'
#
# If you add MONTH, YEAR_MONTH, or YEAR and the resulting date has a day that is larger than
# the maximum day for the new month, the day is adjusted to the maximum days in the new month:
#
# 		SELECT DATE_ADD('2019-01-30', INTERVAL 1 MONTH);
# 			-> '2019-02-28'
#
# Date arithmetic operations require complete dates and do not work with incomplete date such as '2016-07-00' or badly
# malformed dates:
#
# 		SELECT DATE_ADD('2016-07-00', INTERVAL 1 DAY);
# 			-> NULL
# 		SELECT '2005-03-32' + INTERVAL 1 MONTH;
# 			-> NULL
#
# COMMENT SYNTAX
#
# MySQL Server supports three comment styles:
#
# 		) From a # character to end of line
#
# 		) From a -- sequence to the end of the line.
#
# 			In MySQL, the -- (double-dash) comment style requires the second dash to be followed by
# 			at least one whitespace or control character (such as space, tab, newline, and so on).
#
# 			This syntax differs slightly from standard SQL comment syntax, as discussed in earlier.
#
# 		) from a /* sequence to the following */ sequence, as in the C programming language.
#
# 			This syntax enables a comment to extend over multiple lines because the
# 			beginning and closing sequences need not be on the same line.
#
# THe following example demonstrates all three comment styles:
#
# 	SELECT 1+1; #This comment continues to end of line
# 	SELECT 1+1; -- same
# 	SELECT 1 /* inline comment */ + 1;
# 	SELECT 1+
# /*
# multiline 
# comment
# */
# 1;
#
# Nested comments are not supported, as they are dperecated.
#
# Under some conditions they are allowed, but usually not, thus, avoid them.
#
# MySQL server supports some variants of C-style comments.
#
# These enable you to write code that includes MySQL extensions, but is still portable,
# by using comments of the following form:
#
# /*! MySQL-specific code */
#
# In this case, MySQL parses and executes the code within the comment as it would any other SQL statement,
# but other SQL servers will ignore the extensions.
#
# For example, MySQL server recognizes the STRAIGHT_JOIN keyword in the following statment,
# but other servers will not:
#
# 		SELECT /*! STRAIGHT_JOIN */ col1 FROM table1,table2 WHERE ---
#
# If you add a version number after the ! character, the syntax within the comment is executed
# only if the MySQl version is greater than or equal to the specified version
#
# The KEY_BLOCK_SIZE keyword in the following comment is executed only by servers from MySQL 5.1.10 or higher:
#
# 		CREATE TABLE t1(a INT, KEY (a)) /*! 50110 KEY_BLOCK_SIZE=1024 */;
#
# The comment syntax just described applies to how the mysql parses SQL statements.
#
# The MySQL client program also performs some parsing of statements before sending them to
# the server.
#
# (It does this to determine statement boundaries within a multiple-statement input line)
#
# Comments in this format /*!12345 --- */, are not stored on the server.
#
# If this format is used to comment stored routines, the comments will not be retained on
# the server.
#
# Another variant of C-style comment syntax is used to specify optimizer hints.
# Hint comments include a + character following the /* comment opening sequence.
#
# Example:
#
# 	SELECT /*+ BKA(t1) */ FROM ---;
#
# Fore more information, see SECTION 8.9.2, "OPTIMIZER HINTS"
#
# The use of short-form mysql commands such as \C within multiple line /* --- */ comments si not supported.
#
# CHARACTER SETS, COLLATIONS, UNICODE
#
# MySQL includes character set support that enables you to store data using a variety of character
# sets and perform comparsions according to a variety of collations.
#
# You can specify character sets at the server, database, table and column level.
#
# This chapter discusses the following topics:
#
# 		) What are character sets and collations?
#
# 		) The multiple-level default system for character set assignment.
#
# 		) Syntax for specifying character sets and collations
#
# 		) Affected functions and operations.
#
# 		) Unicode support.
#
# 		) The character sets and collations that are available with notes.
#
# 		) Selecting the language for error messages
#
# 		) Selecting the locale for day and month names
#
# Character set issues affect not only data storage, but also communication between client programs
# and the MySQL server.
#
# If you want the client program to communicate with the server using a character set different
# from the default, you'll need to indicate which one.
#
# For example, to use the utf8 unicode character set, issue this statement after connecting to the server:
#
# 		SET NAMES 'utf8';
#
# For more information about configuring character sets for application use and character set-related
# issues in client/server communication, see SECTION 10.5, "CONFIGURING APPLICATION CHARACTER SET AND COLLATION"
#
# SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"
#
# CHARACTER SETS AND COLLATIONS IN GENERAL
#
# A character set is a set of symbols and encodings.
# A collation is a set of rules for comparing characters in a character set.
#
# Let's make the distinction clear with an example of an imaginary char set.
#
# Suppose that we have an alphabet of four letters:
#
# 		A, B, a, b
#
# We give each letter a number:
#
# 		A = 0
#
# 		B = 1
#
# 		a = 2
#
# 		b = 3
#
# The letter A is the symbol, the number 0 is the encoding for A, and the combination
# of all four letters and their encodings is a character set.
#
# Suppose that we want to compare two string values, A and B.
#
# The simplest way to do this is to look at the encodings: 0 for A and 1 for B.
#
# Because 0 < 1, A is < B
#
# What we've just done thus, is to apply a collation to our character set.
# The collation set is a set of rules (only one rule in this case):
#
# 		"compare the encodings"
#
# We call this simplest of all possible collations a binary collation
#
# But what if we want to say that the lowercase and uppercase letters are equivalent?
# Then we would have at least two rules: 
#
# (1) treat the lowercase letter a and b as equivalent to A and B
#
# (2) then compare the encodings
#
# We call this a case-insensitive collation. It is a little more complex than a binary collation.
#
# In real life, most character sets have many characters: not just A and B but whole alphabets,
# sometimes multiple alphabets or eastern writing systems with thousands of characters, along with many
# special symbols and punctuation marks.
#
# Also in real life, most collations have many rules, not just for whether to distinguish
# lettercase, but also for whether to distinguish accents (an "accent" is a mark attached to a character
# as in a German ) and for multiple-character mappings (such as the rule that  = OE in one of the two
# german collations)
#
# MySQL can do these things for you:
#
# 		Store strings using a variety of character sets
#
# 		Compare strings using a variety of collations
#
# 		Mix strings with different character sets or collations in the same server,
# 		the same database, or even the same table
#
# 		Enable specification of character set and collation at any level
#
# To use these features effectively, you must know what character sets and collations
# are available, how to change the defaults, and how they affect the behavior of string operators
# and functions.
#
# CHARACTER SETS AND COLLATIONS IN MYSQL
#
# MySQL Server supports multiple character sets, including several Unicode character sets.
#
# To display the available character sets, use the INFORMATION_SCHEMA CHARACTER_SETS table or the
# SHOW_CHARACTER_SET statement.
# 
# A partial listing follows. For more complete information, see SECTION 10.10 "SUPPORTED CHARACTER SETS
# AND COLLATIONS"
#
# SHOW CHARACTER SET;
# +------------+--------------------------------------------+-------------------------+-------------+
# | Charset 	| Description 											| Default collation 	 	  | Maxlen 		 |
# +------------+--------------------------------------------+-------------------------+-------------+
# | big5 		| Big5 Traditional Chinese 					   | big5_chinese_ci 		  | 		2 	 	 |
# | binary 	   | Binary pseudo charset 							| binary 					  | 		1 	    |
# ---
# | latin1 		| cp1252 West European 								| latin1_swedish_ci 		  | 		1 		 |
# ---
# | ucs2 		| UCS-2 Unicode 										| ucs2_general_ci 		  | 		2 		 |
# ---
# | utf8 		| UTF-8 Unicode 										| utf8_general_ci 		  | 		3 		 |
# | utf8mb4 	| UTF-8 Unicode 										| utf8mb4_0900_ai_ci 	  | 		4 		 |
# ---
#
# By default, the SHOW_CHARACTER_SET statement displays all available character sets.
#
# It takes an optional LIKE or WHERE clause that indicates which character set names to match.
#
# The following examples shows some of the Unicode character sets (those based on Unicode Transformation Format):
#
# 		SHOW CHARACTER SET LIKE 'utf%';
# 		+------------+------------------------+---------------------+------------------+
# 		| Charset 	 | Description 			  | Default collation 	| Maxlen 			 |
# 		+------------+------------------------+---------------------+------------------+
# 		| utf16 		 | UTF-16 Unicode 		  | utf16_general_ci  	| 		4 		   	 |
# 		| utf16le 	 | UTF-16LE Unicode 		  | utf16le_general_ci  | 	   4 				 |
# 		| utf32 		 | UTF-32 Unicode 		  | utf32_general_ci 	| 		4 				 |
# 		| utf8 		 | UTF-8 Unicode 			  | utf8_general_ci 	   | 		3 				 |
# 		| utf8mb4 	 | UTF-8 Unicode 			  | utf8mb4_0900_ai_ci 	| 		4 				 |
# 		+------------+------------------------+---------------------+------------------+
#
# A given character set always has at least one collation, and most character sets have several.
#
# To list the display collations for a character set, use the INFORMATION_SCHEMA COLLATIONS table
# or the SHOW_COLLATION statement.
#
# By default, the SHOW_COLLATION statement displays all available collations.
#
# It takes an optional LIKE or WHERE clause that indicates which collation names to display. 
#
# For example, to see the collations for the default character set, utf8mb4, use this statement:
#
# SHOW COLLATION WHERE Charset = 'utf8mb4';
# +------------------------+---------+-----+------------+-------------+-------------+------------------+
# | Collation 					| Charset | Id  | Default 	  | Compiled 	 | Sortlen 		| Pad_attribute 	 |
# +------------------------+---------+-----+------------+-------------+-------------+------------------+
# | utf8mb4_0900_ai_ci 		| utf8mb4 | 255 | Yes 		  | Yes 			 | 		0 		| NO PAD 			 |
# | utf8mb4_0900_as_ci  	| utf8mb4 | 305 | 			  | Yes 			 | 		0 		| NO PAD 			 |
# | utf8mb4_0900_as_cs  	| utf8mb4 | 278 | 			  | Yes 			 | 		0 	   | NO PAD 			 |
# | utf8mb4_bin 				| utf8mb4 |  46 | 			  | Yes 			 | 		1 		| PAD SPACE 		 |
# | utf8mb4_croatian_ci 	| utf8mb4 | 245 | 			  | Yes 			 | 		8 	   | PAD SPACE 		 |
# | utf8mb4_cs_0900_ai_ci  | utf8mb4 | 266 | 			  | Yes 			 | 		0 	   | NO PAD 			 |
# | utf8mb4_cs_0900_as_cs  | utf8mb4 | 289 | 			  | Yes 			 | 		0 		| NO PAD 			 |
# | utf8mb4_czech_ci 		| utf8mb4 | 234 | 			  | Yes 			 | 		8 		| PAD SPACE 		 |
# | utf8mb4_danish_ci 		| utf8mb4 | 235 | 			  | Yes 			 | 		8 		| PAD SPACE 		 |
# | utf8mb4_da_0900_ai_ci 	| utf8mb4 | 267 | 			  | Yes 			 | 		0 		| NO PAD 			 |
# | utf8mb4_da_0900_as_cs  | utf8mb4 | 290 | 			  | Yes 			 | 		0 		| NO PAD 			 |
# | utf8mb4_de_pb_0900_ai_ci etc.
# 
# --- This carries on for all the different charsets ---
#
# For more information about those collations, see SECTION 10.10.1, "UNICODE CHARACTER SETS"
#
# Collations have these general characteristics:
#
# 		) Two different character sets cannot have the same collation
#
# 		) Each character set has a default collation.
#
# 			For example, the default collations for utf8mb4 and latin1 are utf8mb4_0900_ai_ci and latin1_swedish_ci, respectively.
#
# 			The INFORMATION_SCHEMA CHARACTER_SETS table and the SHOW_CHARACTER_SET statement indicate hte default collation
# 			for each character set.
#
# 			The INFORMATION_SCHEMA COLLATIONS table and the SHOW_COLLATION statement have a column that indicates for each
# 			collation whether it is the default for its character set (yes if so, empty if not)
#
# 		) Collation names start with the name of the character set with which they are associated, generally followed
# 			by one or more suffixes indicating other collation characteristics.
#
# 			For additional information about naming conventions, see SECTION 10.3.1, "COLLATION NAMING CONVENTIONS"
#
# When a character set has multiple collations, it might not be clear which collation is most suitable for a given application.
#
# To avoid choosing an inappropriate collation, perform some comparisons with representative data values to make sure that a 
# given collation sorts values the way you expect.
#
# CHARACTER SET REPETOIRE
#
# The repetoire of a character set is the collection of characters in the set.
#
# String expressions have a repetoire attribute, which can have two values:
#
# 		) ASCII: The expression can contain only characters in the Unicode range U+0000 to U+007F
#
# 		) UNICODE: The expression can contain characters in the Unicode range U+0000 to U+10FFFF
#
# 						This includes characters in the Basic Multilingual Plane (BMP) range (U+0000 to U+FFFF)
# 						and supplementary characters outside the BMP range (U+10000 to U+10FFFF)
#
# The ASCII range is a subset of UNICODE range, so a string with ASCII repetoire can be converted safely without
# loss of information to the character set of any string with UNICODE repetoire or to a character set that is
# a superset of ASCII.
#
# (All MYSQL character sets are supersets of ASCII with the exception of swe7, which reuses some punctuation
# 	characters for Swedish accented characters)
#
# The use of repetoire enables character set conversion in expressions for many cases where MySQL would
# otherwise return an "illegal mix of collations" error
#
# The following discussion provides examples of expressions and their repetoires, and describes how the use
# of repetoire changes string expression evaluation:
#
# 		) The repetoire for a string constant depends on string content and may differ from the repetoire of the string
# 			character set.
#
# 			Consider these statements:
#
# 				SET NAMES utf8; SELECT 'abc';
# 				SELECT _utf8'def';
# 				SELECT N'MySQL';
#
# 			Although the character set is utf8 in each of the preceding cases, the strings do not actually
# 			contain any characters outside the ASCII range, so their repetoire is ASCII rather than UNICODE.
#
# 		) A column having the ascii character set has ASCII repetoire because of its character set.
#
# 			In the following table, c1 has ASCII repetoire:
#
# 				CREATE TABLE t1 (c1 CHAR(1) CHARACTER SET ascii);
#
# 			The following example illustrates how repetoire enables a result to be determined in a case where
# 			an error occurs without repetoire:
#
# 				CREATE TABLE t1 (
# 					c1 CHAR(1) CHARACTER SET latin1,
# 					c2 CHAR(1) CHARACTER SET ascii
# 				);
# 				INSERT INTO t1 VALUES ('a', 'b');
# 				SELECT CONCAT(c1,c2) FROM t1;
#
# 			Without repetoire this error occurs:
#
# 				ERROR 1267 (HY000): Illegal mix of collations (latin1_swedish_ci, IMPLICIT)
# 				and (ascii_general_ci, IMPLICIT) for operation 'concat'
#
# 			Using repetoire, subset to superset (ascii to latin1) conversion can occur and a result is returned:
#
# 				+-------------------+
# 				| CONCAT(c1,c2) 	  |
# 				+-------------------+
# 				| ab 					  |
# 				+-------------------+
#
# 		) Functions with one string argument inherit the repetoire of their argument.
#
# 			The result of UPPER( utf8'abc' ) has ASCII repetoire because its argument has ASCII
# 			repetoire.
#
# 		) For functions that return a string but do not have string arguments and use character_set_connection
# 			as the result character set, the result repetoire is ASCII if character_set_connection is ascii,
# 			and UNICODE otherwise:
#
# 				FORMAT(numeric_column, 4);
#
# 			Use of repetoire changes how MySQL evaluates the following example:
#
# 				SET NAMES ascii;
# 				CREATE TABLE t1 (a INT, b VARCHAR(10) CHARACTER SET latin1);
# 				INSERT INTO t1 VALUES (1, 'b');
# 				SELECT CONCAT(FORMAT(a, 4), b) FROM t1;
#
# 			Without repetoire, this error occurs:
#
# 				ERROR 1267 (HY000): Illegal mix of collations (ascii_general_ci, COERCIBLE)
# 				and (latin1_swedish_ci, IMPLICIT) for operation 'concat'
#
# 			Without repetoire, a result is returned:
#
# 				+--------------------------------+
# 				| CONCAT(FORMAT(a, 4), b) 			|
# 				+--------------------------------+
# 				| 1.0000b 								|
# 				+--------------------------------+
#
# 		) Functions with two or more string arguments use the "widest" argument repetoire for the result
# 			repetoire (UNICODE is wider than ASCII)
#
# 			Consider the following CONCAT() calls:
#
# 				CONCAT(_ucs2 X'0041', _ucs2 X'0042')
# 				CONCAT(_ucs2 X'0041', _ucs2 X'00C2')
#
# 			For the first call, the repetoire is ASCII because both arguments are within the range of the ascii character set.
# 			For the second call, the repetoire is UNICODE because the second argument is outside the ascii character set range.
#
# 		) The repetoire for function return values is determined based only on the repertoire of the arguments
# 			that affect the result's character set and collation.
#
# 				IF(column1 < column2, 'smaller', 'greater')
#
# 			The result repetoire is ASCII because the two string arguments (the second argument and the third argument)
# 			both have ASCII repetoire.
#
# 			The first argument does not matter for the result repetoire, even if the expression uses string values.
#
# UTF-8 FOR METADATA
#
# Metadata is "the data about the data". Anything that describes the DB, as opposed to being the contents of the db, is metadata.
#
# Thus column names, database names, user names, version names, and most of the string results from SHOW are metadata.
#
# This is also true of the contents of tables in INFORMATION_SCHEMA because those tables by definition contain
# information about database objects.
#
# Representation of metadata must satisfy these requirements:
#
# 		) All metadata must be in the same character set.
#
# 			Otherwise, neither the SHOW statements nor SELECT statements for tables in INFORMATION_SCHEMA would work
# 			properly because different rows in the same column of the results of these operations would be in different
# 			character sets.
#
# 		) Metadata must include all characters in all languages. Otherwise, users would not be able to name columns and tables
# 			using their own languages.
#
# To satisfy both requirements, MySQL stores metadata in a Unicode character set, namely UTF-8.
#
# This does not cause any disruption if you never use accented or non-Latin characters.
#
# But if you do, you should be aware that metqdata is in UTF-8.
#
# The metadata requirements mean that the return values of the USER(), CURRENT_USER(), SESSION_USER(),
# SYSTEM_USER(), DATABASE() and VERSION() functions have the UTF-8 character set by default.
#
# The server sets the character_set_system system variable to the name of the metadata character set:
#
# 		SHOW VARIABLES LIKE 'character_set_system';
# 		+-----------------------------+----------+
# 		| Variable_name 					| Value 	  |
# 		+-----------------------------+----------+
# 		| character_set_system 			| utf8 	  |
# 		+-----------------------------+----------+
#
# Storage of metadata using Unicode does NOT mean that the server returns headers of columns
# and the results of DESCRIBE functions in the character_set_system character set by default.
#
# When you use SELECT column1 FROM t, the name column1 itself is returned from the server to the
# client in the character set determined by the value of the character_set_results system variable,
# which has a default value of utf8mb4.
#
# If you want the server to pass metadata results back in a different character set, use the SET_NAMES
# statement to force the server to perform character set conversion.
#
# SET_NAMES sets the character_set_results and other related system variables.
#
# (See SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS")
#
# Alternatively, a client program can perform the conversion after receiving the result from the
# server.
#
# It is more efficient for the client to perform the conversion, but this option is not always available for all clients.
#
# If character_set_results is set to NULL, no conversion is performed and the server returns metadata
# using its original character set (the set indicated by character_set_system)
#
# Error messages returned from the server to the client are converted to the client character set automatically, as with metadata.
#
# If you are using (for example) the USER() function for comparison or assignment within a single statement,
# do not worry.
#
# MySQL performs some automatic conversion for you.
#
# 		SELECT * FROM t1 WHERE USER() = latin1_column;
#
# This works because the contents of latin1_column are automatically converted to
# UTF-8 before the comparison.
#
# 		INSERT INTO t1 (latin1_column) SELECT USER();
#
# This works because the contents of USER() are automatically converted to latin1 before the
# assignment.
#
# Although automatic conversion is not in the SQL standard, the standard does say that every character set
# is (in terms of supported characters) a "subset" of Unicode.
#
# Because it is a well-known principle that "what applies to a superset can apply to a subset", we believe
# that a collation for Unicode can apply for comparisons with non-Unicode strings.
#
# For more information about coercion of strings, see SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS"
#
# SPECIFYING CHARACTER SETS AND COLLATIONS
#
# There are default settings for character sets and collations at four levels:
#
# 		server, database, table and column.
#
# The description in the following sections may appear complex, but it has been found in practice
# that multiple-level defaulting leads to natural and obvious results.
#
# CHARACTER SET is used in clauses that specify a character set.
#
# CHARSET can be used as a synonym for CHARACTER SET.
#
# Character set issues affect not only data storage, but also communication between client
# programs and the MySQL server.
#
# If you want the client program to communicate with the server using a character set different
# from the default, you'll need to indicate which one.
#
# For example, to use the utf8mb4 Unicode character set, issue this statement after connecting
# to the server:
#
# 		SET NAMES 'utf8mb4';
#
# For more information about character set set-related issues in client/server communication,
# see SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"
#
# COLLATION NAMING CONVENTIONS
#
# MySQL collation names follow these conventions:
#
# 		) A collation name starts with the name of the character set with which it is associated,
# 			generally followed by one or more suffixes indicating other collation characteristics.
#
# 			For example, utf8mb4_general_ci and latin1_swedish_ci are collations for the utf8mb4
# 			and latin1 character sets, respectively.
#
# 			The binary character set has a single collation, also named binary, with no suffixes.
#
# 		) A language-specific collation includes a locale code or language name.
#
# 			For example, utf8mb4_tr_0900_ai_ci and utf8mb4_hu_0900_ai_ci sort characters for the
# 			utf8mb4 character set using the rules of Turkish and Hungarian, respectively.
#
# 			utf8mb4_turkish_ci and utf8mb4_hungarian_ci are similar but based on a less recent
# 			version of the Unicode Collation Algorithm
#
# 		) Collation suffixes indicate whether a collation is case and accent sensitive, or binary.
#
# 			The following table shows the suffixes used to indicate these characteristics.
#
# 			TABLE 10.1 COLLATION CASE/ACCENT SENSITIVITY SUFFIXES
#
# 			Suffix 		Meaning
# 			_ai 			Accent insensitive
# 			_as 			Accent sensitive
# 			_ci 			Case insensitive
#
# 			_cs 			case-sensitive
# 			_ks 			Kana sensitive
# 			_bin 			Binary
#
# 			For nonbinary collation names that do not specify accent sensitivity, it is determined by case sensitivity.
#
# 			If a collation name does not contain _ai or _as, _ci in the name implies _ai and _cs in the name implies _as.
#
# 			For example, latin1_general_ci is explicitly case insensitive and implicitly accent insensitive,
# 			latin1_general_cs is explicitly case sensitive and implicitly accent sensitive, and utf8mb4_0900_ai_ci
# 			is explicitly case and accent insensitive.
#
# 			For Japanese collations, the _ks suffix indicates that a collation is kana sensitive; that is,
# 			it distinguishes Katakana characters from Hiragana characters.
#
# 			Japanese collations without the _ks suffix are not kana sensitive and treat Katakana and Hiragana
# 			characters equal for sorting.
#
# 			For the binary collation of the binary character set, comparisons are based on numeric byte values.
#
# 			For the _bin collation of a nonbinary character set, comparisons are based on numeric character code
# 			values, which differ from byte values for multibyte characters.
#
# 			For more information, see SECTION 10.8.5, "THE BINARY COLLATION COMPARED TO _BIN COLLATIONS"
#
# 		) For Unicode character sets, collation names may include a version number to indicate the version of the
# 			Unicode Collation Algorithm (UCA) on which the collation is based.
#
# 			UCA-based collations without a version number in the name use the version-4.0.0 UCA weight keys.
#
# 			For example (These have external links related to them - just not written here):
#
# 				) utf8mb4_0900_ai_ci is based on UCA 9.0.0 weight keys 
#
# 				) utf8mb4_unicode_520_ci is based on UCA 5.2.0 weight keys
#
# 				) utf8mb4_unicode_ci (with no version named) is based on UCA 4.0.0 weight keys 
#
# 		) For Unicode character sets, the xxx_general_mysql500_ci collations preserve the pre-5.1.24 ordering
# 			of the original xxx_general_ci collations and permits upgrades for tables created before MySQL 5.1.24 (BUG #27877)
#
# 
# SERVER CHARACTER SET AND COLLATION
#
# MySQL Server has a server character set and a server collation.
#
# These can be set at server startup on the command line or in an option file and changed at runtime.
#
# Initially, the server character set and collation depend on the options that you use when you start mysqld.
#
# You can use --character-set-server for the character set. Along with it, you can add --collation-server for the collation.
#
# If you do not specify a character set, that is the same as saying --character-set-server=utf8mb4.
#
# If you specify only a character set (for example, utf8mb4) but not a collation, that is the same as saying
# --character-set-server=utf8mb4 --collation-server=utf8mb4_0900_ai_ci because utf8mb4_0900_ai_ci is the default
# collation for utf8mb4.
#
# Therefore, the following three commands all have the same effect:
#
# 		mysqld
# 		mysqld --character-set-server=utf8mb4
# 		mysqld --character-set-server=utf8mb4 \
# 			--collation-server=utf8mb4_0900_ai_ci
#
# One way to change the settings is by recompiling.
#
# To change the default server character set and collation when building from sources,
# use the DEFAULT_CHARSET and DEFAULT_COLLATION options for CMake.
#
# For example:
#
# 		cmake . -DDEFAULT_CHARSET=latin1
#
# or
#
# 		cmake . -DDEFAULT_CHARSET=latin1 \
# 			-DDEFAULT_COLLATION=latin1_german1_ci
#
# Both mysqld and CMake verify that the character set/collation combination is valid.
# If not, each program displays an error message and terminates.
#
# The server character set and collation are used as default values if the database character
# set and collation are not specified in CREATE_DATABASE statements.
#
# They have no other purpose.
#
# The current server character set and collation can be determined from the values of the
# character_set_server and collation_server system variables.
#
# These variables can be changed at runtime.
#
# DATABASE CHARACTER SET AND COLLATION
#
# Every database has a database character set and a database collation.
#
# The CREATE_DATABASE and ALTER_DATABASE statements have optional clauses for specifying the
# database character set and collation:
#
# 		CREATE DATABASE db_name
# 			[[DEFAULT] CHARACTER SET charset_name]
#  		[[DEFAULT] COLLATE collation_name]
#
# 		ALTER DATABASE db_name
# 			[[DEFAULT] CHARACTER SET charset_name]
# 			[[DEFAULT] COLLATE collation_name]
#
# The keyword SCHEMA can be used instead of DATABASE.
#
# The CHARACTER SET AND COLLATE clauses make it possible to create databases
# with different character sets and collations on the same MySQL server.
#
# Database options are stored in the data dictionary and can be examined by checking the INFORMATION_SCHEMA.SCHEMATA table.
#
# Example:
#
# 		CREATE DATABASE db_name CHARACTER SET latin1 COLLATE latin1_swedish_ci;
#
# MySQL chooses the database character set and database collation in the following manner:
#
# 		) If both CHARACTER SET charset_name and COLLATE collation_name are specified, character set charset_name and collation collation_name are used.
#
# 		) If CHARACTER SET charset_name is specified without COLLATE, character set charset_name and its default collation are used.
#
# 			To see the default collation for each character set, use the SHOW_CHARACTER_SET statement or query
# 			the INFORMATION_SCHEMA CHARACTER_SETS table
#
# 		) If COLLATE collation_name is specified without CHARACTER SET, the character set associated with collation_name and collation
# 			collation_name are used.
#
# 		) Otherwise (neither CHARACTER SET nor COLLATE is specified), the server character set and server collation are used.
#
# The character set and collation for the default database can be determined from the values of the character_set_database
# and collation_database system variables.
#
# The server sets these variables whenever the default database changes.
#
# If there is no default database, the variables have the same value as the corresponding server-level
# system variables, character_set_server and collation_server.
#
# To see the default character set and collation for a given database, use these statements:
#
# 		USE db_name;
# 		SELECT @@character_set_database, @@collation_database;
#
# Alternatively, to display the values without changing the default database:
#
# 		SELECT DEFAULT_CHARACTER_SET_NAME, DEFAULT_COLLATION_NAME
# 		FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'db_name';
#
# The database character set and collation affect these aspects of server operation:
#
# 		) For CREATE_TABLE statements, the database character set and collation are used as default values for table definitions
# 			if the table character set and collation are not specified.
#
# 			To override this, provide explicit CHARACTER SET and COLLATE table options.
#
# 		) For LOAD_DATA statements that include no CHARACTER SET clause, the server uses the character set indicated by the
# 			character_set_database system variable to interpret the information in the file.
#
# 			To override this, provide an explicit CHARACTER SET clause.
#
# 		) For stored routines (procedures and functions), the database character set and collation in effect at
# 			routine creation time are used as the character set and collation of character data parameters
# 			for which the declaration includes no CHARACTER SET or COLLATE attribute.
#
# 			To override this, provide explicit CHARACTER SET and COLLATE attributes.
#
# TABLE CHARACTER SET AND COLLATION
#
# Every table has a table character set and a table collation. The CREATE_TABLE and ALTER_TABLE statements have optional clauses
# for specifying the table character set and collation:
#
# 		CREATE TABLE tbl_name (column_list)
# 			[[DEFAULT] CHARACTER SET charset_name]
# 			[COLLATE collation_name]]
#
# 		ALTER TABLE tbl_name
# 			[[DEFAULT] CHARACTER SET charset_name]
# 			[COLLATE collation_name]
#
# Example:
#
# 		CREATE TABLE t1 ( --- )
# 		CHARACTER SET latin1 COLLATE latin1_danish_ci;
#
# MySQL chooses the table character set and collation in the following manner:
#
# 		) If both CHARACTER SET charset_name and COLLATE collation_name are specified, character set charset_name and collation collation_name are used.
#
# 		) If CHARACTER SET charset_name is specified without COLLATE, character set charset_name and its default collation are used.
#
# 			To see the default collation for each character set, use the SHOW_CHARACTER_SET statement or query the INFORMATION_SCHEMA CHARACTER_SETS table
#
# 		) If COLLATE collation_name is specified without CHARACTER SET, the character set associated with collation_name and collation collation_name are used.
#
# 		) Otherwise (neither CHARACTER SET nor COLLATE is specified), the database character set and collation are used.
#
# The table character set and collation are used as default values for column definitions if the column character
# set and collation are not specified in the individual column definitions.
#
# The table character set and collation are MySQL extensions; there are no such things in standard SQL.
#
# COLUMN CHARACTER SET AND COLLATION
#
# Every "character" column (that is, a column of type CHAR, VARCHAR or TEXT) has a column character set
# and a column collation.
#
# Column definition syntax for CREATE_TABLE and ALTER_TABLE has optional clauses for specifying the column
# character set and collation:
#
# 		col_name {CHAR | VARCHAR | TEXT} (col_length)
# 			[CHARACTER SET charset_name]
# 			[COLLATE collation_name]
#
# These clauses can also be used for ENUM and SET columns:
#
# 		col_name {ENUM | SET} (val_list)
# 			[CHARACTER SET charset_name]
# 			[COLLATE collation_name]
#
# Examples:
#
# 		CREATE TABLE t1
# 		(
# 			col1 VARCHAR(5)
# 				CHARACTER SET latin1
# 				COLLATE latin1_german1_ci
# 		);
#
# 		ALTER TABLE t1 MODIFY
# 			col1 VARCHAR(5)
# 				CHARACTER SET latin1
# 				COLLATE latin1_swedish_ci;
#
# MySQL chooses the column character set and collation in the following manner:
#
# 		) If both CHARACTER SET charset_name and COLLATE collation_name are specified, character set
# 			charset_name and collation collation_name are used.
#
# 			CREATE TABLE t1
# 			(
# 				col1 CHAR(10) CHARACTER SET utf8 COLLATE utf8_unicode_ci
# 			) CHARACTER SET latin1 COLLATE latin1_bin;
#
# 			The character set and collation are specified for the column, so they are used.
#
# 			The column has character set UTF8 and collation utf8_unicode_ci
#
# 		) If CHARACTER SET charset_name is specified without COLLATE, character set charset_name
# 			and its default collation are used.
#
# 			CREATE TABLE t1
# 			(
# 				col1 CHAR(10) CHARACTER SET utf8
# 			) CHARACTER SET latin1 COLLATE latin1_bin;
#
# 			The character set is specified for the column, but the collation is not.
#
# 			The column has character set utf8 and the default collation for utf8,
# 			which is utf8_general_ci
#
# 			To see the default collation for each character set, use the SHOW_CHARACTER_SET
# 			statement or query the INFORMATION_SCHEMA CHARACTER_SETS table.
#
# 		) If COLLATE collation_name is specified without CHARACTER SET, the character set associated
# 			with collation_name and collation collation_name are used.
#
# 			CREATE TABLE t1
# 			(
# 				col1 CHAR(10) COLLATE utf8_polish_ci
# 			) CHARACTER SET latin1 COLLATE latin1_bin;
#
# 			The collation is specified for the column, but the character set is not.
#
# 			The column has collation utf8_polish_ci and the character set is the one associated
#			with the collation, which is utf8
#
# 		) Otherwise (neither CHARSET SET nor COLLATE is specified), the table character set and collation are used.
#
# 			CREATE TABLE t1
# 			(
# 				col1 CHAR(10)
# 			) CHARACTER SET latin1 COLLATE latin1_bin;
#
# 			Neither the character set nor collation is specified for the column, so the table
# 			defaults are used.
#
# 			The column has character set latin1 and collation latin1_bin
#
# The CHARACTER SET and COLLATE clause are standard SQL.
#
# If you use ALTER_TABLE to convert a column from one character set to another,
# MySQL attempts to map the data values, but if the character set are incompatible - there may be data loss.
#
# CHARACTER STRING LITERAL CHARACTER SET AND COLLATION
#
# Every character string literal has a character set and a collation.
#
# For the simple SELECT 'string', the string has the connection default character set and collation defined
# by the character_set_connection and collation_connection system variables.
#
# A character string literal may have an optional character set introducer and COLLATE clause, to designate it
# as a string that uses a particular character set and collation:
#
# 		[_charset_name]'string' [COLLATE collation_name]
#
# The _charset_name expression is formally called an introducer.
#
# It tells the parser, "the string that follows uses character set charset_name"
#
# An introducer does not change the string to the introducer character set like CONVERT() would do.
# It does not change the string value, although padding may occur.
#
# The introducer is just a signal. See SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# Examples:
#
# 		SELECT 'abc';
# 		SELECT _latin1'abc';
# 		SELECT _binary'abc';
# 		SELECT utf8mb4'abc' COLLATE utf8mb4_danish_ci;
#
# Character set introducers and the COLLATE clause are implemented according to standard
# SQL specifications.
#
# MySQL determines the character set and collation of a character string literal in the following manner:
#
# 		) If both _charset_name and COLLATE collation_name are specified, character set charset_name
# 			and collation collation_name are used.
#
# 			collation_name must be a permitted collation for charset_name
#
# 		) If _charset_name is specified but COLLATE is not specified, character set charset_name and its
# 			default collation are used.
#
# 			To see the default collation for each character set, use the SHOW_CHARACTER_SET statement or query
# 			the INFORMATION_SCHEMA CHARACTER_SETS table.
#
# 		) If _charset_name is not specified but COLLATE collation_name is specified, the connection default character
# 			set given by the character_set_connection system variable and collation collation_name are used.
#
# 			collation_name must be a permitted collation for the connection default character set.
#
# 		) Otherwise (neither _charset_name nor COLLATE collation_name is specified), the connection default
# 			character set and collation given by the character_set_connection and collation_connection system
# 			variables are used.
#
# Examples:
#
# 		) A nonbinary string with latin1 character set and latin1_german1_ci collation:
#
# 			SELECT _latin1'Mller' COLLATE latin1_german1_ci;
#
# 		) A nonbinary string with utf8mb4 character set and its default collation
# 			(that is, utf8mb4_general_ci):
#
# 			SELECT _utf8mb4'Mller';
#
# 		) A binary string with binary character set and its default collation (that is, binary):
#
# 			SELECT _binary'Mller';
#
# 		) A nonbinary string with the connection default character set and utf8mb4_general_ci collation
# 			(fails if the connection character set is not utf8mb4):
#
# 			SELECT 'Mller' COLLATE utf8mb4_general_ci;
#
# 		) A string with the connection default character set and collation:
#
# 			SELECT 'Mller';
#
# An introducer indicates the character set for the following string, but does not change how the parser
# performs escape processing within the string.
#
# Escapes are always interpreted by the parser according to the character set given by character_set_connection
#
# The following examples show that escape processing occurs using character_set_connection even in the presence
# of an introducer.
#
# The examples use SET_NAMES (which changes character_set_connection, as discussed in Section 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"),
# and display the resulting strings using the HEX() function so that the exact string contents can be seen.
#
# Example 1:
#
# 		SET NAMES latin1;
# 		SELECT HEX('\n'), HEX(_sjis'\n');
# 		+-----------------+-------------------+
# 		| HEX('\n') 		| HEX(_sjis'\n')   |
# 		+-----------------+-------------------+
# 		| E00A 				| E00A 				  |
# 		+-----------------+-------------------+
#
# Here,  (hexadecimal value E0) is followed by \n, the escape sequence for newline.
#
# The escape sequence is interpreted using the character_set_connection value of 
# latin1 to produce a literal newline (hexadecimal value 0A).
#
# This happens even for the second string. That is, the _sjis introducer does not affect
# the parser's escape processing.
#
# Example 2:
#
# 		SET NAMES sjis;
# 		SELECT HEX('\n'), HEX(_latin1,'\n');
# 		+----------------+-------------------+
# 		| HEX('\n') 	  | HEX(_latin1'\n') |
# 		+----------------+-------------------+
# 		| E05C6E 		  | E05C6E 				 |
# 		+----------------+-------------------+
#
# Here, character_set_connection is sjis, a character set in which the sequence of  followed by
# \ (hexadecimal values 05 and 5C) is a valid multibyte character.
#
# Hence, the first two bytes of the string are interpreted as a single sjis character, and the
# \ is not interpreted as an escape character.
#
# The following n (hexadecimal value 6E) is not interpreted as part of an escape sequence.
# This is true even for the second string; the _latin1 introducer does not affect escape processing.
#
# THE NATIONAL CHARACTER SET
#
# Standard SQL defines NCHAR or NATIONAL_CHAR as a way to indicate that a CHAR column should use some predefined
# character set.
#
# MySQL uses utf8 as this predefined character set.
#
# For example, these data type declarations are equivalent:
#
# 		CHAR(10) CHARACTER SET utf8
# 		NATIONAL CHARACTER(10)
# 		NCHAR(10)
#
# As are these:
#
# 		VARCHAR(10) CHARACTER SET utf8
# 		NATIONAL VARCHAR(10)
# 		NCHAR VARCHAR(10)
# 		NATIONAL CHARACTER VARYING(10)
# 		NATIONAL CHAR VARYING(10)
#
# You can use N'literal' (or n'literal') to create a string in the national character set.
# These statements are equivalent:
#
# 		SELECT N'some text';
# 		SELECT n'some text';
# 		SELECT _utf8'some text';
#
# CHARACTER SET INTRODUCERS
#
# A character string literal, hexadecimal literal or bit-value literal may have an optional character
# set introducer and COLLATE clause, to designate it as a string that uses a particular character set and
# collation:
#
# 		[_charset_name] literal [COLLATE collation_name]
#
# The _charset_name expression is formally called an introducer.
#
# IT tells the parser, "The string that follows uses character set charset_name"
#
# An introducer does not change the string to the introducer character set like CONVERT()
# would do.
#
# It does not change the string value, although padding may occur.
#
# The introducer is just a signal.
#
# For character string literals, space between the introducer and the string is permitted but optional.
#
# Examples:
#
# 		SELECT 'abc';
# 		SELECT _latin1'abc';
# 		SELECT _binary'abc';
#
# 		SELECT _utf8mb4'abc' COLLATE utf8mb4_danish_ci;
#
# 		SELECT _latin1 X'4D7953514C';
# 		SELECT _utf8mb4 0x4D7953514C COLLATE utf8mb4_danish_ci;
#
# 		SELECT _latin1 b'1000001';
# 		SELECT _utf8mb4 0b1000001 COLLATE utf8mb4_danish_ci;
#
# Character set introducers and the COLLATE clause are implemented according to standard SQL specifications.
#
# Character string literals can be designated as binary strings by using the _binary introducer.
#
# Hexadecimal literals and bit-value literals are binary strings by default, so _binary is permitted,
# but normally unnecessary.
#
# _binary may be useful to preserve a hexadecimal or bit literal as a binary string in contexts
# for which the literal is otherwise treated as a number.
#
# For example, bit operations permit numeric or binary string arguments in MySQL 8.0 and higher,
# but treat hexadecimal and bit literals as numbers by default.
#
# To explicitly specify binary string context for such literals, use a _binary introducer
# for at least one of the arguments:
#
# 		SET @v1 = X'000D' | X'0BC0';
# 		SET @v2 = _binary X'000D' | X'0BC0';
# 		SELECT HEX(@v1), HEX(@v2);
# 		+---------------+-----------------+
# 		| HEX(@v1) 		 | HEX(@v2) 		 |
# 		+---------------+-----------------+
# 		| BCD 			 | 0BCD 				 |
# 		+---------------+-----------------+
#
# The displayed result appears similar for both bit operations, but the result without _binary is a BIGINT value,
# whereas the result with _binary is a binary string.
#
# Due to the difference in result types, the displayed values differ:
#
# 		High-order 0 digits are not displayed for the numeric result
#
# MySQL determines the character set and collation of a character string literal, hexadecimal literal or
# bit-value literal in the following manner:
#
# 		) If both _charset_name and COLLATE collation_name are specified, character set charset_name and collation
# 			collation_name are used.
#
# 			collation_name must be a permitted collation for charset_name
#
# 		) If _charset_name is specified but COLLATE is not specified, character set charset_name and its default
# 			collation are used.
#
# 			To see the default collation for each character set, use the SHOW_CHARACTER_SET statement or query the
# 			INFORMATION_SCHEMA CHARACTER_SETS table.
#
# 		) If _charset_name it not specified but COLLATE collation_name is specified:
#
# 			) For a character string literal, the connection default character set given by the character_set_connection
# 				system variable and collation collation_name are used.
#
# 				collation_name must be permitted collation for the connection default character set.
#
# 			) For a hexadecimal literal or bit-value literal, the only permitted collation is binary because
# 				these types of literals are binary strings by default.
#
# 		) Otherwise (neither _charset_name nor COLLATE collation_name is specified):
#
# 			) For a character string literal, the connection default character set and collation given by the 
# 				character_set_connection and collation_connection system variables are used.
#
# 			) For a hexadecimal literal or bit-value literal, the character set and collation are binary.
#
# Examples:
#
# 		) Nonbinary strings with latin1 character set and latin1_german1_ci collation:
#
# 			SELECT _latin1'Mller' COLLATE latin1_german1_ci;
# 			SELECT _latin1 X'0A0D' COLLATE latin1_german1_ci;
# 			SELECT _latin1 b'0110' COLLATE latin1_german1_ci;
#
# 		) Nonbinary strings with utf8mb4 character set and its default collation (that is, utf8mb4_0900_ai_ci):
#
# 			SELECT _utf8mb4'Mller';
# 			SELECT _utf8mb4 X'0A0D';
# 			SELECT _utf8mb4 b'0110';
#
# 		) Binary strings with binary character set and its default collation (that is, binary):
#
# 			SELECT _binary'Mller';
# 			SELECT X'0A0D';
# 			SELECT b'0110';
#
# 			The hexadecimal literal and bit-value literal need no introducer because they are binary strings by default
#
# 		) A nonbinary string with the connection default character set and utf8mb4_general_ci collation
# 			(fails if the connection character set is not utf8mb4):
#
# 			SELECT 'Mller' COLLATE utf8mb4_general_ci;
#
# 			This construction (COLLATE ONLY) does not work for hexadecimal literals or bit literals because their
# 			character set is binary no matter the connection character set and binary is not compatible with
# 			the utf8mb4_general_ci collation.
#
# 			The only permitted COLLATE clause in the absence of an introducer is COLLATE binary
#
# 		) A string with the connection default character set and collation:
#
# 			SELECT 'Mller';
#
# For character set literals, an introducer indicates the character set for the following string,
# but does not change how the parser performs escape processing within the string.
#
# Escapes are always interpreted by the parser according to the character set given by
# character_set_connection
#
# For additional discussion and examples, see SECTION 10.3.6 "CHARACTER STRING LITERAL CHARACTER SET AND COLLATION"
#
# EXAMPLES OF CHARACTER SET AND COLLATION ASSIGNMENT
#
# The following examples show how MySQL determines default character set and collation values.
#
# EXAMPLE 1: TABLE AND COLUMN DEFINITION
#
# 		CREATE TABLE t1
# 		(
# 			c1 CHAR(10) CHARACTER SET latin1 COLLATE latin1_german1_ci
# 		) DEFAULT CHARACTER SET latin2 COLLATE latin2_bin;
#
# Here we have a column with a latin1 character set and a latin1_german_ci collation.
#
# the definition is explicit, so that is straightforward. Notice that htere is no problem
# with storing a latin1 column in a latin2 table.
#
# EXAMPLE 2: TABLE AND COLUMN DEFINITION
#
# 		CREATE TABLE t1
# 		(
# 			c1 CHAR(10) CHARACTER SET latin1
# 		) DEFAULT CHARACTER SET latin1 COLLATE latin1_danish_ci;
#
# 		THis time, we have a column with a latin1 character set and a default collation.
#
# 		Although it might seem natural, the default collation is not taken from the table level.
#
# 		INstead, because the default collation for latin1 is always latin1_swedish_ci, column c1 has a collation
# 		of latin1_swedish_ci (not latin1_danish_ci)
#
# EXAMPLE 3: TABLE AND COLUMN DEFINITION
#
# 		CREATE TABLE t1
# 		(
# 			c1 CHAR(10)
# 		) DEFAULT CHARACTER SET latin1 COLLATE latin1_danish_ci;
#
# 		We have a column with a default character set and a default collation.
#
# 		In this circumstance, MySQL checks the table level to determine the column char set
# 		and collation.
#
# 		Consequently, the character set for column c1 is latin1 and its collation is latin1_danish_ci
#
# EXAMPLE 4: DATABASE, TABLE and COLUMN DEFINITION
#
# CREATE DATABASE d1
# 		DEFAULT CHARACTER SET latin2 COLLATE latin2_czech_ci;
# USE d1;
# CREATE TABLE t1
# (
# 		c1 CHAR(10)
# );
#
# We create a column without specifying its character set and collation.
#
# We're also not specifying a character set and a collation at the table level.
#
# In this circumstance, MySQL checks the database level to determine the table settings,
# which thereafter become the column settings.
#
# Consequently, the character set for column c1 is latin2 and its collation is latin2_czech_ci
#
# COMPATBILITY WITH OTHER DBMSs
#
# For MaxDB compatbility these two statements are the same:
#
# 		CREATE TABLE t1 (f1 CHAR(N) UNICODE);
# 		CREATE TABLE t1 (f1 CHAR(N) CHARACTER SET ucs2);
#
# CONNECTION CHARACTER SETS AND COLLATIONS
#
# A "connection" is what a client program makes when it connects to the server, to begin a session
# within which it interacts with the server.
#
# The client sends SQL statements, such as queries, over the session connection.
#
# The server sends responses, such as result sets or error messages, over the connection
# back to the client.
#
# CONNECTION CHARACTER SET AND COLLATION SYSTEM VARIABLES
#
# Several character set and collation system variables relate to a client's interaction
# with the server.
#
# Some of these have been mentioned in earlier sections:
#
# 		) The character_set_server and collation_server system variables indicate the server
# 			character set and collation.
#
# 			See SECTION 10.3.2, "SERVER CHARACTER SET AND COLLATION"
#
# 		) The character_set_database and collation_database system variables indicate the character
# 			set and collation of the default database.
#
# 			See SECTION 10.3.3, "DATABASE CHARACTER SET AND COLLATION"
#
# Additional character set and collation system variables are involved in handling traffic for the
# connection between a client and the server.
#
# Every client has a session-specific connection-related character set and collation system variables.
#
# These session system variable values are initialized at connect time, but can be changed within the
# session.
#
# Several questions about character set and collation handling for client connections can be answered
# in terms of system variables:
#
# 		) What character set are statements in when they leave the client?
#
# 			The server takes the character_set_client system variable to be the
# 			character set in which statements are sent by the client.
#
# 				NOTE:
#
# 					Some characters sets cannot be used as the client character set. See IMPERMISSIBLE CLIENT CHARACTER SETS.
#
# 		) What character set should the server translate statements to after receiving them?
#
# 			To determine this, the server uses the character_set_connection and collation_connection system variables.
#
# 				) The server converts statements sent by the client from character_set_client to character_set_connection
#
# 				 	Exception: For string literals that have an introducer such as utf8mb4 or _latin2, the introducer
# 					determines the character set. See SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# 				) collation_connection is important for comparisons of literal strings.
#
# 					For comparisons of strings with column values, collation_connection does not matter
# 					because columns have their own collation, which has a higher collation precedence.
#
# 					(See SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS")
#
# 		) What character set should the server translate query results to before shipping them back to the client?
#
# 			The character_set_results system variable indicates the character set in which the server
# 			returns query results to the client.
#
# 			This includes result data such as column values, result metadata such as column names and errors messages.
#
# 			To tell the server to perform no conversion of result sets or error messages, set character_set_results
# 			to NULL or binary.
#
# 				SET character_set_results = NULL;
# 				SET character_set_results = binary;
#
# 			For more information about character sets and error messages, see SECTION 10.6, "ERROR MESSAGE CHARACTER SET"
#
# To see the values of the character set and collation system variables that apply to the current session,
# use this statement:
#
# 		SELECT * FROM performance_schema.session_variables
# 		WHERE VARIABLE_NAME IN (
# 			'character_set_client', 'character_set_connection',
# 			'character_set_results', 'collation_connection'
# 		) ORDER BY VARIABLE_NAME;
#
# The following simpler statements also display the connection variables, but include other related variables
# as well.
#
# They can be useful to see ALL character set and collation system variables:
#
# 		SHOW SESSION VARIABLES LIKE 'character\_set\_%';
# 		SHOW SESSION VARIABLES LIKE 'collation\_%';
#
# Clients can fine-tune the settings for these variables, or depend on the defaults (in which case,
# you can skip the rest of this section)
#
# If you do not use defaults, you must change the character settings for each connection to the server.
#
# IMPERMISSIBLE CLIENT CHARACTER SETS
#
# The character_set_client system variable cannot be set to certain character sets:
#
# 		ucs2
# 		utf16
# 		utf16le
# 		utf32
#
# Attempting to use any of those character sets as the client character set produces an error:
#
# 		SET character_set_client = 'ucs2';
# 		ERROR 1231 (42000): Variable 'character_set_client'
# 		can't be set to the value of 'ucs2'
#
# The same error occurs if any of those character sets are used in the following contexts,
# all of which result in an attempt to set character_set_client to the named character set:
#
# 		) The --default-character-set=charset_name command option used by MySQL client programs 
# 			such as mysql and mysqladmin
#
# 		) The SET_NAMES_'charset_name' statement
#
# 		) The SET_CHARACTER_SET_'charset_name' statement
#
# CLIENT PROGRAM CONNECTION CHARACTER SET  CONFIGURATION
#
# When a client connects to the server, it indicates which character set it wants to use for
# communication with the server.
#
# (Actually, the client indicates the default collation for that character set, from which
# 	the server can determine the character set)
#
# The server uses this information to set the character_set_client, character_set_results,
# character_set_connection system variables to the character set, and collation_connection to
# the character set default collation.
#
# In effect, the server performs the equivalent of a SET_NAMES operation.
#
# If the server does not support the requested character set or collation, it falls back
# to using the server character set and collation to configure the connection.
#
# For additional detail, about this fallback behavior, see CONNECTION CHARACTER SET ERROR HANDLING
#
# THe mysql, mysqladmin, mysqlcheck, mysqlimport and mysqlshow client programs determine the default
# character set to use as follows:
#
# 		) In the absence of other information, each client uses the compiled-in default character set, usually utf8mb4
#
# 		) Each client can autodetect which character set to use based on the operating system setting, such as 
# 			the value of the LANG or LC_ALL locale environment variable on Unix systems or the code page
# 			setting on Windows systems.
#
# 			For systems on which the locale is available from the OS, the client uses it to set the default
#  		character set rather than using the compiled-in default.
#
# 			For example, setting LANG to ru_RU.KOI8-R causes the koi8r character set to be used.
#
# 			Thus, users can configure the locale in their environment for use by MySQL clients.
#
# 			The OS character set is mapped to the closest MySQL character set if there is no exact match.
#
# 			IF the client does not support the matching character set, it uses the compiled-in default.
#
# 			FOr example, utf8 and utf-8 map to utf8mb4, and ucs2 is not supported as a connection
# 			character set, so it maps to the compiled-in default.
#
# 			C applications can use character set autodetection based on the OS setting by invoking mysql_options()
# 			as follows before connecting to the server:
#
# 				mysql_options(mysql,
# 								  MYSQL_SET_CHARSET_NAME,
# 								  MYSQL_AUTODETECT_CHARSET_NAME);
#
# 		) Each client supports a --default-character-set option, which enables users to specify the character set
# 			explicitly to override whatever default the client otherwise determines.
#
# 				NOTE:
#
# 					Some character sets cannot be used as the client character set.
#
# 					Attempting to use them with --default-character-set produces an error.
#
# 					See IMPERMISSIBLE CLIENT CHARACTER SETS
#
# With the mysql client, to use a character set different from the default, you could explicitly execute
# a SET_NAMES statement every time you connect to the server (see CLIENT PROGRAM CONNECTION CHARACTER SET CONFIGURATION)
#
# To accomplish the same result more easily, specify the character set in your option files.
#
# For example, the following option file setting changes the three connection-related character
# set system variables set to koi8r each time you invoke mysql:
#
# 		[mysql]
# 		default-character-set=koi8r
#
# If oyu are using the mysql client with auto-reconnect enabled (which is not recommended), it is
# preferable to use the charset command rather than SET_NAMES.
#
# For example:
#
# 		charset koi8r
# 		Charset changed
#
# The charset command issues a SET_NAMES statement, and also changes the default character set that
# mysql uses when it reconnects after the connection has dropped.
#
# When configuring client programs, you must also consider the environment within which they execute.
#
# See SECTION 10.5 "CONFIGURING APPLICATION CHARACTER SET AND COLLATION"
#
# SQL STATEMENTS FOR CONNECTION CHARACTER SET CONFIGURATION
#
# After a connection has been established, clients can change the character set and collation system variables
# for the current session.
#
# These variables can be changed individually using SET statements, but two more convenient statements affect hte
# connection-related character set system variables as a group:
#
# 		) SET NAMES 'charset_name' [COLLATE 'collation_name']
#
# 			SET_NAMES indicates what character set the client will use to send SQL statements to the server.
#
# 			Thus, SET_NAMES_'cp1251' tells the server, "future incoming messages from this client are in the charset cp1251"
#
# 			It also specifies the character set that the server should use for sending results back to the client.
#
# 			(For example, it indicates what character set to use for column values if you use a SELECT statement that produces
# 				a result set)
#
# 			A SET_NAMES_'charset_name' statement is equivalent to these three statements:
#
# 				SET character_set_client = charset_name;
# 				SET character_set_results = charset_name;
# 				SET character_set_connection = charset_name;
#
# 			Setting character_set_connection to charset_name also implicitly sets collation_connection to the default
# 			collation for charset_name.
#
# 			It is unnecessary to set that collation explicitly.
#
# 			To specify a particular collation to use for collation_connection, add a COLLATE clause:
#
# 				SET NAMES 'charset_name' COLLATE 'collation_name'
#
# 		) SET CHARACTER SET 'charset_name'
#
# 			SET_CHARACTER_SET is similar to SET_NAMES but sets character_set_connection and collation_connection
# 			to character_set_database and collation_database
#
# 			(which, as mentioned previously, indicate the character set and collation of the default DB)
#
# 			A SET_CHARACTER_SET_charset_name statement is equivalent to these three statements:
#
# 				SET character_set_client = charset_name;
# 				SET character_set_results = charset_name;
# 				SET collation_connection = @@collation_database;
#
# 			Setting collation_connection also implicitly sets character_set_connection to the character
# 			set associated with the collation (equivalent to executing SET character_set_connection = @@character_set_database)
#
# 			It is unnecessary to set character_set_connection explicitly.
#
# 			NOTE:
#
# 				Some character sets cannot be used as the client character set.
#
# 				Attempting to use them with SET_NAMES or SET_CHARACTER_SET produces an error.
#
# 				See IMPERMISSIBLE CLIENT CHARACTER SETS
#
# Example: Suppose that column1 is defined as CHAR(5) CHARACTER SET latin2.
#
# If you do not say SET_NAMES or SET_CHARACTER_SET, then for SELECT column1 FROM t,
# the server sends back all the values for column1 using the charset that was specified when connecting.
#
# On the other hand, if you say SET NAMES 'latin1' or SET CHARACTER SET 'latin1' before issuing the SELECT
# statement, the server converts the latin2 values to latin1 just before sending results back.
#
# Conversion may be lossy for characters that are not in both character sets.
#
# CONNECTION CHARACTER SET ERROR HANDLING
#
# Attempts to use an inappropriate connection character set or collation can produce an error,
# or cause the server to fall back to its default character set and collation for a given connection.
#
# This section describes problems that can occur when configuring the connection character set.
#
# THese problems can occur when establishing a connection or when changing the char set within an established connection.
#
# CONNECT-TIME ERROR HANDLING
#
# Some character sets cannot be used as the client character set, see IMPERMISSIBLE CLIENT CHARACTER SETS.
#
# If you specify a character set that is valid but not permitted as a client character set,
# the server returns an error:
#
# 		mysql --default-character-set=ucs2
# 		ERROR 1231 (42000): Variable 'character_set_client' can't be set to the value of 'ucs2'
#
# If you specify a character set that the client does not recognize, it produces an error:
#
# 		mysql --default-character-set=bogus
# 		mysql: character set 'bogus' is not a compiled character set and is
# 		not specified in the '/usr/local/mysql/share/charsets/Index.xml' file
# 		ERROR 2019 (HY000): Can't initialize character set bogus
# 		(path: /usr/local/mysql/share/charsets/)
#
# If you specify a character set that the client recognizes but the server does not,
# the server falls back to its default character set and collation.
#
# Suppose that the server is configured to use latin1 and latin1_swedish_ci as its defaults,
# and that it does not recognize gb18030 as a valid character set.
#
# A client that specifies --default-character-set=gb18030 is able to connect to the server,
# but hte resulting character set is not what hte client wants:
#
# 		SHOW SESSION VARIABLES LIKE 'character\_set\_%';
# 		+----------------------------------+------------+
# 		| Variable_name 						  | Value 		|
# 		+----------------------------------+------------+
# 		| character_set_client 				  | latin1 		|
# 		| character_set_connection 		  | latin1 	   |
# 		---
# 		| character_set_results 			  | latin1 		|
# 		---
# 		+----------------------------------+------------+
#
# 		SHOW SESSION VARIABLES LIKE 'collation_connection';
# 		+------------------------+-------------------+
# 		| Variable_name 			 | Value 			   |
#		+------------------------+-------------------+
# 		| collation_connection 	 | latin1_swedish_ci |
# 		+------------------------+-------------------+
#
# YOu can see that the connection system variables have been set to reflect a character
# set and collation of latin1 and latin1_swedish_ci
#
# This occurs because the server cannot satisfy the client char set request and falls back
# to its defaults.
#
# In this case, the client cannot use the character set that it wants because the
# server does not support it.
#
# The client must either be willing to use a different character set, or connect to a 
# different server that supports the desired character set
#
# The same problem occurs in a more subtle context: When the client tells the server to use
# a character set that hte server recognize, but the default collation for that
# char set on the client side is not known on the server side.
#
# THis occurs, ofr example, when a MySQL 8.0 client wnats to connect to a MySQL 5.7 server
# using utf8mb4 as the client character set.
#
# A client that specifies --default-character-set=utf8mb4 is able to connect to the server.
#
# However, as in the previous example, the server falls back to its default character set
# and collation, not what the client requested:
#
# 		SHOW SESSION VARIABLES LIKE 'character\_set\_%';
# 		+----------------------------------+--------------+
# 		| Variable_name 						  | Value 		  |
# 		+----------------------------------+--------------+
# 		| character_set_client 				  | latin1 		  |
# 		| character_set_connection 		  | latin1 		  |
# 		---
# 		| character_set_results 			  | latin1 		  |
# 		---
# 		+----------------------------------+--------------+
#
# 		SHOW SESSION VARIABLES LIKE 'collation_connection';
# 		+-------------------------+-----------------------+
# 		| Variable_name 			  | Value 					  |
# 		+-------------------------+-----------------------+
# 		| collation_connection 	  | latin1_swedish_ci 	  |
# 		+-------------------------+-----------------------+
#
# Why?
#
# After all, utf8mb4 is known to 8.0 client and 5.7 server, so both of them recognize it.
#
# To understand this behavior, it is necessary to understand that when the client tells
# the server which char set it wants to use, it really tells the server the default collation
# for that character set.
#
# Therefore, the aformentioned behavior occurs due to a combination of factors:
#
# 		) The default collation for utf8mb4 differs between MySQL 5.7 and 8.0 (utf8mb4_general_ci for 5.7, utf8mb4_0900_ai_ci for 8.0)
#
# 		) When the 8.0 client requests a char set of utf8mb4, what it sends to the server is the default 8.0 utf8mb4 collation; that is,
# 			the utf8mb4_0900_ai_ci
#
# 		) utf8mb4_0900_ai_ci is implemented only as of MysQL 8.0, so the 5.7 server does not recognize it
#
# 		) Because the 5.7 server does not recognize utf8mb4_0900_ai_ci, it cannot satisfy the client char set request,
# 			and falls back to its default char set and collation (latin1 and latin1_swedish_ci)
#
# In this case, the client can still use utf8mb4 by issuing a SET NAMES 'utf8mb4' statement after connecting.
#
# The resulting collation is the 5.7 default utf8mb4 collation; that is, utf8mb4_general_ci 
#
# If the client additionally wants a collation of utf8mb4_0900_ai_ci, it cannot achieve that because
# the server does not recognize that collation.
#
# The client must either be willing to use a different utf8mb4 collation, or connect to a server from
# MySQL 8.0 or higher.
#
# RUNTIME ERROR HANDLING
#
# Within an estblished connection, the client can request a change of connection character set and collation
# with SET_NAMES or SET_CHARACTER_SET
#
# Some character sets cannot be used as the client character set; see IMPERMISSIBLE CLIENT CHARACTER SETS.
#
# If you specify a character set that is valid, but not permitted as a client character set , the server returns an error:
#
# 		SET NAMES 'ucs2';
# 		ERROR 1231 (42000): Variable 'character_set_client' can't be set to
# 		the value of 'ucs2'
#
# If the server doesn ot recognize the character set (or the collation), it produces an error:
#
# 		SET NAMES 'bogus';
# 		ERROR 1115 (42000): Unknown character set 'bogus'
#
# 		SET NAMES 'utf8mb4' COLLATE 'bogus';
# 		ERROR 1273 (HY000): Unknown collation: 'bogus'
#
# TIP:
#
# 		A client that wants to verify whether its requested character set was honored by the server can execute
# 		the following statement after connecting and checking that hte result is the expected character set:
#
# 			SELECT @@character_set_client;
#
# CONFIGURING APPLICATION CHARACTER SET AND COLLATION
#
# For applications that store data using the default MysQL character set and collation (utf8mb4, utf8mb4_0900_ai_ci),
# no special configuration should be needed.
#
# If applications require data storage using a different character set or collation, you can configure character set
# information in several ways:
#
# 		) Specify character settings per DB. For example, applications that use one database might use the default
# 			of utf8mb4, whereas applications that use another database might use sjis
#
# 		) Specify character settings at server startup. This causes the server to use the given settings for all applications
# 			that do not make other arrangements.
#
# 		) Specify character settings at configuration time, if you build MySQL from source.
#
# 			This causes the server to use the given settings as the defaults for all applications,
# 			without having to specify them at server startup.
#
# When different applications require different character settings, the per-database techniques provides
# a good deal of flexibility.
#
# If most or all applications use the same character set, specifying character settings at server startup 
# or configuration time may be the most convenient.
#
# For the per-database or server-startup techniques, the settings control the character set for data storage.
#
# Applications must also tell the server which character set to use for client/server communications,
# as described in the following instructions.
#
# The examples shown here assume use of the latin1 character set and latin1_swedish_ci collation
# in particular contexts as an alternative to the defaults of utf8mb4 and utf8mb4_0900_ai_ci
#
# 		) Specify character settings per database.
#
# 			To create a database such that its tables will use a given default character set and collation
# 			for data storage, use a CREATE_DATABASE statement as follows:
#
# 				CREATE DATABASE mydb
# 					CHARACTER SET latin1
# 					COLLATE latin1_swedish_ci;
#
# 			Tables created in the database will use latin1 and latin1_swedish_ci by default for any characer columns.
#
# 			APplications that use the datbase should also configure their connection to the server each time they connect.
# 			THis can be done by executing a SET NAMES 'latin1' statement after connecting.
#
# 			THis statement can be used regardless of connection method (the mysql client, PHP scripts, and so forth)
#
# 			In some cases, it may be possible to configure the connection to use the desired char set some other way.
#
# 			For example, to connect using mysql, you can specify the --default-character-set=latin1 command-line option
# 			to achieve the same effect as SET NAMES 'latin1'
#
# 			For more information about configuring client connections, see SECTION 10.4 "CONNECTION CHARACTER SETS AND COLLATIONS"
#
# 			NOTE:
#
# 				If you use ALTER_DATABASE to change the database default character set or collation,
# 				existing stored routines in the database that use those defaults must be dropped
# 				and recreated so that htey use the new defaults.
#
# 				(In a stored routine, variables with character data types use the database defaults
# 				if the character set or collation are not specified explicitly.
#
# 				see SECTION 13.1.17, "CREATE PROCEDURE AND CREATION FUNCTION SYNTAX"
#
# 		) Specifying character settings at server startup.
#
# 			To select a character set and collation at server startup, use the --character-set-server
# 			and --collation-server options.
#
# 			For example, to specify the option in an option file, include these lines:
#
# 				[mysqld]
# 				character-set-server=latin1
# 				collation-server=latin1_swedish_ci
#
# 			These settings apply server-wide and apply as the defaults for databases created by any application,
# 			and for tables created in those datbases.
#
# 			It is still necessary for applications to configure their connection using SET_NAMES or equivalent
# 			after they connect, as described previously.
#
# 			YOu might be tempted to start the server with the --init_connect="SET_NAMES_'latin1'" option to
# 			cause SET_NAMES to be executed automatically for each client that connects.
#
# 			However, this may yield inconsistencies because the init_connect value is not executed for users who
# 			have the CONNECTION_ADMIN or SUPER privilege.
#
# 		) Specify character settings at MySQL configuration time.
#
# 			To select a character set and collation if you configure and build MySQL from source,
# 			use the DEFAULT_CHARSET and DEFAULT_COLLATION CMake options:
#
# 				cmake . -DDEFAULT_CHARSET=latin1 \
# 					-DDEFAULT_COLLATION=latin1_swedish_ci
#
# 			THe resulting server uses latin1 and latin1_swedish_ci as the default for databases and tables and for
# 			client connections.
#
# 			It is unnecessary to use --character-set-server and --collation-server to specify those defaults at server
# 			startup.
#
# 			It is also unecessary for applications to configure their connection using SET_NAMES or equivalent
# 			after they connect to the server.
#
# Regarldess of how you configure the MYSQL character set for application use, you must also consider the
# environment within which those applications execute.
#
# FOr example, if oyu will send statements using UTF-8 text taken from a file that  you create in an editor,
# you shoul dedit the file with the locale of your environment set to UTF-8 so that hte file 
# encoding is correct and so that the operating system handles it correctly.
#
# If you use the mysql client from within a terminal window, the window must be configured to use UTF-8 or characters
# may not display proeprly.
#
# For a script htat executes ina  web environment, the4 script must handle char encodings properly ofr its
# interaction with the MySQl server, and it msut generate pages the correctly indicate the encoding so that
# browsers know how to display the content of the pages.
#
# For example, you can include this <meta> tag within your <head> element:
#
# 		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
#
# ERROR MESSAGE CHARACTER SET
#
# THis section describes how the MySQL server uses char sets for constructing error messages.
#
# FOr information about the language of error messages (rather than the char set), see
# SECTION 10.11 "SETTING THE ERROR MESSAGE LANGUAGE"
#
# FOr general information about configuring error logging, see SECTION 5.4.2 "THE ERROR LOG"
#
# CHARACTER SET FOR ERROR MESSAGE CONSTRUCTION
#
# The server constructs error messages as follows:
#
# 		) The message template uses UTF-8 (utf8mb3)
#
# 		) Parameters in the message template are replaced with values that apply to a specific error occurence:
#
# 			) Identifiers such as table or column names use UTF-8 internally so they are copied as is
#
# 			) Character (nonbinary) string values are converted from their character set to UTF-8
#
# 			) Binary string values are copied as is for bytes in the range 0x20 to 0x7E and using \x
# 				hexadecimal encoding for bytes outside that range.
#
# 				For example, if a duplicate-key error occurs for an attempt to insert 0x41CF9F into a VARBINARY
# 				unique column, the resulting error message uses UTF-8 with some bytes hexadecimal encoded:
#
# 					Duplicate entry 'A\xC3\x9F' for key 1
#
# CHARACTER SET FOR ERROR MESSAGE DISPOSITION
#
# An error message, once ocnstructed, can be written by the server to the error log or sent to clients:
#
# 		) IF the server writes the error message to the error log, it writes it in UTF-8 as constructed, without conversion
# 			to another character set.
#
# 		) If the server sends the error message to a client program, the server converts it from UTF-8 to the character
# 			set specified by the character_set_results system variable.
#
# 			If character_set_results have a value of NULL or binary, no conversion occurs.
#
# 			No conversion occurs if the variable value is utf8mb3 ot utf8mb4, either, because
# 			those character sets have a repetoire that includes all UTF-8 characters used in message
# 			construction.
#
# 			If characters cannot be represented in character_set_results, some encoding may occur during the conversion.
#
# 			The encoding uses Unicode code point values:
#
# 				) Characters in the Basic Multilingual Plane (BMP) range (0x0000 to 0xFFFF) are written using \nnnn notation
#
# 				) Characters outside the BMP range (0x10000 to 0x10FFFF) are written using \+nnnnnn notation
#
# 			Clients can set character_set_results to control the character set in which they receive error messages.
#
# 			THe variable can be set directly, or indireclty, by means such as SET_NAMES.
#
# 			For more information about character_set_results, see SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS"
#
#
# COLUMN CHARACTER SET CONVERSION
#
# To convert a binary or nonbinary string column to use a particular character set, use ALTER_tABLE.
#
# For successful conversion to occur, one of the following conditions must apply:
#
# 		) If the column has a binary data type (BINARY, VARBINARY, BLOB) - all the values that it contains must be encoded
# 			using a single character set (the character set you are converting the column to)
#
# 			If you use a binary column to store information in multiple character sets, MySQL has no way to know which
# 			values use which character set and cannot convert teh data propeprly.
#
# 		) If the column has a nonbinary data type (CHAR, VARCHAR, TEXT), its contents should be encoded
# 			in the column character set, not some other character set.
#
# 			If the contents are encoded in a different character set, you can convert the column to use
# 			a binary data type first, and then to nonbinary column with the desired char set.
#
# Suppose that a table t has a binary column named col1 defined as VARBINARY(50)
#
# Assuming that the information in the column is encoded using a single character set,
# you can convert it to a nonbinary column that has that character set.
#
# For example, if col1 contains binary data representing chars in the greek char set, you can
# convert it as follows:
#
# 		ALTER TABLE t MODIFY col1 VARCHAR(50) CHARACTER SET greek;
#
# If your original column type has a type of BINARY(50), you could convert it to CHAR(50),
# but the resulting values will be padded with 0x00 bytes at the end, which may be
# undesirable.
#
# TO remove these bytes, use the TRIM() function:
#
# 		UPDATE t SET col1 = TRIM(TRAILING 0x00 FROM col1);
#
# SUppose that table t has a nonbinary column named col1 defined as CHAR(50) CHARACTER SET latin1 but
# you want to convert it to use utf8 so that you can store values from many languages.
#
# The following statement accomplishes this:
#
# 		ALTER TABLE t MODIFY col1 CHAR(50) CHARACTER SET utf8;
#
# Conversion may be lossy if the column contains chars that are not in both char sets.
#
# A special case occurs if you have old tables from < 4.1,, where a nonbinary column contains values
# that actually are encoded in a char set different from the server's default char set.
#
# FOr example, an application might have stored sjis value in a column, even though MySQL's default
# character set was different.
#
# iT is possible to convert the column to use the proper character set but an additional step is required.
#
# Suppose that hte server's default character set was latin1 and col1 is defined as CHAR(50), but its content
# are sjis values.
#
# The first step is to convert the column to a binary data type, which removes existting char set information
# without performing any char conversion:
#
# 		ALTER TABLE t MODIFY col1 BLOB;
#
# The next step is to convert the column to a nonbinary data type with the proper character set:
#
# 		ALTER TABLE t1 MODIFY col1 CHAR(50) CHARACTER SET sjis;
#
# This procedure might require that the table not have been modified already with statements such as INSERT
# or UPDATE after an upgrade to 4.1 or later.
#
# In that case, MySQL would store new vlaues in the column using latin1, and the column will contain a mix of
# sjis and latin1 values and cannot be converted properly.
#
# IF you specified attributes when creating a column intiially, you should also specify them when altering
# the table with ALTER_TABLE 
#
# For example, if you specified NOT NULL and an explicit DEFAULT value, you should also provide them
# in the ALTER_TABLE statement.
#
# Otherwise, the resulting column definiton will not include those attributes.
#
# To convert all characer columns in a table, the ALTER TABLE --- CONVERT TO CHARACTER SET charset statement
# may be useful.
#
# See SECTION 13.1.9, "ALTER TABLE SYNTAX"
#
# COLLATION ISSUES
#
# The following section discusses various aspects of char set collations
#
# USING COLLATE IN SQL STATEMENTS
#
# With the COLLATE clause, you can override whathever the default collation is for a comparison.
# COLLATE may be used in various parts of SQL statements.
#
# Here are some examples:
#
# 		) With ORDER BY:
#
# 				SELECT k
# 				FROM t1
# 				ORDER BY k COLLATE latin1_german2_ci;
#
# 		) With AS:
#
# 				SELECT k COLLATE latin1_german2_ci AS k1
# 				FROM t1
# 				ORDER BY k1;
#
# 		) With GROUP BY:
#
# 				SELECT k
# 				FROM t1
# 				GROUP BY k COLLATE latin1_german2_ci;
#
# 		) With aggregate functions:
#
# 				SELECT MAX(k COLLATE latin1_german2_ci)
# 				FROM t1;
#
# 		) With DISTINCT:
#
# 				SELECT DISTINCT k COLLATE latin1_german2_ci
# 				FROM t1;
#
# 		) With WHERE:
#
# 				SELECT
# 				FROM t1
# 				WHERE _latin1 'Mller' COLLATE latin1_german2_ci = k;
#
# 				SELECT
# 				FROM t1
# 				WHERE k LIKE _latin1 'Mller' COLLATE latin1_german2_ci;
#
# 		) With HAVING:
#
# 				SELECT k
# 				FROM t1
# 				GROUP BY k
# 				HAVING k = _latin1 'Mller' COLLATE latin1_german2_ci;
#
# COLLATE CLAUSE PRECEDENCE
#
# The COLLATE clause has high precedence (higehr than binary OR ||), so the following
# two expresisons are equivalent:
#
# 		x || y COLLATE z
# 		x || (y COLLATE z)
#
# CHARACTER SET AND COLLATION COMPATIBILITY
#
# Each character set has one or more collations,, but each collation is associated
# with one and only one character set.
#
# Therefore, the following statement causes an error message
# because the latin2_bin collation is not legal with the latin1 char set:
#
# 		SELECT _latin1 'x' COLLATE latin2_bin;
# 		ERROR 1253 (42000): COLLATION 'latin2_bin' is not valid
# 		for CHARACTER SET 'latin1'
#
# COLLATION COERCIBILITY IN EXPRESSIONS
#
# In the great majority of statements, it is obvious what collation MySQL uses to resolve
# a comparison operation.
#
# FOr example, in the following cases, it should be clear that the collation is the
# collation of column x:
#
# 		SELECT x FROM T ORDER BY x;
# 		SELECT x FROM T WHERE x = x;
# 		SELECT DISTINCT x FROM T;
#
# However, with multiple operands, there can be ambiguity.
#
# For example:
#
# 		SELECT x FROM T WHERE x = 'Y';
#
# SHould the comparison use the collation of the column x, or of the string literal y?
#
# Both x and y have collations, so which one takes precedence?
#
# A mix of collations may also occur in contexts other than comparison.
#
# For example, a multiple-argument concatenation operation such as CONCAT(x, 'Y') combines
# its arguments to produce a single string.
#
# To resolve this, MySQL checks whether the collation of one item can be coerced to hte collation
# of the other.
#
# MySQL assigns coercibility values as follows:
#
# ) An explicit COLLATE clause has a coercibbility of 0 (not coercible at all)
#
# ) The concatenation of two strings with different collations has a coercibility of 1
#
# ) The collation of a column or a stored routine parameter or local variable has a coercibility of 2
#
# ) A "system constant" (the string returned by functions such as USER() or VERSION()) has a coercibility of 3
#
# ) The collation of a literal has a coercibility of 4
#
# ) The collation of a numeric or temporal value has a coercibility of 5
#
# ) NULL or an expression that is derived from NULL has a coercibility of 6
#
# MySQL uses the coercibility values within the following rules to resolve ambiguiteis:
#
# 	) Use the collation with the lowest coercibility value
#
# 	) If both sides have the same coercibility, then:
#
# 		) If both sides are Unicode, or both sides are not Unicode, it is an error.
#
# 		) If one of the sides has a Unicode character set, and another side has a non-Unicode character set,
# 			the side with Unicode char set wins, and automatic char set conversion is applied to the
# 			non-Unicode side.
#
# 			For example, the following statement does not retur nan error:
#
# 				SELECT CONCAT(utf8_column, latin1_column) FROM t1;
#
# 			It returns a result that has a character set of utf8 and the same collation
# 			as utf8_column.
#
# 			Values of latin1_column are automatically converted to utf8 before concatenating.
#
# 		) For an operation with operands from the same character set but that mix a _bin collation
# 			and a _ci or _cs collation, the _bin collation is used.
#
# 			THis is similar to how operations that mix nonbinary and binary strings,
# 			evaluate the operands as binary strings, excpet that it is for collations rather than data types.
#
# Although automatic conversion is not in the SQL standard, the standard does say that every character
# set is (in terms of supported characters) a "subset" of Unicode.
#
# BEcause it is well-known priciple that "what applies to a supsetcan apply to a subset";
# we belive that a collation for Unicode can apply for comparisons with non-Unicode strings.
#
# The following table illustrates some applications of hte preceding rules:
#
# 		COMPARISON 							COLLATION USED
#
# column1 = 'A' 					Use collation of column1
#
# column1 = 'A' COLLATE x 		Use collation of 'A' COLLATE x
#
# column1 COLLATE x = 'A' COLLATE Y    	Error
#
# To determine the coercibility of a string expression, use the COERCIBILITY() function,
# see SECTION 12.15 "INFORMATION FUNCTIONS"
#
# SELECT COERCIBILITY('A' COLLATE latin1_swedish_ci);
# 		-> 0
# SELECT COERCIBILITY(VERSION());
# 		-> 3
# SELECT COERCIBILITY('A');
# 		-> 4
# SELECT COERCIBILITY(1000);
# 		-> 5
#
# For implicit conversion of a numeric or temporal value to a string, such as occurs
# for the argument 1 in the expression CONCAT(1, 'abc'), the result is a character (nonbinary)
# that has a character set and collation determined by the character_set_connection 
# and collation_connection system variables.
#
# See SECTION 12.2 "TYPE CONVERSION IN EXPRESSIONE VALUATION"
#
# THE BINARY COLLATION COMPARED TO _BIN COLLATIONS
#
# This section describes how the binary collation for binary strings
# compares to the _bin collations for nonbinary strings.
#
# Binary strings (as stored using the BINARY, VARBINARY, and BLOB data types) have a character
# set and collation named binary.
#
# Binary strings are sequences of bytes and the numeric values of those bytes determine
# comparison and sort order.
#
# Nonbinary strings (as stored using the CHAR, VARCHAR and TEXT data types) have a character
# and collation other than binary.
#
# A given nonbinary character set can ahve several collations, each of which defines a particular
# comparison and sort order for the characters in the set.
#
# One of these is the binary collation for the character set, indicated by a _bin suffix
# in the collation name.
#
# For example, the binary collations for latin1 and utf8 are named latin1_bin and utf8_bin, respectively.
#
# The binary collation differs from the _bin collations in several respects.
#
# The unit for comparison and sorting.
#
# Binary strings are sequenceso f bytes. For the binary collation, comparison and sortinga re based
# on numeric byte values.
#
# Nonbinary strings are sequences of characters, which might be multibyte. Collations for nonbinary strings
# defines an ordering of the character values for comparison and sorting.
#
# FOr the _bin collation, this ordering is based on numeric character code values, which is similar
# to ordering for binary strings except that character code values might be multibyte.
#
# Character set conversion.
#
# A nonbinary string has a character set and is automatically converted to another character
# set in many cases, even when the string has a _bin collation:
#
# 		) When assigning column values from another column that has a different character set:
#
# 			UPDATE t1 SET utf8_bin_column=latin1_column;
# 			INSERT INTO t1 (latin1_column) SELECT utf8_bin_column FROM t2;
#
# 		) When assigning column values for INSERT or UPDATE using a string literal:
#
# 			SET NAMES latin1;
# 			INSERT INTO t1 (utf8_bin_column) VALUES ('string-in-latin1');
#
# 		) When sending results from the server to a client:
#
# 			SET NAMES latin1;
# 			SELECT utf8_bin_column FROM t2;
#
# For binary string columns, no conversion occurs.
# For the preceding cases, the string value is copied byte-wise.
#
# Lettercase conversion. Collations for nonbinary character sets provide information
# about lettercase of characters, so characters in a nonbinary string can be converted
# from one lettercase to another, even for _bin collations that ignore lettercase for ordering:
# 				
#
#  	SET NAMES latin1 COLLATE latin1_bin;
# 		SELECT LOWER('aA'), UPPER('zZ');
# 		+-----------------+------------------+
# 		| LOWER('aA') 		| UPPER('zZ') 		 |
# 		+-----------------+------------------+
# 		| aa 					| ZZ 					 |
# 		+-----------------+------------------+
#
# The concept of lettercase does not apply to bytes in a binary string.
# To perform lettercase conversion, the string must be converted to a nonbinary string:
#
# 		SET NAMES binary;
# 		SELECT LOWER('aA'), LOWER(CONVERT('aA' USING latin1));
# 		+-----------------+-----------------------------------+
# 		| LOWER('aA') 	   | LOWER(CONVERT('aA' USING latin1)) |
# 		+-----------------+-----------------------------------+
# 		| aA 					| aa 											|
# 		+-----------------+-----------------------------------+
#
# Trailing space handling in comparisons.
#
# Most MySQL collations have a pad attribute of PAD SPACE.
# The exceptions are Unicode collations based on UCA 9.0.0 and higher, which have
# a pad attribute of NO PAD.
#
# (See SECTION 10.10.1, "UNICODE CHARACTER SETS")
#
# To determine the pad attribute for a collation, use the INFORMATION_SCHEMA COLLATIONS
# table, which has a PAD_ATTRIBUTE column.
#
# The pad attribute determines how trailing spaces are treated for comparison of nonbinary
# strings (CHAR, VARCHAR and TEXT values)
#
# NO PAD collations treat spaces at the end of the string like any other character.
#
# For PAD SPACE collations, trailing spaces are insignificant in comparisons; strings
# are compared without regard to any trailing spaces:

# SET NAMES utf8 COLLATE utf8_bin;
# SELECT 'a ' = 'a';
#
# 	+--------------------+
# 	| 'a ' = 'a' 		   |
# 	+--------------------+
# 	| 			1 				|
# 	+--------------------+
#
# For binary strings, all characters are significant in comparisons, including trailing spaces:
#
# 	SET NAMES binary;
# 	SELECT 'a ' = 'a';
#
# 	+-----------------+
# 	| 'a ' = 'a' 		|
# 	+-----------------+
# 	| 		0 				|
# 	+-----------------+
#
# Trailing space handling for inserts and retrievals.
#
# CHAR(N) columns store nonbinary strings. Values shorter than N characters are extended
# with spaces on insertion.
#
# For retrieval, trailing spaces are removed.
#
# BINARY(N) columns store binary strings. Values shorter than N bytes are extended with
# 0x00 bytes on insertion.
#
# For retrieval, nothing is removed; a value of the declared length is always returned.
#
# CREATE TABLE t1 (
# 		a CHAR(10) CHARACTER SET utf8 COLLATE utf8_bin,
# 		b BINARY(10)
# 	 );
# INSERT INTO t1 VALUES ('a', 'a');
# SELECT HEX(a), HEX(b) FROM t1;
#
# +-------------+----------------------------+
# | HEX(a) 	    | HEX(b) 						   |
# +-------------+----------------------------+
# | 61 			 | 6100000000000000000000 		|
# +-------------+----------------------------+
#
# EXAMPLES OF THE EFFECT OF COLLATION
#
# EXAMPLE 1: Sorting German Umlauts
#
# Suppose that column X in table T has these latin1 column values:
#
# 		Muffler
# 		Mller
# 		MX Systems
# 		MySQL
#
# Suppose also that the column values are retrieved using the following statement:
#
# 		SELECT X FROM T ORDER BY X COLLATE collation_name;
#
# The following table shows the resulting order of the values if we use ORDER BY with
# different collations.
#
# latin1_swedish_ci 		latin1_german1_ci 		latin1_german2_ci
# Muffler 					Muffler 						Mller
# MX Systems 				Mller 						Muffler
# Mller 					MX Systems 					MX Systems
# MySQL 						MySQL 						MySQL
#
# The character that causes the different sort orders in this example is the U (), which is the "U-umlaut"
#
# 		) The first column shows the result of the SELECT using the Swedish/Finnish collating rule, which says that
# 			U-umlaut sorts with Y
#
# 		) The second column shows the result of the SELECT using the German DIN-1 rule, which says that U-umlaut sorts with U
#
# 		) The third column shows the result of the SELECT using the German DIN-2 rule, which says that U-umlaut sorts with UE
#
# EXAMPLE 2: SEARCHING FOR GERMAN UMLAUTS
#
# SUppose that you have three tables that differ only by the character set and collation used:
#
# 		SET NAMES utf8;
# 		CREATE TABLE german1 (
# 			c CHAR(10)
# 		) CHARACTER SET latin1 COLLATE latin1_german1_ci;
#
# 		CREATE TABLE german2 (
# 			c CHAR(10)
# 		) CHARACTER SET latin1 COLLATE latin1_german2_ci;
#
# 		CREATE TABLE germanutf8 (
# 			c CHAR(10)
# 		) CHARACTER SET utf8 COLLATE utf8_unicode_ci;
#
# Each table contains two records:
#
# 		INSERT INTO german1 VALUES ('Bar'), ('Br');
# 		INSERT INTO german2 VALUES ('Bar'), ('Br');
# 		INSERT INTO germanutf8 VALUES ('Bar'), ('Br');
#
# Two of the above collations have an A =  equality, and one has no such equality
# (latin1_german2_ci)
#
# For that reason, you'll get these results in comparisons:
#
# 		SELECT * FROM german1 WHERE c = 'Br';
# 		+-----------+
# 		| c 			|
# 		+-----------+
# 		| Bar 		|
# 		| Br 		|
# 		+-----------+
#
# 		SELECT * FROM german2 WHERE c = 'Br';
# 		+-----------+
# 		| c 			|
# 		+-----------+
# 		| Br 		|
# 		+-----------+
#
# 		SELECT * FROM germanutf8 WHERE c = 'Br';
# 		+------------+
# 		| c 			 |
# 		+------------+
# 		| Bar 		 |
# 		| Br 		 |
# 		+------------+
#
# This is not a bug rather a consequence of the sorting properties of latin1_german1_ci and
# utf8_unicode_ci (the sorting shown is done according to the German DIN 5007 standard)
#
# USING COLLATION IN INFORMATION_SCHEMA SEARCHES
#
# String columns in INFORMATION_SCHEMA tables have a collation of utf8_general_ci, which is
# case insensitive.
#
# However, for valuews that correspond to objects that are represented in the file system,
# such as databases and tables, searches in INFORMATION_SCHEMA string columns can be 
# case-sensitive or insensitive, depending on the characteristics of the underlying file system
# and the lower_case_table_names system variable setting.
#
# For example, searches may be case-sensitive if the file system is case-sensitive.
#
# This section describes this behavior and how to modify it if necessary.
#
# Suppose that a query searches the SCHEMATA.SCHEMA_NAME column for the test database.
#
# On Linux, file systems are case-sensitive, so comparisons of SCHEMATA.SCHEMA_NAME with
# 'test' match, but comparisons with 'TEST' do not:
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'test';
# 		+----------------+
# 		| SCHEMA_NAME 	  |
# 		+----------------+
# 		| test 		 	  |
# 		+----------------+
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'TEST';
# 		Empty set (0.00 sec)
#
# These results occur if the lower_case_table_names system variable set to 0.
#
# A lower_case_table_names setting 1 or 2 causes the secondary query to return the
# same (nonempty) results as the first query.
#
# NOTE:
#
# 		It is prohibited to start the server with a lower_case_table_names setting that is different
# 		from the setting used when the server was initialized.
#
# On Windows or macOS, file systems are not case-sensitive, so comparisons match both
# 'test' and 'TEST':
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'test';
# 		+---------------+
# 		| SCHEMA_NAME 	 |
# 		+---------------+
# 		| test 			 |
# 		+---------------+
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA WHERE SCHEMA_NAME = 'TEST';
# 		+---------------+
# 		| SCHEMA_NAME 	 |
# 		+---------------+
# 		| TEST 			 |
# 		+---------------+
#
# The value of lower_case_table_names makes no difference in this context.
#
# The preceding behavior occurs because the utf8_general_ci collation is not used for
# INFORMATION_SCHEMA queries when searching for values that correspond to objects
# represented in the file system.
#
# If the result of a string operation on an INFORMATION_SCHEMA column differs from expectations,
# a workaround is to use an explicit COLLATE clause to force a suitable collation.
#
# See SECTION 10.8.1, "USING COLLATE IN SQL STATEMENTS"
#
# For example, to perform a case-insensitive search, use COLLATE with the INFORMATION_SCHEMA
# column name:
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA
# 		WHERE SCHEMA_NAME COLLATE utf8_general_ci = 'test';
# 		+-------------------+
# 		| SCHEMA_NAME 		  |
# 		+-------------------+
# 		| test 				  |
# 		+-------------------+
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA
# 		WHERE SCHEMA_NAME COLLATE utf8_general_ci = 'TEST';
# 		+-------------------+
# 		| SCHEMA_NAME 		  |
# 		+-------------------+
# 		| test 				  |
# 		+-------------------+
#
# You can also use the UPPER() or LOWER() function:
#
# 		WHERE UPPER(SCHEMA_NAME) = 'TEST'
# 		WHERE LOWER(SCHEMA_NAME) = 'test'
#
# Although a case-insensitive comparison can be performed even on platforms with
# case-sensitive file systems, as just shown, it is not necessarily always the right
# thing to do.
#
# On such platforms, it is possible to have multiple objects with names that differ only
# in lettercase.
#
# For example, tables named city, CITY and City can all exist simultaneously.
#
# Consider whether a search should match all such names or just one and write queries
# accordingly.
#
# The first of the following comparisons (with utf8_bin) is case sensitive;
# the others are not:
#
# 		WHERE TABLE_NAME COLLATE utf8_bin = 'City'
# 		WHERE TABLE_NAME COLLATE utf8_general_ci = 'city'
# 		WHERE UPPER(TABLE_NAME) = 'CITY'
# 		WHERE LOWER(TABLE_NAME) = 'city'
#
# Searches in INFORMATION_SCHEMA string columns for values that refer to INFORMATION_SCHEMA itself
# do use the utf8_general_ci collation because INFORMATION_SCHEMA is a "virtual" database not represented
# in the file system.
#
# For example, comparisons with SCHEMATA.SCHEMA_NAME match 'information_schema' or 'INFORMATION_SCHEMA'
# regardless of platform:
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA
# 		WHERE SCHEMA_NAME = 'information_schema';
# 		+---------------------+
# 		| SCHEMA_NAME 			 |
# 		+---------------------+
# 		| information_schema  |
# 		+---------------------+
#
# 		SELECT SCHEMA_NAME FROM INFORMATION_SCHEMA.SCHEMATA
# 		WHERE SCHEMA_NAME = 'INFORMATION_SCHEMA';
# 		+----------------------+
# 		| SCHEMA_NAME 			  |
# 		+----------------------+
# 		| information_schema   |
# 		+----------------------+
#
# UNICODE SUPPORT
#
# The Unicode Standard includes characters from the Basic Multilingual Plane (BMP) and supplementary
# characters that lie outside the BMP.
#
# This section describes support for Unicode in MySQL. For information about the Unicode Standard itself,
# visit the Unicode Consortium website.
#
# BMP characters have these characteristics:
#
# 		) Their code point values are between 0 and 65535 (or U+0000 and U+FFFF)
#
# 		) They can be encoded in a variable-length encoding using 8, 16, or 24 bits (1 to 3 bytes)
#
# 		) They can be encoded in a fixed-length encoding using 16 bits (2 bytes)
#
# 		) They are sufficient for almost all characters in major languages.
#
# Supplementary characters lie outside the BMP:
#
# 		) Their code point values are between U+10000 AND U+10FFFF
#
# 		) Unicode support for supplementary characters requires character sets that have a range outside
# 			BMP characters and therefore take more space than BMP characters (up to 4 bytes per character)
#
# The UTF-8 (Unicode Transformation Format with 8-bit units) method for encoding Unicode data is implemented
# according to RFC 3629, which describes encoding sequences that take from one to four bytes.
#
# The idea of UTF-8 is that various Unicode characters are encoded using byte sequences of different lengths:
#
# 		) Basic Latin letters, digits, and punctuation signs use one byte.
#
# 		) Most European and Middle East script letters fit into a 2-byte sequence:
#
# 			extended Latin letters (with tilde, macron, acute, grave and other accents), Cyrillic,
# 			Greek, Armenian, Hebrew, Arabic, Syriac and others.
#
# 		) Korean, Chinese, and Japanese ideographs use 3-byte or 4-byte sequences.
#
# MySQL supports these Unicode character sets:
#
# 		) utf8mb4: A UTF-8 encoding of the Unicode character set using one to four bytes per character.
#
# 		) utf8mb3: A UTF-8 encoding of the Unicode character set using one to three bytes per character.
#
# 		) utf8: An alias for utf8mb3
#
# 		) ucs2: The UCS-2 encoding of the Unicode character set using two bytes per character.
#
# 		) utf16: The UTF-16 encoding for the Unicode character set using two or four bytes per character.
#
# 				Like ucs2 but with an extension for supplementary characters.
#
# 		) utf16le: The UTF-16LE encoding for the Unicode character set.
#
# 				Like utf16 but little-endian rather than big-endian.
#
# 		) utf32: The UTF-32 encoding for the Unicode character set using four bytes per character.
#
# 			NOTE:
#
# 				The utf8mb3 character set is deprecated and will be removed in a future MySQL release.
#
# 				Please use utf8mb4 instead. although utf8 is currently an alias for utf8mb3, it will be a reference to utf8mb4.
#
# 				To avoid ambiguity about the meaning of utf8, consider specifying utf8mb4 explicitly for character
# 				set references instead of utf8.
#
# TABLE 10.2, "UNICODE CHARACTER SET GENERAL CHARACTERISTICS", summarizes the general characteristics of Unicode characters
# sets supported by MySQL.
#
# TABLE 10.2 UNICODE CHARACTER SET GENERAL CHARACTERISTICS
#
# CHARACTER SET 		SUPPORTED CHARACTERS 				REQUIRED STORAGE PER CHARACTER
#
# utf8mb3, utf8 		BMP only 								1, 2, or 3 bytes
#
# ucs2 					BMP only 								2 bytes
#
# utf8mb4 				BMP and supplementary 				1, 2, 3 or 4 bytes
#
# utf16 					BMP and supplementary 				2 or 4 bytes
#
# utf16le 				BMP and supplementary 				2 or 4 bytes
#
# utf32 					BMP and supplementary 				4 bytes
#
# Characters outside the BMP compare as REPLACEMENT CHARACTER and convert to '?' when converted to a Unicode
# character set that supports only BMP characters (utf8mb3 or ucs2)
#
# If you use character sets that support supplementary characters and thus are "wider" than the BMP-only
# utf8mb3 and ucs2 character sets, there are potential incompatibility issues for your applications;
#
# See SECTION 10.9.8, "CONVERTING BETWEEN 3-BYTE AND 4-BYTE UNICODE CHARACTER SETS"
#
# That section also describes how to convert tables from the (3-byte) utf8mb3 to the (4-byte)
# utf8mb4, and what constraints may apply in doing so.
#
# A similar set of collations is available for most Unicode character sets.
#
# For example, each has a Danish collation, the names of which are utf8mb4_danish_ci,
# utf8mb3_danish_ci, utf8_danish_ci, ucs2_danish_ci, utf16_danish_ci and utf32_danish_ci.
#
# The exception is utf16le, which has only two collations.
#
# For information about Unicode collations and their differentiating properties, including
# collation properties for supplementary characters, see SECTION 10.10.1, "UNICODE CHARACTER SETS"
#
# The MySQL implementation of UCS-2, UTF-16 and UTF-32 stores characters in big-endian byte
# order and does not use a byte order mark (BOM) at the beginning of values.
#
# Other database systems might use little-endian byte order or a BOM.
#
# In such cases, conversion of values will need to be performed when transferring data between
# those systems and MySQL.
#
# The implementation of UTF-16LE is little-endian
#
# MySQL uses no BOM for UTF-8 values.
#
# Client applications that communicate with the server using Unicode should set the
# client character set accordingly; for example, by issuing a SET NAMES 'utf8mb4' statement.
#
# Some character sets cannot be used as the client character set.
# Attempting to use them with SET_NAMES or SET_CHARACTER_SET produces an error.
#
# See IMPERMISSIBLE CLIENT CHARACTER SETS.
#
# The following sections provide additional detail on the Unicode character sets
# in MySQL.
#
# THE UTF8MB4 CHARACTER SET (4-BYTE UTF-8 UNICODE ENCODING)
#
# The utf8mb4 character set has these characteristics:
#
# 		) Supports BMP and supplementary characters
#
# 		) Requires a maximum of four bytes per multibyte character.
#
# utf8mb4 contrasts with the utf8mb3 character set, which supports only BMP characters
# and uses a maximum of three bytes per character:
#
# 		) For a BMP character, utf8mb4 and utf8mb3 have identical storage characteristics: same code values,
# 			same encoding, same length.
#
# 		) For a supplementary character, utf8mb4 requires four bytes to store it, whereas utf8mb3 cannot store the
# 			character at all.
#
# 			When converting utf8mb3 columns to utf8mb4, you need not worry about converting supplementary characters
# 			because there will be none.
#
# utf8mb4 is a superset of utf8mb3, so for an opperation such as the following concatenation, the result
# has character set utf8mb4 and the collation of utf8mb4_col:
#
# 		SELECT CONCAT(utf8mb3_col, utf8mb4_col);
#
# Similarly, the following comparison in the WHERE clause works according to the collation of utf8mb4_col:
#
# 		SELECT * FROM utf8mb3_tbl, utf8mb4_tbl
# 		WHERE utf8mb3_tbl.utf8mb3_col = utf8mb4_tbl.utf8mb4_col;
#
# For information about data type storage as it relates to multibyte character sets,
# see STRING TYPE STORAGE REQUIREMENTS.
#
# THE UTF8MB3 CHARACTER SET (3-BYTE UTF-8 UNICODE ENCODING
#
# The utf8mb3 character set has these characteristics:
#
# 		) Supports BMP characters only (no support for supplementary characters)
#
# 		) Requires a maximum of three bytes per multibyte character.
#
# Applications that use UTF-8 data but require supplementary character support should use
# utf8mb4 rather than utf8mb3 (see SECTION 10.9.1, "THE UTF8MB4 CHARACTER SET (4-BYTE UTF-8 UNICODE ENCODING)"
#
# Exactly the same set of characters is available in utf8mb3 and ucs2. That is, they have the same repetoire.
#
# utf8 is an alias for utf8mb3; the character limit is implicit, rather than explicit in the name.
#
# 		NOTE:
#
# 			The utf8mb3 character set is deprecated and will be removed in a future MySQL release.
#
# 			Please use utf8mb4 instead. Although utf8 is currently an alias for utf8mb3, at that
# 			point utf8 will become a reference to utf8mb4.
#
# 			To avoid ambiguity about the meaning of utf8, consider specifying utf8mb4 explicitly
# 			for character set references instead of utf8.
#
# utf8mb3 can be used in CHARACTER SET clauses, and utf8mb3_collation_substring in COLLATE clauses,
# where collation_substring is bin, czech_ci, danish_ci, esperanto_ci, estonian_ci and so forth.
#
# For example:
#
# 		CREATE TABLE t (s1 CHAR(1) CHARACTER SET utf8mb3;
# 		SELECT * FROM t WHERE s1 COLLATE utf8mb3_general_ci = 'x';
#
# 		DECLARE x VARCHAR(5) CHARACTER SET utf8mb3 COLLATE utf8mb3_danish_ci;
# 		SELECT CAST('a' AS CHAR CHARACTER SET utf8) COLLATE utf8_czech_ci;
#
# MySQL immediately converts instances of utf8mb3 in statements to utf8, so in statements
# such as SHOW CREATE TABLE or SELECT CHARACTER_SET_NAME FROM INFORMATION_SCHEMA.COLUMNS
# or SELECT COLLATION_NAME FROM INFORMATION_SCHEMA.COLUMNS, users will see the name 
# utf8 or utf8_collation_substring.
#
# utf8mb3 is also valid in contexts other than CHARACTER SET clauses.
#
# For example:
#
# 		mysqld --character-set-server=utf8mb3
#
# 		SET NAMES 'utf8mb3'; /* and other SET statements that have similar effect */
# 		SELECT _utf8mb3 'a';
#
# For information about data type storage as it relates to multibyte character sets,
# see STRING TYPE STORAGE REQUIREMENTS.
#
# THE UTF8 CHARACTER SET (ALIAS FOR UTF8MB3)
#
# utf8 is an alias for the utf8mb3 character set.
#
# For more information, see SECTION 10.9.2, "THE UTF8MB3 CHARACTER SET (3-BYTE UTF-8 UNICODE ENCODING"
#
# 		NOTE:
#
# 			The utf8mb3 character set is deprecated, etc. - use utf8mb4 explicitly 
#
# THE UCS2 CHARACTER SET (UCS-2 UNICODE ENCODING)
#
# In UCS-2, every character is represented by a 2-byte Unicode code with the most significant byte first.
#
# For example: LATIN CAPITAL LETTER A has the code 0x0041 and it is stored as a 2-byte sequence:
#
# 		0x00 0x41
#
# CYRILLIC SMALL LETTER YERU (Unicode 0x044B) is stored as a 2-byte sequence: 0x04 0x4B
#
# For Unicode characters and their codes, please refer to the Unicode Consortium website.
#
# The ucs2 character set has these characteristics:
#
# 		) Supports BMP characters only (no support for supplementary characters)
#
# 		) Uses a fixed-length 16-bit encoding and requires two bytes per character.
#
# THE UTF16 CHARACTER SET (UTF-16 UNICODE ENCODING)
#
# The utf16 character set is the ucs2 character set with an extension that enables
# encoding of supplementary characters:
#
# 		) For a BMP character, utf16 and ucs2 have identical storage characteristics: same code values, same encoding,
# 			same length.
#
# 		) For a supplementary character, utf16 has a special sequence for representing the character using 32 bits.
#
# 			This is called the "surrogate" mechanism: For a number greater than 0xffff, take 10 bits and add them
# 			to 0xd800 and put them in the first 16-bit word, take 10 more bits and add them to 0xdc00 and pput them
# 			in the next 16-bit word.
#
# 			Consequently, all supplementary characters requires 32 bits, where the first 16 bits are a number between
# 			0xd800 and 0xdbff, and the last 16 bits are a number between 0xdc00 and 0xdfff
#
# 			Examples are in SECTION 15.5 SURROGATES AREA of the Unicode 4.0 document
#
# Because utf16 supports surrogates and ucs2 does not, there is a validity check that applies only in utf16:
#
# 		You cannot insert a top surrogate without a bottom surrogate, or vice versa.
#
# For example:
#
# 		INSERT INTO t (ucs2_column) VALUES (0xd800); /* legal */
# 		INSERT INTO t (utf16_column) VALUES (0xd800); /* Illegal */
#
# There is no validity check for characters that are technically valid, but are not true
# Unicode (that is, characters that Unicode considers to be "unassigned code points" or "private use" characters
# or even "illegals")
#
#
# Because MySQL must allow for the worst case (that one character requires four bytes) the maximum length
# of a utf16 column or index is only half of the maximum length for a ucs2 column or index.
#
# For example, the maximum length of a MEMORY table index key is 3072 bytes, so these statements
# create tables with the longest permitted indexes for ucs2 and utf16 columns:
#
# 		CREATE TABLE tf (s1 VARCHAR(1536) CHARACTER SET ucs2) ENGINE=MEMORY;
# 		CREATE INDEX i ON tf (s1);
#
# 		CREATE TABLE tg (s1 VARCHAR(768) CHARACTER SET utf16) ENGINE=MEMORY;
# 		CREATE INDEX i ON tg (s1);
#
# THE UTF16LE CHARACTER SET (UTF-16LE UNICODE ENCODING)
#
# This is the same as utf16 but is little-endian rather than big-endian.
#
# THE UTF32 CHARACTER SET (UTF-32 UNICODE ENCODING)
#
# The utf32 character set is fixed length (like ucs2 and unlike utf16).
#
# utf32 uses 32 bits for every character, unlike ucs2 (which uses 16 bits for every character),
# and unlike utf16 (which uses 16 bits for some characters and 32 bits for others)
#
# utf32 takes twice as much space as ucs2 and more space than utf16, but utf32 has teh same
# advantage as ucs2 that it is predictable for storage:
#
# 		The required number of bytes for utf32 equals the number of characters times 4.
#
# Also, unlike utf16, there are no tricks for encoding in utf32, so the stored value
# equals the code value.
#
# To demonstrate how the latter advantage is useful, here is an example that shows how
# to determine a utf8mb4 value given the utf32 code value:
#
# 		/* Assume code value = 100cc LINEAR B WHEELED CHARIOT */
# 		CREATE TABLE tmp (utf32_col CHAR(1) CHARACTER SET utf32,
# 								utf8mb4_col CHAR(1) CHARACTER SET utf8mb4);
#
# 		INSERT INTO tmp VALUES (0x000100cc, NULL);
# 		UPDATE tmp SET utf8mb4_col = utf32_col;
# 		SELECT HEX(utf32_col), HEX(utf8mb4_col) FROM tmp;
#
# MySQL is very forgiving about additions of unassigned Unicode characters or private-use-area
# characters.
#
# There is in fact only one validity check for utf32; No code value may be greater than
# 0x10ffff
#
# For example, this is illegal:
#
# 		INSERT INTO t (utf32_column) VALUES (0x110000); /* illegal */
#
# CONVERTING BETWEEN 3-BYTE AND 4-BYTE UNICODE CHARACTER SETS
#
# This section describes issues that you may face when converting character data between
# the utf8mb3 and utf8mb4 character sets.
#
# 		NOTE:
#
# 			This discussion focuses primarily on converting between utf8mb3 and utf8mb4, but similar principles
# 			apply to converting between the ucs2 character set and character sets such as utf16 or utf32.
#
# The utf8mb3 and utf8mb4 character sets differ as follows:
#
# 		) utf8mb3 supports only characters in the Basic Multilingual Plane (BMP).
#
# 			utf8mb4 additionally supports supplementary characters that lie outside the BMP.
#
# 		) utf8mb3 uses a maximum of three bytes per character. utf8mb4 uses a maximum of four bytes per character.
#
# NOTE:
#
# 		This discussion refers to the utf8mb3 and utf8mb4 character set names to be explicit about
# 		referring to 3-byte and 4-byte UTF-8 character set data.
#
# 		The exception is that in table definitions, utf8 is used because MySQL converts instances of
# 		utf8mb3 specified in such definitions to utf8, which is an alias for utf8mb3.
#
# One advantage of converting from utf8mb3 to utf8mb4 is that this enables applications to use
# supplementary characters.
#
# One tradeoff is that this may increase data storage space requirements.
#
# In terms of table content, conversion from utf8mb3 to utf8mb4 presents no problems:
#
# 		) For a BMP character, utf8mb4 and utf8mb3 have identical storage characteristics; same code values, same encoding, same length
#
# 		) For a supplementary character, utf8mb4 requires four bytes to store it, whereas utf8mb3 cannot store the character at all.
#
# 			When converting utf8mb3 columns to utf8mb4, you need not worry about converting supplementary characters because there will be none.
#
# In terms of table structure, these are the primary potentional incompatibilities:
#
# 		) For the variable-length character data types (VARCHAR and the TEXT types), the maximum permitted length
# 			in characters is less for utf8mb4 columns than for utf8mb3 columns.
#
# 		) For all character data types (CHAR, VARCHAR and the TEXT types), the maximum number of characters that can be
# 			indexed is less for utf8mb4 columns than for utf8mb3 columns.
#
# Consequently, to convert tables from utf8mb3 to utf8mb4, it may be necessary to change some column or index
# definitions.
#
# Tables can be converted from utf8mb3 to utf8mb4 by using ALTER_TABLE. Suppose that a table has this definition:
#
# 		CREATE TABLE t1 (
# 			col1 CHAR(10) CHARACTER SET utf8 COLLATE utf8_unicode_ci NOT NULL,
# 			col2 CHAR(10) CHARACTER SET utf8 COLLATE utf8_bin NOT NULL
# 		) CHARACTER SET utf8;
#
# The following statement converts t1 to use utf8mb4:
#
# 		ALTER TABLE t1
# 			DEFAULT CHARACTER SET utf8mb4,
# 			MODIFY col1 CHAR(10)
# 				CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci NOT NULL,
# 			MODIFY col2 CHAR(10)
# 				CHARACTER SET utf8mb4 COLLATE utf8mb4_bin NOT NULL;
#
# The catch when converting from utf8mb3 to utf8mb4 is that the maximum length of a column or index key
# is unchanged in terms of bytes.
#
# Therefore, it is smaller in terms of characters because the maximum length of a character
# is four bytes instead of three.
#
# For the CHAR, VARCHAR and TEXT data types, watch for these issues when converting your MySQL tables:
#
# 		) Check all definitions of utf8mb3 columns and make sure they will not exceed the maximum length for the storage engine.
#
# 		) Check all indexes on utf8mb3 columns and make sure they will not exceed the maximum length for the storage engine.
#
# 			Sometimes the maximum can change due to storage engine enhancements.
#
# If the preceding conditions apply, you must either reduce the defined length of columns or indexes,
# or continue to use utf8mb3 rather than utf8mb4.
#
# Here are some examples where structural changes may be needed:
#
# 		) a TINYTEXT column can hold up to 255 bytes, so it can hold up to 85 3-byte or 63 4-byte characters.
#
# 			Suppose that you have a TINYTEXT column that uses utf8mb3 but must be able to contain more than
# 			63 chars.
#
# 			YOu cannot convert it to utf8mb4 unless you also change the data type to a longer type such as TEXT.
#
# 			Similarly, a very long VARCHAR column may need to be changed to one of the longer TEXT types if you
# 			want to convert it from utf8mb3 to utf8mb4
#
# 		) InnoDB has a maximum index length of 767 bytes for tables that use COMPACT or REDUNDANT row format, so for
# 			utf8mb3 or utf8mb4 columns, you can index a maximum of 255 or 191 characters, respectively.
#
# 			If you currently have utf8mb3 columns with indexes longer than 191 characters, you must
# 			index a smaller number of characters.
#
# 			In an InnoDB table that uses COMPACT or REDUNDANT row format, these column and index definitions are legal:
#
# 				col1 VARCHAR(500) CHARACTER SET utf8, INDEX (col1(255))
#
# 			To use utf8mb4 instead, the index must be smaller:
#
# 				col1 VARCHAR(500) CHARACTER SET utf8mb4, INDEX (col1(191))
#
# 				NOTE:
#
# 					For InnoDB tables that use COMPRESSED or DYNAMIC row format, index key prefixes longer
# 					than 767 bytes (up to 3072 bytes) are permitted.
#
# 					Tables created with these row formats enable you to index a maximum of 1024 or 768 characters
# 					for utf8mb3 or utf8mb4 columns, respectively.
#
# 					For related information, see SECTION 15.6.1.7 "LIMITS ON INNODB TABLES"
#
# 					and
#
# 					SECTION 15.10.3 "DYNAMIC AND COMPRESSED ROW FORMATS"
#
# The preceding types of changes are most likely to be required only if you have very long columns or indexes.
#
# Otherwise, you should be able to convert your tables from utf8mb3 to utf8mb4 without problems,
# using ALTER_TABLE as described previously.
#
# The following items summarize other potential incompatibilities:
#
# 		) SET NAMES 'utf8mb4' causes use of the 4-byte character set for connection character sets.
#
# 			As long as no 4-byte characters are sent from the server, there should be
# 			no problems.
#
# 			Otherwise, applications that expect to receive a maximum of three bytes per character
# 			may have problems.
#
# 			Conversely, applications that expect to send 4-byte characters must ensure that the server understands them.
#
# 		) For replication, if character sets that support supplementary characters are to be used on the master,
# 			all slaves must understand them as well.
#
# 			Also, keep in mind the general principle that if a table has different definitions on the master and slave,
# 			this can lead to unexpected results.
#
# 			For example, the differences in maximum index key length make it risky to use utf8mb3 on the master
# 			and utf8mb4 on the slave.
#
# If you have converted to utf8mb4, utf16, utf16le or utf32, and then decide to convert back to utf8mb3
# or ucs2 (for example, to downgrade to an older version of MysQL), these considerations apply:
#
# 		) utf8mb3 and ucs2 data should present no problems.
#
# 		) The server must be recent enough to recognize definitions referring to the character set
# 			from which you are converting.
#
# 		) For object definitions that refer to the utf8mb4 character set, you can dump them with mysqldump
# 			prior to downgrading, eidt the dump file to change instances of utf8mb4 to utf8, and reload the
# 			file in the older server, as long as there are no 4-byte characters in the data.
#
# 			The older server will see utf8 in the dump file object definitions and create new objects
# 			that use the (3-byte) utf8 character set.
#
# SUPPORTED CHARACTER SETS AND COLLATIONS
#
# This section indicates which character sets MySQL supports.
# There is one subsection for each group of related character sets.
#
# For each character set, the permissible collations are listed.
#
# To list the available character sets and their default collations, use the SHOW_CHARACTER_SET
# statement or query the INFORMATION_SCHEMA CHARACTER_SETS table.
#
# For example:
#
# 		SHOW CHARACTER SET;
# 		+----------------+-------------------------------------------------------+-------------------------+---------------+
# 		| Charset 		  | Description 														 | Default collation 		| 	Maxlen   	 |
# 		+----------------+-------------------------------------------------------+-------------------------+---------------+
# 		| armscii8 		  | ARMSCII-8 Armenian 												 | armscii8_general_ci 		| 1 				 |
# 		| ascii 			  | US ASCII 															 | ascii_general_ci 		   | 1 				 |
# 		| big5 			  | Big5 Traditional Chinese 										 | big5_chinese_ci 			| 2 				 |
# 		| binary 		  | Binary pseudo charset 											 | binary 						| 1 				 |
# 		| cp1250 		  | Windows Central European 										 | cp1250_general_ci 		| 1 				 |
# 		| cp1251 		  | Windows Cyrillic 												 | cp1251_general_ci 		| 1 				 |
# 		| cp1256 		  | Windows Arabic 													 | cp1256_general_ci 		| 1 				 |
# 		| cp1257 		  | Windows Baltic 													 | cp1257_general_ci 		| 1 				 |
# 		| cp850 			  | DOS West European 												 | cp850_general_ci 			| 1 				 |
# 		| cp852 			  | DOS Central European 											 | cp852_general_ci 			| 1 				 |
# 		| cp866 			  | DOS Russian 														 | cp866_general_ci 			| 1 				 |
# 		| cp932 			  | SJIS for Windows Japanese 									 | cp932_japanese_ci 		| 2 				 |
# 		| dec8 			  | DEC West European 												 | dec8_swedish_ci 			| 1 				 |
# 		| eucjpms 		  | UJIS for Windows Japanese 									 | eucjpms_japanese_ci 		| 3 				 |
# 		| euckr 			  | EUC-KR Korean 													 | euckr_korean_ci 			| 2 				 |
# 		| gb18030 		  | China National Standard GB18030 						    | gb18030_chinese_ci 		| 4 				 |
# 		| gb2312 		  | GB2312 Simplified Chinese 									 | gb2312_chinese_ci 		| 2 				 |
# 		| gbk 			  | GBK Simplified Chinese 										 | gbk_chinese_ci 			| 2 				 |
# 		| geostd8 		  | GEOSTD8 Georgian 												 | geostd8_general_ci 		| 1 				 |
# 		| greek 			  | ISO 8859-7 Greek 												 | greek_general_ci 			| 1 				 |
# 		| hebrew 		  | ISO 8859-8 Hebrew 												 | hebrew_general_ci 		| 1 				 |
# 		| hp8 			  | HP West European 												 | hp8_english_ci 			| 1 				 |
# 		| keybcs2 		  | DOS Kamenicky Czech-Slovak 									 | keybcs2_general_ci 		| 1 				 |
# 		| koi8r 			  | KOI8-R Relcom Russian 											 | koi8r_general_ci 			| 1 				 |
# 		| koi8u 			  | KOI8-U Ukranian 													 | koi8u_general_ci 			| 1 				 |
# 		| latin1 		  | cp1252 West European 											 | latin1_swedish_ci 		| 1 				 |
# 		| latin2 		  | ISO 8859-2 Central European 									 | latin2_general_ci 		| 1 				 |
# 		| latin5 		  | ISO 8859-9 Turkish 												 | latin5_turkish_ci 		| 1 				 |
# 		| latin7 		  | ISO 8859-13 Baltic 												 | latin7_general_ci 		| 1 				 |
# 		| macce 			  | Mac Central European 											 | macce_general_ci 			| 1 				 |
# 		| macroman 		  | Mac West European 												 | macroman_general_ci 		| 1 				 |
# 		| sjis 			  | Shift-JIS Japanese 												 | sjis_japanese_ci 			| 2 				 |
# 		| swe7 			  | 7bit Swedish 														 | swe7_swedish_ci 			| 1 				 |
# 		| tis620 		  | TIS620 Thai 														 | tis620_thai_ci 			| 1 				 |
# 		| ucs2 			  | UCS-2 Unicode 													 | ucs2_general_ci 		   | 2 				 |
# 		| ujis 			  | EUC-JP Japanese 													 | ujis_japanese_ci 			| 3 				 |
# 		| utf16 			  | UTF-16 Unicode 													 | utf16_general_ci 			| 4 				 |
# 		| utf16le 		  | UTF-16LE Unicode 												 | utf16le_general_ci 		| 4 				 |
# 		| utf32 			  | UTF-32 Unicode 													 | utf32_general_ci 			| 4 				 |
# 		| utf8 			  | UTF-8 Unicode 													 | utf8_general_ci 			| 3 				 |
# 		| utf8mb4 		  | UTF-8 Unicode 													 | utf8mb4_0900_ai_ci 		| 4 				 |
# 		+----------------+-------------------------------------------------------+-------------------------+---------------+
#
# In cases where a character set has multiple collations, it might not be clear which collation is most suitable
# for a given application.
#
# To avoid choosing the wrong collation, it can be helpful to perform some comparisons with representative data values to make sure
# that a given collation sorts values the way you expect.
#
# UNICODE CHARACTER SETS
#
# MySQL supports multiple Unicode character sets:
#
# 		) utf8mb4: A UTF-8 encoding of the Unicode character set using one to four bytes per character
#
# 		) utf8mb3: A UTF-8 encoding of the Unicode character set using one to three bytes per character
#
# 		) utf8: An alias for utf8mb3
#
# 		) ucs2: The UCS-2 encoding of the Unicode character set using two bytes per  character.
#
# 		) utf16: The uTF-16 encoding for the Unicode character set using two or four bytes per character.
# 		
# 					Like ucs2 but with an extension for supplementary characters.
#
# 		) utf16le: The UTF-16LE encoding for the Unicode character set. Like utf16 but little-endian rather than big-endian
#
# 		) utf32: The UTF-32 encoding for the Unicode character set using four bytes per character
#
# NOTE:
#
# 		The utf8mb3 character set is deprecated, use explicit reference to utf8mb4 instead.
#
# utf8 and ucs2 support Basic Multilingual Plane (BMP) characters.
# utf8mb4, utf16, utf16le and utf32 support BMP and supplementary characters.
#
# This section describes the collations available for Unicode character sets and their
# differentiating properties.
#
# For general information about Unicode, see SECTION 10.9, "UNICODE SUPPORT"
#
# Most Unicode character sets have a general collation (indicated by _general in the name or by
# the absence of a language specifier), a binary collation (indicated by _bin in the name),
# and several language-specific collations (indicated by language specifiers).
#
# For example, for utf8, utf8_general_ci and utf8_bin are its general and binary collations,
# and utf8_danish_ci is one of its language-specific collations.
#
# Collation support for utf16le is limited.
#
# The only collations available are utf16le_general_ci and utf16le_bin.
#
# These are similar to utf16_general_ci and utf16_bin
#
# A locale code or language name shown in the following table indicates a language-specific
# collation.
#
# Unicode character sets may include collations for one or more of these languages.
#
# TABLE 10.3 UNICODE COLLATION LANGUAGE SPECIFIERS
#
# 	Language 				Language Specifier
#
# Classical Latin 		la or roman
#
# Croatian 					hr or croatian
#
# Czech 						cs or czech
#
# Danish 					da or danish
#
# Esperanto 				eo or esperanto
#
# Estonian 					et or estonian
#
# German phone book 		de_pb or german2
# order
#
# Hungarian 				hu or hungarian
#
# Icelandic 				is or icelandic
#
# Japanese 					ja
#
# Latvian 					lv or latvian
#
# Lithuanian 				lt or lithuanian
#
# Persian 					persian
#
# Polish 					pl or polish
#
# Romanian 					ro or romanian
#
# Russian 					ru
#
# Sinhala 					sinhala
#
# Slovak 					sk or slovak
#
# Slovenian 				sl or slovenian
#
# Modern Spanish 			es or spanish
#
# Traditional Spanish 	es_trad or spanish2
#
# Swedish 					sv or Swedish
#
# Turkish 					tr or turkish
#
# Vietnamese 				vi or vietnamese
#
# Croatian collations are tailored for specific Croatian letters.
#
# Danish collations may also be used for Norweigan.
#
# For japanese, the utf8mb4 character set includes utf8mb4_ja_0900_as_cs and utf8mb4_ja_0900_as_cs_ks collations.
#
# Both collations are accent sensitive and case-sensitive.
#
# utf8mb4_ja_0900_as_cs_ks is also kana sensitive and distinguishes Katakana characters
# from Hiragana characters, whereas utf8mb4_ja_0900_as_cs treats Katakana and Hiragana
# characters as equal for sorting.
#
# Applications that require Japanese collation but not kana sensitivity may use utf8mb4_ja_0900_as_cs
# for better sort performance.
#
# utf8mb4_ja_0900_as_cs uses three weight levels for sorting: utf8mb4_ja_0900_as_cs_ks uses four.
#
# For Classical Latin collations that are accent insensitive, I and J compare as equal, and U
# and V compare as equal.
#
# I and J, U and V compare as equal on the base letter level.
#
# IN other words, J is regarded as an accented I, and U is regarded as an accented V.
#
# Spanish collations are available for modern and traditional Spanish.
# For both n-tilde is a separate letter between n and o.
#
# In addition, for traditional Spanish, ch is separate letter between
# c and d, and ll is a separate letter between l and m.
#
# Traditional Spanish collations may also be used for Austrian and Galician.
#
# Swedish collations include Swedish rules. For example, in Swedish, the following relationship
# holds, which is not something expected by German or French:
#
# 		 = Y < 
#
# FOr questions about particular langauge orderings, unicode provides Common Locale Data
# Repositories (CLDR) collation charts.
#
# The xxx_general_mysql500_ci collations preserve the pre-5.1.24 ordering of the original
# xxx_general_ci collations and permits upgrades for tables created before 5.1.24 (A bug, #27877)
#
# MySQL implements the xxx_unicode_ci collations according to the Unicode Collation Algorithm
# (UCA).
#
# The collation uses the version-4.0.0 UCA weight keys.
#
# The xxx_unicode_ci collations have only partial support for the Unicode Collation Algorithm.
#
# Some characters are not supported, and combining marks are not fully supported.
#
# This affects primarily  Vietnamese, Yoruba and some smaller languages such as Navajo.
#
# A combined character is considered different from the same character written with a single
# unicode character in string comparisons, and the two characters are considered to have
# a different length (for example, as returned by the CHAR_LENGTH() function or in result set metadata)
#
# Unicode collations based on UCA versions later than 4.0.0 include the version in the
# collation name.
#
# Thus, utf8mb4_unicode_520_ci is based on UCA 5.2.0 weight keys, where as utf8mb4_0900_ai_ci
# is based on UCA 9.0.0 weight keys
#
# Collations based on UCA 9.0.0 and higher are faster than collations based on UCA versions below
# 9.0.0
#
# They also have a PAD attribute of NO PAD, in contrast to PAD SPACE as used in collations
# based on UCA versions below 9.0.0
#
# NO PAD collations treat spaces at the end of the strings like any other character.
#
# To determine the pad attribute for a collation, use the INFORMATION_SCHEMA COLLATIONS
# table, which has a PAD_ATTRIBUTE column.
#
# Comparisons of VARCHAR columns that have a NO PAD collation differ from other collations
# with respect to trailing spaces.
#
# For example, 'a' and 'a ' compare as different strings, not the same string.
#
# MySQL implements language-specific Unicode collations if the ordering based only on
# UCA does not work well for a language.
#
# Language-specific collations are UCA-based, with additional language tailoring rules.
#
# For example, the nonlanguage-specific utf8mb4_0900_ai_ci and language-specific utf8mb4_LOCALE_0900_ai_ci
# Unicode collations each have these characteristics:
#
# 		) The collation is based on Unicode Collation Algorithm (UCA) 9.0.0 and Common Locale Data Repository (CLDR)v30,
# 			is accent insensitive and case insensitive.
#
# 			These characteristics are indicated by _0900_ai and _ci in the collation name.
#
# 			Exception: utf8mb4_la_0900_ai_ci is not based on CLDR because Classical Latin is not definded in CLDR.
#
# 		) The collation works for all characters in the range [U+0, U+10FFFF]
#
# 		) If the collation is not language specific, it sorts all characters, including supplementary characters,
# 			in default order (described following).
#
# 			If the collation is language specific, it sorts characters of the language correctly according to
# 			to language-specific rules, and characters not in the language in default order.
#
# 		) By default, the collation sorts characters having a code point listed in teh DUCET table (Default Unicode Collation Element Table)
# 			according to the weight value assigned in the table.
#
# 			The collation sorts characters not having a code point listed in the DUCET table using their
# 			implicit weight value, which is constructed according to the UCA.
#
# 		) For non-language-specific collations, characters in contraction sequences are treated as separate characters.
#
# 			For language-specific collations, contractions might change character sorting order.
#
# LOWER() and UPPER() perform case folding according to the collation of their argument.
#
# A character that has uppercase and lowercase versions only in a Unicode version more recent
# than 4.0.0 is converted by these functions only if the argument has a collation that uses a 
# recent enough UCA version.
#
# For any Unicode character set, operations performed using the xxx_general_ci collation are
# faster than those for the xxx_unicode_ci collation.
#
# For example, comparisons for the utf8_general_ci collation are faster, but slightly less correct,
# than comparisons for utf8_unicode_ci.
#
# The reason for this is that utf8_unicode_ci supports mapping such as expansions; that is, when one
# character compares as equal to combinations of other characters.
#
# For example, in German and some other language the german S is equal to ss.
#
# utf8_unicode_ci also supports contractions and ignorable characters.
#
# utf8_general_ci is a legacy collation that does not support expansions,
# contractions, or ignorable characters.
#
# It can make only one-to-one comparisons between characters.
#
# To further illustrate, the following equalities hold in both utf8_general_ci and utf8_unicode_ci
# (for the effect of this in comparisons or searches, see SECTION 10.8.6 "EXAMPLES OF THE EFFECT OF COLLATION"):
#
# 		 = A
# 		 = O
# 		 = U
#
# A difference between collations is that htis is true for utf8_general_ci:
#
# 		[german s] = s
#
# Whereas this is  true for utf8_unicode_ci, which supports the German DIN-1 ordering
# (also known as dictionary order):
#
# 		[german s] = ss
#
# MySQL implements utf8 language-specific collations if the ordering with utf8_unicode_ci does not
# work well for a language.
#
# For example, utf8_unicode_ci works fine for German dictionary order and French, so there is no
# need to create special utf8 collations.
#
# utf8_general_ci also is satisfactory for both German and French, except that [german s] is equal
# to s and not ss.
#
# If this is acceptable in the app, you should use utf8_general_ci because its faster.
#
# If this is not acceptable, i.e, requiring German dictionary order, use utf8_unicode_ci because
# it is more accurate.
#
# If you require German DIN-2 (phone book) ordering, use the utf8_german2_ci collation,
# which compares the following sets of characters equal:
#
# 		 = [AE] = AE
# 		 = [OE] = OE
# 		 = UE
# 		[German S] = ss
#
# utf8_german2_ci is similar to latin1_german2_ci, but hte latter does not compare [AE] equal
# to AE or [OE] equal to OE.
#
# There is no utf8_german_ci corresponding to latin1_german_ci for German dictionary order
# because utf8_general_ci suffices.
#
# For all Unicode collations except the binary (_bin) collations, MySQL performs a table lookup
# to find a characters collating weight.
#
# This weight can be displayed using the WEIGHT_STRING() function.
#
# See SECTION 12.5, "STRING FUNCTIONS"
#
# If a character is not in the table (for example, because it is a "new" character),
# collating weight determination becomes more complex:
#
# 		) For BMP characters in general collations (xxx_general_ci), weight = code point
#
# 		) For BMP characters in UCA collations (for example, xxx_unicode_ci and language-specific collations),
# 			the following algorithm applies:
#
	# 			if (code >= 0x3400 && code <= 0x4DB5)
	# 				base= 0xFB80; /* CJK Ideograph Extension */
	# 			else if (code >= 0x4E00 && code <= 0x9FA5)
	# 				base= 0xFB40; /* CJK Ideograph */
	# 			else
	# 				base= 0xFBC0; /* All other characters */
	# 			aaaa= base + (code >> 15);
	# 			bbbb= (code & 0x7FFF) | 0x8000;
#
# 			The result is a sequence of two collating elements, aaaa followed by bbbb.
#
# 			For example:
#
# 				SELECT HEX(WEIGHT_STRING(_ucs2 0x04CF COLLATE ucs2_unicode_ci));
# 				+-------------------------------------------------------------------+
# 				| HEX(WEIGHT_STRING(_ucs2 0x04CF COLLATE ucs2_unicode_ci)) 			  |
# 				+-------------------------------------------------------------------+
# 				| FBC084CF 																			  |
# 				+-------------------------------------------------------------------+
#
# 			Thus, U+04cf CYRILLIC SMALL LETTER PALOCHKA is, with all UCA 4.0.0 collations,
# 			greater than U+04c0 CYRILLIC LETTER PALOCHKA.
#
# 			With UCA 5.2.0 collations, all palochkas sort together.
#
# 		) FOr supplementary characters in general collations, the weight is the weight for
# 			0xfffd REPLACEMENT CHARACTER.
#
# 			For supplementary characters in UCA 4.0.0 collations, their collating weight
# 			is 0xfffd.
#
# 			That is, to MySQL, all supplementary characters are equal to each other, and greater than
# 			almost all BMP characters.
#
# 			An example with Deseret characters and COUNT(DISTINCT):
#
# 				CREATE TABLE t (s1 VARCHAR(5) CHARACTER SET utf32 COLLATE utf32_unicode_ci);
# 				INSERT INTO t VALUES (0xfffd); /* REPLACEMENT CHARACTER */
# 				INSERT INTO t VALUES (0x010412); /* DESERET CAPITAL LETTER BEE */
# 				INSERT INTO t VALUES (0x010413); /* DESERET CAPITAL LETTER TEE */
# 				SELECT COUNT(DISTINCT s1) FROM t;
#
# 			The result is 2 because the MySQL xxx_unicode_ci collations, the replacement character has
# 			a weight of 0x0dc6, whereas Deseret Bee and Deseret Tee both have a weight of
# 			0xfffd.
#
# 			(Were the utf32_general_ci collation used instead, the result is 1 because all three characters
# 			have a weight of 0xfffd in that collation)
#
# 			An example with cuneiform characters and WEIGHT_STRING():
#
# 				/*
# 				The four characters in the INSERT string are
# 				00000041 	# LATIN CAPITAL LETTER A
# 				0001218F 	# CUNEIFORM SIGN KAB
# 				000121A7 	# CUNEIFORM SIGN KISH
# 				00000042 	# LATIN CAPITAL LETTER B
# 				*/
# 				CREATE TABLE t (s1 CHAR(4) CHARACTER SET utf32 COLLATE utf32_unicode_ci);
# 				INSERT INTO t VALUES (0x000000410001218f000121a700000042);
# 				SELECT HEX(WEIGHT_STRING(s1)) FROM t;
#
# 			The result is:
#
# 				0E33 FFFD FFFD 0E4A
#
# 			0E33 and 0E4A are primary weights as in UCA 4.0.0. FFFD is the weight for KAB and also for KISH.
#
# 			The rule that all supplementary characters are equal to each other is nonoptimal but is not expected
# 			to cause trouble.
#
# 			These characters are very rare, so it is rare that a multi-character string consists entirely of
# 			supplementery characters.
#
# 			In Japan, since the supplementary characters are obscure Kanji ideographs, the typical user
# 			does not care what order they are in.
#
# 			If you really want rows sorted by the MySQL rule and secondarily by code point value:
#
# 				ORDER BY s1 COLLATE utf32_unicode_ci, s1 COLLATE utf32_bin
#
# 		) For supplementary characters based on UCA versions higher than 4.0.0 (for example, xxx_unicode_520_ci),
# 			supplementary characters do not necessarily all have the same collation weight.
#
# 			Some have explicit weights from the UCA allkeys.txt file.
#
# 			Others have weights calculated from this algorithm:
#
# 				aaaa= base + (code >> 15);
# 				bbbb= (code & 0x7FFF) | 0x8000;
#
# There is a difference between "Ordering by the character's code value" and "ordering by the character's binary representation",
# a difference that only appears with utf16_bin, because of surrogates.
#
# Suppose that utf16_bin (the binary collation for utf16) was a binary comparison "byte by byte" rather than
# "character by character".
#
# If that were so, the order of characters in utf16_bin would differ from the order in utf8_bin.
#
# For example, the following chart shows two rare characters.
#
# The first character is in the range E000-FFFF, so it is greater than a surrogate
# but less than a supplementary.
#
# The second character is a supplementary:
#
# 		CODE POINT 		CHARACTER 								UTF8 						UTF16
# 		-------------- --------------- 						----- 					-----
# 		0FF9D 			HALFWIDTH KATAKANA LETTER N 		EF BE 9D 				FF 9D
# 		10384 			UGARITIC LETTER DELTA 				F0 90 BE 84 			D8 00 DF 84
#
# The two characters in the chart are in order by code point values because 0xff9d < 0x10384.
#
# And they are in order by utf8 value because 0xef < 0xf0
#
# But they are not in order by utf16 value, if we use a byte-by-byte comparison, because 0xff > 0xd8
#
# So MySQL's utf16_bin collation is not "byte by byte". It is by "code point".
#
# When MySQL sees a supplementary-character encoding in utf16, it converts the character's code-point value,
# and then compares.
#
# Therefore, utf8_bin and utf16_bin are the same ordering.
#
# THis is consistent with the SQL:2008 standard requirement for a UCS_BASIC collation:
#
# "UCS_BASIC is a collation in which the ordering is determined entirely by the Unicode scalar
# values of the characters in the strings being sorted.
#
# IT is applicable to the UCS character repertoire. Since every character repertoire is a subset
# of the UCS repertoire, the UCS_BASIC collation is potentionally applicable to every character set.
#
# NOTE:
#
# 		The Unicode scalar value of a character is its code point treated as an unsigned integer."
#
# If the character set is ucs2, comparison is byte-by-byte, but ucs2 strings should
# not contain surrogates, anyway.
#
# WEST EUROPEAN CHARACTER SETS
#
# Western European character sets cover most West European languages, such as French,
# Spanish, Catalan, Basque, Portuguese, Italian, Albanian, Dutch, German, Danish,
# Swedish, Norweigan, Finnish, Faroese, Icelandic, Irish, Scottish and English.
#
# 		) ascii (US ASCII) collations:
#
# 			) ascii_bin
#
# 			) ascii_general_ci (default)
#
# 		) cp850 (DOS West European) collations:
#
# 			) cp850_bin
#
# 			) cp850_general_ci (default)
#
# 		) dec8 (DEC Western European) collations:
#
# 			) dec8_bin
#
# 			) dec8_swedish_ci (default)
#
# 		) hp8 (HP Western European) collations:
#
# 			) hp8_bin
#
# 			) hp8_english_ci (default)
#
# 		) latin1 (cp1252 West European) collations:
#
# 			) latin1_bin
#
# 			) latin1_danish_ci
#
# 			) latin1_general_ci
#
# 			) latin1_general_cs
#
# 			) latin1_german1_ci
#
# 			) latin1_german2_ci
#
# 			) latin1_spanish_ci
#
# 			) latin1_swedish_ci (default)
#
# latin1 is the default character set. MySQL's latin1 is the same as the WIndows cp1252 cahracter set.
#
# This means it is the same as the official ISO 8859-1 or IANA (Internet Assigned Numbers Authority) latin1,
# except that IANA latin1 treats the code points between 0x80 and 0x9f as "undefined",
# whereas cp1252, and therefore MySQL's latin1 - assigns characters for those positions.
#
# For example, 0x80 is the Euro sign.
#
# For the "undefined" entries in cp1252, MySQL translates 0x81 to Unicode
# 0x0081, 0x8d to 0x008d, 0x8f to 0x008f, 0x90 to 0x0090 and 0x9d to 0x009d.
#
# The latin1_swedish_ci collation is the default that probably is used by the
# majority of MySQL customers.
#
# Although it is frequently said that it is based on the Swedish/Finnish collation rules,
# there are discussions on this.
#
# The latin1_german1_ci and latin1_german2_ci collations are based on the DIN-1 and DIN-2 standards,
# where DIN stands for Deutsches Institut Fr Normung.
#
# DIN-1 is called the "dictionary collation" and DIN-2 is called the "phone book collation".
#
# For an example of the effect this has in comparisons or when doing searches,
# see SECTION 10.8.6, "EXAMPLES OF THE EFFECT OF COLLATION"
#
# 		) latin1_german1_ci (dictionary) rules:
#
# 				 = A
# 				 = O
# 				 = U
# 				[German s] = s
#
# 		) latin1_german2_ci (phone-book) rules:
#
# 				 = AE
# 				 = OE
# 				 = UE
# 				[German s] = ss
#
# 			In the latin1_spanish_ci collation, n-tilde is a separate letter between n and o.
#
# 		) macroman (Mac West European) collations:
#
# 			) macroman_bin
#
# 			) macroman_general_ci (default)
#
# 		) swe7 (7bit Swedish) collations:
#
# 			) swe7_bin
#
# 			) swe7_swedish_ci (default)
#
# CENTRAL EUROPEAN CHARACTER SETS
#
# MySQL provides some support for character sets used in the Czech Republic,
# Slovakia, Hungary, Romania, Slovenia, Croatia, Poland and Serbia (Latin)
#
# 		) cp1250 (Windows Central European) collations:
#
# 			) cp1250_bin
#
# 			) cp1250_coratian_ci
#
# 			) cp1250_czech_cs
#
# 			) cp1250_general_ci (default)
#
# 			) cp1250_polish_ci
#
# 		) cp852 (DOS Central European) collations:
#
# 			) cp852_bin
#
# 			) cp852_general_ci (default)
#
# 		) keybcs2 (DOS Kamenicky Czech-Slovak) collations:
#
# 			) keybcs2_bin
#
# 			) keybcs2_general_ci (default)
#
# 		) latin2 (ISO 8859-2 Central European) collations:
#
# 			) latin2_bin
#
# 			) latin2_croatian_ci
#
# 			) latin2_czech_cs
#
# 			) latin2_general_ci (default)
#
# 			) latin2_hungarian_ci
#
# 		) macce (Mac Central European) collations:
#
# 			) macce_bin
#
# 			) macce_general_ci (default)
#
# SOUTH EUROPEAN AND MIDDLE EAST CHARACTER SETS
#
# South European and Middle Eastern character sets supported by MySQL include Armenian,
# Arabic, Georgian, Greek, Hebrew and Turkish.
#
# 		) armscii8 (ARMSCII-8 Armenian) collations:
#
# 			) armscii8_bin
#
# 			) armscii8_general_ci (default)
#
# 		) cp1256 (Windows Arabic) collations:
#
# 			) cp1256_bin
#
# 			) cp1256_general_ci (default)
#
# 		) geostd8 (GEOSTD8 Georgian) collations:
#
# 			) geostd8_bin
#
# 			) geostd8_general_ci (default)
#
# 		) greek (ISO 8859-7 Greek) collations:
#
# 			) greek_bin
#
# 			) greek_general_ci (default)
#
# 		) hebrew (ISO 8859-8 Hebrew) collations:
#
# 			) hebrew_bin
#
# 			) hebrew_general_ci (default)
#
# 		) latin5 (ISO 8859-9 Turkish) collations:
#
# 			) latin5_bin
#
# 			) latin5_turkish_ci (default)
#
# BALTIC CHARACTER SETS
#
# The Baltic character sets cover Estonian, latvian and Lithuanian languages.
#
# 		) cp1257 (Windows Baltic) collations:
#
# 			) cp1257_bin
#
# 			) cp1257_general_ci (default)
#
# 			) cp1257_lithuanian_ci
#
# 		) latin7 (ISO 8859-13 Baltic) collations:
#
# 			) latin7_bin
#
# 			) latin7_estonian_cs
#
# 			) latin7_general_ci (default)
#
# 			) latin7_general_cs
#
# CYRILLIC CHARACTER SETS
#
# The  Cyrllic character sets and collations are for use with Belarusian,
# Bulgarian, Russian, Ukrainian, and Serbian (Cyrillic) languages.
#
# 		) cp1251 (Windows Cyrillic) collations:
#
# 			) cp1251_bin
#
# 			) cp1251_bulgarian_ci
#
# 			) cp1251_general_ci (default)
#
# 			) cp1251_general_cs
#
# 			) cp1251_ukrainian_ci
#
# 		) cp866 (DOS Russian) collations:
#
# 			) cp866_bin
#
# 			) cp866_general_ci (default)
#
# 		) koi8r (KOI8-R Relcom Russian) collations:
#
# 			) koi8r_bin
#
# 			) koi8r_general_ci (default)
#
# 		) koi8u (KOI8-U Ukranian) collations:
#
# 			) koi8u_bin
#
# 			) koi8u_general_ci (default)
#
# ASIAN CHARACTER SETS
#
# The Asian character sets that we support include Chinese, Japanese, Korean and Thai.
#
# These can be complicated. For example, the Chinese sets must allow for thousands of different
# characters.
#
# See SECTION 10.10.7.1, "THE CP932 CHARACTER SET", for additional information about the cp932 and
# sjis character sets.
#
# See SECTION 10.10.7.2, "THE GB 18030 CHARACTER SET", for additional information about character
# set support for the Chinese National Standard GB 18030.
#
# For answers to some common questions and problems relating support for Asian character sets
# in MySQL - see SECTION A. 11, "MySQL 8.0 FAQ: MySQL Chinese, Japanese, and Korean Character Sets"
#
# 		) big5 (Big5 Traditional Chinese) collations:
#
# 			) big5_bin
#
# 			) big5_chinese_ci (default)
#
# 		) cp932 (SJIS for Windows Japanese) collations:
#
# 			) cp932_bin
#
# 			) cp932_japanese_ci (default)
#
# 		) eucjpms (UJIS for Windows Japanese) collations:
#
# 			) eucjpms_bin
#
# 			) eucjpms_japanese_ci (default)
#
# 		) euckr (EUC-KR Korean) collations:
#
# 			) euckr_bin
#
# 			) euckr_korean_ci (default)
#
# 		) gb2312 (GB2312 Simplified Chinese) collations:
#
# 			) gb2312_bin
#
# 			) gb2312_chinese_ci (default)
#
# 		) gbk (GBK Simplified Chinese) collations:
#
# 			) gbk_bin
#
# 			) gbk_chinese_ci (default)
#
# 		) gb18030 (China National Standard GB18030) collations:
#
# 			) gb18030_bin
#
# 			) gb18030_chinese_ci (default)
#
# 			) gb18030_unicode_520_ci
#
# 		) sjis (Shift-JIS Japanese) collations:
#
# 			) sjis_bin
#
# 			) sjis_japanese_ci (default)
#
# 		) tis620 (TIS620 Thai) collations:
#
# 			) tis620_bin
#
# 			) tis620_thai_ci (default)
#
# 		) ujis (EUC-JP Japanese) collations:
#
# 			) ujis_bin
#
# 			) ujis_japanese_ci (default)
#
# The big5_chinese_ci collation sorts on number of strokes.
#
# 10.10.7.1 THE CP932 CHARACTER SET
#
# In MySQL, the sjis character set corresponds to the Shift_JIS character set defined by IANA,
# which supports JIS X0201 and JIS X0208 characters.
#
# However, the meaning of "SHIFT JIS" as a descriptive term has become very vague and it often
# includes the extensions to Shift_JIS that are defined by various vendors.
#
# For example, "SHIFT JIS" used in Japanese Windows environments is a Microsoft extension of
# Shift_JIS and its exact name is Microsoft Windows Codepage : 932 or cp932
#
# IN addition to the characters supported by Shift_JIS, cp932 supports extension characters
# such as NEC special characters, NEC selected - IBM extended characters, and IBM Selected characters.
#
# Many Japanese users have experienced problems using these extension characters.
#
# These problems stem from the following factors:
#
# 		) MySQL automatically converts character sets
#
# 		) Character sets are converted using Unicode (ucs2)
#
# 		) The sjis character set does not support the conversion of these extension characters.
#
# 		) There are several conversion rules from so-called "SHIFT JIS" to Unicode, and some characters
# 			are converted to Unicode differently depending on the conversion rule.
#
# 			MySQL supports only one of these rules (described later)
#
# The MySQL cp932 character set is designed to solve tehse problems.
#
# Because MySQL supports character set conversion, it is important to separate IANA Shift_JIS and cp932
# into two different character sets because they provide different conversion rules.
#
# HOW DOES CP932 DIFFER FROM SJIS
#
# The cp932 character set differs from sjis in the following ways:
#
# 		) cp932 supports NEC special characters, NEC selected - IBM extended characters, and IBM selected characters.
#
# 		) Some cp932 characters have two different code points, both of which converts to the same Unicode code point.
#
# 			When converting from Unicode back to cp932, one of the code points must be selected.
# 			For this "round trip conversion", the rule recommended by Microsoft is used. 
#
# 			The conversion rule works like this:
#
# 				) If the character is in both JIS X 0208 and NEC special characters, use the code point of JIS X 0208
#
# 				) If the character is in both NEC special characters and IBM Selected characters, use the code point of NEC special characters.
#
# 				) If the character is in both IBM selected characters and NEC selected - IBM extended characters,
# 					use the code point of IBM extended characters.
#
# 			The table shown at <link> provides information about the Unicode values of cp932 characters.
#
# 			For cp932 table entries with characters under which a four-digit number appears,
# 			the number represents the corresponding Unicode (ucs2) encoding.
#
# 			For tables entries with an underlined two-digit value appears, there is a range of cp932 char values that
# 			begin with those two digits.
#
# 			Clicking such a table entry takes you to a page that displays the Unicode value for each of the
# 			cp932 character that begin with those digits.
#
# 			The following links are of special interest.
#
# 			They correspond to the encodings for the following sets of characters:
#
# 				) NEC special characters (lead byte 0x87):
#
# 					<link>
#
# 				) NEC selected - IBM extended characters (lead byte 0xED and 0xEE):
#
# 					<link>
# 					<link>
#
# 				) IBM selected characters (lead byte 0xFA, 0xFB, 0xFC):
#
# 					<link>
# 					<link>
# 					<link>
#
# 		) cp932 supports conversion of user-defined characters in combination with eucjpms, and solves
# 			the problems with sjis/ujis conversion.
#
# 			For details, please refer to <link>
#
# For some characters, conversion to and from ucs2 is different for sjis and cp932.
#
# The following tables illustrate these differences.
#
# Conversion to ucs2:
#
# 		sjis/cp932 Value 			sjis -> ucs2 Conversion 		cp932 -> ucs2 Conversion
#
# 		5C 							005C 									005C
# 
# 		7E 							007E 									007E
#
# 		815C 							2015 									2015
#
# 		815F 							005C 									FF3C
#
# 		8160 							301C 									FF5E
#
# 		8161 							2016 									2225
#
# 		817C 							2212 									FF0D
#
# 		8191 							00A2 									FFE0
#
# 		8192 							00A3 									FFE1
#
# 		81CA 							00AC 									FFE2
#
# Conversion from ucs2:
#
# 		ucs2 Value 					ucs2 -> sjis Conversion 		ucs2 -> cp932 Conversion
#
# 		005C 							815F 									5C
#
# 		007E 							7E 									7E
#
# 		00A2 							8191 									3F
#
# 		00A3 							8192 									3F
#
# 		00AC 							81CA 									3F
#
# 		2015 							815C 									815C
#
# 		2016 							8161 									3F
#
# 		2212 							817C 									3F
#
# 		2225 							3F 									8161
#
# 		301C 							8160 									3F
#
# 		FF0D 							3F 									817C
#
# 		FF3C 							3F 									815F
#
# 		FF5E 							3F 									8160
#
# 		FFE0 							3F 									8191
#
# 		FFE1 							3F 									8192
#
# 		FFE2 							3F 									81CA
#
# Users of any Japanese character sets should be aware that using --character-set-client-handshake
# (or --skip-character-set-client-handshake) has an important effect.
#
# See earlier, under SECTION 5.1.7, "SERVER COMMAND OPTIONS"
#
# 10.10.7.2 THE GB18030 CHARACTER SET
#
# In MySQL, the gb18030 character set correspond to the "Chinese National Standard GB 18030-2005: information technology - chinese coded char set",
# which is the official char set of the People's Republic of China (PRC)
#
# Characteristics of the MySQL gb18030 Character Set
#
# 		) Supports all code points defined by the GB 18030-2005 standard.
#
# 			Unassigned code points in the ranges (GB+8431A439, GB+90308130) and
# 			(GB+E3329A36, GB+EF39EF39) are treated as '?' (0x3F).
#
# 			Conversion of unassigned code points return '?'
#
# 		) Supports UPPER and LOWER conversion for all GB18030 code points.
#
# 			Case folding defined by Unicode is also supported (based on CaseFolding-6.3.0.txt)
#
# 		) Supports Conversion of data to and from other character sets.
#
# 		) Supports SQL statements such as SET_NAMES
#
# 		) Supports comparison between gb18030 strings, and between gb18030 strings and strings of other
# 			character sets.
#
# 			There is a conversion if strings have different character sets.
#
# 			Comparisons that include or ignore trailing spaces are also supported.
#
# 		) The private use area (U+E000, U+F8FF) in Unicode is mapped to gb18030.
#
# 		) There is no mapping between (U+D800, U+DFFF) and GB18030.
#
# 			Attempted conversion of code points in this range returns '?'
#
# 		) If an incoming sequence is illegal, an error or warning is returned.
#
# 			If an illegal sequence is used in CONVERT(), an error is returned.
#
# 			Otherwise, a warning is returned.
#
# 		) For consistency with utf8 and utf8mb4, UPPER is not supported for ligatures.
#
# 		) Searches for ligatures also match uppercase ligatures when using the gb18030_unicode_520_ci collation.
#
# 		) If a character has more than one uppercase character, the chosen uppercase character
# 			is the one whose lowercase is the character itself.
#
# 		) The minimum multibyte length is 1 and the maximum is 4.
#
# 			The character set determines the length of a sequence using the first 1 or 2 bytes.
#
# SUPPORTED COLLATIONS
#
# 		) gb18030_bin: A binary collation.
#
# 		) gb18030_chinese_ci: The default collation, which supports Pinyin.
#
# 			SOrting of non-Chinese characters is based on the order of the original sort key.
#
# 			The original sort key is GB(UPPER(ch)) if UPPER(ch) exists.
#
# 			Otherwise, the original sort key is GB(ch). Chinese characters are sorted according to
# 			the Pinyin collation defined in the Unicode Common Locale Data Repository (CLDR 24).
#
# 			Non-Chinese characters are sorted before Chinese characters with the exception of
# 			GB+FE39FE39, which is the code point maximum.
#
# 		) gb18030_unicode_520_ci: A Unicode collation: Use this collation if you need to ensure that ligatures
# 			are sorted correctly.
#
# THE BINARY CHARACTER SET
#
# The binary character set is the character set of bianry strings, which are sequences of bytes.
#
# The binary character set has one collation, also named binary.
#
# Comparison and sorting are based on numeric byte values.
#
# The effect is that lettercase and accent differences are significant in comparisons.
# That is, the binary collation is case-sensitive and accent sensitive.
#
# 		SET NAMES 'binary';
# 		SELECT CHARSET('abc'), COLLATION('abc');
# 		+--------------------+-----------------------+
# 		| CHARSET('abc') 		| COLLATION('abc') 		|
# 		+--------------------+-----------------------+
# 		| binary 				| binary 					|
# 		+--------------------+-----------------------+
#
# 		SELECT 'abc' = 'ABC', 'a' = '';
# 		+---------------------+-----------------------+
# 		| 'abc' = 'ABC' 	    | 'a' = '' 				 |
# 		+---------------------+-----------------------+
# 		| 		0 					 | 		0 					 |
# 		+---------------------+-----------------------+
#
# For information about the differences between the binary collation of the binary character set
# and the _bin collations of nonbinary character sets, see SECTION 10.8.5, "THE BINARY COLLATION COMPARED TO _BIN COLLATIONS"
#
# To convert a string expression to a binary string, any of these constructs are equivalent:
#
# 		BINARY expr
# 		CAST(expr AS BINARY)
# 		CONVERT(expr USING BINARY)
#
# If expr is a character string literal, the _binary introducer may be used to designate it as a bianry string.
# For example:
#
# 		_binary 'a'
#
# The _binary introducer is permitted for hexadecimal literals and bit-value literals as well, but uncalled for.
#
# Such literals are binary strings by default.
#
# For more information about introducers, see SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# 10.11 SETTING THE ERROR MESSAGE LANGUAGE
#
# By default, mysqld produces error messages in English, but they can be displayed
# instead in any of several other languages: Czech, Danish, Dutch, Estonian, French,
# German, Greek, Hungarian, Italian, Japanese, Korean, Norweigan, Norweigan-ny, Polish,
# Portuguese, Romanian, Russian, Slovak, Spanish or Swedish.
#
# THis applies to messages the server writes to the error log and sends to clients.
#
# To select the language in which the server writes error messages, follow the instructions
# in this section.
#
# For information about changing the character set for error messages (rather than the language),
# see SECTION 10.6, "ERROR MESSAGE CHARACTER SET"
#
# For general information about configuring error logging, see SECTION 5.4.2, "THE ERROR LOG"
#
# The server searches for the error message file using these rules:
#
# 		) It looks for the file in a directory constructed from two system variable values,
# 			lc_messages_dir and lc_messages, with the latter converted to a language name.
#
# 			Suppose that you start the server using this command:
#
# 				mysqld --lc_messages_dir=/usr/share/mysql --lc_messages=fr_FR
#
# 			in this case, Mysqld maps the locale fr_FR to the language french and looks for the
# 			error file in the /usr/share/mysql/french directory.
#
# 			By default, the language files are located in the share/mysql/LANGUAGE directory under
# 			the MySQL base directory.
#
# 		) If the message file cannot be found in the directory constructed as just described,
# 			the server ignores the lc_messages value and uses only the lc_messages_dir value
# 			as the location in which to look.
#
# 		) If the server cannot find the configured message file, it writes a message to the error log file
# 			to indicate the problem and defaults to built-in English messages.
#
# The lc_messages_dir system variable can be set only at server startup and has only a global
# read-only value at runtime.
#
# lc_messages can be set at server startup and has globlal and session values that can be 
# modified at runtime.
#
# Thus, the error message language can be changed while the server is running, and each
# client can have its own error message language by setting its session lc_messages value
# to the desired locale name.
#
# FOr example, if the server is using the fr_FR locale for error messages,
# a client can execute this statement to receive error messages in English:
#
# 		SET lc_messages = 'en_US';
#
# ADDING A CHARACTER SET
#
# THis section discusses the procedure for adding a character set to MySQL.
# For proper procedure depends on whether the character set is simple or complex:
#
# 		) If the character set does not need special string collating routines for sorting
# 			and does not need multibyte character support, it is simple.
#
# 		) IF the character set needs either of those features, it is complex.
#
# For example, greek and swe7 are simple character sets, whereas big5 and czech are complex.
#
# TO use the following instructions, you must have a MySQL source distrib.
#
# In the instructions, MYSET represents hte name of the char set that you want to add.
#
# 		1. Add a <charset> element for MYSET to the sql/share/charsets/Index.xml file
#
# 			Use the existing contents in the file as a guide to adding new contents.
#
# 			A partial listing for the latin1 <charset> element follows:
#
# 				<charset name="latin1">
# 					<family>Western</family>
# 					<description>cp1252 West European</description>
# 					---
# 					<collation name="latin1_swedish_ci" id="8" order="Finnish, Swedish">
# 						<flag>primary</flag>
# 						<flag>compiled</flag>
#  				</collation>
# 					<collation name="latin1_danish_ci" id="15" order="Danish"/>
# 					---
# 					<collation name="latin1_bin" id="47" order="Binary">
# 						<flag>binary</flag>
# 						<flag>compiled</flag>
# 					</collation>
# 					---
# 				</charset>
#
# 			The <charset> element must list all the collations for the character set.
# 			
# 			These must include at least a binary collation and a default (primary) collation.
# 			The default collation is often named using a suffix of general_ci (general, case insensitive).
#
# 			It is possible for the binary collation to be the default collation,
# 			but usually they are different.
#
# 			The default collation should have a primary flag. The binary collation should have a binary flag.
#
# 			You must assign a unique ID number to each collation.
#
# 			The range of IDs from 1024 to 2047 is reserved for user-defined collations.
# 			To find the maximum of the currently used collation IDs, use this query:
#
# 				SELECT MAX(ID) FROM INFORMATION_SCHEMA.COLLATIONS;
#
# 		2. This step depends on whether you are adding a simple or complex character set.
#
# 			A simple character set requires only a configuration file, whereas a complex character
# 			set requires C source file that defines collation functions, multibyte functions, or both.
#
# 			For a simple character set, create a configuration file, MYSET.xml, that describes the
# 			character set properties.
#
# 			Create this file in the sql/share/charsets directory. 
# 			You can use a copy of latin1.xml as the basis for this file.
#
# 			The syntax for the file is very simple:
#
# 				) Comments are written as ordinary XML comments (<!-- text -->)
#
# 				) Words within <map> array elements are separated by arbitrary amounts of whitespace.
#
# 				) Each word within <map> array elements must be a number in hexadecimal format.
#
# 				) The <map> array element for the <ctype> element has 257 words.
#
# 					The other <map> array elements after that have 256 words.
#
# 					See SECTION 10.12.1, "CHARACTER DEFINITION ARRAYS"
#
# 				) For each collation listed in the <charset> element for the character set in
# 					Index.xml, MYSET.xml must contain a <collation> element that defines the character
# 					ordering.
#
# 			For a complex character set, create a C source file that describes the character set
# 			properties and defines the support routines necessary to properly perform operations
# 			on the character set:
#
# 				) Create the file ctype-MYSET.c in the strings directory.
#
# 					Look at one of the existing ctype-*.c files (such as ctype-big5.c) to see what
# 					needs to be defined.
#
# 					The arrays in your file must have names like ctype_MYSET, to_lower_MYSET,
# 					and so on.
#
# 					These correspond to the arrays for a simple character set.
#
# 					See SECTION 10.12.1, "CHARACTER DEFINITION ARRAYS"
#
# 				) For each <collation> element listed in the <charset> element for the character set
# 					in Index.xml, the ctype-MYSET.c file must provide an implementation of the collation.
#
# 				) If the character set requires string collating functions, see SECTION 10.12.2, "STRING COLLATING SUPPORT FOR COMPLEX CHARACTER SETS"
#
# 				) If the character set requires multibyte character support, see SECTION 10.12.3, "MULTI-BYTE CHARACTER SUPPORT FOR COMPLEX CHARACTER SETS"
#
# 			3. Modify the configuration information. Use the existing configuration information as a guide to adding information
# 				for MYSYS.
#
# 				The example here assumes that the character set has default and binary collations, but more lines are
# 				needed if MYSET has additional collations.
#
# 					a. Edit mysys/charset-def.c, and "register" the collations for the new character set.
#
# 						Add these lines to the "declaration" section:
#
# 							#ifdef HAVE_CHARSET_MYSET
# 							extern CHARSET_INFO my_charset_MYSET_general_ci;
# 							extern CHARSET_INFO my_charset_MYSET_bin;
# 							#endif
#
# 						Add these lines to the "registration" section:
#
# 							#ifdef HAVE_CHARSET_MYSET
# 								add_compiled_collation(&my_charset_MYSET_general_ci);
# 								add_compiled_collation(&my_charset_MYSET_bin);
# 							#endif
#
# 					b. If the character set uses ctype-MYSET.c, edit strings/CMakeLists.txt and add
# 						ctype-MYSET.c to the definition of the STRINGS_SOURCES variable.
#
# 					c. Edit cmake/character_sets.cmake:
#
# 						i. Add MYSET to the value of with CHARSETS_AVAILABLE in alphabetic order.
#
# 						ii. Add MYSET to the value of CHARSETS_COMPLEX in aplhabetic order.
#
# 							This is needed even for simple character sets, or CMake will not recognize
# 							-DDEFAULT_CHARSET=MYSET
#
# 				4. Reconfigure, recompile and test.
#
# CHARACTER DEFINITION ARRAYS
#
# Each simple character set has a configuration file located in the sql/share/charsets directory.
#
# For a character set named MYSYS, the file is named MYSET.xml.
#
# It uses <map> array elements to list character set properties.
#
# <map> elements appear within these elements:
#
# 		) <ctype> defines attributes for each character.
#
# 		) <lower> and <upper> list the lowercase and uppercase characters.
#
# 		) <unicode> maps 8-bit character values to Unicode values.
#
# 		) <collation> elements indicate character ordering for comparison and sorting,
# 			one element per collation.
#
# 			Binary collations need no <map> element because the character codes themselves provide the ordering.
#
# For a complex character set as implemented in a ctype-MYSET.c file in the strings directory,
# there are corresponding arrays:
#
# 		ctype_MYSET[]
#
# 		to_lower_MYSET[]
#
# 		|
# 		v etc.
#
# Not every complex char set has all of the arrays.
#
# See also the existing ctype-*.c files for examples.
# See the CHARSET_INFO.txt file in the strings directory for additional information.
#
# Most of the arrays are indexed by character value and have 256 elements.
# The <ctype> array is indexed by character value + 1 and has 257 elements.
#
# This is a legacy convention for handling EOF.
#
# <ctype> array elements are bit values.
# Each element describes the attributes of a single character in the character set.
#
# Each attribute is associated with a bitmask, as defined in include/m_ctype.h:
#
# 		#define _MY_U 		01 			/* Upper case */
# 		#define _MY_L 		02 			/* Lower case */
# 		#define _MY_NMR 	04 			/* Numeral (digit) */
# 		#define _MY_SPC  	010 			/* Spacing character */
# 		#define _MY_PNT 	020 			/* Punctuation */
# 		#define _MY_CTR 	040 			/* Control character */
# 		#define _MY_B 		0100 			/* Blank */
# 		#define _MY_X 		0200 			/* hexadecimal digit */
#
# The <ctype> value for a given character should be the union of the applicable bitmask values
# that describe the character.
#
# For example, 'A' is an uppercase character (_MY_U) as well as a hexadecimal digit (_MY_X), so its
# ctype value should be defined like this:
#
# 		ctype['A'+1] = _MY_U | _MY_X = 01 | 0200 = 0201
#
# The bitmask values in m_ctype.h are octal values, but the elements of the <ctype> array
# MYSET.xml should be written as hexadecimal values.
#
# The <lower> and <upper> arrays hold the lowercase and uppercase characters corresponding
# to each member of the character set.
#
# For example:
#
# 		lower['A'] should contain 'a'
# 		upper['a'] should contain 'A'
#
# Each <collation> array indicates how characters should be ordered for comparison and sorting purposes.
# MySQL sorts characters based on the values of this information.
#
# In some cases, this is the same as the <upper> array, which means that sorting is case-insensitive.
#
# For more complicated sorting rules (for complex character sets), see the discussion of string collating
# in SECTION 10.12.2, "STRING COLLATING SUPPORT FOR COMPLEX CHARACTER SETS"
#
# 10.12.2 STRING COLLATING SUPPORT FOR COMPLEX CHARACTER SETS
#
# For a simple character set named MYSET, sorting rules are specified in the
# MYSET.xml configuration file using <map> array elements within <collation> elements.
#
# If the sorting rules for your language are too complex to be handled with simple arrays,
# you must define string collating functions in the ctype-MYSET.c source file in the
# strings directory.
#
# The existing character sets provide the best documentation and examples to show how these
# functions are implemented.
#
# Look at the ctype-*.c files in the strings directory, such as the files for the big5,
# czech, gbk, sjis and tis160 character sets.
#
# Take a look at the MY_COLLATION_HANDLER structures to see how they are used.
#
# See also the CHARSET_INFO.txt file in the strings directory for additional information.
#
# 10.12.3 MULTI-BYTE CHARACTER SUPPORT FOR COMPLEX CHARACTER SETS
#
# If you want to add support for a new character set named MYSET that includes
# multibyte characters, you must use multibyte character functions in the ctype-MYSET.c
# source file in the strings directory.
#
# The existing character sets provide the best documentation and examples on how they are implemented.
#
# Look at the ctype-*.c files in the strings directory, such as the files for the 
# euc_kr, gb2312, gbk, sjis and ujis character sets.
#
# Take a look at the MY_CHARSET_HANDLER structures to see how they are used.
#
# See also the CHARSET_INFO.txt file in the strings directory for additional information.
#
# ADDING A COLLATION TO A CHARACTER SET
#
# A collation is a set of rules that defines how to compare and sort character strings.
# Each collation in MySQL belongs to a single character set.
#
# Every character set has at least one collation, and most have two or more collations.
#
# A collation orders characters based on weights. Each character in a character set maps to a 
# weight.
#
# Characters with equal weights compare as equal, and characters with unequal weights compare
# according to the relative magnitude of their weights.
#
# THe WEIGHT_STRING() function can be used to see the weights for the characters in a string.
#
# The value that it returns to indicate weights is a binary string, so it is convenient to use HEX(WEIGHT_STRING(str))
# to display the weights in printable form.
#
# The following example shows that weights do not differ for lettercase for the letters
# in 'AaBb' if it is a nonbinary case-insensitive string, but do differ if it is a binary string:
#
# 		SELECT HEX(WEIGHT_STRING('AaBb' COLLATE latin1_swedish_ci));
# 		+-----------------------------------------------------------+
# 		| HEX(WEIGHT_STRING('AaBb' COLLATE latin1_swedish_ci)) 		|
# 		+-----------------------------------------------------------+
# 		| 41414242 																	|
# 		+-----------------------------------------------------------+
#
# 		SELECT HEX(WEIGHT_STRING(BINARY 'AaBb'));
# 		+----------------------------------------+
# 		| HEX(WEIGHT_STRING(BINARY 'AaBb')) 	  |
# 		+----------------------------------------+
# 		| 41614262 										  |
# 		+----------------------------------------+
#
# MySQL supports several collation implementations, as discussed in SECTION 10.13.1, "COLLATION IMPLEMENTATION TYPES".
#
# Some of these can be added to MySQL without recompiling:
#
# 		) Simple collations for 8-bit character sets
#
# 		) UCA-based collations for Unicode character sets
#
# 		) Binary (xxx_bin) collations
#
# The following sections describe how to add collations of the first two types to existing character sets.
#
# All existing character sets already have a binary collation, so there is no
# need here ot describe how to add one.
#
# Summary of the procedure for adding a new collation:
#
# 		1. Choose a collation ID
#
# 		2. Add configuration information that names the collation and describes the character-ordering rules.
#
# 		3. Restart the server.
#
# 		4. Verify that the collation is present
#
# The instructions here cover only collations that can be added without recompiling MysQL.
#
# To add a collation that does require recompiling (as implemented by means of functions
# in a C source file), use the instructions in SECTION 10.12, "ADDING A CHARACTER SET".
#
# However, instead of adding all the information required for a complete character set,
# just modify the appropriate files for an existing character set.
#
# That is, based on what is already present for the character set's current collations,
# add data structures, functions and configuration information for the new collation.
#
# 		NOTE:
#
# 			If you modify an existing collation, that may affect the ordering of rows for indexes
# 			on columns that use the collation.
#
# 			In this case, rebuild any such indexes to avoid problems such as incorrect query results.
#
# 			See SECTION 2.11.3, "REBUILDING OR REPAIRING TABLES OR INDEXES"
#
# ADDITIONAL RESOURCES
#
# ) The Unicode Collation Algorithm (UCA) spec -> <link>
#
# ) The Locale Data Markup Language (LDML) spec -> <link>
#
# 10.13.1 COLLATION IMPLEMENTATION TYPES
#
# MySQL implements several types of collations:
#
# Simple collations for 8-bit character sets
#
# This kind of collation is implemented using an array of 256 weights that
# defines a one-to-one mapping from character codes to weights.
#
# latin1_swedish_ci is an example.
#
# It is a case-insensitive collation, so the uppercase and lowercase versions of a character
# have the same weights and they compare as equal.
#
# 		SET NAMES 'latin1' COLLATE 'latin1_swedish_ci';
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		SELECT HEX(WEIGHT_STRING('a')), HEX(WEIGHT_STRING('A'));
# 		+---------------------------+-------------------------+
# 		| HEX(WEIGHT_STRING('a')) 	 | HEX(WEIGHT_STRING('A')) |
# 		+---------------------------+-------------------------+
# 		| 41 								 | 41 							|
# 		+---------------------------+-------------------------+
#
# 		SELECT 'a' = 'A';
# 		+-----------------+
# 		| 'a' = 'A' 		|
# 		+-----------------+
# 		| 			1 			|
# 		+-----------------+
# 		1 row in set (0.12 sec)
#
# For implementation instructions, see SECTION 10.13.3, "ADDING A SIMPLE COLLATION TO AN 8-BIT CHARACTER SET"
#
# COMPLEX COLLATIONS FOR 8-BIT CHARACTER SETS
#
# This kind of collation is implemented using functions in a C source file that define how to order
# characters, as described in SECTION 10.12, "ADDING A CHARACTER SET"
#
# COLLATIONS FOR NON-UNICODE MULTIBYTE CHARACTER SETS
#
# For this type of collation, 8-bit (single-byte) and multibyte characters are
# handled differently.
#
# For 8-bit characters, character codes map to weights in case-insensitive fashion.
#
# (For example, the single-byte characters 'a' and 'A' both have a weight of 0x41)
#
# For multibyte characters, there are two types of relationship between character
# codes and weights:
#
# 		) Weights equal character codes.
#
# 			sjis_japanese_ci is an example of this kind of collation.
#
# 			The multibyte character '<japanese char>' has a character code of 0x82C0,
# 			and the weight is also 0x82C0
#
# 				CREATE TABLE t1
# 					(c1 VARCHAR(2) CHARACTER SET sjis COLLATE sjis_japanese_ci);
# 				Query OK, 0 rows affected (0.01 sec)
#
# 				INSERT INTO t1 VALUES ('a'), ('A'), (0x82C0);
# 				Query OK, 3 rows affected (0.00 sec)
# 				Records: 3 Duplicates: 0 Warnings: 0
#
# 				SELECT c1, HEX(c1), HEX(WEIGHT_STRING(c1)) FROM t1;
# 				+--------+-----------+--------------------------------+
# 				| c1 		| HEX(c1) 	| HEX(WEIGHT_STRING(c1)) 			|
# 				+--------+-----------+--------------------------------+
# 				| a 		| 61 			| 41 										|
# 				| A 		| 41 			| 41 										|
# 				| <char> | 82C0 		| 82C0 									|
# 				+--------+-----------+--------------------------------+
# 				3 rows in set (0.00 sec)
#
# 		) Character codes map one-to-one to weights, but a code is not necessarily equal
# 			to the weight.
#
# 			gbk_chinese_ci is an example of this kind of collation.
#
# 			The multibyte character '<Japanese Char>', has a character code of 0x81B0 but
# 			a weight of 0xC286.
#
# 			CREATE TABLE t1(c1 VARCHAR(2) CHARACTER SET gbk COLLATE gbk_chinese_ci);
# 			Query OK, 0 rows affected (0.33 sec)
#
# 			INSERT INTO t1 VALUES ('a'), ('A'), (0x81B0);
# 			Query OK, 3 rows affected (0.00 sec)
# 			Records: 3 Duplicates: 0 Warnings: 0
#
# 			SELECT c1, HEX(c1), HEX(WEIGHT_STRING(c1)) FROM t1;
# 			+-----+---------+-----------------------+
# 			| c1  | HEX(c1) | HEX(WEIGHT_STRING(c1))|
# 			+-----+---------+-----------------------+
# 			| a 	| 61 		 | 41 						 |
# 			| A 	| 41 		 | 41 						 |
# 			| * 	| 81B0 	 | C286 						 |
# 			+-----+---------+-----------------------+
# 			3 rows in set (0.00 sec)
#
# For implementation instructions, see SECTION 10.12, "ADDING A CHARACTER SET"
#
# Collations for Unicode multibyte character sets
#
# Some of these collations are based on the Unicode Collation Algorithm (UCA), others are not.
#
# Non-UCA collations have a one-to-one mapping from character code to weight.
# In MySQL, such collations are case insensitive and accent insensitive.
#
# utf8_general_ci is an example: 'a', 'A', '', and '' each have different character codes
# but all have a weight of 0x0041 and compare as equal.
#
# 		SET NAMES 'utf8' COLLATE 'utf8_general_ci';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		CREATE TABLE t1 (c1 CHAR(1) CHARACTER SET UTF8 COLLATE utf8_general_ci);
# 		Query OK, 0 rows affected (0.01 sec)
#
# 		INSERT INTO t1 VALUES ('a'),('A'),(''), ('');
# 		Query OK, 4 rows affected (0.00 sec)
# 		Records: 4 Duplicates: 0 Warnings: 0
#
# 		SELECT c1, HEX(c1), HEX(WEIGHT_STRING(c1)) FROM t1;
# 		+----+--------+-----------------------+
# 		| c1 | HEX(c1)| HEX(WEIGHT_STRING(c1))|
# 		+----+--------+-----------------------+
# 		| a  | 61 	  | 0041 					  |
# 		| A  | 41 	  | 0041 					  |
# 		|   | C380   | 0041 					  |
# 		|   | C3A1   | 0041 					  |
# 		+----+--------+-----------------------+
# 		4 rows in set (0.00 sec)
#
# UCA-based collations in MySQL have these properties:
#
# 		) If a character has weights, each weight uses 2 bytes (16 bits)
#
# 		) A character may have zero weights (or an empty weight).
#
# 			In this case, the character is ignorable.
#
# 			Example: "U+0000 NULL" does not have a weight and is ignorable.
#
# 		) A character may have one weight. Example: 'a' has a weight of 0x0E33
#
# 			SET NAMES 'utf8' COLLATE 'utf8_unicode_ci';
# 			Query OK, 0 rows affected (0.05 sec)
#
# 			SELECT HEX('a'), HEX(WEIGHT_STRING('a'));
# 			+---------+-------------------------+
# 			| HEX('a')| HEX(WEIGHT_STRING('a')) |
# 			+---------+-------------------------+
# 			| 61 		 | 0E33 							|
# 			+---------+-------------------------+
# 			1 row in set (0.02 sec)
#
# 		) A character may have many weights. This is an expansion.
# 			Example: The German letter '[german s]' (SZ ligature, or SHARP S) has a weight of 0x0FEA0FEA
#
# 			SET NAMES 'utf8' COLLATE 'utf8_unicode_ci';
# 			Query OK, 0 rows affected (0.11 sec)

# 			SELECT HEX('[german s]'), HEX(WEIGHT_STRING('[german s]'));
# 			+------------------+---------------------------------+
# 			| HEX('[german s]')| HEX(WEIGHT_STRING('[german s]'))|
# 			+------------------+---------------------------------+
# 			| C39F 				 | 0FEA0FEA 							  |
# 			+------------------+---------------------------------+
# 			1 row in set (0.00 sec)
#
# 		) Many characters may have one weight. This is a contraction.
#
# 			Example: 'ch' is a single letter is a single letter in Czech
# 			and has a weight of 0x0EE2
#
# 			SET NAMES 'utf8' COLLATE 'utf8_czech_ci';
# 			Query OK, 0 rows affected (0.09 sec)
#
# 			SELECT HEX('ch'), HEX(WEIGHT_STRING('ch'));
# 			+--------------+------------------------------+
# 			| HEX('ch') 	| HEX(WEIGHT_STRING('ch')) 	 |
# 			+--------------+------------------------------+
# 			| 6368 			| 0EE2 								 |
# 			+--------------+------------------------------+
# 			1 row in set (0.00 sec)
#
# A many-characters-to-many-weights mapping is also possible (this is contraction with expaison),
# but it is not supported by MySQL.
#
# For implementation instructions, for a non-UCA collation, see Section 10.12, "ADDING A CHARACTER SET"
#
# For a UCA collation, see SECTION 10.13.4, "Adding a UCA Collation to a Unicode Character Set"
#
# MISCELLANEOUS COLLATIONS
#
# There are also a few collations that do not fall into any of the previous categories.
#
# 10.13.2 CHOOSING A COLLATION ID
#
# Each collation must have a unique ID.
# To add a collation, you must choose an ID value that is not currently used.
#
# MySQL supports two-byte collation IDs. The range of IDs from 1024 to 2047
# is reserved for user-defined collations.
#
# The collation ID that you choose will appear in these contexts:
#
# 		) The ID column of the INFORMATION_SCHEMA.COLLATIONS table
#
# 		) The Id column of SHOW_COLLATION output
#
# 		) The charsetnr member of the MYSQL_FIELD C API data structure.
#
# 		) The number member of the MY_CHARSET_INFO data structure returned by the mysql_get_character_set_info()
# 			C API function.
#
# To determine the largest currently used ID, issue the following statement:
#
# 		SELECT MAX(ID) FROM INFORMATION_SCHEMA.COLLATIONS;
# 		+----------+
# 		| MAX(ID)  |
# 		+----------+
# 		| 210 	  |
# 		+----------+
#
# To display a list of all currently used IDs, issue this statement:
#
# 		SELECT ID FROM INFORMATION_SCHEMA.COLLATIONS ORDER BY ID;
# 		+---------+
# 		| ID 		 |
# 		+---------+
# 		| 		1 	 |
# 		| 		2   |
# 		|   ---   |
# 		| 	  52   |
# 		| 	  53   |
# 		| 	  57   |
# 		| 	  58   |
# 		| 	 ---   |
# 		| 	  98   |
# 		| 	  99   |
# 		|   128   |
# 		| 	 129 	 |
# 		| 	 ---   |
# 		|   210   |
# 		+---------+
#
# WARNING:
#
# 		Before upgrading, you should save the configuration files that you change.
#
# 		If you upgrade in place, the process will replace your modified files.
#
# 10.13.3 ADDING A SIMPLE COLLATION TO AN 8-BIT CHARACTER SET
#
# This section describes how to add a simple collation for an 8-bit character set by writing
# the <collation> elements associated with a <charset> character set description in the
# MySQL Index.xml file.
#
# The procedure described here does not require recompiling MySQL.
#
# The example adds a collation named latin1_test_ci to the latin1 character set.
#
# 		1. Choose a collation ID, as shown in SECTION 10.13.2, "CHOOSING A COLLATION ID". The following steps use an ID of 1024
#
# 		2. Modify the Index.xml and latin1.xml configuration files.
#
# 			These files are located in the directory named by the character_sets_dir system variable.
#
# 			You can check the variable value as follows, although the path name might be different
# 			on your system:
#
# 				SHOW VARIABLES LIKE 'character_sets_dir';
# 				+--------------------+----------------------------------------+
# 				| Variable_name 		| Value 											  |
# 				+--------------------+----------------------------------------+
# 				| character_sets_dir | /user/local/mysql/share/mysql/charsets/|
# 				+--------------------+----------------------------------------+
#
# 		3. Choose a name for the collation and list it in the Index.xml file
#
# 			Find the <charset> element for the character set to which the collation is being
# 			added, and a <collation> element that indicates the collation name and ID, to associate
# 			the name with the ID.
#
# 			For example:
#
# 				<charset name="latin1">
# 					---
# 					<collation name="latin1_test_ci" id="1024"/>
# 					---
# 				</charset>
#
# 		4. In the latin1.xml configuration file, add a <collation> element that names the collation
# 			and that contains a <map> element that defines a character code-to-weight mapping table
# 			for character codes 0 to 255.
#
# 			Each value within the <map> element must be a number in hexadecimal format.
#
# 			<collation name="latin1_test_ci">
# 			<map>
# 			00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F
# 			10 11 -> etc.
# 			|
# 			v
# 			etc.		
# 			</map>
# 			</collation>
#
# 		5. Restart the server and use this statement to verify that the collation is present:
#
# 			SHOW COLLATION WHERE Collation = 'latin1_test_ci';
# 			+--------------------+-------------+----------+--------------+------------+----------------+
# 			| Collation 			| Charset 	  | Id 		 | Default 		 | Compiled   | Sortlen 		 |
# 			+--------------------+-------------+----------+--------------+------------+----------------+
# 			| latin1_test_ci 		| latin1 	  | 1024 	 | 				 | 			  | 		1 			 |
# 			+--------------------+-------------+----------+--------------+------------+----------------+
#
# 10.13.4 ADDING A UCA COLLATION TO A UNICODE CHARACTER SET
#
# This section describes how to add a UCA collation for a Unicode character set by writing the <collation>
# element within a <charset> character set description in the MySQL Index.xml file
#
# The procedure described here does not require recompiling MySQL.
#
# It uses a subset of the Locale Data Markup Language (LDML) specification, which is available
# at <link>
#
# With this method, you need not define the entire collation.
#
# Instead, you begin with an existing "base" collation and describe the new collation
# in terms of how it differs from the base collation.
#
# The following table lists the base collations of the Unicode character sets for which
# UCA collations can be defined.
#
# It is not possible to create a user-defined UCA collations for utf16le; there is no utf16le_unicode_ci
# collation that would serve as the basis of such collations.
#
# TABLE 10.4 MySQL CHARACTER SETS AVAILABLE FOR USER-DEFINED UCA COLLATIONS
#
# 	Character Set 		Base Collation
# +---------------+-----------------+
# | utf8 			| utf8_unicode_ci |
# | ucs2 			| ucs2_unicode_ci |
# | utf16 			| utf16_unicode_ci|
# | utf32 			| utf32_unicode_ci|
# +---------------+-----------------+
#
# THe following sections show how to add a collation that is defined using LDML syntax, and
# provide a summary of LDML rules supported in MySQL.
#
# 10.13.4.1 DEFINING A UCA COLLATION USING LDML SYNTAX
#
# To add a UCA collation for a Unicode character set without recompiling MySQL, use the following
# procedure.
#
# If you are unfamiliar with the LDML rules used to describe the collations sort characteristics,
# see SECTION 10.13.4.2, "LDML SYNTAX SUPPORTED IN MYSQL"
#
# The example adds a collation named utf8_phone_ci to the utf8 character set.
#
# The collation is designed for a scenario involving a Web app for which users post
# their names and phone numbers.
#
# The numbers can be given in very different formats:
#
# 		+7-12345-67
# 		+7-12-345-67
# 		+7 12 345 67
# 		+7 (12) 345 67
# 		+71234567
#
# The problem raised by dealing with these kinds of values is that the varying permissible
# formats make searching for a specific phone number very difficult.
#
# The solution is to define a new collation that reorders punctuation characters, making them ignorable.
#
# 		1. Choose a collation ID, as shown in SECTION 10.13.2, "CHOOSING A COLLATION ID". The following steps use an ID of 1029
#
# 		2. To modify the Index.xml configuration file.
#
# 			THis file is located in the directory named by the character_sets_dir system variable.
#
# 			YOu can check the variable value as follows, although the path name might
# 			be different on your system:
#
# 				SHOW VARIABLES LIKE 'character_sets_dir';
# 				+------------------------+----------------------------------------+
# 				| Variable_name 			 | Value 										   |
# 				+------------------------+----------------------------------------+
# 				| character_sets_dir 	 | /user/local/mysql/share/mysql/charsets/|
# 				+------------------------+----------------------------------------+
#
# 		3. Choose a name for the collation and list it in the Index.xml file.
#
# 			In addition, you'll need to provide the collation ordering rules.
#
# 			Find the <charset> element for the character set to which the collation is being added,
# 			and add a <collation> element that indicates the collation name and ID, to associate
# 			the name with the ID.
#
# 			Within the <collation> element, provide a <rules> element containing the ordering rules:
#
# 				<charset name="utf8">
# 					---
# 					<collation name="utf8_phone_ci" id="1029">
# 						<rules>
# 							<reset>\u0000</reset>
# 							<i>\u0020</i> <!-- space -->
# 							<i>\u0028</i> <!-- left paranthesis -->
# 							<i>\u0029</i> <!-- right paranthesis -->
# 							<i>\u002B</i> <!-- plus -->
# 							<i>\u002D</i> <!-- hyphen -->
# 						</rules>
# 					</collation>
# 					---
# 				</charset>
#
# 		4. If you want a similar collation for other Unicode character sets, add other <collation> elements.
#
# 			For example, to define ucs2_phone_ci, add a <collation> element to the <charset name="ucs2"> element.
#
# 			Remember that each collation must have its own unique ID.
#
# 		5. Restart the server and use this statement to verify that the collation is present:
#
# 				SHOW COLLATION WHERE Collation = 'utf8_phone_ci';
# 				+--------------------+-------------+------+--------------+------------+------------+
# 				| Collation 			| Charset 	  | Id   | Default 	   | Compiled 	 | Sortlen    |
# 				+--------------------+-------------+------+--------------+------------+------------+
# 				| utf8_phone_ci 		| utf8 		  | 1029 | 				   | 				 | 		8    |
# 				+--------------------+-------------+------+--------------+------------+------------+
#
# Now test the collation to make sure that it has the desired properties.
#
# Create a table containing some sample phone numbers using the new collation:
#
# 		CREATE TABLE phonebook (
# 			name VARCHAR(64),
# 			phone VARCHAR(64) CHARACTER SET utf8 COLLATE utf8_phone_ci
# 		);
# 		Query OK, 0 rows affected (0.09 sec)
#
# 		INSERT INTO phonebook VALUES ('Svoj', '+7 912 800 80 02');
# 		Query OK, 1 row affected (0.00 sec)
#
# 		INSERT INTO phonebook VALUES ('Hf', '+7 (912) 800 80 04');
# 		Query OK, 1 row affected (0.00 sec)
#
# 		INSERT INTO phonebook VALUES ('Bar', '+7 912-800-80-01');
# 		Query OK, 1 row affected (0.00 sec)
#
# 		etc.
#
# Run some queries to see whether the ignored punctuation characters are in fact ignored
# for comparison and sorting:
#
# 		SELECT * FROM phonebook ORDER BY phone;
# 		+----------+--------------------------+
# 		| name 	  | Phone 						  |
# 		+----------+--------------------------+
# 		| Sanja    | +380 (912) 8008005 		  |
# 		| Bar 	  | +7-912-800-80-01 		  |
# 		etc.
#
# 		5 rows in set (0.00 sec)
#
# 		SELECT * FROM phonebook WHERE phone='+7(912)800-80-01';
# 		+--------+-------------------+
# 		| name   | phone 				  |
# 		+--------+-------------------+
# 		| Bar    | 7-912-800-80-01   |
# 		+--------+-------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT * FROM phonebook WHERE phone='79128008001';
# 		+--------+-------------------+
# 		| name   | phone 				  |
# 		+--------+-------------------+
# 		| Bar 	| +7-912-800-80-01  |
# 		+--------+-------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT * FROM phonebook WHERE phone='7 9 1 2 8 0 0 8 0 0 1';
# 		+--------+-------------------+
# 		| name 	| phone 				  |
# 		+--------+-------------------+
# 		| Bar 	| +7-912-800-80-01  |
# 		+--------+-------------------+
# 		1 row in set (0.00 sec)
#
# 10.13.4.2 LDML SYNTAX SUPPORTED IN MYSQL
#
# This section describes the LDML syntax that MySQL recognizes.
#
# This is a subset of the syntax described in the LDML specification available at <link>,
# which should be consulted for further information.
#
# MySQL recognizes a large enough subset of the syntax that, in many cases, it is possible
# to download a collation definition from the Unicode Common Locale Data Repository and paste
# the relevant part (that is, the part between the <rules> and </rules> tags) into the MysQL
# Index.xml file.
#
# The rules described here are all supported except that character sorting occurs only at the
# primary leve.
#
# Rules that specify differences at secondary or higher sort levels are recognized (and thus can
# be included in collation definitions) but are treated as equality at the primary level.
#
# The MySQL server generates diagnostics when it finds problems while parsing the Index.xml file.
# See SECTION 10.13.4.3, "DIAGNOSTICS DURING INDEX.XML PARSING".
#
# CHARACTER REPRESENTATION
#
# Characters named in LDML rules can be written literally or in \unnnn format, where nnnn is the
# hexadecimal Unicode code point value.
#
# For example, A and  can be written literally or as \u0041 and \u00E1.
#
# Within hexadecimal values, the digits A through F are not case-sensitive;
# \u00E1 and \u00e1 are equivalent.
#
# For UCA 4.0.0 collations, hexadecimal notation can be used only for characters in the
# Basic Multilingual Plane, not for characters outside the BMP range of 0000 to FFFF.
#
# For UCA 5.2.0 collations, the hexadecimal notation can be used for any character.
#
# THe Index.xml file itself should be written using UTF-8 encoding
#
# SYNTAX RULES
#
# LDML has reset rules and shift rules to specify character ordering.
#
# Orderings are given as a set of rules that begin with a reset rule that establishes
# an anchor point, followed by shift rules that indicate how characters sort relative
# to the anchor point. 
#
# 		) A <reset> rule does not specify any ordering in and of itself.
#
# 			INstead, it "resets" the ordering for subsequent shift rules to cause them to
# 			be taken in relation to a given character.
#
# 			Either of hte following rules resets subsequent shift rules to be taken in relation
# 			to the letter 'A':
#
# 				<reset>A</reset>
#
# 				<reset>\u0041</reset>
#
# 		) The <p>, <s>, and <t> shift rules define primary, secondary and tertiary differences
# 			of a character from another character::
#
# 			) Use primary differences to distinguish separate letters.
#
# 			) Use secondary differences to distinguish accent variations.
#
# 			) Use tertiary differences to distinguish lettercase variations.
#
# 			Either of these rules specify a primary shift rule for the 'G' character:
#
# 				<p>G</p>
#
# 				<p>\u0047</p>
#
# 		) The <i> shift rule indicates that one character sorts identically to another.
#
# 			The following rules cause 'b' to sort the same as 'a':
#
# 				<reset>a</reset>
# 				<i>b</i>
#
# 		) Abbreviated shift syntax specifies multiple shift rules using a single pair of tags.
#
# 			The following table shows the correspondence between abbreviated syntax rules and
# 			the equivalent nonabbreviated rules.
#
# 			TABLE 10.5 ABBREVIATED SHIFT SYNTAX
#
# 			ABBREVIATED SYNTAX 		NONABBREVIATED SYNTAX
#
# 			<pc>xyz</pc> 				<p>x</p><p>y</p><p>z</p>
# 			<sc>xyz</sc> 				<s>x</s><s>y</s><s>z</s>
# 			<tc>xyz</tc> 				<t>x</t><t>y</t><t>z</t>
# 			<ic>xyz</ic> 				<i>x</i><i>y</i><i>z</i>
#
# 		) An expansion is a reset rule that establishes an anchor point for a multiple-character sequence.
# 			MySQL supports expansions to 2 to 6 characters long.
#
# 			The following rules put 'z' greater at the primary level than the sequence
# 			of three characters 'abc':
#
# 				<reset>abc</reset>
# 				<p>z</p>
#
# 		) A contraction shift is a shift rule that sorts a multiple-character sequence.
# 			MySQL supports contractions 2 to 6 characters long.
#
# 			The following rules put the sequence of three characters 'xyz' greater at
# 			primary level than 'a':
#
# 				<reset>a</reset>
# 				<p>xyz</p>
#
# 		) Long expansions and long contractions can be used together.
#
#			These rules put the sequence of three characters 'xyz' greater at the
# 			primary level than the sequence of three characters 'abc':
#
# 				<reset>abc</reset>
# 				<p>xyz</p>
#
# 		) Normal expansion syntax uses <x> plus <extend> elements to specify an expansion.
#
# 			The following rules put the character 'k' greater at secondary level than the 			 
# 			sequence 'ch'.
#
# 			That is, 'k' behaves as if it expands to a character after 'c' followed by 'h':
#
# 				<reset>c</reset>
# 				<x><s>k</s><extend>h</extend></x>
#
# 			This syntax permits long sequences. These rules sort the sequence 'ccs' greater
# 			at the tertiary level than the sequence 'cscs':
#
# 				<reset>cs</reset>
# 				<x><t>ccs</t><extend>cs</extend></x>
#
# 			The LDML specification describes normal expansion syntax as "tricky". See that spec for details.
#
# 		) Previous context syntax uses <x> plus <context> elements to specify that the context before
# 			a character affects how it sorts.
#
# 			The following rules put '-' greater at the secondary level than 'a',
# 			but only when '-' occurs after 'b':
#
# 				<reset>a</reset>
# 				<x><context>b</context><s>-</s></x>
#
# 		) Previous context syntax can include the <extend> element.
#
# 			These rules put 'def' greater at the primary level than 'aghi', but only when
# 			'def' comes after 'abc':
#
# 				<reset>a</reset>
# 				<x><context>abc</context><p>def</p><extend>ghi</extend></x>
#
# 		) Reset rules permit a before attribute. Normally, shift rules after a reset rule indicate characters
# 			that sort after the reset character.
#
# 			Shift rules after a reset rule that has the before attribute indicate characters that
# 			sort before the reset character.
#
# 			The following rules put the character 'b' immediately before 'a' at the primary level:
#
# 				<reset before="primary">a</reset>
# 				<p>b</p>
#
# 			Permissible before attribute values specify the sort level by name or the equivalent numeric value:
#
# 				<reset before="primary">
# 				<reset before="1">
#
# 				<reset before="secondary">
# 				<reset before="2">
#
# 				<reset before="tertiary">
# 				<reset before="3">
#
# 		) A reset rule can name a logical reset position rather than a literal character:
#
# 				<first_tertiary_ignorable/>
# 				<last_tertiary_ignorable/>
# 				<first_secondary_ignorable/>
# 				<last_secondary_ignorable/>
# 				<first_primary_ignorable/>
# 				<last_primary_ignorable/>
# 				<first_variable/>
# 				<last_variable/>
# 				<first_non_ignorable/>
# 				<last_non_ignorable/>
# 				<first_trailing/>
# 				<last_trailing/>
#
# 			These rules put 'z' greater at the primary level than nonignorable characters that have a 
# 			Default Unicode Collation Element Table (DUCET) entry and that are not CJK:
#
# 				<reset><last_non_ignorable/></reset>
# 				<p>z</p>
#
# 			Logical position have the code points as follows:
#
# 			TABLE 10.6 LOGICAL RESET POSITION CODE POINTS
# 			
# 			LOGICAL POSITION 				UNICODE 4.0.0 CODE POINT 		UNICODE 5.2.0 CODE POINT
# 			
# 			<first_non_ignorable/> 			U+02D0 								U+02D0
# 			<last_non_ignorable/> 			U+A48C 								U+1342E
# 			<first_primary_ignorable/> 	U+0332 								U+0332
#
# 			<last_primary_ignorable/>  	U+20EA 								U+101FD
# 			<first_secondary_ignorable/>  U+0000 								U+0000
# 			<last_secondary_ignorable/>	U+FE73 								U+FE73
# 			<first_tertiary_ignorable/> 	U+0000 								U+0000
# 			<last_tertiary_ignorable/> 	U+FE73 								U+FE73
#
# 			<first_trailing/> 			   U+0000 								U+0000
# 			<last_trailing/> 					U+0000 								U+0000
# 			<first_variable/> 				U+0009 								U+0009
# 			<last_variable/> 					U+2183 								U+1D371
#
# 		) The <collation> element permits a shift-after-method attribute that affects character weight
# 			calculation for shift rules.
#
# 			The attribute has these permitted values:
#
# 				) simple: Calculate character weights as for reset rules that do not have a before attribute.
#
# 							This is the default if the attribute is not given.
#
# 				) expand: Use expansions for shifts after reset rules.
#
# 			Suppose that '0' and '1' have weights of 0E29 and 0E2A and we want to put all basic Latin
# 			letters between '0' and '1':
#
# 				<reset>0</reset>
# 				<pc>(alphabet)</pc>
#
# 			For simple shift mode, weights are calculated as follows:
#
# 				'a' has weight 0E29+1
# 				'b' has weight 0E29+2
# 				'c' has weight 0E29+3
# 				---
#
# 			However, there are not enough vacant position to put 26 characters between '0' and '1'.
# 			The result is that digits and letters are intermixed.
#
# 			to solve this, use shift-after-method="expand". Then weights are calculated like this:
#
# 				'a' has weight [0E29][233D+1]
# 				'b' has weight [0E29][233D+2]
# 				'c' has weight [0E29][233D+3]
# 				---
#
# 			233D is the UCA 4.0.0 weight for character 0xA48C, which is the last nonignorable character
# 			(a sort of the greatest character in the collation, excluding CJK).
#
# 			UCA 5.2.0 is similar but uses 3ACA, for character 0x1342E
#
# MYSQL-Specific LDML Extensions
# 
# An extension to LDML rules permits the <collation> element to include an optional version
# attribute in <collation> tags to indicate the UCA version on which the collation is based.
#
# IF the version attribute is omitted, its default value is 4.0.0
#
# For example, this specification indicates a collation that is based on UCA 5.2.0:
#
# 		<collation id="nnn" name="utf8_xxx_ci" version="5.2.0">
# 		---
# 		</collation>
#
# 10.13.4.3 DIAGNOSTICS DURING INDEX.XML PARSING
#
# The MySQL server generates diagnostics when it finds problems while parsing the Index.xml file:
#
# 		) Unknown tags are written to the error log.
#
# 			For example, the following message results if a collation definition contains a <aaa> tag:
#
# 				[Warning] Buffered warning: Unknown LDML tag:
# 				'charsets/charset/collation/rules/aaa'
#
# 		) If collation intiialization is not possible, the server reports an "Uknown collation" error, and also
# 			generates warnings explaining the problems, such as in the previous example.
#
# 			In other cases, when a collation description is generally correct but contains some unknown tags,
# 			the collation is initialized and is available for use.
#
# 			The unknown parts are ignored, but a warning is generated in the error log.
#
# 		) Problems with collations generate warnings that clients can display with SHOW_WARNINGS.
#
# 			Suppose that a reset rule contains an expansion longer than the maximum supported length
# 			of 6 characters:
#
# 				<reset>abcdefghi</reset>
# 				<i>x</i>
#
# 			An attempt to use the collation produces warnings:
#
# 				SELECT _utf8'test' COLLATE utf8_test_ci;
# 				ERROR 1273 (HY000): Unknown collation: 'utf8_test_ci'
# 				SHOW WARNINGS;
# 				+--------------+----------+-----------------------------------------------+
# 				| Level 			| Code 	  | Message 												  |
# 				+--------------+----------+-----------------------------------------------+
# 				| Error 		   | 1273 	  | Unknown collation: 'utf8_test_ci' 				  |
# 				| Warning 		| 1273 	  | Expansion is too long at 'abcdefghi=x' 		  |
# 				+--------------+----------+-----------------------------------------------+
#
# 10.14 CHARACTER SET CONFIGURATION
#
# The MySQL server has a compiled-in default cahracter set and collation.
#
# TO change these defaults, use the --character-set-server and --collation-server options
# when you start the server.
#
# See SECTION 5.1.7, "SERVER COMMAND OPTIONS".
#
# The collation must be a legal collation for the default character set.
#
# To determine which collations are available for each character set, use the SHOW_COLLATION				 			
# statement or query the INFORMATION_SCHEMA COLLATIONS table.
#
# If you try to use a character set that is not compiled into your binary, you might run into
# the following problems:
#
# 		) If your program uses an incorrect path to determine where the character sets are stored
# 			(which is typically the share/mysql/charsets or share/charsets directory under the MySQL install dir)
# 			, this can be fixed using the --character-sets-dir option when you run the program.
#
# 			For example, to specify a directory to be used by MysQL client programs, list it in the
# 			[client] group of your option file.
#
# 			The examples given here show what the setting might look like for Unix or Windows.
#
# 				[client]
# 				character-sets-dir=/usr/local/mysql/share/mysql/charsets
#
# 				[client]
# 				character-sets-dir="C:/Program Files/MySQL/MySQL Server 8.0/share/charsets"
#
# 		) If the character set is a complex character set that cannot be loaded dynamically, you must recompile
# 			the program with support for the character set.
#
# 			For Unicode character sets, you can define collations without recompiling by using LDML notation.
#
# 			See SECTION 10.13.4, "ADDING A UCA COLLATION TO A UNICODE CHARACTER SET"
#
# 		) If the character set is a dynamic character set, but you do not have a configuration file for it,
# 			you should install the configuration file for the character set from a new MySQL distrib.
#
# 		) If your character set index file (Index.xml) does not contain the name for the character set, your program
# 			displays an error message:
#
# 				Character set 'charset_name' is not a compiled character set and is not
# 				specified in the '/usr/share/mysql/charsets/Index.xml' file
#
# 			To solve this problem, you should either get a new index file or manually add the name
# 			of any missing character sets to the current file.
#
# You can force client programs to use specific character set as follows:
#
# 	[client]
# 	default-character-set=charset_name
#
# This is normally uncalled for.
#
# However, when character_set_system differs from character_set_server or  character_set_client, and you
# input characters manually (as database object identifiers, column values, or both), these may be displayed
# incorrectly in output from the client or the output itself may be formatted incorrectly.
#
# In such cases, starting the mysql client with --default-character-set=system_character_set - that is,
# setting the client character set to match the system cahracter set - should fix the problem.
#
# 10.15 MYSQL SERVER LOCALE SUPPORT
#
# The locale indicated by the lc_time_names system variable controls the language used to 
# display day and month names and abbreviations.
#
# This variable affects the output from the DATE_FORMAT(), DAYNAME() and MONTHNAME() functions.
#
# lc_time_names does not effect the STR_TO_DATE() or GET_FORMAT() function.
#
# The lc_time_names value does not affect the result from FORMAT(), but this function takes an optional
# third parameter that enables a locale to be specified to be used for the result number's decimal point,
# thousands separator, and grouping between separators.
#
# Permissible locale values are the same as the legal values for the lc_time_names System varaible.
#
# Locale names have language and region subtags listed by IANA (<link>), such as 'ja_JP' or 'pt_BR'.
#
# THe default value is 'en_US' regardless of your system's locale setting, but you can set the value
# at server startup, or set the GLOBAL value at runtime if you have privileges sufficient to set global
# system variables;
#
# See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES".
#
# ANy client can examine the value of lc_time_names or set its SESSION value to affect the locale
# for its own connection.
#
# 		SET NAMES 'utf8';
# 		Query OK, 0 rows affected (0.09 sec)
#
# 		SELECT @@lc_time_names;
# 		+-------------------+
# 		| @@lc_time_names   |
# 		+-------------------+
# 		| en_US 				  |
# 		+-------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT DAYNAME('2010-01-01'), MONTHNAME('2010-01-01');
# 		+------------------------+---------------------------+
#		| DAYNAME('2010-01-01')  | MONTHNAME('2010-01-01')   |
# 		+------------------------+---------------------------+
# 		| Friday 					 | January 						  |
# 		+------------------------+---------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT DATE_FORMAT('2010-01-01', '%W %a %M %b');
# 		+----------------------------------------------+
# 		| DATE_FORMAT('2010-01-01', %W, %a, %M, %b')   |
# 		+----------------------------------------------+
# 		| Friday Fri January Jan 							  |
# 		+----------------------------------------------+
# 		1 row in set (0.00 sec)
#
# 		SET lc_time_names = 'es_MX';
# 		Query OK, 0 rows affected (0.00 sec9
#
# 		SELECT @@lc_time_names;
# 		+-----------------------+
# 		| @@lc_time_names 		|
# 		+-----------------------+
# 		| es_MX 						|
# 		+-----------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT DAYNAME('2010-01-01'), MONTHNAME('2010-01-01');
# 		+------------------------+-------------------------+
# 		| DAYNAME('2010-01-01')  | MONTHNAME('2010-01-01') |
# 		+------------------------+-------------------------+
# 		| viernes 					 | enero 						|
# 		+------------------------+-------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT DATE_FORMAT('2010-01-01', '%W %a %M %b');
# 		+---------------------------------------------------+
# 		| DATE_FORMAT('2010-01-01', '%W %a %M %b') 			 |
# 		+---------------------------------------------------+
# 		| viernes vie enero ene 									 |
# 		+---------------------------------------------------+
# 		1 row in set (0.00 sec)
#
# The day or month name for each of the affected functions is converted from utf8 to the char set indicated
# by the character_set_connection system variable.
#
# lc_time_names may be set to any of the following locale values.
# The set of locales supported by MySQL may differ from those supported by your operating system:
#
# 		LOCALE VALUE 								Meaning
#
# ar_AE: Arabic - United Arab Emirates 	ar_BH: Arabic - Bahrain
# ar_DZ: Arabic - Algeria 						ar_EG: Arabic - Egypt
# ar_IN. Arabic - India 						ar_IQ: Arabic - Iraq
# ar_JO: Arabic - Jordan 						ar_KW: Arabic - Kuwait
#
# ar_LB: Arabic - Lebanon 						ar_LY: Arabic - Libya
# ar_MA: Arabic - Morocco 						ar_OM: Arabic - Oman
# ar_QA: Arabic - Qatar 						ar_SA: Arabic - Saudi Arabia
# aq_SD: Arabic - Sudan 						ar_SY: Arabic - Syria
#
# ar_TN: Arabic - Tunisia 						AR_YE: Arabic - Yemen
# be_BY: Belarusian - Belarus 				bg_BG: Bulgarian - Bulgaria
# ca_ES: Catalan - Spain 						cs_CZ: Czech - Czech Republic
# da_DK: Danish - Denmark 						de_AT: German - Austria
#
# de_BE: German - Belgium 						de_CH: German - Switzerland
# de_DE: German - Germany 						de_LU: German - Luxembourg
# el_GR: Greek - Greece 						en_AU: English - Australia
# en_CA: English - Canada 						en_GB: English - United Kingdom
#
# en_IN: English - India 						en_NZ: English - New Zealand
# en_PH: English - Philippines 				en_US: English - United States
# en_ZA: English - South Africa 				en_ZW: English - Zimbabwe
#
# es_AR: Spanish - Argentina 					es_BO: Spanish - Bolivia
# es_CL: Spanish - Chile 						es_CO: Spanish - Colombia
# es_CR: Spanish - Costa Rica 				es_DO: Spanish - Dominican Republic
# es_EC: Spanish - Ecuador 					es_ES: Spanish - Spain
#
# es_GT: Spanish - Guatemala 					es_HN: Spanish - Honduras
# es_MX: Spanish - Mexico 						es_NI: Spanish - Nicaragua
# es_PA: Spanish - Panama 						es_PE: Spanish - Peru
# es_PR: Spanish - Puerto Rico 				es_PY: Spanish - Paraguay
#
# es_SV: Spanish - El Salvador 				es_US: Spanish - United States
# es_UY: Spanish - Uruguay 					es_VE: Spanish - Venezuela
# et_EE: Estonian - Estonia 					eu_ES: Basque - Basque
# fi_FI: Finnish - Finland 					fo_FO: Faroese - Faroe Islands
#
# fr_BE: French - Belgium 						fr_CA: French - Canada
# fr_CH: French - Switzerland 				fr_FR: French - France
# fr_LU: French - Luxembourg 					gl_ES: Galician - Spain
# gu_IN: Gujarati - India 						he_IL: Hebrew - Israel
#
# hi_IN: Hindi - India 							hr_HR: Croatian - Croatia
# hu_HU: Hungarian - Hungary 					id_ID: Indonesian - Indonesia
# is_IS: Icelandic - Iceland 					it_CH: Italian - Switzerland
# it_IT: Italian - Italy 						ja_JP: Japanese - japan
#
# ko_KR: Korean - Republic of Korea 		lt_LT : Lithuanian - Lithuania
# lv_LV: Latvian - Latvia 						mk_MK: Macedonian - FYROM
# mn_MN: Mongolia - Mongolian 				ms_MY: Malay - Malaysia
# nb_NO: Norweigan (Bokml) - Norway 		nl_BE: Dutch - Belgium
#
# nl_NL: Dutch - The Netherlands 			no_NO: Norweigan - Norway
# pl_PL: Polish - Poland 						pt_BR: Portugese - Brazil
# pt_PT: Portugese - Portugal 				rm_CH: Romansh - Switzerlands
# ro_RO: Romanian - Romania 					ru_RU: Russian - Russia
#
# ru_UA: Russian - Ukraine 					sk_SK: SLovak - Slovakia
# sl_SI: Slovenian - Slovenia 				sq_AL: Albanian - Albania
# sr_RS: Serbian - Yugoslavia 				sv_Fi: Swedish - Finland
# sv_SE: Swedish - Sweden 						ta_IN: Tamil - India
#
# te_IN: Telugu - India 						tn_TH: Thai - Thailand
# tr_TR: Turkish - Turkey 						uk_UA: Ukrainian - Ukraine
# ur_PK: Urdu - Pakistan 						vi_VN: Vietnamese - Viet Nam
# zh_CN: Chinese - China 						zh_HK: Chinese - Hong Kong
# zh_TW: Chinese - Taiwan Province of China
#
# 11 DATA TYPES
#
# MySQL supports a number of SQL data types in several categories: numeric types, date, and time types,
# string (character and byte) types, spatial types, and the JSON data type.
#
# This chapter provides an overview of these data types, a more detailed description of the
# properties of the types in each category, and a summary of the data type storage requirements.
#
# The initial overview is brief.
#
# The later chapters are more detailed with particular data types, permissible formats, etc.
#
# Data type descriptions use these conventions:
#
# 		) M indicates the maximum display width for integer types.
#
# 			For floating-point and fixed-point types, M is the total number of digits that
# 			can be stored (the precision).
#
# 			For string types, M is the maximum length.
#
# 			The maximum permissible value of M depends on the data type.
#
# 		) D applies to floating-point and fixed-point types and indicates the number of digits
# 			following the decimal point (the scale).
#
# 			The maximum possible value is 30, but should be no greater than M-2
#
# 		) fsp applies to the TIME, DATETIME and TIMESTAMP types and represents fractional seconds precision;
# 			that is, the number of digits following the decimal point for fractional parts of seconds.
#
# 			The fsp value, if given, must be in the range 0 to 6.
#
# 			A value of 0 signifies that there is no fractional part.
#
# 			If omitted, the default precision is 0.
# 			(This differs from the standard SQL default of 6, for compatibility with previous versions of MySQL)
#
# 		) Square brackets ([ and ]) indicate optional parts of type definitions.
#
# 11.1 NUMERIC TYPE OVERVIEW
#
# A summary of the numeric data types follows.
#
# For additional information about properties and storage requirements of the numeric types, 
# see SECTION 11.2, "NUMERIC TYPES", and SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# M indicates the maximum display width for integer types.
# The maximum display width is 255.
#
# Display width is unrelated to the range of values a type can contain, as described
# in SECTION 11.2, "NUMERIC TYPES". For floating-point and fixed-point types, M, is the
# total number of digits that can be stored.
#
# If you specify ZEROFILL for a numeric column, MySQL automatically adds the UNSIGNED attribute
# to the column.
#
# NUmeric data types that permit the UNSIGNED attribute also permit SIGNED.
# However, these data types are signed by default, so the SIGNED attribute has no effect.
#
# SERIAL is an alias for BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE.
#
# SERIAL DEFAULT VALUE in definition of an integer column is an alias for NOT NULL 
# AUTO_INCREMENT UNIQUE
#
# 		WARNING:
#
# 			When you use subtraction between integer values where one is of type UNSIGNED,
# 			the result is unsigned unless the NO_UNSIGNED_SUBTRACTION SQL mode is enabled.
#
# 			See SECTION 12.12, "CAST FUNCTIONS AND OPERATORS"
#
# 		) BIT [(M)]
# 		
# 			A bit-value type. M indicates the number of bits per value, from 1 to 64.
# 			The default is 1 if M is omitted.
#
# 		) TINYINT[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			A very small integer. The signed range is -128 to 127.
# 			Unsigned range is 0 to 255.
#
# 		) BOOL, BOOLEAN
#
# 			These types are synonyms for TINYINT(1).
#
# 			A value of zero is considered false.
# 			Nonzero values are considered true:
#
# 				SELECT IF(0, 'true', 'false');
# 				+-----------------------------+
# 				| IF(0, 'true', 'false') 		|
# 				+-----------------------------+
# 				| false 							   |
# 				+-----------------------------+
#
# 				SELECT IF(1, 'true', 'false');
# 				+-----------------------------+
# 				| IF(1, 'true', 'false') 		|
# 				+-----------------------------+
# 				| true 								|
# 				+-----------------------------+
#
# 				SELECT IF(2, 'true', 'false');
# 				+------------------------------+
# 				| IF(2, 'true', 'false') 		 |
# 				+------------------------------+
# 				| true 								 |
# 				+------------------------------+
#
# 			However, the values TRUE and FALSE are merely aliases for 1 and 0,
# 			respectively, as shown here:
#
# 				SELECT IF(0 = FALSE, 'true', 'false');
# 				+------------------------------------+
# 				| IF(0 = FALSE, 'true', 'false') 	 |
# 				+------------------------------------+
# 				| true 										 |
# 				+------------------------------------+
#
# 				SELECT IF(1 = TRUE, 'true', 'false');
# 				+------------------------------------+
# 				| IF(1 = TRUE, 'true', 'false') 		 |
# 				+------------------------------------+
# 				| true 										 |
# 				+------------------------------------+
#
# 				SELECT IF(2 = TRUE, 'true', 'false');
# 				+------------------------------------+
# 				| IF(2 = TRUE, 'true', 'false') 		 |
# 				+------------------------------------+
# 				| false 										 |
# 				+------------------------------------+
#
# 				SELECT IF(2 = FALSE, 'true', 'false');
# 				+------------------------------------+
# 				| IF(2 = FALSE, 'true', 'false') 	 |
# 				+------------------------------------+
# 				| false 										 |
# 				+------------------------------------+
#
# 			The last two statements display the results shown because 2 is equal to neither 1 nor 0.
#
# 		) SMALLINT[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			A small integer. The signed range is -32768 to 32767
#
# 			The unsigned range is 0 to 65535
#
# 		) MEDIUMINT[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			A medium-sized integer.
#
# 			The signed range is -8388608 to 8388607
#
# 			The unsigned range is 0 to 16777215
#
# 		) INT[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			A normal-size integer.
#
# 			The signed range is -2147483648 to 2147483647.
#
# 			The unsigned range is 0 to 4294967295
#
# 		) INTEGER[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			This type is a synonym for INT.
#
# 		) BIGINT[ (M) ] [UNSIGNED] [ZEROFILL]
#
# 			A large integer. The signed range is -9.223.372.036.854.775.808 to same but - 1. Unsigned is 0 to x2
#
# 			SERIAL is an alias for BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE.
#
# 			Some things you should be aware of with respect to BIGINT columns:
#
# 				) All arithmetic is done using signed BIGINT or DOUBLE values, so you should not use
# 					unsigned big integers larger than unsigned positive cap (63 bits), except with bit functions.
#
# 					If you do that, some of the last digits in the result may be wrong because of rounding
# 					errors when converting a BIGINT value to a DOUBLE.
#
# 					MySQL can handle BIGINT in the following cases:
#
# 						) When using integers to store large unsigned values in a BIGINT column.
#
# 						) In MIN(col name) or MAX(col name), where col_name refers to a BIGINT column.
#
# 						) When using operators (+, -, * and so on) where both operands are integers.
#
# 				) You can always store an exact integer value in a BIGINT column by storing it using a string.
#
# 					IN this case, MySQL performs a string-to-number conversion that involves no
# 					intermediate double-precision representation.
#
# 				) The -, + and * operators use BIGINT arithmetic when both operands are integer values.
#
# 					This means that if you multiply two big integers (or results from functions that return integers),
# 					you may get unexpected results when the result is larger than the max of positive signed.
#
# 		) DECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]
#
# 			A packed "exact" fixed-point number.
#
# 			M is the total number of digits (the precision) and D is the number of digits after
# 			after the decimal point (the scale).
#
# 			The decimal point and (for negative numbers) the - sign are not counted in M.
#
# 			If D is 0, values have no decimal point or fractional part.
#
# 			THe maximum number of digits (M) for DECIMAL is 65.
#
# 			The maximum number of supported decimals (D) is 30.
#
# 			If D is omitted, the default is 0. If M is omitted, the default is 10.
#
# 			UNSIGNED, if specified, disallows negative values.
#
# 			All basic calculations (+, -, *, /) with DECIMAL columns are done with a precision of 65 digits.
#
# 		) DEC[(M[,D])] [UNSIGNED] [ZEROFILL], NUMERIC[(M[,D])] [UNSIGNED] [ZEROFILL], FIXED[(M[,D])] [UNSIGNED] [ZEROFILL]
#
# 			These types are synonyms for DECIMAL. The FIXED synonym is available for compatibility
# 			with other database systems.
#
# 		) FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]
#
# 			A small (single-precision) floating point number.
#
# 			Permissible values are -3.4E+38 to -1.1E-38,0 and 1.1~E-38 to 3.4~E38
#
# 			These are the theoretical limits, based on the IEEE standard.
# 			The actual range might be slightly smaller depending on your hardware or OS.
#
# 			M is the total number of digits and D is the number of digits following the decimal point.
# 			If M and D are omitted, values are stored to the limits permitted by the hardware.
#
# 			A single-precision floating-point number is accurate to approximately 7 decimal places.
#
# 			UNSIGNED, if specified, disallows negative values.
#
# 			Using FLOAT might give you some unexpected problems because all calculations
# 			in MySQL are done with double precision.
#
# 			See SECTION B.6.4.7, "SOLVING PROBLEMS WITH NO MATCHING ROWS"
#
# 		) DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]
#
# 			A normal-size (double-precision) floating-point number.
# 			Permissible values are -1.7~E+308 to -2.2~E-308, 0 and 2.2~E-308 to 1.7~E+308
#
# 			These are the theoretical limits, based on the IEEE standard.
#
# 			The actual range might be slightly smaller depending on your hardware or OS.
#
# 			M is the total number of digits and D is the number of digits following
# 			the decimal point.
#
# 			If M and D are omitted, values are stored to the limits permitted by the hardware.
#
# 			A double-precision floating-point number is accurate to approximately 15 decimal places.
#
# 			UNSIGNED, if specified, disallows negative values.
#
# 		) DOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL], REAL[(M,D)] [UNSIGNED] [ZEROFILL]
#
# 			These types are synonyms for DOUBLE:
#
# 			Exception: If the REAL_AS_FLOAT SQL mode is enabled, REAL is a synonym for FLOAT
# 			rather than DOUBLE.
#
# 		) FLOAT(p) 	[UNSIGNED] [ZEROFILL]
#
# 			A floating point number.
#
# 			p represents the precision in bits, but MySQL uses this value only to determine
# 			whether to use FLOAT or DOUBLE for the resulting data type.
#
# 			If p is from 0 to 24, the data type becomes FLOAT with no M or D values.
#
# 			IF p is from 25 to 53, the data type becomes DOUBLE with no M or D values.
#
# 			The range of resulting column is the same as for the single-precision FLOAT or
# 			double-precision DOUBLE data types described earlier in this section.
#
# 			FLOAT(p) syntax is provided for ODBC compatibility.
#
# 11.1..2 DATE AND TIME TYPE OVERVIEW
#
# A summary of the temporal data types follows.
#
# For additional information about properties and storage requirements
# of the temporal types, see SECTION 11.3, "DATE AND TIME TYPES" and
# SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS".
#
# FOr descriptions of functions that operate on temporal values,
# see SECTION 12.7, "DATE AND TIME FUNCTIONS"
#
# For the DATE and DATETIME range descriptions, "supported" means that although
# earlier values might work - that is ascertained.
#
# MySQL permits fractional seconds for TIME, DATETIME and TIMESTAMP values, with up to
# microseconds (6 digits) precision.
#
# To define a column that includes a fractional seconds part, use the syntax
# type_name(fsp), where type_name is TIME, DATETIME or TIMESTAMP and fsp is the fractional
# seconds precision.
#
# For example:
#
# 		CREATE TABLE t1 (t TIME(3), dt DATETIME(6));
#
# The fsp value, if given, must be in the range 0 to 6.
#
# A value of 0 signifies that htere is no fractional part.
# If omitted, the default precision is 0.
#
# (This differs from the standard SQL default of 6, for compatibility
# with previous versions)
#
# Any TIMESTAMP or DATETIME column in a table can have automatic initialization
# and updating properties.
#
# 		) DATE
#
# 			A date.
#
# 			The supported range is '1000-01-01' to '9999-12-31'. 
#
# 			MySQL displays DATE values in 'YYYY-MM-DD' format, but permits assignments
# 			of values to DATE columns using either strings or numbers. 	
#
# 		) DATETIME[(fsp)]
#
# 			A date and time combination.
#
# 			The supported range is '1000-01-01 00:00:00.000000' to '9999-12-31 23:59:59.999999'
#
# 			MySQL displays DATETIME Values in 'YYYY-MM-DD HH:MM:SS[.fraction]' format, but permits
# 			assignment of values to DATETIME columnns using either strings or numbers.
#
# 			An optional fsp value in the range from 0 to 6 may be given to specify fractional
# 			seconds precision.
#
# 			A value of 0 signifies that there is no fractional part.
#
# 			iF omitted, the default precision is 0.
#
# 			Automatic intiialization and updating ot the current date and time for DATETIME
# 			columns can be specified using DEFAULT and ON UPDATE column definition clauses,
# 			as described in SECTION 11.3.5,"AUTOMATIC INITIALIZATION AND UPDATING FOR TIMESTAMP AND DATETIME"
#
# 		) TIMESTAMP[(fsp)]
#
# 			A timestamp.
#
# 			The range is '1970-01-01 00:00:01.000000' UTC to '2038-01-19 03:14:07.999999' UTC.
#
# 			TIMESTAMP values are stored as the number of seconds since the epoch
# 			('1970-01-01 00:00:00' UTC).
#
# 			A TIMESTAMP cannot represent the value '1970-01-01 00:00:00' because that is
# 			equivalent to 0 seconds from the epoch and the value 0 is reserved
# 			for representing '0000-00-00 00:00:00', the "zero" TIMESTAMP value.
#
# 			An optional FSP value in the range from 0 to 6 may be given to specify
# 			fractional second precision.
#
# 			A value of 0 signifies taht there is no fractional part.
# 			If omitted, the default precision is 0.
#
# 			The way the server handles TIMESTAMP definitions depends on the
# 			value of the explicit_defaults_for_timestamp system variable.
#
# 			IF explicit_defaults_for_timestamp is enabled, there is no automatic
# 			assignment of the DEFAULT CURRENT_TIMESTAMP or ON UPDATE CURRENT_TIMESTAMP
# 			attributes to any TIMESTAMP column.
#
# 			They must be included explicitly in the column definition.
#
# 			Also, any TIMESTAMP not explicit declared as NOT NULL permits NULL
# 			values.
#
# 			If explicit_defaults_for_timestamp id disabled, the server handles TIMESTAMP
# 			as follows:
#
# 				Unless specified otherwise, the first TIMESTAMP column in a table is defined to be
# 				automatically set to the date and time of the most recent modification if not
# 				explicitly assigned a value.
#
# 				This makes TIMESTAMP useful for recording the timestamp of an INSERT or UPDATE
# 				operation.
#
# 				YOu can also set any TIMESTAMP column to the current date and time by assigning it
# 				a NULL value, unless it has been defined with the NULL attribute to permit NULL values.
#
# 				Automatic intiialization and updating to the current date and time can be specified
# 				using DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP column definition clauses.
#
# 				By default, the first TIMESTAMP column has these properties, as previously noted.
#
# 				However, any TIMESTAMP column in a table can be defined to have these properties.
#
# 		) TIME[(fsp)]
#
# 			A time. The range is '-838:59:59.000000' to '838:59:59.000000'.
#
# 			MySQL displays TIME values in 'HH:MM:SS[.fraction]' format, but permits
# 			assignment of values to TIME columns using either strings or numbers.
#
# 			An optional fsp value in the range from 0 to 6 may be given to specify fractional seconds precision.
#
# 			A value of 0 signifies that there is no fractional part.
# 			If omitted, the default precision is 0.
#
# 		) YEAR[(4)]
#
# 			A year in a four-digit format.
#
# 			MySQL displays YEAR values in YYYY format, but permits assignment
# 			of values to YEAR columns using either strings or numbers.
#
# 			Values display as 1901 to 2155 and 0000
#
# 			For additional information about YEAR display format and interpretation of input values,
# 			see SECTION 11.3.3 "THE YEAR TYPE"
#
# 			NOTE:
#
# 				MySQL 8.0 does NOT support the YEAR(2) data tpye permitted in older versions of MysQL.
# 				For instructions on converting, see SECTION 11.3.4, "Migrating YEAR(2) Columns to YEAR(4)"
#
# The SUM() and AVG() aggregate functiosn do not work with temporal values.
#
# (They convert the values ot numbers, losing everything after the first nonnumeric character)
#
# To work around this problem, convert to numeric units, perform the aggregate operation,
# and convert back to a temporal value. Examples:
#
# SELECT SEC_TO_TIME(SUM(TIME_TO_SEC(time_col))) FROM tbl_name;
# SELECT FROM_DAYS(SUM(TO_DAYS(date_col))) FROM tbl_name;
#
# 11.1.3 STRING TYPE OVERVIEW
#
# A summary of the string data types follows.
#
# For additional information about properties and storage requirements of the string types,
# see SECTION 11.4, "STRING TYPES" and SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# in some cases, MySQL may change a string column to a type different from that given in
# a CREATE_TABLE or ALTER_TABLE statement.
#
# See SECTION 13.1.20.7 "SILENT COLUMN SPECIFICATION CHANGES"
#
# MySQL interprets length specification in character column definitions in character units.
# This applies to CHAR, VARCHAR and the TEXT types.
#
# Column definitions for many string data types can include attributes that specify the
# character set or collation of the column.
#
# These attributes apply to the  CHAR, VARCHAR, the TEXT types, ENUM and SET data types:
#
# 		) The CHARACTER SET attribute specifies the character set, and the COLLATE attribute specifies
# 			a collation for the character set.
#
# 			For example:
#
# 				CREATE TABLE t
# 				(
# 					c1 VARCHAR(20) CHARACTER SET utf8,
# 					c2 TEXT CHARACTER SET latin1 COLLATE latin1_general_cs
# 				);
#
# 			This table definition creates a column named c1 that has a character set of utf8
# 			with the default collation for that character set, and a column named c2 that has
# 			a character set of latin1 and a case-sensitive collation.
#
# 			The rules for assigning the character set and collation when either or both of the
# 			CHARACTER SET and COLLATE attributes are missing are described in SECTION 10.3.5,
# 			"COLUMN CHARACTER SET AND COLLATION"
#
# 			CHARSET is a synonym for CHARACTER SET.
#
# 		) Specifying the CHARACTER SET binary attribute for a character string data type causes
# 			the column to be created as the corresponding binary string data type:
#
# 				CHAR becomes BINARY
#
# 				VARCHAR becomes VARBINARY
#
# 				TEXT becomes BLOB
#
# 			For the ENUM and SET data types, this does not occur.
# 			They are created as declared.
#
# 			Suppose that you specify a table using this definition:
#
# 				CREATE TABLE t
# 				(
# 					c1 VARCHAR(10) CHARACTER SET binary,
# 					c2 TEXT CHARACTER SET binary,
# 					c3 ENUM('a', 'b', 'c') CHARACTER SET binary
# 				);
#
# 			The resulting table has this defintiion:
#
# 				CREATE TABLE t
# 				(
# 					c1 VARBINARY(10),
# 					c2 BLOB,
# 					c3 ENUM('a', 'b', 'c') CHARACTER SET binary
# 				);
#
# 		) The BINARY attribute is shorthand for specifying the table default char set and the binary (_bin) collation
# 			of that character set.
#
# 			IN this case, comparison and sorting are based on numeric character code values.
#
# 		) The ASCII attribute is shorthand for CHARACTER SET latin1
#
# 		) The UNICODE attribute is shorthand for CHARACTER SET ucs2
#
# Character column comparison and sortings are based on the collation assigned to the column.
#
# FOr the CHAR, VARCHAR, TEXT, ENUM and SET data types, you can declare a column with a binary
# (_bin) collation or the BINARY attribute to cause comparison and sorting to use the underlying
# character code values rather than a lexical ordering.
#
# For addition information about use of character sets in MySQL, see CHAPTER 10, CHARACTER SETS, COLLATIONS, UNICODE.
#
# 		) [NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]
#
# 			A fixed-length string that is always right-padded with spaces to the specified length when stored.
#
# 			M represents the column length in characters.
# 			The range of M is 0 to 255.
#
# 			If M is omitted, the length is 1.
#
# 			NOTE:
#
# 				Trailing spaces are removed when CHAR values are retrieved unless the PAD_CHAR_TO_FULL_LENGTH
# 				SQL mode is enabled.
#
# 			CHAR is shorthand for CHARACTER, NATIONAL_CHAR (or its equivalent short form, NCHAR) is the
# 			standard SQL way to define that a CHAR column should use some predefined char set.
#
# 			MySQL uses utf8 as this predefined character set.
#
# 			See SECTION 10.3.7, "THE NATIONAL CHARACTER SET"
#
# 			The CHAR_BYTE data type is an alias for the BINARY data type.
# 			THis is a compatbility feature.
#
# 			MySQL permitws you to create a column of type CHAR(0).
#
# 			THis is useful primarily when you have to be compliant with old applications that depend
# 			on the existence of a column but that do not actually use its value. 
#
# 			CHAR(0) is also quite nice when you need a column that can take only two values:
#
# 				a column taht is defined as CHAR(0) NULL occupies only one bit and can take only NULL or ''
#
# 		) [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name]
#
# 			A variable-length string.
#
# 			M represents the maximum column length in characters.
# 			The range of M is 0 to 65,535.
#
# 			The effective maximum length of a VARCHAR is subject to the maximum row size (65,535 bytes,
# 			which is shared among all columns) and the character set used.
#
# 			For example, utf8 characters can require up to three bytes per character, so
# 			a VARCHAR column that uses the utf8 character set can be declared to be a maximum of
# 			21,844 characters.
#
# 			See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# 			MySQL stores VARCHAR values as a 1-byte or 2-byte length prefix plus data.
#
# 			The length prefix indicates the number of bytes in the value.
#
# 			A VARCHAR column uses one length byte if values requires no more than 255 bytes,
# 			two length bytes if values may require more than 255 bytes.
#
#			NOTE:
#
# 				MySQL follows the standard SQL specification, and does not remove trailing spaces from VARCHAR values.
#
# 			VARCHAR is shorthand for CHARACTER_VARYING. NATIONAL_VARCHAR is the standard SQL way to define that
# 			a VARCHAR column should use some predefined character set.
#
# 			MySQL uses utf8 as this predefined character set. SECTION 10.3.7, "THE NATIONAL CHARACTER SET"
#
# 			NVARCHAR is shorthand for NATIONAL_VARCHAR
#
# 		) BINARY[(M)]
#
# 			The BINARY type is similar to the CHAR type, but stores binary byte strings rather than nonbinary
# 			character strings.
#
# 			An optional length M represents the column length in bytes.
#
# 			If omitted, M defaults to 1.
#
# 		) VARBINARY(M)
#
# 			The VARBINARY tpye is similar to the VARCHAR type, but stores binary byte strings
# 			rather than nonbinary character strings.
#
# 			M represents the max column length in bytes.
#
# 		) TINYBLOB
#
# 			A BLOB column with a max length of 255 (2^8 - 1) bytes. Each TINYBLOB value is stored using 1-byte length
# 			prefix that indicates the number of bytes in the value.
#
# 		) TINYTEXT [CHARACTER SET charset_name] [COLLATE collation name]
#
# 			A TEXT Column with a max length of 255 (2^8 - 1) chars. 
#
# 			The effective length is less if the values contains multibyte characters.
#
# 			Each TINYTEXT value is stored using a 1-byte length prefix that indicates
# 			the number of bytes in the value.
#
# 		) BLOB[(M)]
#
# 			A BLOB column with a max length of 65,535 (2^16 - 1) bytes.
#
# 			Each BLOB value is stored using 2-byte length prefix that indicates the number
# 			of bytes in the value.
#
# 			An optional length M can be given for this type.
#
# 			IF this is done, MySQL creates the column as the smallest BLOB tpye large enough to hold values of
# 			M bytes long.
#
# 		) TEXT[(M)] [CHARACTER SET charset name] [COLLATE collation name]
#
# 			A TEXT column with a maximum of length 65,535 (2^16-1) chars.
#
# 			The effective max length is less if the value contains multibyte chars.
#
# 			Each TEXT value is stored using a 2-byte length prefix that indicates the
# 			number of bytes in the value.
#
# 			An optional length M can be given for this type.
#
# 			If this is done, MySQL creates the column as the smallest TEXT type large enough
# 			to hold values M chars long.
#
# 		) MEDIUMBLOB
#
# 			A BLOB column with a maximum length of 16,777,215 (2^24-1) bytes.
#
# 			Each MEDIUMBLOB value is stored using a 3-bytes length prefix that indicates
# 			the number of bytes in the value.
#
# 		) MEDIUMTEXT [CHARACTER SET charset name] [COLLATE collation name]
#
# 			A TEXT column with a max length of 16,777,215 (2^24-1) chars.
#
# 			The effective max length is less if the value contains multibyte characters.
#
# 			Each MEDIUMTEXT value is stored using 3-byte length prefix that indicates
# 			the number of bytes in the value.
#
# 		) LONGBLOB
#
# 			A BLOB colum with a maximum length of 4,294,967,295 or 4GB (2^32 - 1) bytes.
#
# 			The effective maximum length of LONGBLOB columns depends on the configured maximum
# 			packet size in the client/server protocol and available memory.
#
# 			Each LONGBLOB value is stored using a 4-byte length prefix that indicates
# 			the number of bytes in the value.
#
# 		) LONGTEXT [CHARACTER SET charset name] [COLLATE collation name]
#
# 			A TEXT column with a maximum length of 4,294,967,295 or 4GB (2^32 - 1) characters.
#
# 			The effective maximum length is less if the value contains multibyte characters.
#
# 			The effective maximum length of LONGTEXT columns also depends on the configured
# 			maximum packet size in the client/server protocol and available memory.
#
# 			Each LONGTEXT value is stored using a 4-byte length prefix that indicates the number
# 			of bytes in the value.
#
# 		) ENUM ('value1', 'value2', ---) [CHARACTER SET charset name] [COLLATE collation name]
#
# 			An enumeration. A string object that can have only one value, chosen from the list
# 			of values 'value1', 'value2', ---, NULL or the special '' error value.
#
# 			ENUM values are represented internally as integers.
#
# 			An ENUM column can have a maximum of 65,535 distinct elements.
#
# 			The maximum supported length of an individual ENUM element is M <= 255 and
# 			(M x w) <= 1020, where M is the element literal length and w is the number of bytes
# 			required for the maximum-length character in the character set.
#
# 		) SET('value1', 'value2', ---) [CHARACTER SET charset name] [COLLATE collation name]
#
# 			A set. A string object that can have zero or more values, each of which must be
# 			chosen from the list of values 'value1', 'value2', --- SET values are represented
# 			internally as integers.
#
# 			A SET column can have a maximum of 64 distinct members.
#
# 			The maximum supported length of an individual SET element is M <= 255 and
# 			(M x w) <= 1020, where M is the elemental literal length and w is the number
# 			of bytes required for the maximum-length character in the character set.
#
# 11.2 NUMERIC TYPES
#
# MySQL supports all standard SQL numeric data types. These types include the exact numeric
# data types (INTEGER, SMALLINT, DECIMAL and NUMERIC), as well as the approximate numeric
# data types (FLOAT, REAL, and DOUBLE PRECISION)
#
# The keyword INT is a synonym for INTEGER, and the keyword DEC and FIXED are synonynms
# for DECIMAL
#
# MySQL treats DOUBLE as a synonym for DOUBLE PRECISION (a nonstandard extension).
#
# MySQL also treats REAL as a synonym for DOUBLE PRECISION (a nonstandard variation),
# unless the REAL_AS_FLOAT SQL mode is enabled.
#
# The BIT data type stores bit values and is supported for MyISAM, MEMORY, InnoDB and NDB tables.
#
# For information about how MySQL handles assignment of out-of-range values to columns and overflow
# during expression evaluation, see SECTION 11.2.6, "OUT-OF-RANGE AND OVERFLOW HANDLING"
#
# For information about numeric type storage requirements, see SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# The data type used for the result of a calculation on numeric operands depends on the
# types of the operands and the operations performed on them.
#
# For more information, see SECTION 12.6.1, "ARITHMETIC OPERATORS"
#
# 11.2.1 INTEGER TYPES (EXACT VALUE) - INTEGER, INT, SMALLINT, TINYINT, MEDIUMINT, BIGINT
#
# MySQL supports the SQL standard integer types INTEGER (or INT) and SMALLINT.
#
# As an extension to the standard, MySQL also supports the integer types TINYINT,
# MEDIUMINT, and BIGINT.
#
# The following table shows the required storage and range for each integer type.
#
# TABLE 11.1 REQUIRED STORAGE AND RANGE FOR INTEGER TYPES SUPPORTED BY MYSQL
#
# 		Type 						Storage (Bytes) 					Minimum Value SIgned 				Minimum value Unsigned 		Maximum Value Signed 		Maximum Value Unsigned
#
# 	TINYINT 						1 										-128 										0 									127 								255
#
# 	SMALLINT 					2 										-32768 									0 									32767 							65535
#
# 	MEDIUMINT 					3 										-8388608 								0 									8388607 							16777215
#
#  INT 							4 										-2147483648 							0 									2147483647 						429467295
#
# 	BIGINT 						8 										-2^63 									0 									2^63-1 							2^64-1
#
# 11.2.2 FIXED-POINT TYPES (EXACT VALUE) - DECIMAL, NUMERIC
#
# The DECIMAL and NUMERIC types store exact numeric data values. These types are used when it is important
# to preserve exact precision, for exaxmple in monetary data.
#
# In MySQL, NUMERIC is implemented as DECIMAL, so the following remarks about DECIMAL apply equally to NUMERIC.
#
# MySQL stores DECIMAL values in binary format. See SECTION 12.24, "PRECISION MATH"
#
# In a DECIMAL column declaration, the precision and scale can be (and usually is) specified,
# for example:
#
# 		salary DECIMAL(5,2)
#
# In this example, 5 is the precision and 2 is the scale.
#
# The precision represents the number of significant digits that are stored for values, and the scale represents
# the number of digits that can be stored following the decimal point.
#
# Standard SQL requires that DECIMAL(5,2) be able to store any value with five digits and two decimals,
# so values that can be stored in the salary column range from -999.99 to 999.99
#
# In standard SQL, the syntax DECIMAL(M) is equivalent to DECIMAL(M,0)
#
# Similarly, the syntax DECIMAL is equivalent to DECIMAL(M,0), where the implementation is permitted
# to decide the value of M.
#
# MySQL supports both of these variant forms of DECIMAL syntax. The default value of M is 10.
#
# If the scale is 0, DECIMAL values contain no decimal point or fractional part.
#
# The maximum number of digits for DECIMAL is 65, but the actual range for a given DECIMAL column
# can be constrained by the precision or scale for a given column.
#
# When such a column is assigned a value with more digits following the decimal point than are
# permitted by the specified scale, the value is converted to that scale.
#
# (The precise behavior is operating system-specific, but generally the effect is truncation
# to the permissible number of digits)
#
# 11.2.3 FLOATING-POINT TYPES (APPROXIMATE VALUE) - FLOAT, DOUBLE
#
# The FLOAT and DOUBLE types represent approximate numeric data values.
#
# MySQL uses four bytes for single-precision values and eight bytes for double-precision
# values.
#
# For FLOAT, the SQL standard permits an optional specification of the precision
# (but not the range of the exponent) in bits following the keyword FLOAT in parantheses.
#
# MySQL also supports this optional precision specification, but the precision value is used
# only to determine storage size.
#
# A precision from 0 to 23 results in a 4-byte single-precision FLOAT column.
# A precision from 24 to 53 results in a 8-byte double-precision DOUBLE column.
#
# MYSQL permits a nonstandard syntax: FLOAT(M,D) or REAL(M,D) or DOUBLE PRECISION(M,D).
#
# Here, (M,D) means that values can be stored with up to M digits in total,
# of which D digits may be after the decimal point.
#
# For example, a column defined as FLOAT(7,4) will look like -999.9999 when displayed.
#
# MySQL performs rounding when storing values, so if you insert 999.00009 into a FLOAT(7,4) column,
# the approximate result is 999.0001
#
# Because floating-point values are approximate and not stored as exact values, attempts to treat them
# as exact in comparisons may lead to problems.
#
# They are also subject to platform or implementation dependencies. For more information,
# see SECTION B.6.4.8, "PROBLEMS WITH FLOATING-POINT VALUES"
#
# For maximum portability, code requiring storage of approximate numeric data values should
# use FLOAT or DOUBLE precision with no specification of precision or number of digits.
#
# 11.2.4 BIT-VALUE TYPE - BIT
#
# The BIT data type is used to store bit values. A type of BIT(M) enables storage
# of M-bit values. M can range from 1 to 64.
#
# To specify bit values, b 'value' notation can be used.
# value is a binary value written using zeros and ones.
#
# For example, b'111' and b'10000000' represent 7 and 128, respectively.
#
# See SECTION 9.1.5, "BIT-VALUE LITERALS"
#
# If you assign a value to a BIT(M) column that is less than M bits long,
# the value is padded on the left with zeros.
#
# For example, assigning a value of b'101' to a BIT(6) column is, in effect,
# the same as assigning b'000101'
#
# NDB cluster. The maximum combined size of all BIT columns used in a given NDB
# table must not exceed 4096 bits.
#
# 11.2.5 NUMERIC TYPE ATTRIBUTES
#
# MySQL supports an extension for optionally specifying the display width of integer data
# types in parantheses following the base keyword for the type.
#
# For example, INT(4) specifies an INT with a display width of four digits.
#
# This optional display width may be used by applications to display integer values
# having a width less than the width specified for the column by left-padding them with
# spaces. 
#
# (That is, this width is present in the metadata returned with result sets.
#  Whether it used or not is up to the application)
#
# The display width does NOT constrain the range of values that can be stored in
# the column.
#
# Nor does it prevent values wider than the column display width from being displayed
# correctly.
#
# For example, a column specified as SMALLINT(3) has the usual SMALLINT range of
# -32768 to 32767, and values outside the range permitted by three digits are displayed
# in full using more than three digits.
#
# When used in conjunction with the optional (nonstandard) attribute ZEROFILL, the default
# padding of spaces is replaced with zeros.
#
# For example, for a column declared as INT(4)_ZEROFILL, a value of 5 is retrieved as 0005.
#
# NOTE:
#
# 		THe ZEROFILL attribute is ignored when a columnm is involved in expressions or UNION queries.
#
# 		If you store values larger than the display width in an integer column that has the ZEROFILL
# 		attribute, you may experience problems when MySQL generates temporary tables for some complicated
# 		joins.
#
# 		In these cases, MySQL assumes that the data values fit within the column display width.
#
# All integer types can have an optional (nonstandard) attribute UNSIGNED.
#
# Unsigned type can be used to permit only nonnegative numbers in a column or when you 
# need a large upper numeric range for the column.
#
# For example, if an INT column is UNSIGNED, the size of the column's range is the same
# but its endpoints shift from -2147483648 to the opposite of that in positive,
# to 0 to 2*the low point
#
# Floating-point and fixed-point types also can be UNSIGNED. As with integer types,
# this attribute prevents negative values from being stored in the column.
#
# Unlike the integer types, the upper range of column values remains the same.
#
# If you specify ZEROFILL for a numeric column, MySQL automatically adds the UNSIGNED
# attribute to the column.
#
# Integer or floating-point data types can have the additional attribute AUTO_INCREMENT.
#
# When you insert a value of NULL into an indexed AUTO_INCREMENT column, the column is set
# to the next sequence value.
#
# Typically this is value+1, where value is the largest value for the column currently
# in the table. (AUTO_INCREMENT sequences begin with 1)
#
# Storing 0 into an AUTO_INCREMENT column has the same effect as storing NULL, unless the
# NO_AUTO_VALUE_ON_ZERO SQL mode is enabled.
#
# Inserting NULL to generate AUTO_INCREMENT values requires that the column be declared 
# NOT NULL.
#
# If the column is declared NULL, inserting NULL stores a NULL.
#
# When you insert any other value into an AUTO_INCREMENT column, the column is set to that
# value and the sequence is reset so that the next automatically generated value follows
# sequentially from the inserted value.
#
# In MySQL 8.0, negative values for AUTO_INCREMENT columns are not supported.
#
# 11.2.6 OUT-OF-RANGE AND OVERFLOW HANDLING
#
# When MySQL stores a value in a numeric column that is outside the permissible range of the
# column data type, the result depends on the SQL mode in effect at the time:
#
# 		) If strict SQL mode is enabled, MySQL rejects the out-of-range values with an error and the insert fails,
# 			in accordance with the SQL standard.
#
# 		) If no restrictive modes are enabled, MySQL clips the value to the appropriate endpoint of the column data
# 			type range and stores the resulting value instead.
#
# 			When an out-of-range value is assigned to an integer column, MySQL stores the value representing the corresponding
# 			endpoint of the column data type range.
#
# 			When a floating-point or fixed-point column is assigned a value that exceeds the range implied by the
# 			specified (or default) precision and scale, MySQL stores the value representing the corresponding
# 			endpoint of that range.
#
# Suppose that a table t1 has this definition:
#
# 		CREATE TABLE t1 (i1 TINYINT, i2 TINYINT UNSIGNED);
#
# With strict SQL mode enabled, an out of range error occurs:
#
# 		SET sql_mode = 'TRADITIONAL';
# 		INSERT INTO t1 (i1, i2) VALUES(256, 256);
# 		ERROR 1264 (22003): Out of range value for column 'i1' at row 1
# 		SELECT * FROM t1;
# 		Empty set (0.00 sec)
#
# With strict SQL mode not eabled, clipping with warnings occurs:
#
# 		SET sql_mode = '';
# 		INSERT INTO t1 (i1, i2) VALUES(256,256);
# 		SHOW WARNINGS;
# 		+---------------+-----------+------------------------------------------------------------+
# 		| Level 			 | Code 		 | Message 																	  |
# 		+---------------+-----------+------------------------------------------------------------+
# 		| Warning 		 | 1264 		 | Out of range value for column 'i1' at row 1 					  |
# 		| Warning 		 | 1264 		 | Out of range value for column 'i2' at row 1 					  |
# 		+---------------+-----------+------------------------------------------------------------+
# 		SELECT * FROM t1;
# 		+-----------+-------------+
# 		| i1 			| i2 			  |
# 		+-----------+-------------+
# 		| 127 		| 255 		  |
# 		+-----------+-------------+
#
# When strict SQL mode is not enabled, column-assignment conversions that occur due to clipping
# are reported as warnings for ALTER_TABLE, LOAD_DATA_INFILE, UPDATE, and multiple-row INSERT
# statements.
#
# In strict mode, these statements fail, and some or all the values are not inserted or changed,
# depending on whether the table is a transactional table and other factors.
#
# For details, see SECTION 5.1.11, "SERVER SQL MODES"
#
# Overflow during numeric expression evaluation results in an error.
# For example, the largest signed BIGINT value is <a lot>, thus, the following gives an error:
#
# 		SELECT <a lot> + 1;
# 		ERROR 1690 (22003): BIGINT value is out of range in '(<a lot> + 1)'
#
# To enable the operation to succeed in this case, conver the value to unsigned:
#
# 		SELECT CAST(<a lot> AS UNSIGNED) + 1;
# 		+------------------------------------+
# 		| CAST(<a lot> AS UNSIGNED) + 1 		 |
# 		+------------------------------------+
# 		| 						<a lot> + 1 		 |
# 		+------------------------------------+
#
# Whether overflow occurs depends on the range of the operands, so another way to handle
# the preceding expression is to use exact-value arithmetic because DECIMAL values 
# have a larger range than integers:
#
# 		SELECT <a lot>.0 + 1;
# 		+------------------------------------+
# 		| <a lot>.0 + 1 							 |
# 		+------------------------------------+
# 		| 					<a lot>.0 + 1 			 |
# 		+------------------------------------+
#
# Subtraction between integer values, where one is of type UNSIGNED, produces an unsigned
# result by default.
#
# If the result would otherwise have been negative, an error results:
#
# 		SET sql_mode = '';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT CAST(0 AS UNSIGNED) - 1;
# 		ERROR 1690 (22003): BIGINT UNSIGNED value is out of range in '(cast(0 as unsigned) - 1)'
#
# If the NO_UNSIGNED_SUBTRACTION SQL mode is enabled, the result is negative:
#
# 		SET sql_mode = 'NO_UNSIGNED_SUBTRACTION';
# 		SELECT CAST(0 AS UNSIGNED) - 1;
# 		+---------------------------------------+
# 		| 	CAST(0 AS UNSIGNED) - 1 				 |
# 		+---------------------------------------+
# 		| 							-1 					 |
# 		+---------------------------------------+
#
# If the result of such an operation is used to update an UNSIGNED integer column,
# the result is clipped to the maximum value for the column type, or clipped to 0 if
# NO_UNSIGNED_SUBTRACTION is enabled.
#
# If strict SQL mode is enabled, an error occurs and the column remains unchanged.
#
# 11.3 DATE AND TIME TYPES
#
# The date and time types for representing temporal values are DATE, TIME, DATETIME,
# TIMESTAMP, and YEAR.
#
# Each temporal type has a range of valid  values, as well as a "zero" value that may be
# used when you specify an invalid value that MySQL cannot represent.
#
# The TIMESTAMP type has special automatic updating behavior, described later.
#
# For temporal type storage requirements, see SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# Keep in mind these general considerations when working with date and time types:
#
# 		) MySQL retrieves values for a given date or time type in a standard output format,
# 			but it attempts to interpret a variety of formats for input values that you supply
# 			(for example, when you specify a value to be assigned to or compared to a date or time type).
#  
# 			For a description of the permitted formats for date and time types, see SECTION 9.1.3, "DATE AND TIME LITERALS".
#
# 			It is expected that you supply valid values. Unpredictable results may occur if oyu use values 
# 			in other formats.
#
# 		) Although MySQL tries to interpret values in several formats, date parts must always be given in year-month-day order
# 			(for example, '98-09-04'), rather than in the month-day-year or day-month-year orders commonly used elsewhere
# 			(for example, '09-04-98', '04-09-98')
#
# 		) Dates containing two-digit year values are ambiguous because the century is unknown.
#
# 			MySQL interprets two-digit year values using these rules:
#
# 				) Year values in the range 70-99 are converted to 1970-1999
#
# 				) Year values in the range 00-69 are converted to 2000-2069
#
# 			See also SECTION 11.3.8, "TWO-DIGIT YEARS IN DATES"
#
# 		) Conversion of values from one temporal type to another occurs according to the rules
# 			in SECTION 11.3.7, "CONVERSION BETWEEN DATE AND TIME TYPES"
#
# 		) MySQL automatically converts a date or time value to a number if the value is used in a numeric context and vice versa.
#
# 		) By default, when MySQL encounters a value for a date or time type that is out of range or otherwise
# 			invalid for the type, it converts the value to the "zero" value for that type.
#
# 			The exception is that out-of-range TIME values are clipped to the appropriate endpoint of the TIME range.
#
# 		) By setting the SQL mode to the appropriate value, you can specify more exactly what kind of dates you want
# 			MySQL to support.
#
# 			(See SECTION 5.1.11, "SERVER SQL MODES")
#
# 			You can get MySQL to accept certain dates, such as '2009-11-13', by enabling the ALLOW_INVALID_DATES SQL mode.
#
# 			This is useful when you want to store a "possibly wrong" value which the user has specified (for example, in a web
# 			form) in the DB for future processing.
#
# 			Under this mode, MySQL verifies only that the month is in the range from 1 to 12 and that the day is in the range
# 			from 1 to 31.
#
# 		) MySQL permits you to store dates where the day or month and day are zero in a DATE or DATETIME column.
#
# 			This is useful for applications that need to store birthdates for which you may not know the exact date.
#
# 			In this case, you simply store the date as '2009-00-00' or '2009-01-00'.
#
# 			If you store the dates such as these, you should not expect to get correct results
# 			for functions such as DATE_SUB() or DATE_ADD() that require complete dates.
#
# 			To disallow zero month or day parts in dates, enable the NO_ZERO_IN_DATE mode.
#
# 		) MySQL permits you to store a "zero" value of '0000-00-00' as a "dummy date".
#
# 			This is in some cases more convenient than using NULL values, and uses less data and
# 			index space.
#
# 			To disallow '0000-00-00', enable the NO_ZERO_DATE mode.
#
# 		) "Zero" date or time values used through Connector/ODBC are converted automatically to NULL
# 			because ODBC cannot handle such values.
#
# The following table shows the format of the "zero" value for each type.
#
# The "zero" values are special, but you can store or refer to them explicitly using
# the values shown in the table.
#
# You can also do this using the values '0' or 0, which are easier to write.
#
# For temporal types that include a date part (DATE, DATETIME and TIMESTAMP), use of
# these values produces warnings if the NO_ZERO_DATE SQL mode is enabled.
#
# 		DATA TYPE 					"Zero" Value
#
# 	DATE 							'0000-00-00'
#
#  TIME 							'00:00:00'
#
# 	DATETIME 					'0000-00-00 00:00:00'
#
# 	TIMESTAMP 					'0000-00-00 00:00:00'
#
#	YEAR 							0000
#
# 11.3.1 THE DATE, DATETIME and TIMESTAMP TYPES
#
# The DATE, DATETIME, and TIMESTAMP types are related.
# This section describes their characteristics, how they are similar, and how they differ.
#
# MySQL recognizes DATE, DATETIME, and TIMESTAMP values in several formats, described in SECTION 9.1.3,
# "DATE AND TIME LITERALS"
#
# For the DATE and DATETIME range descriptions, "supported" means that although earlier values might
# work, there is no guarantee.
#
# The DATE type is used for values with a date part but no time part.
# MySQL retrieves and displays DATE values in 'YYYY-MM-DD' format.
#
# The supported range is '1000-01-01' to '9999-12-13'
#
# The DATETIME type is used for values that contain both date and time parts.
# MySQL retrieves and displays DATETIME values in 'YYYY-MM-DD HH:MM:SS' format.
#
# The supported range is '1000-01-01 00:00:00' to '9999-12-31 23:59:59'
#
# The TIMESTAMP data type is used for values that contain both date and time parts.
# TIMESTAMP has a range of '1970-01-01 00:00:01' UTC to '2038-01-19 03:14:07' UTC.
#
# A DATETIME or TIMESTAMP value can include a trailing fractional seconds part in up to microseconds
# (6 digits) precision.
#
# In particular, any fractional part in a value inserted into a DATETIME or TIMESTAMP column is stored
# rather than discarded.
#
# With the fractional part included, the format for these values is 'YYYY-MM-DD HH:MM:SS[.fraction]',
# the range for DATETIME values is '1000-01-01 00:00:00.000000' to '9999-12-31 23:59:59.999999', and the
# range for TIMESTAMP values is '1970-01-01 00:00:01.000000' to '2038-01-19 03:14:07.999999'
#
# The fractional part should always be separated from the rest of the time by a decimal point;
# no other fractional seconds delimiter is recognized.
#
# For information about fractional seconds support in MySQL, see SECTION 11.3.6, "FRACTIONAL SECONDS IN TIME VALUES"
#
# The TIMESTAMP and DATETIME data types offer automatic initialization and updating to the current
# date and time.
#
# For more information, see SECTION 11.3.5, "AUTOMATIC INITIALZIATION AND UPDATING FOR TIMESTMAP AND DATETIME"
#
# MySQL converts TIMESTAMP values from the current time zone to UTC for storage, and back from UTC to the
# current time zone for retrieval.
#
# (This does not occur for other types such as DATETIME)
#
# By default, the current time zone for each connection is the server's time.
# The time zone can be set on a per-connection basis.
#
# As long as the time zone setting remains constant, you get back the same value you store.
# If you store a TIMESTAMP value, and then change the time zone and retrieve the value, the retrieved
# value is different from the value you stored.
#
# This occurs because the same time zone was not used for conversion in both directions.
# The current time zone is available as the value of the time_zone system variable.
#
# For more information, see SECTION 5.1.13, "MYSQL SERVER TIME ZONE SUPPORT"
#
# Invalid DATE, DATETIME or TIMESTAMP values are converted to the "zero" value of the
# appropriate type ('0000-00-00' or '0000-00-00 00:00:00')
#
# Be aware of certain properties of date value interpretation in MySQL:
#
# 		) MySQL permits a "relaxed" format for values specified as strings, in which any punctuation
# 			character may be used as the delimiter between date parts or time parts.
#
# 			In some cases, this syntax can be decieving.
#
# 			For example, a value such as '10:11:12' might look like a time value because of the :,
# 			but it is interpreted as the year '2010-11-12' if used in a date context.
#
# 			The value '10:45:15' is converted to '0000-00-00' because '45' is not a valid month.
#
# 			The only delimiter recognized between a date and time part and a fractional second part
# 			is the decimal point.
#
# 		) The server requires that month and day values be valid, and not merely in the range 1 to 12, and 1 to 31,
# 			respectively.
#
# 			With strict mode disabled, invalid dates such as '2004-04-31' are converted to '0000-00-00' and
# 			a warning is generated.
#
# 			With strict mode enabled, invalid dates generate an error.
# 			To permit such dates, enable ALLOW_INVALID_DATES. See SECTION 5.1.11, "SERVER SQL MODES", for more info.
#
# 		) MySQL does not accept TIMESTAMP values that include a zero in the day or month column or values that
# 			are not a valid date.
#
# 			The sole exception to this rule is the special "zero" value '0000-00-00 00:00:00'
#
# 		) Dates containing two-digit year values are ambiguous because the century is unknown.
#
# 			MySQL interprets two-digit year values using these rules:
#
# 				) Year values in the range 00-69 are converted to 2000-2069
#
# 				) year values in the range 70-99 are converted to 1970-1999
#
# 			See also SECTION 11.3.8, "TWO-DIGIT YEARS IN DATES"
#
# 11.3.2 THE TIME TYPE
#
# 	MySQL retrieves and displays TIME values in 'HH:MM:SS' format (or 'HHH:MM:SS' format for large hours values).
# 	TIME values may range from '-839:59:59' to '838:59:59'.
#
# 	The hours part may be so large because the TIME type can be used not only to represent a time
# of day (which must be less than 24 hours), but also elapsed time or a time interval between two events
# (which may be much greater than 24 hours, or even negative)
#
# MySQL recognizes TIME values in several formats, some of which can include a trailing fractional seconds
# part in up to microseconds (6 digits) precision.
#
# See SECTION 9.1.3, "DATE AND TIME LITERALS"
#
# For information about fractional seconds support in MySQL, see SECTION 11.3.6, "FRACTIONAL SECONDS IN TIME VALUES".
#
# In particular, any fractional part in a value inserted into a TIME column is stored rather than discarded.
# With the fractional part included, the range for TIME values is '-838:59:59.000000' to '838:59:59.000000'
#
# Be careful about assigning abbreviated values to a TIME column. MySQL interprets abbreviated TIME values
# with colons as time of the day.
#
# that is, '11:12' means '11:12:00', not '00:11:12'.
#
# MySQL interprets abbreviated values without colons using the assumption that the two rightmost digits represent
# seconds (That is, as elapsed time rather than as time of day)
#
# For example, you might think of '1112' and 1112 as meaning '11:12:00' (12 minutes after 11 o'clock),
# but MySQL interprets them as '00:11:12' (11 minutes, 12 seconds).
#
# Similarly, '12' and 12 are interpreted as '00:00:12'
#
# The only delimiter recognized between a time part and a fractional seconds part is the decimal point.
#
# By default, values that lie outside the TIME range but are otherwise valid are clipped to the closest
# endpoint of the range.
#
# For example, '-850:00:00' and '850:00:00' are converted to '-838:59:59' and '838:59:59'.
#
# Invalid TIME values are converted to '00:00:00'. Note that because '00:00:00' is itself
# a valid TIME value, there is no way to tell, from a value of '00:00:00' stored in a table, whether the
# original value was specified as '00:00:00' or whether it was invalid.
#
# For more restrictive treatment of invalid TIME values, enable strict SQL mode to cause errors to occur.
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# 11.3.3 THE YEAR TYPE
#
# The YEAR type is a 1-byte type used to represent year values.
# It can be declared as YEAR or YEAR(4) and has a display width of 4 characters.
#
# NOTE:
#
# 		MySQL 8.0 does not support hte YEAR(2) data type permitted in older versions of MysQL.
# 		For instructions on converting to YEAR(4), see SECTION 11.3.4, "MIGRATING YEAR(2) COLUMNS TO YEAR(4)"
#
# MySQL displays YEAR values in YYYY format, with a range of 1901 to 2155, or 0000.
#
# You can specify input YEAR values in a variety of formats:
#
# 		) As a 4-digit number in the range 1901 to 2155
#
# 		) AS a 4-digit string in the range '1901' to '2155'
#
# 		) As a 1- or 2-digit number in the range 1 to 99. MySQL converts values in the ranges 1 to 69 and 70 to 99 to YEAR
# 			values in ranges 2001 to 2069 and 1970 and 1999
#
# 		) As a 1- or 2-digit string in the range '0' to '99'. MySQL converts values in the ranges '0' to '69' and '70' to '99' to
# 			YEAR values in the ranges 2000 to 2069 and 1970 to 1999
#
# 		) The result of inserting a numeric 0 has a display value of 0000 and an internal value of 0000.
#
# 			To insert zero and have it be interpreted as 2000, specify it as a string '0' or '00'
#
# 		) As the result of a function that returns a value that is acceptable in a YEAR context, such as NOW().
#
# 	MySQL converts invalid YEAR values to 0000.
#
# See also SECTION 11.3.8, "TWO-DIGIT YEARS IN DATES"
#
# 11.3.4 MIGRATING YEAR(2) COLUMNS TO YEAR(4)
#
# MySQL 8.0 does not support the YEAR(2) data type permitted in older versions of MySQL.
# Existing YEAR(2) columns must be converted to YEAR(4) to become usable again.
#
# This section provides information about performing that conversion.
#
# REMOVED YEAR(2) SUPPORT IN MYSQL 8.0
#
# MysQL 8.0 handles YEAR(2) columns as follows:
#
# 		) YEAR(2) column definitions for new tables produce an ER_INVALID_YEAR_COLUMN_LENGTH error:
#
# 			CREATE TABLE t1 (y YEAR(2));
# 			ERROR 1818 (HY000): Supports only YEAR or YEAR(4) column.
#
# 		) YEAR(2) column in existing tables remain as YEAR(2), but YEAR(2) columns in queries produce warnings
# 			or errors.
#
# 		) Several programs or statements convert YEAR(2) to YEAR(4) automatically:
#
# 			) ALTER_TABLE statements that result in a table rebuild.
#
# 			) REPAIR_TABLE (which CHECK_TABLE recommends you use if it finds that a table contains YEAR(2) columns)
#
# 			) mysql_upgrade (which uses REPAIR_TABLE)
#
# 			) Dumping with mysqldump and reloading the dump file.
#
# 				Unlike the conversions performed by the preceding three items,
# 				a dump and reload has the potential to change values.
#
# 		A MySQL upgrade usually involves at least one of the last two items.
# 		However, with respect to YEAR(2), mysql_upgrade is preferable.
#
# 		You should avoid using mysqldump because, as noted, that can change values.
#
# MIGRATING FROM YEAR(2) TO YEAR(4)
#
# To convert YEAR(2) columns to YEAR(4), you can do so manually at any time without upgrading.
#
# Alternatively, you can upgrade to a version of MySQL with reduced or removed support
# for YEAR(2) (MySQL 5.6.6 or later), then have MySQL convert YEAR(2) columns automatically.
#
# In the latter case, avoid upgrading by dumping and reloading your data because that can
# change data values.
#
# In addition, if you use replication, there are upgrade considerations you must take into account.
#
# To convert YEAR(2) columns to YEAR(4) manually, use ALTER_TABLE or REPAIR_TABLE.
# Suppose that a table t1 has this definition:
#
# 		CREATE TABLE t1 (ycol YEAR(2) NOT NULL DEFAULT '70');
#
# Modify the column using ALTER TABLE as follows:
#
# 		ALTER TABLE t1 FORCE;
#
# The ALTER_TABLE statement converts the table without changing YEAR(2) values.
#
# If the server is a replication master, the ALTER_TABLE statement replicates to slaves and
# makes the corresponding table change on each one.
#
# Another migration method is to perform a binary upgrade: Install MySQL without dumping and
# reloading your data.
#
# Then run mysql_upgrade, which uses REPAIR_TABLE to convert YEAR(2) columns to YEAR(4) without
# changing data values.
#
# If the server is a replication master, the REPAIR_TABLE statements replicate to slaves and make
# the corresponding table changes on each one, unless you invoke mysql_upgrade with the --skip-write-binlog option.
#
# Upgrades to replication servers usually involve upgrading slaves to a newer version of MySQL, then upgrading
# the master.
#
# For example, if a master and slave both run MysQL 5.5, a typical upgrade sequence involves upgrading the slave
# to 5.6, then upgrading the master to 5.6
#
# With regard to the different treatment of YEAR(2) as of MysQL 5.6.6, that upgrade sequence results in a problem:
#
# Suppose that hte slave has been upgraded but not yet the master.
#
# Then creating a table containing a YEAR(2) column on the master results in a table containing a 
# YEAR(4) column on the slave.
#
# Consequently, these operations will have a different result on the master and slave, if you use
# statement-based replication:
#
# 		) Inserting numeric 0. The resulting value has an internal value of 2000 on the master but 0000 on the slave.
#
# 		) Converting YEAR(2) to string. This operation uses the display value of YEAR(2) on the master but YEAR(4) on the slave.
#
# To avoid such problems, modify all YEAR(2) columns on the master to YEAR(4) before upgrading.
#
# (Use ALTER_TABLE as described previously). Then you can upgrade normally (slave first, then master) without
# introducing any YEAR(2) to YEAR(4) differences between the master and slave.
#
# One migration method should be avoided: Do not dump your data with mysqldump and reload the dump file after
# upgrading.
#
# This has the potential to change YEAR(2) values, as described previously.
#
# A migration from YEAR(2) to YEAR(4) should also involve examining application code for the
# possibility of changed behavior under conditions such as these:
#
# 		) Code that expects selecting a YEAR column to produce exactly two digits.
#
# 		) Code that does not account for different handling for inserts of numeric 0:
# 			inserting 0 into YEAR(2) or YEAR(4) results in an internal value of 2000 or 0000, respectively.
#
# 11.3.5 AUTOMATIC INITIALIZATION AND UPDATING FOR TIMESTAMP AND DATETIME
#
# TIMESTAMP and DATETIME columns can be automatically initialized and updated to the current date and time
# (that is, the current timestamp)
#
# For any TIMESTAMP or DATETIME column in a table, you can assign the current timestamp as the default value,
# the auto-update value, or both:
#
# 		) An auto-initialized column is set to the current timestamp for inserted rows that specify no value for the column.
#
# 		) An auto-updated column is automatically updated to the current timestamp when the value of any other column
# 			in the row is changed from its current value.
#
# 			An auto-updated column remains unchanged if all other columns are set to their current values.
#
# 			To prevent an auto-updated column from updating when other columns change, explicitly set it to
# 			its current value.
#
# 			To update an auto-updated column even when other columns do not change, explicitly set it to
# 			the value it should have (for example, set it to CURRENT_TIMESTAMP)
#
# In addition, if the explicit_defaults_for_timestamp system variable is disabled, you can initialize
# or update any TIMESTAMP (but not DATETIME) column to the current date and time by assigning it a NULL value,
# unless it has been defined with the NULL attribute to permit NULL values.
#
# To specify automatic properties, use the DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP clauses
# in column definitions.
#
# The order of the clauses does not matter.
#
# If both are present in a column definition, either can occur first.
#
# Any of the synonyms for CURRENT_TIMESTAMP have the same meaning as CURRENT_TIMESTAMP.
# 
# These are CURRENT_TIMESTAMP(), NOW(), LOCALTIME, LOCALTIME(), LOCALTIMESTAMP, and
# LOCALTIMESTAMP()
#
# Use of DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP is specific to TIMESTAMP and DATETIME.
#
# The DEFAULT clause also can be used to specify a constant (nonautomatic) default value; for example,
# DEFAULT 0 or DEFAULT '2000-01-01 00:00:00'
#
# NOTE:
#
# 		The following examples use DEFAULT 0, a default that can produce warnings or errors depending
# 		on whether strict SQL mode or the NO_ZERO_DATE SQL mode is enabled.
#
# 		Be aware that the TRADITIONAL SQL mode includes strict mode and NO_ZERO_DATE.
#
# 		See SECTION 5.1.11, "SERVER SQL MODES"
#
# TIMESTAMP or DATETIME column definitions can specify the current timestamp for both the default
# and auto-update values, for one but not hte other, or for neither.
#
# Different columns can have different combinations of automatic properties.
# The following rules describe the possibilities:
#
# 		) With both DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP, the column has the
# 			current timestamp for its default value and is automatically updated to the current timestamp.
#
# 				CREATE TABLE t1 (
# 					ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
# 					dt DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
# 				);
#
# 		) With a DEFAULT clause but no ON UPDATE CURRENT_TIMESTAMP clause, the column has the given
# 			default value and is not automatically updated to the current timestamp.
#
# 			The default depends on whether the DEFAULT clause specifies CURRENT_TIMESTAMP or
# 			a constant value.
#
# 			With CURRENT_TIMESTAMP, the default is the current timestamp.
#
# 				CREATE TABLE t1 (
# 					ts TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
# 					dt DATETIME DEFAULT CURRENT_TIMESTAMP
# 				);
#
# 			With a constant, the default is the given value. In this case,
# 			the column has no automatic properties at all.
#
# 				CREATE TABLE t1 (
# 					ts TIMESTAMP DEFAULT 0,
# 					dt DATETIME DEFAULT 0
# 				);
#
# 		) With an ON UPDATE CURRENT_TIMESTAMP clause and a constant DEFAULT clause, the column
# 			is automatically updated to the current timestamp and has the given constant default
# 			value.
#
# 				CREATE TABLE t1 (
# 					ts TIMESTAMP DEFAULT 0 ON UPDATE CURRENT_TIMESTAMP,
# 					dt DATETIME DEFAULT 0 ON UPDATE CURRENT_TIMESTAMP
# 				);
#
# 		) With an ON UPDATE CURRENT_TIMESTAMP clause but no DEFAULT clause, the column is automatically
# 			updated to the current timestamp but does not have the current timestamp for its
# 			default value.
#
# 			The default in this case is type dependent.
#
# 			TIMESTAMP has a default of 0 unless defined with the NULL attribute, in which case
# 			the default is NULL.
#
# 				CREATE TABLE t1 (
# 					ts1 TIMESTAMP ON UPDATE CURRENT_TIMESTAMP, -- default 0
# 					ts2 TIMESTAMP NULL ON UPDATE CURRENT_TIMESTAMP -- NULL
# 				);
#
# 			DATETIME has a default of NULL unless defined with the NOT NULL attribute,
# 			in which case the default is 0.
#
# 				CREATE TABLE t1 (
# 					dt1 DATETIME ON UPDATE CURRENT_TIMESTAMP, 		-- default NULL
# 					dt2 DATETIME NOT NULL ON UPDATE CURRENT_TIMESTAMP -- default 0
# 				);
#
# TIMESTAMP and DATETIME columns have no automatic properties unless they are specified
# explicitly, with this exception:
#
# 		If the explicit_defaults_for_timestamp system variable is disabled, the first TIMESTAMP column has both
# 		DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP if neither is specified explicitly.
#
# To surpress automatic properties for the first TIMESTAMP column, use one of these strategies:
#
# 		) Enable the explicit_defaults_for_timestamp system variable.
#
# 			In this case, the DEFAULT CURRENT_TIMESTAMP and ON UPDATE CURRENT_TIMESTAMP clauses
# 			that specify automatic initialization and updating are available, but are not assigned
# 			to any TIMESTAMP column unless explicitly included in the column definition.
#
# 		) Alternatively, if explicit_defaults_for_timestamp is disabled, do either of the following:
#
# 			) Define the column with a DEFAULT clause that specifies a constant default value.
#
# 			) Specify the NULL attribute.
#
# 				This also causes the column to permit NULL values, which means that you cannot assign
# 				the current timestamp by setting the column to NULL.
#
# 				Assigning NULL sets the column to NULL, not the current timestamp.
#
# 				To assign the current timestamp, set the column to CURRENT_TIMESTAMP or a synonym
# 				such as NOW()
#
# Consider these table definitions:
#
# 		CREATE TABLE t1 (
# 			ts1 TIMESTAMP DEFAULT 0,
# 			ts2 TIMESTAMP DEFAULT CURRENT_TIMESTAMP
# 							  ON UPDATE CURRENT_TIMESTAMP);
#
# 		CREATE TABLE t2 (
# 			ts1 TIMESTAMP NULL,
# 			ts2 TIMESTAMP DEFAULT CURRENT_TIMESTAMP
# 							  ON UPDATE CURRENT_TIMESTAMP);
#
# 		CREATE TABLE t3 (
# 			ts1 TIMESTAMP NULL DEFAULT 0,
# 			ts2 TIMESTAMP DEFAULT CURRENT_TIMESTAMP
# 							  ON UPDATE CURRENT_TIMESTAMP);
#
# The tables have these properties:
#
# 		) In each table definition, the first TIMESTAMP column has no automatic initialization or updating.
#
# 		) The tables differ in how the ts1 column handles NULL values.
#
# 			For t1, ts1 is NOT NULL and assigning it a value of NULL sets it to the
# 			current timestamp.
#
# 			For t2 and t3, t1 permits NULL and assigning it a value of NULL sets it to NULL.
#
# 		) t2 and t3 differ in the default value for ts1.
#
# 			For t2, ts1 is defined to permit NULL; so the default is also NULL in the absence
# 			of an explicit DEFAULT clause.
#
# 			For t3, ts1 permits NULL but has an explicit default of 0.
#
# If a TIMESTAMP or DATETIME column definition includes an explicit fractional
# seconds precision value anywhere, the same value must be used throughout the column definition.
#
# This is permitted:
#
# 		CREATE TABLE t1 (
# 			ts TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6)
# 		);
#
# This is not:
#
# 		CREATE TABLE t1 (
# 			ts TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP(3)
# 		);
#
# TIMESTAMP INITIALIZATION AND THE NULL ATTRIBUTE
#
# If the explicit_defaults_for_timestamp system variable is disabled, TIMESTAMP columns
# by default are NOT NULL, cannot contain NULL values, and assigning NULL assigns the current timestamp.
#
# TO permit a TIMESTAMP column to contain NULL, explicitly declare it with the NULL attribute.
#
# In this case, the default value also becomes NULL unless overridden with a DEFAULT clause
# that specifies a different default value.
#
# DEFAULT NULL can be used to explicitly specify NULL as the default value.
#
# (For a TIMESTAMP column not declared with the NULL attribute, DEFAULT NULL is invalid)
#
# If a TIMESTAMP column permits NULL values, assigning NULL sets it to NULL, not to the current
# timestamp.
#
# The following table contains several TIMESTAMP columns that permit NULL values:
#
# 		CREATE TABLE t
# 		(
# 			ts1 TIMESTAMP NULL DEFAULT NULL,
# 			ts2 TIMESTAMP NULL DEFAULT 0,
# 			ts3 TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP
# 		);
#
# A TIMESTAMP column that permits NULL values does not take on the current timestamp at
# insert time except under one of the following conditions:
#
# 		) Its default value is defined as CURRENT_TIMESTAMP and no value is specified for the column.
#
# 		) CURRENT_TIMESTAMP or any of its synonyms such as NOW() is explicitly inserted into the column.
#
# in other words, a TIMESTAMP column defined to permit NULL values auto-initializes only if its
# definition includes DEFAULT CURRENT_TIMESTAMP.
#
# 		CREATE TABLE t (ts TIMESTAMP NULL DEFAULT CURRENT_TIMESTAMP);
#
# If the TIMESTAMP column permits NULL values but its definition does not include DEFAULT CURRENT_TIMESTAMP,
# you must explicitly insert a value corresponding to the current date and time.
#
# Suppose that tables t1 and t2 have these definitions:
#
# 		CREATE TABLE t1 (ts TIMESTAMP NULL DEFAULT '0000-00-00 00:00:00');
# 		CREATE TABLE t2 (ts TIMESTAMP NULL DEFAULT NULL);
#
# To set the TIMESTAMP column in either table to the current timestamp at insert time,
# explicitly assign it that value.
#
# For example:
#
# 		INSERT INTO t2 VALUES (CURRENT_TIMESTAMP);
# 		INSERT INTO t1 VALUES (NOW());
#
# If the explicit_defaults_for_timestamp system variable is enabled, TIMESTAMP columns
# permit NULL values only if declared with the NULL attribute.
#
# Also, TIMESTAMP columns do not permit assigning NULL to assign the current timestamp,
# whether declared with the NULL or NOT NULL attribute.
#
# To assign the current timestamp, set the column to CURRENT_TIMESTAMP or a synonym such
# as NOW()
#
# 11.3.6 FRACTIONAL SECONDS IN TIME VALUES
#
# MySQL 8.0 has fractional seconds support for TIME, DATETIME and TIMESTAMP values,
# with up to microseconds (6 digits) precision:
#
# 		) To define a column that includes a fractional seconds part, use the syntax type_name(fsp),
# 			where type_name is TIME, DATETIME or TIMESTAMP and fsp is the fractional second precision.
#
# 			For example:
#
# 				CREATE TABLE t1 (t TIME(3), dt DATETIME(6));
#
# 			The fsp value, if given, must be in the range 0 to 6.
#
# 			A value of 0 signifies that there is no fractional part.
# 			If omitted, the default precision is 0.
#
# 			(This differs from the standard SQL default of 6, for compatibility with previous MySQL versions)
#
# 		) Inserting a TIME, DATE or TIMESTAMP value with a fractional seconds part into a column
# 			of the same type but having fewer fractional digits results in rounding.
#
# 			Consider a table created and populated as follows:
#
# 				CREATE TABLE fractest (c1 TIME(2), c2 DATETIME(2), c3 TIMESTAMP(2) );
#
# 				INSERT INTO fractest VALUES
# 				('17:51:04.777', '2018-09-08 17:51:04.777', '2018-09-08 17:51:04.777');
#
# 			The temporal values are inserted into the table with rounding:
#
# 				SELECT * FROM fractest;
# 				+-----------------+------------------------------------+------------------------------+
# 				| c1 					| c2 											 | c3  								  |
# 				+-----------------+------------------------------------+------------------------------+
# 				| 17:51:04.78 		| 2018-09-08 17:51:04.78 				 | 2018-09-08 17:51:04.78 		  |
# 				+-----------------+------------------------------------+------------------------------+
#
# 			No warning or error is given when such rounding occurs.
# 			This behavior follows the SQL standard.
#
# 			To insert the values with truncation instead, enable the TIME_TRUNCATE_FRACTIONAL SQL mode:
#
# 				SET @@sql_mode = sys.list_add(@@sql_mode, 'TIME_TRUNCATE_FRACTIONAL');
#
# 			With that SQL mode enabled, the temporal values are inserted with truncation:
#
# 				SELECT * FROM fractest;
# 				+-----------------+-------------------------------------+-------------------------------+
# 				| c1 					| c2 											  | c3 									 |
# 				+-----------------+-------------------------------------+-------------------------------+
# 				| 17:51:04.77 		| 2018-09-08 17:51:04.77 				  | 2018-09-08 17:51:04.77 		 |
# 				+-----------------+-------------------------------------+-------------------------------+
#
# 		) Functions that take temporal arguments accept values with fractional seconds.
#
# 			Return values from temporal functions include fractional seconds as appropriate.
#
# 			For example, NOW() with no argument returns the current date and time with no fractional part,
# 			but takes an optional argument from 0 to 6 to specify that the return value includes a
# 			fractional seconds part of that many digits.
#
# 		) Syntax for temporal literals produces temporal values:
#
# 			DATE 'str', TIME 'str' and TIMESTAMP 'str' and the ODBC syntax equivalents.
# 
# 			The resulting value includes a trailing fractional second part if specified.
#
# 			Previously, the temporal type keyword was ignored and these constructs produced
# 			the string value.
#
# 			See STANDARD SQL AND ODBC DATE AND TIME LITERALS
#
# 11.3.7 CONVERSION BETWEEN DATE AND TIME TYPES
#
# To some extent, you can convert a value from one temporal type to another.
#
# However, there may be some alteration of the value or loss of information.
#
# In all cases, conversion between temporal types is subject to the range of valid values
# for the resulting type.
#
# For example, although DATE, DATETIME and TIMESTAMP values all can be specified using the
# same set of formats, the types do not all have the same range of values.
#
# TIMESTAMP values cannot be earlier than 1970 UTC or later than '2038-01-19 03:14:07' UTC.
#
# This means that a date such as '1968-01-01', while valid as a DATE or DATETIME value, is not
# valid as a TIMESTAMP value and is converted to 0.
#
# Conversion of DATE values:
#
# 		) Conversion to a DATETIME or TIMESTAMP value adds a time part of '00:00:00' because the DATE
# 			value contains no time information.
#
# 		) Conversion to a TIME value is not useful, the result is '00:00:00'
#
# Conversion of DATETIME and TIMESTAMP values:
#
# 		) Conversion to a DATE value takes fractional seconds into account and rounds the time part.
# 			For example, '1999-12-31 23:59:59.499' becomes '1999-12-31', whereas '1999-12-31 23:59:59.500' becomes '2000-01-01'
#
# 		) Conversion to a TIME value discards the date part because the TIME type contains no date information.
#
# For conversion of TIME values to other temporal types, the value of CURRENT_DATE() is used for the date part.
#
# The TIME is interpreted as elapsed time (not time of day) and added to the date.
#
# THis means that the date part of the result differs from the current date if the time value is
# outside the range from '00:00:00' to '23:59:59'
#
# Suppose that the current date is '2012-01-01'.
#
# TIME Values of '12:00:00', '24:00:00', and '-12:00:00', when converted to DATETIME
# or TIMESTAMP values, result in '2012-01-01 12:00:00', '2012-01-02 00:00:00' and
# '2011-12-31 12:00:00', respectively.
#
# Conversion of TIME to DATE is similar, but discards the time part from the result:
#
# 	'2012-01-01', '2012-01-02' and '2011-12-31', respectively.
#
# Explicit conversion can be used to override implicit conversion.
#
# FOr example, in comparison of DATE and DATETIME values, the DATE value is coerced to the
# DATETIME type by adding a time part of '00:00:00'
#
# To perform the comparison by ignoring the time part of the DATETIME value instead, use the
# CAST() function in the following way:
#
# 		date_col = CAST(datetime_col AS DATE);
#
# Conversion of TIME and DATETIME values to numeric form (for example, by adding +0) depends on whether
# the value contains a fractional seconds part.
#
# TIME(N) or DATETIME(N) is converted to integer when N is 0 (or omitted) and to a DECIMAL
# value with N decimal digits when N is greater than 0:
#
# 		SELECT CURTIME(), CURTIME()+0, CURTIME(3)+0;
# 		+------------+---------------+-----------------+
# 		| CURTIME()  | CURTIME()+0   | CURTIME(3)+0 	  |
# 		+------------+---------------+-----------------+
# 		| 09:28:00   | 		92800   | 92800.887 		  |
# 		+------------+---------------+-----------------+
#
# 		SELECT NOW(), NOW()+0, NOW(3)+0;
# 		+----------------------+-----------------+--------------------------+
# 		| NOW() 					  | NOW()+0 		  | NOW(3)+0 					  |
# 		+----------------------+-----------------+--------------------------+
# 		| 2012-08-15 09:28:00  | 20120815092800  | 201220815092800.889 	  |
# 		+----------------------+-----------------+--------------------------+
#
# 11.3.8 TWO-DIGIT YEARS IN DATES
#
# Date values with two-digit years are ambiguous because the century is unknown.
#
# Such values must be interpreted into four-digit form because MySQL stores years
# internally using four digits.
#
# For DATETIME, DATE and TIMESTAMP types, MySQL interprets dates specified with ambiguous year values
# using these rules:
#
# 		) Year values in the range 00-69 are converted to 2000-2069
#
# 		) Year values in the range 70-99 are converted to 1970-1999
#
# For YEAR, the rules are the same, with this exception:
#
# 		A numeric 00 inserted into YEAR(4) results in 0000 rather than 2000.
#
# 		TO specify zero for YEAR(4) and have it be interpreted as 2000, specify
# 		it as a string '0' or '00'
#
# Remember that these rules are only heuritics that provide reasonable guesses as to what
# your data values mean.
#
# If the rules used by MySQL do not produce the values you require, you must 
# provide unambiguous input containing four-digit year values.
#
# ORDER BY properly sorts YEAR values that have two-digit years.
#
# Some functions like MIN() and MAX() convert a YEAR to a number.
#
# This means that a value with a two-digit year does not work properly with these
# functions. 	
#
# THe fix in this case is to convert the YEAR to four-digit year format.
#
# 11.4 STRING TYPES
#
# The string types are CHAR, VARCHAR, BINARY, VARBINARY, BLOB, TEXT, ENUM and SET.
#
# This section describes how these types work and how to use them in your
# queries.
#
# For string type storage requirements, see SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# 11.4.1 THE CHAR AND VARCHAR TYPES
#
# The CHAR and VARCHAR types are similar, but differ in the way they are stored and retrieved.
#
# They also differ in maximum length and in whether trailing spaces are retained.
#
# The CHAR and VARCHAR types are declared with a length that indicates the maximum number of
# characters you want to store.
#
# For example, CHAR(30) can hold up to 30 characters.
#
# THe length of a CHAR column is fixed to the length that you declare when you
# create the table.
#
# THe length can be any value from 0 to 255.
#
# When CHAR values are stored, they are right-padded with spaces to the specified length.
#
# When CHAR values are retrieved, trailing spaces are removed unless the PAD_CHAR_TO_FULL_LENGTH
# SQL mode is enabled.
#
# Values in VARCHAR columns are variable-length strings.
#
# The length can be specified as a value from 0 to 65,535.
#
# The effective maximum length of a VARCHAR is subject to the maximum row size (65,535 bytes,
# which is shared among all columns) and the character set used.
#
# See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# In contrast to CHAR, VARCHAR values are stored as 1-byte or 2-byte length prefix 
# plus data.
#
# The length prefix indicates the number of bytes in the value.
#
# A column uses one length byte if values require no more than 255 bytes,
# two length bytes if values may require more than 255 bytes.
#
# If strict SQL mode is not enabled, and you assign a value ot a CHAR or VARCHAR column
# that exceeds the column's maximum length, the value is truncated to fit and a warning
# is generated.
#
# For truncation of nonspace characters, you can cause an error to occur (rather than a warning)
# and suppress insertion of the value by using strict SQL mode.
#
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# For VARCHAR columns, trailing spaces in excess of the column length are truncated prior
# to insertion and a warning is generated, regardless of the SQL mode in use.
#
# For CHAR columns, truncation of excess trailing spaces from inserted values is performed
# silently regardless of the SQL mode.
#
# VARCHAR values are not padded when they are stored. Trailing spaces are retained when values
# are stored and retrieved, in conformance with standard SQL.
#
# The following table illustrates the difference between CHAR and VARCHAR by showing the result
# of storing various string values into CHAR(4) and VARCHAR(4) columns (assuming that the column
# uses a single-byte character set such as latin1)
#
# 	Value 				CHAR(4) 			STORAGE REQUIRED 		VARCHAR(4) 		STORAGE REQUIRED
#
# 	'' 					'    ' 			4 bytes 					'' 				1 byte
# 	'ab' 					'ab  ' 			4 bytes 					'ab' 				3 bytes
# 	'abcd' 				'abcd' 			4 bytes 					'abcd' 			5 bytes
# 	'abcdefgh' 			'abcd' 			4 bytes 					'abcd' 			5 bytes
#
# The values shown as stored in the last row of the table apply only when not using strict mode;
# if MySQL is running in strict mode, values that exceed the column length are NOT stored, and an error results.
#
# InnoDB enforces fixed-length fields greater than or equal to 768 bytes in length as variable-length
# fields, which can be stored off-page.
#
# For example, a CHAR(255) column can exceed 768 bytes if the maximum byte length of the character
# set is greater than 3, as it is with utf8mb4.
#
# If a given value is stored into the CHAR(4) and VARCHAR(4) columns, the values retrieved from the
# columns are not always the same because trailing spaces are removed from CHAR columns upon retrieval.
#
# The following example illustrates this difference:
#
# 		CREATE TABLE vc (v VARCHAR(4), c CHAR(4));
# 		Query OK, 0 rows affected (0,01 sec)
#
# 		INSERT INTO vc VALUES ('ab  ', 'ab  ');
# 		Query OK, 1 row affected (0.00 sec)
#
# 		SELECT CONCAT('(', v, ')'), CONCAT('(', c, ')') FROM vc;
# 		+-------------------------+----------------------------+
# 		| CONCAT('(', v, ')') 	  | CONCAT('(', c, ')') 		 |
# 		+-------------------------+----------------------------+
# 		| (ab  ) 					  | (ab) 							 |
# 		+-------------------------+----------------------------+
# 		1 row in set (0.06 sec)
#
# Values in CHAR and VARCHAR columns are sorted and compared according to the
# character set collation assigned to the column.
#
# Most MySQL collations have a pad attribute of PAD SPACE.
#
# The exceptions are Unicode collations based on UCA 9.0.0 and higher,
# which have a pad attribute of NO PAD.
#
# (See SECTION 10.10.1, "UNICODE CHARACTER SETS")
#
# To determine the pad attribute for a collation; use the INFORMATION_SCHEMA COLLATIONS table,
# which has a PAD_ATTRIBUTE column.
#
# THe pad attribute determines how trailing spaces are treated for comparison of nonbinary strings
# (CHAR, VARCHAR, and TEXT values).
#
# NO PAD collations treat spaces at the end of strings like any other character.
#
# For PAD SPACE collations, trailing spaces are insignificant in comparisons; strings are compared
# without regard to any trailing spaces.
#
# "Comparison" in this context does not include the LIKE pattern-matching operator, for which
# trailing spaces are significant.
#
# For example:
#
# 		CREATE TABLE names (myname CHAR(10));
# 		Query OK, 0 rows affected (0.03 sec)
#
# 		INSERT INTO names VALUES ('Monty');
# 		Query OK, 1 row affected (0.00 sec)
#
# 		SELECT myname = 'Monty', myname = 'Monty    ' FROM names;
#		+------------------------+--------------------------+
# 		| myname = 'Monty' 		 | myname = 'Monty    ' 	 |
# 		+------------------------+--------------------------+
# 		| 			1 					 |				1 					 |
# 		+------------------------+--------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT myname LIKE 'Monty', myname LIKE 'Monty    ' FROM names;
# 		+------------------------+--------------------------+
# 		| myname LIKE 'Monty' 	 | myname LIKE 'Monty    '  |
# 		+------------------------+--------------------------+
# 		| 				1 				 | 				0 				 |
# 		+------------------------+--------------------------+
# 		1 row in set (0.00 sec)
#
# This is true for all MySQL versions, and is not affected by the server SQL mode.
#
# Note:
#
# 		For more information about MySQL character sets and collations, see
# 		CHAPTER 10, CHARACTER SETS, COLLATIONS, UNICODE.
#
# 		For additional information about storage requirements, see
# 		SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# For those cases where trailing pad characters are stripped or comparisons ignore them,
# if a column has an index that requires unique values, inserting into the column values
# that differ only in number of trialing pad chars will result in a duplicate key error.
#
# For example, if a table contains 'a', an attempt to store 'a  ' causes a duplicate-key error.
#
# 11.4.2 THE BINARY AND VARBINARY TYPES
#
# The BINARY and VARBINARY types are similar to CHAR and VARCHAR, except that they contain
# binary strings rather than nonbinary strings.
#
# That is, they contain byte strings rather than character strings.
#
# This means they have the binary character set and collation, and comparison
# and sorting are based on the numeric values of the bytes in the values.
#
# The permissible maximum length is the same for BINARY and VARBINARY as it is
# for CHAR and VARCHAR, except that the length for BINARY and VARBINARY is a length
# in bytes rather than in characters.
#
# The BINARY and VARBINARY data types are distinct from the CHAR BINARY and VARCHAR BINARY
# data types.
#
# For the latter types, the BINARY attribute does not cause the column to be treated as a binary
# string column.
#
# Instead, it causes the binary (_bin) collation for the column character set to be used, and
# the column itself contains nonbinary character strings rather than binary byte strings.
#
# For example, CHAR(5) BINARY is treated as CHAR(5) CHARACTER SET utf8mb4 COLLATE utf8mb4_bin, assuming
# that the default character set is utf8mb4.
#
# This differs from BINARY(5), which stores 5-bytes binary strings that have the binary
# character set and collation.
#
# For information about differences between binary strings and binary collations for nonbinary strings,
# see SECTION 10.8.5, "THE BINARY COLLATION COMPARED TO _BIN COLLATIONS"
#
# If strict SQL mode is not enabled and you assign a value to a BINARY or VARBINARY column that 
# exceeds the column's maximum length, the value is truncated to fit and a warning is generated.
#
# For cases of truncation, you can cause an error to occur (rather than a warning), and suppress
# insertion of the value by using strict SQL mode.
#
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# When BINARY values are stored, they are right-padded with the pad value to the specified length.
#
# The pad value is 0x00 (the zero byte). Values are right-padded with 0x00 on insert, and no trailing
# bytes are removed on select.
#
# All bytes are significant in comparisons, including ORDER BY and DISTINCT operations.
#
# 0x00 bytes and spaces are different in comparisons, with 0x00 < space.
#
# Example:
#
# 		For a BINARY(3) column, 'a  ' becomes 'a \0' when inserted.
# 		'a\0' becomes 'a\0\0' when inserted.
#
# 		Both inserted values remain unchanged when selected.
#
# 		For VARBINARY, there is no padding on insert and no bytes are stripped on select.
#
# 		All bytes are significant in comparisons, including ORDER BY and DISTINCT operations.
# 		0x00 bytes and spaces are different in comparisons, with 0x00 < space.
#
# 		For those cases where trailing pad bytes are stripped or comparisons ignore them, if a column
# 		has an index that requires unique values, inserting into the column values that differ
# 		only in number of trailing pad bytes will result in a duplicate key error.
#
# 		For example,, if a table contains 'a', an attempt to store 'a\0', causes a duplicate-key
# 		errror.
#
# 		You should consider the preceding padding and stripping characteristics carefully if you plan
# 		to use the BINARY data type for storing binary data and you require that hte value
# 		retrieved be exactly the same as the value stored.
#
# 		The following example illustrates how 0x00-padding of BINARY values affects
# 		column value comparisons:
#
# 			CREATE TABLE t (c BINARY(3));
# 			Query OK, 0 rows affected (0.01 sec)
#
# 			INSERT INTO t SET c = 'a';
# 			Query OK, 1 row affected (0.01 sec)
#
# 			SELECT HEX(c), c = 'a', c = 'a\0\0' from t;
# 			+-----------+--------------+---------------+
# 			| HEX(c) 	| c = 'a' 	   | c = 'a\0\0'   |
# 			+-----------+--------------+---------------+
# 			| 610000 	| 			0 		| 1 				 |
# 			+-----------+--------------+---------------+
# 			1 row in set (0.09 sec)
#
# If the value retrieved must be the same as the value specified for storage with no padding,
# it might be preferable to use VARBINARY or one of the BLOB data types instead.
#
# 11.4.3 THE BLOB AND TEXT TYPES
#
# A BLOB is a binary large object that can hold a variable amount of data.
# The four BLOB types are TINYBLOB, MEDIUMBLOB, and LONGBLOB.
#
# These differ only in the maximum length of the values they can hold.
#
# The four TEXT types are TINYTEXT, TEXT, MEDIUMTEXT, and LONGTEXT.
#
# These correspond to the four BLOB types and have the same maximum lengths
# and storage requirements.
#
# See SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# BLOB values are treated as binary strings (byte strings).
#
# THey have the binary character set and collation, and comparison and sorting
# are based on the numeric values of the bytes in column values.
#
# TEXT values are treated as nonbinary strings (char strings)
#
# They have a character set other than binary, and values are sorted and compared based
# on the collation of the character set.
#
# If strict SQL mode is not enabled and you assign a value to a BLOB or TEXT column that
# exceeds the column's maximum length, the value is truncated to fit and a warning is
# generated.
#
# For truncation of nonspace characters, you can cause an error to occur (rather than a warning)
# and suppress insertion of the value by using strict SQL mode.
#
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# Truncation of excess trailing spaces from values to be inserted into TEXT columns always
# generate a warning, regardless of the SQL mode.
#
# For TEXT and BLOB columns, there is no padding on insert and no bytes are stripped on select.
#
# If a TEXT column is indexed, index entry comparisons are space-padded at the end.
#
# This means that, if the index requires unique values, duplicate-key errors will occur for
# values that  differ only in the number of trailing spaces.
#
# For example, if a table contains 'a', an attempt to store 'a  ' causes a duplicate-key error.
#
# This is not true for BLOB columns.
#
# In most respects, you can regard a BLOB column as a VARBINARY column that can be as large
# as you like.
#
# Similarly, you can regard a TEXT column as a VARCHAR column.
#
# BLOB and TEXT differ from VARBINARY and VARCHAR in the following ways:
#
# 		) For indexes on BLOB and TEXT columns, you must specify an index prefix length.
# 			For CHAR and VARCHAR, a prefix length is optional.
#
# 			See SECTION 8.3.5, "COLUMN INDEXES"
#
# 		) BLOB and TEXT columns cannot have DEFAULT values.
#
# If you use the BINARY attribute with a TEXT data type, the column is assigned
# the binary (_bin) collation of the column character set.
#
# LONG and LONG VARCHAR map to the MEDIUMTEXT data type.
# This is a compatbility feature.
#
# MySQL Connector/ODBC defines BLOB values as LONGVARBINARY and TEXT values as LONGVARCHAR.
#
# Because BLOB and TEXT values cna be extremely long, you might encounter some constraints in using them:
#
# 		) Only the first max_sort_length bytes of the column are used when sorting.
#
# 			The default value of max_sort_length is 1024.
#
# 			You can make more bytes significant in sorting or grouping by increasing
# 			the value of max_sort_length at server startup or runtime.
#
# 			Any client can change the value of its session max_sort_length variable:
#
# 				SET max_sort_length = 2000;
# 				SELECT id, comment FROM t
# 				-> ORDER BY comment;
#
# 		) Instances of BLOB or TEXT columns in the result of a query that is processed using a temporary table
# 			causes the server to use a table on disk rather than in memory because the MEMORY storage engine
# 			does not support those data types. (see SECTION 8.4.4, "INTERNAL TEMPORARY TABLE USE IN MYSQL")
#
# 			Use of disk incurs a performance penalty, so include BLOB or TEXT columns in the query result only
# 			if they are really needed.
#
# 			For example, avoid using SELECT_*, which selects all columns.
#
# 		) The maximum size of a BLOB or TEXT object is determined by its type, but the largest value
# 			you actually can transmit between the client and server is determined by the amount of
# 			available memory and the size of the communications buffers.
#
# 			You can change the message buffer size by changing the value of the max_allowed_packet
# 			variable, but you must do so for both the server and your client program.
#
# 			For example, both mysql and mysqldump enable you to change the client-side 
# 			max_allowed_packet value.
#
# 			See SECTION 5.1.1, "CONFIGURING THE SERVER", SECTION 4.5.1 "MYSQL - THE MYSQL COMMAND-LINE TOOL";
# 			and SECTION 4.5.4 "MYSQLDUMP - A DATABASE BACKUP PROGRAM".
#
# 			YOu may also want ot compare the packet sizes of the data objects you are storing with the storage
# 			requirements, see SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS"
#
# Each BLOB or TEXT value is represented internally by a separately allocated object.
#
# This is in contrast to other data types, for which storage is allocated once per column when the
# table is opened.
#
# IN some cases, it may be desirable to store binary data such as media files in BLOB or TEXT columns.
# You may find MySQL's string handling functions useful for workting with such data.
#
# See SECTION 12.5, "STRING FUNCTIONS".
#
# For security and other reasons, it is usually preferable to do so using application code rather
# than giving application users the FILE privilege.
#
# 11.4.4 THE ENUM TYPE
#
# An ENUM is a string object with a value chosen from a list of permitted values that are enumerated explicitly
# in the column specification at table creation time.
#
# It has these advantages:
#
# 		) Compact data storage in situations where a column has a limited set of possible values.
#
# 			The strings you specify as input values are automatically encoded as numbers.
#
# 			See SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS" for the storage requirements
# 			for ENUM types.
#
# 		) Readable queries and output.
#
# 			The numbers are tralsated back to the corresponding string in query results.
#
# and these potentional issues ot consider:
#
# 		) If you make enumeration values that look like numbers, it is easy ot mix up the literal values
# 			with their internal index numbers, as explained in Enumeration Limitations.
#
# 		) Using ENUM columns in ORDER BY clauses requires extra care, as explained in Enumeration Sorting.
#
# 		) Creating and Using ENUM columns
#
# 		) INdex Values for Enumeration Literals
#
# 		) Handling of ENumeraiton lierals
#
# 		) Empty or NULL Enumeration values
#
# 		) Enumeration Sorting
#
# 		) Enumeration Limitations
#
# CREATING AND USING ENUM COLUMNS
#
# An enumeration value must be a quoted string literal.
# For example, you can create a table with an ENUM column like this:
#
# 		CREATE TABLE shirts (
# 			name VARCHAR(40),
# 			size ENUM('x-small', 'small', 'medium', 'large', 'x-large')
# 		);
#
# 		INSERT INTO shirts (name, size) VALUES ('dress shirt', 'large', ('t-shirt', 'medium'),
# 			('polo shirt', 'small');
#
# 		SELECT name, size FROM shirts WHERE size = 'medium';
# 		+------------+-----------+
# 		| name 		 | size 		 |
# 		+------------+-----------+
# 		| t-shirt 	 | medium 	 |
# 		+------------+-----------+
#
# 		UPDATE shirts SET size = 'small' WHERE size = 'large';
# 		COMMIT;
#
# Inserting 1 million rows into this table with a value of 'medium' would require 1 million bytes
# of storage, as opposed to 6 mil bytes if you stored the actual string 'medium' in a VARCHAR column.
#
# INDEX VALUES FOR ENUMERATION LITERALS
#
# Each enumeration has an index:
#
# 		) The elements listed in the column specification are assigned
# 			index numbers, beginning with 1.
#
# 		) The index value of the empty string error  value is 0.
#
# 			This means that you can use the following SELECT statement
# 			to find rows into which invalid ENUM values were assigned:
#
# 				SELECT * FROM tbl_name WHERE enum_col=0;
#
# 		) The index of the NULL value is NULL
#
# 		) The term "index" here refers to position within list of enum values. Not table indexes.
#
# For example, a column speicifed as ENUM('Mercury', 'Venus', 'Earth') can have any of the values as:
#
# 		VALUE 					INDEX
#
# 		NULL 						NULL
# 
# 		'' 						0
#
# 		'Mercury' 				1
# 
# 		'Venus' 					2
#
# 		'Earth' 					3
#
# An ENUM column can have a maximum of 65,535 distinct elements.
#
# if you retrieve an ENUM value in a numeric context, the column value's index is returned.
#
# For example, you can retrieve numeric values from an ENUM column like this:
#
# 		SELECT enum_col+0 FROM tbl_name;
#
# Functions such as SUM() or AVG() that expect a numeric argument cast the argument 
# to a number if necessary.
#
# For ENUM values, the index number is used in the calculation.
#
# HANDLING OF ENUMERATION LITERALS
#
# Trailing spaces are automatically deleted from ENUM member values
# in the table definition when a table is created.
#
# When retrieved, values stored into an ENUM column are displayed using the lettercase
# that was used in the column definition.
#
# Note that ENUM columns can be assigned a character set and collation.
#
# For binary or case-sensitive collations, lettercase is taken into account
# when assigning values to the column.
#
# If you store a number into an ENUM column, the number is treated as the index into the
# possible values, and the value stored is the enumeration member with that index.
#
# (However, this does NOT work with LOAD_DATA, which treats all input as strings)
#
# If the numeric value is quoted, it is still interpeted as an index if there
# is no matching string in the list of enumeration values.
#
# For these reasons, it is not advisable to define an ENUM column with enumeration values
# that look like numbers, because this can easily become confusing.
#
# For example, the following column has enumeration members with string values of '0', '1', '2',
# but numeric index values of 123
#
# numbers ENUM('0', '1', '2')
#
# If you store 2, it is interpeted as an index value and becomes '1' (the value with index 2).
#
# If you store '2', it matches an enumeration value, so it is stored as '2'.
#
# If you store '3', it does not match any enumeration value, so it is treated as an index and
# becomes '2' (the value with index 3)
#
# 	INSERT INTO t (numbers) VALUES(2), ('2'), ('3');
# 	SELECT * FROM t;
# 	+-------------+
# 	| numbers 	  |
# 	+-------------+
# 	| 1 			  |
## | 2 			  |
# 	| 2 			  |
# 	+-------------+
#
# To determine all possible values for an ENUM column, use SHOW_COLUMNS_FROM_tbl_name_LIKE_'enum col' and parse the
# ENUM definition in the Type column of the output.
#
# In the C API, ENUM values are returned as strings.
#
# For information about using result set metadata to distinguish them from otehr strings,
# see SECTION 28.7.5, "C API DATA STRUCTURES"
#
# EMPTY OR NULL ENUMERATION VALUES
#
# An enumeration value can also be the empty string ('') or NULL under certain circumnstances:
#
# 		) If oyu insert an invalid value into an ENUM(that is, a string ot present in the list of permitted values),
# 			the empty string is inserted instead as a special error value.
#
# 			THis string can be distinguished from a "normal" empty string by the fact that this string has
# 			the numeric value 0.
#
# 			See INDEX VALUES FOR ENUMERATION LITERALS for details about the numeric
# 			indexes for the enumeration values.
#
# 			If strict SQL mode is enabled, attempts to insert invalid ENUM values result in an error.
#
# 		) If an ENUM column is declared to permit NULL, the NULL value is a valid value for hte column,
# 			and the default value is NULL.
#
# 			If an ENUM column is declared NOT NULL, its default value is the first element
# 			of the list of permitted values.
#
# ENUMERATION SORTING
#
# ENUM values are sorted based on their index numbers, which depend on the order in which the enumeration members
# were listed in the column specification.
#
# FOr example, 'b' sorts before 'a' for ENUM('b', 'a')
#
# The empty string sorts before nonempty strings, and NULL values sort before ALL other enumeration values.
#
# TO prevent unexpected resultswhen using ORDER BY clause on an ENUM column,
# use one of these techniques:
#
# 		) Specify the ENUM list in alphabetic order
#
# 		) Make sure taht hte column is sorted lexically rather
# 		than by index number by coding ORDER BY CAST(col AS CHAR) or ORDER BY CONCAT(col)
#
# ENUMERATION LIMITATIONS
#
# AN enumeraiton value cannot be an expression, even one that evaluates to a string value.
#
# FOr example, this CREATE TABLE statement DOES NOT work because the CONCAT function CANNOT 
# be used ot cosntruct an enumeration value:
#
# 		CREATE TABLE sizes (
# 			size ENUM('small', CONCAT('med', 'ium'), 'large')
# 		);
#
# YOu also cannot employ a user variable as an enumeration value.
#
# This pair of staetments do NOT work:
#
# 		SET @mysize = 'medium';
#
# 		CREATE TABLE sizes (
# 			size ENUM('small', @mysize, 'large')
# 		);
#
# We strongly recommend that you do NOT use numbers as Enum values.
#
# BEcause it does not save on storage over the appropriate TINYINT or SMALLINT types,
# and it is easy to mix up strings and the underlying number values (which might not be the same),
# if oyu quote the ENUM values incorrectly.
#
# If you do use a number as an enum value, always enclose it in quotation marks.
#
# If the quotation marks are omitted, the number is regarded as an index.
#
# SEe HANDLING OF ENUMERAITON LITERALS to see how even a quoted number could be
# mistakenly used as a numeric index value.
#
# Duplicate vlaues in teh definition cause a warning, or an error if strict mode
# is enabled.
#
# 11.4.5 THE SET TYPE
#
# A SET is a string object that can have zero or more values,each of which must be chosen
# from a list of permitted values specified when the table is created.
#
# SET column values that consist of multiple set members are specified with members
# separated by commas (,)
#
# A consequence of this is that SET members values should not themselves
# contain commas.
#
# For example, a column specified as SET('one', 'two') NOT NULL can have any of these values:
#
# 		''
# 		'one'
# 		'two'
# 		'one, two'
#
# A SET column can have a maximum of 64 distinct members.
#
# Duplicate values in the definition cause a warning, or an error if strict
# SQL mode is enabled.
#
# Trailing spaces are automatically deleted from SET member values in the table
# definition when a table is created.
#
# WHen retrieved, values stored in a SET column are displayed using the lettercase
# that was used in the column definition.
#
# Note that SET columns can be assigned a character set and collation.
#
# For binary or case-sensitive collations, lettercase is taken into account when assinging
# values ot hte column.
#
# MySQL stores SET values numerically, with the low-order bit of the stored value correpsonding
# to the first set member.
#
# If you retrieve a SET value in a numeric context, the value retrieved has bits set corresponding
# to the set members that make up the column vlaue.
#
# For example, you can retrieve numeric values from a SET column like this:
#
# 		SELECT set_col+0 FROM tbl_name;
#
# If a number is stored into a SET column, the bits that are set in the binary representation
# of the number determine the set members in the column value.
#
# FOr a column specified as SET('a', 'b', 'c', 'd'), the members have the following decimal
# and binary values:
#
# 		SET member 			DECIMAL VALUE 			BINARY VALUE
#
# 		'a' 					1 							0001
# 		'b' 					2 							0010
# 		'c' 					4 							0100
# 		'd' 					8 							1000
#
# If you assign a value of 9 to this column, that is 1001 in binary, so the first and fourth SET value members
# 'a' and 'd' are selected and the resulting value is 'a,d'
#
# For a value containing more than one SET element, it doesn ot matter what order the elements are listed in
# when you insert the value.
#
# It also does not matter how many times a given element is listed in the value.
#
# When the value is retrieved later, each element in the value appears once, with
# elements listed according to the order in which they were specified at table creation time.
#
# For example, suppose tha a column is specified as SET('a','b','c','d'):
#
# 		CREATE TABLE myset (col SET('a', 'b', 'c', 'd'));
#
# If you insert the values 'a,d', 'd,a', 'a,d,d', 'a,d,a', and 'd,a,d':
#
# 		INSERT INTO myset (col) VALUES
# 		-> ('a,d'), ('d,a'), ('a,d,a'), ('a,d,d'); ('d,a,d');
# 		Query OK, 5 rows affected (0.01 sec)
# 		Records: 5 Duplicates: 0 Warnings: 0
#
# THen all these values appear as 'a,d' when retrieved:
#
# 		SELECT col FROM myset;
#
# 		+-------+
# 		| col   |
# 		+-------+
# 		| a,d   |
# 		| a,d   |
# 		| a,d   |
# 		| a,d   |
# 		| a,d   |
# 		+-------+
# 		5 rows in set (0.04 sec)
#
# If you set a SET column to an unsupported value, the value is ignored and a warning is issued:
#
#
# 		INSERT INTO myset (col) VALUES ('a,d,d,s');
# 		Query OK, 1 row affected, 1 warning (0.03 sec)
#
# 		SHOW WARNING;
# 		+-----------+-----------+------------------------------------------+
# 		| Level 	   | Code 		| Message 						   				 |
# 		+-----------+-----------+------------------------------------------+
# 		| Warning 	| 1265 		| Data truncated for column 'col' at row 1 |
# 		+-----------+-----------+------------------------------------------+
# 		1 row in set (0.04 sec)
#
# 		SELECT col FROM myset;
# 		+-----+
# 		| col |
# 		+-----+
# 		| a,d |
# 		| a,d |
# 		| a,d |
# 		| a,d |
# 		| a,d |
# 		| a,d |
# 		+-----+
# 		6 rows in set (0.01 sec)
#
# If strict SQL mode is enabled, attempts to insert invalid SET values
# result in an error.
#
# SET values are sorted numerically. 
#
# NULL values sort before non-NULL SET values.
#
# Functions such as SUM() or AVG() that expect a numeric argument cast teh argument
# to a number if necessary.
#
# For SET values, the cast operation causes the numeric value
# to be used.
#
# Normally, you search for SET values using the FIND_IN_SET() function or the LIKE operator:
#
# 		SELECT * FROM tbl_name WHERE FIND_IN_SET('value',set_col)>0;
# 		SELECT * FROM tbl_name WHERE set_col LIKE '%value%';
#
# The first statement finds rows where set_col contains the value set member.
#
# The second is similarr, but not the same, it finds rows where set_col contains
# value anywhere, even as a substring of another set member.
#
# The following statements also are permitted:
#
# 		SELECT * FROM tbl_name WHERE set_col & 1;
# 		SELECT * FROM tbl_name WHERE set_col = 'val1,val2';
#
# The first of the statement looks for values containing the first set member.
#
# The second looks for an exact match.
#
# Be careful with comparisons of the second tpye.
#
# Comparing set values to 'val1,val2' returns different reuslts than comparin values
# to 'val2, val1'.
#
# You should specify the values in the same order they are listed in the column definition.
#
# TO determine all possible values for a SET column, use SHOW COLUMNS FROM tbl_name LIKE
# set_col and parse the SET definition in the Type column of the output.
#
# In the C API, SET values are returned as strings.
#
# FOr information about using result set metadata to distinguish them from other strings,
# see SECTION 28.7.5, "C API DATA STRUCTURES"
#
#
# 11.5 SPATIAL DATA TYPES
#
# The Open Geospatial Consortium (OGC) is an international consortium of more than 250
# companies, agencies, and universities participating in the development of publicly
# available conceptual solutions that can be useful with all kinds of applications that manage spatial data.
#
# The Open-Geospatial Consortium publishes the OpenGIS Implementation Standard for Geographic 
# Information - Simple feature access - Part 2: SQL option, a document that proposes
# several conceptual ways for extending an SQL RDBMS to support spatial data.
#
# Available at the OGC website, <link>
#
# Following the OGC specification, MySQL implements spatial extensions as a subset of the
# SQL with Geometry Types environment.
#
# This term refers to an SQL environment that has been extended with a set of geometry
# types.
#
# A geometry-valued SQL column is implemented as a column that has a geometry type.
#
# The specification describes a set of SQL geometry types, as well as functions on those
# types to create and analyze geometry values.
#
# MySQL spatial extensions enable the generation, storage and analysis of geographic features:
#
# 		) Data types for representing spatial values
#
# 		) Functions for manipulating spatial values
#
# 		) Spatial indedxing for improved access times to spatial columns
#
# The spatial data types and functions are available for MyISAM, InnoDB, NDB and ARCHIVE tables.
#
# For indexing spatial columns, MyISAM and InnoDB support both SPATIAL and
# non-SPATIAL indexes.
#
# The other storage engines support non-SPATIAL indexes, as described in
# SECTION 13.1.15, "CREATE INDEX SYNTAX" later
#
# A geographic feature is anything in the world that has a location.
# A feature can be:
#
# 		) An entity. For example, a mountain, a pond, a city
#
# 		) A space. For example, town district, the tropics.
#
# 		) a definable location. For example, a crossroad, as a particular place where two streets intersect.
#
# Some documents use the term geospatial feature to refer to geographic features.
#
# Geometry is another word that denotes a geographic feature. Originally the word geometry
# meant measurement of the earth.
#
# Another meaning comes from cartography, referring to the geometric features that cartographers
# use to map the world.
#
# The discussion here considers these terms synonymous:
#
# 	geographic feature, geospatial feature, feature, or geometry.
#
# The term most commonly used is gometry, defined as a point or an
# aggregate of points representing anything in the world that has a location.
#
# The following material covers these topics:
#
# 		) The spatial data types implemented in MySQL model
#
# 		) The basis of the spatial extensions in the OpenGIS geometry model
#
# 		) Data formats for representing spatial data
#
# 		) How to use spatial data in MySQL
#
# 		) Use of indexing for spatial data
#
# 		) MysQL differences from the OpenGIS spec
#
# For informaiton about functions that operate on spatial data,
# see SECTION 12.16, "SPATIAL ANALYSIS FUNCTIONS"
#
# ADDITIONAL RESOURCES
#
# These standards are important for the MySQL implementation of spatial operations:
#
# 		) SQL/MM Part 3: Spatial
#
# 		) The Open Geospatial consortium publishes the OpenGIS Implementation Standard for Geographic
# 			Information, a document that proposes several conceptual ways for extending an SQL
# 			RDBMS to support spatial data.
#
# 			See in particular Simple Feature Access - Part 1: Common Architechture, and Simple
# 			Feature Access - part 2: SQL option
#
# 			The Open Geospatial Consortium (OGC) maintains a website at <link>
#
# 			The specification is available there at <link>
#
# 			It contains additional information relevant to the material here
#
# 		) The grammar for spatial reference system (RFS) definitions is based on the grammar
# 			defined in OpenGIS Implementation-Specific: Coordinate Transformation Service,
# 			More info at links.
#
# 			For differences from that specification in SRS definitions as implemented in MySQL,
# 			see SECTION 13.1.19, "CREATE SPATIAL REFERENCE SYSTEM SYNTAX"
#
# If you have questions or concerns about the use of the spatial extensions to MySQL,
# you can discuss at forums.
#
# 11.5.1 SPATIAL DATA TYPES
#
# MySQL has spatial data types that correspond to OpenGIS classes.
# The basis for these types is described in SECTION 11.5.2, "THE OPENGIS GEOMETRY MODEL"
#
# Some spatial data types hold single geometry values:
#
# 		) GEOMETRY
#
# 		) POINT
#
# 		) LINESTRING
#
# 		) POLYGON
#
# GEOMETRY can store geometry values of any type. The other single-value types (POINT, LINESTRING,
# and POLYGON) restrict their values to a particular geometry type.
#
# The other spatial data types hold collections of  values:
#
# 		) MULTIPOINT
#
# 		) MULTILINESTRING
#
# 		) MULTIPOLYGON
#
# 		) GEOMETRYCOLLECTION
#
# GEOMETRYCOLLECTION can store a collection of objects of any type.
#
# The other collection types (MULTIPOINT, MULTILINESTRING, MULTIPOLYGON, and
# GEOMETRYCOLLECTION) restrict collection members to those having a particular
# geometry type.
#
# Example: To create a table named geom that has a column named g that can store values
# of any geometry type, use this statement:
#
# 		CREATE TABLE geom (g GEOMETRY);
#
# Columns with a spatial data type can have an SRID attribute, to explicitly indicate the
# spatial reference system (SRS) for values stored in the column.
#
# For example:
#
# 		CREATE TABLE geom (
# 			p POINT SRID 0,
# 			g GEOMETRY NOT NULL SRID 4326
# 		);
#
# SPATIAL indexes can be created on spatial columns if they are NOT NULL and have a specific SRID,
# so if you plan to index the column, declare it with the NOT NULL and SRID attributes:
#
# 		CREATE TABLE geom (g GEOMETRY NOT NULL SRID 4326);
#
# InnoDB tables permit SRID values for Cartesian and geographic SRSs.
# MyISAM tables permit SRID values for Cartesian SRSs.
#
# The SRID attribute makes a spatial column SRID-restricted, which has these implications:
#
# 		) The column can contain only values with the given SRID. Attempts to insert values with a different
# 			SRID produce an error.
#
# 		) The optimizer can use SPATIAL indexes on the column. See SECTION 8.3.3, "SPATIAL INDEX OPTIMIZATION"
#
# Spatial columns with no SRID attribute are not SRID-restricted and accept values with any SRID.
#
# However, the optimizer cannot use SPATIAL indexes on them until the column definition is modified
# to include an SRID attribute, which may require that the column contents first be modified so that
# all values have the same SRID.
#
# For other examples showing how to use spatial data types in MySQL, see SECTION 11.5.6, "CREATING SPATIAL COLUMNS"
# For information about spatial reference systems, see SECTION 11.5.5 "SPATIAL REFERENCE SYSTEM SUPPORT"
#
# 11.5.2 THE OPENGIS GEOMETRY MODEL
#
# The set of geometry types proposed by OGC's SQL with Geometry Types environment is based on
# the OpenGIS Geometry Model.
#
# In this model, each geometric object has the following general properties:
#
# 		) It is associated with a spatial reference system, which describes the coordinate space
# 			in which the object is defined.
#
# 		) It belongs to some geometry class.
#
# 11.5.2.1 THE GEOMETRY CLASS HIERARCHY
#
# The geometry classes define a hierarchy as follows:
#
# 		) Geometry (noninstantiable)
#
# 			) Point (instansiable)
#
# 			) Curve (noninstansiable)
#
# 				) LineString (instansible)
#
# 					) Line
#
# 					) LinearRing
#
# 			) Surface (noninstansiable)
#
# 				) Polygon (instansiable)
#
# 			) GeometryCollection (instansible)
#
# 				) MultiPoint (instansible)
#
# 				) MultiCurve (Noninstansible)
#
# 					) MultiLineString (Instansible)
#
# 				) MultiSurface (noninstansible)
#
# 					) MultiPolygon (instansible)
#
# It is not possible to create objects in noninstansible classes.
#
# IT is possible to create objects in instansible classes.
#
# All classes have properties, and instansible classes may also have assertions
# (rules that define valid class instances)
#
# Geometry is the base class. It is an abstract class.
#
# The instansible subclasses of Geometry is restricted to zero, one or two-dimensional
# geometric objects that exist in two-dimensional co-ordinate space.
#
# All instansible geometry classes are defined so that valid instances of a geometry
# class are topologically closed (that is, all defined geometries include their boundary)
#
# The base Geometry class has subclasses for Point, Curve, Surface and GeometryCollection:
#
# 		) Point represents zero-dimensional objects
#
# 		) Curve represents one-dimensional object, and has subclass LineString, with sub-subclasses Line
# 			and LinearRing
#
# 		) Surface is designed for two-dimensional objects and has subclass Polygon.
#
# 		) GeometryCollection has specialized zero, one and two dimensional collection classes named
# 			MultiPoint, MultiLineString and MultiPolygon for modeling geometries corresponding to collections
# 			of Points, LineStrings, and Polygons, respectively.
#
# 			MultiCurve, and MultiSurface are introduced as abstract superclasses that generalize
# 			the collection interfaces to handle Curves and Surfaces.
#
# Geometry, Curve, Surface, MultiCurve, and MultiSurface are defined as noninstansiable classes.
#
# They define a common set of methods for their subclasses and are included for extensibility.
#
# Point, LineString, Polygon, GeometryCollection, MultiPoint, MultiLineString and MultiPolygon
# are instansiable classes.
#
# 11.5.2.2 GEOMETRY CLASS
#
# Geometry is the root class of the hierarchy. It is a noninstansiable class but has a number
# of properties, described in the following list, that are common to all geometry values created
# from any of the Geometry subclasses.
#
# Particular subclasses have their own specific properties, described later.
#
# GEOMETRY PROPERTIES
#
# A geometry value has the following properties:
#
# 		) Its type. Each geometry belongs to one of the instantiable classes in the hiearchy
#
# 		) Its SRID, or spatial reference identifier.
#
# 			This value identifies the geometry's associated spatial reference system that describes
# 			the coordinate space in which the geometry object is defined.
#
# 			In MySQL, the SRID value is an integer associated with the geometry value.
# 			The maximum usable SRID value is 2^32-1.
#
# 			If a large value is given, only the lower 32 bits are used.
#
# 			SRID 0 represents an infinite flat Cartesian plane with no units assigned to its axes.
# 			To ensure SRID 0 behavior, create geometry values using SRID 0.
#
# 			SRID 0 is the default for new geometry values if no SRID is specified.
#
# 			FOr computations on multiple geometry values, all values must have the same
# 			SRID or an error occurs.
#
# 		) Its coordinates in its spatial reference system, represented as double-precision (8 byte) numbers.
#
# 			All nonempty geometries include at least one pair of (X,Y) coordinates.
#
# 			Empty geometries contain no coordinates.
#
# 			Coordinates are related to the SRID. For example, in different coordinate systems,
# 			the distance between two objects may differ even when objects have the same coordinates,
# 			because the distance on the planar coordinate system and the distance on the geodetic
# 			system (co-ords on the Earth's surface) are different things.
#
# 		) Its interior, boundary and exterior.
#
# 			Every geometry occupies some position in space.
#
# 			The exterior of a geometry is all space not occupied by the geometry.
#
# 			The interior is the space occupied by the geometry.
#
# 			The boundary is the interface between the geometry's interior and exterior.
#
# 		) Its MBR (minimum bounding rectangle) or envelope.
#
# 			This is the bounding geometry, formed by the minimum and maximum (X,Y) coordinates:
#
# 				((MINX MINY, MAXX MINY, MAXX MAXY, MINX MAXY, MINX MINY))
#
# 		) Whether the value is simple or nonsimple. Geometry values of types (LineString, MultiPoint,
# 			MultiLineString) are either simple or nonsimple.
#
# 			Each type determines its own assertions for being simple or nonsimple.
#
# 		) Whether the value is closed or not closed. Geometry values of types (LineString, MultiString) are either
# 			closer or not closed.
#
# 			Each type determines its own assertions for being closed or not closed.
#
# 		) Whether the value is empty or nonempty A geometry is empty if it does not have any points.
#
# 			Exterior, interior, and boundary of an empty geometry are not defined (that is,
# 			they are represented by a NULL value)
#
# 			An empty geometry is defined to be always simple and has an area of 0.
#
# 		) Its dimension. A geometry can have dimension of -1, 0, 1 or 2:
#
# 			) -1 for an empty geometry
#
# 			) 0 for a geometry with no length and no area
#
# 			) 1 for a geometry with nonzero length and zero area
#
# 			) 2 for a geometry with nonzero area
#
# 			Point objects have a dimension of zero.
#
# 			LineString objects have a dimension of 1.
# 			Polygon objects have a dimension of 2.
#
# 			The dimensions of MultiPoint, MultiLineString and MultiPolygon
# 			objects are the same as the dimensions of the elements they consist of.
#
# 11.5.2.3 POINT CLASS
#
# A Point is a geometry that represents a single location in coordinate space.
#
# Point Examples
#
# 		) Imagine a large-scale map of the world with many cities. A Point object could represent each city.
#
# 		) On a city map, a Point object could represent a bus stop.
#
# Point Properties
#
# 		) X co-ord value
#
# 		) Y co-ord value
#
# 		) Point is defined as a zero-dimensional geometry
#
# 		) The boundary of a Point is the empty set
#
# 11.5.2.4 CURVE CLASS
#
# A Curve is a one-dimensional geometry, usually represented by a sequence of points.
# Particular subclasses of Curve define the type of interpolation between points.
#
# Curve is a noninstantiable class.
#
# Curve Properties:
#
# 		) A Curve has the coordinates of its points
#
# 		) A Curve is defined as a one-dimensional geometry
#
# 		) A Curve is simple if it does not pass through the same point twice, with the exception
# 			that a curve can still be simple if the start and end points are the same.
#
# 		) A Curve is closed if its start point is equal to its endpoint
#
# 		) The boundary of a closed Curve is empty
#
# 		) The boundary of a nonclosed Curve consists of its two endpoints
#
# 		) A Curve that is simple and closed is a LinearRing
#
# 11.5.2.5 LineString Class
#
# A LineString is a Curve with linear interpolation between points.
#
# LineString Examples
#
# 		) On a world map, LineString objects could represent rivers
#
# 		) In a City map, LineString objects could represent streets
#
# LineString Properties
#
# 		) A LineString has coordinates of segments, defined by each consecutive pair of points.
#
# 		) A LineString is a Line if it consists of exactly two points.
#
# 		) A LineString is a LinearRing if it is both closed and simple
#
# 11.5.2.6 SURFACE CLASS
#
# A Surface is a two-dimensional geometry. It is a noninstantiable class.
#
# Its only instantible subclass is Polygon.
#
# Surface Properties
#
# 		) A Surface is defined as a two-dimensional geometry
#
# 		) The OpenGIS specification defines a simple Surface as a geometry that consists of a single
# 			"patch" that is associated with a single exterior boundary and zero or more interior boundaries.
#
# 		) The boundary of a simple Surface is the set of closed curves corresponding to its exterior and interior boundaries.
#
# 11.5.2.7 POLYGON CLASS
#
# A Polygon is a planar Surface representing a multisided geometry.
#
# It is defined by a single exterior boundary and zero or more interior boundaries,
# where each interior boundary defines a Hole in the Polygon.
#
# Polygon Examples
#
# 		) On a region map, Polygon objects could represent forests, districts and so on
#
# Polygon ASsertions
#
# 		) The boundary of a Polygon consists of a set of LinearRing objects (that is, LineString objects
# 			that are both simple and closed) that make up its exterior and interior boundaries.
#
# 		) A Polygon has no rings that cross. The rings in the boundary of a Polygon may intersect at a Point, but only as a tangent.
#
# 		) A Polygon has no lines, spikes or punctures.
#
# 		) A Polygon has an interior that is a connected point set.
#
# 		) A Polygon may have holes. The exterior of a Polygon with holes is not connected.
# 			Each hole defines a connected component of the exterior.
#
# THe preceding assertions make a Polygon a simple geometry.
#
# 11.5.2.8 GEOMETRYCOLLECTION CLASS
#
# A GeomCollection is a geometry that is a collection of zero or more geometries of any class.
#
# GeomCollection and GeometryCollection are synonymous, with GeomCollection the preferred type name.
#
# All the elements in a geometry collection must be in the same spatial reference system (that is,
# in the same coordinate system)
#
# There are no other constraints on the elements of a geometry collection, although the subclasses
# of GeomCollection described in the following sections may restrict membership.
#
# Restrictions may be based on:
#
# 		) Element type (for example, a MultiPoint may contain only Point elements)
#
# 		) Dimension
#
# 		) Constraints on the degree of spatial overlap between elements.
#
# 11.5.2.9 MULTIPOINT CLASS
#
# A MultiPoint is a geometry collection composed of Point elements.
# The points are not connected or ordered in any way.
#
# MultiPoints Examples:
#
# 		) On a world map, a MultiPoint could represent a chain of small islands
#
# 		) On a city map, a MultiPoint could represent the outlets for a ticket office
#
# MultiPoint Properties:
#
# 		) A MultiPoint is a zero-dimensional geometry
#
# 		) A MultiPoint is simple if no two of its Point values are equal (hve identical coordinate values)
#
# 		) The boundary of a MultiPoint is the empty set
#
# 11.5.2.10 MULTICURVE CLASS
#
# A MultiCurve is a geometry collection composed of Curve elements.
#
# MultiCurve is a noninstansiable class.
#
# MultiCurve Properties:
#
# 		) A MultiCurve is a one-dimensional geometry
#
# 		) A MultiCurve is simple if and only if all of its elements are simple;
# 			the only intersections between any two elements occur at points that are
# 			on the boundaries of both elements.
#
# 		) A MultiCurve boundary is obtained by applying the "mod 2 union rule" (also known as odd-even rule):
#
# 			A point is in the boundary of a MultiCurve if it is in the boundaries of an
# 			Odd number of Curve elements.
#
# 		) A MultiCurve is closed if all of its elements are closed.
#
# 		) The boundary of a closed MultiCurve is always empty.
#
# 11.5.2.11 MULTILINESTRING CLASS
#
# A MultiLineString is a MultiCurve geometry collection composed of LineString elements.
#
# MultiLineString Examples:
#
# 		) On a region map, a MultiLineString could represent a river system or a high way system
#
# 11.5.2.12 MULTISURFACE CLASS
#
# A MultiSurface is a geometry collection composed of surface elements.
# MultiSurface is a noninstansiable class.
#
# Its only instantiable subclass is MultiPolygon
#
# MultiSurface Assertions
#
# 		) Surfaces within a MultiSurface have no interiors that intersect
#
# 		) Surfaces within a MultiSurface have boundaries that intersect at most a finite number of points.
#
# 11.5.2.13 MULTIPOLYGON CLASS
#
# A MultiPolygon is a MultiSurface object composed of Polygon elements.
#
# MultiPolygon Examples
#
# 		) On a region map, a MultiPolygon could represent a system of lakes.
#
# MultiPolygon ASsertions
#
# 		) A MultiPolygon has no two polygon elements with interiors that intersect.
#
# 		) A MultiPolygon has no two Polygon elements that cross (crossing is also forbidden by the previous assertion), or that touch at an infinite number of points.
#
# 		) A MultiPolygon may not have cut lines, spikes, or punctures. A MultiPolygon is a regular, closed point set.
#
# 		) A MultiPolygon that has more than one Polygon has an interior that is not connected.
#
# 			The number of connected components of the interior of a MultiPolygon is equal to
# 			the number of Polygon values in the MultiPolygon.
#
# MultiPolygon Properties
#
# 		) A MultiPolygon is a two-dimensional geometry
#
# 		) A MultiPolygon boundary is a set of closed curves (LineSTring values) corresponding
# 			to the boundaries of its Polygon elements.
#
# 		) Each Curve in the boundary of the MultiPolygon is in the boundary of exactly one
# 			polygon element.
#
# 		) Every Curve in the boundary of an Polygon element is in the boundary of the MultiPolygon.
#
# 11.5.3 SUPPORTED SPATIAL DATA FORMATS
#
# Two standard spatial data formats are used to represent geometry objects in queries:
#
# 		) Well-known Text (WKT) format
#
# 		) Well-known Binary (WKB) format
#
# INternally, MySQl stores geometry values in a format that is not identical to either WKT or WKB format.
# (Internal format is like WKB but with an initial 4 bytes to indicate the SRID)
#
# There are functions available to  convert between different data formats; see SECTION 12.16.6, "GEOMETRY FORMAT CONVERSION FUNCTIONS"
#
# The following sections describe the spatial data formats MySQL uses:
#
# 		) Well-Known Text (WKT) Format
#
# 		) Well-Known Binary (WKB) Format
#
# 		) Internal Geometry Storage Format
#
# WELL-KNOWN TEXT (WKT) FORMAT
#
# The Well-Known Text (WKT) representation of geometry values is designed for exchanging
# geometry data in ASCII form.
#
# The OpenGIS specification provides a Backus-Naur grammar that specifies the formal
# production rules for writing WKT values (see 11.5, "SPATIAL DATA TYPES")
#
# Examples of WKT representations of geometry objects:
#
# 		) A Point:
#
# 			POINT(15 20)
#
# 			THe point coordinates are specified with no separating comma.
#
# 			this differs from the syntax for the SQL Point() function, which requires a comma between
# 			the coordinates.
#
# 			Take care to use the syntax appropriate to the context of a given spatial operation.
#
# 			For example, the following statements both use ST_X() to extract the X-coordinate from a 
# 			Point object.
#
# 			The first produces the object directly using the Point() function.
#
# 			The second uses a WKT representation converted to a Point with ST_GeomFromText()
#
# 				SELECT ST_X(Point(15, 20));
# 				+------------------------------+
# 				| ST_X(POINT(15, 20)) 			 |
# 				+------------------------------+
# 				| 			15 						 |
# 				+------------------------------+
#
# 				SELECT ST_X(ST_GeomFromText('POINT(15 20)'));
# 				+--------------------------------------+
# 				| ST_X(ST_GeomFromText('POINT(15 20)'))|
# 				+--------------------------------------+
# 				| 					15 							|
# 				+--------------------------------------+
#
# 		) A LineString with four points:
#
# 			LINESTRING(0 0, 10 10, 20 25, 50 60)
#
# 			The point coordinate pairs are separated by commas.
#
# 		) A Polygon with one exterior ring and one interior ring:
#
# 			POLYGON ((0 0, 10 0, 10 10, 0 10, 0 0), (5 5, 7 5, 7 7, 5 7, 5 5))
#
# 		) A MultiPoint with three Point values:
#
# 			MULTIPOINT(0 0, 20 20, 60 60)
#
# 			Spatial functions such as ST_MPointFromText() and ST_GeomFromText() that accept
# 			WKT-format representations of MultiPoint values permit individual points within values
# 			to be surrounded by parantheses.
#
# 			For example, both of the following function calls are valid:
#
# 				ST_MPointFromText('MULTIPOINT (1 1, 2 2, 3 3)')
# 				ST_MPointFromText('MULTIPOINT ((1 1), (2 2), (3 3))')
#
# 		) A MultiLineString with two LineString values:
#
# 			MULTILINESTRING((10 10, 20 20), (15 15, 30 15))
#
# 		) A MultiPolygon with two Polygon values:
#
# 			MULTIPOLYGON(((0 0, 10 0, 10 10, 0 10, 0 0)), ((5 5, 7 5, 7 7, 5 7, 5  5)))
#
# 		) A GeometryCollection consisting of two Point values and one LineString:
#
# 			GEOMETRYCOLLECTION(POINT(10 10), POINT(30 30), LINESTRING(15 15, 20 20))
#
# WELL-KNOWN BINARY (WKB) Format
#
# The Well-Known Binary (WKB) representation of Geometric values is used for exchanging geometry
# data as binary streams represented by BLOB values containing geometric WKB information.
#
# This format is defined by the OpenGIS specification (see SECTION 11.5, "SPATIAL DATA TYPES").
# It is also defined in the ISO SQL/MM PART 3: SPATIAL STANDARD.
#
# WKB uses 1-byte unsigned integers, 4-byte unsigned integers and 8-byte double precision numbers
# (IEEE 754 format).
#
# A byte is 8 bits.
#
# For example, a WKB value that corresponds to POINT(1 -1) consists of this sequence of 21 bytes,
# each represented by 2 hexadecimal digits:
#
# 	0101000000000000000000F03F000000000000F0BF
#
# The sequence consists of the components shown in the following table.
#
# TABLE 11.2 WKB COMPONENTS EXAMPLE
#
# COMPONENT 		SIZE 			VALUE
#
# Byte order 		1 byte 		01
#
# WKB type 			4 bytes 		01000000
#
# X co-ord 			8 bytes 		0000000000000000F03F
# 
# Y co-ord 			8 bytes 		0000000000000000F0BF
#
# Components representation is as follows:
#
# 		) The byte order is either 1 or 0 to signify little-endian or big-endian storage.
#
# 			The little-endian and big-endian byte orders are also known as Network Data
# 			Representation (NDR) and External Data Representation (XDR), respectively.
#
# 		) The WKB type is a code that indicates the geometry type.
#
# 			MySQL uses values from 1 through 7 to indicate Point, LineString, Polygon,
# 			MultiPoint, MultiLineString, Multipolygon, and GeometryCollection
#
# 		) A Point value has X and Y coordinates, each represented as a double-precision value.
#
# WKB values for more complex geometry values have more complex data structures,
# as detailed in the OpenGIS specification.
#
# INTERNAL GEOMETRY STORAGE FORMAT
#
# MySQL stores geometry values using 4 bytes to indicate the SRID followed by the WKB representation
# of the value.
#
# For a description of WKB format, see Well-Known Binary (WKB) Format
#
# For the WKB part, these MySQL-specific considerations apply:
#
# 		) The byte-order indicator byte is 1 because MySQL stores geometries as little-ending values.
#
# 		) MySQL supports geometry types of Point, LineString, Polygon, MultiPoint, MultiLineString, MultiPolygon,
# 			and GeometryCollection.
#
# 			Other geometry types are not supported.
#
# 		) Only GeometryCollection can be empty. Such a value is stored with 0 elements.
#
# 		) Polygon rings can be specified both clockwise and counterclockwise.
# 			MySQL flips the rings auotmatically when reading data.
#
# Cartesian coordinates are stored in the length unit of the spatial reference system, with
# X values in the X coordinates and Y values in the Y coordinates.
#
# Axis directions are those specified by the spatial reference system.
#
# Geographic coordinates are stored in the angle unit of the spatial reference system,
# with longitudes in the X coordinates and latitude in the Y coordinates.
#
# Axis directions and the meridian are those specified by the spatial reference system.
#
# THe LENGTH() function returns the space in bytes required for value storage.
# Example:
#
# 		SET @g = ST_GeomFromText('POINT(1 -1)');
# 		SELECT LENGTH(@g);
# 		+-----------------+
# 		| LENGTH(@g) 		|
# 		+-----------------+
# 		| 		25 			|
# 		+-----------------+
#
# 		SELECT HEX(@g);
# 		+----------------------------------------------------------+
# 		| HEX(@g) 																  |
# 		+----------------------------------------------------------+
# 		| <same as before> 													  |
# 		+----------------------------------------------------------+
#
# The value length is 25 bytes, made up of these components (as can be seen from the Hexadecimal
# value):
#
# 		)  4 bytes for integer SRID (0)
#
# 		) 1 byte for integer byte order (1 = little endian)
#
# 		) 4 bytes for integer type information (1 = Point)
#
# 		) 8 bytes for double-precision X coordinate (1)
#
# 		) 8 bytes for double-precision Y coordinate (-1)
#
# 11.5.4 GEOMETRY WELL-FORMEDNESS AND VALIDITY
#
# For geometry values, MySQL distinguishes between the concepts of syntactically well-formed
# and geometrically valid.
#
# A geometry is syntactically well-formed if it satisfies conditions such as those in this
# (nonexhaustive) list:
#
# 		) Linestrings have at least two points
#
# 		) Polygons have at least one ring
#
# 		) Polygon rings are closed (first and last points the same)
#
# 		) Polygon rings have at least 4 points (minimum polygon is a triangle with first and last points the same)
#
# 		) Collections aren ot empty (except GeometryCollection)
#
# A geometry is geometrically valid if it is syntactically well-formed and satisfies conditions
# such as those in this (nonexhaustive) list:
#
# 		) Polygons are not self-intersecting
#
# 		) Polygon interior rings are inside the exterior ring
#
# 		) Multipolygons do not have overlapping polygons
#
# Spatial functions fail if a geometry is not syntactically well-formed.
#
# Spatial import functions that parse WKT or WKB values raise an error for attempts
# to create a geometry that is not syntactically well-formed.
#
# Syntactically well-formedness is also checked for attempts to store geometries
# into tables.
#
# It is permitted to insert, select, and update geometrically invalid geometries,
# but they must be syntactically well-formed.
#
# Due to the computational expenses, MySQL does not check explicitly for geometric 
# validity.
#
# Spatial computations may detect some cases of invalid geometries and raise an error,
# but they may also return an undefined result without detecting the invalidity.
#
# APplications that require geometrically valid geometries should check them using
# the ST_IsValid() function.
#
# 11.5.5 Spatial Reference System Support
#
# A spatial reference system (SRS) for spatial data is a coordinate-based system
# for geographic locations.
#
# There are different types of spatial reference systems:
#
# 		) A projected SRS is a projection of a globe onto a flat surface; that is, a flap map.
#
# 			For example, a light bulb inside a globe that shines on a paper cylinder surrounding
# 			the globe projects a map onto the paper.
#
# 			The result is georeferenced: Each point maps to a place on the globe.
#
# 			The coordinate system on that plane is Cartesian using a length unit (meters, feet, etc.)
# 			rather than degrees of longitude and latitude.
#
# 			The globes in this case are ellipsoids; that is, flattened spheres.
#
# 			Earth is a bit shorter in its North-South Axis than its Easter-West Axis, so a slightly
# 			flattened sphere is more correct but perfect spheres permit faster calculations.
#
# 		) A geographic SRS is a nonprojected SRS representing longitude-latitude (or latitude-longitude) coordinates
# 			on an ellipsoid, in any angular unit.
#
# 		) The SRS denoted in MySQL by SRID 0 represents an infite flat Cartesian plane with no units assigned to its axes.
#
# 			unlike projected SRSs, it is not georeferenced and it does not necessarily represent Earth.
#
# 			IT is an abstract plane that cna be used for anything. SRID 0 is the default SRID for spatial data in MySQL.
#
# MySQL maintains information about available spatial reference systems for spatial data in the data dictionary
# mysql.st_spatial_reference_systems table, which can store entries for projected and geographic SRSs.
#
# THis data dictionary table is invisible, but SRS entry contents are available through the INFORMATION_SCHEMA
# ST_SPATIAL_REFERENCE_SYSTEMS table, implemented as a view on mysql.st_spatial_reference_systems 
#
# (See SECTION 25.27, "THE INFORMATION_SCHEMA ST_SPATIAL_REFERENCE_SYSTEMS TABLE" for more info)
#
# The following example shows what an SRS entry looks like:
#
# 		SELECT
# 		FROM INFORMATION_SCHEMA.ST_SPATIAL_REFERENCE_SYSTEMS
# 		WHERE SRS_ID = 4326\G
# 		************************ 1. row ***********************
# 								SRS_NAME: WGS 84
# 								  SRS_ID: 4326
# 						ORGANIZATION  : EPSG
# 		  ORGANIZATION_COORDSYS_ID: 4326
# 						DEFINITION    : GEOGCS["WGS 84", DATUM["World Geodetic System 1984",
# 											 SPHEROID["WGS 84", 6378137, 298-257223563,
# 											 AUTHORITY["EPSG", "7030"]], AUTHORITY["EPSG", "6326"]],
# 											 PRIMEM["Greenwhich", 0, AUTHORITY["EPSG", "8901"]],
# 											 UNIT["degree",0-01745329519943278,
# 											 AUTHORITY["EPSG","9122"]],
# 											 AXIS["Lat",NORTH],AXIS["Long", EAST],
# 											 AUTHORITY["EPSG", "4326"]]
# 						DESCRIPTION  :
#
# This entry describes the SRS used for GPS systems.
#
# It has a name (SRS_NAME) of WGS 84 and an ID (SRS_ID) of 4326,
# which is the ID used by the European Petroleum Survey Group (EPSG)
#
# SRS definitions in the DEFINITION column are WKT values, represented as specified in the
# Open Geospatial Consortium document OGC 12-063r5.
#
# SRS_ID values represent the same kind of values passed as the SRID argument to spatial
# functions.
#
# SRID 0 (the unitless Cartesian plane) is special.
#
# it is always a legal spatial reference system ID and can be used in any computations
# on spatial data that depend on SRID values. 
#
# For computations on multiple geometry values, all values must have the same SRID or an error occurs.
#
# SRS definition parsing occurs on demand when definitions are needed by GIS functions.
#
# Parsed definitions are cached in the data dictionary cache so that parsing overhead
# is not incurred for every statement that needs SRS information.
#
# To enable manipulation of SRS entries stored in the data dictionary, MySQL provides
# these SQL statements:
#
# 		) CREATE_SPATIAL_REFERENCE_SYSTEM: See SECTION 13.1.19, "CREATE SPATIAL REFERENCE SYSTEM SYNTAX".
# 			The description for this statement includes additional information about SRS components.
#
# 		) DROP_SPATIAL_REFERENCE_SYSTEM: See SECTION 13.1.31, "DROP SPATIAL REFERENCE SYSTEM SYNTAX"
#
# 11.5.6 CREATING SPATIAL COLUMNS
#
# MySQL provides a standard way of creating spatial columns for geometry types, for example,
# with CREATE_TABLE or ALTER_TABLE.
#
# Spatial columns are supported for MyISAM, InnoDB, NDB and ARCHIVE tables.
#
# See also the notes about spatial indexes under SECTION 11.5.10, "CREATING SPATIAL INDEXES"
#
# Columns with a spatial data type can have an SRID attribute, to explicitly indicate the
# spatial reference system (SRS) for values stored in the column.
#
# For implications of an SRID-restricted column, see SECTION 11.5.1, "SPATIAL DATA TYPES"
#
# 		) Use the CREATE_TABLE statement to create a table with a spatial column:
#
# 			CREATE TABLE geom (g GEOMETRY);
#
# 		) Use the ALTER_TABLE statement to add or drop a spatial column to or from
# 			an existing table:
#
# 			ALTER TABLE geom ADD pt POINT;
# 			ALTER TABLE geom DROP pt;
#
# 11.5.7 POPULATING SPATIAL COLUMNS
#
# After you have created spatial columns, you can populate them with spatial data.
#
# Values should be stored in internal geometry format, but you can convert them to that
# format from either Well-Known Text (WKT) or Well-Known Binary (WKB) format.
#
# The following examples demonstrate how to insert geometry values into a table by
# converting WKT values to internal geometry format:
#
# 		) Perform the conversion directly in the INSERT statement:
#
# 			INSERT INTO geom VALUES (ST_GeomFromText('POINT(1 1)'));
# 			
# 			SET @g = 'POINT(1 1)';
# 			INSERT INTO geom VALUES (ST_GeomFromText(@g));
#
# 		) Perform the conversion prior to the INSERT:
#
# 			SET @g = ST_GeomFromText('POINT(1 1)');
# 			INSERT INTO geom VALUES (@g);
#
# The following examples insert more complex geometries into the table:
#
# 		SET @g = 'LINESTRING(0 0, 1 1, 2 2)';
# 		INSERT INTO geom VALUES (ST_GeomFromText(@g));
#
# 		SET @g = 'POLYGON((0 0,10 0,10 10,0 10,0 0),(5 5,7 5,7 7,5 7,5 5))';
# 		INSERT INTO geom VALUES (ST_GeomFromText(@g));
#
# 		SET @g =
# 		'GEOMETRYCOLLECTION(POINT(1 1),LINESTRING(0 0,1 1,2 2,3 3,4 4))';
# 		INSERT INTO geom VALUES (ST_GeomFromText(@g));
#
# The preceding examples use ST_GeomFromText() to create geometry values.
# You can also use type-specific functions:
#
# 		SET @g = 'POINT(1 1)';
# 		INSERT INTO geom VALUES (ST_PointFromText(@g));
#
# 		SET @g = 'LINESTRING(0 0,1 1,2 2)';
# 		INSERT INTO geom VALUES (ST_LineStringFromText(@g));
#
# 		SET @g = 'POLYGON((0 0,10 0,10 10,0 10,0 0), (5 5,7 5,7 7,7 5,5 5))';
# 		INSERT INTO geom VALUES (ST_PolygonFromText(@g));
#
# 		SET @g =
# 		'GEOMETRYCOLLECTION(POINT(1 1),LINESTRING(0 0,1 1,2 2,3 3,4 4))';
# 		INSERT INTO geom VALUES (ST_GeomCollFromText(@g));
#
# A client application program that wants to use WKB representations of geometry
# value is responsible for sending correctly formed WKB in queries to the server.
#
# There are several ways to satisfy this requirement. For example:
#
# 		) Inserting a POINT(1 1) value with hex literal syntax:
#
# 			INSERT INTO geom VALUES
# 			(ST_GeomFromWKB(X'<same as before>'));
#
# 		) An ODBC application can send a WKB representation, binding it to a placeholder
# 			using an argument of BLOB type:
#
# 			INSERT INTO geom VALUES (ST_GeomFromWKB(?))
#
# 			Other programming interfaces may support a similar placeholder mechanism.
#
# 		) In a C program, you can escape a binary value using mysql_real_escape_string_quote()
# 			and include the result in a query string that is sent to the server.
#
# 			See SECTION 28.7.7.56, "MYSQL_REAL_ESCAPE_STRING_QUOTE()"
#
# 11.5.8 FETCHING SPATIAL DATA
#
# Geometry values stored in a table can be fetched in internal format.
# You can also convert them to WKT or WKB format.
#
# 		) Fetching spatial data in internal format:
#
# 			Fetching geometry values using internal format can be useful in table-to-table transfers:
#
# 				CREATE TABLE geom2 (g GEOMETRY) SELECT g FROM geom;
#
# 		) Fetching spatial data in WKT format:
#
# 			The ST_AsText() function converts a geometry from internal format to
# 			a WKT string.
#
# 				SELECT ST_AsText(g) FROM geom;
#
# 		) Fetching spatial data in WKB format:
#
# 			The ST_AsBinary() function converts a geometry from internal format to a BLOB
# 			containing the WKB value:
#
# 				SELECT ST_AsBinary(g) FROM geom;
#
# 11.5.9 OPTIMIZING SPATIAL ANALYSIS
#
# For MyISAM and InnoDB tables, search operations in columns containing spatial data
# can be optimized using SPATIAL indexes.
#
# The most typical operations are:
#
# 		) Point queries that search for all objects that contain a given point
#
# 		) Region queries that search for all objects that overlap a given region
#
# MySQL uses R-Trees with quadratic splitting for SPATIAL indexes on spatial columns.
#
# A SPATIAL index is built using the minimum bounding rectangle (MBR) of a geometry.
# For most geometries, the MBR is a minimum rectangle that surrounds the geometries.
#
# For a horizontal or a vertical linestring, the MBR is a rectangle degenrated into
# the linestring.
#
# For a point, the MBR is a rectangle degenerated into the point.
#
# It is also possible to create normal indexes on spatial columns.
#
# In a non-SPATIAL index, you must declare a prefix for any spatial column
# except for POINT columns.
#
# MyISAM and InnoDB support both SPATIAL and non-SPATIAL indexes.
#
# Other storage engines support non-SPATIAL indexes, as described in
# SECTION 13.1.15, "CREATE INDEX SYNTAX". 
#
# 11.5.10 CREATING SPATIAL INDEXES
#
# For InnoDB and MyISAM tables, MySQL can create spatial indexes using syntax similar
# to that for creating regular indexes, but using the SPATIAL keyword.
#
# Columns in spatial indexes must be declared NOT NULL.
#
# The following examples demonstrate how to create spatial indexes:
#
# 		) With CREATE_TABLE:
#
# 			CREATE TABLE geom (g GEOMETRY NOT NULL SRID 4326, SPATIAL INDEX(g));
#
# 		) With ALTER_TABLE:
#
# 			CREATE TABLE geom (g GEOMETRY NOT NULL SRID 4326);
# 			ALTER TABLE geom ADD SPATIAL INDEX(g);
#
# 		) With CREATE_INDEX:
#
# 			CREATE TABLE geom (g GEOMETRY NOT NULL SRID 4326);
# 			CREATE SPATIAL INDEX g ON geom (g);
#
# SPATIAL INDEX creates an R-tree index. 
#
# For storage engines that support nonspatial indexing of spatial columns, teh engine creates a B-tree index.
#
# A B-tree index on spatial values is useful for exact-value lookups, but not for range scans.
#
# The optimizer can use spatial indexes defined on columns that are SRID-restricted.
# For more information, see SECTION 11.5.1, "SPATIAL DATA TYPES", and SECTION 8.3.3, "SPATIAL INDEX OPTIMIZATION"
#
# For more information on indexing spatial columns, see SECTION 13.1.15, "CREATE INDEX SYNTAX"
#
# To drop spatial indexes, use ALTER_TABLE or DROP_INDEX:
#
# 		) With ALTER_TABLE:
#
# 				ALTER TABLE geom DROP INDEX g;
#
# 		) With DROP_INDEX:
#
# 				DROP INDEX g ON geom;
#
# Example: Suppose that a table geom contains more than 32,000 geometries, which are stored in the column
# g of type GEOMETRY.
#
# The table also has an AUTO_INCREMENT column fid for storing object ID values.
#
# 	DESCRIBE geom;
# 	+----------------+------------------+---------+--------+------------+----------------+
# 	| Field 			  | Type 				| Null 	 | Key 	 | Default    | Extra 			 |
# 	+----------------+------------------+---------+--------+------------+----------------+
# 	| fid 			  | int(11) 			| 			 | PRI 	 | NULL 		  | auto_increment |
# 	| g 				  | geometry 			| 			 | 		 | 			  | 					 |
# 	+----------------+------------------+---------+--------+------------+----------------+
#
# SELECT COUNT(*) FROM geom;
# 	+---------------+
# 	| count(*) 		 |
# 	+---------------+
# 	| 		32376 	 |
# 	+---------------+
# 	1 row in set (0.00 sec)
#
# To add a spatial index on the column g, use this statement:
#
# ALTER TABLE geom ADD SPATIAL INDEX(g);
# Query OK, 32376 rows affected (4.05 sec)
# Records: 32376  Duplicates: 0 Warnings: 0
#
# 11.5.11 USING SPATIAL INDEXES
#
# The optimizer investigates whether available spatial indexes can be involved in the search
# for queries that use a function such as MBRContains() or MBRWithin() in the WHERE clause.
#
# The following query finds all objects that are in the given rectangle:
#
# 		SET @poly =
# 		-> 'Polygon((30000 15000,
# 						 31000 15000,
# 						 31000 16000,
# 						 30000 16000,
# 						 30000 15000))';
# 		SELECT fid,ST_AsText(g) FROM geom WHERE 
# 		-> MBRContains(ST_GeomFromText(@poly),g);
# 		
#
# 		+-----+-----------------------------------------------------------------+
# 		| fid | ST_AsText(g) 									 								|
# 		+-----+-----------------------------------------------------------------+
# 		| 21  | LINESTRING(30350.4 15828.8, 30350.6 15845,30333.8 15845,30 ---  |
# 		| 22 	| etc.
# 		| | 	|
# 		  V
#
# 		20 rows in set (0.00 sec)
#
# Use EXPLAIN to check the way this query is executed:
#
# 		SET @poly =
# 		-> 'Polygon((30000 15000,
# 						 31000 15000,
# 						 31000 16000,
# 						 30000 16000,
# 						 30000 15000))';
# 		EXPLAIN SELECT fid,ST_AsText(g) FROM geom WHERE
# 		-> MBRContains(ST_GeomFromText(@poly),g)\G
# 		******************** 1. row ***********************
# 							id: 1
# 				select_type: SIMPLE
# 						table: geom
# 						 type: range
# 			possible_keys : g
# 						  key: g
# 					key_len : 32
# 						  ref: NULL
# 						 rows: 50
# 					   Extra: Using where
# 		1 row in set (0.00 sec)
#
# Check what would happen without a spatial index:
#
# 		SET @poly =
# 		-> 'Polygon((30000 15000,
# 						 31000 15000,
# 						 31000 16000,
# 						 30000 16000,
# 						 30000 15000))';
#		EXPLAIN SELECT fid,ST_AsText(g) FROM g IGNORE INDEX (g) WHERE
# 		-> MBRContains(ST_GeomFromText(@poly),g)\G
# 		******************** 1. row ************************'
# 							id: 1
# 				select_type: SIMPLE
# 					table   : geom
# 					    type: ALL
# 			possible_keys : NULL
# 						  key: NULL
# 					key_len : NULL
# 						  ref: NULL
# 						rows : 32376
# 					  Extra : Using where
# 		1 row in set (0.00 sec)
#
# Executing the SELECT statement without the spatial index yields the same result, but causes
# the execution time to rise from 0.00 sec to 0.46 seconds.
#
# 		SET @poly =
# 		-> 'Polygon((30000 15000,
# 						 31000 15000,
# 						 31000 16000,
# 						 30000 16000,
# 						 30000 15000))';
# 		SELECT fid,ST_AsText(g) FROM geom IGNORE INDEX (g) WHERE
# 		-> MBRContains(ST_GeomFromText(@poly),g);
# 		+-------+-------------------------
# 		| fid   | ST_AsText(g) 
# 		+-------+-------------------
# 		| 1 	  | LINESTRING(30250.4 15129.2, 30248.8 15138.4, 30238.2 15136 ---
# 		| 2 	  | etc ->
# 		| | 	  | 
# 		| V 	  |
# 
# 		20 rows in set (0.46 sec)
# 		
#
# 11.6 THE JSON DATA TYPE
#
# 		) CREATING JSON VALUES
#
# 		) NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES
#
# 		) SEARCHING AND MODIFYING JSON VALUES
#
# 		) COMPARISON AND ORDERING OF JSON VALUES
#
# 		) CONVERTING BETWEEN JSON AND NON-JSON VALUES
#
# 		) AGGREGATION OF JSON VALUES
#
# MySQL supports a native JSON data type defined by RFC 7159 taht enables efficient access to data in JSON
# (JavaScript Object Notation) documents.
#
# The JSON data type provides these advantages over storing JSON-format strings in a string column:
#
# 		) Automatic validation of JSON documents stored in JSON columns. Invalid documents produce an error.
#
# 		) Optimized storage format.
#
# 			JSON documents stored in JSON columns are converted to an internal format that permits quick read
# 			access to document elements.
#
# 			When the server later must be read a JSON value stored in this binary format, the value need not be 
# 			parsed from a text representation.
#
# 			The binary format is structured to enable the server to look up subobjects or nested values
# 			directly by key or array index without reading all values before or after them in the document.
#
# MySQL 8.0 also supports the JSON MERGE PATCH format defined in RFC 7396, using the JSON_MERGE_PATCH() function.
#
# See the description of this function, as well as NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES, for examples
# and furtehr information.
#
# NOTE:
#
# 		This discussion uses JSON in monotype to indicate specifically the JSON data type and "JSON" in regular font
# 		to indicate JSON data in general.
#
# The space required to store a JSON document is roughly the same as for LONGBLOB or LONGTEXT;
# See SECTION 11.8, "DATA TYPE STORAGE REQUIREMENTS", for more information.
#
# It is important to keep in mind that the size of any JSON document stored in a JSON column
# is limited to the value of the max_allowed_packet system variable.
#
# (When the server is manipulating a JSON value internally in memory, it can be larger than this;
# the limit applies when the server stores it).
#
# You can obtain the amount of space required to store a JSON document using the JSON_STORAGE_SIZE()
# function; note that for a JSON column, the storage size - and thus the value returned by ths function -
# is that used by column prior to any partial updates that may have been performed on it.
#
# (See the discussion of the JSON partial update optimization later in this section)
#
# A JSON column cannot have a default value.
#
# Along with the JSON data type, a set of SQL functions is available to enable operations on JSON
# values, such as creation, manipulation and searching.
#
# The following discussion shows examples of these operations.
#
# For details about individual functions, see SECTION 12.17, "JSON FUNCTIONS"
#
# A set of spatial functions for operating on GeoJSON values is also available.
# See SECTION 12.16.11, "SPATIAL GEOJSON FUNCTIONS"
#
# JSON columns, like columns of other binary types, are not indexed directly;
# instead, you can create an index on a generated column that extracts a scalar
# value from the JSON column.
#
# See INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX, for a detailed example.
#
# The MySQL optimizer also looks for compatible indexes on virtual columns that match
# JSON expressions.
#
# MySQL NDB Cluster 8.0 supports JSON columns and MySQL JSON functions, including creation
# of an index on a column generated from a JSON column as a workaround for being unable
# to index a JSON column.
#
# A maximum of 3 JSON columns per NDB table is supported.
#
# PARTIAL UPDATES OF JSON VALUES
#
# In MySQL 8.0, the optimizer can perform a partial, in-place update of a JSON
# column instead of removing the old document and writing the new document in its
# entirety to the column.
#
# This optimization can be peformed for an update that meets the following conditions:
#
# 		) The column being updated was declared as JSON
#
# 		) The UPDATE statement uses any of the three functions:
#
# 			JSON_SET()
#
# 			JSON_REPLACE()
#
#			JSON_REMOVE()
#
# 			to update the column.
#
# 			A direct assignment of the column value (for example, UPDATE mytable SET jcol = '{"a": 10, "b": 25'}) cannot be
# 			performed as a partial update.
#
# 			Updats of multiple JSON columns in a single UPDATE statement can be optimized in this fashion;
# 			MySQL can perform partial updates of only those columns whose values are updated using the
# 			three functions above.
#
# 		) The input column and the target column must be the same column; 
# 		  a statement such as UPDATE mytable SET jcol1 = JSON_SET(jcol2, '$.a', 100)
# 		 cannot be performed as a partial update.
#
# 			The update can use nested calls to any of the functions listed above,
# 			in any combination - as long as the input and target columns are the same.
#
# 		) All changes replace existing array or object values with new ones, and do not add any new elements
# 			to the parent object or array.
#
# 		) The value being replaced must be at least as large as the replacement value.
#
# 			In other words, the new value cannot be any larger than the old one.
#
# 			A possible exception to this requirement occurs when a previous partial update has
# 			left sufficient space for the larger value.
#
# 			You can use the function JSON_STORAGE_FREE() to see how much space has been freed
# 			by any partial updates of a JSON column.
#
# Such partial updates can be written to the binary log using a compact form that saves space;
# this can be enabled by setting the binlog_row_value_options system variable to PARTIAL_JSON.
#
# See the description of this variable ofr more information.
#
# The next few sections provide basic info regarding the creation and manipulation of JSON values.
#
# CREATING JSON VALUES
#
# A JSON array contains a list of values separated by commas and eclosed within { and } characters:
#
# 		["abc", 10, null, true, false]
#
# A JSON Object contains a set of key value pairs separated by commas enclosed with { and } characters:
#
# 		{"k1": "value", "k2": 10}
#
# As the examples illustrate, JSON arrays and objects can contain scalar values that
# are strings or numbers, the JSON null literal, or the JSON boolean true or false literals.
#
# Keys in JSON objects must be strings. Temporal (date, time, or datetime) scalar values
# are also permitted:
#
# 		["12:18:29.000000", "2015-07-29", "2015-07-29 12:18:29.000000"]
#
# Nesting is permitted within JSON array elements and JSON object key values:
#
# 		[99, {"id": "HK500", "cost": 75.99}, ["hot", "cold"]]
# 		{"k1": "value", "k2": [10, 20]}
#
# You can also obtain JSON values from a number of functions supplied by MySQL for this
# purpose (see SECTION 12.17.2, "FUNCTIONS THAT CREATE JSON VALUES") as well as by casting
# values of other types to the JSON type using CAST(value AS JSON)
#
# (see CONVERTING BETWEEN JSON AND NON-JSON VALUES)
#
# THe next paragraphs describes how MySQL handles JSON values provided as input.
#
# In MySQL, JSON values are written as strings.
#
# MySQL parses any string used in a context that requires a JSON value, and produces
# an error if it is not valid as JSON.
#
# These contexts include inserting a value into a column that has the JSON data type
# and passing an argument to a function that expects a JSON value (usually shown as
# json_doc or json_val in the documentation for MySQL JSON functions), as follows:
#
# 		) Attempting to insert a value into a JSON column succeeds if the value is a valid JSON value,
# 			but fails if it is not:
#
# 			CREATE TABLE t1 (jdoc JSON);
# 			Query OK, 0 rows affected (0.20 sec)
#
# 			INSERT INTO t1 VALUES('{"key1": "value1", "key2": "value2"}');
# 			Query OK, 1 row affected (0.01 sec)
#
# 			INSERT INTO T1 VALUES('[1, 2,');
# 			ERROR 3140 (22032) at line 2: Invalid JSON text:
# 			"Invalid value" at position 6 in value (or column) '[1, 2,'
#
# 			Positions for "at position N" in such error messages are 0-based, but should
# 			be considered rough indications of where the problem in a value actually occurs.
#
# 		) The JSON_TYPE() function expects a JSON argument and attempts to parse it into
# 			a JSON value.
#
# 			It returns the value's JSON type if it is valid and produces an error otherwise:
#
# 				SELECT JSON_TYPE('["a", "b", 1]');
# 				+---------------------------------+
# 				| JSON_TYPE('["a", "b", 1]') 		 |
# 			   +---------------------------------+
# 				| ARRAY 									 |
# 				+---------------------------------+
#
# 				SELECT JSON_TYPE('"hello"');
# 				+---------------------------+
# 				| JSON_TYPE('"hello"') 		 |
# 				+---------------------------+
# 				| STRING 						 |
# 				+---------------------------+
#
# 				SELECT JSON_TYPE('hello');
# 				ERROR 3146 (22032): Invalid data type for JSON data in argument 1
# 				to function json_type; a JSON string or JSON type is required.
#
# MySQL handles strings used in JSON context using the utf8mb4 character set and utf8mb4_bin
# collation.
#
# Strings in other character sets are converted to utf8mb4 as necessary.
# (For strings in  the ascii or utf8 character sets, no conversion is needed because ascii
# and utf8 are subsets of utf8mb4)
#
# As an alternative to writing JSON values using literal strings, functions exist for composing
# JSON values from component elements.
#
# JSON_ARRAY() takes a (possibly empty) list of values and returns a JSON array containing those
# values:
#
# 		SELECT JSON_ARRAY('a', 1, NOW());
# 		+----------------------------------------+
# 		| JSON_ARRAY('a', 1, NOW()) 			  	  |
# 		+----------------------------------------+
# 		| ["a", 1, "2015-07-27 09:43:47.000000"] |
# 		+----------------------------------------+
#
# JSON_OBJECT() takes a (possibly empty) list of key-value pairs and returns
# a JSON object containing those pairs:
#
# 		SELECT JSON_OBJECT('key1', 1, 'key2', 'abc');
# 		+-------------------------------------------+
# 		| JSON_OBJECT('key1', 1, 'key2', 'abc') 	  |
# 		+-------------------------------------------+
# 		| {"key1": 1, "key2": "abc"} 					  |
# 		+-------------------------------------------+
#
# JSON_MERGE_PRESERVE() takes two or more JSON documents and returns the combined result:
#
# 		SELECT JSON_MERGE_PRESERVE('["a", 1]', '{"key": "value"}');
# 		+---------------------------------------------------------+
# 		| JSON_MERGE_PRESERVE('["a", 1]', '{"key": "value"}') 	 |
# 		+---------------------------------------------------------+
# 		| ["a", 1, {"key": "value"}] 										 |
# 		+---------------------------------------------------------+
# 		1 row in set (0.00 sec)
#
# For information about the merging rules, see NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES.
#
# (MySQL 8.0.3 and later also support JSON_MERGE_PATCH(), which has somewhat different behavior.
#
# See JSON_MERGE_PATCH() COMPARED WITH JSON_MERGE_PRESERVE(), for information about the differences
# between these two functions.)
#
# JSON values can be assigned to user-defined variables:
#
# 		SET @j = JSON_OBJECT('key', 'value');
# 		SELECT @j;
# 		+----------------------+
# 		| @j 						  |
# 		+----------------------+
# 		| {"key": "value"} 	  |
# 		+----------------------+
#
# However, user-defined variables cannot be of JSON data type, so although @j in the preceding
# example looks like a JSON value and has the same character set and collation as a JSON value,
# it does NOT have the JSON data type.
#
# Instead, the result from JSON_oBJECT() is converted to a string when assigned to the variable.
#
# Strings produced by converting JSON values have a character set of utf8mb4 and a collation
# of utf8mb4_bin:
#
# 		SELECT CHARSET(@j), COLLATION(@j);
# 		+--------------+----------------+
# 		| CHARSET(@j)  | COLLATION(@j)  |
# 		+--------------+----------------+
# 		| utf8mb4 		| utf8mb4_bin 	  |
# 		+--------------+----------------+
#
# Because utf8mb4_bin is a binary collation, comparison of JSON values is case-sensitive.
#
# 		SELECT JSON_ARRAY('x') = JSON_ARRAY('X');
# 		+-------------------------------------------+
# 		| JSON_ARRAY('x') = JSON_ARRAY('X') 		  |
# 		+-------------------------------------------+
# 		| 							0 							  |
# 		+-------------------------------------------+
#
# Case sensitivity also applies to the JSON null, true, and false literals,
# which always must be written in lowercase:
#
# 		SELECT JSON_VALID('null'), JSON_VALID('Null'), JSON_VALID('NULL');
# 		+-----------------------+---------------------+------------------------+
# 		| JSON_VALID('null') 	| JSON_VALID('Null')  | JSON_VALID('NULL') 	  |
# 		+-----------------------+---------------------+------------------------+
# 		| 					1 			| 					0 		 | 				0 			  |
# 		+-----------------------+---------------------+------------------------+
#
# 		SELECT CAST('null' AS JSON);
# 		+-------------------------+
# 		| CAST('null' AS JSON) 	  |
# 		+-------------------------+
# 		| null 						  |
# 		+-------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT CAST('NULL' AS JSON);
# 		ERROR 3141 (22032): Invalid JSON text in argument 1 to function cast_as_json:
# 		"Invalid value." at position 0 in 'NULL'.
#
# Case sensitivity of the JSON literals differs from that of the SQL NULL, TRUE and FALSE
# literals, which can be written in any lettercase:
#
# 		SELECT ISNULL(null), ISNULL(Null), ISNULL(NULL);
# 		+----------------+----------------+------------------+
# 		| ISNULL(null)   | ISNULL(Null)   | ISNULL(NULL) 	  |
# 		+----------------+----------------+------------------+
# 		| 				1 	  | 			1 		 | 			1 		  |
# 		+----------------+----------------+------------------+
#
# Sometimes it may be necessary or desirable to insert quote characters (" or ') into a 
# JSON document.
#
# Assume for this example that you want to insert some JSON objects containing strings
# representing sentences that state some facts about MySQL, each paired with an appropriate
# keyword, into a table created using the SQL statement shown here:
#
# 		CREATE TABLE facts (sentence JSON);
#
# Among these keyword-sentence pairs is this one:
#
# 		mascot: The MySQL mascot is a dolphin named "sakila"
#
# On way to insert this as a JSON object into the facts table is to use the MySQL JSON_OBJECT() function.
# IN this case, you must escape each quote character using a backslash, as shown here:
#
# 		INSERT INTO facts VALUES
# 			(JSON_OBJECT("mascot", "Our mascot is a dolphin named \"Sakila\"."));
#
# THis does not work in the same way if you insert the value as a JSON object literal, in which case,
# you must use the double backslash escape sequence, like this:
#
# 		INSERT INTO facts VALUES
# 			('{"mascot": "Our mascot is a dolphin named \\"Sakila\\"."}');
#
# Using the double backslash keeps MySQL from performing escape sequence processing, and instead
# causes it to pass the string literal to the storage engine for processing.
#
# After inserting the JSON object in either of the ways just shown, you can see that the
# backslashes are present in the JSON column value by doing a simple SELECT, like this:
#
# 		SELECT sentence FROM facts;
# 		+---------------------------------------------------------+
# 		| sentence 												  				 |
# 		+---------------------------------------------------------+
# 		| {"mascot": "Our mascot is a dolphin named \"Sakila\"."} |
# 		+---------------------------------------------------------+
#
# To look up this particular sentence employing mascot as the key, you can use
# the column-path operator -> as shown, here:
#
# 		SELECT col->"$.mascot" FROM qtest;
# 		+--------------------------------------------------+
# 		| col->"$.mascot" 										   |
# 		+--------------------------------------------------+
# 		| "Our mascot is a dolphin named \"Sakila\"." 		|
# 		+--------------------------------------------------+
#
# THis leaves the backslashes intact, along with the surrounding quote marks.
#
# To display the desired value using mascot as the key, but without including the
# surrounding quote marks or any escapes, use the inline path operator ->>, like this: 
#
# 		SELECT sentence->>"$.mascot" FROM facts;
# 		+-----------------------------------------------+
# 		| sentence->>"$.mascot" 								|
# 		+-----------------------------------------------+
# 		| "Our mascot is a dolphin named "Sakila". 	   |
# 		+-----------------------------------------------+
#
# 
# NOTE:
#
# 		THe previous example does not work as shown if the NO_BACKSLASH_ESCAPES server SQL mode
# 		is enabled.
#
# 		If this mode is set, a single backslash instead of double backslashes can be used to
# 		insert the JSON object literal, and the backslashes are preserved.
#
# 		If you use the JSON_OBJECT() function when performing the insert and this mode is set,
# 		you must alternate single and double quotes, like this:
#
# 			INSERT INTO facts VALUES
# 			(JSON_OBJECT('mascot', 'Our mascot is a dolphin named "Sakila".'));
#
# 		See the description of the JSON_UNQUOTE() functions for more info about the effects
# 		of this mode on escaped characters in JSON values.
#
# NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES
#
# WHen a string is parsed and found ot be a valid JSON document, it is also normalized.
#
# THis means that members with keys that duplicate a key found later in the document,
# reading from left to right, are discarded.
#
# The object value produced by the following JSON_OBJECT() call includes only the second
# key1 element because that key name occurs earlier in the value, as shown here:
#
# 		SELECT JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def');
# 		+----------------------------------------------------------+
# 		| JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def') 	  |
# 		+----------------------------------------------------------+
# 		| {"key1": "def", "key2": "abc"} 								  |
# 		+----------------------------------------------------------+
#
# Normalization is also performed when values are inserted into JSON columns,
# as shown here:
#
# 		CREATE TABLE t1 (c1 JSON);
#
# 		INSERT INTO t1 VALUES
# 			('{"x": 17, "x": "red"}'),
# 			('{"x": 17, "x": "red", "x": [3, 5, 7]}');
#
# 		SELECT c1 FROM t1;
# 		+----------------------+
# 		| c1 						  |
# 		+----------------------+
# 		| {"x": "red"} 		  |
# 		| {"x": [3, 5, 7]} 	  |
# 		+----------------------+
#
# This "last duplicate key wins" behavior is suggested by RFC 7159 and is implemented by most JavaScript
# parsers. (BUG #86866, BUG #26369555)
#
# In versions of MySQL prior to 8.0.3, members with keys that duplicated a key found earlier
# in the document were discarded.
#
# The object value produced by the following JSON_OBJECT() call does not include the second
# key1 element because that key name occurs earlier in this value:
#
# 		SELECT JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def');
# 		+-----------------------------------------------------------+
# 		| JSON_OBJECT('key1', 1, 'key2', 'abc', 'key1', 'def') 		|
# 		+-----------------------------------------------------------+
# 		| {"key1": 1, "key2": "abc"} 										   |
# 		+-----------------------------------------------------------+
#
# Prior to MySQL 8.0.3, this "first duplicate key wins" normalization was also performed
# when inserting values into JSON columns.
#
# 		CREATE TABLE t1 (c1 JSON);
#
# 		INSERT INTO t1 VALUES
# 		> 			('{"x": 17, "x": "red"}'),
# 		> 			('{"x": 17, "x": "red", "x": [3, 5, 7]}');
#
# 		SELECT c1 FROM t1;
# 		+---------------------+
# 		| c1 						 |
# 		+---------------------+
# 		| {"x": 17} 			 |
# 		| {"x": 17}				 |
# 		+---------------------+
#
# MySQL also discards extra whitespace between keys, values or elements in the original JSON document.
#
# To make lookups more efficient, it also sorts the keys of a JSON object.
#
# You should be aware that hte result of this ordering is subject to change and not guaranteeed to be
# consistent across releases.
#
# MySQL functions that produce JSON values (see SECTION 12.17.2, "FUNCTIONS THAT CREATE JSON VALUES")
# always return normalized values.
#
# MERGING JSON VALUES
#
# Two merging algorithms are supported in MySQL 8.0.3 (and later), implemented by the functions JSON_MERGE_PRESERVE()
# and JSON_MERGE_PATCH().
#
# These differ in how they handle duplicate keys: JSON_MERGE_PRESERVE() retains values for duplicate keys,
# while JSON_MERGE_PATCH() discards all but the last value.
#
# The next few paragraphs explain how each of these two functions handles the merging
# of different combinations of JSON documents (that is, of objects and arrays)
#
# NOTE:
#
# 		JSON_MERGE_PRESERVE() is the same as the JSON_MERGE() function found in previous versions
# 		of MySQL (renamed in MySQL 8.0.3)
#
# 		JSON_MERGE() is still supported as an alias for JSON_MERGE_PRESERVE() in MySQL 8.0, but is
# 		deprecated and will be removed.
#
# MERGING ARRAYS.
#
# In contexts that combine multiple arrays, the arrays are merged into a single array.
# JSON_MERGE_PRESERVE() does this by concatenating arrays named later to the end of the first array..
#
# JSON_MERGE_PATCH() considers each argument as an array consisting of a single element
# (thus having 0 as its index) and then applies "last duplicate key wins" logic to select only
# the last argument.
#
# YOu can compare the results shown by this query:
#
# 		SELECT
# 			JSON_MERGE_PRESERVE('[1, 2]', '["a", "b", "c"]', '[true, false]') AS Preserve,
# 			JSON_MERGE_PATCH('[1, 2]', '["a", "b", "c"]', '[true, false]') AS Patch\G
# 		******************************** 1. row ************************************
# 		Preserve: [1, 2, "a", "b", "c", true, false]
# 			Patch: [true, false]
#
# Multiple objects when merged produce a single object.
#
# JSON_MERGE_PRESERVE() handles multiple objects having the same key by combining all
# unique values for that key in an array; this array is then used as the value for that key
# in the result.
#
# JSON_MERGE_PATCH() discards values for which duplicate keys are found, working from left
# to right, so that hte result contains only the last value for that key.
#
# THe following query illuistrates the difference in the results for the duplicate key a:
#
# 		SELECT
# 			JSON_MERGE_PRESERVE('{"a": 1, "b", 2}', '{"c": 3, "a": 4}', '{"c": 5, "d": 3}') AS Preserve,
# 			JSON_MERGE_PATCH('{"a": 3, "b": 2}', '{"c": 3, "a": 4}', '{"c": 5, "d": 3}') AS Patch\G
# 		******************************* 1. row ***************************************
# 		Preserve: {"a": [1,4], "b": 2, "c": [3, 5], "d": 3}
# 			Patch: {"a": 4, "b": 2, "c": 5, "d": 3}
#
# Nonarray values used in a context that requires an array value are autowrapped: The value is surrounded
# by [ and ] characters to convert it to an array.
#
# in the following statement, each argument is autowrapped as an array ([1], [2])
#
# These are then merged to produce a single result array; as in the previous two cases,
# JSON_MERGE_PRESERVE() combines values having the same key while JSON_MERGE_PATCH() dicards
# values for all duplicate keys except the last, as shown here:
#
# 		SELECT 
# 			JSON_MERGE_PRESERVE('1', '2') AS Preserve,
# 			JSON_MERGE_PATCH('1', '2') AS Patch\G
# 		*************************** 1. row ***************************
# 		Preserve: [1, 2]
# 			Patch: 2
#
# Array and object values are merged by autowrapping the object as an array and merging
# the arrays by combining values or by "last duplicate key wins" according to the choice of
# merging function (JSON_MERGE_PRESERVE() or JSON_MERGE_PATCH(), respectively), as can be seen
# in this example:
#
# 		SELECT
# 			JSON_MERGE_PRESERVE('[10, 20]', '{"a": "x", "b": "y"}') AS Preserve,
# 			JSON_MERGE_PATCH('[10,20]', '{"a": "x", "b": "y"}') AS Patch\G
# 		**************************** 1. row ****************************
# 		Preserve: [10, 20, {"a": "x", "b": "y"}]
# 			Patch: {"a": "x", "b": "y"}
#
# SEARCHING AND MODIFYING JSON VALUES
#
# A JSON path expression selects a value within a JSON document.
#
# Path expressions are useful with functions that extract parts of or modify a JSON document,
# to specify where within that document to operate.
#
# For example, the following query extracts from a JSON document the value of the member
# with the name key:
#
# 		SELECT JSON_EXTRACT('{"id": 14, "name": "Aztalan"}', '$.name');
# 		+-------------------------------------------------------------+
# 		| JSON_EXTRACT('{"id": 14, "name": "Aztalan"}', '$.name') 	  |
# 		+-------------------------------------------------------------+
# 		| "Aztalan" 																  |
# 		+-------------------------------------------------------------+
#
# Path syntax uses a leading $ char to represent the JSON document under consideration,
# optionally followed by selectors that indicate successively more specific parts of
# the document:
#
# 		) A period followed by a key name names the member in an object with the gven key.
#
# 			The key name must be specified within double quotation marks if the name
# 			without quotes is not legal within path expressions (for example, if it contains a space)
#
# 		) [N] appended to a path that selects an array names the value at position [N] within the array.
#
# 			Array positions work as per normal index accessing.
#
# 			If path does not select an array value, path[0] evaluates to the same as path:
#
# 				SELECT JSON_SET('"x"', '$[0]', 'a');
# 				+-----------------------------------+
# 				| JSON_SET('"x"', '$[0]', 'a') 		|
# 				+-----------------------------------+
# 				| "a" 										|
# 				+-----------------------------------+
# 				1 row in set (0.00 sec)
#
# 		) [M to N] specifies a subset or range of array values starting with the value at position M,
# 			and ending with the value at position N.
#
# 			last is supported as a synonym for the index of the rightmost array element.
#
# 			Rleative addressing of array elements is also supported.
#
# 			If path does not select an array value, path[last] evaluates
# 			to the same value as path,as shown later in this section. (SEE RIGHTMOST ARRAY ELEMENT)
#
# 		) Paths can contain * or ** wildcards:
#
# 			) .[*] evalutes to the values of all members in a JSON object.
#
# 			) [*] evaluates to the values of all elements in a JSON array.
#
# 			) prefix**suffix evalutes to all paths that begin with the named prefix and end with the named suffix.
#
# 		) Ap ath that does not exist in the document (evaluates to nonexistent data) evaluates to NULL.
#
# Let $ refer to this JSON array with three elements:
#
# 		[3, {"a": [5, 6], "b": 10}, [99, 100]]
#
# Then:
#
# 		) $[0] evaluates to 3
#
# 		) $[1] evaluates to {"a": [5,6], "b": 10}
#
# 		) $[2] evaluates to [99, 100]
#
# 		) $[3] evaluates to NULL (it refers to the fourth array element, which does not exist)
#
# Because $[1] and $[2] evaluate to nonscalar values, they can be used as the basis for more specific
# path expressions that select nested values.
#
# Examples:
#
# 		) $[1].a evaluates to [5,6]
#
# 		) $[1].a[1] evaluates to 6
#
# 		) $[1].b evaluates to 10
#
# 		) $[2][0] evaluates to 99
#
# As mentioned previously, path components that name keys msut be quoted if the unquoted key name is not legal
# in path expressions.
#
# Let $ refer to this value:
#
# 		{"a fish": "shark", "a bird": "sparrow"}
#
# The keys both contain a space and must be quoted:
#
# 		) $."a fish" evaluates to shark
#
# 		) $."a bird" evaluates to sparrow
#
# Paths that use wildcards evaluate to an array that can contain multiple values:
#
# 		SELECT JSON_EXTRACT('{"a": 1, "b": 2, "c": [3, 4, 5]}', '$.*');
# 		+--------------------------------------------------------------+
# 		| jSON_EXTRACT('{"a": 1, "b": 2, "c": [3,4,5]}', '$.*') 			|
# 		+--------------------------------------------------------------+
# 		| [1, 2, [3, 4, 5]] 														   |
# 		+--------------------------------------------------------------+
#
# 		SELECT JSON_EXTRACT('{"a": 1, "b": 2, "c": [3, 4, 5]}', '$.c[*]');
# 		+--------------------------------------------------------------+
# 		| JSON_EXTRACT('{"a": 1, "b": 2, "c": [3, 4, 5]}', '$.c[*]')	|
# 		+--------------------------------------------------------------+
# 		| [3, 4, 5] 																	|
# 		+--------------------------------------------------------------+
#
# In the following example, the path $**.b evaluates to multiple paths ($.a.b and $.c.b) and produces
# an array of the matching pattern values:
#
# 		SELECT JSON_EXTRACT('{"a": {"b": 1}, "c": {"b": 2}}', '$**.b');
# 		+------------------------------------------------------------+
# 		| JSON_EXTRACT('{"a": {"b": 1}, "c": {"b": 2}}', '$**.b') 	 |
# 		+------------------------------------------------------------+
# 		| [1, 2] 																	 |
# 		+------------------------------------------------------------+
#
# RANGES FROM ARRAYS.
#
# You can use ranges with the to keyword to specify subsets of JSON arrays.
#
# For example, $[1 to 3] includes the second, third and fourth elements of an array,
# as shown here:
#
# 		SELECT JSON_EXTRACT('[1, 2, 3, 4, 5]', '$[1 to 3]');
# 		+---------------------------------------------------+
# 		| JSON_EXTRACT('[1, 2, 3, 4, 5]', '$[1 to 3]') 		 |
# 		+---------------------------------------------------+
# 		| [2, 3, 4] 													 |
# 		+---------------------------------------------------+
# 		1 row in set (0.00 sec)
#
# The syntax is M to N, where M and N are, respectively, the first and last indexes of a range of elements
# from a JSON array.
#
# N must be greater than M, M must be greater than or equal to 0.
#
# Array elements are indexed beginning with 0.
#
# You can use ranges in contexts where wildcards are supported.
#
# RIGHTMOST ARRAY ELEMENT
#
# The last keyword is supported as a synonym for the index of the last element in an array.
#
# Expressions of the form lqst - N can be used for relative addressing, and within range
# definitons, like this:
#
# 		SELECT JSON_EXTRACT('[1, 2, 3, 4, 5]', '$[last-3 to last-1]');
# 		+------------------------------------------------------------+
# 		| JSON_EXTRACT('[1, 2, 3, 4, 5]', '$[last-3 to last-1]') 	 |
# 		+------------------------------------------------------------+
# 		| [2, 3, 4] 																 |
# 		+------------------------------------------------------------+
# 		1 row in set (0.01 sec)
#
# If the path is evaluated against a value that is not an array, the result of the evaluation
# is the same as if the value had been wrapped in a single-element array:
#
# 		SELECT JSON_REPLACE('"Sakila"', '$[last]', 10);
# 		+---------------------------------------------+
# 		| JSON_REPLACE('"Sakila"', '$[last]', 10) 	 |
# 		+---------------------------------------------+
# 		| 10 														 |
# 		+---------------------------------------------+
# 		1 row in set (0.00 sec)
#
# You can use column->path with a JSON column identifier and JSON path expression
# as a synonym for JSON_EXTRACT(column, path)
#
# See SECTION 12.17.3, "FUNCTIONS THAT SEARCH JSON VALUES" FOR MORE INFO.
#
# See also INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX.
#
# Some functions take an existing JSON document, modify it in some way, and return the
# resulting modified document.
#
# Path expressions indicate where in teh document to make changes.
#
# For example:
#
# 		JSON_SET()
#
# 		JSON_INSERT()
#
# 		JSON_REPLACE()
#
# functions each take a JSON document, plus one or more path-value pairs that describe
# where to modify the document and the values to use.
#
# The functions differi n how they handle existing and nonexisting values within the document.
#
# Consider this document:
#
# 		SET @j = '["a", {"b": [true, false]}, [10, 20]]';
#
# JSON_SET() replaces values for paths that exist and adds values for paths
# that do not exist:
#
# 		SELECT JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2);
# 		+-------------------------------------------------+
# 		| JSON_SET(@j, '$[1].b[0]', 1, '$[2][2]', 2) 	  |
# 		+-------------------------------------------------+
# 		| ["a", {"b": [1, false]}, [10, 20, 2]] 			  |
# 		+-------------------------------------------------+
#
# In this case, the path $[1].b[0] selects an existing value (true), which is
# replaced with the value following the path argument(1)
#
# The path $[2][2] does not exist, so the corresponding value(2) is added to the
# value selected by [2]
#
# JSON_INSERT() adds new values but does not replace existing values:
#
# 		SELECT JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2);
# 		+---------------------------------------------------+
# 		| JSON_INSERT(@j, '$[1].b[0]', 1, '$[2][2]', 2) 	 |
# 		+---------------------------------------------------+
# 		| ["a", {"b": [true, false]}, [10, 20, 2]] 		    |
# 		+---------------------------------------------------+
#
# JSON_REPLACE() replaces existing values and ignores new values:
#
# 		SELECT JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2);
# 		+----------------------------------------------------+
# 		| JSON_REPLACE(@j, '$[1].b[0]', 1, '$[2][2]', 2) 	  |
# 		+----------------------------------------------------+
# 		| ["a", {"b": [1, false]}, [10, 20]] 					  |
# 		+----------------------------------------------------+
#
# THe path-value pairs are evaluated left to right. The document produced by
# evaluating one pair becomes the new value against which the next pair is evaluated.
#
# JSON_REMOVE() takes a JSON document and one or more paths that specify values to be
# removed from the document.
#
# The return value is the original document minus the values selected by paths that exist
# within the document:
#
# 		SELECT JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]');
# 		+------------------------------------------------------+
# 		| JSON_REMOVE(@j, '$[2]', '$[1].b[1]', '$[1].b[1]') 	 |
# 		+------------------------------------------------------+
# 		| ["a", {"b": [true]}] 											 |
# 		+------------------------------------------------------+
#
# The path have these effects:
#
# 		) $[2] matches [10, 20] and removes it.
#
# 		) The first instance of $[1].b[1] matches false in the b element and removes it.
#
# 		) The second instance of $[1].b[1] matches nothing. That element has already been removed,
# 			the path no longer exists, and has no effect.
#
# CCOMPARISON AND ORDERING OF JSON VALUES
#
# JSON values can be compared using the =, <,<=, >, >=, <>, !=, and <=> operators.
#
# The following comparison operators and functions are not yet supported with JSON values:
#
# 		) BETWEEN
#
# 		) IN()
#
# 		) GREATEST()
#
# 		) LEAST()
#
# A workaround for the comparison operators and functions just listed is to cast JSON values
# to a native MySQL numeric or string data type so they have a consistent non-JSON scalar type.
#
# Comparison of JSON values takes place at two levels.
#
# The first level of comparison is based on the JSON types of the compared values.
#
# If the types differ, the comparison result is determined solely by which type has higher
# precedence.
#
# If the two values have the same JSON type, a second level of comparison occurs using
# type-specific rules.
#
# The following list shows the precedences of JSON types, from highest precedence to the lowest.
# (The type names are those returned by the JSON_TYPE() function)
#
# Types shown together on a line have the same precedence.
#
# Any value having a JSON type listed earlier in the list compares greater than any value having
# a JSON type listed later in the list.
#
# BLOB
# BIT
# OPAQUE
# DATETIME
# TIME
# DATE
# BOOLEAN
# ARRAY
# OBJECT
# STRING
# INTEGER, DOUBLE
# NULL
#
# For JSON values of the same precedence, the comparison rules are type specific:
#
# 		) BLOB
#
# 			The first N bytes of the two values are compared, where N is the number of bytes in teh shorter value.
#
# 			If the first N bytes of the two values are identical, the shorter value is ordered before the longer value.
#
# 		) BIT
#
# 			Same rules as for BLOB.
#
# 		) OPAQUE
#
# 			Same rule as for BLOB. OPAQUE values are values that are not classified as one of the other types.
#
# 		) DATETIME
#
# 			A value that represent an earlier point in time is ordered before a value that represents a later point in time.
#
# 			If two values originally come from the MySQL DATETIME and TIMESTAMP types, respectively,
# 			they are equal if they represent the same point in time.
#
# 		) TIME
#
# 			The smaller of two time values is ordered before the larger one.
#
# 		) DATE
#
# 			The earlier data is ordered before the more recent date.
#
# 		) ARRAY
#
# 			Two JSON arrays are equal if they have the same length and values in corresponding positions
# 			in the arrays are equal.
#
# 			If the arrays are not equal, their order is determined by the elements in the first position where
# 			there is a difference.
#
# 			The array with the smaller value in that position is ordered first.
#
# 			If all values of the shorter array are equal to the corresponding values in the longer array,
# 			the shorter array is ordered first.
#
# 			Example:
#
# 				[] < ["a"] < ["ab"] < ["ab", "cd", "ef"] < ["ab", "ef"]
#
# 		) BOOLEAN
#
# 			The JSON false literal is less than the JSON true literal
#
# 		) OBJECT
#
# 			Two JSON objects are equal if they have the same set of keys, and
# 			each key has the same value in both objects.
#
# 			Example:
#
# 				{"a": 1, "b": 2} = {"b": 2, "a": 1}
#
# 			The order of two objects that are not equal is unspecified but determinsitic.
#
# 		) STRING
#
# 			Strings are ordered lexically on the first N bytes of the utf8mb4 representation
# 			of the two strings being compared, where N is the length of the shorter string.
#
# 			If the first N bytes of the two strings are identical, the shorter string is considered
# 			smaller than the longer string.
#
# 			Example:
#
# 				"a" < "ab" < "b" < "bc"
#
# 			This ordering is equivalent to the ordering of SQL strings with collation utf8mb4_bin
#
# 			Because utf8mb4_bin is a binary collation, comparison of JSON values is case-sensitive:
#
# 				"A" < "a"
#
# 		) INTEGER, DOUBLE
#
# 			JSON values can contain exact-value numbers and approximate-value numbers.
# 			For a general discussion of these types of numbers, see SECTION 9.1.2, "NUMERIC LITERALS"
#
# 			The rules for comparing native MySQL numeric types are discussed in SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION",
# 			but the rules for comparing numbers within JSON values differ somewhat:
#
# 				) In a comparison between two columns that use the native MySQL INT and DOUBLE numeric types, respectively,
# 					it is known that all comparisons involve an integer and a double, so the integer is converted to double
# 					for all rows.
#
# 					That is, exact-value numbers are converted to approximate-value numbers.
#
# 				) On the other hand, if the query compares two JSON columns containing numbers, it cannot be known
# 					in advance whether numbers will be integer or double.
#
# 					To provide the most consistent behavior across all rows, MySQL converts approximate-value numbers
# 					to exact-value numbers.
#
# 					The resulting ordering is consistent and does not lose precision for the exact-value numbers.
# 					
#
# 			Were JSON comparisons to use the non-JSON numeric comparison rules, inconsistent ordering could occur.
#
# 			The usual MySQL comparison rules for numbers yield these orderings:
#
# 				) Integer comparison:
#
# 					1 < 2 < 3 (where doubles would be not defined)
#
# 				) Double comparison:
#
# 					Inconsistent
#
# For comparison of any JSON value to SQL NULL the result is UNKNOWN.
#
# For comparison of JSON and non-JSON values, the non-JSON value is converted to JSON according
# to the rules in the following table, then the values compared as described previously.
#
# CONVERTING BETWEEN JSON AND NON-JSON VALUES
#
# The following table provides a summary of the rules that MySQL follows when casting between
# JSON values and values of other types:
#
# 		TABLE 11.3 JSON CONVERISON RULES
#
# 		OTHER TYPE 					CAST(other type AS JSON) 						CAST(JSON AS other type)
#
# 		JSON 							No change 											No change
#
# 		utf8 char type 			The string is parsed into 						The JSON value is serialized into a utf8mb4 string.
# 		(utf8mb4, utf8, ascii)  a JSON value.
#
# 		Other character 			Other char encodings are treated
# 		types 						implicitly and converted to utf8mb4 		The JSON value is serialized to a utf8mb4, then cast to other
#	 																							character encodings. The result may not be meaningful.
#
# 		NULL 							Results in a NULL value of type JSON 		N/A
#
# 		Geometry types 			The geometry value is converted into  		Illegal operation. Workaround: Pass the result of CAST(json val AS CHAR) 
# 										a JSON document by calling ST_AsGeoJSON() to ST_GeomFromGeoJSON()
#
# 		All other types 			Results in a JSON document consisting 		Succeeds if the JSON document consists of a single scalar value of the
# 										of a single scalar value. 						target type and that scalar value can be cast to the target type. (Otherwise NULL and Warning)
#
# ORDER BY and GROUP BY for JSON values works according to these principles:
#
# 		) Ordering of scalar JSON values uses the same rules as in the preceding discussion.
#
# 		) For ascending sorts, SQL NULL orders before all JSON values, including the JSON null literal;
# 			for descending sorts, SQL NULL orders after all JSON values, including the JSON null literal.
#
# 		) Sort keys for JSON values are bound by the value of the max_sort_length system variable,
# 			so keys that differ only after the first max_sort_length bytes compare as equal.
#
# 		) Sorting of nonscalar values is not currently supported and a warning occurs.
#
# For sorting, it can be beneficial to cast a JSON scalar to some other native MySQL type.
#
# For example, if a column named jdoc contains JSON objects having a member consisting of an
# an id key and a nonnegative value, use this expression to sort by id values:
#
# 		ORDER BY CAST(JSON_EXTRACT(jdoc, '$.id') AS UNSIGNED)
#
# If there happens to be a generated column defined to use the same expression as in the ORDER BY,
# the MySQL optimizer recognizes that and considers using the index for the query execution plan.
#
# See SECTION 8.3.11, "OPTIMIZER USE OF GENERATED COLUMN INDEXES"
#
# AGGREGATION OF JSON VALUES
#
# For aggregation of JSON values, SQL NULL values are ignored as for other data types.
#
# Non-NULL values are converted to a numeric type and aggregated, except for MIN(), MAX() and GROUP_CONCAT().
#
# The conversion to number should produce a meaningful result for JSON values that are numeric scalars,
# although (depending on the values) truncation and loss of precision may occur.
#
# Conversion to number of other JSON values may not produce a meaningful result.
#
# 11.7 DATA TYPE DEFAULT VALUES
#
# Data type specifications can have explicit or implicit default values.
#
# A DEFAULT value clause in a data type specificaiton explicitly indicates a default
# value for a column.
#
# Examples:
#
# 		CREATE TABLE t1 (
# 			i 		INT DEFAULT -1,
# 			c 		VARCHAR(10) DEFAULT '',
# 			price DOUBLE(16,2) DEFAULT 0.00
# 		);
#
# SERIAL DEFAULT VALUE is a special case.
# In the definition of an integer column, it is an alias for NOT NULL AUTO_INCREMENT UNIQUE.
#
# Some aspects of explicit DEFAULT clause handling are version dependent, as described following:
#
# 		) Handling of Explicit Defaults as of MySQL 8.0.13
# 
# 		) Handling of Explicit Defaults Prior to MySQL 8.0.13
#
# 		) Handling of Implicit Defaults
#
# HANDLING OF EXPLICIT DEFAULTS AS OF MySQL 8.0.13
#
# The default value specified in a DEFAULT caluse can be a literal constant or an expression.
#
# With one exception, enclose expression default values within parantheses to
# distinguish them from literal constant default values.
#
# Examples:
#
# 		CREATE TABLE t1 (
# 			-- literal defaults
# 			i INT 			DEFAULT 0,
# 			c VARCHAR(10) 	DEFAULT '',
# 			-- expression defaults
# 			f FLOAT 			DEFAULT (RAND() * RAND()),
# 			b BINARY(16) 	DEFAULT (UUID_TO_BIN(UUID())),
# 			d DATE 			DEFAULT (CURRENT_DATE + INTERVAL 1 YEAR),
# 			p POINT 			DEFAULT (Point(0, 0)),
# 			j JSON 			DEFAULT (JSON_ARRAY())
# 		);
#
# The exception is that, for TIMESTAMP and DATETIME columns, you can specify the
# CURRENT_TIMESTAMP function as the default, without enclosing parentheses.
#
# See SECTION 11.3.5, "AUTOMATIC INITIALIZATION AND UPDATING FOR TIMESTAMP AND DATETIME"
#
# The BLOB, TEXT, GEOMETRY and JSON data types can be assigned a default value only if
# the value is written as an expression, even if the expression value is a literal:
#
# 		) This is permitted (literal default specified as expression):
#
# 			CREATE TABLE t2 (b BLOB DEFAULT ('abc'));
#
# 		) This produces an error (literal default not specified as expression):
#
# 			CREATE TABLE t2 (b BLOB DEFAULT 'abc');
#
# Expression default values must adhere to the following rules.
# An error occurs if an expression contains disallowed constructs.
#
# 		) Literals, built-in functions (both deterministic and nondeterministic), and operators are permitted.
#
# 		) Subqueries, parameters, variables, stored functions, and user-defined functions are not permitted.
#
# 		) An expression default value cannot depend on a column that has the AUTO_INCREMENT attribute
#
# 		) An expression default value for one column can refer to other table columns, with the exception that
# 			references to generated columns or columns with expression default values must be to columns that occur
# 			earlier in the table definition.
#
# 			That is, expression default values cannot contain forward references to generated columns or columns
# 			with expression default values.
#
# 			The ordering constraint also applies to the use of ALTER_TABLE to reorder table columns.
#
# 			If the resulting table would have an expression default value that contains a forward reference
# 			to a generated column or column with an expression default value, the statment fails.
#
# 			NOTE:
#
# 				If any component of an expression default value depends on the SQL mode, different
# 				results may occur for different uses of the table unless the SQL mode is the same during
# 				all uses.
#
# For CREATE_TABLE_---_LIKE and CREATE_TABLE_---_SELECT, the destination table preserves expression default
# values from the original table.
#
# If an expression default value refers to a nondeterministic function, any statement that causes the expression
# to be evaluated is unsafe for statement-based replication.
#
# This includes statements such as INSERT, UPDATE and ALTER_TABLE.
#
# When inserting a new row, the default value for a column with an expression default can be inserted either by
# omitting the column name or by specifying the column as DEFAULT (just as for columns with literal defaults):
#
# 		CREATE TABLE t4 (uid BINARY(16) DEFAULT (UUID_TO_BIN(UUID())));
# 		INSERT INTO t4 () VALUES();
# 		INSERT INTO t4 () VALUES(DEFAULT);
#
# 		SELECT BIN_TO_UUID(uid) AS uid FROM t4;
# 		+----------------------------------------+
# 		| uid 											  |
# 		+----------------------------------------+
# 		| f1109174-94c9-11e8-971d-3bf1095aa633   |
# 		| f110cf9a-94c9-11e8-971d-3bf1095aa633   |
# 		+----------------------------------------+
#
# However, the use of DEFAULT(col name) to specify the default value for a named column is permitted only
# for columns that have a literal default value, not for columns that have an expression default value.
#
# Not all storage engines permit expression default values. For those that do not, an ER_UNSUPPORTED_ACTION_ON_DEFAULT_VAL_GENERATED
# error occurs.
#
# If a default value evaluates to a data type that differs from the declared column type, implicit coercion to the declared
# type occurs according to the usual MySQL type-conversion rules.
#
# See SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION"
#
# HANDLING OF EXPLICIT DEFAULTS PRIOR TO MYSQL 8.0.13
#
# With one exception, the default value specified in a DEFAULT clause must be a literal constant;
# it cannot be a function or an expression.
#
# This means, for example, that you cannot set the default for a date column to be the value of a 
# function such as NOW() or CURRENT_DATE.
#
# The exception is that, for TIMESTAMP and DATETIME columns, you can specify CURRENT_TIMESTAMP as
# the default.
#
# See SECTION 11.3.5, "AUTOMATIC INITIALIZATION AND UPDATING FOR TIMESTAMP AND DATETIME"
#
# The BLOB, TEXT, GEOMETRY, and JSON data types cannot be assigned a default value.
#
# If a default value evaluates to a data type that differs from the declared column type,
# implicit coercion to the declared type occurs according to the usual MySQL type-conversion
# rules.
#
# See SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION"
#
# HANDLING OF IMPLICIT DEFAULTS
#
# If a data type specification includes no explicit DEFAULT value, MySQL determines
# the default value as follows:
#
# If the column can take NULL as a value, the column is defined with an explicit DEFAULT NULL clause.
#
# IF the column cannot take NULL as a value, MySQL defines the column with no explicit DEFAULT clause.
# Exception:
#
# 		If the column is defined as part of a PRIMARY KEY but not explicitly as NOT NULL, MySQL creates
# 		it as a NOT NULL column (because PRIMARY KEY columns must be NOT NULL)
#
# For data entry into a NOT NULL column that has no explicit DEFAULT clause, if an INSERT or REPLACE
# statement includes no value for the column, or an UPDATE statement sets the column to NULL,
# MySQL handles the column according to the SQL mode in effect at the time:
#
# 		) If strict SQL mode is enabled, an error occurs for transactional tables and the statement
# 			is rolled back.
#
# 			For nontransactional tables, an error occurs, but if this happens for the second
# 			or subsequent row of a multiple-row statement, the preceding rows will have been inserted.
#
# 		) If strict mode is not enabled, MySQL sets the column to the implicit default value for the column data type.
#
# Suppose that a table t is defined as follows:
#
# 		CREATE TABLE t (i INT NOT NULL);
#
# In this case, i has no explicit default, so in strict mode each of the following statements produce
# an error and no row is inserted.
#
# When not using strict mode, only the third statement produces an error; the implicit default is inserted
# for the first two statements, but the third fails because DEFAULT(i) cannot produce a value:
#
# 		INSERT INTO t VALUES();
# 		INSERT INTO t VALUES(DEFAULT);
# 		INSERT INTO t VALUES(DEFAULT(i));
#
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# For a given table, the SHOW_CREATE_TABLE statement displays which columns have an explicit DEFAULT clause.
#
# Implicit defaults are defined as follows:
#
# 		) For numeric types, the default is 0, with the exception that for integer or floating-point types declared
# 			with the AUTO_INCREMENT attribute, the default is the next value in the sequence.
#
# 		) For date and time types other than TIMESTMAP, the default is the appropriate "zero" value for the type.
#
# 			This is also true for TIMESTAMP if the explicit_defaults_for_timestamp system variable is enabled
# 			(See SECTION 5.1.8, "SERVER SYSTEM VARIABLES").
#
# 			Otherwise, for the first TIMESTAMP column in a table, the default value is the current
# 			date and time. See SECTION 11.3, "DATE AND TIME TYPES"
#
# 		) For string types other than ENUM, the default value is the empty string..
#
# 			For ENUM, the default is the first enumeration value.
#
# 11.8 DATA TYPE STORAGE REQUIREMENTS
#
# 		) INNODB TABLE STORAGE REQUIREMENTS
#
# 		) NDB TABLE STORAGE REQUIREMENTS
#
# 		) NUMERIC TYPE STORAGE REQUIREMENTS
#
# 		) DATE AND TIME TYPE STORAGE REQUIREMENTS
#
# 		) STRING TYPE STORAGE REQUIREMENTS
#
# 		) SPATIAL TYPE STORAGE REQUIREMENTS
#
# 		) JSON STORAGE REQUIREMENTS
#
# The storage requirements for table data on disk depend on several factors.
#
# Different storage engines represent data types and store raw data differently.
# 
# Table data might be compressed, either for a column or an entire row, complicating
# the calculation of storage requirements for a table or column.
#
# Despite differences in storage layout on disk, the internal MySQL APIs that communicate
# and exchange information about table rows use a consistent data structure that applies
# across all storage engines.
#
# This section includes guidelines and information for the storage requirements for each data
# type supported by MySQL, including the internal format and size for storage engines that
# use a fixed-size representation for data types.
#
# Information is listed by category or storage engine.
#
# The internal representation of a table has maximum row size of 65,535 bytes, even if the storage
# engine is capable of supporting larger rows.
#
# This figure excludes BLOB or TEXT columns, which contribute only 9 to 12 bytes toward thi sisze.
#
# For BLOB and TEXT data, the information is stored internally in a different area of memory than
# the row buffer.
#
# Different storage engines handle the allocation and storage of this data in different ways, according
# to the method they use for handling the corresponding types.
#
# For more information, see CHAPTER 16, ALTERNATIVE STORAGE ENGINES, and SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND RWO SIZE"
#
# INNODB TABLE STORAGE REQUIREMENTS
#
# See SECTION 15.10, "INNODB ROW FORMATS" for information about storage requirements for InnoDB tables
#
# NDB TABLE STORAGE REQUIREMENTS
#
# 		IMPORTANT:
#
# 			NDB tables use 4-byte alignment; all NDB data storage is done in multiples of 4 bytes.
#
# 			Thus, a column value that would typically take 15 bytes, requires 16 bytes in an NDB table.
#
# 			For example, in NDB tables, teh TINYINT, SMALLINT, MEDIUMINT, and INTEGER(INT) column types
# 			each require 4 bytes storage per record due to the alignment factor.
#
# 			Each BIT(M) column takes M bits of storage space.
#
# 			 Although an individual BIT column is NOT 4-byte aligned, 
# 			NDB reserves 4 bytes (32 bits) per row for the first 1-32 bits needed for BIT columns,
# 			then another 4 bytes for bits 33-64, and so on.
#
#  		While a NULL itself does not require any storage space, NDB reserves 4 bytes per row if
# 			the table definition contains any columns allowing NULL, up to 32 NULL columns.
#
# 			(If an NDB Cluster table is defined with more than 32 NULL columns up to 64 NULL
# 			columns, then 8 bytes per row are reserved)
#
# Every table using the NDB storage engine requires a primary key; if you do not define a primary
# key, a "hidden" primary key is created by NDB.
#
# THis hidden primary key consumes 31-35 bytes per table record.
#
# You can use the ndb_size.pl Perl script to estimate NDB storage requirements. It connects
# to a current MySQL (not NDB cluster) database and creates a report on how much space that database
# would require if it used the NDB storage engine.
#
# See SECTION 22.4.29, "NDB_SIZE.PL -- NDBCLUSTER SIZE REQUIREMENTS ESTIMATOR" for more information.
#
# NUMERIC TYPE STORAGE REQUIREMENTS
#
# DATA TYPE 				STORAGE REQUIRED
#
# TINYINT 					1 byte
#
# SMALLINT 					2 bytes
#
# MEDIUMINT 				3 bytes
#
# INT, INTEGER 			4 bytes
#
# BIGINT 					8 bytes
#
# FLOAT(p) 					4 bytes if 0 <= p <= 24, 8 bytes if 25 <= 25 <= 53
#
# FLOAT 						4 bytes
#
# DOUBLE [PRECISION],  	8 bytes
# REAL 
#
# DECIMAL(M,D), 			Varies, see following
# NUMERIC(M,D)
#
# BIT(M) 					approximately (M+7)/8 bytes
#
# Values for DECIMAL (and NUMERIC) columns are represented using a bianry format that packs
# nine decimal (base 10) digits into four bytes.
#
# Storage for the integer and fractional parts of each value are determined separately.
#
# Each multiple of nine digits requires four bytes, and the "leftover"  digits require some
# fraction of four bytes.
#
# The storage required ofr excess digits is given by the following table:
#
#
#
# 	LEFTOVER DIGITS 					NUMBER OF BYTES
#
# 	0 										0
#
# 	1 										1
#
# 	2 										1
#
# 	3 										2
#
# 	4 										2
#
# 	5 										3
#
# 	6 										3
#
# 	7 										4
#
# 	8 										4
#
#
# DATE AND TIME TYPE STORAGE REQUIREMENTS
#
# For TIME, DATETIME and TIMESTAMP columns, the storage required for tables created before MySQL
# 5.6.4 differs from tables created from 5.6.4 on.
#
# This is due to a change in 5.6.4 that permits these types to have a fractional part, which
# reuqires from 0 to 3 bytes.
#
# 	DATA TYPES 		STORAGE REQUIRED PRE 5.6.4 	STORAGE REQUIRED POST 5.6.4
#
# 	YEAR 				1 byte 								1 byte
#
# 	DATE 				3 bytes 								3 bytes
#
# 	TIME 				3 bytes 								3 bytes + fractional seconds storage
#
#  DATETIME 		8 bytes 								5 bytes + fractional seconds storage
#
#  TIMESTAMP 		4 bytes 								4 bytes + fractional seconds storage
#
# As of MySQL 5.6.4, storage for YEAR and DATE remains unchanged.
#
# However, TIME, DATETIME and TIMESTAMP are represented differently.
#
# DATETIME is packed more efficiently, requiring 5 rather than 8 bytes for the
# nonfractional part, and all three parts have a fractional part that requires
# from 0 to 3 bytes, depending on the fractional seconds precision of stored values.
#
# FRACTIONAL SECONDS PRECISION 		STORAGE REQUIRED
#
# 0 											0 bytes
#
# 1,2 										1 byte
#
# 3,4 										2 bytes
#
# 5,6 										3 bytes
#
# For example, TIME(0), TIME(2), TIME(4), and TIME(6) use 3,4,5 and 6 bytes, respectively.
#
# TIME and TIME(0) are equivalent and require the same storage.
#
# For details about internal representation of temporal values, see MySQL INTERNALS: IMPORTANT ALGORITHMS AND STRUCTURES.
#
# STRING TYPE STORAGE REQUIREMENTS
#
# In the following table, M represents the declared column length in characters for nonbinary string
# types and bytes for binary string types.
#
# L represents the actual length in bytes of a given string value.
#
# 		DATA TYPE 							REQUIRED
#
# 	CHAR(M) 						The compact family of INnoDB row formats optimize storage for variable-length character sets.
# 									See COMPACT ROW FORMAT STORAGE CHARACTERISTICS.
#
# 									Otherwise, M x w bytes, <= M <= 255, where w is the number of bytes required for
# 									the maximum length character in the character set.
#
# 	BINARY(M) 					M bytes, 0 <= M <= 255
#
# 	VARCHAR(M), 				L + 1 bytes if column values require 0 - 255 bytes, 
# 	VARBINARY(M)  				L + 2 bytes if values may require more than 255 bytes.
#
# 	TINYBLOB,TINYTEXT 		L + 1 bytes, where L < 2^8
#
# 	BLOB, TEXT 					L + 2 bytes, where L < 2^16
#
# 	MEDIUMBLOB, 				L + 3 bytes, where L < 2^24
# 	MEDIUMTEXT
#
# 	LONGBLOB, 					L + 4 bytes, where L < 2^32
# 	LONGTEXT
#
# 	ENUM('value1', 			1 or 2 bytes, depending on the number of enumeration values (65,535 values maximum) 
# 	'value2', ---)
#
#  SET('value1', 				1,2,3,4 or 8 bytes, depending on the number of set members (64 members maximum)
# 	'value2', ---)
#
# Variable-length string types are stored using a length prefix plus data.
#
# THe length prefix requires from one to four bytes depending on the data type, and the value of the 
# prefix is L (the byte length of the string)
#
# For example, storage for a MEDIUMTEXT value requires L bytes to store the value plus three bytes
# to store the length of the value.
#
# To calculate the number of bytes used to store a particular CHAR, VARCHAR or TEXT column value, you must
# take into account the character set used for that column and whether the value contains multibyte characters.
#
# IN particular, when using a utf8 Unicode character set, you must keep in mind that not all characters use
# the same number of bytes.
#
# Utf8mb3 and utf8mb4 character sets can require up to three and four bytes per character, respectively.
#
# For a breakdown of the storage used for different categories of utf8mb3 or utf8mb4 characters,
# see SECTION 10.9, "UNICODE SUPPORT"
#
# VARCHAR, VARBINARY and the BLOB and TEXT types are variable-length types.
# For each, the storage requirements depend on these factors:
#
# 		) The actual length of the column value
#
# 		) The column's maximum possible length
#
# 		) The character set used for the column, because some character sets contain multibyte characters
#
# For example, a VARCHAR(255) column can hold a string with a maximum length of 255 characters.
#
# Assuming that the column uses the latin1 character set (one byte per character), the actual stoage
# required is the length of the String (L), plus one byte to record the length of the string.
#
# For the string, 'abcd', L is 4 and the storage requirement is 5 bytes.
#
# If the same column is instead declared to use the ucs2 double-byte character set, the storage
# requirement is 10 bytes:
#
# 		THe length of 'abcd' is eight bytes and the column requires two bytes to store lengths
# 		because the maximum length is greater than 255 (up to 510 bytes)
#
# THe efective maxixmum number of bytes that can be stored in a VARCHAR or VARBINARY column 
# is subject to the row size of 65,535 bytes, which is shared among all columns.
#
# For a VARCHAR column that stores multibyte characters, the effective maximum number of characters
# is less.
#
# For example, utf8mb4 characters can require up to four bytes per character.
#
# So a VARCHAR column that uses the utf8mb4 character set can be declared to be a maxximum of
# 16,383 chars. See SECTION C.10.4, "LIMITS ON TABLE COLUMN COUNT AND ROW SIZE"
#
# InnoDB encodes fixed-length fields greater than or equal to 768 bytes in length as variable-length
# fields, which can be stored off-page.
#
# For example, a CHAR(255) column can exceed 768 bytes if the maximum byte length of the character set
# is greater than 3,as it is with utf8mb4.
#
# The NDB storage engine supports variable-width columns.
#
# This means that VARCHAR columns in an NDB CLuster table requires the same amount of storage as would
# any other storage engine, with the exception that such values are 4-byte aligned.
#
# Thus, the string 'abcd' stored in a VARCHAR(50) column using the latin1 character set
# requires 8 bytes (rather than 5 bytes for the same column value in a MyISAM table)
#
# TEXT and BLOB columns are implemented differently in NDB, each row in a TEXT column is
# made up of two separate parts.
#
# One of these is of fixed size (256 bytes) and is actually stored in the original table.
#
# The other consists of any data in excess of 256 bytes, which is stored in a hidden table.
#
# The rows in the second table are always 2000 bytes long.
#
# This means that hte size of a TEXT column is 256 if size <= 256 (where size represents the size
# of the row);
#
# Otherwise, the size is 256 + size + (2000 X ( size - 256 ) % 2000)
#
# The size of an ENUM object is determined by the number of different enumeration values.
# One byte is used for enumerations with up to 255 possible values.
#
# Two bytes are used for enumerations having between 256 and 65,535 possible values.
# See SECTION 11.4.4, "THE ENUM TYPE"
#
# THe size of a SET object is determined by the number of different set members.
#
# If the set size is N, the object occupies (N+7)/8 bytes, rounded up to 1, 2,3,4 or 8 bytes.
#
# A SET can have a maximum of 64 members. See SECTION 11.4.5, "THE SET TYPE"
#
# SPATIAL TYPE STORAGE REQUIREMENTS
#
# MySQL stores geometry values using 4 bytes to indicate the SRID followed by the WKB
# representation of the value.
#
# The LENGTH() function returns the space in bytes required for value storage.
#
# For descriptions of WKB and internal storage formats for spatial values, 
# see SECTION 11.5.3, "SUPPORTED SPATIAL DATA FORMATS"
#
# JSON STORAGE REQUIREMENTS
#
# In general, the storage requirements for a JSON column is approximately the same as for
# a LONGBLOB or LONGTEXT column; that is, the space consumed by a JSON document is roughly
# the same as it would be for the document's string representation stored in a column of one
# of these types.
#
# However, there is an overhead imposed by the binary encoding, including metadata and dictionaries
# needed for lookup, of the individual values stored in the JSON document.
#
# For example, a string stored in a JSON document requires 4 to 10 bytes additional storage,
# depending on the length of the string and the size of hte object or array in which it is sorted.
#
# In addition, MySQL imposes a limit on the size of any JSON document stored in a JSON column
# such that it cannot be any larger than the value of max_allowed_packet.
#
# 11.9 CHOOSING THE RIGHT TYPE FOR A COLUMN
#
# For optimum storage, you should try to use the most precise type in all cases.
#
# For example, if an integer column is used for values in the range from 1 to 99.999,
# MEDIUMINT UNSIGNED is the best type.
#
# Of the types that represent all the required values, this type uses the least amount o storage.
#
# All basic calculations (+, -, *, and /) with DECIMAL columns are done with precision of 65
# decimal (base 10) digits.
#
# See SECTION 11.1.1, "NUMERIC TYPE OVERVIEW"
#
# If accuracy is not too important, or if speed is the higehst priority, the DOUBLE tpye may be good
# enough.
#
# For high precision, you can always convert to a fixed-point type stored in a BIGINT.
#
# This enables you to do all calculations with 64-bit integers and then convert results back
# to floating-point values as necessary.
#
# 11.10 USING DATA TYPES FROM OTHER DATABASE ENGINES
#
# To facilitate the use of code written for SQL implementations from other vendors, MySQL
# maps data types as shown in the following table.
#
# These mappings make it easier to import table definitions from other database systems
# into MySQL.
#
# 		OTHER VENDOR TYPE 	MYSQL TYPE
# 	
# 		BOOL 						TINYINT
#
# 		BOOLEAN 					TINYINT
#
# 		CHAR VARYING(M) 		VARCHAR(M)
#
# 		FIXED 					DECIMAL
#
# 		FLOAT4  					FLOAT
#
# 		FLOAT8 					DOUBLE
#
# 		INT1 						TINYINT
#
# 		INT2 						SMALLINT
#
# 		INT3 						MEDIUMINT
#
# 		INT4 						INT
#
# 		INT8 						BIGINT
#
# 		LONG VARBINARY 		MEDIUMBLOB
#
# 		LONG VARCHAR 			MEDIUMTEXT
#
# 		LONG 						MEDIUMTEXT
#
# 		MIDDLEINT 				MEDIUMINT
#
# 		NUMERIC 					DECIMAL
#
# Data type mapping occurs at table creation time, after which the original type specifications are discarded.
#
# If you create a table used by other vendors and then issue a DESCRIBE tbl_name statement, MySQL reports
# the table structure using the equivalent MySQL types.
#
# For example:
#
# 		CREATE TABLE t (a BOOL, b FLOAT8, c LONG VARCHAR, d NUMERIC);
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		DESCRIBE t;
# 		+------------+--------------------------+--------+--------+-----------+------------+
# 		| Field 		 | Type 							 | Null   | Key 	 | Default 	 | Extra 	  |
# 		+------------+--------------------------+--------+--------+-----------+------------+
# 		| a 			 | tinyint(1) 					 | YES 	 | 		 | NULL 		 | 			  |
# 		| b 			 | double 						 | YES 	 | 		 | NULL 		 | 			  |
# 		| c 			 | mediumtext 					 | YES 	 | 		 | NULL 		 | 			  |
# 		| d 			 | decimal(10,0) 				 | YES 	 | 		 | NULL 		 | 			  |
# 		+------------+--------------------------+--------+--------+-----------+------------+
# 		4 rows in set (0.01 sec)
#
# CHAPTER 12 FUNCTIONS AND OPERATORS
#
# Expressions can be used at several points in SQL statements, such as in teh ORDER BY or HAVING clauses
# of SELECT statements, in the WHERE clause of a SELECT, DELETE or UPDATE statement, or in SET statements.
#
# Expressions can be written using literal values, column values, NULL, built-in functions, stored functions,
# user-defined functions, and operators.
#
# This chapter describes the functions and operators that are permitted for writing expressions in MySQL.
#
# Instructions for writing stored functions and user-defined functions are given in SECTION 24.2, "USING STORED ROUTINES (PROCEDURES AND FUNCTIONS)",
# and SECTION 29.4, "ADDING NEW FUNCTIONS TO MYSQL".
#
# See SECTION 9.2.4, "FUNCTION NAME-PARSING AND RESOLUTION", for hte rules descirbing how the server interprets
# references to different kinds of functions.
#
# An expression that contains NULL always produces a NULL value unless otherwise indicated in the documentation
# for a particular function or operator.
#
# NOTE:
#
# 		By default, there must be no whitespace between a function name and the parenthesis following it.
#
# 		THis helps the MySQL parser distinguish between function calls and references to tables or columns
# 		that happen to have the same name as the function.
#
# 		However, spaces around the function arguments are permitted.
#
# You can tell the MySQL server to accept spaces after function names by starting it with the
# --sql-mode=IGNORE_SPACE option.
#
# (See SECTION 5.1.11, "SERVER SQL MODES")
#
# Individual client programs can request this behavior by using the CLIENT_IGNORE_SPACE option
# for mysql_real_connect()
#
# In either case, all function names become reserved words.
#
# For the sake of brevity, most examples in this chapter display the output from the Mysql program
# in abbreviated form.
#
# Rather than showing examples in this format:
#
# 		SELECT MOD(29,9);
# 		+----------------+
# 		| mod(29,9) 	  |
# 		+----------------+
# 		| 		2 			  |
# 		+----------------+
# 		1 rows in set (0.00 sec)
#

# This formati s used:
#
# 		SELECT MOD(29,9);
# 			-> 2
#
# 12.1 FUNCTION AND OPERATOR REFERENCE
#
# TABLE 12.1 FUNCTIONS AND OPERATORS
#
# NAME 							DESC
#
# ABS() 						Return the absolute value
#
# ACOS() 					Return the arc cosine
#
# ADDDATE() 				Add time values (intervals) to a date value
#
# ADDTIME() 				Add time
#
# AES_DECRYPT() 			Decrypt using AES
#
# AES_ENCRYPT() 			Encrypt using AES
#
# AND, && 					Logical AND
#
# ANY_VALUE() 				Suppress ONLY_FULL_GROUP_BY value rejection
#
# ASCII() 					Return numeric value of left-most character
#
# ASIN() 					Return the arc sine
#
# = 							Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)
#
# := 							Assign a value
#
# ASYMMETRIC_DECRYPT() 	Decrypt ciphertext using private or public key
#
# ASYMMETRIC_DERIVE() 	Derive symmetric key from asymmetric keys
#
# ASYMMETRIC_ENCRYPT() 	Encrypt cleartext using private or public key
#
# ASYMMETRIC_SIGN() 		Generate signature from digest
#
# ASYMMETRIC_VERIFY() 	Verify that signature matches digest
#
# ATAN() 					Return the arc tangent
#
# ATAN2(), ATAN() 		Return the arc tangent of the two arguments
#
# AVG() 						Return the average value of the argument
#
# BENCHMARK() 				Repeatedly execute an expression
#
# BETWEEN -- AND -- 		Check whether a value is within a range of values
#
# BIN() 						Return a string containing binary representation of a number
#
# BIN_TO_UUID() 			Convert binary UUID to string
#
# BINARY 					Cast a string to a binary string
#
# BIT_AND() 				Return bitwise AND
#
# BIT_COUNT() 				Return the number of bits that are set
#
# BIT_LENGTH() 			Return length of argument in bits
#
# BIT_OR() 					Return bitwise OR
#
# BIT_XOR() 				Return bitwise XOR
#
# & 							Bitwise AND
#
# ~ 							Bitwise inversion
#
# | 							Bitwise OR
#
# ^ 							Bitwise XOR
#
# CAN_ACCESS_COLUMN() 	Internal use only
#
# CAN_ACCESS_DATABASE() Internal use only
#
# CAN_ACCESS_TABLE() 	INternal use only
#
# CAN_ACCESS_VIEW() 		Internal use only
#
# CASE 						Case operator
#
# CAST() 					Cast a value as a certain type
#
# CEIL() 					Return the smallest integer value not less than the argument
#
# CEILING() 				Return the smallest integer value not less than the argument
#
# CHAR() 					Return the character for each integer passed
#
# CHAR_LENGTH() 			Return number of characters in argument
#
# CHARACTER_LENGTH() 	Synonym for CHAR_LENGTH()
#
# CHARSET() 				Return the character set of the argument
#
# COALESCE() 				Returns the first non-NULL argument
#
# COERCIBILITY() 			Returns the collation coercibility value of the string argument
#
# COLLATION() 				Return the collation of the string argument
#
# COMPRESS() 				Return result as a bianry string
#
# CONCAT()	 				Return concatenated string
#
# CONCAT_WS() 				Return concatenate with separator
#
# CONNECTION_ID() 		Return the connection ID (thread ID) for the connection
#
# CONV() 					Convert numbers between different number bases
#
# CONVERT() 				Cast a value as a certain type
#
# CONVERT_TZ() 			Convert from one time zone to another
#
# COS() 						Return the cosine
#
# COT() 						Return the cotangent
#
# COUNT() 					Return a count of the number of rows returned
#
# COUNT(DISTINCT) 		Return the count of a number of different values
# 
# CRC32() 					Compute a cyclic redundancy check value
#
# CREATE_ASYMMETRIC_PRIV_KEY() 		Create private key
#
# CREATE_ASYMMETRIC_PUB_KEY() 		Create public key
#
# CREATE_DH_PARAMETERS() Generate shared DH secret
#
# CREATE_DIGEST() 		Generate digest from string
#
# CUME_DIST() 				Cumulative distrib value
#
# CURDATE() 				Return the current date
#
# CURRENT_DATE(), 		Synonyms for CURDATE()
# CURRENT_DATE
#
# CURRENT_ROLE() 			Returns the current active roles
#
# CURRENT_TIME(), 		Synonyms for CURTIME()
# CURRENT_TIME
#
# CURRENT_TIMESTAMP(), 	Synonyms for NOW()
# CURRENT_TIMESTAMP
#
# CURRENT_USER(), 		The authenticated user name and host name
# CURRENT_USER
#
# CURTIME() 				Return the current time
#
# DATABASE() 				Return the default (current) DB name
#
# DATE() 					Extract hte date part of a date or datetime expression
#
# DATE_ADD() 				Add time values(intervals) to a date value
#
# DATE_FORMAT() 			Format date as specified
#
# DATE_SUB() 				Subtract a time value (interval) from a date
#
# DATEDIFF() 				Subtract two dates
#
# DAY() 						Synonym for DAYOFMONTH()
# 
# DAYNAME() 				Return the name of the weekday
#
# DAYOFMONTH() 			Return the day of the month (0-31)
#
# DAYOFWEEK() 				Return the weekday index of the argument
#
# DAYOFYEAR() 				Return the day of the year (1-366)
#
# DECODE() 					Decodes a string encrypted using ENCODE()
#
# DEFAULT() 				Return the default value for a table column
#
# DEGREES() 				Convert radians to degrees
#
# DENSE_RANK() 			Rank of current row within its partition, without gaps
#
# DES_DECRYPT() 			Decrypt a string
#
# DES_ENCRYPT 				Encrypt a string
#
# DIV 						Integer division
#
# / 							Division operator
#
# ELT() 						Return string at index number
#
# ENCODE() 					Encode a string
#
# ENCRYPT() 				Encrypt a string
#
# = 							Equal operator
#
# <=> 						NULL-safe equal to operator
#
# EXP() 						Raise to the power of
#
# EXPORT_SET() 			Return string such that for every bit set in the value bits,
# 								you get an on string and for every unset bit, you get an off string.
#
# EXTRACT() 				Extract part of a date
#
# ExtractValue() 			Extract a value from an XML string using XPath notation
#
# FIELD() 					Return the index (position) of the first argument in the subsequent arguments
#
# FIND_IN_SET() 			Return the index position of the first argument within the second argument
#
# FIRST_VALUE() 			Value of argument from first row of window frame
#
# FLOOR() 					Return the alrgest integer value not greater than the argument
#
# FORMAT() 					Return a number formatted to specified number of decimal places
#
# FOUND_ROWS() 			For a SELECT with a LIMIT clause, the number of rows that would be returned were there no LIMIT clause
#
# FROM_BASE64() 			Decode base64 encoded string and return result
#
# FROM_DAYS() 				Convert a day number to a date
#
# FROM_UNIXTIME() 		Format Unix timestamp as a date
#
# GeomCollection() 		Construct geometry collection from geometries
#
# GeometryCollection() 	Construct geometry collection from geometries
#
# GET_DD_COLUMN 			Internal use only
# _PRIVILEGES()
#
# GET_DD_CREATE_OPTIONS() Internal use only
#
# GET_DD_INDEX_SUB_PART_LENGTH Internal use only
#
# GET_FORMAT() 			Return a date format string
#
# GET_LOCK() 				Get a named lock
#
# > 							Greater than operator
#
# >= 							Greater than or equal operator
#
# GREATEST() 				Return the largest argument
#
# GROUP_CONCAT() 			Return a concatenated string
#
# GROUPING() 				Distinguish super-aggregate ROLLUP rows from regular rows
#
# GTID_SUBSET() 			Return true if all GTIDs in subset are also in set; otherwise false.
#
# GTID_SUBTRACT() 		Return all GTIDs in set that are not in subset.
#
# HEX() 						Return a hexadecimal representation of a decimal or string vlaue
#
# HOUR() 					Extract the hour
#
# ICU_VERSION() 			ICU library version
#
# IF() 						If/Else construct
#
# IFNULL() 					Null if/else construct
#
# IN() 						Check whether a value is within a set of values
#
# INET_ATON() 				Return the numeric value of an IP address
#
# INET_NTOA() 				Return the IP address from a numeric value
#
# INET6_ATON() 			Return the numeric value of an IPV6 address
#
# INET6_NTOA() 			Return the IPv6 address from a numeric value
#
# INSERT() 					Insert a substring at the specified position up to the specified number of characters
#
# INSTR() 					Returns the index of the first occurence of substring
#
# INTERNAL_AUTO_INCREMENT() Internal use only
#
# INTERNAL_AVG_ROW_LENGTH() Internal use only
#
# INTERNAL_CHECK_TIME() 	 Internal use only
#
# INTERNAL_CHECKSUM() 		 Internal use only
#
# INTERNAL_DATA_FREE() 		 Internal use only
# 
# INTERNAL_DATA_LENGTH() 	 Internal use only
#
# INTERNAL_DD_CHAR_LENGTH() Internal use only
#
# INTERNAL_GET_COMMENT_OR_ERROR() Internal use only
#
# INTERNAL_GET_VIEW_WARNING_OR_ERROR() Internal useo nly
#
# INTERNAL_INDEX_COLUMN_CARDINALITY() Internal useo nly
#
# INTERNAL_INDEX_LENGTH() 	 Internal use only
#
# INTERNAL_KEYS_DISABLED()  Internal useo nly
#
# INTERNAL_MAX_DATA_LENGTH() Internal use only
#
# INTERNAL_TABLE_ROWS() 	 INTERNAL USE ONLY 
#
# INTERNAL_UPDATE_TIME() 	 Intenral use only
#
# INTERVAL() 					 Return the index of the argument that is less than the first argument
#
# IS 								 Test a value against a boolean
#
# IS_FREE_LOCK() 				 Whether the named lock is free
#
# IS_IPV4() 					 Whether argument is an ipv4 address
#
# IS_IPV4_COMPAT() 			 Whether argument is an IPV4-compatible address
#
# IS_IPV4_MAPPED() 			 Whether argument is an IPv4-mapped address
#
# IS_IPV6() 					 Whether argument is an IPV6 address
#
# IS_NOT 						 Test a value against a boolean
#
# IS_NOT_NULL 					 NOT NULL value test
#
# IS_NULL 						 NULL value test
#
# IS_USED_LOCK() 				 Whether the named lock is in use; return connection identifier if true
#
# IS_UUID() 					 Whether argument is a valid UUID
#
# ISNULL() 						 Test whether the argument is NULL
#
# JSON_ARRAY() 				 Create JSON array
#
# JSON_ARRAY_APPEND() 		 Append data to JSON document
#
# JSON_ARRAY_INSERT() 		 Insert into JSON array
#
# JSON_ARRAYAGG() 			 Return result set as a single JSON array
#
# -> 								 Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()
#
# JSON_CONTAINS() 		    Whether JSON document contains specific object at Path
#
# JSON_CONTAINS_PATH() 		 Whether JSON document contains any data at path
#
# JSON_DEPTH() 				 Maximum depth of JSON document
#
# JSON_EXTRACT() 				 Return data from JSON document
#
# ->> 							 Return value from JSON column after evaluating path and unquoting the result;
# 									 equivalent to JSON_UNQUOTE(JSON_EXTRACT())
#
# JSON_INSERT() 				 Insert data into JSON document
#
# JSON_KEYS() 					 Array of keys from JSON document
#
# JSON_LENGTH() 				 Number of elements in JSON document
#
# JSON_MERGE() (deprecated >= 8.0.3) Merge JSON documents, preserving duplicate keys. Deprecated synonym for JSON_MERGE_PRESERVE()
#
# JSON_MERGE_PATCH() 		 Merge JSON documents, replacing values of duplicate keys
#
# JSON_MERGE_PRESERVE() 	 Merge JSON documents, preserving duplicate keys
#
# JSON_OBJECT() 				 Create JSON object
#
# JSON_OBJECTAGG() 			 Return result set as a single JSON object
#
# JSON_PRETTY() 				 Prints a JSON document in human-readable format, with each array
# 									 element or object member printed on a new line, indented two spaces
# 									 with respect to its parent.
#
# JSON_QUOTE() 				 Quote JSON document
#
# JSON_REMOVE() 				 Remove data from JSON document
#
# JSON_REPLACE() 				 Replace values in JSON document
#
# JSON_SEARCH() 				 Path to value within JSON document
#
# JSON_SET() 					 Insert data into JSON document
#
# JSON_STORAGE_FREE() 		 Freed space within binary representation of a JSON column value following a partial update
#
# JSON_STORAGE_SIZE() 		 Space used for storage of binary representation of a JSON document, for a JSON column, the space
# 									 used when the document was inserted, prior to any partial updates
#
# JSON_TABLE() 				 Returns data from a JSON expression as a relational table
#
# JSON_TYPE() 					 Type of JSON value
#
# JSON_UNQUOTE() 				 Unquote JSON value
#
# JSON_VALID() 				 Whether JSON value is valid
#
# LAG() 							 Value of argument from row lagging current row within partition
#
# LAST_DAY 						 Return the last day of the month for the argument
#
# LAST_INSERT_ID() 			 Value of the AUTOINCREMENT column for the last INSERT
#
# LAST_VALUE() 				 Value of an argument from last row of window frame
#
# LCASE() 					    Synonym for LOWER()
#
# LEAD() 						 Value of argument from row leading current row within partition
#
# LEAST() 						 Return  the smallest argument
#
# LEFT() 						 Return the leftmost number of characters as specified
#
# << 								 left shift
#
# LENGTH() 						 Return the length of a string in bytes
#
# < 								 Less than operator
#
# <= 								 Less than or equal operator
#
# LIKE 							 Simple pattern matching
#
# LineString() 				 Construct LineString from Point values
#
# LN() 							 Return the natural logarithm of the argument
#
# LOAD_FILE() 					 Load the named file
#
# LOCALTIME(), LOCALTIME 	 Synonym for NOW()
#
# LOCALTIMESTAMP, 			 Synonym for NOW()
# LOCALTIMESTAMP() 
#
# LOCATE() 						 Return the position of hte first occurence of substring
#
# LOG() 							 Return the natural logarithm of the first argument
#
# LOG10() 						 Return the base-10 logarithm of the argument
#
# LOG2() 						 Return the base-2 logarithm of the argument
#
# LOWER() 						 Return the arguments in lowercase
#
# LPAD() 						 Return the string argument, left-padded with the specified string
#
# LTRIM() 						 Remove leading spaces
#
# MAKE_SET() 					 Return a set of comma-separated strings that have the corresponding bit in bits set
#
# MAKEDATE() 					 Create a date from the year and day of year
#
# MAKETIME() 					 Create time from hour, minute, second
#
# MASTER_POS_WAIT() 			 Block until the slave has read and applied all updates up to the specified position
#
# MATCH 							 Perform full-text search
#
# MAX() 							 Return the maximum value
#
# MBRContains() 				 Whether MBR of one geometry contains MBR of another
#
# MBRCoveredBy() 				 Whether one MBR is covered by another
#
# MBRCovers() 					 Whether one MBR covers another
#
# MBRDisjoint() 				 Whether MBRs of two geometries are disjoint
#
# MBREquals() 					 Whether MBRs of two geometries are equal
#
# MBRIntersects() 			 Whether MBRs of two geometries insersect
#
# MBROverlaps() 				 Whether MBRs of two geometries overlap
#
# MBRTouches() 				 Whether MBRs of two geometries touch
#
# MBRWithin() 					 Whether MBR of one geometry is within MBR of another
#
# MD5() 							 Calculates MD5 Checksum
#
# MICROSECOND() 				 Return the microseconds from argument
#
# MID() 							 Return A substring starting from the specified position
#
# MIN() 							 Return the minimum value
#
# - 								 Minus operator
#
# MINUTE() 						 Return the minute from the argument
#
# MOD() 							 Return the remainder
#
# %, MOD 						 Modulo operator
#
# MONTH() 						 Return the month from the date passed
#
# MONTHNAME() 					 Return the name of the month
#
# MultiLineString() 			 Construct MultiLineString from LineString Values
#
# MultiPoint() 				 Construct MultiPoint from Point values
#
# MultiPolygon() 				 Construct MultiPolygon from Polygon values
#
# NAME_CONST() 				 Causes the column to have the given name
#
# NOT, ! 						 Negates value
#
# NOT_BETWEEN_---_AND_--- 	 Check wether a value is not within a range of values
#
# !=, <> 						 Not equal operator
#
# NOT_IN() 						 Check wether a value is not within a set of values
#
# NOT_LIKE 						 Negation of simple pattern matching
#
# NOT_REGEXP 					 Negation of REGEXP
#
# NOW() 							 Return the current date and time
#
# NTH_VALUE() 					 Value of argument from N-th row of Window frame
#
# NTILE() 						 Bucket number of current row within its partition
#
# NULLIF() 						 Return NULL if expr1 = expr2
#
# OCT() 							 Return a string containing octal representation of a number
#
# OCTET_LENGTH() 				 Synonym for LENGTH()
#
# ||, OR 						 Logical OR
#
# ORD() 							 Return charater code for leftmost char of the argument
#
# PASSWORD() 					 Calculate and return a password string
#
# PERCENT_RANK() 				 Percentage rank value
#
# PERIOD_ADD() 				 Add a period to a year-month
#
# PERIOD_DIFF() 				 Return the number of months between periods
#
# PI() 							 Return the vlaue of PI
#
# + 								 Addition operator
#
# Point() 						 Construct Point from coordinates
#
# Polygon() 					 Construct Polygon from LineString arguments
#
# POSITION() 					 Synonym for LOCATE()
#
# POW() 							 Return the argument raised to the specified power
#
# POWER() 						 Return the argument raised to the specified power
#
# QUARTER() 					 Return the quarter from a date argument
#
# QUOTE() 						 Escape the argument for use in an SQL statement
#
# RADIANS() 					 Return argument converted to radians
#
# RAND() 						 Return a random floating point value
#
# RANDOM_BYTES() 				 Return a random byte vector
#
# RANK() 						 Rank of current row within its partition, with gaps
#
# REGEXP 						 Whether string matches regular expression
#
# REGEXP_INSTR() 				 Starting index of substring matching regular expression
#
# REGEXP_lIKE() 				 Whether string matches regular expression
#
# REGEXP_REPLACE() 			 Replace substrings matching regular expression
#
# REGEXP_SUBSTR() 			 Return substring matching regular expressions
#
# RELEASE_ALL_LOCKS() 		 Release all current named locks
#
# RELEASE_LOCK() 				 RElease the named lock
#
# REPEAT() 						 Repeat a string the specified number of times
#
# REPLACE() 					 Replace occurences of a specified string
#
# REVERSE() 					 Reverse the characters in a string
#
# RIGHT() 						 Return the specified rightmost number of characters
#
# >> 								 Right shift
#
# RLIKE 							 Whether string matches regular expression
#
# ROLE_GRAPHML() 				 Returns a GraphML document representing memory role subgraphs
#
# ROUND() 						 Round the argument
#
# ROW_COUNT() 					 The number of rws updated
#
# ROW_NUMBER() 				 Number of current row within its partition
#
# RPAD() 						 Append string the specified number of times
#
# RTRIM() 						 Removes trailing spaces
#
# SCHEMA() 						 Synonym for DATABASE()
#
# SEC_TO_TIME() 				 Converts seconds to 'HH:MM:SS' format
#
# SECOND() 						 Return the second (0-59)
#
# SESSION_USER() 				 Synonym for USER()
#
# SHA1(), SHA() 				 Calculate an SHA-1 160-bit checksum
#
# SHA2() 						 Calculate an SHA-2 checksum
#
# SIGN() 						 Return the sign of the argument
#
# SIN() 							 Return the sine of the argument
#
# SLEEP() 						 Sleep for a number of seconds
#
# SOUNDEX() 					 Return a soundex string
#
# SOUNDS_LIKE 					 Compare sounds
#
# SPACE() 						 Return a string of the specified number of spaces
#
# SQRT() 						 Return the square root of the argument
#
# ST_Area() 					 Return Polygon or MultiPolygon area
#
# ST_AsBinary(), ST_AsWKB() Convert from internal geometry format to WKB
#
# ST_AsGeoJSON() 				 Generate GeoJSON object from geometry
#
# ST_AsText(), 				 Convert from internal geometry format to WKT
# ST_AsWKT()
#
# ST_Buffer() 					 Return geometry of points within given distance from geometry
#
# ST_Buffer_Strategy() 		 Produce strategy option for ST_Buffer()
#
# ST_Centroid() 				 Return centroid as a point
#
# ST_Contains() 				 Whether one geometry contains another
#
# ST_ConvexHull() 			 Return convex hull of geometry
#
# ST_Crosses() 				 Whether one geometry crosses another
#
# ST_Difference() 			 Return point set difference of two geometries
#
# ST_Dimension() 				 Dimension of geometry
#
# ST_Disjoint() 				 Whether one geometry is disjoint from another
#
# ST_Distance() 				 The distance of one geometry from another
#
# ST_Distance_Sphere() 		 Minimum distance on earth between geometries
#
# ST_EndPoint() 				 End Point of LineString
#
# ST_Envelope() 				 Return MBR of geometry
#
# ST_Equals() 					 Whether one geometry is equal to another
#
# ST_ExteriorRing() 			 Return exterior ring of Polygon
#
# ST_GeoHash() 				 Produce a geohash value
#
# ST_GeomCollFromText(), 				Return geometry collection from WKT
# ST_GeometryCollectionFromText(),
# ST_GeomCollFromTxt()
#
# ST_GeomCollFromWKB(), 				Return geometry collection from WKB
# ST_GeometryCollectionFromWKB()
#
# ST_GeometryN() 				  Return N-th geometry from geometry collection
#
# ST_GeometryType() 			Return name of geometry type
#
# ST_GeomFromGeoJSON() 		Generate geometry from GeoJSON object
#
# ST_GeomFromText(), 		Return geometry from WKT
# ST_GeometryFromText()
#
# ST_GeomFromWKB(), 			Return geometry from WKB
# ST_GeometryFromWKB()
#
# ST_InteriorRingN() 		Return N-th interior ring of Polygon
#
# ST_Intersection() 			Return point set intersection of two geometries
#
# ST_Intersects() 			Whether one geometry intersects another
#
# ST_IsClosed() 			 	Whether a geometry is closed and simple
#
# ST_IsEmpty() 				Placeholder function
#
# ST_IsSimple() 				Whether a geometry is simple
#
# ST_IsValid() 				Whether a geometry is valid
#
# ST_LatFromGeoHash() 		Return latitude from geohash value
#
# ST_Latitude() 			 	Return latitude of Point
#
# ST_Length() 					Return length of LineString
#
# ST_LineFromText(), 		Construct LineString from WKT
# ST_LineStringFromText()
#
# ST_LineFromWKB(), 			Construct LineString from WKB
# ST_LineStringFromWKB()
#
# ST_longFromGeoHash() 		Return longitude from geohash value
#
# ST_Longitude() 				Return longitude of Point
#
# ST_MakeEnvelope() 			Rectangle around two points
#
# ST_MLineFromText(), 				Construct MultiLineString from WKT
# ST_MultiLineStringFromText()
#
# ST_MLineFromWKB(), 				Construct MultiLineString from WKB
# ST_MultiLineStringFromWKB()
#
# ST_MPointFromText(), 			 	Construct MultiPoint from WKT
# ST_MultiPointFromText()
#
# ST_MPointFromWKB(), 				Construct MultiPoint from WKB
# ST_MultiPointFromWKB()
#
# ST_MPolyFromText(), 			 	Construct MultiPolygon from WKT
# ST_MultiPolygonFromText()
#
# ST_MPolyFromWKB(), 				Construct MultiPolygon from WKB
# ST_MultiPolygonFromWKB()
#
# ST_NumGeometries() 				Return number of geometries in geometry collection
#
# ST_NumINteriorRing(), 			Return number of interior rings in Polygon
# ST_NumInteriorRings()
#
# ST_NumPoints() 					 	Return number of points in lineString
#
# ST_Overlaps() 						Whether one geometry overlaps another
#
# ST_PointFromGeoHash() 			Convert geohash value to POINT value
#
# ST_PointFromText() 				Construct Point from WKT
#
# ST_PointFromWKB() 					Constuct point from WKB
#
# ST_PointN 							Return N-th point from LineString
#
# ST_PolyFromText(), 				Construct polygon from WKT
# ST_PolygonFromText()
#
# ST_PolyFromWKB(), 					Construct Polygon from WKB
# ST_PolygonFromWKB()
#
# ST_Simplify() 						Return simplified geometry
#
# ST_SRID() 							Return spatial reference system ID for geometry
#
# ST_StartPoint() 					Start Point of LineString
#
# ST_SwapXY() 							Return argument with X/Y coordinates swapped
#
# ST_SymDifference() 				Return point set symmetric difference of two geometries
#
# ST_Touches() 						Whether one geometry touches another
#
# ST_Transform() 						Transform coordinates of geometry
#
# ST_Union() 							Return point set union of two geometries
#
# ST_Validate() 						Return validated geometry
#
# ST_Within() 							Whether one geometry is within another
#
# ST_X() 								Return X coordinate of Point
#
# ST_Y() 								Return Y coordinate of Point
#
# STATEMENT_DIGEST() 				Compute statement digest hash value
#
# STATEMENT_DIGEST_TEXT() 			Compute normalized statement digest
#
# STD() 									Return the population standard deviation
#
# STDDEV() 								Return the pop standard deviation
#
# STDDEV_POP() 						Return the pop standard deviation
#
# STDDEV_SAMP() 						Return the sample standard deviation
#
# STR_TO_DATE() 						Convert a string to a date
#
# STRCMP() 								Compare two strings
#
# SUBDATE() 							Synonym for DATE_SUB() when invoked with three arguments
#
# SUBSTR() 								Return the substring as specified
#
# SUBSTRING() 							Return the substring as specified
#
# SUBSTRING_INDEX() 					Return a substring from a string before the specified number of occurrences of the delimiter
#
# SUBTIME() 							Subtract times
#
# SUM() 									Return the sum
#
# SYSDATE() 							Return the time at which the function executes
#
# SYSTEM_USER() 						Synonym for USER()
#
# TAN() 									Return the tangent of the argument
#
# TIME() 								Extract the time portion of the expression passed
#
# TIME_FORMAT() 						Format as time
#
# TIME_TO_SEC() 						Return the argument converted to seconds
#
# TIMEDIFF() 							Subtract time
#
# * 										Multiplication operator
#
# TIMESTAMP() 							With a single argument, this function returns the date or datetime expression;
# 											with two arguments, the sum of the arguments
#
# TIMESTAMPADD() 						Add an internval to a datetime expression
#
# TIMESTAMPDIFF() 					Subtract an internal from a datetime expression
#
# TO_BASE64() 							Return the argument converted to a base-64 string
#
# TO_DAYS() 							Return the date argument converted to days
#
# TO_SECONDS() 						Return the date or datetime argument converted to seconds since Year 0
#
# TRIM() 								Remove leading and trailing spaces
#
# TRUNCATE() 							Truncate to specified number of decimal places
#
# UCASE() 								Synonym for UPPER()
#
# - 										Change the sign of the argument
#
# UNCOMPRESS() 						Uncompress a string compressed
#
# UNCOMPRESSED_LENGTH() 			Return the length of a string before compression
#
# UNHEX() 								Return a string containing hex representation of a number
#
# UNIX_TIMESTAMP() 					Return a Unix timestamp
#
# UpdateXML() 							Return replaced XML fragment
#
# UPPER() 								Conver to uppercase
#
# USER() 								The user name and host name provided by the client
#
# UTC_DATE() 							Return the current UTC date
#
# UTC_TIME() 							Return the current UTC time
#
# UTC_TIMESTAMP() 					Return the current UTC date and time
#
# UUID() 								Return a Universal Unique Identifier (UUID)
#
# UUID_SHORT() 						Return an integer-valued universal identifier
#
# UUID_TO_BIN() 						Convert string UUID to binary
#
# VALIDATE_PASSWORD_STRENGTH() 	Determine strength of a password
#
# VALUES() 								Defines the values to be used during an INSERT
#
# VAR_POP() 							Return the population standard variance
#
# VAR_SAMP() 							Return the sample variance
#
# VARIANCE() 							Return the population standard variance
#
# VERSION() 							Return a string that indicates the MySQL server version
#
# WAIT_FOR_EXECUTED_GTID_SET() 	Wait until the given GTIDs havve executed on slave.
#
# WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() Wait until the given GTIDs have executed on slave.
#
# WEEK() 								Return the week number
#
# WEEKDAY() 							Return the weekday index
#
# WEEKOFYEAR() 						Return the calendar week of the date (1-53)
#
# WEIGHT_STRING() 					Return the weight string for a string
#
# XOR 									Logical XOR
#
# YEAR() 								Return the year
#
# YEARWEEK() 							return the year and week.
#
# 12.2 TYPE CONVERSION IN EXPRESSION EVALUATION
#
# When an operator is used with operands of different types, type conversion occurs to make the operands
# compatible.
#
# Some conversions occur implicitly.
#
# for example, MySQL automatically converts strings to numbers as called for, and vice versa.
#
# 		SELECT 1+'1';
# 			-> 2
# 		SELECT CONCAT(2,' test');
# 			-> '2 test'
#
# It is also possible to convert a number to a string explicitly using the CAST() function.
#
# Conversion occurs implicitly with the CONCAT() function because it expects string
# arguments.
#
# SELECT 38.8, CAST(38.8 AS CHAR);
# 		-> 38.8, '38.8'
# SELECT 38.8, CONCAT(38.8);
# 		-> 38.8, '38.8'
#
# See later in this section for information about the character set of implicit number-to-string conversions,
# and for modified rules that apply to CREATE TABLE --- SELECT statements.
#
# The following rules describe how conversion occurs for comparison operations:
#
# 	) If one or both arguments are NULL, the result of the comparison is NULL, except for the NULL-safe
# 		<=> equality comparison operator.
#
# 		For NULL <=> NULL, the result is true.
#
# 		No conversion called for.
#
# 	) If both arguments in a comparison operation are strings, they are compared as strings.
#
# 	) If both arguments are integers, they are compared as integers.
#
# 	) Hexadecimal values are treated as binary strings if not compared to a number.
#
# 	) If one of the arguments is a TIMESTAMP or DATETIME column and the other argument is a constant,
# 		the constant is converted to a timestamp before the comparison is performed.
#
# 		This is done to be more ODBC-friendly.
#
# 		This is not done for the arguments to IN().
#
# 		TO be safe, always use complete datetime, date or time strings when doing comparisons.
#
# 		For example, to achieve the best results when using BETWEEN with date or time values, use CAST()
# 		to explicitly convert the values to the desired data type.
#
# 		A single-row subquery from a table or tables is not considered a constant.
#
# 		For example, if a subquery returns an integer ot be compared to a DATETIME value,
# 		the comparison is done as two integers.
#
# 		The integer is not converted to a temporal value.
#
# 		To compare the operans as DATETIME values, use CAST() to explicitly convert the
# 		subquery value to DATETIME.
#
#  ) If one of the argument is a decimal value, comparison depends on the other argument.
#
# 		The arguments are compared as decimal values if the other argument is a decimal
# 		or integer value, or as floating-point values if the other argument is a floating-point value.
#
# 	) In all other cases, the arguments are compared as floating-point (real) numbers.
#
# For information about conversion of values from one temporal type to another, see
# SECTION 11.3.7, "CONVERSION BETWEEN DATE AND TIME TYPES"
#
# Comparison of JSON values takes place at two levels.
#
# The first level of comparison is based on the JSON types of the compared values.
#
# If the types differ, the comparison result is determined solely by which type has
# higher precedence.
#
# IF the two values have the same JSON type, a second level of comparison occurs using
# type-specific rules.
#
# For comparison of JSON and non-JSON values, the non-JSON value is converted to JSON and
# the values compared as JSON values.
#
# For details, See COMPARISON AND ORDERING OF JSON VALUES.
#
# The following examples illustrate conversion of strings to numbers for comparison operations:
#
# 		SELECT 1 > '6x';
# 			-> 0
#
# 		SELECT 7 > '6x';
# 			-> 1
#
# 		SELECT 0 > 'x6';
# 			-> 0
#
# 		SELECT 0 = 'x6';
# 			-> 1
#
# For comparisons of a string column with a number, MySQL cannot use an index on the column
# to look up the value quickly.
#
# If str_col is an indexed string column, the index cannot be used when performing the lookup
# in the following statement:
#
# 		SELECT * FROM tbl_name WHERE str_col=1;
#
# The reason for htis is that there are many different strings that may convert to the value 1,
# such as '1', ' 1' or '1a'
#
# Comparisons that use floating-point numbers (or values that are converted to floating-point numbers)
# are approximate because such numbers are inexact.
#
# This might lead to results that appear inconsistent:
#
# 		SELECT '18015376320243458' = 18015376320243458;
# 			-> 1
# 		SELECT '18015376320243459' = <same as defined ot the left>
# 			-> 0
#
# Such results can occur because the values are converted to floating-point numbers,
# which have only 53 bits of precision and are subject to rounding:
#
# 		SELECT '18015376320243459'+0.0;
# 			-> 1.8015376320243e+16
#
# Furthermore, the conversion from string to floating-point and from integer to floating-point
# do not necessarily occur the same way.
#
# The integer may be converted to floating-point by the CPU, whereas the string is converted
# digit by digit in an operation that involves floating-point multiplications.
#
# The results shown will vary on different systems, and can be affected by factors such as
# computer architechture or the compiler version or optimization level.
#
# One way to avoid such problems is to use CAST() so that a value is not converted implicitly
# to a float-point number:
#
# 		SELECT CAST('18015376320243459' AS UNSIGNED) = 18015376320243459;
# 			-> 1
#
# For more information about floating-point comparisons, see SECTION B.6.4.8, "PROBLEMS WITH FLOATING-POINT VALUES"
#
# The server includes dtoa, a conversion library that provides the basis for improved conversion between
# string or DECIMAL values and approximate value (FLOAT/DOUBLE) numbers:
#
# 		) Consistent conversion results across platforms, which eliminates, for example, Unix versus Windows conversion differences.
#
# 		) Accurate representation of values in cases where results previously did not provide sufficient precision,
# 			such as for values close to IEEE limits.
#
# 		) Conversion of numbers to string format with the best possible precision.
#
# 			The precision of dtoa is always the same or better than that of the standard C library functions.
#
# Because the conversions produced by this library differ in some cases from non-dtoa results,
# the potential exists for incompatibilities in applications that rely on previous results.
#
# For example, applications that depend on a specific exact result from previous conversions might
# need adjustment to accomodate additional precision.
#
# The dtoa library provides conversions with the following properties.
#
# D represents a value with a DECIMAL or string representation, and F represents a floating-point
# number in native binary (IEEE) format.
#
# 		) F -> D conversion is done with the best possible precision, returning D as the shortest string
# 			that yields F when read back in and rounded to the nearest value in native binary format
# 			as specified by IEEE.
#
# 		) D -> F conversion is done such that F is the nearest native binary number to the input decimal string D.
#
# These properties imply that F -> D -> F converions are lossless unless F is -inf, +inf or NaN.
#
# The latter values are not supported because the SQL standard defines them as invalid values
# for FLOAT or DOUBLE.
#
# For D -> F -> D conversions, a sufficient condition for losslessness is that D uses 15 or fewer digits
# of precision, is not a denormal value, -inf, +inf or NaN.
#
# In some cases, the conversion is lossless even if D has more than 15 digits of precision,
# but this is not always the case.
#
# Implicit conversion of a numeric or temporal value to string produces a value that has a character
# set and collation determined by the character_set_connection and collation_connection system variables.
#
# (These variables commonly are set with SET_NAMES. For information about connection character sets,
# see SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS")
#
# This means that such a conversion results in a character (nonbinary) string (a CHAR, VARCHAR, or LONGTEXT value),
# except in the case that the connection character set is set to bianry.
#
# In that case, the conversion result is a binary string (a BINARY, VARBINARY or LONGBLOB value)
#
# For integer expressions, the preceding remarks about expression evaluation apply somewhat differently
# for expression assignment; for example, in a statement such as this:
#
# 		CREATE TABLE t SELECT integer_expr;
#
# In this case, the table in the column resulting from the expression has type INT or BIGINT
# depending on the length of the integer expression.
#
# If the maximum length of the expression does not fit in an INT, BIGINT is used instead.
#
# The length is taken from the max_length value of the SELECT result set metadata
# (see SECTION 28.7.5 "C API DATA STRUCTURES")
#
# This means that you can force a BIGINT rather than INT by use of a sufficiently long
# expression:
#
# 		CREATE TABLE t SELECT 0000000000000000000000000000000000;
#
# 12.3 OPERATORS
#
# TABLE 12.2 OPERATORS
#
# NAME 				DESC
#
# AND, && 			Logical AND
#
# = 					Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)
#
# := 					Assign a value
#
# BETWEEN_---_AND_--- Check whether a value is within range of values
#
# BINARY 			Cast a string to a binary string
#
# & 					Bitwise AND
#
# ~  					Bitwise inversion
#
# | 					Bitwise OR
#
# ^ 					Bitwise XOR
#
# CASE 				Case operator
#
# DIV 				Integer division
#
# / 					Division operator
#
# = 					Equal operator
#
# <=> 				NULL-safe equal to operator
#
# > 					Greater than operator
#
# >= 					Greater than or equal operator
#
# IS 					Test a value against a boolean
#
# IS NOT 			Test a value against a boolean
#
# IS NOT NULL 		NOT NULL value test
#
# IS NULL 			NULL value test
#
# -> 					Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()
#
# ->> 				Return value from JSON column after evaluating path and unquoting the result;
# 						equivalent to JSON_UNQUOTE(JSON_EXTRACT())
#
# << 					Left shit
#
# < 					Less than operator
#
# <= 					Less than or equal operator
#
# LIKE 				Simple pattern matching
#
# - 					Minus operator
#
# %, MOD 			Modulo operator
#
# NOT, ! 			Negates value
#
# NOT BETWEEN_---_AND_--- Check whether a value is not within a range of values
#
# !=, <> 			Not equal operator
#
# NOT_LIKE 			Negation of simple pattern matching
#
# NOT_REGEXP 		Negation of REGEXP
#
# ||, OR 			Logical OR
#
# + 					Addition operator
#
# REGEXP 			Whether string matches regular expression
#
# >> 					Right shift
#
# RLIKE 				Whether string matches regular expression
#
# SOUNDS_LIKE 		Compare sounds
#
# * 					Multiplication operator
#
# - 					Change the sign of the argument
#
# XOR 				Logical XOR
#
# 12.3.1 OPERATOR PRECEDENCE
#
# Operator precedences are shown in the following list, from highest precedence 
# to the lowest.
#
# Operators that are shown together on a line have the same precedence.
#
# 		INTERVAL
# 		BINARY, COLLATE
# 		!
# 		- (unary minus), ~ (unary bit inversion)
# 		^
# 		*, /, DIV, %, MOD
# 		-, +
# 		<<, >>
# 		&
# 		|
# 		= (comparison), <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP, IN
# 		BETWEEN, CASE, WHEN, THEN, ELSE
# 		NOT
# 		AND, &&
# 		XOR
# 		OR, ||
# 		= (assignment), :=
#
# The precedence of = depends on whether it is used as a comparison operator (=) or as an
# assignment operator (=)
#
# When used as a comparison operator, it has the same precedence as <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP and IN.
#
# WHen used as an assignment operator, it has the same precedence as :=, SECTION 13.7.5.1, "SET SYNTAX FOR VARIABLE ASSIGNMENT",
# and SECTION 9.4, "USER-DEFINED VARIABLES", explain how MySQL determines which interpretation of = should apply.
#
# For operators that occur at the same precedence level within an expression, evaluation proceeds left to right, with the
# exception that assignments evaluate right to left.
#
# The precedence and meaning of some operators depends on the SQL mode:
#
# 		) By default, || is a logical OR operator. With PIPES_AS_CONCAT enabled, || is string concatenation,
# 			with a precedence between ^ and the unary operators.
#
# 		) By default, ! has a higher precedence than NOT.
#
# 			With HIGH_NOT_PRECEDENCE enabled, ! and NOT have the same precedence.
#
# See SECTION 5.1.11, "SERVER SQL MODES"
#
# The precedence of operators determines the order of evaluation of terms in an expression.
# To override this order and group terms explicitly, use parantheses.
#
# For example:
#
# 		SELECT 1+2*3;
# 			-> 7
# 		SELECT (1+2)*3;
# 			-> 9
#
# 12.3.2 COMPARISON FUNCTIONS AND OPERATORS
#
# TABLE 12.3 COMPARISON OPERATORS
#
# Name 									Desc
#
# BETWEEN_---_AND_--- 				Check whether a value is within a range of  values
#
# COALESCE() 							Returns the first non-NULL argument
#
# = 										Equal operator
#
# <=> 									NULL-safe equal to operator
#
# > 										Greater than operator
#
# >= 										Greater than or equal operator
#
# GREATEST() 							Return the largest argument
#
# IN() 									Check whether a value is within a set of values
#
# INTERVAL() 							Returns the index of the argument that is less than the first argument
#
# IS 										Test a value against a boolean
#
# IS_NOT 								Test a value against a boolean
#
# IS_NOT_NULL 							NOT NULL value test
#
# IS_NULL 								NULL value test
#
# ISNULL() 								NULL value test
#
# LEAST() 								Return the smallest argument
#
# < 										Less than operator
#
# <= 										Less than or equal operator
#
# LIKE 									Simple pattern matching
#
# NOT_BETWEEN_---_AND_--- 			Check whether a value is not within a range of values
#
# !=, <> 								Not equal operator
#
# NOT_IN() 								Check whether a value is not within a set of values
#
# NOT_LIKE 								Negation of simple pattern matching
#
# STRCMP() 								Compare two strings
#
# Comparison operations result in a value of 1 (TRUE), 0 (FALSE), or NULL.
#
# These operations work for both numbers and strings.
# Strings are automatically converted to numbers and numbers to strings as necessary.
#
# The following relational comparison operators can be used to compare not only scalar
# operands, but row operands:
#
# 		= > < >= <= <> !=
#
# The descriptions for those operators later in this section detail how they work with
# row operands.
#
# For additional examples of row comparisons in the context of row subqueries, see 
# SECTION 13.2.11.5, "ROW SUBQUERIES"
#
# Some of the functions in this section return values other than !(TRUE), 0(FALSE) or
# NULL.
#
# LEAST() and GREATEST() are examples of such functions;
# 
# SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION", describes the rules for comparison
# operations performed by these and similar functions for determining their return values.
#
# NOTE:
#
# 		In previous versions of MySQL, when evaluating an expression containing LEAST() or
# 		GREATEST(), the server attempted to guess the context in which the function was used,
# 		and to coerce the function's arguments to the data type of the expression as a whole.
#
# 		For example, the arguments to LEAST("11", "45", "2") are evaluated and stored as strings,
# 		so that this expansion returns "11".
#
# 		In MySQL 8.0.3 and earlier, when evaluating the expression LEAST("11", "45", "2") + 0,
# 		the server converted the arguments to integers (anticipating the addition of integer 0
# 		to the result) before sorting them, thus returning 2.
#
# 		Beginning with 8.0.4, the server no longer attempts to infer context in this fashion.
#
# 		Instead, the function is executed using the arguments as provided, performing data type
# 		conversions to one or more of the arguments if and only if they are not all of the
# 		same type.
#
# 		Any type coercion mandated by an expression that makes use of the return value is now
# 		performed following function execution.
#
# 		This means that, In MysQL 8.0.4, and later, LEAST("11", "45", "2") + 0 evaluates to
# 		"11" + 0 and thus to integer 11. (Bug #83895, Bug #25123839)
#
# To convert a value to a specific type for comparison purposes, you can use the CAST()
# function.
#
# String values can be converted to a different character set using CONVERT()
#
# See SECTION 12.10, "CAST FUNCTIONS AND OPERATORS"
#
# By default, string comparisons are not case-sensitive and use the current char set.
# The default is utf8mb4.
#
# ) =
#
# 		Equal:
#
# 				SELECT 1 = 0;
# 					-> 0
#
# 				SELECT '0' = 0;
# 					-> 1
#
# 				SELECT '0.0' = 0;
# 					-> 1
#
# 				SELECT "0.01" = 0;
# 					-> 0
#
# 				SELECT '.01' = 0.01;
# 					-> 1
#
# For row comparisons, (a,b) = (x,y) is equivalent to:
#
# 		(a = x) AND (b = y)
#
# ) <=>
#
# 		NULL-safe equal.
#
# 		THis operator performs an equality comparison like the = operator, but returns 1
# 		rather than NULL if both operands are NULL and 0 rather than NULL if one operand is NULL.
#
# 		The <=> operator is equivalent to the standard SQL IS NOT DISTINCT FROM operator.
#
# 			SELECT 1 <=> 1, NULL <=> NULL, 1 <=> NULL;
# 				-> 1, 1, 0
#
# 			SELECT 1 = 1, NULL = NULL, 1 = NULL;
# 				-> 1, NULL, NULL
#
# 		For row comparisons, (a,b) <=> (x,y) is equivalent to:
#
# 			(a <=> x) AND (b <=> y)
#
# ) <>, !=
#
# 		Not equal:
#
# 			SELECT '.01' <> '0.01';
# 				-> 1
# 			SELECT .01 <> '0.01';
# 				-> 0
#			SELECT 'zapp' <> 'zappp';
# 				-> 1
#
# 		For row comparisons, (a,b) <> (x, y) and (a,b) != (x,y) are equivalent to:
#
# 			(a <> x) OR (b <> y)
#
# ) <=
#
# 		Less than or equal:
#
# 			SELECT 0.1 <= 2;
# 				-> 1
#
# 		For row comparisons, (a, b) <= (x, y) is equivalent to:
#
# 			(a < x) OR ((a = x) AND (b <= y))
#
# ) < 
#
# 		Less than:
#
# 			SELECT 2 < 2;
# 				-> 0
#
# 		For row comparisons, (a, b) < (x, y) is equivalent to.
#
# 			(a < x) OR ((a = x) AND (b < y))
#
# ) >=
#
# 		Greater than or equal:
#
# 			SELECT 2 >= 2;
# 				-> 1
#
# 		For row comparisons, (a, b) >= (x, y) is equivalent to:
#
# 			(a > x) OR ((a = x) AND (b >= y))
#
# ) >
#
# 		Greater than:
#
# 			SELECT 2 > 2;
# 				-> 0
#
# 		For row comparisons, (a, b) > (x, y) is equivalent to:
#
# 			(a > x) OR ((a = x) AND (b > y))
#
# ) IS_boolean_value
#
# 		Tests a value against a boolean value, where boolean_value can be TRUE, FALSE, or UNKNOWN.
#
# 			SELECT 1 IS TRUE, 0 IS FALSE, NULL IS UNKNOWN;
# 				-> 1, 1, 1
#
# ) IS_NOT_boolean_value
#
# 		Test a value against a boolean value, where boolean_value can be TRUE, FALSE or UNKNOWN.
#
# 			SELECT 1 IS NOT UNKNOWN, 0 IS NOT UNKNOWN, NULL IS NOT UNKNOWN;
# 				-> 1, 1, 0
#
# ) IS_NULL
#
# 		Test whether a value is NULL
#
# 			SELECT 1 IS NULL, 0 IS NULL, NULL IS NULL;
# 				-> 0, 0, 1
#
# 		To work well with ODBC programs, MySQL supports the following extra features when using IS_NULL:
#
# 			) If sql_auto_is_null variable is set to 1, then after a statement that successfully inserts an
# 				automatically generated AUTO_INCREMENT value, you can find that value by issuing a statement
# 				of the following form:
#
# 					SELECT * FROM tbl_name WHERE auto_col IS NULL
#
# 				If the statement returns a row, the value returned is the same as if you invoked the 
# 				LAST_INSERT_ID() function.
#
# 				For details, including the return value after a multiple-row insert, see SECTION 12.15, "INFORMATION FUNCTIONS"
#
# 				If no AUTO_INCREMENT value was successfully inserted, the SELECT statement returns no row.
#
# 				The behavior of retrieving an AUTO_INCREMENT value by using an IS_NULL comparison can be disabled
# 				by setting sql_auto_is_null = 0
#
# 				See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 				The default value of sql_auto_is_null is 0
#
# 			) For DATE and DATETIME columns that are declared as NOT NULL, you can find the special date
# 				'0000-00-00' by using a statement like this:
#
# 					SELECT * FROM tbl_name WHERE date_column IS NULL
#
# 				This is needed to get some ODBC applications to work because ODBC does not support a
# 				'0000-00-00' date value.
#
# 				See OBTAINING AUTO-INCREMENT VALUES, and the description for the FLAG_AUTO_IS_NULL option at 
# 				CONNECTOR/ODBC CONNECTION PARAMETERS
#
# 		) IS_NOT_NULL
#
# 			Tests whether a value is not NULL.
#
# 			SELECT 1 IS NOT NULL, 0 IS NOT NULL, NULL IS NOT NULL;
# 				-> 1, 1, 0
#
# 		) expr_BETWEEN_min_AND_max
#
# 			If expr is greater than or equal to min and expr is less than or equal to max, BETWEEN returns 1, otherwise it returns 0.
#
# 			This is equivalent to the expression (min <= expr AND expr <= max) if all the arguments are of the same type.
#
# 			Otherwise type conversion takes place according to the rules described in SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION",
# 			but applied to all the three arguments.
#
# 				SELECT 2 BETWEEN 1 AND 3, 2 BETWEEN 3 AND 1;
# 					-> 1, 0
# 				SELECT 1 BETWEEN 2 AND 3;
#  				-> 0
#
# 				SELECT 'b' BETWEEN 'a' AND 'c';
# 					-> 1
# 				SELECT 2 BETWEEN 2 AND '3';
# 					-> 1
#
# 				SELECT 2 BETWEEN 2 AND 'x-3';
# 					-> 0
#
# 			For best results when using BETWEEN with date or time values, use CAST() to explicitly convert the values
# 			to the desired data type.
#
# 			Examples:
#
# 				If you compare a DATETIME to two DATE values, convert the DATE values to DATETIME values.
#
# 				If you are to use a string constant such as '2001-1-1' in a comparison to a DATE, cast the string
# 				a DATE.
#
# 		) expr_NOT_BETWEEN_min_AND_max
#
# 			This is the same as NOT (expr BETWEEN min AND max)
#
# 		) COALESCE(value, ---)
#
# 			Returns the first non-NULL value in the list, or NULL if there are no non-NULL values.
#
# 			The return type of COALESCE() is the aggregated type of the argument types.
#
# 				SELECT COALESCE(NULL,1);
# 					-> 1
#
# 				SELECT CCOALESCE(NULL, NULL, NULL);
# 					-> NULL
#
# 		) GREATEST(value1, value2, ---)
#
# 			With two or more arguments, returns the largest (maximum-value) argument.
#
# 			The arguments are compared using the same rules as for LEAST()
#
# 				SELECT GREATEST(2,0);
# 					-> 2
# 				SELECT GREATEST(34.0,3.0, 5.0, 767.0);
# 					-> 767.0
# 				SELECT GREATEST('B', 'A', 'C');
# 					-> 'C'
#
# 				GREATEST() returns NULL if any argument is NULL
#
# 		) expr_IN_(value,---)
#
# 			Returns 1 if expr is equal to any of the values in the IN list, else returns 0.
#
# 			If all values are constants, they are evaluated according to the type of expr
# 			and sorted.
#
# 			The search for the item then is done using a binary search.
#
# 			This means IN is very quick if the IN value list consists entirely of constants.
#
# 			Otherwise, type conversion takes place according to the rules described in
# 			SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION", but applied to all
# 			the arguments.
#
# 				SELECT 2 IN (0, 3, 5, 7);
# 					-> 0
#
# 				SELECT 'wefwf' IN ('wee', 'wefwf', 'weg');
# 					-> 1
#
# 			IN can be used to compare row constructors:
#
# 				SELECT (3,4) IN ((1,2), (3,4));
# 					-> 1
#
# 				SELECT (3,4) IN ((1,2), (3,5));
# 					-> 0
#
# 			You should never mix quoted and unquoted values in an IN list because the comparison rules
# 			for quoted values (such as strings) and unquoted values (such as numbers) differ.
#
# 			Mixing types may therefore lead to inconsistent results.
#
# 			For example, do not write an IN expression like this:
#
# 				SELECT val1 FROM tbl1 WHERE val1 IN (1,2, 'a');
#
# 			Instead, write it like this:
#
# 				SELECT val1 FROM tbl1 WHERE val1 IN ('1', '2', 'a');
#
# 			The number of values in the IN list is only limited by the max_allowed_packet value.
#
# 			To comply with the SQL standard, IN returns NULL not only if the expression on the left
# 			hand side is NULL, but also if no match is found in the list and one of the expression
# 			in the list is NULL.
#
# 			IN() syntax cal also be used to write certain types of subqueries.
#
# 			See SECTION 13.2.11.3, "SUBQUERIES WITH ANY, IN, OR SOME"
#
# 		) expr_NOT_IN_(value, ---)
#
# 			This is the same as NOT (expr IN (value, ---))
#
# 		) ISNULL(expr)
#
# 			If expr is NULL, ISNULL() returns 1, otherwise, it returns 0.
#
# 				SELECT ISNULL(1+1);
# 					-> 0
# 				SELECT ISNULL(1/0);
# 					-> 1
#
# 			ISNULL() can be used instead of = to test whether a value is NULL.
#
# 			(Comparing a value to NULL using = ALWAYS yields NULL)
#
# 			The ISNULL() function shares some special behaviors with the IS_NULL comparison operator.
#
# 			See the description of IS_NULL.
#
# 		) INTERVAL(N,N1,N2,N3,---)
#
# 			Returns 0 if N < N1, 1 if N < N2 and so on, or -1 if N is NULL.
#
# 			All arguments are treated as integers.
#
# 			It is required that N1 < N2 < N3 < --- < Nn for this function to work correctly.
#
# 			THis is because a binary search is used (very fast)
#
# 				SELECT INTERVAL(23, 1, 15, 17, 30, 44, 200);
# 					-> 3
#
# 				SELECT INTERVAL(10, 1, 10, 100, 1000);
# 					-> 2
#
# 				SELECT INTERVAL(22, 23, 30, 44, 200);
# 					-> 0
#
# 		) LEAST(value1, value2)
#
# 			With two or more arguments, returns the smallest (minimum-valued) argument.
# 			The arguments are compared using the following rules:
#
# 				) If any argument is NULL, the result is NULL. No comparison is needed.
#
# 				) If all arguments are integer-valued, they are compared as integers
#
# 				) If at least one argument is double precision, they are compared as double-precision values.
#
# 					Otherwise, if at least one argument is a DECIMAL value, they are compared as DECIMAL values.
#
# 				) If hte argument comprises a mix of numbers and strings, they are compared as numbers.
#
# 				) If any argument is a nonbinary (character) string, the arguments are compared as nonbinary strings.
#
# 				) In all other cases, the arguments are compared as binary strings.
#
# 			The return type of LEAST() is the aggregated type of the comparison argument types.
#
# 				SELECT LEAST(2,0);
# 					-> 0
# 				SELECT LEAST(34.0, 3.0, 5.0, 767.0);
# 					-> 3.0
# 				SELECT LEAST('B', 'A', 'C');
# 					-> 'A'
#
# 12.3.3 LOGICAL OPERATORS
#
# TABLE 12.4 LOGICAL OPERATORS
#
# NAME 		DESCRIPTION
#
# AND, && 	Logical AND
#
# NOT, ! 	Negates value
#
# ||, OR 	Logical OR
#
# XOR 		Logical XOR
#
# In SQL, all logical operators evaluate to TRUE, FALSE or NULL (UNKNOWN).
#
# In MySQL, these are implemented as 1 (TRUE), 0 (FALSE) and NULL.
#
# Most of this is common to different SQL db servers, although some servers may
# return any nonzero value for TRUE.
#
# MySQL evaluates any nonzero, non-NULL value to TRUE.
#
# For example, the following statements all assess to TRUE:
#
# 		SELECT 10 IS TRUE;
# 		-> 1
# 		SELECT -10 IS TRUE;
# 		-> 1
# 		SELECT 'string' IS NOT NULL;
# 		-> 1
#
# ) NOT, !
#
# 		Logical NOT. Evaluates to 1 if the operand is 0, to 0 if the operand is nonzero,
# 		and NOT NULL returns NULL
#
# 			SELECT NOT 10;
# 			-> 0
#
# 			SELECT NOT 0;
# 			-> 1
#
# 			SELECT NOT NULL;
# 			-> NULL
#
# 			SELECT ! (1+1);
# 			-> 0
#
# 			SELECT ! 1+1;
# 			-> 1
#
# 		The last example produces 1 because the expression evaluates the same way as (!1)+1
#
# ) AND, &&
#
# 		Logical AND.
#
# 		Evaluates to 1 if all operands are nonzero and not NULL, to 0 if one or more operands
# 		are 0, otherwise NULL is returned.
#
# 			SELECT 1 AND 1;
# 				-> 1
#
# 			SELECT 1 AND 0;
# 				-> 0
#
# 			SELECT 1 AND NULL;
# 				-> NULL
#
# 			SELECT 0 AND NULL;
# 				-> 0
#
# 			SELECT NULL AND 0;
# 				-> 0
#
# ) OR, ||
#
# 		Logical OR.
#
# 		When both operans are non-NULL, the result is 1 if any operand is nonzero, and 0 otherwise.
#
# 		With a NULL operand, the result is 1 if the other operand is nonzero, and NULL otherwise.
#
# 		If both operands are NULL, the result is NULL.
#
# 			SELECT 1 OR 1;
# 			-> 1
#
# 			SELECT 1 OR 0;
# 			-> 1
#
# 			SELECT 0 OR 0;
# 			-> 0
#
# 			SELECT 0 OR NULL;
# 			-> NULL
#
# 			SELECT 1 OR NULL;
# 			-> 1
#
# ) XOR
#
# 		Logical XOR.
#
# 		Returns NULL if either operand is NULL.
#
# 		For non-NULL operands, evaluates to 1 if an odd number of operands is nonzero,
# 		otherwise 0 is returned.
#
# 			SELECT 1 XOR 1;
# 			-> 0
#
# 			SELECT 1 XOR 0;
# 			-> 1
#
# 			SELECT 1 XOR NULL;
# 			-> NULL
#
# 			SELECT 1 XOR 1 XOR 1;
# 			-> 1
#
# 		a XOR b is mathematically equal to (a AND (NOT b)) OR ((NOT a) AND b)
#
# 12.3.4 ASSIGNMENT OPERATORS
#
# TABLE 12.5 ASSIGNMENT OPERATORS
#
# Name 			Desc
#
# = 				Assigns a value (as part of SET statement, or as part of hte SET clause in an UPDATE statement)
#
# := 				ASsign a value
#
# 		) :=
#
# 			Assignment operator.
#
# 			Causes the user variable on the left hand side of the operator to take on the value
# 			to its right.
#
# 			The value on the right hand side may be a literal value, another variable storing a value,
# 			or any legal expression that yields a scalar value, including the result of a query (provided that
# 			this value is a scalar value)
#
# 			You can perform multiple assignments in the same SET statement.
#
# 			You can perform multiple assignments in the same statement.
#
# 			UNlike =, the := operator is never interpreted as a comparison operator.
#
# 			THis means that you can use := in any valid SQL statement (not just in SET statements)
# 			to assign a value to a variable.
#
# 				SELECT @var1, @var2;
# 					-> NULL, NULL
#
# 				SELECT @var1 := 1, @var2;
# 					-> 1, NULL
#
# 				SELECT @var1, @var2;
# 					-> 1, NULL
#
# 				SELECT @var1, @var2 := @var1;
# 					-> 1, 1
#
# 				SELECT @var1, @var2;
# 					-> 1, 1
#
# 				SELECT @var1:=COUNT(*) FROM t1;
# 					-> 4
# 				SELECT @var1;
# 					-> 4
#
# 			You can make value assignments using := in other statements besides SELECT,
# 			such as UPDATE as shown here:
#
# 				SELECT @var1;
# 					-> 4
#
# 				SELECT * FROM t1;
# 					-> 1, 3, 5, 7
#
# 				UPDATE t1 SET c1 = 2 WHERE c1 = @var1 := 1;
# 				Query OK, 1 row affected (0.00 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT @var1;
# 					-> 1
# 				SELECT * FROM t1;
# 					-> 2, 3, 5, 7
#
# 			While it is also possible both to set and to read the value of the same variable in a single SQL statement
# 			using the := operator, this is not recommended.
#
# 			SECTION 9.4, "USER-DEFINED VARIABLES", explains why you should avoid doing this.
#
# 		) =
#
# 			This operator is used to perform value assignments in two cases, described here.
#
# 			Within a SET statement, = is treated as an assignment operator that causes the user variable
# 			on the left hand side of the operator to take on the value to its right.
#
# 			(In other words, when used in a SET statement, = is treated identically to :=)
#
# 			The value on the right hand side may be a literal value, another variable storing
# 			a value, or any legal expression that yields a scalar value, including the result of a query
# 			(provided that this value is a scalar value)
#
# 			You can perform multiple assignments in the same SET statement.
#
# 			In the SET clause of an UPDATE statement, = also acts as an assignment operator;
#
# 			IN this case, however, it causes the column named on the left hand side of the operator
# 			to assume the value given to the right, provided any WHERE conditions that are part of
# 			the UPDATE are met.
#
# 			You can make multiple assignments in the same SET clause of an UPDATE statement.
#
# 			In any other context, = is treated as a comparison operator.
#
# 				SELECT @var1, @var2;
# 					-> NULL, NULL
#
# 				SELECT @var1 := 1, @var2;
# 					-> 1, NULL
#
# 				SELECT @var1, @var2;
# 					-> 1, NULL
#
# 				SELECT @var1, @var2 := @var1;
# 					-> 1, 1
#
# 				SELECT @var1, @var2;
# 					-> 1, 1
#
# 			For more information, see SECTION 13.7.5.1, "SET SYNTAX FOR VARIABLE ASSIGNMENT",
# 			SECTION 13.2.12, "UPDATE SYNTAX" and SECTION 13.2.11, "SUBQUERY SYNTAX"
#
# 12.4 CONTROL FLOW FUNCTIONS
#
# TABLE 12.6 FLOW CONTROL OPERATORS
#
# NAME 		DESC
#
# CASE 		Case operator
#
# IF() 		If/else construct
#
# IFNULL() 	Null if/else construct
#
# NULLIF() 	Return NULL if expr1 = expr2
#
# 		) CASE value WHEN [compare value] THEN result [WHEN [compare value] THEN result ---] [ELSE result] END
#
# 			CASE WHEN [condition] THEN result [WHEN [condition] THEN result ---] [ELSE result] END
#
# 			The first CASE syntax returns the result for the first value=compare_value comparison that is true.
#
# 			The second syntax returns the result for the first condition that is true.
#
# 			If no comparison or condition is true, the result after ELSE is returned, or NULL if there is no ELSE part.
#
# 				NOTE:
#
# 					The syntax of the CASE expression described here difers slightly from that of the SQL CASE statement
# 					described in SECTION 13.6.5.1 "CASE SYNTAX", for use inside stored programs.
#
# 					The CASE statement cannot have an ELSE NULL clause, and it is terminated with END CASE instead of END.
#
# 			The return type of a CASE expression result is the aggregated type of all result values:
#
# 				) If all types are numeric, the aggregated type is also numeric:
#
# 					) If at least one argument is double precision, the result is double precision.
#
# 					) Otherwise, if at least one argument is DECIMAL, the result is DECIMAL.
#
# 					) Otherwise, the result is an integer type (with one exception):
#
# 						) If all integer types are all signed or all unsigned, the result is the same sign and the precision
# 							is the highest of all specified integer types (that is, TINYINT, SMALLINT, MEDIUMINT, INT or BIGINT)
#
# 						) If there is a combination of signed and unsigned integer types, the result is signed and the precision may
# 							be higher.
#
# 							For example, if the types are signed INT and unsigned INT, the result is signed BIGINT.
#
# 						) The exception is unsigned BIGINT combined with any signed integer type.
#
# 							The result is DECIMAL with sufficient precision and scale 0.
#
# 				) If all types are BIT, the result is BIT. Otherwise, BIT arguments are treated similar to BIGINT.
#
# 				) If all types are YEAR, teh result is YEAR. Otherwise, YEAR arguments are treated similar to INT.
#
# 				) If all types are character string (CHAR or VARCHAR), the result is VARCHAR with maximum length
# 					determined by the longest character length of the operands.
#
# 				) If all types are character or binary string, the result is VARBINARY
#
# 				) SET and ENUM are treated similar to VARCHAR; the result is VARCHAR
#
# 				) If all types are JSON, the result is JSON
#
# 				) If all types are temporal, the result is temporal:
#
# 					) If all temporal types are DATE, TIME, or TIMESTAMP, the result is DATE, TIME or TIMESTAMP, respectively.
#
# 					) Otherwise, for a mix of temporal types, teh result is DATETIME
#
# 				) If all types are GEOMETRY, the result is GEOMETRY.
#
# 				) If any type is BLOB, the result is BLOB.
#
# 				) For all other type combinations, the result is VARCHAR.
#
# 				) Literal NULL operands are ignored for type aggregation.
#
# 					SELECT CASE 1 WHEN 1 THEN 'one'
# 						-> WHEN 2 THEN 'two' ELSE 'more' END;
# 						-> 'one'
#
# 					SELECT CASE WHEN 1>0 THEN 'true' ELSE 'false' END;
# 						-> 'true'
#
# 					SELECT CASE BINARY 'B'
# 							WHEN 'a' THEN 1 WHEN 'b' THEN 2 END;
# 					-> NULL
#
# 		) IF(expr1, expr2, expr3)
#
# 			If expr1 is TRUE (expr1 <> 0 and expr1 <> NULL), IF() returns expr2.
#
# 			Otherwise, it returns expr3.
#
# 				NOTE:
#
# 					THere is also an IF statement, which differs from the IF() function described here. 
# 					See SECTION 13.6.5.2, "IF SYNTAX"
#
# 			If only one of expr2 or expr3 is explicitly NULL, the result type of the IF() function is the type
# 			of the non-NULL expression.
#
# 			The default return type of IF() (which may matter when it is stored into a temporary table) is calculated
# 			as follows:
#
# 				) If expr2 or expr3 produce a string, the result is a string
#
# 				  If expr2 and expr3 are both strings, the result is case-sensitive if either string
# 					is case sensitive.
#
# 				) If expr2 or expr3 produce a floating-point value, the result is a floating-point value
#
# 				) If expr2 or expr3 produce an integer, the result is an integer.
#
# 					SELECT IF(1>2,2,3);
# 					  -> 3
# 
# 					SELECT IF(1<2, 'yes', 'no');
# 					  -> 'yes'
#
# 					SELECT IF(STRCMP('test', 'test1'), 'no', 'yes');
# 					  -> 'no'
#
# 		) IFNULL(expr1,expr2)
#
# 			If expr1 is not NULL, IFNULL() returns expr1; otherwise it returns expr2
#
# 				SELECT IFNULL(1,0);
# 				  -> 1
#
# 				SELECT IFNULL(NULL,10);
# 				  -> 10
#
# 				SELECT IFNULL(1/0,10);
# 				  -> 10
#
#				SELECT IFNULL(1/0, 'yes');
# 				  -> 'yes'
#
# 			The default return type of IFNULL(expr1,expr2) is the more "general" of the two expressions,
# 			in the order STRING, REAL or INTEGER.
#
# 			Consider the case of a table based on expressions or where MySQL must internally
# 			store a value returned by IFNULL() in a temporary table:
#
# 				CREATE TABLE tmp SELECT IFNULL(1, 'test') AS test;
# 				DESCRIBE tmp;
# 				+----------+------------------+----------+----------+------------+----------+
# 				| Field    | Type 				| Null 	  | Key 		 | Default 	  | Extra 	 |
# 				+----------+------------------+----------+----------+------------+----------+
# 				| test 	  | varbinary(4) 	   | NO 		  | 			 | 			  | 			 |
# 				+----------+------------------+----------+----------+------------+----------+
#
# 			In this example, the type of the test column is VARBINARY(4) (a string type)
#
# 		) NULLIF(expr1,expr2)
#
# 			Returns NULL if expr1 = expr2 is true, otherwise returns expr1.
#
# 			This is the same as CASE_WHEN_expr1 = expr2 THEN_NULL_ELSE expr1 END
#
# 			The return value has the same type as the first argument.
#
# 				SELECT NULLIF(1,1);
# 				  -> NULL
# 				SELECT NULLIF(1,2);
# 				  -> 1
#
# 			NOTE:
#
# 				MySQL evaluates expr1 twice if the arguments are not equal.
#
# 12.5 STRING FUNCTIONS
#
# 	12.5.1 STRING COMPARISON FUNCTIONS
#
# 	12.5.2 REGULAR EXPRESSIONS
#
# 	12.5.3 CHARACTER SET AND COLLATION OF FUNCTION RESULTS
#
# 	TABLE 12.7 STRING OPERATORS
#
# 	NAME 							Desc
#
# 	ASCII() 						Return numeric value of left-most character
#
# 	BIN() 						Return a string containing binary representation of a number
#
# 	BIT_LENGTH() 				Return length of argument in bits
#
# 	CHAR() 						Return the character of each integer passed
#
# 	CHAR_LENGTH() 				Return number of characters in argument
#
# 	CHARACTER_LENGTH() 		Synonym for CHAR_LENGTH()
#
# 	CONCAT() 					Return concatenated string
#
# 	CONCAT_WS() 				Return concatenate with separator
#
# 	ELT() 						Return string at index number
#
# 	EXPORT_SET() 				Return a string such that for every bit set in the value bits,
# 									you get an on string and for every unset bit, you get an off string
#
# 	FIELD() 						Return the index (position) of the first argument in the subsequent arguments
#
# 	FIND_IN_SET() 				Return the index position of the first argument within the second argument
#
# 	FORMAT() 					Return a number formatted to specified number of decimal places
#
# 	FROM_BASE64() 				Decode base64 encoded string and return result
#
#  HEX() 						Return a hexadecimal representation of a decimal or string value
#
#  INSERT() 					Insert a substring at the specified position up to the specified number of characters
#
# 	INSTR() 						Return the index of the first occurence of substring
#
# 	LCASE() 						Synonym for LOWER()
#
#  LEFT() 						Return the leftmost number of characters as specified
#
#  LENGTH() 					Return the length of a string in bytes
#
#  LIKE 							Simple pattern matching
#
#  LOAD_FILE() 			   Load the named file
#
#  LOCATE() 					Return the position of the first occurence of substring
#
#  LOWER() 						Return the argument in lowercase
#
#  LPAD() 						Return the string argument, left-padded with the specified string
#
#  LTRIM() 						Remove leading spaces
#
# 	MAKE_SET() 					Return a set of comma-separated strings that have the corresponding bit in bits set
#
# 	MATCH 						Perform full-text search
#
#  MID() 						Return a substring starting from the specified position
#
# 	NOT_LIKE 					Negation of simple pattern matching
#
#  NOT_REGEXP 					Negation of REGEXP
#
#  OCT() 						Return a string containing octal representation of a number
#
# 	OCTET_LENGTH() 			Synonym for LENGTH()
#
# 	ORD() 						Return character code for leftmost character of the argument
#
# 	POSITION() 					Synonym for LOCATE()
#
#  QUOTE() 						Escape the argument for use in an SQL statement
#
# 	REGEXP 						Whether string matches regular expression
#
# 	REGEXP_INSTR() 			Starting index of substring matching regular expression
#
# 	REGEXP_LIKE() 				Whether string matches regular expression
#
# 	REGEXP_REPLACE() 			Replace substrings matching regular expression
#
# 	REGEXP_SUBSTR() 			Return substring matching regular expression
#
# 	REPEAT() 					Repeat a string the specified number of times
#
# 	REPLACE() 					Replace occurences of a specified string
#
# 	REVERSE() 					Reverse the characters in a string
#
# 	RIGHT() 						Return the specified rightmost number of characters
#
# 	RLIKE 						Whether string matches regular expression
#
# 	RPAD() 						Append string the specified number of times
#
# 	RTRIM() 						Remove trailing spaces
#
# 	SOUNDEX() 					Return a soundex string
#
# 	SOUNDS_LIKE 				Compare sounds
#
# 	SPACE() 						Return a string of the specified number of spaces
#
# 	STRCMP() 					Compare two strings
#
# 	SUBSTR() 					Return the substring as specified
#
# 	SUBSTRING() 				Return the substring as specified
#
# 	SUBSTRING_INDEX() 		Return a substring from a string before the specified number of occurences of the delimiter
#
# 	TO_BASE64() 				Return the argument converted to a base-64 string
#
# 	TRIM() 						Remove leading and trailing spaces
#
# 	UCASE() 						Synonym for UPPER()
#
# 	UNHEX() 						Return a string containing hex representation of a number
#
# 	UPPER() 						Convert to uppercase
#
# 	WEIGHT_STRING() 			Return the weight string for a string
#
# String-valued functions return NULL if the length of the result would be greater than the
# value of the max_allowed_packet system variable.
#
# See SECTION 5.1.1, "CONFIGURING THE SERVER"
#
# For functions that operate on string positions, the first position is numbered 1
#
# For functions that take length arguments, noninteger arguments are rounded to the 
# nearest integer.
#
# 		) ASCII(str)
#
# 			Returns the numeric value of the leftmost character of the string str.
#
# 			Returns 0 if str is the empty string.
#
# 			Returns NULL if str is NULL.
#
# 			ASCII() works for 8-bit characters.
#
# 				SELECT ASCII('2');
# 					-> 50
#
# 				SELECT ASCII(2);
# 					-> 50
#
# 				SELECT ASCII('dx');
# 					-> 100
#
# 			See also the ORD() function
#
# 		) BIN(N)
#
# 			Returns a string representation of the binary value of N, where N is a longlong (BIGINT) number.
#
# 			This is equivalent to CONV(N,10,2)
#
# 			Returns NULL if N is NULL.
#
# 				SELECT BIN(12);
# 					-> '1100'
#
# 		) BIT_LENGTH(str)
#
# 			Returns the length of the str in bits.
#
# 				SELECT BIT_LENGTH('text');
# 					-> 32
#
# 		) CHAR(N, --- [USING charset_name])
#
# 			CHAR() interprets each argument N as an integer and returns a string consisting of the
# 			characters given by the code values of those integers.
#
# 			NULL values are skipped.
#
# 				SELECT CHAR(77,121,83,81,'76');
# 					-> 'MySQL'
# 				SELECT CHAR(77, 77.3, '77.3');
# 					-> 'MMM'
#
# 			CHAR() arguments larger than 255 are converted into multiple result bytes.
#
# 			For example, CHAR(256) is equivalent to CHAR(1, 0) and CHAR(256*256) is equivalent to
# 			CHAR(1,0,0)
#
# 				SELECT HEX(CHAR(1,0)), HEX(CHAR(256));
# 				+-------------------+-----------------+
# 				| HEX(CHAR(1,0)) 	  | HEX(CHAR(256))  |
# 				+-------------------+-----------------+
# 				| 0100 				  | 0100 			  |
# 				+-------------------+-----------------+
#
# 				SELECT HEX(CHAR(1,0,0)), HEX(CHAR(256*256));
# 				+-------------------+-----------------+
# 				| HEX(CHAR(1,0,0))  | HEX(CHAR(256*256|
# 				+-------------------+-----------------+
# 				| 010000 			  | 010000 			  |
# 				+-------------------+-----------------+
#
# 			By default, CHAR() returns a binary string.
#
# 			To produce a string in a given character set, use the optional
# 			USING clause:
#
# 				SELECT CHARSET(CHAR(X'65')), CHARSET(CHAR(X'65' USING utf8));
# 				+------------------------------+----------------------------------+
# 				| CHARSET(CHAR(X'65')) 			 | CHARSET(CHAR(X'65' USING utf8))  |
# 				+------------------------------+----------------------------------+
# 				| binary 							 | utf8 										|
# 				+------------------------------+----------------------------------+
#
# 			If USING is given and the result string is illegal for the given character set, a warning is issued.
#
# 			Also, if strict SQL mode is enabled, the result from CHAR() becomes NULL
#
# 		) CHAR_LENGTH(str)
#
# 			Returns the length of the string str, measured in characters.
#
# 			A multibyte character counts as a single character.
#
# 			This means that for a string containing five 2-byte characters,
# 			LENGTH() returns 10, whereas CHAR_LENGTH() returns 5
#
# 		) CHARACTER_LENGTH(str)
#
# 			CHARACTER_LENGTH() is a synonym for CHAR_LENGTH()
#
# 		) CONCAT(str1, str2, ---)
#
# 			Returns the string that results from concatenating the arguments.
#
# 			May have one or more arguments.
#
# 			If all arguments are nonbinary strings, the result is a nonbinary
# 			string.
#
# 			If the arguments include any binary strings, the result is a binary string.
#
# 			A numeric argument is converted to its equivalent nonbinary string form.
#
# 			CONCAT() returns NULL if any argument is NULL.
#
# 				SELECT CONCAT('My', 'S', 'QL');
# 					-> 'MySQL'
#
# 				SELECT CONCAT('My', NULL, 'QL');
# 					-> NULL
#
# 				SELECT CONCAT(14.3);
# 					-> '14.3'
#
# 			For quoted strings, concatenation can be performed by placing the strings
# 			next to each other:
#
# 				SELECT 'My' 'S' 'QL';
# 					-> 'MySQL'
#
# 		) CONCAT_WS(separator, str1, str2, ---)
#
# 			CONCAT_WS() stands for Concatenate With Separator and is a special form of CONCAT().
#
# 			The first argument is the separator for the rest of the arguments.
#
# 			The separator is added between the strings to be concatenated.
#
# 			The separator can be a string, as can the rest of the argumnets.
# 			If the separator is NULL, the result is NULL.
#
# 				SELECT CONCAT_WS(',','First name', 'Second name', 'Last Name');
# 					-> 'First name,Second name,Last Name'
# 				SELECT CONCAT_WS(',','First name', NULL, 'Last Name');
# 					-> 'First name, Last Name'
#
# 			CONCAT_WS() does not skip empty strings.
#
# 			However, it does skip any NULL values after the separator argument.
#
# 		) ELT(N, str1, str2, str3, ---)
#
# 			ELT() returns the Nth element of the list of strings:
#
# 				str1 if N = 1, str2 if N = 2, etc.
#
# 			Returns NULL if N less than 1 or greater than the number of arguments.
#
# 			ELT() is the complement of FIELD()
#
# 				SELECT ELT(1, 'Aa', 'Bb', 'Cc', 'Dd');
# 					-> 'Aa'
# 				SELECT ELT(4, 'Aa', 'Bb', 'Cc', 'Dd');
#
# 		) EXPORT_SET(bits, on, off[, separator[, number of bits]])
#
# 			Returns a string such that for every bit set in the value bits, you get an
# 			on string and for every bit not set in the value, you get an off string.
#
# 			Bits in bits are examined from right to left (from low-order to high-order bits)
#
# 			Strings are added to the result from left to right, separated by the separator string
# 			(the default being the comma character ,)
#
# 			The number of bits examined is given by number_of_bits, which has a default of 64
# 			if not specified.
#
# 			number_of_bits is silently clipped to 64 if larger than 64.
#
# 			It is treated as an unsigned integer, so a value of -1 is effectively the same as 64.
#
# 				SELECT EXPORT_SET(5, 'Y', 'N', ',', 4);
# 					-> 'Y,N,Y,N'
#
# 				SELECT EXPORT_SET(6, '1','0', ',', 10);
# 					-> '0,1,1,0,0,0,0,0,0'
#
# 		) FIELD(str, str1, str2, str3, ---)
#
# 			Returns the index (position) of str in the str1, str2, str3, --- list.
#
# 			Returns 0 if str is not found.
#
# 			If all arguments to FIELD() are strings, all arguments are compared as strings.
#
# 			If all arguments are numbers, they are compared as numbers.
#
# 			Otherwise, the arguments are compared as double.
#
# 			If str is NULL, the return value is 0 because NULL fails equality comparison
# 			with any value.
#
# 			FIELD() is the complement of ELT()
#
# 				SELECT FIELD('Bb', 'Aa', 'Bb', 'Cc', 'Dd', 'Ff');
# 					-> 2
#
# 				SELECT FIELD('Gg', 'Aa', 'Bb', 'Cc', 'Dd', 'Ff');
# 					-> 0
#
# 		) FIND_IN_SET(str, strlist)
#
# 			Returns a value in the range of 1 to N if the string is in the string list strlist consisting
# 			of N substrings.
#
# 			A string list is a string composed of substrings separated by , characters.
#
# 			If the first argument is a constant string and the second is a column of type SET,
# 			the FIND_IN_SET() function is optimized to use bit arithmetic.
#
# 			Returns 0 if str is not in strlist or if strlist is the empty string.
#
# 			Returns NULL if either argument is NULL.
#
# 			This function does not work properly if the first argument contains a comma
# 			(,) character
#
# 				SELECT FIND_IN_SET('b', 'a,b,c,d');
# 					-> 2
#
# 		) FORMAT(X,D[,locale])
#
# 			Formats the number X to a format like '#,###,###.##', rounded to D decimal palces, and returns
# 			the result as a string.
#
# 			If D is 0, the result has no decimal point or fractional part.
#
# 			The optional third parameter enables a locale to be specified to be used for the
# 			result number's decimal point, thousands separator, and grouping between
# 			separators.
#
# 			Permissible locale values are the same as the legal values for the lc_time_names system variable
# 			(see SECTION 10.15, "MySQL SERVER LOCALE SUPPORT")
#
# 			If no locale is specified, the default is 'en_US'
#
# 				SELECT FORMAT(12332.123456, 4);
# 					-> '12, 332.1235'
#
# 				SELECT FORMAT(12332.1, 4);
# 					-> '12, 332.1000'
#
# 				SELECT FORMAT(12332.2, 0);
# 					-> '12, 332'
#
# 				SELECT FORMAT(12332.2, 2, 'de_DE');
# 					-> '12.332,20'
#
# 		) FROM_BASE64(str)
#
# 			Takes a string encoded with the base-64 encoded rules used by TO_BASE64() and returns
# 			the decoded result as a binary string.
#
# 			The result is NULL if the argument is NULL or not a valid base-64 string.
#
# 			See the description of TO_BASE64() for details about the encoding and decoding
# 			rules.
#
# 				SELECT TO_BASE64('abc'), FROM_BASE64(TO_BASE64('abc'));
# 					-> 'JWJj', 'abc'
#
# 		) HEX(str), HEX(N)
#
# 			For a string argument str, HEX() returns a hexadecimal string representation of str where
# 			each byte of each character in str is converted to two hexadecimal digits.
#
# 			(Multibyte characters therefore become more than two digits)
#
# 			The inverse of this operation is performed by the UNHEX() function
#
# 			For a numeric argument N, HEX() returns a hexadecimal string representation of the value
# 			of N treated as a longlong (BIGINT) number.
#
# 			This is equivalent to CONV(N,10,16)
#
# 			The inverse of this operation is performed by CONV(HEX(N), 16, 10)
#
# 				SELECT X'616263', HEX('abc'), UNHEX(HEX('abc'));
# 						-> 'abc', 616263, 'abc'
#
# 				SELECT HEX(255), CONV(HEX(255), 16, 10);
# 						-> 'FF', 255
#
# 		) INSERT(str, pos, len, newstr)
#
# 			Returns the string str, with the substring beginning at position pos and len characters
# 			long replaced by the string newstr.
#
# 			Returns the original string if pos is not within the length of the string.
#
# 			Replaces the rest of the string from the position pos if len is not written within
# 			the length of the rest of the string.
#
# 			Returns NULL if any argument is NULL.
#
# 				SELECT INSERT('Quadratic', 3, 4, 'What');
# 					-> 'QuWhattic'
#
# 				SELECT INSERT('Quadratic', -1, 4, 'What');
# 					-> 'Quadratic';
#
# 				SELECT INSERT('Quadratic', 3, 100, 'What');
# 					-> 'QuWhat'
#
# 			This function is multibyte safe.
#
# 		) INSTR(str, substr)
#
# 			Returns the position of the first occurence of substring substr in string str.
#
# 			THis is the same as the two-argument form of LOCATE(), except that hte order
# 			of the arguments is reversed.
#
# 				SELECT INSTR('foobarbar', 'bar');
# 					-> 4
#
# 				SELECT INSTR('xbar', 'foobar');
# 					-> 0
#
# 			This function is multibyte safe, and is case-sensitive only if at least one argument is a binary string.
#
# 		) LCASE(str)
#
# 			LCASE() is a synonym for LOWER()
#
# 			LCASE() used in a view is rewritten as LOWER() when storing the view's definition. (Bug #12844279)
#
# 		) LEFT(str, len)
#
# 			Returns the leftmost len characters from the string str, or NULL if any argument is NULL.
#
# 				SELECT LEFT('foobarbar', 5);
# 					-> 'fooba'
#
# 			This function is multibyte safe.
#
# 		) LENGTH(str)
#
# 			Returns the length of the string str, measured in bytes.
#
# 			A multibyte character counts as multiple bytes.
#
# 			This means that for a string containing five 2-byte characters,
# 			LENGTH() returns 10, whereas CHAR_LENGTH() returns 5.
#
# 				SELECT LENGTH('text');
# 					-> 4
#
# 			NOTE:
#
# 				The Length() OpenGIS spatial function is named ST_Length() in MySQL.
#
# 		) LOAD_FILE(file name)
#
# 			Reads the file and returns the file contents as a string.
#
# 			To use this function, the file must be located on the server host, you must specify
# 			the full path name to the file, and you must have the FILE privilege.
#
# 			The file must be readable by all and its size less than max_allowed_packet bytes.
#
# 			If the secure_file_priv system variable is set to a nonempty directory name,
# 			the file must be located in that directory.
#
# 			If the file does not exist or cannot be read because one of the preceding conditions
# 			is not satisfied, the function returns NULL.
#
# 			The character_set_filesystem system variable controls interpretation of file names
# 			that are given as literal strings.
#
# 				UPDATE t
# 						SET blob_col=LOAD_FILE('/tmp/picture')
# 						WHERE id=1;
#
# 		) LOCATE(substr, str), LOCATE(substr,str,pos)
#
# 			The first syntax returns the position of the first occurence of substring substr in string str.
#
# 			The second syntax returns the position of the first occurence of substring substr in string str,
# 			starting at position pos.
#
# 			Returns 0 if substr is not in str.
#
# 			Returns NULL if any argument is NULL.
#
# 				SELECT LOCATE('bar', 'foobarbar');
# 					-> 4
#
# 				SELECT LOCATE('xbar', 'foobar');
# 					-> 0
#
# 				SELECT LOCATE('bar', 'foobarbar', 5);
# 					-> 7
#
# 			This function is multibyte safe, and is case-sensitive only if at least one
# 			argument is a binary string.
#
# 		) LOWER(str)
#
# 			Returns the string str with all characters changed to lowercase according to the current
# 			char set mapping.
#
# 			The default is utf8mb4.
#
# 				SELECT LOWER('QUADRATICALLY');
# 					-> 'quadratically'
#
# 			LOWER() (and UPPER)) are ineffective when applied to binary strings (BINARY, VARBINARY, BLOB)
#
# 			To perform lettercase conversion, convert the string to a nonbinary string:
#
# 				SET @str = BINARY 'New York';
# 				SELECT LOWER(@str), LOWER(CONVERT(@str USING utf8mb4));
#
# 				+----------------+------------------------------------+
# 				| LOWER(@str) 	  | LOWER(CONVERT(@str USING utf8mb4)) |
# 				+----------------+------------------------------------+
# 				| New York 		  | new york 									|
# 				+----------------+------------------------------------+
#
# 			For collations of Unicode character sets, LOWER() and UPPER() work according ot the
# 			UNicode Collation Algorithm (UCA) version in teh collation name, if there is one,
# 			and UCA 4.0.0 if no version is specified.
#
# 			For example, utf8mb4_0900_ai_ci and utf8_unicode_520_ci work according to UCA 9.0.0
# 			and 5.2.0, respectively, whereas utf8_unicode_ci works according to UCA 4.0.0
#
# 			See SECTION 10.10.1, "UNICODE CHARACTER SETS"
#
# 			This function is multibyte safe
#
# 			LCASE() used within views is written as LOWER()
#
# 		) LPAD(str,len,padstr)
#
# 			Returns the string str, left-padded with the string padstr to a length of len characters.
#
# 			If str is longer than len, the return value is shortened to len characters.
# 		
# 			
# 				SELECT LPAD('hi',4,'??');
# 					-> '??hi'
#
# 				SELECT LPAD('hi', 1, '??');
# 					-> 'h'
#
# 		) LTRIM(str)
#
# 			Returns the string str with leading space characters removed.
#
# 				SELECT LTRIM('  barbar');
# 					-> 'barbar'
#
# 			This function is multibyte safe.
#
# 		) MAKE_SET(bits, str1, str2, ---)
#
# 			Returns a set value (a string containing substrings separated by , characters)
# 			consisting of the strings taht ahve the corresponding bit in bits set.
#
# 			str1 corresponds to bit 0, str2 to bit 1, and so on.
#
# 			NULL values in str1, str2, --- aren ot appended to the result.
#
# 				SELECT MAKE_SET(1, 'a', 'b', 'c');
# 					-> 'a'
#
# 				SELECT MAKE_SET(1 | 4, 'hello', 'nice', 'world');
# 					-> 'hello,world'
#
# 				SELECT MAKE_SET(1 | 4, 'hello', 'nice', NULL, 'world');
# 					-> 'hello'
#
# 				SELECT MAKE_SET(0, 'a', 'b', 'c');
# 					-> ''
#
# 		) MID(str, pos, len)
#
# 			MID(str,pos,len) is a synonym for SUBSTRING(str,pos,len)
#
# 		) OCT(N)
#
# 			Returns a string representation of the octal value of N, where N is a longlong
# 			(BIGINT) number.
#
# 			This is equivalent to CONV(N,10,8)
#
# 			Returns NULL if N is NULL
#
# 				SELECT OCT(12);
# 					-> '14'
#
# 		) OCTET LENGTH(STR)
#
# 			OCTET_LENGTH() is a synonym for LENGTH()
#
# 		) ORD(str)
#
# 			If the leftmost character of the string str is a multibyte character,
# 			returns the code for that character, calculated form the numeric values
# 			of its constituent bytes using this formula:
#
# 				(1st byte code)
# 			+  (2nd byte code * 256)
# 			+  (3rd byte code * 256^2) ---
#
# 			If the leftmost character is not a multibyte character, ORD() returns 
# 			the same value as the ASCII() function.
#
# 				SELECT ORD('2');;
# 					-> 50
#
# 		) POSITION(substr IN str)
#
# 			POSITION(substr IN str) is a synonym for LOCATE(substr, str)
#
# 		) QUOTE(str)
#
# 			Quotes a string to produce a result that can be used as a properly escaped data value in an SQL statement.
#
# 			The string is returned enclosed by single quotation marks and with each instance of backslash(\),
# 			single quote('), ASCII NUL, and Control+Z preceded by a backslash.
#
# 			If the argument is NULL, the return value is the word "NULL" without ecnlosing single quotation marks.
#
# 				SELECT QUOTE('Don\'t!');
# 					-> 'Don\t!'
# 				SELECT QUOTE(NULL);
# 					-> NULL
#
# 			For comparison, see the quoting rules for literal strings and within the C API in
# 			SECTION 9.1.1, "STRING LITERALS", and "SECTION 28.7.7.56, "MYSQL_REAL_ESCAPE_STRING_QUOTE()"
# 			for more info.
#
# 		) REPEAT(str, count)
#
# 			Returns a string consisting of the string str repeated count times.
#
# 			If count is less than 1, returns an empty string.
#
# 			Returns NULL if str or count are NULL.
#
#
# 				SELECT REPEAT('MySQL', 3);
# 					-> 'MySQLMySQLMySQL'
#
# 		) REPLACE(str, from str, to str)
#
# 			Returns the string str with all occurences of the string from_str replaced by the string 
# 			to_str.
#
# 			REPLACE() performs a case-sensitive match when searching for from_str
#
# 				SELECT REPLACE('www.mysql.com', 'w', 'WW');
# 					-> 'WWWWWW.mysql.com'
#
# 			This function is multibyte safe.
#
# 		) REVERSE(str)
#
# 			Returns the string str with the order of the characters reversed.
#
# 				SELECT REVERSE('abc');
# 					-> 'cba'
#
# 			This function is multibyte safe.
#
# 		) RIGHT(str,len)
#
# 			Returns the rightmost len characters from the string str, or NULL if any
# 			argument is NULL
#
# 				SELECT RIGHT('foobarbar', 4);
# 					-> 'rbar'
#
# 			This function is multibyte safe
#
# 		) RPAD(str, len, padstr)
#
# 			Returns the string str, right-padded with the string padstr to a length of len characters.
# 			
# 			If str is longer than len, the return value is shortened to len characters.
#
# 				SELECT RPAD('hi', 5, '?');
# 					-> 'hi???'
# 				
# 				SELECT RPAD('hi', 1, '?');
# 					-> 'h'
#
# 			This function is multibyte safe
#
# 		) RTRIM(str)
#
# 			Returns the string str with trailing space characters removed.
#
# 				SELECT RTRIM('barbar  ');
# 					-> 'barbar'
#
# 			This function is multibyte safe
#
# 		) SOUNDEX(str)
#
# 			Returns a soundex string from str.
#
# 			Two strings that sound almost the same should have identical soundex strings.
#
# 			A standard soundex string is four characters long, but hte SOUNDEX() function
# 			returns an arbitrarily long string.
#
# 			You can use SUBSTRING() on the result to get a standard soundex string.
#
# 			All nonalphabetic characters in str are ignored.
#
# 			ALl international alphabetic characters outside the A-Z range are
# 			treated as vowels.
#
# 				IMPORTANT:
#
# 					When using SOUNDEX(), you should be aware of the following limitaitons:
#
#
# 						) This function, as currently implemented - is intended to work well with strings
# 							that are in the English language only.
#
# 							Strings in other langauges may not produce reliable results.
#
# 						) THis function is not guaranteed to provide consistent results with strings
# 							that use multibyte character sets, including utf-8.
#
# 							See BUG #22638 for more information.
#
# 				SELECT SOUNDHEX('Hello');
# 					-> 'H400'
# 
# 				SELECT SOUNDHEX('Quadratically');
# 					-> 'Q36324'
#
# 			NOTE:
#
# 				This function implements the original Soundex algorithm, not hthe more popular enhanced
# 				version (also described by D. Knuth)
#
# 				The differnece is that the origina version discards vowels first and duplicates second, whereas
# 				the enhanced version discards duplicates first and vowels second.
#
# 		) expr1 SOUNDS LIKE expr2
#
# 			This is the same as SOUNDEX(expr1) = SOUNDEX(expr2)
#
# 		) SPACE(N)
#
# 			Returns a string consisting of N Space characters
#
# 				SELECT SPACE(6);
# 					-> '      '
#
# 		) SUBSTR(str,pos), SUBSTR(str FROM pos), SUBSTR(str, pos, len), SUBSTR(str FROM pos FOR len)
#
# 			SUBSTR() is a synonym for SUBSTRING()
#
# 		) SUBSTRING(str,pos), SUBSTRING(str FROM pos), SUBSTRING(str,pos,len), SUBSTRING(str FROM pos FOR len)
#
# 			The forms without a len argument return a substring from string str starting at position pos.
#
# 			This forms with a len argument returns a substring len chars long from string str,
# 			starting at position pos.
#
# 			The forms that use FROM are standard SQL syntax.
#
# 			IT is also possible to use a negative value for pos.
#
# 			IN this case, the beginning of the substring is pos characerts
# 			from the end of the string, rather than the beginning.
#
# 			A negative value may be used for pos in any of the forms of this function.
#
# 			For all forms of SUBSTRING(), the position of hte first character in the 
# 			string from which the substring is to be extracted is reckoned as 1.
#
# 				SELECT SUBSTRING('Quadratically', 5);
# 					-> 'ratically'
#
# 				SELECT SUBSTRING('foobarbar' FROM 4);
# 					-> 'barbar'
#
# 				SELECT SUBSTRING('Quadratically', 5, 6);
# 					-> 'ratica'
#
# 				SELECT SUBSTRING('Sakila', -3);
# 					-> 'ila'
#
# 				SELECT SUBSTRING('Sakila', -5, 3);
# 					-> 'aki'
#
# 				SELECT SUBSTRING('Sakila' FROM -4 FOR 2);
# 					-> 'ki'
#
# 			THis function is multibyte safe.
#
# 			If len is less than 1, the result is the empty string.
#
# 		) SUBSTRING INDEX(str, delim, count)
#
# 			Returns the substring from string str before count occurences of the delimiter delim.
#
# 			If count is positive, everything to the left of the final delimiter (counting from
# 			the left) is returned.
#
# 			iF count is negative, everything to the right of the final delimiter (counting form the right)
# 			is returned.
#
# 			SUBSTRING_INDEX() performs a case-sensitive match when searching for delim.
#
# 					SELECT SUBSTRING_INDEX('www.mysql.com', '.', 2);
# 						-> 'www.mysql'
#
# 					SELECT SUBSTRING_INDEX('www.mysql.com', '.', -2);
# 						-> 'mysql.com'
#
# 			The function is multibyte safe.
#
# 		) TO_BASE64(str)
#
# 			Converts the string argument to base-64 encoded form and returns the result
# 			as a character string with the connection character set and collation.
#
# 			If the argument is not a string, it is converted to a string before conversion
# 			takes place.
#
# 			The result is NULL if the argument is NULL.
#
# 			Base-64 encoded strings can be decoded using the FROM_BASE64() function.
#
# 				SELECT TO_BASE64('abc'), FROM_BASE64(TO_BASE64('abc'));
# 					-> 'JWJj', 'abc'
#
# 			Different base-64 encoding schemes exist.
#
# 			These are the encoding and decoding rules used by TO_BASE64()
# 			and FROM_BASE64():
#
# 				) The encoding for alphabet value 62 is '+'
#
# 				) The encoding for alphabet value 63 is '/'
#
# 				) Encoded output consists of groups of 4 printable characters.
#
# 					Each 3 bytes of the input data are encoded using 4 characters.
#
# 					If the last group is incomplete, it is padded with '=' characters
# 					to a length of 4
#
# 				) A newline is added after each 76 characters of encoded output to divide
# 					long output into multiple lines.
#
# 				) Decoding recognizes and ignores newline, carriage return, tab and space.
#
# 		) TRIM ([{BOTH | LEADING | TRAILING} [remstr] FROM] str), TRIM([remstr FROM] str)
#
# 			Returns the string str with all remstr prefixes or suffixes removed.
#
# 			If none of the specifiers BOTH, LEADING or TRAILING is given, BOTH is assumed.
# 			Remstr is optional, and if not specified, spaces are removed.
#
# 				SELECT TRIM('  bar  ');
# 					-> 'bar'
# 				
# 				SELECT TRIM(LEADING 'x' FROM 'xxxbarxxx');
# 					-> 'barxxx'
#
# 				SELECT TRIM(BOTH 'x' FROM 'xxxbarxxx');
# 					-> 'bar'
#
# 				SELECT TRIM(TRAILING 'xyz' FROM 'barxxyz');
# 					-> 'barx'
#
# 			This function is multibyte safe.
#
# 		) UCASE(str)
#
# 			UCASE() is a synonym for UPPER()
#
# 			UCASE() used within views is rewritten as UPPER()
#
# 		) UNHEX(str)
#
# 			For a string argument str, UNHEX(str) interprets each pair of characters in
# 			the argument as a hexadecimal number and converts it to the byte represented
# 			by the number.
#
# 			The return value is a binary string.
#
# 				SELECT UNHEX('4D7953514C');
# 					-> 'MySQL'
#
# 				SELECT X'4D7953514C';
# 					-> 'MySQL'
#
# 				SELECT UNHEX(HEX('string'));
# 					-> 'string'
#
# 				SELECT HEX(UNHEX('1267'));
# 					-> '1267'
#
# 			The characters in the argument string must be legal hexadecimal digits:
#
# 				'0 --- '9', 'A' --- 'F', 'a' --- 'f'
#
# 			If the argument contains any nonhexadecimal digits, the result is NULL:
#
# 				SELECT UNHEX('GG');
#
# 				+------------------+
# 				| UNHEX('GG') 		 |
# 				+------------------+
# 				| NULL 				 |
# 				+------------------+
#
# 			A NULL result can occur if the argument to UNHEX() is a BINARY column, because
# 			values are padded with 0x00 bytes when stored but those bytes are not stripped on
# 			retrieval.
#
# 			For example, '41' is stored into a CHAR(3) column as '41 ' and retrieved as '41'
# 			(with the trailing pad space stripped), so UNHEX() for the column value returns 'A'
#
# 			By contrast, '41' stored into a BINARY(3) column as '41\0' and retrieved as '41\0'
# 			(with the trailing pad 0x00 byte not stripped)
#
# 			'\0' is not a legal hexadecimal digit, so UNHEX() for the column value returns NULL
#
# 			For a numeric argument N, the inverse of HEX(N) is not performed by UNHEX().
#
# 			Use CONV(HEX(N),16,10) instead.
#
# 			See the description of HEX()
#
# 		) UPPER(str)
#
# 			Returns the string str with all characters changed to uppercase according to the current
# 			character set mapping.
#
# 			The default is utf8mb4
#
# 				SELECT UPPER('Hej');
# 					-> 'HEJ'
#
# 			See the description of LOWER() for information that also applies to UPPER().
#
# 			This included information about how to perform lettercase conversion of binary strings
# 			(BINARY, VARBINARY, BLOB) for which these functions are ineffective, and information about case folding
# 			for Unicode character sets.
#
# 			This function is multibyte safe.
#
# 			UCASE() used within views is rewritten as UPPER()
#
# 		) WEIGHT_STRING(str [AS {CHAR|BINARY}(N)] [flags])
#
# 			This function returns the weight string for the input string.
#
# 			The return value is a binary string that represents the comparison and sorting
# 			value of the string.
#
# 			It has these properties:
#
# 				) If WEIGHT_STRING(str1) = WEIGHT_STRING(str2), then str1 = str2(str1 and str2 are considered equal)
#
# 				) If WEIGHT_STRING(str1) < WEIGHT_STRING(str2), then str1 < str2(str1 sorts before str2)
#
# 			WEIGHT_STRING() is a debugging function intended for internal use.
#
# 			Its behavior can change without notice between MySQL versions.
#
# 			It can be used for testing and debugging of collations, especially
# 			if you are adding a new collation.
#
# 			See SECTION 10.13, "ADDING A COLLATION TO A CHARACTER SET"
#
# 			This list briefly summaries the arguments. More details are given in the discussion
# 			following the list.
#
# 				) str: The input string expression
#
# 				) AS clause: Optional; cast the input string to a given type and length
#
# 				) flags: Optional; unused
#
# 			The input string, str, is a string expression.
#
# 			If the input is a nonbinary (character) string such as a CHAR, VARCHAR
# 			or TEXT value, the return value contains the collation weights for the string.
#
# 			If the input is a binary (byte) string such as a BINARY, VARBINARY or BLOB value,
# 			the return value is the same as the input (the weight for each byte in a binary
# 			string is the byte value)
#
# 			If the input is NULL, WEIGHT_STRING() returns NULL.
#
# 			Examples:
#
# 				SET @s = _utf8mb4 'AB' COLLATE utf8mb4_0900_ai_ci;
# 				SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s));
# 				+-----------+-------------+---------------------------+
# 				| @s 			| HEX(@s) 	  | HEX(WEIGHT_STRING(@s)) 	|
# 				+-----------+-------------+---------------------------+
# 				| AB 			| 4142 		  | 1C471C60 						|
# 				+-----------+-------------+---------------------------+
#
# 				SET @s = _utf8mb4 'ab' COLLATE utf8mb4_0900_ai_ci;
# 				SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s));
# 				+-----------+--------------+-------------------------+
# 				| @s 			| HEX(@s) 		| HEX(WEIGHT_STRING(@s))  |
# 				+-----------+--------------+-------------------------+
# 				| ab 			| 6162 			| 1C471C60 					  |
# 				+-----------+--------------+-------------------------+
#
# 				SET @s = CAST('AB' AS BINARY);
# 				SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s));
# 				+-----------+--------------+--------------------------+
# 				| @s 			| HEX(@s) 		| HEX(WEIGHT_STRING(@s)) 	|
# 				+-----------+--------------+--------------------------+
# 				| AB 			| 4142 			| 4142 							|
# 				+-----------+--------------+--------------------------+
#
# 				SET @s = CAST('ab' AS BINARY);
# 				SELECT @s, HEX(@s), HEX(WEIGHT_STRING(@s));
# 				+----------+---------------+--------------------------+
# 				| @s 		  | HEX(@s) 		| HEX(WEIGHT_STRING(@s))   |
# 				+----------+---------------+--------------------------+
# 				| ab 		  | 6162 			| 6162 							|
# 				+----------+---------------+--------------------------+
#
# 			The preceding examples use HEX() to display the WEIGHT_STRING() result.
#
# 			Because the result is a binary value, HEX() can be especially useful when
# 			the result contains nonprinting values, to display it in printable form:
#
# 				SET @s = CONVERT(X'C39F' USING utf8) COLLATE utf8_czech_ci;
# 				SELECT HEX(WEIGHT_STRING(@s));
# 				+-----------------------------+
# 				| HEX(WEIGHT_STRING(@s)) 		|
# 				+-----------------------------+
# 				| 0FEA0FEA 							|
# 				+-----------------------------+
#
# 			For non-NULL return values, the data type of the value is VARBINARY if its
# 			length is within the maximum length for VARBINARY, otherwise the data type
# 			is BLOB.
#
# 			The AS clause may be given to cast the input string to a nonbinary or binary string
# 			and to force it to a given length:
#
# 				) AS CHAR(N) casts the string to a nonbinary string and pads it on the right with spaces
# 					to a length of N characters.
#
# 					N must be at least 1. 
#
# 					If N is less than the length of the input string, the string is truncated
# 					to N characters.
#
# 					No warning occurs for truncation.
#
# 				) AS BINARY(N) is similar but casts the string to a binary string, N is measured
# 					in bytes (not characters), and padding uses 0x00 bytes (not spaces)
#
# 					SET NAMES 'latin1';
# 					SELECT HEX(WEIGHT_STRING('ab' AS CHAR(4)));
# 					+------------------------------------------+
# 					| HEX(WEIGHT_STRING('ab' AS CHAR(4))) 		 |
# 					+------------------------------------------+
# 					| 41422020 											 |
# 					+------------------------------------------+
#
# 					SET NAMES 'utf8';
# 					SELECT HEX(WEIGHT_STRING('ab' AS CHAR(4)));
# 					+---------------------------------------+
# 					| HEX(WEIGHT_STRING('ab' AS CHAR(4))) 	 |
# 					+---------------------------------------+
# 					| 0041004200200020 							 |
# 					+---------------------------------------+
#
# 					SELECT HEX(WEIGHT_STRING('ab' AS BINARY(4)));
# 					+---------------------------------------+
# 					| HEX(WEIGHT_STRING('ab' AS BINARY(4))) |
# 					+---------------------------------------+
# 					| 61620000 										 |
# 					+---------------------------------------+
#
# 			The flags clause currently is unused.
#
# 12.5.1 STRING COMPARISON FUNCTIONS
#
# TABLE 12.8 STRING COMPARISON OPERATORS
#
# 		NAME 				Description
#
# 		LIKE 				Simple pattern matching
#
# 		NOT_LIKE 		Negation of simple pattern matching
#
# 		STRCMP() 		Compare two strings
#
# If a string function is given a binary string as an argument, the resulting string
# is also a binary string.
#
# A number converted to a string is treated as a bianry string.
#
# This affects only comparisons.
#
# Normally, if any expression in a string comparison is  case sensitive, the comparison
# is performed in case-sensitive fashion.
#
# 		) expr_LIKE_pat_[ESCAPE_'escape char']
#
# 			Pattern matching using an SQL pattern.
#
# 			Returns 1 (TRUE) or 0 (FALSE). If either expr or pat is NULL, the result is NULL.
#
# 			The pattern need not be a literal string.
#
# 			For example, it can be specified as a string expression or table column.
#
# 			Per the SQL standard, LIKE performs matching on a per-character basis,
# 			thus it can produce results different from the = comparison operator:
#
# 				SELECT '' LIKE 'ae' COLLATE latin1_german2_ci;
#
# 				+----------------------------------------------+
# 				| '' LIKE 'ae' COLLATE latin1_german2_ci 	  |
# 				+----------------------------------------------+
# 				| 											0 				  |
# 				+----------------------------------------------+
#
# 				SELECT '' = 'ae' COLLATE latin1_german2_ci;
# 				+----------------------------------------------+
# 				| '' = 'ae' COLLATE latin1_german2_ci 		  |
# 				+----------------------------------------------+
# 				| 								1 							  |
# 				+----------------------------------------------+
#
# 			In particular, trailing spaces are significant, which is not true
# 			for CHAR or VARCHAR comparisons performed with the = operator:
#
# 				SELECT 'a' = 'a ', 'a' LIKE 'a ';
# 				+-----------------+-----------------+
# 				| 'a' = 'a ' 		| 'a' LIKE 'a ' 	|
# 				+-----------------+-----------------+
# 				| 			1 			| 0 					|
# 				+-----------------+-----------------+
# 				1 row in set (0.00 sec)
#
# 			With LIKE you can use the following two wildcard characters
# 			in the pattern:
#
# 				) % matches any number of characters, even zero characters
#
# 				) _ matches exactly one character
#
# 					SELECT 'David!' LIKE 'David_';
# 						-> 1
#
# 					SELECT 'David!' LIKE '%D%v%';
# 						-> 1
#
# 			To test for literal instances of a wildcard character, precede it
# 			by the escape character.
#
# 			If you do not specify the ESCAPE character, \ is assumed.
#
# 				) \% matches one % character
#
# 				) \_ matches one _ character.
#
# 					SELECT 'David!' LIKE 'David\_';
# 						-> 0
#
# 					SELECT 'David_' LIKE 'David\_';
# 						-> 1
#
# 			To specify a different escape character, use the ESCAPE clause:
#
# 				SELECT 'David_' LIKE 'David|_' ESCAPE '|';
# 					-> 1
#
# 			The escape sequence should be empty or one character long.
#
# 			The expression must evaluate as a constant at execution time.
#
# 			If the NO_BACKSLASH_ESCAPES SQL mode is enabled, the sequence cannot be empty.
#
# 			The following two statements illustrate that string comparisons are not case-sensitive
# 			unless one of the operands is case-sensitive (uses a case-sensitive collation or is
# 			a binary string):
#
# 				SELECT 'abc' LIKE 'ABC';
# 					-> 1
#
# 				SELECT 'abc' LIKE _utf8mb4 'ABC' COLLATE utf8mb4_0900_as_cs;
# 					-> 0
#
# 				SELECT 'abc' LIKE _utf8mb4 'ABC' COLLATE utf8mb4_bin;
# 					-> 0
#
# 				SELECT 'abc' LIKE BINARY 'ABC';
# 					-> 0
#
# 			As an extension to standard SQL, MySQL permits LIKE on numeric expressions.
#
# 				SELECT 10 LIKE '1%';
# 					-> 1
#
# 			NOTE:
#
# 				Because MySQL uses C escape syntax in strings (for example, \n to represent newline chars),
# 				you must doubvle any \ that you use in LIKE strings.
#
# 				For example, to search for \n, specify it as \\n.
#
# 				To search for \, specify it as \\\\; this is because the backslashes
# 				are strippedo nce by the parser, and again when the pattern match is made, leaving
# 				a single one to be matched against.
#
# 				Exception:
#
# 					At the end of the pattern string, backslash can be specified as \\.
#
# 					At the end of the string, backslash stands for itself because there is
# 					nothing following to escape.
#
# 					Suppose that a table contains the following values:
#
# 						SELECT filename FROM t1;
# 						+--------------------+
# 						| filename 				|
# 						+--------------------+
# 						| C: 						|
# 						| C:\ 					|
# 						| C:\Programs 			|
# 						| C:\Programs\ 		|
# 						+--------------------+
#
# 					TO test for values that end with backslash, you can match the values
# 					using either of the following patterns:
#
# 						SELECT filename, filename LIKE '%\\' FROM t1;
# 						+--------------+------------------------------+
# 						| filename 		| filename LIKE '%\\' 			 |
# 						+--------------+------------------------------+
# 						| C: 				| 							0 			 |
# 						| C:\ 			| 							1 			 |
# 						| C:\Programs  | 							0 			 |
# 						| C:\Programs\ | 							1 			 |
# 						+--------------+------------------------------+
#
# 						SELECT filename, filename LIKE '%\\\\' FROM t1;
# 						+---------------+------------------------------+
# 						| filename 		 | filename LIKE '%\\\\' 		  |
# 						+---------------+------------------------------+
# 						| C: 				 | 						0 			  |
# 						| C:\ 			 | 						1 			  |
# 						| C:\Programs 	 | 						0 			  |
# 						| C:\Programs\  | 						1 			  |
# 						+---------------+------------------------------+
#
# 		) expr_NOT_LIKE_pat_[ESCAPE_'escape_char']
#
# 			This is the same as NOT (expr LIKE pat [ESCAPE 'escape_char'])
#
# 			Note:
#
# 				Aggregate queries involving NOT_LIKE comparisons with columns containing
# 				NULL may yield unexpected results.
#
# 				For example, consider the following table and data:
#
# 					CREATE TABLE foo (bar VARCHAR(10));
#
# 					INSERT INTO foo VALUES (NULL), (NULL);
#
# 				The query SELECT COUNT(*) FROM foo WHERE bar LIKE '%baz%'; returns 0.
#
# 				You might assume that the SELECT COUNT(*) FROM foo WHERE bar NOT LIKE '%baz%';
# 				would return 2.
#
# 				However, this is not the case; the second query returns 0.
#
# 				This is because NULL NOT LIKE expr always returns NULL, regardless of the value
# 				of expr.
#
# 				The same is true for aggregate queries involving NULL and comparisons using NOT_RLIKE
# 				or NOT_REGEXP.
#
# 				In such cases, you must test explicitly for NOT NULL using OR (and not AND),
# 				as shown here:
#
# 					SELECT COUNT(*) FROM foo WHERE bar NOT LIKE '%baz%' OR bar IS NULL;
#
# 		) STRCMP(expr1, expr2)
#
# 			STRCMP() returns 0 if the strings are the same, -1 if the first argument is smaller
# 			than the second according to the current sort order, and 1 otherwise.
#
# 				SELECT STRCMP('text', 'text2');
# 					-> -1
#
# 				SELECT STRCMP('text2', 'text');
# 					-> 1
#
# 				SELECT STRCMP('text', 'text');
# 					-> 0
#
# 			STRCMP() performs the comparison using the collation of the arguments.
#
# 				SET @s1 = _utf8mb4 'x' COLLATE utf8mb4_0900_ai_ci;
# 				SET @s2 = _utf8mb4 'X' COLLATE utf8mb4_0900_ai_ci;
#
# 				SET @s3 = _utf8mb4 'x' COLLATE utf8mb4_0900_as_cs;
# 				SET @s4 = _utf8mb4 'X' COLLATE utf8mb4_0900_as_cs;
# 			
# 				SELECT STRCMP(@s1, @s2), STRCMP(@s3, @s4);
# 				+--------------------+----------------------+
# 				| STRCMP(@s1, @s2) 	| STRCMP(@s3, @s4) 	  |
# 				+--------------------+----------------------+
# 				| 				0 			| 			1 				  |
# 				+--------------------+----------------------+
#
# 			If hte collations are incompatible, one of the arguments must be converted to be
# 			compatible with the other.
#
# 			See SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS"
#
# 				SET @s1 = _utf8mb4 'x' COLLATE utf8mb4_0900_ai_ci;
# 				SET @s2 = _utf8mb4 'X' COLLATE utf8mb4_0900_ai_ci;
#
# 				SET @s3 = _utf8mb4 'x' COLLATE utf8mb4_0900_as_cs;
# 				SET @s4 = _utf8mb4 'X' COLLATE utf8mb4_0900_as_cs;
#
# 				SELECT STRCMP(@s1, @s3);
# 				ERROR 1267 (HY000): Illegal mix of collations (utf8mb4_0900_ai_ci, IMPLICIT)
# 				and (utf8mb4_0900_as_cs, IMPLICIT) for operation 'strcmp'
#
# 				SELECT STRCMP(@s1, @s3 COLLATE utf8mb4_0900_ai_ci);
# 				+--------------------------------------------------+
# 				| STRCMP(@s1, @s3 COLLATE utf8mb4_0900_ai_ci) 		|
# 				+--------------------------------------------------+
# 				| 													0 				|
# 				+--------------------------------------------------+
#
# 12.5.2 REGULAR EXPRESSIONS
#
# TABLE 12.9 REGULAR EXPRESSION FUNCTIONS AND OPERATORS
#
# NAME 					DESCRIPTION
#
# NOT_REGEXP 			Negation of REGEXP
#
# REGEXP 				Whether string matches regular expression
#
# REGEXP_INSTR() 		Starting index of substring matching regular expression
#
# REGEXP_LIKE() 		Whether string matches regular expression
#
# REGEXP_REPLACE() 	Replace substrings matching regular expression
#
# REGEXP_SUBSTR() 	Return substring matching regular expression
#
# RLIKE 					Whether string matches regular expression
#
# A regular expression is a powerful way of specifying a pattern for a complex search.
#
# This section discusses the functions and operators available for regular expression
# matching and illustrates, with examples, some of the special characters and constructs
# that can be used for regular expression operations.
#
# See also SECTION 3.3.4.7, "PATTERN MATCHING"
#
# MySQL implements regular expression support using international Components for Unicode
# (ICU), which provides full Unicode support and is multibyte safe.
#
# (Prior to MySQL 8.0.4, MySQL used Henry Spencer's implementation of regex, which operates
# in byte-wise fashion and is not multibyte safe.
#
# For information about ways in which applications that use regex may be affected by the
# implementation change, see REGULAR EXPRESSION COMPATBILITY CONSIDERATIONS)
#
# 		) REGULAR EXPRESSION FUNCTIONS AND OPERATORS
#
# 		) REGULAR EXPRESSION SYNTAX
#
# 		) REGULAR EXPRESSION RESOURCE CONTROL
#
# 		) REGULAR EXPRESSION COMPATIBILITY CONSIDERATIONS
#
# REGULAR EXPRESSION FUNCTIONS AND OPERATORS
#
# 	) expr_NOT_REGEXP_pat, expr_NOT_RLIKE_pat
#
# 		This is the same as NOT (expr REGEXP pat)
#
# 	) expr_REGEXP_pat, expr_RLIKE_pat
#
# 		Returns 1 if the string expr matches the regular expression specified by the 
# 		pattern pat, 0 otherwise.
#
# 		If expr or pat is NULL, the return value is NULL.
#
# 		REGEXP and RLIKE are synonyms for REGEXP_LIKE()
#
# 		For additional information about how matching occurs, see the description
# 		for REGEXP_LIKE()
#
# 			SELECT 'Michael!' REGEXP '.*';
# 			+-------------------------------+
# 			| 'Michael!' REGEXP '.*' 		  |
# 			+-------------------------------+
# 			| 						1 				  |
# 			+-------------------------------+
#
# 			SELECT 'new*\n*line' REGEXP 'new\\*.\\*line';
# 			+-----------------------------------------+
# 			| 'new*\n*line' REGEXP 'new\\*.\\*line'   |
# 			+-----------------------------------------+
# 			| 						0 								|
# 			+-----------------------------------------+
#
# 			SELECT 'a' REGEXP '^[a-d]';
# 			+-------------------------+
# 			| 'a' REGEXP '^[a-d]' 	  |
# 			+-------------------------+
# 			| 						1 		  |
# 			+-------------------------+
#
# 			SELECT 'a' REGEXP 'A', 'a' REGEXP BINARY 'A';
# 			+-----------------+-----------------------+
# 			| 'a' REGEXP 'A' 	| 'a' REGEXP BINARY 'A' |
# 			+-----------------+-----------------------+
# 			| 			1 			| 				0 				|
# 			+-----------------+-----------------------+
#
# 	) REGEXP_INSTR(expr, pat[, pos[, occurence[, return option[, match type]]]])
#
# 		Returns the starting index of the substring of the string expr that matches the regular expression
# 		specified by the pattern pat, 0 if there is no match.
#
# 		If expr 0 or pat is NULL, the return value is NULL. Character index begin at 1.
#
# 		REGEXP_INSTR() takes these optional arguments:
#
# 			) pos: The position in expr at which to start the search. If omitted, the default is 1.
#
# 			) occurence: Which occurence of a match to search for. If omitted, the default is 1.
#
# 			) return_option: Which type of position to return.
#
# 				If this value is 0, REGEXP_INSTR() returns the position of the matched substring's
# 				first character.
#
# 				If this value is 1, REGEXP_INSTR() returns the position following the matched substring.
#
# 				If omitted, the default is 0
#
# 			) match_type: A string that specifies how to perform matching.
#
# 				The meaning is as described for REGEXP_LIKE()
#
# 		For additional information about how matching occurs, see the description for
# 		REGEXP_LIKE()
#
# 			SELECT REGEXP_INSTR('dog cat dog', 'dog');
# 			+-----------------------------------------+
# 			| REGEXP_INSTR('dog cat dog', 'dog') 	   |
# 			+-----------------------------------------+
# 			|								1 					   |
# 			+-----------------------------------------+
#
# 			SELECT REGEXP_INSTR('dog cat dog', 'dog', 2);
# 			+-----------------------------------------+
# 			| REGEXP_INSTR('dog cat dog', 'dog', 2)   |
# 			+-----------------------------------------+
# 			| 											9 		   |
# 			+-----------------------------------------+
#
# 			SELECT REGEXP_INSTR('aa aaa aaaa', 'a{2}');
# 			+-----------------------------------------+
# 			| REGEXP_INSTR('aa aaa aaaa', 'a{2}') 		|
# 			+-----------------------------------------+
# 			| 											1 			|
# 			+-----------------------------------------+
#
# 			SELECT REGEXP_INSTR('aa aaa aaaa', 'a{4}');
# 			+-----------------------------------------+
# 			| REGEXP_INSTR('aa aaa aaaa', 'a{4}') 		|
# 			+-----------------------------------------+
# 			| 										 	8 			|
# 			+-----------------------------------------+
#
# 	) REGEXP_LIKE(expr, pat[, match type])
#
# 		Returns 1 if the string expr matches the regular expression specified by the pattern
# 		pat, 0 otherwise.
#
# 		If expr or pat is NULL, the return value is NULL.
#
# 		THe pattern can be an extended regular expression, the syntax for which is discussed
# 		in REGULAR EXPRESSION SYNTAX.
#
# 		THe pattern need not be a literal string.
#
# 		For example, it can be specified as a string expression or table column.
#
# 		The optional match_type argument is a string that may contain any or all the
# 		following characters specifying how to perform matching:
#
# 			) c: Case sensitive matching
#
# 			) i: Case insensitive matching
#
# 			) m: Multiple-line mode. Recognize line terminators within the string.
#
# 				The default behavior is to match line terminators only at the start
# 				and end of the string expression.
#
# 			) n: The . character matches line terminators. The default is for . matching to stop at teh end of a line.
#
# 			) u: Unix-only line endings.
#
# 				Only the newline characters is recognized as a line ending by the ., ^, and $ match operators.
#
# 		If characters specifying contradictory options are specified within match_type, the rightmost one takes precedence.
#
# 		By default, regular expression operations use the character set and collation of the expr and pat arguments
# 		when deciding the type of a character and performing the comparison.
#
# 		If the arguments have different character sets or collations, coercibility rules apply as described,
# 		in SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS"
#
# 		Arguments may be specified with explicit collation indicators to change comparison behavior.
#
# 			SELECT REGEXP_LIKE('CamelCase', 'CAMELCASE');
# 			+--------------------------------------------+
# 			| REGEXP_LIKE('CamelCase', 'CAMELCASE') 		|
# 			+--------------------------------------------+
# 			| 							1 							   |
# 			+--------------------------------------------+
#
# 			SELECT REGEXP_LIKE('CamelCase', 'CAMELCASE' COLLATE utf8mb4_0900_as_cs);
# 			+------------------------------------------------------------------+
# 			| REGEXP_LIKE('CamelCase', 'CAMELCASE' COLLATE utf8mb4_0900_as_cs) |
# 			+------------------------------------------------------------------+
# 			| 											0 											 |
# 			+------------------------------------------------------------------+
#
# 		match_type may be specified with the c or i characters to override the default
# 		case sensitivity.
#
# 		Exception: If either argument is a binary string, the arguments are handled in case-sensitive
# 						fashion as binary strings, even if match_type contains the i character.
#
# 		NOTE:
#
# 			Because MySQL uses the C escape syntax in strings (for example, \n to represent the newline character),
# 			you must double any \ that you use in your expr and pat arguments.
#
# 			SELECT REGEXP_LIKE('Michael!', '.*');
# 			+------------------------------------+
# 			| REGEXP_lIKE('Michael!', '.*') 		 |
# 			+------------------------------------+
# 			| 						1 						 |
# 			+------------------------------------+
#
# 			SELECT REGEXP_LIKE('new*\n*line', 'new\\*.\\*line');
# 			+------------------------------------------------+
# 			| REGEXP_LIKE('new*\n*line', 'new\\*.\\*line')   |
# 			+------------------------------------------------+
# 			| 								0 								 |
# 			+------------------------------------------------+
#
# 			SELECT REGEXP_LIKE('a', '^[a-d]');
# 			+-----------------------------------+
# 			| REGEXP_LIKE('a', '^[a-d]') 			|
# 			+-----------------------------------+
# 			| 						1 						|
# 			+-----------------------------------+
#
# 			SELECT REGEXP_LIKE('a', 'A'), REGEXP_LIKE('a', BINARY 'A');
# 			+-------------------------+------------------------------+
# 			| REGEXP_LIKE('a', 'A')   | REGEXP_lIKE('a', BINARY 'A') |
# 			+-------------------------+------------------------------+
# 			| 					1 			  |  				0 						|
# 			+-------------------------+------------------------------+
#
# 			SELECT REGEXP_LIKE('abc', 'ABC');
# 			+-----------------------------------+
# 			| REGEXP_LIKE('abc', 'ABC') 			|
# 			+-----------------------------------+
# 			|  				1 							|
# 			+-----------------------------------+
#
# 			SELECT REGEXP_LIKE('abc', 'ABC', 'c');
# 			+-----------------------------------+
# 			| REGEXP_LIKE('abc', 'ABC', 'c') 	|
# 			+-----------------------------------+
# 			| 					0 						   |
# 			+-----------------------------------+
#
# 	) REGEXP_REPLACE(expr, pat, repl[, pos[, occurence[, match_type]]])
#
# 		Replaces occurences in the string expr that match the regular expression
# 		specified by the pattern pat with the replacement string repl, and returns the
# 		resulting string.
#
# 		If expr, pat, or repl is NULL, the return value is NULL.
#
# 		REGEXP_REPLACE() takes these optional arguments:
#
# 			) pos: The position in expr at which to start the search. If omitted, the default is 1.
#
# 			) occurence: Which occurence of a match to replace.
#
# 							If omitted, the default is 0 (which means "replace all occurences")
#
# 			) match_type: A string that specifies how to perform matching.
#
# 							 The meaning is as described for REGEXP_LIKE()
#
# 		For additional information about how matching occurs, see the description for REGEXP_LIKE()
#
# 			SELECT REGEXP_REPLACE('a b c', 'b', 'X');
# 			+-------------------------------------------+
# 			| REGEXP_REPLACE('a b c', 'b', 'X') 		  |
# 			+-------------------------------------------+
# 			| a X c 												  |
# 			+-------------------------------------------+
#
# 			SELECT REGEXP_REPLACE('abc def ghi', '[a-z]+', 'X', 1, 3); #Replace the third occurence
# 			+---------------------------------------------------+
# 			| REGEXP_REPLACE('abc def ghi', '[a-z]+', 'X', 1, 3 |
# 			+---------------------------------------------------+
# 			| abc def X 													 | 
# 			+---------------------------------------------------+
#
# 	) REGEXP_SUBSTR(expr, pat[, pos[, occurence[, match type]]])
#
# 		Returns hte substring of the string expr that matches the regular expression specified
# 		by the pattern pat, NULL if there is no match.
#
# 		If expr or pat is NULL, the return value is NULL
#
# 		REGEXP_SUBSTR() takes these optional arguments:
#
# 			) pos: The position in expr at which to start the search. If omitted, the default is 1.
#
# 			) occurence: Which occurence of a match to search for. If omitted, the default is 1.
#
# 			) match_type: A string that specifies how to perform matching. The meaning is as described for REGEXP_LIKE()
#
# 		For additional information about how matching occurs, see the description for REGEXP_LIKE()
#
# 			SELECT REGEXP_SUBSTR('abc def ghi', '[a-z]+');
# 			+-----------------------------------------------+
# 			| REGEXP_SUBSTR('abc def ghi', '[a-z]+') 			|
# 			+-----------------------------------------------+
# 			| abc 														|
# 			+-----------------------------------------------+
#
# 			SELECT REGEXP_SUBSTR('abc def ghi', '[a-z]+', 1, 3);
# 			+------------------------------------------------+
# 			| REGEXP_SUBSTR('abc def ghi', '[a-z]+', 1, 3) 	 |
# 			+------------------------------------------------+
# 			| ghi 														 |
# 			+------------------------------------------------+
#
# REGULAR EXPRESSION SYNTAX
#
# A regular expression describes a set of strings.
#
# THe simplest regular expression is one that has no special characters in it.
#
# For example, the regular expression hello matches hello and nothing else.
#
# Nontrivial regular expressions use certain special constructs so that they can match
# more than one string.
#
# For example, the regular expression hello|world contains the | alternation operator
# and matches either the hello or world
#
# As a more complex example, the regular expression B[an]*s matches any of the strings:
#
# 		Bananas
#
# 		Baaaaas
#
# 		Bs
#
# and any other string starting with a B, ending with an s and containing any number
# of a or n characters in between.
#
# The following list covers some of the basic special characters and constructs that can be
# used in regular expressions.
#
# For information about the full regular expression syntax supported by the ICU library used
# to implement regular expression support, visit the <link>
#
# 		) ^
#
# 			Match the beginning of a string.
#
# 			SELECT REGEXP_LIKE('fo\nfo', '^fo$'); 		-> 0
# 			SELECT REGEXP_LIKE('fofo', '^fo'); 			-> 1
#
# 		) $
#
# 			Match the end of a string
#
# 				SELECT REGEXP_LIKE('fo\no', '^fo\no$'); 	-> 1
# 				SELECT REGEXP_LIKE('fo\no', '^fo$'); 		-> 0
#
# 			
# 		) .
#
# 			Match any character (including carriage return and newline, although to match these
# 			in the middle of a string, the m (multiple line) match-control character or the
# 			(?m) within-pattern modifier must be given)
#
# 			SELECT REGEXP_LIKE('fofo', '^f.*$'); 		-> 1
# 			SELECT REGEXP_LIKE('fo\r\nfo', '^f.*$');  -> 0
#
# 			SELECT REGEXP_LIKE('fo\r\nfo', '^f.*$', 'm'); -> 1
#
# 			SELECT REGEXP_LIKE('fo\r\nfo', '(?m)^f.*$');  -> 1
#
# 		) a* 
#
# 			Match any sequence of zero or more a characters.
#
# 				SELECT REGEXP_LIKE('Ban', '^Ba*n'); 		-> 1
#
# 				SELECT REGEXP_LIKE('Baaan', '^Ba*n'); -> 1
#
# 				SELECT REGEXP_LIKE('Bn', '^Ba*n'); 	-> 1
#
# 		) a+
#
# 			Match any sequence of one or more a characters
#
# 				SELECT REGEXP_LIKE('Ban', '^Ba+n'); 	-> 1
# 				SELECT REGEXP_LIKE('Bn', '^Ba+n'); 		-> 0
#
# 		) a?
#
# 			Match either zero or one a character
#
# 				SELECT REGEXP_LIKE('Bn', '^Ba?n'); 		-> 1
# 				SELECT REGEXP_LIKE('Ban', '^Ba?n'); 	-> 1
# 				SELECT REGEXP_LIKE('Baan', '^Ba?n'); 	-> 0
#
# 		) de|abc
#
# 			Alternation; match either of the sequences de or abc
#
# 				SELECT REGEXP_LIKE('pi', 'pi|apa'); -> 1
# 				SELECT REGEXP_LIKE('axe', 'pi|apa'); -> 0
#
# 				SELECT REGEXP_LIKE('apa', 'pi|apa'); -> 1
# 				SELECT REGEXP_LIKE('apa', '^(pi|apa)$'); -> 1
#
# 				SELECT REGEXP_LIKE('pi', '^(pi|apa)$'); -> 1
#
# 				SELECT REGEXP_LIKE('pix', '^(pi|apa)$'); ->
#
# 		) (abc)*
#
# 			Match zero or more instances of the sequence abc
#
# 				SELECT REGEXP_LIKE('pi', '^(pi)*$'); -> 1
#
# 				SELECT REGEXP_LIKE('pip', '^(pi)*$'); -> 0
#
# 				SELECT REGEXP_LIKE('pipi', '^(pi)*$'); -> 1
#
# 		) {1}, {2,3}
#
# 			Repetition; {n} and {m,n} notation provide a more general way of writing
# 			regular expressions that match many occurences of the previous atom (or "Piece")
# 			of the pattern.
#
# 			m and n are integers.
#
# 				) a*
#
# 					Can be written as a{0,}
#
# 				) a+
#
# 					Can be written as a{1,}
#
# 				) a?
#
# 					Can be written as a{0,1}
#
# 			TO be more precise, a{n} matches exactly n instances of a.
#
# 			a{n,} matches n or more instances of a
#
# 			a{m,n} matches m through n instances of a, inclusive.
#
# 			If both m and n are given, m must be less than or equal to n.
#
# 				SELECT REGEXP_LIKE('abcde', 'a[bcd]{2}e'); 	-> 0  
#
# 				SELECT REGEXP_LIKE('abcde', 'a[bcd]{3}e'); 	-> 1
# 
# 				SELECT REGEXP_LIKE('abcde', 'a[bcd]{1,10}e'); -> 1
#
# 		) [a-dX], [^a-dX]
#
# 			Matches any character that is (or is not, if ^ is used) either a, b, c, d or X.
#
# 			A - character between two other characters forms a range that matches all characters
# 			from the first character to the second.
#
# 			For example, [0-9] matches any decimal digit.
#
# 			To include a literal ] character, it must immediately follow the opening bracket [.
#
# 			To include a literal - character, it must be written first or last.
#
# 			Any character that does not have a defined special meaining inside a [] pair matches
# 			only itself.
#
# 				SELECT REGEXP_LIKE('aXbc', '[a-dXYZ]'); 		-> 1
# 				
# 				SELECT REGEXP_LIKE('aXbc', '^[a-dXYZ]$'); 	-> 0
#
# 				SELECT REGEXP_LIKE('aXbc', '^[a-dXYZ]+$'); 	-> 1
#
# 				SELECT REGEXP_LIKE('aXbc', '^[^a-dXYZ]+$');  -> 0
#
# 				SELECT REGEXP_LIKE('gheis', '^[^a-dXYZ]+$'); -> 1
#
# 				SELECT REGEXP_LIKE('gheisa', '^[^a-dXYZ]+$'); -> 0
#
# 		) [=character_class=]
#
# 			Within a bracket expression (written using [ and ]), [=character_class=] represents
# 			an equivalence class.
#
# 			It matches all characters with the same collation value, including itself.
#
# 			For example, if o and (+) are the members of an equivalence class, [[=o=]],
# 			[[=(+)=]], and [o(+)] are all synonyms.
#
# 			An equivalence class may not be used as an endpoint of a range.
#
# 		) [:character_class:]
#
# 			Within a bracket expression (written using [ and ]), [:character_class:] represents
# 			a character class that matches all characters belonging to that class.
#
# 			The following table lists the standard class names.
#
# 			These names stand for the character classes defined in the ctype(3) manual page.
#
# 			A particular locale may provide other class names.
#
# 			A character class may not be used as an endpoint of a range.
#
# 			CHARACTER CLASS NAME 			MEANING
#
# 			alnum 								Alphanumeric characters
#
# 			alpha 								Alphabetic characters
#
# 			blank 								Whitespace characters
#
# 			cntrl 								Control characters
#
# 			digit 								Digit characters
#
# 			graph 								Graphic characters
#
# 			lower 								Lowercase alphabetic characters
#
# 			print 								Graphic or space characters
#
# 			punct 								Punctuation characters
#
# 			space 								Space, tab, newline and carriage return
#
# 			upper 								Uppercase alphabetic characters
#
# 			xdigit 								Hexadecimal digit characters
#
# 				SELECT REGEXP_LIKE('justalnums', '[[:alnum:]]+');  -> 1
#
# 				SELECT REGEXP_LIKE('!!', '[[:alnum:]]+'); 			-> 0
#
# 		To use a literal instance of a special character in a regular expression, precede it by two
# 		backslash (\) characters.
#
# 		The MySQL parser interpets one of the backslashes, and the regular expression library interprets
# 		the other.
#
# 		For example, to match the string 1+2 taht contains the special + character, only the last one
# 		of the following regular expressions is the correct one:
#
# 			SELECT REGEXP_LIKE('1+2', '1+2'); 		-> 0
# 			SELECT REGEXP_LIKE('1+2', '1\+2'); 		-> 0
#
# 			SELECT REGEXP_LIKE('1+2', '1\\+2'); 	-> 1
#
# REGULAR EXPRESSION RESOURCE CONTROL
#
# REGEXP_LIKE() and similar functions use resources that can be controlled by setting system variables:
#
# 		) The match engine uses memory for its internal stack.
#
# 			To control the maximum available memory for the stack in bytes,
# 			set the regexp_stack_limit system variable.
#
# 		) The match engine operates in steps.
#
# 			To control the maximum number of steps performed by the engine (and thus indirectly
# 			the execution time), set the regexp_time_limit system variable.
#
# 			Because this limit is expressed as number of steps, it affects execution time only indirectly.
#
# 			Typically, it is on the order of milliseconds.
#
# REGULAR EXPRESSION COMPATIBILITY CONSIDERATIONS
#
# Prior to MySQL 8.0.4, MySQL used the Henry Spencer regular expression library to support
# regular expression operations, rather than International Components for Unicode (ICU).
#
# The following discussion describes differences between the Spencer and ICU libraries
# that may affect applications:
#
# 		) With the Spencer library, the REGEXP and RLIKE operators work in byte-wise fashion,
# 			so they are not multibyte safe and may produce unexpected results with multibyte
# 			character sets.
#
# 			In addition, these operators compare characters by their byte values and accented characters
# 			may not compare as equal even if a given collation treats them as equal.
#
# 			ICU has full Unicode support and is multibyte safe.
#
# 			Its regular expression functions treat all strings as UTF-16.
#
# 			You should keep in mind that positional indexes are based on 16-bit chunks and not
# 			on code points.
#
# 			This means that, when passed to such functions, characters using more than one chunk
# 			may produce unanticipated results, such as those shown here:
#
# 				SELECT REGEXP_INSTR('U+1F363U+1F363Ub', 'b');
# 				+------------------------------------------+
# 				| REGEXP_INSTR('??b', 'b') 					 |
# 				+------------------------------------------+
# 				| 											5 			 |
# 				+------------------------------------------+
# 				1 row in set (0.00 sec)
#
# 				SELECT REGEXP_INSTR('U+1F363U+1F363bxxx', 'b', 4);
# 				+------------------------------------------+
# 				| REGEXP_INSTR('??bxxx', 'b', 4) 			 |
# 				+------------------------------------------+
# 				| 										5 				 |
# 				+------------------------------------------+
# 				1 row in set (0.00 sec)
#
# 			Characters within the Unicode Basic Multilingual Plane, which includes
# 			characters used by most modern languages, are safe in this regard:
#
# 				/* There are some examples here, but i cannot be arsed to handle outside of utf8 casing */
#
# 			Emoji, such as the "sushi" character (U+1F363) used in the first two examples,
# 			are not included in the Basic Multilingual Plane, but rather in Unicode's Supplementary
# 			Multilingual Plane.
#
# 			Another issue can arise with emoji and other 4-byte characters when REGEXP_SUBSTR()
# 			or a similar function begins searching in the middle of a character.
#
# 			Each of the two statements in the following example starts from the second 2-byte position
# 			in the first argument.
#
# 			The first statement works on a string consisting solely of 2-byte (BMP) characters.
#
# 			The second statement contains 4-byte characters which are incorrectly interpreted in
# 			the result because the first two bytes are stripped off and so the remainder of
# 			the character data is misaligned.
#
# 					SELECT REGEXP_SUBSTR('', '.*', 2);
#					+------------------------------------------+
# 					| REGEXP_SUBSTR('', '.*', 2) 		|
# 					+------------------------------------------+
# 					|  											 |
# 					+------------------------------------------+
# 					1 row in set (0.00 sec)
# 
# 					SELECT REGEXP_SUBSTR('', '.*', 2);
# 					+------------------------------------------+
# 					| REGEXP_SUBSTR('', '.*', 2) 		 |
# 					+------------------------------------------+
# 					| ?  									 |
# 					+------------------------------------------+
# 					1 row in set (0.00 sec)
#
# 		) For the . operator, the Spencer library matches line-terminator characters (carriage return, newline)
# 			anywhere in string expressions, including in the middle.
#
# 			To match line terminator characters in the middle of strings with ICU,
# 			specify the m match-control character.
#
# 		) The Spencer Library supports word-beginning and word-end boundary markers ([[:<:]] and [[:>:]] notation)
#
# 			ICU does not.
#
# 			For ICU, you can use \b to match word boundaries;
# 			double the backslash because MySQL interprets it as the escape character within strings.
#
# 		) THe Spencer library supports collating element bracket expressions ([.characters.] notation). ICU does not.
#
# 		) For repetition counts ({n} and {m,n} notation), the Spencer library has a maximum of 255.
#
# 			ICU has no such limit, although the maximum number of match engine steps can be limited by setting
# 			the regexp_time_limit system variable.
#
# 		) ICU interprets parantheses as metacharacters.
#
# 			To specify a literal open parenthesis ( in a regular expression, it must be escaped:
#
# 				SELECT REGEXP_LIKE('(', '(');
# 				ERROR 3692 (HY000): Mismatched parenthesis in regular expression.
#
# 				SELECT REGEXP_LIKE('(', '\\(');
# 				+------------------------------+
# 				| REGEXP_LIKE('(', '\\(') 	    |
# 				+------------------------------+
# 				| 								1 		 |
# 				+------------------------------+
#
# 12.5.3 CHARACTER SET AND COLLATION OF FUNCTION RESULTS
#
# MySQL has many operators and functions that return a string.
#
# This section answers the question: What is the character set and collation of such a string?
#
# For simple functions that take string input and return a string result as output, the output's
# character set and collation are the same as those of the principal input value.
#
# For example, UPPER(X) returns a string with the same character string and collation as X.
#
# The same applies for INSTR(), LCASE(), LOWER(), LTRIM(), MID(), REPEAT(), REPLACE(),
# 	REVERSE(), RIGHT(), RPAD(), RTRIM(), SOUNDEX(), SUBSTRING(), TRIM(), UCASE() and UPPER()
#
# 	NOTE:
#
# 		The REPLACE() function, unlike all other functions, always ignores the collation
# 		of the string intput and performs a case-sensitive comparison.
#
# If a string input or function result is a binary string, the string has the binary character
# set and collation.
#
# This can be checked using the CHARSET() and COLLATION() functions, both of which return
# binary for a binary string argument:
#
# 		SELECT CHARSET(BINARY 'a'), COLLATION(BINARY 'a');
# 		+-------------------------+------------------------+
# 		| CHARSET(BINARY 'a')     | COLLATION(BINARY 'a')  |
# 		+-------------------------+------------------------+
# 		| binary 					  | binary 						|
# 		+-------------------------+------------------------+
#
# For operations that combine multiple string inputs and return a single string output,
# the "aggregation rules" of standard SQL apply for determining the collation of hte result:
#
# 		) If an explicit COLLATE Y occurs, use Y
#
# 		) If explicit COLLATE Y and COLLATE Z occur, raise an error
#
# 		) Otherwise, if all collations are Y, use Y
#
# 		) Otherwise, the result has no collation
#
# For example, with CASE_---_WHEN a THEN b WHEN b THEN c COLLATE X END the resulting collation is X.
#
# The same applies for UNION, ||, CONCAT(), ELT(), GREATEST(), IF() and LEAST()
#
# For operations that convert to character data, the character set and collation of the
# strings that result from the operations are defined by the character_set_connection 
# and collation_connection system variables that determine the default connection character set
# and collation (see SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS")
#
# This applies only to BIN_TO_UUID(), CAST(), CONV(), FORMAT(), HEX() and SPACE()
#
# An exception to the preceding principle occurs for expressions for virtual generated
# columns.
#
# In such expressions, the table character set is used for BIN_TO_UUID(), CONV()
# or HEX() results, regardless of connection character set.
#
# If there is any question about the character set or collation of the result
# returned by a string function, use the CHARSET() or COLLATION() function to find out:
#
# 		SELECT USER(), CHARSET(USER()), COLLATION(USER());
# 		+---------------+-----------------+--------------------+
# 		| USER() 		 | CHARSET(USER()) | COLLATION(USER())  |
# 		+---------------+-----------------+--------------------+
# 		| test@localhost| utf8 				 | utf8_general_ci    |
# 		+---------------+-----------------+--------------------+
#
# 		SELECT CHARSET(COMPRESS('abc')), COLLATION(COMPRESS('abc'));
# 		+--------------------------+-----------------------------+
# 		| CHARSET(COMPRESS('abc')) | COLLATION(COMPRESS('abc'))  |
# 		+--------------------------+-----------------------------+
# 		| binary 						| binary 							|
# 		+--------------------------+-----------------------------+
#
# 12.6 NUMERIC FUNCTIONS AND OPERATORS
#
# 12.6.1 ARITHMETIC OPERATORS
# 12.6.2 MATHEMATICAL FUNCTIONS
#
# TABLE 12.10 NUMERIC FUNCTIONS AND OPERATORS
#
# 	NAME 							DESC
#
# ABS() 				Return the absolute value
#
# ACOS() 			Return the arc cosine
#
# ASIN() 			Return the arc sine
#
# ATAN() 			Return the arc tangent
#
# ATAN2(), ATAN() Return the arc tangent of the two arguments
#
# CEIL() 			Return the smallest integer value not less than the argument
#
# CEILING() 		Return the smallest integer value not less than the argument
#
# CONV() 			Convert numbers between different number bases
#
# COS() 				Return the cosine
#
# COT() 				Return the cotangent
#
# CRC32() 			Compute a cyclic redundancy check value
#
# DEGREES() 		Convert radians to degrees
#
# DIV 				Integer division
#
# / 					Division operator
#
# EXP() 				Raise to the power of
#
# FLOOR() 			Return the largest integer value not greater than the argument
#
# LN() 				Return the natural logarithm of the argument
#
# LOG() 				Return the natural logarithm of the first argument
#
# LOG10() 			Return the base-10 logarithm of the argument
#
# LOG2() 			Return the base-2 logarithm of the argument
#
# - 					Minus operator
#
# MOD() 				Return the remainder
#
# %, MOD 			Modulo operator
#
# PI() 				Return the value of pi
#
# + 					Addition operator
#
# POW() 				Return the argument raised to the specified power
#
# POWER() 			Return the argument raised to the specified power
#
# RADIANS() 		Return argument converted to radians
#
# RAND() 			Return a random floating-point value
#
# ROUND() 			Round the argument
#
# SIGN() 			Return the sign of the argument
#
# SIN() 				Return the sine of the argument
#
# SQRT() 			Return the square root of the argument
#
# TAN() 				Return the tangent of the argument
#
# * 					Multiplication operator
#
# TRUNCATE() 		Truncate to specified number of decimal places
#
# - 					Change the sign of the argument
#
# 12.6.1 ARITHMETIC OPERATORS
#
# TABLE 12.11 ARITHMETIC OPERATORS
#
# NAME 			DESCRIPTION
#
# DIV 			Integer division
#
# / 				Division operator
#
# - 				Minus operator
#
# %, MOD 		Modulo operator
#
# + 				Addition operator
#
# * 				Multiplication operator
#
# - 				Change the sign of the argument
#
# The usual arithmetic operators are available.
#
# The result is determined according to the following rules:
#
# 		) In the case of -, +, and *, the result is calculated with BIGINT(64-bit) precision
# 			if both operands are integers.
#
# 		) If both operands are integers and any of them are unsigned, the result is an unsigned integer.
#
# 			For subtraction, if the NO_UNSIGNED_SUBTRACTION SQL mode is enabled,
# 			the result is signed even if any operand is unsigned.
#
# 		) If any of the operands of a +, -, /, *, % is a real or string value, the precision of the result
# 			is the precision of the operand with the maximum precision.
#
# 		) In division performed with /, the scale of the result when using two exact-value operands
# 			is the scale of the first operand plus the value of the div_precision_increment system
# 			variable
#
# 			(which is 4 by default)
#
# 			For example, the result of the expression 5.05 / 0.014 has a scale of six decimal places
# 			(360.714286)
#
# These rules are applied for each operation, such that nested calculations imply the precision
# of each component.
#
# Hence, (14620 / 9432456) / (24250 / 9432456),
# resolves first to (0.0014) / (0.0026), with the final result having 8 decimal places
# (0.60288653)
#
# Because of these rules and the way they are applied, care should be taken to ensure that components
# and subcomponents of a calculation use the appropriate level of precision.
#
# See SECTION 12.10, "CAST FUNCTIONS AND OPERATORS"
#
# For information about handling of overflow in numeric expression evaluation,
# see SECTION 11.2.6, "OUT-OF-RANGE AND OVERFLOW HANDLING"
#
# Arithmetic operators apply to numbers.
#
# For other types of values, alternative operations may be available.
#
# For example, to add date values, use DATE_ADD(); see - SECTION 12.7, "DATE AND TIME FUNCTIONS"
#
# 		) +
#
# 			Addition:
#
# 				SELECT 3+5;
# 					-> 8
#
# 		) -
#
# 			Subtraction:
#
# 				SELECT 3-5;
# 					-> -2
#
# 		) -
#
# 			Unary minus. This operator changes the sign of the operand.
#
# 				SELECT - 2;
# 					-> -2
#
# 			NOTE:
#
# 				If this operator is used with a BIGINT, the return value is also a BIGINT.
#
# 				This means that you should avoid using - on integers that may have the value
# 				of -2^63
#
# 		) *
#
# 			Multiplication:
#
# 				SELECT 3*5;
# 					-> 15
# 				etc.
#
# 			In this example, under the etc., is an illustration of an out of range BIGINT error, because of too large sizing.
# 	
# 		) /
#
# 			Division:
#
# 				SELECT 3/5;
# 					-> 0.60
#
# 			Division by zero produces a NULL result:
#
# 				SELECT 102/(1-1);
# 					-> NULL
#
# 			A division is calculated with BIGINT arithmetic only if performed
# 			in a context where its result is converted to an integer.
#
# 		) DIV
#
# 			Integer division.
#
# 			Discards from the division result any fractional part to the right of the decimal point.
#
# 			If either operand has a noninteger type, the operands are converted to DECIMAL and divided
# 			using DECIMAL arithmetic before converting the result to BIGINT.
#
# 			If the result exceeds BIGINT range, again, an error.
#
# 				SELECT 5 DIV 2, -5 DIV 2, 5 DIV -2, -5 DIV -2;
# 					-> 2, -2, -2, 2
#
# 		) N % M, N MOD M
#
# 			Modulo operation.
#
# 			Returns the remainder of N divided by M.
#
# 			For more information, see the description for the MOD() function
# 			in SECTION 12.6.2, "MATHEMATICAL FUNCTIONS"
#
# 12.6.2 MATHEMATICAL FUNCTIONS
#
# TABLE 12.12 MATHEMATICAL FUNCTIONS
#
# NAME 			Desc
#
# ABS() 			Return the absolute value
#
# ACOS() 		Return the arc cosine
#
# ASIN() 		Return the arc sine
#
# ATAN() 		Return the arc tangent
#
# ATAN2(), 		Return the arc tangent of the two arguments
# ATAN()
#
# CEIL() 		Return the smallest integer value not less than the argument
#
# CEILING() 	Return the smallest integer value not less than the argument
#
# CONV() 		Converts numbers between different number bases
#
# COS() 			Return the cosine
#
# COT() 			Return the cotangent
#
# CRC32() 		Compute a cyclic redundancy check value
#
# DEGREES() 	Convert radians to degrees
#
# EXP() 			Raise to the power of
#
# FLOOR() 		Return the largest integer value not greater than the argument
#
# LN() 			Return the natural logarithm of the argument
#
# LOG() 			Return the natural logarithm of the first argument
#
# LOG10() 		Returns the base-10 logarith mof the argument
#
# LOG2() 		Returns the base-2 logarith, of the argument
#
# MOD() 			Return the remainder
#
# PI() 			Return the value of pi
#
# POW() 			Return the argument raised to the specified power
#
# POWER() 		Return the argument raised to the specified power
#
# RADIANS() 	Return argument converted to radians
#
# RAND() 		Return a random floating-point value
#
# ROUND() 		Round the argument
#
# SIGN() 		Return the sign of the argument
#
# SIN() 			Return the sine of the argument
#
# SQRT() 		Return the square root of the argument
#
# TAN() 			Return the tangent of the argument
#
# TRUNCATE() 	Truncate to specified number of decimal places
#
# All mathematical functions return NULL in the event of an error.
#
# 		) ABS(X)
#
# 			Returns the absolute value of X
#
# 				SELECT ABS(2);
# 					-> 2
#
# 				SELECT ABS(-32);
# 					-> 32
#
# 			This function is safe to use with BIGINT values.
#
# 		) ACOS(X)
#
# 			Returns the arc cosine of X, that is, the value whose cosine is X.
#
# 			Returns NULL if X is not in the range -1 to 1
#
# 			SELECT ACOS(1);
# 				-> 0
#
# 			SELECT ACOS(1.0001);
# 				-> NULL
#
# 			SELECT ACOS(0);
# 				-> 1.5707963267949
#
# 		) ASIN(X)
#
# 			Returns the arc sine of X, that is, the value whose
# 			sine is X.
#
# 			Returns NULL if X is not in the range -1 to 1
#
# 			SELECT ASIN(0.2);
# 				-> 0.20135792079033
# 			
# 			SELECT ASIN('foo');
#
# 			+------------------------+
# 			| ASIN('foo') 				 |
# 			+------------------------+
# 			| 			0 					 |
# 			+------------------------+
# 			1 row in set, 1 warning (0.00 sec)
#
# 			SHOW WARNINGS;
# 			+---------+-------+-----------------------------------------+
# 			| Level   | Code  | Message 											|
# 			+---------+-------+-----------------------------------------+
# 			| Warning | 1292  | Truncated incorrect DOUBLE value: 'foo' |
# 			+---------+-------+-----------------------------------------+
#
# 		) ATAN(X)
#
# 			Returns the arc tangent of X, that is, the value whose tangent is X.
#
# 				SELECT ATAN(2);
# 					-> 1.1071487177941
#
# 				SELECT ATAN(-2);
# 					-> -1.1071487177941
#
# 		) ATAN(Y,X), ATAN2(Y,X)
#
# 			Returns the arc tangent of the two variables X and Y.
#
# 			IT is similar to calculating the arc tangent of Y / X, except that
# 			the signs of both arguments are used to determine the quadrant of the result.
#
# 				SELECT ATAN(-2,2);
# 					-> -0.785etc.
#
# 				SELECT ATAN2(PI(),0);
# 					-> 1.570796etc.
#
# 		) CEIL(X)
#
# 			CEIL() is a synonym for CEILING()
#
# 		) CEILING(X)
#
# 			Returns the smallest integer value not less than X.
#
# 				SELECT CEILING(1.23);
# 					-> 2
#
# 				SELECT CEILING(-1.23);
# 					-> -1
#
# 			For exact-value numeric arguments, the return value has an exact-value numeric type.
# 			For string or floating-point arguments, the return value has a floating-point type.
#
# 		) CONV(N,from base, to base)
#
# 			Converts numbers between different number bases.
#
# 			Returns a string representation of the number N, converted from base
# 			from_base to base to_base
#
# 			Returns NULL if any argument is NULL
#
# 			The argument N is interpreted as an integer, but may be specified as
# 			an integer or a string.
#
# 			The minimum base is 2 and the maximum base is 36.
#
# 			If from_base is a negative number, N is regarded as a signed number.
#
# 			Otherwise, N is treated as unsigned, CONV() works with 64-bit precision.
#
# 				SELECT CONV('a', 16, 2);
# 					-> '1010'
#
# 				SELECT CONV('6E',18,8);
# 					-> '172'
#
# 				SELECT CONV(-17,10, -18);
# 					-> '-H'
#
# 				SELECT CONV(10+'10'+'10'+X'0a',10,10);
# 					-> '40'
#
# 		) COS(X)
#
# 			Returns the cosine of X, where X is given in radians.
#
# 			SELECT COS(PI());
# 				-> -1
#
# 		) COT(X)
#
# 			Returns the cotangent of X.
#
# 				SELECT COT(12);
# 					-> -1.57
# 				
# 				SELECT COT(0);
# 					-> out-of-range error
#
# 		) CRC32(expr)
#
# 			Computes a cylic redundancy check value and returns a 32-bit unsigned value.
#
# 			The result is NULL if the argument is NULL.
#
# 			The argument is expected to be a string and (if possible), is treated as one
# 			if it is not.
#
# 			SELECT CRC32('MySQL');
# 				-> 3259397556
# 			SELECT CRC32('mysql');
# 				-> 2501908538
#
# 		) DEGREES(X)
#
# 			Returns the argument X, converted from radians to degrees.
#
# 				SELECT DEGREES(PI());
# 					-> 180
#
# 				SELECT DEGREES(PI() / 2);
# 					-> 90
#
# 		) EXP(X)
#
# 			Returns the value of e (the base of natural logarithms) raised to the power of X.
#
# 			The inverse of this function is LOG() (using a single argument only) or LN()
#
# 				SELECT EXP(2);
# 					-> 7.3890- etc
#
# 				SELECT EXP(-2);
# 					-> 0.135- etc
#
# 				SELECT EXP(0);
# 					-> 1
#
# 		) FLOOR(X)
#
# 			Returns the largest integer value not greater than X.
#
# 				SELECT FLOOR(1.23), FLOOR(-1.23),
# 					-> 1, -2
#
# 			For exact-value numeric arguments, the return value has an exact-value
# 			numeric type.
#
# 			For string or floating-point arguments, the return value has a floating-point type.
#
# 		) FORMAT(X, D)
#
# 			Formats the number X to a format like '#,###, ###.##', rounded to D decimal places,
# 			and returns the result as a string.
#
# 			For details, see SECTION 12.5, "STRING FUNCTIONS"
#
# 		) HEX(N or S)
#
# 			This function can be used to obtain a hexadecimal representation of a decimal number
# 			or a string;
#
# 			The manner in which it does so varies according to the argument's type.
#
# 			See this function's description in SECTION 12.5, "STRING FUNCTIONS", for details
#
# 		) LN(X)
#
# 			Returns the natural logarithm of X;
#
# 			That is, the base-e logarithm of X.
#
# 			If X is less than or equal to 0.0E0, the function returns NULL
# 			and a warning 'Invalid argument for logarithm' is reported.
#
# 				SELECT LN(2);
# 					-> 0.6937147- etc
# 				SELECT LN(-2);
# 					-> NULL
#
# 			This function is synonymous with LOG(X).
#
# 			The inverse of this function is the EXP() function
#
# 		) LOG(X), LOG(B,X)
#
# 			If called with one parameter, this function returns the natural logarithm of X.
#
# 			If X is less than or equal to 0.0E0, the function returns NULL and a warning
# 			"Invalid argument for logarithm" is reported.
#
# 			The inverse of this function (when called with a single argument)
# 			is the EXP() function.
#
# 				SELECT LOG(2);
# 					-> 0.69314-etc
#
# 				SELECT LOG(-2);
# 					-> NULL
#
# 			If called with two parameters, this function returns the logarithm of X
# 			to the base B.
#
# 			If X is less than or equal to 0, or if B is less than or equal to 1,
# 			then NULL is returned.
#
# 				SELECT LOG(2, 65536);
# 					-> 16
#
# 				SELECT LOG(10, 100);
# 					-> 2
#
# 				SELECT LOG(1,100);
# 					-> NULL
#
# 			LOG(B,X) is equivalent to LOG(X) / LOG(B)
#
# 		) LOG2(X)
#
# 			Returns the base-2 logarithm of X.
#
# 			If X is less than or equal to 0.0E0, the function returns NULL
# 			and a warning "Invalid argument for logarithm" is reported.
#
# 				SELECT LOG2(65536);
# 					-> 16
#
# 				SELECT LOG2(-100);
# 					-> NULL
#
# 			LOG2() is useful for finding out how many bits a number reuqires for storage.
#
# 			This function is equivalent to the expression LOG(X) / LOG(2)
#
# 		) LOG10(X)
#
# 			Returns the base-10 logarithm of X.
#
# 			If X is less than or equal to 0.0E0, the function returns NULL
# 			and a warning "Invalid argument for logarithm" is reported.
#
# 				SELECT LOG10(2);
# 					-> 0.03010-etc
#
# 				SELECT LOG10(100);
# 					-> 2
#
# 				SELECT LOG10(-100);
# 					-> NULL
#
# 			LOG10(X) is equivalent to LOG(10,X)
#
# 		) MOD(N,M), N % M, N MOD M
#
# 			Modulo operation.
#
# 			Returns the remainder of N divided by M.
#
# 				SELECT MOD(234, 10);
# 					-> 4
#
# 				SELECT 253 % 7;
# 					-> 1
#
# 				SELECT MOD(29,9);
# 					-> 2
#
# 				SELECT 29 MOD 9;
# 					-> 2
#
# 			This function is safe to use with BIGINT values.
#
# 			MOD() also works on values that have a fractional part and
# 			returns the exact remainder after division:
#
# 				SELECT MOD(34.5,3);
# 					-> 1.5
#
# 			MOD(N,0) returns NULL
#
# 		) PI()
#
# 			Returns the value of pi
#
# 			The default number of decimal places displayed is seven, but MySQL uses
# 			the full double-precision value internally.
#
# 				SELECT PI();
# 					-> 3.141593
#
# 				SELECT PI()+0.000000000000;
# 					-> 3.14159265-etc
#
# 		) POW(X,Y)
#
# 			Returns the value of X raised to the power of Y
#
# 				SELECT POW(2,2);
# 					-> 4
#
# 				SELECT POW(2, -2);
# 					-> 0.25
#
# 		) POWER(X,Y)
#
# 			Synonym to POW()
#
# 		) RADIANS(X)
#
# 			Returns the argument X, converted from degrees to radians.
#
# 			(Note that radians equal 180 degrees)
#
# 				SELECT RADIANS(90);
# 					-> 1.570796-etc
#
# 		) RAND([N])
#
# 			Returns a random floating-point value v in the range 0 <= v < 1.0. 
#
# 			To obtain a random integer R in the range i <= R < j, 			
# 			use the expression FLOOR(i + RAND() * (j - i))
#
# 			For example, to obtain a random integer in the range of
# 			7 <= R < 12, use the following statement:
#
# 				SELECT FLOOR(7 + (RAND() * 5));
#
# 			If an integer argument N is specified, it is used as the seed value:
#
# 				) With a constant initializer argument, the seed is initialized once when the statement is prepared,,
# 					prior to execution.
#
# 				) With a nonconstant initializer argument (such as a column name),
# 					the seed is initialized with the value for each invocation of RAND()
#
# 			One implication of this behavior is that for equal argument values, RAND(N) returns
# 			the same value each time, and thus produces a repeatable sequence of column values.
#
# 			In the following example, the sequence of values produced by RAND(3) is the same both
# 			places it occurs.
#
# 				CREATE TABLE t (i INT);
# 				Query OK, 0 rows affected (0.42 sec)
#
# 				INSERT INTO t VALUES(1), (2), (3);
# 				Query OK, 3 rows affected (0.00 sec)
# 				Records: 3 Duplicates: 0 Warnings: 0
#
# 				SELECT i, RAND() FROM t;
# 				+-------+----------------------+
# 				| i 	  | RAND() 					 |
# 				+-------+----------------------+
# 				| 1 	  | 0.619-etc 				 |
# 				| 2 	  | 0.938-etc 				 |
# 				| 3 	  | 0.834-etc 				 |
# 				+-------+----------------------+
# 				3 rows in set (0.00 sec)
#
# 				SELECT i, RAND(3) FROM t;
# 				+-------+----------------------+
# 				| i 	  | RAND(3) 				 |
# 				+-------+----------------------+
# 				| 1 	  | 0.90-etc 				 |
# 				| 2 	  | 0.373-etc 				 |
# 				| 3 	  | 0.148-etc 				 |
# 				+-------+----------------------+
# 				3 rows in set (0.00 sec)
#
# 				SELECT i, RAND() FROM t;
# 				+-------+----------------------+
# 				| i 	  | RAND() 					 |
# 				+-------+----------------------+
# 				| 1 	  | 0.358-etc 				 |
# 				| 2 	  | 0.289-etc 				 |
# 				| 3 	  | 0.370-etc 				 |
# 				+-------+----------------------+
# 				3 rows in set (0.00 sec) 		
#
# 				SELECT i, RAND(3) FROM t;
# 				+--------+---------------------+
# 				| i 	   | RAND(3) 				 |
# 				+--------+---------------------+
# 				| 1 		| 0.905-etc 			 |
# 				| 2 	   | 0.373-etc 			 |
# 				| 3 		| 0.148-etc 			 |
# 				+--------+---------------------+
# 				3 rows in set (0.01 sec)
#
# RAND() in a WHERE clause is evaluated for every row (when selecting from one table)
# or combination of rows (when selecting from a multiple-table join).
#
# Thus, for optimizer purposes, RAND() is not a constant value and cannot be used
# for index optimizations.
#
# For more information, see SECTION 8.2.1.18,, "FUNCTION CALL OPTIMIZATION"
#
# Use of a column with RAND() values in an ORDER BY or GROUP BY clause may yield
# unexpected results because for either clause a RAND() expression can be evaluated
# multiple times for the same row, each time returning a different result.
#
# If the goal is to retrieve rows in random order, you can use a statement like this:
#
# 		SELECT * FROM tbl_name ORDER BY RAND();
#
# To select a random sample from a set of rows, combine ORDER BY RAND() with LIMIT:
#
# 		SELECT * FFROM table1, table2 WHERE a=b AND c<d ORDER BY RAND() LIMIT 1000;
#
# RAND() is not meant to be a perfect random generator. It is a fast way to generate
# random numbers on demand that is portable between platforms for the same MySQL version.
#
# This funciton is unsafe for statement-based replication. A warning is logged if you use
# this function when binlog_format is set to STATEMENT. (Bug #49222)
#
# 		) ROUND(X), ROUND(X, D)
#
# 			Rounds the argument X to D decimal places.
#
# 			The rounding algorithm depends on the data type of X.
#
# 			D defaults to 0 if not specified. D can be negative to cause
# 			D digits left of the decimal point of the value X to become zero.
#
# 				SELECT ROUND(-1.23);
# 					-> -1
#
# 				SELECT ROUND(-1.58);
# 					-> -2
#
# 				SELECT ROUND(1.58);
# 					-> 2
#
# 				SELECT ROUND(1.298, 1);
# 					-> 1.3
#
# 				SELECT ROUND(1.298, 0);
# 					-> 1
#
# 				SELECT ROUND(23.298, -1);
# 					-> 20
#
# 			The return value has the same type as the first argument (assuming that it is integer,
# 			double or decimal)
#
# 			This means that for an integer argument, the result is an integer (no decimal places):
#
# 				SELECT ROUND(150.000,2), ROUND(150,2);
# 				+----------------------+------------------------+
# 				| ROUND(150.000,2) 	  | ROUND(150,2) 				|
# 				+----------------------+------------------------+
# 				| 			150.00 		  | 		150 					|
# 				+----------------------+------------------------+
#
# 			ROUND() uses the following rules depending on the type of the first argument:
#
# 				) For exact-value numbers, ROUND() uses the "round half away from zero" or
# 					"round toward nearest" rule:
#
# 						A value with a fractional part of .5 or greater is rounded up to the next
# 						integer if positive or down to the next integer if negative.
#
# 						(In other words, it is rounded away from zero)
#
# 						A value with a fractional part less than .5 is rounded down to the
# 						next integer if positive or up to the next integer if negative.
#
# 				) For approximate-value numbers, the result depends on the C library.
#
# 					On many systems, this means that ROUND() uses the "round to nearest even" rule:
#
# 						A value with a fractional part exactly halfway between two integers is
# 						rounded to the nearest even integer.
#
# 			The following example shows how rounding differs for exact and approximate values:
#
# 				SELECT ROUND(2.5), ROUND(25E-1);
# 				+----------------+----------------------+
# 				| ROUND(2.5) 	  | ROUND(25E-1) 			 |
# 				+----------------+----------------------+
# 				| 3 				  | 2 						 |
# 				+----------------+----------------------+
#
# 			For more information, see SECTION 12.24, "PRECISION MATH"
#
# 	) SIGN(X)
#
# 		Returns the sign of the argument as -1,0 or 1, depending on whether X is negative,
# 		zero or positive.
#
# 			SELECT SIGN(-32);
# 				-> -1
#
# 			SELECT SIGN(0);
# 				-> 0
#
# 			SELECT SIGN(234);
# 				-> 1
#
# 	) SIN(X)
#
# 		Returns the sine of X, where X is given in radians.
#
# 			SELECT SIN(PI());
# 				-> 1.2246-etc
# 			SELECT ROUND(SIN(PI()));
# 				-> 0
#
# 	) SQRT(X)
#
# 		Returns hte square root of a nonnegative number X
#
# 			SELECT SQRT(4);
# 				-> 2
#
# 			SELECT SQRT(20);
# 				-> 4.4721-etc
#
# 			SELECT SQRT(-16);
# 				-> NULL
#
# 	) TAN(X)
#
# 		Returns the tangent of X, where X is given in radians.
#
# 			SELECT TAN(PI());
# 				-> 1.224-etc
#
# 			SELECT TAN(PI()+1);
# 				-> 1.5574-etc
#
# 	) TRUNCATE(X,D)
#
# 		Returns the number X, truncated to D decimal places.
#
# 		If D is 0, the result has no decimal point or fractional part.
#
# 		D can be negative to cause D digits left of the decimal point of
# 		the value X to become zero.
#
# 			SELECT TRUNCATE(1.223, 1);
# 				-> 1.2
#
# 			SELECT TRUNCATE(1.999,1);
# 				-> 1.9
#
# 			SELECT TRUNCATE(1.999,0);
# 				-> 1
#
# 			SELECT TRUNCATE(-1.999,1);
# 				-> -1.9
#
# 			SELECT TRUNCATE(122, -2);
# 				-> 100
#
# 			SELECT TRUNCATE(10.28*100,0);
# 				-> 1028
#
# 		All numbers are rounded towards zero.
#
# 12.7 DATE AND TIME FUNCTIONS
#
# This section describes the functions that can be used to manipulate temporal values.
#
# See SECTION 11.3, "DATE AND TIME TYPES", for a description of the range of values each
# date and time type has and the valid formats in which values may be specified.
#
# TABLE 12.13 DATE AND TIME FUNCTIONS
#
# 		NAME 							DESCRIPTION
#
# ADDDATE() 						Add time values (intervals) to a date value
#
# ADDTIME() 						Add time
#
# CONVERT_TZ() 					Convert from one time zone to another
#
# CURDATE() 						Returns the current date
#
# CURRENT_DATE(),  				Synonyms for CURDATE()
# CURRENT_DATE	
#
# CURRENT_TIME(), 				Synonyms for CURTIME()
# CURRENT_TIME
#
# CURRENT_TIMESTAMP(), 			Synonyms for NOW()
# CURRENT_TIMESTAMP 
#
# CURTIME() 						Returns the current time
#
# DATE() 							Extract the date part of a date or datetime expression
#
# DATE_ADD() 						Add time values (intervals) to a date value
#
# DATE_FORMAT() 					Format date as specified
#
# DATE_SUB() 						Subtract a time value (interval) from a date
#
# DATEDIFF() 						Subtract two dates
#
# DAY() 								Synonym for DAYOFMONTH()
#
# DAYNAME() 						Return the name of the weekday
#
# DAYOFMONTH() 					Return the day of the month (0-31)
#
# DAYOFWEEK() 						Return the weekday index of the argument
#
# DAYOFYEAR() 						Return the day of the year (1-366)
#
# EXTRACT() 						Extract part of a date
#
# FROM_DAYS() 						Convert a day number to a date
#
# FROM_UNIXTIME() 				Format Unix timestamp as a date
#
# GET_FORMAT() 					Return a date format string
#
# HOUR() 							Extract the hour
#
# LAST_DAY 							Return the last day of the month for the argument
#
# LOCALTIME(), 					Synonym for NOW()
# LOCALTIME
#
# LOCALTIMESTAMP, 				Synonym for NOW()
# LOCALTIMESTAMP()
#
# MAKEDATE() 						Create a date from the year and day of year
#
# MAKETIME() 						Create time from hour, minute, second
#
# MICROSECOND() 					Return the microseconds from argument
#
# MINUTE() 							Return the minute from the argument
#
# MONTH() 							Return the month from the date passed
#
# MONTHNAME() 						Return the name of the month
#
# NOW() 								Return the current date and time
#
# PERIOD_ADD() 					Add a period to a year-month
#
# PERIOD_DIFF() 					Return the number of months between periods
#
# QUARTER() 						Return the quarter from a date argument
#
# SEC_TO_TIME() 					Converts seconds to 'HH:MM:SS' format
#
# SECOND() 							Return the second (0-59)
#
# STR_TO_DATE() 					Convert a string to a date
#
# SUBDATE() 						Synonym for DATE_SUB() when invoked with three arguments
#
# SUBTIME() 						Subtract times
#
# SYSDATE() 						Return the time at which the function executes
#
# TIME() 							Extract the time portion of the expression passed
#
# TIME_FORMAT() 					Format as time
#
# TIME_TO_SEC() 					Return the argument converted to seconds
#
# TIMEDIFF() 						Subtract time
#
# TIMESTAMP() 						With a single argument, this function returns the date or datetime expression;
# 										with two arguments, the sum of the arguments
#
# TIMESTAMPADD() 					Add an interval to a datetime expression
#
# TIMESTAMPDIFF() 				Subtract an interval from a datetime expression
#
# TO_DAYS() 						Return the date argument converted to days
#
# TO_SECONDS() 					Return the date or datetime argument converted to seconds since Year 0
#
# UNIX_TIMESTAMP() 				Return a Unix timestamp
#
# UTC_DATE() 						Return the current UTC date
#
# UTC_TIME() 						Return the current UTC time
#
# UTC_TIMESTAMP() 				Return the current UTC date and time
#
# WEEK() 							Return the week number
#
# WEEKDAY() 						Return the weekday index
#
# WEEKOFYEAR() 					Return the calendar week of the date (1-53)
#
# YEAR() 							Return the year
#
# YEARWEEK() 						Return the year and week
#
# Here is an example that uses date functions.
#
# The following query selects all rows with a date_col value from
# within the last 30 days:
#
# 		SELECT something FROM tbl_name
# 		WHERE DATE_SUB(CURDATE(), INTERVAL 30 DAY) <= date_col;;
#
# The query also selects rows with dates that lie in the future.
#
# Functions that expect date values usually accept datetime values and ignore the time part.
#
# Functions that expect time values usually accept datetime values and ignore the date part.
#
# Functions that return the current date or time each are evaluated only once per query at the
# start of query execution.
#
# This means that multiple references to a function such as NOW() within a single query always
# produce the same result.
#
# For our purposes, a single query also includes a call to a stored program (stored routine, trigger
# or event) and all subprograms called by that program).
#
# This principle also applies to CURDATE(), CURTIME(), UTC_DATE(), UTC_TIME(), UTC_TIMESTAMP(),
# and to any of their synonyms.
#
# The CURRENT_TIMESTAMP(), CURRENT_TIME(), CURRENT_DATE(), and FROM_UNIXTIME() functions return
# values in the connection's current time zone, which is available as the value of the time_zone
# system variable.
#
# In addition, UNIX_TIMESTAMP() assumes that its argument is a datetime value in the current time zone.
#
# See SECTION 5.1.13, "MYSQL SERVER TIME ZONE SUPPORT"
#
# Some date functions can be used with "zero" dates or incomplete dates such as '2001-11-00',
# whereas others cannot.
#
# Functions that extract parts of dates typically work with incomplete dates and thus can return
# 0 when you might otherwise expect a nonzero value.
#
# For example:
#
# 		SELECT DAYOFMONTH('2001-11-00'), MONTH('2005-00-00');
# 			-> 0, 0
#
# Other functions expect complete dates and return NULL for incomplete dates.
#
# These include functions that perform date arithmetic or that map parts of
# dates to names.
#
# For example:
#
# 		SELECT DATE_ADD('2006-05-00', INTERVAL 1 DAY);
# 			-> NULL
#
# 		SELECT DAYNAME('2006-05-00');
# 			-> NULL
#
# Several functions are more strict when passed a DATE() function value as their argument
# and reject incomplete dates with a day part of zero.
#
# These functions are affected:
#
# 		CONVERT_TZ(), DATE_ADD(), DATE_SUB(), DAYOFYEAR(), LAST_DAY() (permits a day part of zero),
# 		TIMESTAMPDIFF(), TO_DAYS(), TO_SECONDS(), WEEK(), WEEKDAY(), WEEKOFYEAR(), YEARWEEK()
#
# Fractional seconds for TIME, DATETIME and TIMESTAMP values are supported, with up to microsecond
# precision.
#
# Functions that take temporal arguments accept values with fractional seconds.
#
# Return values from temporal functions include fractional seconds as appropriate.
#
# 		) ADDDATE(date, INTERVAL expr unit), ADDDATE(expr,days)
#
# 			When invoked with the INTERVAL form of the second argument, ADDDATE() is a synonym
# 			for DATE_ADD()
#
# 			The related function SUBDATE() is a synonym for DATE_SUB()
#
# 			For information on the INTERVAL unit argument, see TEMPORAL INTERVALS
#
# 				SELECT DATE_ADD('2008-01-02', INTERVAL 31 DAY);
# 					-> '2008-02-02'
#
# 				SELECT ADDDATE('2008-01-02', INTERVAL 31 DAY);
# 					-> '2008-02-02'
#
# 			WHen invoked with the days form of the second argument, MySQL treats it
# 			as an integer number of days to be added to expr.
#
# 				SELECT ADDDATE('2008-01-02', 31);
# 					-> '2008-02-02'
#
# 		) ADDTIME(expr1, expr2)
#
# 			ADDTIME() adds expr2 to expr1 and returns the result.
#
# 			expr1 is a time or datetime expression, and expr2 is a time expression.
#
# 				SELECT ADDTIME('2007-12-31 23:59:59.999999', '1 1:1:1.000002');
# 					-> '2008-01-02 01:01:01.000001'
#
# 				SELECT ADDTIME('01:00:00.999999', '02:00:00.999998');
# 					-> '03:00:01.999997'
#
# 		) CONVERT_TZ(dt, from tz, to tz)
#
# 			CONVERT_TZ() converts a datetime value dt from the time zone given by from_tz to
# 			the time zone given by to_tz and returns the resulting value.
#
# 			Time zones are specified as described in SECTION 5.1.13, "MYSQL SERVER TIME ZONE SUPPORT".
#
# 			This function returns NULL if the arguments are invalid.
#
# 			If the value falls out of the supported range of the TIMESTAMP type when converted
# 			from from_tz to UTC, no conversion occurs.
#
# 			The TIMESTAMP range is described in SECTION 11.1.2, "DATE AND TIME TYPE OVERVIEW"
#
# 				SELECT CONVERT_TZ('2004-01-01 12:00:00', 'GMT', 'MET');
# 					-> '2004-01-01 13:00:00'
#
# 				SELECT CONVERT_TZ('2004-01-01 12:00:00', '+00:00', '+10:00');
# 					-> '2004-01-01 22:00:00'
#
# 			NOTE:
#
# 				To use named time zones such as 'MET' or 'Europe/Moscow', the time zone tables
# 				must be properly set up.
#
# 				see SECTION 5.1.13, "MYSQL SERVER TIME ZONE SUPPORT", for instructions.
#
# 		) CURDATE()
#
# 			Returns the current date as a value in 'YYYY-MM-DD' or YYYYMMDD format, depending
# 			on whether the function is used in a string or numeric context.
#
# 				SELECT CURDATE();
# 					-> '2008-06-13'
#
# 				SELECT CURDATE() + 0;
# 					-> 20080613
#
# 		) CURRENT_DATE, CURRENT_DATE()
#
# 			CURRENT_DATE and CURRENT_DATE() are synonyms for CURDATE()
#
# 		) CURRENT_TIME, CURRENT_TIME([fsp])
#
# 			CURRENT_TIME and CURRENT_TIME() are synonyms for CURTIME()
#
# 		) CURRENT_TIMESTAMP, CURRENT_TIMESTAMP([fsp])
#
# 			CURRENT_TIMESTAMP and CURRENT_TIMESTAMP() are synonyms for NOW()
#
# 		) CURTIME([fsp])
#
# 			Returns the current time as a value in 'HH:MM:SS' or HHMMSS format, depending on
# 			whether the function is used in a string or numeric context.
#
# 			The value is expressed in the current time zone.
#
# 			If the fsp argument is given to specify a fractional seconds precision from 0 to 6,
# 			the return value includes a fractional seconds part of that many digits.
#
# 				SELECT CURTIME();
# 					-> '23:50:26'
#
# 				SELECT CURTIME() + 0;
# 					-> 235026.000000
#
# 		) DATE(expr)
#
# 			Extracts the date part of the date or datetime expression expr
#
# 				SELECT DATE('2003-12-31 01:02:03');
# 					-> '2003-12-31'
#
# 		) DATEDIFF(expr1, expr2)
#
# 			DATEDIFF() returns expr1 - expr2 expressed as a value in days from one date
# 			to the other.
#
# 			expr1 and expr2 are date or date-and-time expressions.
#
# 			Only the date parts of the values are used in the calculation.
#
# 				SELECT DATEDIFF('2007-12-31 23:59:59', '2007-12-30');
# 					-> 1
#
# 				SELECT DATEDIFF('2010-11-30 23:59:59', '2010-12-31');
# 					-> 31
#
# 		) DATE_ADD(date, INTERVAL expr unit), DATE_SUB(date, INTERVAL expr unit)
#
# 			These functions perform date arithmetic.
#
# 			The date argument specifies the starting date or datetime value.
#
# 			expr is an expression specifying the interval values to be added or subtracted
# 			from the starting date.
#
# 			expr is evaluated as a string; it may start with a - for negative intervals.
#
# 			unit is a keyword indicating the units in which the expression should be interpreted.
#
# 			For more information about temporal interval syntax, including a full list of unit specifiers,
# 			the expected form of the expr argument for each unit value, and rules for operand 
# 			interpretation in temporal arithmetic, see TEMPORAL INTERVALS.
#
# 			The return value depends on the arguments:
#
# 				) DATE if the date argument is a DATE value and your calculations involve only YEAR,
# 					MONTH and DAY parts (that is, no time parts)
#
# 				) DATETIME if the first argument is a DATETIME(or TIMESTAMP) value, or if the first argument
# 					is a DATE and the unit value uses HOURS, MINUTES, or SECONDS.
#
# 				) String otherwise.
#
# 			To ensure that the result is DATETIME, you can use CAST() to convert the first argument
# 			to DATETIME.
#
# 				SELECT DATE_ADD('2018-05-01', INTERVAL 1 DAY);
# 					-> '2018-05-02'
# 				SELECT DATE_SUB('2018-05-01', INTERVAL 1 YEAR);
# 					-> '2017-05-01'
#
# 				SELECT DATE_ADD('2020-12-31 23:59:59',
# 									  INTERVAL 1 SECOND);
# 					-> '2021-01-01 00:00:00'
#
# 				SELECT DATE_ADD('2018-12-31 23:59:59',
# 									  INTERVAL 1 DAY);
# 					-> '2019-01-01 23:59:59'
#
# 				SELECT DATE_ADD('2100-12-31 23:59:59',
# 									  INTERVAL '1:1' MINUTE_SECOND);
# 					-> '2101-01-01 00:01:00'
#
# 				SELECT DATE_SUB('2025-01-01 00:00:00',
# 									  INTERVAL '1 1:1:1' DAY_SECOND);
# 					-> '2024-12-30 22:58:59'
#
# 				SELECT DATE_ADD('1900-01-01 00:00:00',
# 									  INTERVAL '-1 10' DAY_HOUR);
# 					-> '1899-12-30 14:00:00'
#
# 				SELECT DATE_SUB('1998-01-02', INTERVAL 31 DAY);
# 					-> '1997-12-02'
#
# 				SELECT DATE_ADD('1992-12-31 23:59:59.000002',
# 							INTERVAL '1.999999' SECOND_MICROSECOND);
# 					-> '1993-01-01 00:00:01.000001'
#
# 		) DATE_FORMAT(date, format)
#
# 			Formats the date value according to the format string.
#
# 			THe following specifies may be used in the format string.
#
# 			The % character is required before format specifier characters.
#
# 				SPECIFIER 			DESC
#
# 				%a 					Abbreviated weekday name (Sun--Sat)
#
# 				%b 					Abbreivated month name (Jan--Dec)
#
# 				%c 					Month, numeric(0--12)
#
# 				%D 					Day of the month with English suffix (0th, 1st, 2nd, 3rd, ---)
#
# 				%d 					Day of the month, numeric (00--31)
#
# 				%e 					Day of the month, numeric (0--31)
#
# 				%f 					Microseconds (000000-999999)
#
# 				%H 					Hour (00-23)
#
# 				%h 					Hour (01--12)
#
# 				%I 					Hour (01--12)
#
# 				%i 					Minutes, numeric (00--59)
#
# 				%j 					Day of year (001--366)
#
# 				%k 					Hour (0--23)
#
# 				%l 					hour (1--12)
#
# 				%M 					Month name (January--December)
#
# 				%m 					Month, numeric (00--12)
#
# 				%p 					AM or PM
#
# 				%r 					Time, 12-hour (hh:mm:ss followed by AM or PM)
#
# 				%S 					Seconds (00--59)
#
# 				%s 					Seconds (00--59)
#
# 				%T 					Time, 24-hour (hh:mm:ss)
#
# 				%U 					Week (00--53), where Sunday is the first day of the week; WEEK() mode 0
#
# 				%u 					Week (00--53), where Monday is the first day of the week; WEEK() mode 1
#
# 				%V						Week (01--53), where Sunday is the first day of the week; WEEK() mode 2; used with %X
#
# 				%v 					Week (01--53), where Monday is the first day of the week; WEEK() mode 3, used with %x
#
# 				%W 					Weekday name (Sunday--Saturday)
#
# 				%w 					Day of the week (0=Sunday--6=Saturday
#
# 				%X 					Year for the week where Sunday is the first day of the week, numeric, four digits; used with %V
#
# 				%x 					Year for the week, where Monday is the first day of the week, numeric, four digits; used with %v
#
# 				%Y 					Year, numeric, four digits
#
# 				%y 					Year, numeric, (Two digits)
#
# 				%% 					A literal % character
#
# 				%x 					x, for any "x" not listed above
#
# Ranges for the month and day specifiers begin with zero due to the fact that
# MySQL permits the storing of incomplete dates such as '2014-00-00'
#
# The language used for day and month names and abbreviations is controlled by the
# value of the lc_time_names system variable
#
# (SECTION 10.15, "MYSQL SERVER LOCALE SUPPORT")
#
# For the %U, %u, %V, and %v specifiers, see the description of the WEEK() function
# for information about the mode values.
#
# The mode affects how week numbering occurs.
#
# DATE_FORMAT() returns a string with a character set and collation given by character_set_connection
# and collation_connection so that it can return month and weekday names containing non-ASCII chars.
#
# 		SELECT DATE_FORMAT('2009-10-04 22:23:00', '%W %M %Y');
# 			-> 'Sunday October 2009'
#
# 		SELECT DATE_FORMAT('2007-10-04 22:23:00', '%H:%i:%s');
# 			-> '22:23:00'
#
# 		SELECT DATE_FORMAT('1900-10-04 22:23:00',
# 								'%D %y %a %d %m %b %j');
# 			-> '4th 00 Thu 04 10 Oct 277'
#
# 		SELECT DATE_FORMAT('1997-10-04 22:23:00',
# 								'%H %k %I %r %T %S %w');
# 			-> '22 22 10 10:23:00 PM 22:23:00 00 6'
#
# 		SELECT DATE_FORMAT('1999-01-01', '%X %V');
# 			-> '1998 52'
#
# 		SELECT DATE_FORMAT('2006-06-00', '%d');
# 			-> '00'
#
# 	) DATE_SUB(date, INTERVAL expr unit)
#
# 		See the description for DATE_ADD()
#
# 	) DAY(date)
#
# 		DAY() is a synonym for DAYOFMONTH()
#
# 	) DAYNAME(date)
#
# 		Returns the name of the weekday for date.
#
# 		The language used for the name is controlled by the value of the lc_time_names
# 		system variable
#
# 		(SECTION 10.15, "MySQL SERVER LOCALE SUPPORT")
#
# 			SELECT DAYNAME('2007-02-03');
# 				-> 'Saturday'
#
# 	) DAYOFMONTH(date)
#
# 		Returns the day of the month for date, in the range 1 to 31, or 0 for dates such as 
# 		'0000-00-00' or '2008-00-00' that have a zero day part.
#
# 			SELECT DAYOFMONTH('2007-02-03');
# 				-> 3
#
# 	) DAYOFWEEK(date)
#
# 		Returns the weekday index for date (1 = Sunday, 2 = Monday, ---, 7 = Saturday)
#
# 		These index values correspond to the ODBC standard.
#
# 			SELECT DAYOFWEEK('2007-02-03');
# 				-> 7
#
# 	) DAYOFYEAR(date)
#
# 		Returns the day of the year for date, in teh range 1 to 366
#
# 			SELECT DAYOFYEAR('2007-02-03');
# 				-> 34
#
# 	) EXTRACT(unit FROM date)
#
# 		The EXTRACT() function uses the same kinds of unit specifiers as DATE_ADD() or
# 		DATE_SUB(), but extracts parts from the date rather than performing date arithmetic.
#
# 		For information on the unit argument, see TEMPORAL INTERVALS
#
# 			SELECT EXTRACT(YEAR FROM '2019-07-02');
# 				-> 2019
#
# 			SELECT EXTRACT(YEAR_MONTH FROM '2019-07-02 01:02:03');
# 				-> 201907
#
# 			SELECT EXTRACT(DAY_MINUTE FROM '2019-07-02 01:02:03');
# 				-> 20102
#
# 			SELECT EXTRACT(MICROSECOND
# 								FROM '2003-01-02 10:30:00.000123');
# 				-> 123
#
# 	) FROM_DAYS(N)
#
# 		Given a day number N, returns a DATE Value
#
# 			SELECT FROM_DAYS(730669);
# 				-> '2000-07-03'
#
# 		Use FROM_DAYS() with caution on old dates.
#
# 		It is not inteded for use with values that precede the advent of the Gregorian
# 		calendar (1582)
#
# 		See SECTION 12.8, "WHAT CALENDAR IS USED BY MYSQL?"
#
# 	) FROM_UNIXTIME(unix timestamp), FROM_UNIXTIME(unix timestamp, format)
#
# 		Returns a representation of the unix_timestamp argument as a value in 'YYYY-MM-DD HH:MM:SS'
# 		or YYYYMMDDHHMMSS format, depending on whether the function is used in a string or numeric context.
#
# 		The value is expressed in the current time zone.
#
# 		unix_timestamp is an internal timestamp value such as is produced by the
# 		UNIX_TIMESTAMP() function
#
# 		If format is given, the result is formatted according to the format string, which is used
# 		the same way as listed in the entry for hte DATE_FORMAT() function
#
# 		SELECT FROM_UNIXTIME(1447430881);
# 			-> '2015-11-13 10:08:01'
#
# 		SELECT FROM_UNIXTIME(1447430881) + 0;
# 			-> 20151113100801
#
# 		SELECT FROM_UNIXTIME(UNIX_TIMESTAMP(),
# 			-> '%Y %D %M %h:%i:%s %x');
# 			
# 			-> '2015 13th November 10:08:01 2015'
#
# 		NOTE:
#
# 			If you use UNIX_TIMESTAMP() and FROM_UNIXTIME() to convert between TIMESTAMP values
# 			and Unix timestamp values, the conversion is lossy because the mapping is not one-to-one
# 			in both directions.
#
# 			For details, see the description of the UNIX_TIMESTAMP() function
#
# 	) GET_FORMAT({DATE|TIME|DATETIME}, {'EUR'|'USA'|'JIS'|'ISO'|'INTERNAL'})
#
# 		Returns a format string.
#
# 		This function is useful in combination with the DATE_FORMAT() and the
# 		STR_TO_DATE() functions.
#
# 		The possible values for the first and second arguments result in several
# 		possible format strings (for the specifiers used, see the table in the DATE_FORMAT()
# 		function description)
#
# 		ISO format refers to ISO 9075, not ISO 8601
#
# 		FUNCTION CALL 									RESULT
#
# 		GET_FORMAT(DATE, 'USA') 					'%m.%d.%Y'
#
# 		GET_FORMAT(DATE, 'JIS') 					'%Y-%m-%d'
#
# 		GET_FORMAT(DATE, 'ISO') 					'%Y-%m-%d'
#
# 		GET_FORMAT(DATE; 'EUR') 					'%d.%m.%Y'
#
# 		GET_FORMAT(DATE, 'INTERNAL') 				'%Y%m%d'
#
# 		GET_FORMAT(DATETIME, 'USA') 				'%Y-%m-%d %H.%i.%s'
#
# 		GET_FORMAT(DATETIME, 'JIS') 				'%Y-%m-%d %H:%i:%s'
#
# 		GET_FORMAT(DATETIME, 'ISO') 				'%Y-%m-%d %H:%i:%s'
#
# 		GET_FORMAT(DATETIME, 'EUR') 				'%Y-%m-%d %H.%i.%s'
#
# 		GET_FORMAT(DATETIME, 'INTERNAL') 		'%Y%m%d%H%i%s'
#
# 		GET_FORMAT(TIME, 'USA') 					'%h:%i:%s %p'
#
# 		GET_FORMAT(TIME, 'JIS') 					'%H:%i:%s'
#
# 		GET_FORMAT(TIME, 'ISO') 					'%H:%i:%s'
#
# 		GET_FORMAT(TIME, 'EUR') 					'%H.%i.%s'
#
# 		GET_FORMAT(TIME, 'INTERNAL') 				'%H%i%s'
#
# 		TIMESTAMP can also be used as the first argument to GET_FORMAT(),
# 		in which case the function returns the same values as for DATETIME.
#
# 			SELECT DATE_FORMAT('2003-10-03', GET_FORMAT(DATE, 'EUR'));
# 				-> '03.10.2003'
#
# 			SELECT STR_TO_DATE('10.31.2003', GET_FORMAT(DATE, 'USA'));
# 				-> '2003-10-30'
#
# 	) HOUR(time)
#
# 		Returns the hour for time.
#
# 		The range of the return value is 0 to 23 for time-of-day values.
#
# 		However, the range of TIME values actually is much larger, so HOUR can
# 		return values greater than 23.
#
# 			SELECT HOUR('10:05:03');
# 				-> 10
#
# 			SELECT HOUR('272:59:59');
# 				-> 272
#
# 	) LAST_DAY(date)
#
# 		Takes a date or datetime value and returns the corresponding value for hte last day
# 		of the month.
#
# 		Returns NULL if the argument is invalid.
#
# 			SELECT LAST_DAY('2003-02-05');
# 				-> '2003-02-28'
#
# 			SELECT LAST_DAY('2004-02-05');
# 				-> '2004-02-29'
#
# 			SELECT LAST_DAY('2004-01-01 01:01:01');
# 				-> '2004-01-31'
#
# 			SELECT LAST_DAY('2003-03-32');
# 				-> NULL
#
# 	) LOCALTIME, LOCALTIME([fsp])
#
# 		LOCALTIME and LOCALTIME() are synonyms for NOW()
#
# 	) LOCALTIMESTAMP, LOCALTIMESTAMP([fsp])
#
# 		LOCALTIMESTAMP and LOCALTIMESTAMP() are synonyms for NOW()
#
# 	) MAKEDATE(year, dayofyear)
#
# 		Returns a date, given year and day-of-year values.
#
# 		dayofyear must be greater than 0 or the result is NULL
#
# 			SELECT MAKEDATE(2011,31), MAKEDATE(2011,32);
# 				-> '2011-01-31', '2011-02-01'
#
# 			SELECT MAKEDATE(2011,365), MAKEDATE(2014,365);
# 				-> '2011-12-31', '2014-12-31'
#
# 			SELECT MAKEDATE(2011,0);
# 				-> NULL
#
# 	) MAKETIME(hour,minute,second)
#
# 		Returns a time value calculated from the hour, minute and second arguments.
#
# 		The second argument can have a fractional part.
#
# 			SELECT MAKETIME(12,15,30);
# 				-> '12:15:30'
#
# 	) MICROSECOND(expr)
#
# 		Returns the microseconds from the time or datetime expression expr as
# 		a number in the range from 0 to 999999
#
# 			SELECT MICROSECOND('12:00:00.123456');
# 				-> 123456
#
# 			SELECT MICROSECOND('2019-12-31 23:59:59.000010');
# 				-> 10
#
# 	) MINUTE(time)
#
# 		Returns the minute for time, in the range 0 to 59
#
# 			SELECT MINUTE('2008-02-03 10:05:03');
# 				-> 5
#
# 	) MONTH(date)
#
# 		Returns the month for date, in the range 1 to 12 for January ot December, or 0 for dates
# 		such as '0000-00-00' or '2008-00-00' that have a zero month part.
#
# 			SELECT MONTH('2008-02-03');
# 				-> 2
#
# 	) MONTHNAME(date)
#
# 		Returns the full name of hte month for date.
#
# 		The language used for the name is controlled by the value of the lc_time_names system
# 		variable (SECTION 10.15, "MYSQL SERVER LOCALE SUPPORT")
#
# 			SELECT MONTHNAME('2008-02-03');
# 				-> 'February'
#
# 	) NOW([fsp])
#
# 		Returns the current date and time as a value in 'YYYY-MM-DD HH:MM:SS' or YYYYMMDDHHMMSS format,
# 		depending on whether the function is used in a string or numeric context.
#
# 		The value is expressed in the current time zone.
#
# 		If hte fsp argument is given to specify a fractional seconds precision from 0 to 6,
# 		the return value includes a fractional seconds part of that many digits.
#
# 			SELECT NOW();
# 				-> '2007-12-15 23:50:26'
# 			
# 			SELECT NOW() + 0;
# 				-> 20071215235026.000000
#
# 		NOW() returns a constant time that indicates the time at which the statement began to execute.
#
# 		(Within a stored function or trigger, NOW() returns the time at which the function or trigger
# 			statement began to execute.)
#
# 		This differs from the behavior for SYSDATE(), which returns the exact time at which it executes.
#
# 			SELECT NOW(), SLEEP(2), NOW();
# 			+-----------------------------+--------------+--------------------------+
# 			| NOW() 								| SLEEP(2) 		| NOW() 							|
# 			+-----------------------------+--------------+--------------------------+
# 			| 2006-04-12 13:47:36 			| 0 				| 2006-04-12 13:47:36 		|
# 			+-----------------------------+--------------+--------------------------+
#
# 			SELECT SYSDATE(), SLEEP(2), SYSDATE();
# 			+-----------------------------+---------------+-------------------------+
# 			| SYSDATE() 					   | SLEEP(2) 		 | SYSDATE() 					|
# 			+-----------------------------+---------------+-------------------------+
# 			| 2006-04-12 13:47:44 			| 0 				 | 2006-04-12 13:47:46 	   |
# 			+-----------------------------+---------------+-------------------------+
#
# 		In addition, the SET TIMESTAMP statement affects the value returned by NOW()
# 		but not by SYSDATE().
#
# 		This means that timestamp settings in the binary log have no effect on invocations
# 		of SYSDATE()
#
# 		Setting the timestamp to a nonzero value causes each subsequent invocation of NOW()
# 		to return that value.
#
# 		Setting the timestamp to zero cancels this effect so that NOW() once again returns
# 		the current date and time.
#
# 		See the description for SYSDATE() for additional information about the differences
# 		between the two functions.
#
# 	) PERIOD_ADD(P, N)
#
# 		Adds N months to period P (in the format YYMM or YYYYMM).
#
# 		Returns a value in the format YYYYMM.
#
# 		Note that the period argument P is NOT a date value.
#
# 			SELECT PERIOD_ADD(200801, 2);
# 				-> 200803
#
# 	) PERIOD_DIFF(P1, P2)
#
# 		Returns the number of months between periods P1 and P2.
#
# 		P1 and P2 should be in the format YYMM or YYYYMM.
#
# 		Note that the period arguments P1 and P2 are NOT date values.
#
# 			SELECT PERIOD_DIFF(200802, 200703);
# 				-> 11
#
# 	) QUARTER(date)
#
# 		Returns the quarter of hte year for date, in the range 1 to 4
#
# 			SELECT QUARTER('2008-04-01');
# 				-> 2
#
# 	) SECOND(time)
#
# 		Returns the second for time, in the range 0 to 59
#
# 			SELECT SECOND('10:05:03');
# 				-> 3
#
# 	) SEC_TO_TIME(seconds)
#
# 		Returns the seconds argument, converted to hours, minutes, and seconds, as 
# 		a TIME Value.
#
# 		THe range of the result is constrained to that of the TIME data type.
#
# 		A warning occurs if the argument corresponds to a value outside that range.
#
# 			SELECT SEC_TO_TIME(2378);
# 				-> '00:39:38'
#
# 			SELECT SEC_TO_TIME(2378) + 0;
# 				-> 3938
#
# 	) STR_TO_DATE(str, format)
#
# 		This is the inverse of the DATE_FORMAT() function.
#
# 		It takes a string str and a format string format.
#
# 		STR_TO_DATE() returns a DATETIME value if the format string contains both
# 		date and time parts, or a DATE or TIME value if the string contains only date or
# 		time parts.
#
# 		If the date, time or datetime value extracted from str is illegal,
# 		STR_TO_DATE() returns NULL and produces a warning.
#
# 		The server scans str attempting to match format ot it.
#
# 		The format string can contain literal characters and format specifiers
# 		beginning with %.
#
# 		Literal characters in format must match literally in str.
#
# 		Format specifiers in format must match a date or time part in str.
#
# 		For the specifiers that can be used in format, see the DATE_FORMAT()
# 		function description.
#
# 			SELECT STR_TO_DATE('01,5,2013', '%d, %m, %Y');
# 				-> '2013-05-01'
#
# 			SELECT STR_TO_DATE('May 1, 2013', '%M %d,%Y');
# 				-> '2013-05-01'
#
# 		Scanning starts at the beginning of str and fails if format is found not to match.
#
# 		Extra characters at the end of the str are ignored.
#
# 			SELECT STR_TO_DATE('a09:30:17', 'a%h:%i:%s');
# 				-> '09:30:17'
#
# 			SELECT STR_TO_DATE('a09:30:17', '%h:%i:%s');
# 				-> NULL
#
# 			SELECT STR_TO_DATE('09:30:17a', '%h:%i:%s');
# 				-> '09:30:17'
#
# 		Unspecified date or time parts have a value of 0, so incompletely specified values
# 		in str produce a result with some or all parts set to 0:
#
# 			SELECT STR_TO_DATE('abc', 'abc');
# 				-> '0000-00-00'
#
# 			SELECT STR_TO_DATE('9', '%m');
# 				-> '0000-09-00'
#
# 			SELECT STR_TO_DATE('9', '%s');
# 				-> '00:00:09'
#
# 		Range checking on the parts of date values is as described in SECTION 11.3.1, "THE DATE, DATETIME, AND TIMESTAMP TYPES"
#
# 		This means, for example, that "zero" dates or dates with part values of 0 are permitted
# 		unless the SQL mode is set to disallow such values.
#
# 			SELECT STR_TO_DATE('00/00/0000', '%m/%d/%Y');
# 				-> '0000-00-00'
#
# 			SELECT STR_TO_DATE('04/31/2004', '%m/%d/%Y');
# 				-> '2004-04-31'
#
# 		If the NO_ZERO_DATE or NO_ZERO_IN_DATE SQL mode is enabled, zero dates or part
# 		of dates are disallowed.
#
# 		In that case, STR_TO_DATE() returns NULL and generates a warning:
#
# 			SET sql_mode = '';
# 			SELECT STR_TO_DATE('15:35:00', '%H:%i:%s');
# 			+-----------------------------------------+
# 			| STR_TO_DATE('15:35:00', '%H:%i:%s') 		|
# 			+-----------------------------------------+
# 			| 15:35:00 										   |
# 			+-----------------------------------------+
#
# 			SET sql_mode = 'NO_ZERO_IN_DATE';
# 			SELECT STR_TO_DATE('15:35:00', '%h:%i:%s');
# 			+--------------------------------------------+
# 			| STR_TO_DATE('15:35:00', '%h:%i.%s') 			|
# 			+--------------------------------------------+
# 			| NULL 													|
# 			+--------------------------------------------+
#
# 			SHOW WARNINGS\G
# 			****************************** 1. row ******************************
# 			LeveL: Warning
# 			 Code: 1411
# 			Message: Incorrect datetime value: '15:35:00' for function str_to_date
#
# 		NOTE:
#
# 			You cannot use format "%X%V" to convert a year-week string to a date because
# 			the combination of a year and week does not uniquely identify a year and month
# 			if hte week crosses a month boundary.
#
# 			To convert a year-week to a date, you should also specify the weekday:
#
# 				SELECT STR_TO_DATE('200442 Monday', '%X%V %W');
# 					-> '2004-10-18'
#
# ) SUBDATE(date, INTERVAL expr unit), SUBDATE(expr, days)
#
# 		When invoked with the INTERVAL form of the second argument, SUBDATE() is a synonym
# 		for DATE_SUB()
#
# 		For information on the INTERVAL unit argument, see the discussion for DATE_ADD()
#
# 			SELECT DATE_SUB('2008-01-02', INTERVAL 31 DAY);
# 				-> '2007-12-02'
#
# 			SELECT SUBDATE('2008-01-02', INTERVAL 31 DAY);
# 				-> '2007-12-02'
#
# 		The second form enables the use of an integer value for days.
#
# 		IN such cases, it is interpreted as the number of days ot be subtracted
# 		from the date or datetime expresison expr.
#
# 			SELECT SUBDATE('2008-01-02 12:00:00', 31);
# 				-> '2007-12-02 12:00:00'
#
# ) SUBTIME(expr1, expr2)
#
# 		SUBTIME() returns expr1 - expr2 expressed as a value in the same format as
# 		expr1.
#
# 		Expr1 is a time or datetime expression, and expr2 is a time expression.
#
# 			SELECT SUBTIME('2007-12-31 23:59:59.999999', '1 1:1:1.000002');
# 				-> '2007-12-30 22:58:58.999997'
#
# 			SELECT SUBTIME('01:00:00-999999', '02:00:00.999998');
# 				-> '-00:59:59.999999'
#
# ) SYSDATE([fsp])
#
# 		Returns the current date and time as value in 'YYYY-MM-DD HH:MM:SS' or 
# 		YYYYMMDDHHMMSS format, depending on whether the function is used in a string
# 		or numeric context.
#
# 		If the fsp argument is given to specify a fractional seconds precision from 0 to 6,
# 		the return value includes a fractional seconds part of that many digits.
#
# 		SYSDATE() returns the time at which it executes.
#
# 		This differs from the behavior for NOW(), which returns a constant time that
# 		indicates the time at which the statement began to execute.
#
# 		(Within a stored function or trigger, NOW() returns the time at which the function
# 			or triggering statement began to execute)
#
# 			SELECT NOW(), SLEEP(2), NOW();
# 			+---------------------------------+--------------------+--------------------------+
# 			| NOW() 									 | SLEEP(2) 			 | NOW() 						 |
# 			+---------------------------------+--------------------+--------------------------+
# 			| 2006-04-12 13:47:36 				 | 0 						 | 2006-04-12 13:47:36 		 |
# 			+---------------------------------+--------------------+--------------------------+
#
# 			SELECT SYSDATE(), SLEEP(2), SYSDATE();
# 			+---------------------------------+--------------------+---------------------------+
# 			| SYSDATE() 							 | SLEEP(2) 			 | SYSDATE() 					  |
# 			+---------------------------------+--------------------+---------------------------+
# 			| 2006-04-12 13:47:44 				 |  	0 					 | 2006-04-12 13:47:46 		  |
# 			+---------------------------------+--------------------+---------------------------+
#
# 		In addition, the SET TIMESTAMP statement affects the value returned by NOW() but not by SYSDATE().
#
# 		This means that timestamp settings in the binary log have no effect on invocations of SYSDATE()
#
# 		Because SYSDATE() can return different values even within the same statement, and is not affected
# 		by SET TIMESTAMP, it is nondeterministic and therefore unsafe for replication if statement
# 		based binary logging is used.
#
# 		If that is a problem, you can use row-based logging.
#
# 		Alternatively, you can use the --sysdate-is-now option to cause SYSDATE() to be an alias for NOW().
#
# 		This works if the option is used on both the master and the slave.
#
# 		The nondeterministic nature of SYSDATE() also means that indexes cannot be used for evaluating 
# 		expressions that refer to it.
#
# ) TIME(expr)
#
# 		Extracts the time part of the time or datetime expression expr and returns it as a string.
#
# 		This function is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format is set to STATEMENT.
#
# 			SELECT TIME('2003-12-31 01:02:03');
# 				-> '01:02:03'
#
# 			SELECT TIME('2003-12-31 01:02:03.000123');
# 				-> '01:02:03.000123'
#
# ) TIMEDIFF(expr1, expr2)
#
# 		TIMEDIFF() returns expr1 - expr2 expressed as a time value.
#
# 		expr1 and expr2 are time or date-and-time expressions, but both must be of the same type.
#
# 		The result returned by TIMEDIFF() is limited to the range allowed for TIME values.
#
# 		Alternatively, you can use either of the functions TIMESTAMPDIFF() and UNIX_TIMESTAMP(),
# 		both of which return integers.
#
# 			SELECT TIMEDIFF('2000:01:01 00:00:00',
# 								 '2000:01:01 00:00:00.000001');
#
# 				-> '-00:00:00.000001'
#
# 			SELECT TIMEDIFF('2008-12-31 23:59:59.000001',
# 								 '2008-12-30 01:01:01.000002');
#
# 				-> '46:58:57.999999'
#
# ) TIMESTAMP(expr), TIMESTAMP(expr1, expr2)
#
# 		With a single argument, this function returns the date or datetime expression expr
# 		as a datetime value.
#
# 		With two arguments, it adds the time expression expr2 to the date or datetime expression
# 		expr1 and returns the result as a datetime value.
#
# 			SELECT TIMESTAMP('2003-12-31');
# 				-> '2003-12-31 00:00:00'
#
# 			SELECT TIMESTAMP('2003-12-31 12:00:00', '12:00:00');
# 				-> '2004-01-01 00:00:00'
#
# ) TIMESTAMPADD(unit, interval, datetime expr)
#
# 		Adds the integer expression interval to the date or datetime expression
# 		datetime_expr.
#
# 		The unit for interval is given by the unit argument, which should be one
# 		of the following values:
#
# 			MICROSECOND (microseconds)
#
# 			SECOND
#
# 			MINUTE
#
# 			HOUR
#
# 			DAY
#
# 			WEEK
#
# 			MONTH
#
# 			QUARTER
#
# 			YEAR
#
# 		The unit value may be specified using one of keywords as shown, or with a prefix
# 		of SQL_TSI_.
#
# 		For example, DAY and SQL_TSI_DAY both are legal.
#
# 			SELECT TIMESTAMPADD(MINUTE,1,'2003-01-02');
# 				-> '2003-01-02 00:01:00'
#
# 			SELECT TIMESTAMPADD(WEEK,1,'2003-01-02');
# 				-> '2003-01-09'
#
# ) TIMESTAMPDIFF(unit, datetime expr1, datetime expr2)
#
# 	 	Returns datetime_expr2 - datetime_expr1, where datetime_expr1 and datetime_expr2 are date
# 		or datetime expressions.
#
# 		One expression may be a date and the other a datetime; a date value is treated as a datetime
# 		having the time part '00:00:00' where necessary.
#
# 		The unit for the result (an integer) is given by the unit argument.
#
# 		The legal values for unit are the same as those listed in the description
# 		of the TIMESTAMPADD() function
#
# 			SELECT TIMESTAMPDIFF(MONTH, '2003-02-01', '2003-05-01');
# 				-> 3
#
# 			SELECT TIMESTAMPDIFF(YEAR, '2002-05-01', '2001-01-01');
# 				-> -1
#
# 			SELECT TIMESTAMPDIFF(MINUTE, '2003-02-01', '2003-05-01 12:05:55');
# 				-> 128885
#
# 		NOTE:
#
# 			The order of hte date or datetime arguments for htis function is the opposite of that used
# 			with the TIMESTAMP() function when invoked with 2 arguments.
#
# ) TIME_FORMAT(time, format)
#
# 		This is used like the DATE_FORMAT() function, but the format string may contain format specifiers
# 		only for hours, minutes, seconds and microseconds.
#
# 		Other specifiers produce a NULL value or 0.
#
# 		If the time value contains an hour part that is greater than 23, the %H and %k hour format
# 		specifiers produce a value larger than the usual range of 0--23
#
# 		The other hour format specifiers produce the hour value modulo 12
#
# 			SELECT TIME_FORMAT('100:00:00', '%H %k %h %I %l');
# 				-> '100 100 04 04 4'
#
# ) TIME_TO_SEC(time)
#
# 		Returns the time argument, converted to seconds.
#
# 			SELECT TIME_TO_SEC('22:23:00');
# 				-> 80580
#
# 			SELECT TIME_TO_SEC('00:39:38');
# 				-> 2378
#
# ) TO_DAYS(date)
#
# 		Given a date date, returns a day number (the numbers of days since year 0)
#
# 			SELECT TO_DAYS(950501);
# 				-> 728779
#
# 			SELECT TO_DAYS('2007-10-07');
# 				-> 733321
#
# 		TO_DAYS() is not intended for use with values that precede the advent of the Gregorian 
# 		calendar (1582), because it does not take into account the days that were lost when the
# 		calendar was changed.
#
# 		For dates before 1582 (and possibly a later year in other locales), results from this
# 		function are not reliable.
#
# 		See SECTION 12.8, "WHAT CALENDAR IS USED BY MYSQL?" for details
#
# 		Remember that MySQL converts two-digit year values in dates to four-digit form
# 		using the rules in SECTION 11.3, "DATE AND TIME TYPES".
#
# 		For example, '2008-10-07' and '08-10-07' are seen as identical dates:
#
# 			SELECET TO_DAYS('2008-10-07'), TO_DAYS('08-10-07');
# 				-> 733687, 733687
#
# 		In MySQL, the zero date is defined as '0000-00-00', even though this date
# 		is itself considered invalid.
#
# 		This means that, for '0000-00-00' and '0000-01-01' TO_DAYS() returns the values
# 		shown here:
#
# 			SELECT TO_DAYS('0000-00-00');
# 			+----------------------------+
# 			| to_days('0000-00-00') 	  |
# 			+----------------------------+
# 			| 						NULL 		  |
# 			+----------------------------+
# 			1 row in set, 1 warning (0.00 sec)
#
# 			SHOW WARNINGS;
# 			+---------------+-----------+---------------------------------------------+
# 			| Level 			 | Code 		 | Message 												  |
# 			+---------------+-----------+---------------------------------------------+
# 			| Warning 		 | 1292 		 | Incorrect datetime value: '0000-00-00' 	  |
# 			+---------------+-----------+---------------------------------------------+
# 			1 row in set (0.00 sec)
#
# 			SELECT TO_DAYS('0000-01-01');
# 			+-----------------------------+
# 			| to_days('0000-01-01') 		|
# 			+-----------------------------+
# 			| 						1 				|
# 			+-----------------------------+
# 			1 row in set (0.00 sec)
#
# 		This is true whether or not the ALLOW_INVALID_DATES SQL server mode is enabled.
#
# 	) TO_SECONDS(expr)
#
# 		Given a date or datetime expr, returns the number of seconds since the year 0.
#
# 		If expr is not a valid date or datetime value, returns NULL.
#
# 			SELECT TO_SECONDS(950501);
# 				-> 62966505600
#
# 			SELECT TO_SECONDS('2009-11-29');
# 				-> 634266720000
#
# 			SELECT TO_SECONDS('2009-11-29 13:43:32');
# 				-> 63426721412
#
# 			SELECT TO_SECONDS( NOW() );
# 				-> 63426721458
#
# 		Like TO_DAYS(), TO_SECONDS() is not intended for use with values that precede the advent
# 		of the Gregorian calendar (1582), because it does not take into account the days that were lost
# 		when the calendar was changed.
#
# 		For dates before 1582 (and possibly a later year in other locales), results from this function
# 		are not reliable.
#
# 		See SECTION 12.8, "WHAT CALENDAR IS USED BY MYSQL?", For details.
#
# 		Like TO_DAYS(), TO_SECONDS(), converts to-digit year values in dates to four-digit form
# 		using the rules in SECTION 11.3 "DATE AND TIME TYPES"
#
# 		In MySQL, the zero date is defined as '0000-00-00', even though this date is itself considered
# 		invalid.
#
# 		This means that, for '0000-00-00' and '0000-01-01', TO_SECONDS() returns the values shown here:
#
# 			SELECT TO_SECONDS('0000-00-00');
# 			+-------------------------------+
# 			| TO_SECONDS('0000-00-00') 	  |
# 			+-------------------------------+
# 			| 						NULL 			  |
# 			+-------------------------------+
# 			1 row in set, 1 warning (0.00 sec)
#
# 			SHOW WARNINGS;
# 			+----------------+-----------+------------------------------------------+
# 			| Level 			  | Code 	  | Message 											|
# 			+----------------+-----------+------------------------------------------+
# 			| Warning 		  | 1292 	  | Incorrect datetime value: '0000-00-00' 	|
# 			+----------------+-----------+------------------------------------------+
# 			1 row in set (0.00 sec)
#
# 			SELECT TO_SECONDS('0000-01-01');
# 			+-------------------------------------+
# 			| TO_SECONDS('0000-01-01') 			  |
# 			+-------------------------------------+
# 			| 								86400 		  |
# 			+-------------------------------------+
# 			1 row in set (0.00 sec)
#
# 		This is true whether or not hte ALLOW_INVALID_DATES SQL server mode is enabled.
#
# 	) UNIX_TIMESTAMP(), UNIX_TIMESTAMP(date)
#
# 		If called with no argument, returns a Unix timestamp (seconds since '1970-01-01 00:00:00' UTC)
#
# 		The return value is an integer if no argument is given or the argument doesn ot include
# 		a fractional seconds part, or DECIMAL if an argument is given that includes a fractional seconds part.
#
# 		If UNIX_TIMESTAMP() is called with a date argument, it returns the value of the argument as
# 		seconds since '1970-01-01 00:00:00' UTC.
#
# 		The date argument may be a DATE, DATETIME, or TIMESTAMP string, or a number in YYMMDD, YYMMDDHHMMSS,
# 		YYYYMMDD, or YYYYMMDDHHMMSS format.
#
# 		If the argument includes a time part, it may optionally include a fractional seconds part.
#
# 		The server interprets date as a value in the current time zone and converts it to
# 		an internal value in UTC.
#
# 		Clients can set their time zone as described in SECTION 5.1.13, "MYSQL SERVER TIME ZONE SUPPORT"
#
# 			SELECT UNIX_TIMESTAMP();
# 				-> 1447431666
#
# 			SELECT UNIX_TIMESTAMP('2015-11-13 10:20:19');
# 				-> 1447431619
#
# 			SELECT UNIX_TIMESTAMP('2015-11-13 10:20:19.012');
# 				-> 1447431619.012
#
# 		When UNIX_TIMESTAMP() is used on a TIMESTAMP column, the function returns the internal timestamp
# 		value directly, with no implicit "string-to-Unix timestamp" conversion.
#
# 		If you pass an out-of-range date to UNIX_TIMESTAMP(), it returns 0.
#
# 		The valid range of values is the same as for the TIMESTAMP data type:
#
# 			'1970-01-01 00:00:01.000000' UTC to '2038-01-19 03:14:07.999999' UTC.
#
# 		If you use UNIX_TIMESTAMP() and FROM_UNIXTIME() to convert between TIMESTAMP values
# 		and Unix timestamp values, the conversion is lossy because the mapping is not one-to-one 
# 		in both directions.
#
# 		For example, due to conventions for local time zone changes, it is possible for two
# 		UNIX_TIMESTAMP() to map two TIMESTAMP values to the same Unix timestamp value.
#
# 		FROM_UNIXTIME() will map that value back to only one of the original TIMESTAMP values.
#
# 		Here is an example, using TIMESTAMP values in the CET time zone:
#
# 			SELECT UNIX_TIMESTAMP('2005-03-27 03:00:00');
# 			+-----------------------------------------------+
# 			| UNIX_TIMESTAMP('2005-03-27 03:00:00') 			|
# 			+-----------------------------------------------+
# 			| 								1111885200 				   |
# 			+-----------------------------------------------+
#
# 			SELECT UNIX_TIMESTAMP('2005-03-27 02:00:00'); 
# 			+-----------------------------------------------+
# 			| UNIX_TIMESTAMP('2005-03-27 02:00:00') 			|
# 			+-----------------------------------------------+
# 			| 								1111885200 					|
# 			+-----------------------------------------------+
#
# 			SELECT FROM_UNIXTIME(1111885200); 			
# 			+---------------------------------+
# 			| FROM_UNIXTIME(1111885200) 		 |
# 			+---------------------------------+
# 			| 2005-03-27 03:00:00 				 |
# 			+---------------------------------+
#
# 		If you want ot subtract UNIX_TIMESTAMP() columns, you might want to
# 		cast the result to signed integers.
#
# 		See SECTION 12.10, "CAST FUNCTIONS AND OPERATORS"
#
# ) UTC_DATE, UTC_DATE()
#
# 		Returns the current UTC date as a value in 'YYYY-MM-DD' or YYYYMMDD format,
# 		depending on whether the function is used in a string or numeric context.
#
# 			SELECT UTC_DATE(), UTC_DATE() + 0;
# 				-> '2003-08-14', 200030814
#
# ) UTC_TIME, UTC_TIME([fsp])
#
# 		Returns the current UTC time as a value in 'HH:MM:SS' or
# 		HHMMSS format, depending on whether the function is used in a string or
# 		numeric context.
#
# 		If the fsp argument is given to specify a fractional second precision from
# 		0 to 6, the return value includes a fractional seconds part of that many digits.
#
# 			SELECT UTC_TIME(), UTC_TIME() + 0;
# 				-> '18:07:53', 180753.000000
#
# ) UTC_TIMESTAMP, UTC_TIMESTAMP([fsp])
#
# 		Returns the current UTC datea nd time as avalue in 'YYYY-MM-DD HH:MM:SS' or
# 		YYYYMMDDHHMMSS format, depending on whether the function is used in a string or
# 		numeric context.
#
# 		If the fsp argument is given to specify a fractional seconds precision from
# 		0 to 6, the return value includes a fractional seconds part of that many digits.
#
# 			SELECT UTC_TIMESTAMP(), UTC_TIMESTAMP() + 0;
# 				-> '2003-08-14 18:08:04', 20030814180804.000000
#
# ) WEEK(date[,mode])
#
# 		This function returns the week number for date.
#
# 		The two-argument form of WEEK() enables you to specify whether hte week
# 		starts on Sunday or Monday and whether the return value should be in the range
# 		from 0 to 53 or from 1 to 53.
#
# 		If the mode argument is omitted, the value of the default_week_format
# 		system variable is used.
#
# 		See SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 		The following table describes how the mode argument works.
#
# 		MODE 		FIRST DAY OF WEEK 		RANGE 					WEEK 1 is the first week --
# 		
# 		0 			Sunday 						0-53 						With a Sunday in this year
#
# 		1 			Monday 						0-53 						With 4 or more days this year
#
# 		2 			Sunday 						1-53 						With a Sunday in this year
#
# 		3 			Monday 						1-53 						With 4 or more days this year
#
# 		4 			Sunday 						0-53 						With 4 or more days this year
#
# 		5  		Monday 						0-53 						With a Monday in this year
#
# 		6 			Sunday 						1-53 						With 4 or more days this year
#
# 		7 			Monday 						1-53 						with A monday inthis year
#
# 		For mode values with a meaning of "with 4 or more days this year", weeks are numbered
# 		according to ISO 8601:1988
#
# 			) If the week containing January 1 has 4 or more days inthe new year, it is week 1
#
# 			) Otherwise, it is the last week of hte previous year, and the next week is week 1
#
# 				SELECT WEEK('2008-02-20');
# 					-> 7
#
# 				SELECT WEEK('2008-02-20', 0);
# 					-> 7
#
# 				SELECT WEEK('2008-02-20', 1);
# 					-> 8
#
# 				SELECT WEEK('2008-12-31', 1);
# 					-> 53
#
# 		If a date falls in the last week of the previous year, MySQL returns 0 if you do not use 2, 3, 6 or 7 as the
# 		optional mode argument:
#
# 			SELECT YEAR('2000-01-01'), WEEK('2000-01-01', 0);
# 				-> 2000, 0
#
# 		One might argue that WEEK() should return 52 because the given date actually occurs in the
# 		52nd week of 1999.
#
# 		WEEK() returns 0 instead so that hte return value is "the week number in the given year"
#
# 		This makes use of the WEEK() function reliable when combined with other functions that
# 		extract a date part from a date.
#
# 		If you prefer a result evaluated with respect to the year that contains the first day
# 		of the week for the given date, use 0, 2, 5 or 7 as the optional mode argument.
#
# 			SELECT WEEK('2000-01-01' 2);
# 				-> 52
#
# 		Alternatively, use hte YEARWEEK() function:
#
# 			SELECT YEARWEEK('2000-01-01');
# 				-> 199952
#
# 			SELECT MID(YEARWEEK('2000-01-01'), 5, 2);
# 				-> '52'
#
# 	) WEEKDAY(date)
#
# 		Returns the weekday index for date (0 = Monday, 1 = Tuesday, --- 6 = Sunday)
#
# 			SELECT WEEKDAY('2008-02-03 22:23:00');
# 				-> 6
#
# 			SELECT WEEKDAY('2007-11-06');
# 				-> 1
#
# 	) WEEKOFYEAR(date)
#
# 		Returns the calendar week of the date as a number in the range from 1 to 53.
#
# 		WEEKOFYEAR() is a compatbility function that is equivalent to WEEK(date, 3)
#
# 			SELECT WEEKOFYEAR('2008-02-20');
# 				-> 8
#
# 	) YEAR(date)
#
# 		Returns hte year for date, in the range 1000 to 9999, or 0 for the "zero" date.
#
# 			SELECT YEAR('1987-01-01');
# 				-> 1987
#
#  ) YEARWEEK(date), YEARWEEK(date, mode)
#
# 		Returns year and week for a date.
#
# 		The year in the result may be different from the year in the date argument for the first and the last
# 		week of the year.
#
# 		The mode argument works exactly like the mode argument to WEEK()
#
# 		For the single-argument syntax, a mode value of 0 is used.
#
# 		Unlike WEEK(), the value of default_week_format does not influence YEARWEEK()
#
# 			SELECT YEARWEEK('1987-01-01');
# 				-> 198652
#
# 		The week number is different from what the WEEK() function would return (0) for optional
# 		arguments 0 or 1, as WEEK() then returns the week in the context of the given year.
#
# 12.8 WHAT CALENDAR IS USED BY MYSQL
#
# MySQL uses what is known as a proleptic Gregorian calendar.
#
# Every country that has switched from the Julian to the Gregorian calendar has had
# to discard at least ten days during the switch:
#
# To see how this works, consider the month of October 1582, when the first Julian-to-Gregorian
# swith occurred.
#
# 		MONDAY 			TUESDAY 			WEDNESDAY 		THURSDAY 		FRIDAY 		SATURDAY 		SUNDAY
# 		1 					2 					3 					4 					15 			16 				17
# 		18 				19 				20 				21 				22 			23 				24
# 		25 				26 				27 				28 				29 			30 				31
#
# There are no dates between October 4 and Ocotber 15.
#
# This discontinuity is called the Cutover.
#
# Any dates before the cutover are Julian, and any dates following the cutover are Gregorian.
#
# Dates during a cutover are nonexistent.
#
# A calendar applied to dates when it was not actually in use is called proleptic.
#
# THus, if we assume there never was a cutover and Gregorian rules always rule, we have
# a proleptic Gregorian calendar.
#
# This is what is used by MySQL, as is reuqired by standard SQL.
#
# FOr this reason, dates prior ot the cutover stored as MySQL DATE or DATETIME
# values must be adjusted to compensate for the difference.
#
# IT is important to realize that the cutover did not occur at the same itme in all
# countries.
#
# That hte later it happened, the more days were lost.
#
# FOr example, in Great Britain, it took palce in 1752, when Wednesday September 2 was followed
# by Thursday September 14
#
# Russia remained on the Julian calendar until 1918, losing 13 days in the process, and what is
# popularly refered to as its "October REvolution" occured in November according to the Gregorian
# calendar.
#
# 12.9 FULL-TEXT SEARCH FUNCTIONS
#
# 12.9.1 NATURAL LANGUAGE FULL-TEXT SEARCHES
# 12.9.2 BOOLEAN FULL-TEXT SEARCHES
# 12.9.3 FULL-TEXT SEARCHES WITH QUERY EXPANSION
#
# 12.9.4 FULL-TEXT STOPWORDS
# 12.9.5 FULL-TEXT RESTRICTIONS
# 12.9.6 FINE-TUNING MYSQL FULL-TEXT SEARCH
#
# 12.9.7 ADDING A COLLATION FOR FULL-TEXT INDEXING
# 12.9.8 NGRAM FULL-TEXT PARSER
# 12.9.9 MECAB FULL-TEXT PARSER PLUGIN
#
# MATCH_(col1,col2, ---) AGAINST (expr [search modifier])
# 
# 		search_modifier:
# 		{
# 				IN NATURAL LANGUAGE MODE
# 		 	| IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION
# 		 	| IN BOOLEAN MODE
# 		 	| WITH QUERY EXPANSION
# 		}
# 			
#
# MySQL has support for full-text indexing and searching:
#
# 		) A full-text index in MySQL is an index of type FULLTEXT
#
# 		) Full-text indexes can be used only with InnoDB or MyISAM tables, and can be 
# 			created only for CHAR, VARCHAR or TEXT columns.
#
# 		) MySQL provides a built-in full-text ngram parser that supports CHinese, Japanese and Korean
# 			(CJK), and an installable MeCab full-text parser plugin for Japanese.
#
# 			Parsing differences are outlined IN SECTION 12.9.8, "NGRAM FULL-TEXT PARSER" and
# 			SECTION 12.9.9,, "MECAB FULL-TEXT PARSER PLUGIN"
#
# 		) A FULLTEXT index definition can be given in the CREATE_TABLE statement when a table
# 			is created, or added later using ALTER_TABLE or CREATE_INDEX
#
# 		) For large data sets, it is much faster to load your data int oa table that has no FULLTEXT
# 			index and then create the index after that, than to load data into a table that has an 
# 			existing FULLTEXT index.
#
# Full-text searching is performed using MATCH()_---_AGAINST syntax
#
# MATCH() takes a comma-separated list that names the columns to be searched.
#
# AGAINST takes a string to search for, and an optional modifier that indicates
# what type of search to perform.
#
# The search string must be a string value that is constant during query evaluation.
#
# This rules out, for example, a table column because that can differ for each row.
#
# There are three types of full-text searches:
#
# 		) A natural language search interprets the search string as a phrase in natural human language (a phrase in free text)
#
# 			There are no special operators, with the exception of double quotes (") characters
#
# 			THe stopword list applies
#
# 			FOr more information about stopword lists, see SECTION 12.9.4, "FULL-TEXT STOPWORDS"
#
# 			Full-text searches are natural language searches if the IN NATURAL LANGUAGE MODE modifier
# 			is given or if no modifier is given.
#
# 			For more information, see SECTION 12.9.1, "NATURAL LANGUAGE FULL-TEXT SEARCHES"
#
# 		) A boolean search interprets the search string using the rules of a special query language.
#
# 			THe string contains the words to search for.
#
# 			IT can also contain operators that specify requirements such that a word must be present
# 			or absent in matching rows, or that it should be weighted higher or lower than usual.
#
# 			Certain common words (stopwords) are omitted from the search index and do not match if present
# 			in the search string.
#
# 			The IN BOOLEAN MODE modifier specifies a boolean search.
#
# 			For more information, see SECTION 12.9.2, "BOOLEAN FULL-TEXT SEARCHES"
#
# 		) A query expansion search is a modification of a natural language search.
#
# 			The search string is used to perform a natural language search.
#
# 			Then words from the most relevant rows returned by the search are added
# 			to the search string and the search is done again.
#
# 			The query returns the rows from the second search.
#
# 			The IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION or WITH QUERY EXPANSION modifier
# 			specifies a query expansion search.
#
# 			For more information, see SECTION 12.9.3, "FULL-TEXT SEARCHES WITH QUERY EXPANSION"
#
# For information about FULLTEXT query performance, see SECTION 8.3.5, "COLUMN INDEXES"
#
# For more information about InnoDB FULLTEXT indexes, see SECTION 15.6.2.4, "INNODB FULLTEXT INDEXES"
#
# Constraints on full-text searching are listed in SECTION 12.9.5, "FULL-TEXT RESTRICTIONS"
#
# The myisam_ftdump utility dumps the contents of a MyISAM full-text index.
#
# This may be helpful for debugging full-text queries.
#
# See SECTION 4.6.3, "myisam_ftdump -- DISPLAY FULL-TEXT INDEX INFORMATION"
#
# 12.9.1 NATURAL LANGUAGE FULL-TEXT SEARCHES
#
# By default or with the IN NATURAL LANGUAGE MODE modifier, teh MATCH() function performs
# a natural language search for a string against a text collection.
#
# A collection is a set of one or more columns included in a FULLTEXT Index.
#
# The search string is given as the argument to AGAINST()
#
# FOr each row in the table, MATCH() returns a relevance value; that is, a similarity
# measure between the search string and the text in that row in the columns named
# in the MATCH() list.
#
# 		CREATE TABLE articles (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			title VARCHAR(200),
# 			body TEXT,
# 			FULLTEXT (title, body)
# 		) ENGINE=InnoDB;
# 		Query OK, 0 rows affected (0.08 sec)
#
# 		INSERT INTO articles (title, body) VALUES
# 			('MySQL Tutorial', 'DBMS stands for DataBase --'),
# 			etc.
# 		Query OK, 6 rows affected (0.01 sec)
# 		Records: 6 Duplicates: 0 Warnings: 0
#
# 		SELECT * FROM articles
# 		WHERE MATCH (title, body)
# 		AGAINST ('database' IN NATURAL LANGUAGE MODE);
# 		+-------+------------------------------------+--------------------------------+
# 		| id 	  | title 										| body 									|
# 		+-------+------------------------------------+--------------------------------+
# 		| 1 	  | MySQL Tutorial 					| DBMS stands for DataBase ---    		|
# 		| 5 	  | MySQL vs. YourSQL 				| In the following databasecomparison 	|
# 		+-------+------------------------------+--------------------------------------+
# 		2 rows in set (0.00 sec)
#
# By default, the search is performed in case-insensitive fashion.
#
# To perform a case-sensitive full-text search, use a case-sensiive or binary collation
# for the indexed columns.
#
# For example, a column htat uses utf8mb4 char set can be assigned a collation of 
# utf8mb4_0900_as_cs or utf8mb4_bin to make it case-sensiive for full-text searches.
#
# When MATCH() is used in a WHERE clause, as in the example shown earlier, the rows returned
# are automatically sorted with the highest relevance first.
#
# Relevance values are nonnegative floating points.
#
# Zero relevance means no similarity.
#
# Relevance is computed based on the number of words in the row (document),
# the number of unique words in the row, the total number of words in the collection,
# and the number of rows that contain a particular word.
#
# NOTE:
#
# 		The term "document" may be used interchangably with the term "row", and both terms
# 		refer to the indexed part of the row.
#
# 		THe term "collection" refers to the indexed columns and ecompasses all rows.
#
# To simply count matches, you could use a query as:
#
# 		SELECT COUNT(*) FROM articles
# 		WHERE MATCH (title,body)
# 		AGAINST ('database' IN NATURAL LANGUAGE MODE);
#
# 		+---------------+
# 		| COUNT(*) 		 |
# 		+---------------+
# 		| 			2 		 |
# 		+---------------+
# 		1 row in set (0.00 sec)
#
# You might find it quicker to rewrite it as follows:
#
# 		SELECT
# 		COUNT(IF(MATCH (title,body) AGAINST ('database' IN NATURAL LANGUAGE MODE), 1, NULL))
# 		AS count
# 		FROM articles;
# 		+--------+
# 		| count 	|
# 		+--------+
# 		| 	2 		|
# 		+--------+
# 		1 row in set (0.03 sec)
#
# The first query does some extra work (Sorting the results by relevance), but also can use
# an index lookup based on the WHERE clause.
#
# The index lookup might make the first query faster if the search matches few rows.
#
# The second query performs a full table scan, which might be faster than the index
# lookup if the search term was present in most rows.
#
# For natural-language full-text searches, the columns namedin the MATCH() function must be the same
# columns included in some FULLTEXT index in your table.
#
# For hte preceding query, note that hte columns named in teh MATCH() function (title and body)
# are the same as those named in the definition of the article table's FULLTEXT index.
#
# To search the title or body separately, you would create separate FULLTEXT indexes for each column.
#
# You can also perform a boolean search or a search with query epxansion.
#
# These search types are described in SECTION 12.9.2, "BOOLEAN FULL-TEXT SEARCHES", and
# SECTION 12.9.3, "FULL-TEXT SEARCHES WITH QUERY EXPANSION"
#
# A full-text search that uses an index can name columns only from a single table in the MATCH() clause
# because an index cannot span multiple tables.
#
# For MyISAM tables, a boolean search can be done in the absence of an index (albeit more slowly),
# in which case it is possible to name columns from multiple tables.
#
# THe preceding example is a basic illustration that shows how to use the MATCH() function
# where rows are returned in order of decreasing relevance.
#
# The next example shows how to retrieve the relevance values explicitly.
#
# Returned rows are not oredered because the SELECT statement includes neither WHERE
# nor ORDER BY clauses:
#
# 		SELECT id, MATCH (title,body)
# 		AGAINST ('Tutorial' IN NATURAL LANGUAGE MODE) AS score
# 		FROM articles;
# 		+-------+---------------------------------+
# 		| id 	  | score 									|
# 		+-------+---------------------------------+
# 		| 1 	  | 0.227644- etc 						|
# 		| 2 	  | 0 										|
# 		| 3 	  | 0.227644- etc 						|
# 		| 4 	  | 0 										|
# 		| 5 	  | 0 										|
# 		| 6 	  | 0 										|
# 		+-------+---------------------------------+
# 		6 rows in set (0.00 sec)
#
# The following example is more complex.
#
# The query returns the relevance values and it also sorts the rows in order of
# decreasing relevance.
#
# To achieve this result, specify MATCH() twice: 
#
# 		Once in the SELECT list 
#
# 		Once in the WHERE clause
#
# This causes no additional overhead, because the MySQL optimizer notices
# that the two MATCH() calls are identical and invokes the full-text search
# code only once.
#
# 		SELECT id, body, MATCH (title,body) AGAINST
# 		('Security implications of running MySQL as root'
# 		IN NATURAL LANGUAGE MODE) AS score FROM articles
# 		WHERE MATCH (title,body) AGAINST ('Security implications
# 		of running MySQL as root' IN NATURAL LANGUAGE MODE);
#
# 		+-----+--------------------------------+----------------+
# 		| id 	| body 									| score 			  |
# 		+-----+--------------------------------+----------------+
# 		| 4 	| 1. Never run mysqld as root. 2.| 1.521927- etc  |
# 		| 6   | When configured properly, MySQL| 1.31-etc 		  |
# 		+-----+--------------------------------+----------------+
# 		2 rows in set (0.00 sec)
#
# A phrase that is enclosed within double quote (") characters matches only rows that
# contain the phrase literally, as it was typed.
#
# The full-text engine splits the phrase into words and performs a search in the FULLTEXT
# index for the words.
#
# Nonword characters need not be matched exactly: Phrase searching requires only that matches
#  contain exactly the same words as the phrase and in the same order.
#
# For example, "test phrase" matches "test, phrase"
#
# If the phrase contains no words that are in the index, the result is empty.
#
# For example, if all words are either stopwords or shorter than the minimum length
# of indexed words, the result is empty.
#
# The MySQL FULLTEXT implementation regards any sequence of true word characters
# (letters, digits, and underscores) as a word.
#
# That sequence may also contain apostrophes ('), but not more than one in a row.
#
# This means that aaa'bbb is regarded as one word, but aaa''bbb is regarded as
# two words.
#
# Apostrophes at the beginning or the end of the word are stripped by the FULLTEXT
# parser; 'aaa'bbb' would be parsed as aaa'bbb
#
# The built-in FULLTEXT parser determines where words start and end by looking for
# certain delimiter characters; for example, (space), , (comma) and . (period)
#
# If words are not separated by delimiters (as in, for example, Chinese), the built-in
# FULLTEXT parser cannot determine where a word begins or ends.
#
# To be able to add words or other indexed terms in such languages to a FULLTEXT index
# that uses the built-in FULLTEXT parser, you must preprocess them so that they
# are separated by some arbitrary delimiter.
#
# Alternatively, you can create FULLTEXT indexes using the ngram parser plugin
# (for Chinese, Japanese, or Korean) or the MeCab parser plugin (for Japanese)
#
# It is possible to write a plugin that replaces the built-in full-text parser.
#
# For details, see SECTION 29.2, "THE MYSQL PLUGIN API"
#
# For example parser plugin source code, see the plugin/fulltext directory
# of a MySQL source distribution.
#
# Some words are ignored in full-text searches:
#
# 		) Any word that is too short is ignored.
#
# 			The default minimum length of words that are found by full-text searches
# 			is three characters for InnoDB search indexes, or four characters for
# 			MyISAM.
#
# 			You can control the cutoff by setting a configuration option before creating
# 			the index:
#
# 				innodb_ft_min_token_size configuration option for InnoDB search indexes,
# 				or ft_min_word_len for MyISAM
#
# 			NOTE:
#
# 				This behavior does not apply to FULLTEXT indexes that use the ngram parser.
#
# 				For the ngram parser, token length is defined by the ngram_token_size option.
#
# 		) Words in the stopword list are ignored.
#
# 			A stopword is a word such as "the" or "some" that is so common that it is considered
# 			to have zero semantic value.
#
# 			There is a built-in stopword list, but it can be overridden by a user-defined list.
#
# 			The stopword lists and related configuration options are different for InnoDB search
# 			indexes and MyISAM ones.
#
# 			Stopword processing is controlled by the configuration options innodb_ft_enable_stopword,
# 			innodb_ft_server_stopword_table, and innodb_ft_user_stopword_table for InnoDB
# 			search indexes, and ft_stopword_file for MyISAM ones.
#
# See SECTION 12.9.4, "FULL-TEXT STOPWORDS" to view default stopword lists and how to change them.
#
# The default minimum word length can be changed as described in SECTION 12.9.6, "FINE-TUNING MYSQL FULL-TEXT SEARCH"
#
# Every correct word in the collection and in the query is weighted according to its significance
# in the collection or query.
#
# Thus, a word that is present in many documents has a lower weight, because it has lower semantic
# value in this particular collection.
#
# Conversely, if the word is rare, it receives a higher weight.
#
# The weights of the words are combined to compute the relevance of the row.
#
# This technique works best with large collections.
#
# 		MyISAM LIMITATION
#
# 			For very small tables, word distributions does not adequately reflect their
# 			semantic value, and this model may sometimes produce bizarre results for
# 			search indexes on MyISAM tables.
#
# 			For example, although the word "MySQL" is present in every row of the articles
# 			table shown earlier, a search for the word in a MyISAM search index produces
# 			no result:
#
# 				SELECT * FROM articles
# 					WHERE MATCH (title,body)
# 					AGAINST ('MySQL' IN NATURAL LANGUAGE MODE);
# 				Empty set (0.00 sec)
#
# 			The search result is empty because the word "MySQL" is present in at least 50%
# 			of the words, and so is effectively treated as a stopword.
#
#  		This filtering technique is more suitable for large data sets, where you might
# 			not want the result set to return every second row from a 1GB table, than for
# 			small data sets where it might cause poor results for popular terms.
#
# 			The 50% threshold can surprise you when you first try full-text searching to see
# 			how it works, and makes InnoDB tables more suited to experimentation with full-text
# 			searches.
#
# 			If you create a MyISAM table and insert only one or two rows of text into it,
# 			every word in the text occurs in at least 50% of the rows.
#
# 			As a result, no search returns any results until the table contains more rows.
#
# 			Users who need to bypass the 50% limitation can build search indexes on
# 			InnoDB tables, or use the boolean search mode explained in SECTION 12.9.2,
# 			"BOOLEAN FULL-TEXT SEARCHES"
#
# 12.9.2 BOOLEAN FULL-TEXT SEARCHES
#
# MySQL can perform boolean full-text searches using the IN BOOLEAN MODE modifier.
#
# With this modifier, certain characters have special meaning at hte beginning or end
# of words in the search string.
#
# In the following query, the + and - operators indicate that a word must be present
# or absent, respectively, for a match to occur.
#
# Thus, the query retrieves all the rows that contain the word "MySQL" but that do NOT
# contain the word "YourSQL":
#
# 		SELECT * FROM articles WHERE MATCH (title,body)
# 			AGAINST ('+MySQL -YourSQL' IN BOOLEAN MODE);
# 		+------+--------------------------------+---------------------------+
# 		| id 	 | title 								 | body 							  |
# 		+------+--------------------------------+---------------------------+
# 		| 1 	 | MySQL Tutorial 					 | DBMS stands for DataBase- |
# 		| 2 	 | How To Use MySQL Well 			 | After you went through a -|
# 		| 3 	 | Optimizing MySQL 					 | In this tutorial we will -|
# 		| 4 	 | 1001 MySQL Tricks 				 | 1. Never run mysqld as -  |
# 		| 6 	 | MySQL Security 					 | When configured properly, |
# 		+------+--------------------------------+---------------------------+
#
# 	NOTE:
#
# 		In implementing this feature, MySQL uses what is sometimes referred to
# 		as implied Boolean logic, in which:
#
# 			) + stands for AND
#
# 			) - stands for NOT
#
# 			) [no operator] implies OR
#
# Boolean full-text searches have these characteristics:
#
# 		) They do not automatically sort rows in order of decreasing relevance.
#
# 		) InnoDB tables require a FULLTEXT index on all columns of the MATCH() expression to perform
# 			boolean queries.
#
# 			Boolean queries against a MyISAM search index can work even without a FULLTEXT index,
# 			although a search executed in this fashion would be quite slow.
#
# 		) The minimum and maximum word length full-text parameters apply to FULLTEXT indexes created
# 			using the built-in FULLTEXT parser and MeCab parser plugin.
#
# 			innodb_ft_min_token_size and innodb_ft_max_token_size are used for InnoDB search indexes.
#
# 			ft_min_word_len and ft_max_word_len are used for MyISAM search indexes.
#
# 			Minimum and maximum word length full-text parameters do not apply to FULLTEXT
# 			indexes created using the ngram parser.
#
# 			ngram token size is defined by the ngram_token_size option.
#
# 		) The stopword list applies, controlled by innodb_ft_enable_stopword,
# 			innodb_ft_server_stopword_table and innodb_ft_user_stopword_table
# 			for InnoDB search indexes, and ft_stopword_file for MyISAM ones.
#
# 		) InnoDB full-text search does not support the use of multiple operators on a single
# 			search word, as in this example: '++apple'
#
# 			Use of multiple operators on a single search word returns a syntax error to standard
# 			out.
#
# 			MyISAM full-text search will successfully process the same search ignoring all operators
# 			except for the operator immediately adjacent to the search word.
#
# 		) InnoDB full-text search only supports leading plus or minus signs.
#
# 			For example, InnoDB supports '+apple' but does not support 'apple+'
#
# 			Specifying a trailing plus or minus sign causes InnoDB to report a syntax error
#
# 		) InnoDB full-text search does not support the use of a leading plus sign with wildcard
# 			('+*'), a plus and minus sign combination ('+-') or leading a plus and minus sign
# 			combinattion ('+-apple')
#
# 			These invalid queries return a syntax error
#
# 		) InnoDB full-text search does not support the use of the @ symbol in boolean full-text
# 			searches.
#
# 			The @ symbol is reserved for use by the @distance proximity search operator.
#
# 		) They do not use the 50% threshold that applies to MyISAM search indexes.
#
# 	The boolean full-text search capability supports the following operators:
#
# 		) +
#
# 			A leading or trailing plus indicates that the word MUST be present in each row that is returned.
#
# 			InnoDB only supports leading plus signs.
#
# 		) -
#
# 			A leading or trailing minus sign indicates that this word must NOT be present in any of the
# 			rows that are returned.
#
# 			InnoDB only supports leading minus signs.
#
# 			Note:
#
# 				The - operator acts only to exclude rows that are otherwise matched by other search terms.
#
# 				Thus, a boolean-mode search that contains only terms preceded by - returns an empty result.
#
# 				It does not return "all rows except those containing any of the excluded terms"
#
# 		) (no operator)
#
# 			By default (when neither + nor - is specified), the word is optional, but the rows that contain
# 			it are rated higher.
#
# 			This mimics the behavior of MATCH()_---_AGAINST() without the IN BOOLEAN MODE modifier.
#
# 		) @distance
#
# 			This operator works on InnoDB tables only.
#
# 			It tests whether two or more words all start within a specified distance from each other,
# 			measured in words.
#
# 			Specify the search words within a double-quoted string immediately before the @distance
# 			operator, for example, MATCH(col1) AGAINST('"word1 word2 word3" @8' IN BOOLEAN MODE)
#
# 		) > <
#
# 			These two operators are used to change a word's contribution to the relevance value that
# 			is assigned to a row.
#
# 			The > operator increases the contribution and the < operator decreases it.
#
# 			See the example following this list.
#
# 		) ( )
#
# 			Parantheses group words into subexpressions. Parenthesized groups can be nested.
#
# 		) ~
#
# 			A leading tilde acts as a negation operator, causing the word's contribution to the row's
# 			relevance to be negative.
#
# 			This is useful for marking "noise" words.
#
# 			A row containing such a word is rated lower than others, but is not excluded altogether,
# 			as it would be with the - operator.
#
# 		) *
#
# 			The asterisk serves as the truncation (or wildcard) operator.
#
# 			Unlike the other operators, it is appended to the word to be affected.
#
# 			Words match if they begin with the word preceding the * operator.
#
# 			If a word is specified with the truncation operator, it is not stripped from
# 			a boolean query, even if it is too short or a stopword.
#
# 			Whether a word is too short is determined from the innodb_ft_min_token_size
# 			setting for InnoDB tables, or ft_min_word_len for MyISAM tables.
#
# 			These options are not applicable to FULLTEXT indexes that use the ngram parser.
#
# 			THe wildcarded word is considered as a prefix that must be present at the
# 			start of one or more words.
#
# 			If the minimum word length is 4, a search for '+word +the*' could return fewer
# 			rows than a search for '+word +the', because the second query ignores the too-short
# 			search term the.
#
# 		) "
#
# 			A phrase that is enclosed within double quote(") characters matches only rows that
# 			contain the phrase literally, as it was typed.
#
# 			The full-text engine splits the phrase into words and performs a search in the
# 			FULLTEXT index for the words.
#
# 			Nonword characters need not be matched exactly:
#
# 				Phrase searching requires only that matches contain exactly
# 				the same words as the phrase and in the same order.
#
# 				For example, "test phrase" matches "test, phrase"
#
# 				If the phrase contains no words that are in the index, the result is empty.
#
# 				The words might not be in the index because of a combination of factors:
#
# 					If they do not exist in the text, are stopwords, or are shorter than the
# 					minimum length of indexed words.
#
# The following examples demonstrates some search strings that use boolean full-text operators:
#
# 		) 'apple banana'
#
# 				Find rows that contain at least one of the two words
#
# 		) '+apple +juice'
# 			
# 				Find rows that contain both words
#
# 		) '+apple macintosh'
#
# 				Find rows that contain the word "apple", but rank rows higher if they also contain "macintosh"
#
# 		) '+apple -macintosh'
#
# 				Find rows that contain the word "apple" but not "macintosh"
#
# 		) '+apple ~macintosh'
#
# 				Find rows that contain the word "apple", but if the row also contains the word
# 				"macintosh", rate it lower than if the row does not.
#
# 				This is "softer" than a search for "+apple -macintosh", for which the presence of
# 				"macintosh" causes the row not to be returned at all.
#
# 		) '+apple +(>turnover <strudel)'
#
# 			Find rows that contain the words "apple" and "turnover", or "apple" and "strudel" (in any order),
# 			but rank "apple turnover" higher than "apple strudel"
#
# 		) 'apple*'
#
# 			Find rows that contain words such as "apple", "apples", "applesauce" or "applet"
#
# 		) '"some words"'
#
# 			Find rows that contain the exact phrase "some words" (for example, rows that contain
# 			"some words of wisdom" but not "some noise words")
#
# 			Note that the " characters that enclose the phrase are operator characters
# 			that delimit the phrase.
#
# 			They are not the quotation marks that enclose the search string itself.
#
# RELEVANCY RANKINGS FOR INNODB BOOLEAN MODE SEARCH
#
# InnoDB full-text search is modeled on the Sphinx full-text search engine, and the
# algorithms used are based on BM25 and TF-IDF ranking algorithms.
#
# For these reasons, relevancy rankings for InnoDB boolean full-text search may differ
# from MyISAM relevancy rankings.
#
# InnoDB uses a variation of the "term frequency-inverse document frequency" (TF-IDF)
# weighting system to rank a document's relevance for a given full-text search query.
#
# The TF-IDF weighting is based on how frequently a word appears in a document, offset
# by how frequently the word appears in all documents in the collection.
#
# In other words, the more frequently a word appears in a document, and the less
# frequently the word appears in the document collection, the higher the document is ranked.
#
# HOW RELEVANCY RANKING IS CALCULATED
#
# The term frequency (TF) value is the number of times that a word appears in a document.
#
# The inverse document frequency (IDF) value of a word is calculated using the following
# formula, where total_records is the number of records in the collection, and matching_records
# is the number of records that the search term appears in.
#
# 		${IDF} = log10( ${total_records} / ${matching_records} )
#
# When a document contains a word multiple times, the IDF value is multiplied by the TF value:
#
# 		${TF} * ${IDF}
#
# Using the TF and IDF values, the relevancy ranking for a document is calculated using this formula:
#
# 		${rank} = ${TF} * ${IDF} * ${IDF}
#
# The formula is demonstrated in the following examples.
#
# RELEVANCY RANKING FOR A SINGLE WORD SEARCH
#
# This example demonstrates the relevancy ranking calculation for a single-word search.
#
# 		CREATE TABLE articles (
# 		id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 		title VARCHAR(200),
# 		body TEXT,
# 		FULLTEXT (title,body)
# 		) ENGINE=InnoDB;
# 		Query OK, 0 rows affected (1.04 sec)
#
# 		INSERT INTO articles (title,body) VALUES
# 		('MySQL Tutorial', 'This database tutorial ---'),
# 		("How To Use MySQL", 'After you went through a ---'),
# 		('Optimizing Your Database', 'In this database tutorial ---'),
# 		('MySQL vs. YourSQL', 'When comparing databases ---'),
# 		('MySQL Security', 'When configured properly, MySQL ---'),
# 		('Database, Database, Database', 'database database database'),
# 		('1001 MySQL Tricks', '1. Never run mysqld as root. 2. ---'),
# 		('MySQL Full-Text Indexes', 'MySQL fulltext indexes use a --');
# 		Query OK, 8 rows affected (0.06 sec)
# 		Records: 8 Duplicates: 0 Warnings: 0
#
# 		SELECT id, title, body, MATCH (title,body) AGAINST ('database' IN BOOLEAN MODE)
# 		AS score FROM articles ORDER BY score DESC;
# 		+--------+-------------------------------------+-------------------------------------------+-----------------------+
# 		| id 		| title 										  | body 												 | score 					 |
# 		+--------+-------------------------------------+-------------------------------------------+-----------------------+
# 		| 6 		| Database, Database, Database 		  | database database database 					 | 1.08869-- 				 |
# 		| 3 		| Optimizing Your Database 			  | In this database tutorial --- 				 | 0.362-- 					 |
# 		| 1 		| MySQL Tutorial 							  | This database tutorial -- 					 | 0.181-- 					 |
# 		| 2 		| How To Use MySQL 						  | After you went through a --- 				 | 0 							 |
# 		| 4 		| MySQL vs. YourSQL 						  | When comparing databases -- 					 | 0 							 |
# 		| 5 		| MySQL Security 							  | When configured properly, MySQL -- 		 | 0 							 |
# 		| 7 		| 1001 MySQL Tricks 						  | 1. Never run mysqld as root. 2. --- 		 | 0 							 |
# 		| 8 		| MySQL Full-Text Indexes 				  | MySQL fulltext indexes use a -- 			 | 0 							 |
# 		+--------+-------------------------------------+-------------------------------------------+-----------------------+
# 		8 rows in set (0.00 sec)
#
# There are 8 records in total, with 3 that match the "database" search term.
#
# The first record (id 6) contains the search term 6 times and has a relevancy ranking of 1.0- etc.
#
# This ranking value is calculated using a TF value of 6 (the "database" search term appears 6 times in record id 6)
# and an IDF value of 0.42-, which ias calculated as follows:
#
# 	(where 8 is the total number of records and 3 is the number of records that the search term appears in):
#
# 		${IDF} = log10( 8 / 3 ) = 0.425-etc.
#
# 	The TF and IDF values are then entered into the ranking formula:
#
# 		${rank} = ${TF} * ${IDF} * ${IDF}
#
# Performing the calculation in the MySQL command-line client returns a ranking value of 1.08- etc
#
# 		SELECT 6*log10(8/3)*log10(8/3);
# 		+--------------------------------+
# 		| 6*log10(8/3)*log10(8/3) 			|
# 		+--------------------------------+
# 		| 		1.088- etc 						|
# 		+--------------------------------+
# 		1 row in set (0.00 sec)
#
# NOTE:
#
# 		You may notice a slight difference in the ranking values returned by the SELECT_---_MATCH_---_AGAINST statement
# 		and the MySQL command line client value.
#
# 		The difference is due to how the casts between integers and floats/doubles are performed
# 		internally by InnoDB (along with related precision and rounding decisions), and how they are
# 		performed elsewhere, such as in the MySQL command-line client or other types of calculators.
#
# RELEVANCY RANKING FOR A MULTIPLE WORD SEARCH
#
# This example demonstrates the relevancy ranking calculation for a multiple-word full-text
# search based on the articles table and data used in the previous example.
#
# If you search on more than one word, the relevancy ranking value is a sum of the relevancy
# ranking value for each word, as shown in this formula:
#
# 		${rank} = ${TF} * ${IDF} * ${IDF} + ${TF} * ${IDF} * ${IDF}
#
# Performing a search on two terms ('mysql tutorial') returns the following results:
#
# 		SELECT id, title, body, MATCH (title,body) AGAINST ('mysql tutorial' IN BOOLEAN MODE)
# 		AS score FROM articles ORDER BY score DESC;
#
# 		+-------+--------------------------------+--------------------------------------+---------------------+
# 		| id 	  | title 								  | body 										  | score 					|
# 		+-------+--------------------------------+--------------------------------------+---------------------+
# 		| 1 	  | MySQL Tutorial 					  | This database tutorial --- 			  | 0.74- etc 				|
# 		| 3 	  | Optimizing Your Database 		  | In this database tutorial --- 		  | 0.36- etc 				|
# 		| 5 	  | MySQL Security 					  | When configured properly, MySQL --   | 0.031- etc 			|
# 		| 8 	  | MySQL Full-Text Indexes 		  | MySQL fulltext indexes use a -- 	  | 0.031- etc 			|
# 		| 2 	  | How To Use MySQL 				  | After you went through a --- 		  | 0.015- etc. 			|
# 		| 4 	  | MySQL vs. YourSQL 				  | When comparing databases --- 		  | 0.015- etc. 		   |
# 		| 7     | 1001 MySQL Tricks 				  | 1. never run mysqld as root. 2. --   | 0.015- etc 			|
# 		| 6 	  | Database, Database, Database   | database database database 			  | 0 						|
# 		+-------+--------------------------------+--------------------------------------+---------------------+
# 		8 rows in set (0.00 sec)
#
# In the first record (id 8), 'mysql' appears once and 'tutorial' appears twice.
#
# There are six matching records for 'mysql' and two matching records for 'tutorial'
#
# The MySQL command-line client returns the expected ranking value when inserting these values
# into the ranking formula for a multiple word search:
#
# 		SELECT (1*log10(8/6)*log10(8/6)) + (2*log10(8/2)*log10(8/2));
# 		+--------------------------------------------------------------+
# 		| (1*log10(8/6)*log10(8/6)) + (2*log10(8/2)*log10(8/2)) 		   |
# 		+--------------------------------------------------------------+
# 		| 										0.740-etc 								|
# 		+--------------------------------------------------------------+
# 		1 row in set (0.00 sec)
#
# NOTE:
#
# 		The slight difference in the ranking values returned by the SELECT_---_MATCH_---_AGAINST
# 		statement and the MySQL command-line client is explained in the preceding example.
#
# 12.9.3 FULL-TEXT SEARCHES WITH QUERY EXPANSION
#
# Full-text search supports query expansion (and in particular, its variant "blind query expansion")
#
# This is generally useful when a search phrase is too short, which often means that hte user
# is relying on implied knowledge that the full-text search engine lacks.
#
# For example, a user searching for "database" may really mean that "MySQL", "Oracle",
# "DB2", and "RDBMS" all are phrases that should match "databases" and should be returned, too.
#
# THis is implied knowledge.
#
# Blind query expansion (also known as automatic relevance feedback) is enabled by adding
# WITH QUERY EXPANSION or IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION following the search phrase.
#
# It works by performing the search twice, where the search phrase for the second search is the original
# search phrase concatenated with the few most highly relevant documents from the first search.
#
# Thus, if one of these documents contains the word "databases" and the word "MySQL";
# the second search finds the documents that contain the word "MySQL" even if they do not contain
# the word "database"
#
# The following example shows this difference:
#
# 		SELECT * FROM articles
# 		WHERE MATCH (title,body)
# 		AGAIN ('database' IN NATURAL LANGUAGE MODE);
# 		+-----+-----------------------------+-----------------------------------+
# 		| id 	| title 								| body 										|
# 		+-----+-----------------------------+-----------------------------------+
# 		| 1 	| MySQL Tutorial 					| DBMS stands for DataBase --- 	   |
# 		| 5 	| MySQL vs. YourSQL 				| In the following database comp. - |
# 		+-----+-----------------------------+-----------------------------------+
# 		2 rows in set (0.00 sec)
#
# 		SELECT * FROM articles
# 		WHERE MATCH (title,body)
# 		AGAINST ('database' WITH QUERY EXPANSION);
# 		+----+------------------------------+------------------------------------+
# 		| id | title 								| body 										 |
# 		+----+------------------------------+------------------------------------+
# 		| 5  | MySQL vs. YourSQL 				| In the following database comp --  |
# 		| 1  | MySQL Tutorial 					| DBMS stands for DataBase --- 		 |
# 		| 3  | Optimizing MySQL 				| In this tutorial we will show ---  |
# 		| 6  | MySQL Security 					| When configured properly, MySQL -- |
# 		| 2  | How To Use MySQL Well 			| After you went through a --- 		 |
# 		| 4  | 1001 MySQL Tricks 				| 1. Never run mysqld as root. 2. -- |
# 		+----+------------------------------+------------------------------------+
# 		6 rows in set (0.00 sec)
#
# Another example could be searching for books by Georges Simenon about Maigret, when one is unsure of
# how to spell "Maigret".
#
# A search for "Megre and the reluctant witnesses" finds only "Maigret and the REluctant Witnesses" without
# a query expansion.
#
# A search with query expansion finds all books with the word "Maigret" on the second pass.
#
# NOTE:
#
# 		Because blind query expansion tends to increase noise significantly by returning
# 		nonrelevant documents, use it only when a search phrase is short.
#
# 12.9.4 FULL-TEXT STOPWORDS
#
# The stopword list is loaded and searched for full-text queries using the server character set
# and collation (the values of the character_set_server and collation_server system variables)
#
# False hits or misses might occur for stopword lookups if the stopword file or columns used
# for full-text indexing or searches have a character set or collation different from character_set_server
# or collation_server
#
# Case sensitivity of stopword lookups depends on the server collation.
#
# For example, lookups are case insensitive if the collation is utf8mb4_0900_ai_ci,
# whereas lookups are case-sensitive if the collation is utf8mb4_0900_as_cs or
# utf8mb4_bin
#
# 		) Stopwords for InnoDB Search Indexes
#
# 		) Stopwords for MyISAM Search Indexes
#
# STOPWORDS FOR INNODB SEARCH INDEXES
#
# InnoDB has a relativily short list of default stopwords, because documents from technical,
# literary and other sources often use short words as keywords or in significant phrases.
#
# For example, you might search for "to be or not to be" and expect to get a sensible result,
# rather than having all those words ignored.
#
# To see the default InnoDB stopword list, query the INFORMATION_SCHEMA.INNODB_FT_DEFAULT_STOPWORD table.
#
# 		SELECT * FROM INFORMATION_SCHEMA.INNODB_FT_DEFAULT_STOPWORD;
# 		+------------+
# 		| value 		 |
# 		+------------+
# 		| a 			 |
# 		| about 	    |
# 		| an 
# 		| etc.
#
# To define your own stopword list for all InnoDB tables, define a table with the same structure
# as the INNODB_FT_DEFAULT_STOPWORD table, populate it with stopwords, and set the value of the
# innodb_ft_server_stopword_table option to a value in the form db_name/table_name before creating
# the full-text index.
#
# The stopword table must have a single VARCHAR column named value.
#
# The following example demonstrates creating and configuring a new global stopword
# table for InnoDB.
#
# --- CREATE A NEW STOPWORD TABLE
#
# CREATE TABLE my_stopwords(value VARCHAR(30)) ENGINE = INNODB;
# Query OK, 0 rows affected (0.01 sec)
#
# --- INSERT STOPWORDS (FOR SIMPLICITY, A SINGLE STOPWORD IS USED IN THIS EXAMPLE)
#
# INSERT INTO my_stopwords(value) VALUES ('Ishmael');
# Query OK, 1 row affected (0.00 sec)
#
# -- CREATE THE TABLE
# 
# CREATE TABLE opening_lines (
# id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# opening_line TEXT(500),
# author VARCHAR(200),
# title VARCHAR(200)
# ) ENGINE=InnoDB;
# Query OK, 0 rows affected (0.01 sec)
#
# --- INSERT DATA INTO THE TABLE
#
# INSERT INTO opening_lines(opening_line,author,title) VALUES
# ('Call me Ishmael.', 'Herman Melville', 'Moby-Dick'),
# ('A screaming comes across the sky.', 'Thomas Pynchon', 'Gravity\'s Rainbow'),
# ('I am an invisible man.', 'Ralph Ellison') etc.
#  Query OK, 8 rows affected (0.00 sec)
#  Records: 8 Duplicates: 0 Warnings: 0
#
# -- Set the innodb_ft_server_stopword_table option to the new stopword table
#
# SET GLOBAL innodb_ft_server_stopword_table = 'test/my_stopwords';
# Query OK, 0 rows affected (0.00 sec)
#
# -- Create the full-text index (which rebuilds the table if no FTS_DOC_ID column is defined)
# 
# CREATE FULLTEXT INDEX idx ON opening_lines(opening_line);
# Query OK, 0 rows affected, 1 warning (1.17 sec)
# Records: 0, Duplicates: 0 Warnings: 1
#
# Verify that the specified stopword ('Ishmael') does not appear by querying the
# words in INFORMATION_SCHEMA.INNODB_FT_INDEX_TABLE
#
# NOTE:
#
# 		By default, words less than 3 characters in length or greater than 84 characters
# 		in length do not appear in an InnoDB full-text search index.
#
# 		Maximum and minimum word length values are configurable using the innodb_ft_max_token_size
# 		and innodb_ft_min_token_size variables.
#
# 		This default behavior does not apply to the ngram parser plugin.
#
# 		ngram token size is defined by the ngram_token_size option.
#
# SET GLOBAL innodb_ft_aux_table='test/opening_lines';
# Query OK, 0 rows affected (0.00 sec)
#
# SELECT word FROM INFORMATION_SCHEMA.INNODB_FT_INDEX_TABLE LIMIT 15;
# +---------------------+
# | word 					|
# +---------------------+
# | across 				   |
# | all 						|
# | etc.
# 15 rows in set (0.00 sec)
#
# To create stopword lists on a table-by-table basis, create other stopword tables and use the
# innodb_ft_user_stopword_table option to specify the stopword table that you want to use
# before you create the full-text index.
#
# STOPWORDS FOR MYISAM SEARCH INDEXES
#
# The stopword file is loaded and searched using latin1 if character_set_server is ucs2, utf16, utf16le, or utf32.
#
# To override the default stopword list for MyISAM tables, set the ft_stopword_file system variable.
#
# (See SECTION 5.1.8, "SERVER SYSTEM VARIABLES")
#
# The variable value should be the path name of the file containing the stopword list, or the empty string
# to disable stopword filtering.
#
# The server looks for the file in the data directory unless an absolute path name is given to specify
# a different directory.
#
# After changing the value of this variable or the contents of the stopword file, restart the server
# and rebuild your FULLTEXT indexes.
#
# The stopword list is free-form, separating stopwords with any nonalphanumeric character such as newline,
# space, or comma.
#
# Exceptions are the underscore character (_) and a single apostrophe (') which are treated as part of a word.
#
# The character set of the stopword list is the server's default character set; see SECTION 10.3.2, "SERVER CHARACTER SET AND COLLATION"
#
# There is a list of stopwords in relation to MyISAM search indexes.
#
# In a MySQL source distrib, find it in the storage/myisam/ft_static.c file
#
# 12.9.5 FULL-TEXT RESTRICTIONS
#
# 	) Full-text searches are supported for InnoDB and MyISAM tables only
#
# 	) Full-text searches are not supported for partitioned tables. See SECTION 23.6, "RESTRICTIONS AND LIMITATIONS ON PARTITIONING"
#
# 	) Full-text searches can be used with most multibyte char sets.
#
# 		The exception is that for Unicode, the utf8 character set can be used, but not the ucs2 character set.
#
# 		Although FULLTEXT indexes on ucs2 columns cannot be used, you can perform IN BOOLEAN MODE searches
# 		on a ucs2 column that has no such index.
#
# 		The remarks for utf8 also apply to utf8mb4, and the remarks for ucs2 also apply to utf16, utf16le and
# 		utf32
#
# 	) Ideographic languages such as Chinese and Japanese do not have word delimiters.
#
# 		Therefore, the built-in full text parser CANNOT DETERMINE WHERE WORDS BEGIN AND END IN THESE AND OTHER SUCH LANGUAGES.
#
# 		A character-based ngram full-text parser that supports Chinese, Japanese, and Korean (CJK), and a word-based
# 		MeCab parser plugin that supports Japanese are provided for use with InnoDB and MyISAM tables.
#
# 	) Although the use of multiple character sets within a single table is supported, all columns in a FULLTEXT index must
# 		use the same character set and collation.
#
# 	) The MATCH() column list must match exactly the column list in some FULLTEXT index definition for the table, unless this
# 		MATCH() is IN BOOLEAN MODE on a MyISAM table.
#
# 		For MyISAM tables, boolean-mode searches can be done on nonindexed columns, although they are likely to be slow.
#
# 	) The argument to AGAINST() must be a string that is constant during query evaluation.
#
# 		This rules out, for example, a table column because that can differ for each row.
#
# 	) Index hints are more limited for FULLTEXT searches than for non-FULLTEXT searches.
#
# 		SEE SECTION 8.9.4, "INDEX HINTS"
#
# 	) For InnoDB, all DML operations (INSERT, UPDATE, DELETE) involving columns with full-text indexes are processed
# 		at transaction commit time.
#
# 		For example, for an INSERT operation, an inserted string is tokenized and is decomposed into individual words.
#
# 		The individual words are then added to full-text index tables when the transaction is committed.
#
# 		As a result, full-text searches only return committed data.
#
# 	) The '%' character is not a supported wildcard character for full-text searches
#
# 12.9.6 FINE-TUNING MYSQL FULL-TEXT SEARCH
#
# MySQL's full-text search capability has few user-tunable parameters.
#
# You can exert more control over full-text searching behavior if you have a MySQL
# source distrib because some changes require source code modifications.
#
# See SECTION 2.9, "INSTALLING MySQL FROM SOURCE"
#
# Full-text search is carefully tuned for effectiveness.
#
# Modifying the default behavior in most cases can actually decrease effectiveness.
#
# i.e, DO NOT MODIFY THE MYSQL SOURCE UNLESS YOU KNOW WHAT YOU ARE DOING
#
# Most full-text variables described in this section must be set at server startup time.
#
# A server restart is required to change them; they cannot be modified while the server is
# running.
#
# Some variable changes require that you rebuild the FULLTEXT indexes in your tables.
#
# Instructions for doing so are given later in this section.
#
# 		) Configuring Minimum and Maximum Word Length
#
# 		) Configuring the Natural Language Search Threshold
#
# 		) Modifying Boolean Full-Text Search Operators
#
# 		) Character Set Modifications
#
# 		) Rebuilding InnoDB Full-Text Indexes
#
# 		) Optimizing InnoDB Full-Text Indexes
#
# 		) Rebuilding MyISAM Full-Text Indexes
#
# CONFIGURING MINIMUM AND MAXIMUM WORD LENGTH
#
# The minimum and maximum lengths of words to be indexed are defined by the
# innodb_ft_min_token_size and innodb_ft_max_token_size for InnoDB search indexes,
# and ft_min_word_len and ft_max_word_len for MyISAM ones.
#
# NOTE:
#
# 		Minimum and maximum word length full-text parameters do not apply to FULLTEXT
# 		indexes created using the ngram parser.
#
# 		ngram token size is defined by the ngram_token_size option
#
# After changing any of these options, rebuild your FULLTEXT indexes for the change to take effect.
#
# For example, to make two-character words searchable, you could put the following lines in an option file:
#
# 		[mysqld]
# 		innodb_ft_min_token_size=2
# 		ft_min_word_len=2
#
# Then restart the server and rebuild your FULLTEXT indexes.
#
# For MyISAM tables, note the remarks regarding myisamchk in the instructions
# that follow for rebuilding MyISAM full-text indexes.
#
# CONFIGURING THE NATURAL LANGUAGE SEARCH THRESHOLD
#
# For MyISAM search indexes, the 50% threshold for natural language searches is 
# determined by the particular weighting scheme chosen.
#
# To disable it, look for the following line in storage/myisam/ftdefs.h:
#
# 		#define GWS_IN_USE GWS_PROB
#
# Change that line to:
#
# 		#define GWS_IN_USE GWS_FREQ
#
# Then recompile MySQL.
#
# There is no need to rebuild the indexes in this case.
#
# NOTE:
#
# 		By making this change, you SEVERELY decrease MySQL's capacity to provide adequate relevance 
# 		values for the MATCH() function.
#
# 		If you really need to search for such common words, it would be better to search
# 		using IN BOOLEAN MODE instead, which does not observe the 50% threshold.
#
# MODIFYING BOOLEAN FULL-TEXT SEARCH OPERATORS
#
# To change the operators used for boolean full-text searches on MyISAM tables, set the
# ft_boolean_syntax system variable.
#
# (InnoDB does not have na equivalent setting)
#
# This variable can be changed while the server is running, but you must have the privileges
# sufficient to set global system variables.
#
# (See SECTION 5.1.9.1, "SYSTEM VARIABLE PRIVILEGES")
#
# No rebuilding of indexes is necessary in this case
#
# CHARACTER SET MODIFICATIONS
#
# For the built-in full-text parser, you can change the set of characters that are considered
# word characters in several ways, as described in the following list.
#
# After making the modification, rebuild the indexes for each table that contains any 
# FULLTEXT indexes.
#
# Suppose that you want to treat the hyphen character ('-') as a word character.
#
# Use one of these methods:
#
# 		) Modify the MySQL source: In storage/innobase/handler/ha_innodb.cc (for InnoDB) or in
# 			storage/myisam/ftdefs.h (for MyISAM), see the true_word_char() and misc_word_char() macros.
#
# 			Add '-' to one of those macros and recompile MySQL
#
# 		) Modify a character set file:
#
# 			This requires no recompilation.
#
# 			The true_word_char() macro uses a "character type" table to distinguish
# 			letters and numbers from other characters.
#
# 			You can edit the contents of the <ctype><map> array in one of the character set
# 			XML files to specify that '-' is a "letter".
#
# 			Then use the given character set for your FULLTEXT indexes.
#
# 			For information about the <ctype><map> array format, see SECTION 10.12.1, "CHARACTER DEFINITIONS ARRAYS"
#
# 		) Add a new collation for the character set used by the indexed columns, and alter the columns
# 			to use that collation.
#
# 			For general information about adding collations, see SECTION 10.13, "ADDING A COLLATION TO A CHARACTER SET"
#
# 			For an example specific to full-text indexing, see SECTION 12.9.7, "ADDING A COLLATION FOR FULL_TEXT INDEXING"
#
# REBUILDING INNODB FULL-TEXT INDEXES
#
# If you modify full-text variables that affect indexing, of which are:
#
# 		innodb_ft_min_token_size
#
# 		innodb_ft_max_token_size
#
# 		innodb_ft_server_stopword_table
#
# 		innodb_ft_user_stopword_table
#
# 		innodb_ft_enable_stopword
#
# 		ngram_token_size 
#
# you must rebuild your FULLTEXT indexes after making the changes.
#
# Modifying the innodb_ft_min_token_size, innodb_ft_max_token_size or ngram_token_size variables,
# which cannot be set dynamically, require restarting the server and rebuilding the indexes.
#
# To rebuild the FULLTEXT indexes for an InnoDB table, use ALTER_TABLE with the DROP INDEX and
# ADD INDEX options to drop and re-create each index.
#
# OPTIMIZING INNODB FULL-TEXT INDEXES
#
# Running OPTIMIZE_TABLE on a table with a full-text index rebuilds the full-text index, removing
# deleted Document IDs and consolidating multiple entries for the same word, where possible.
#
# To optimize a full-text index, enable innodb_optimize_fulltext_only and run OPTIMIZE TABLE
#
# set GLOBAL innodb_optimize_fulltext_only=ON;
# Query OK, 0 rows affected (0.01 sec)
#
# OPTIMIZE TABLE opening_lines;
# +--------------------------------+---------------+------------------+-----------------+
# | Table 								  | Op 				| Msg_type 			 | Msg_text 		 |
# +--------------------------------+---------------+------------------+-----------------+
# | test.opening_lines 				  | optimize 	   | status 			 | OK 				 |
# +--------------------------------+---------------+------------------+-----------------+
# 1 row in set (0.01 sec)
#
# To avoid lengthy rebuild times for full-text indexes on large tables, you can use the innodb_ft_num_word_optimize
# option to perform the optimization in stages.
#
# The innodb_ft_num_word_optimize option defines the number of words that are optimized each
# time OPTIMIZE_TABLE is run.
#
# The default string is 2000, which means that 2000 words are optimized each time OPTIMIZE_TABLE is run.
#
# Subsequent OPTIMIZE_TABLE operations continue from where hte preceding OPTIMIZE_TABLE operation ended.
#
# REBUILDING MYISAM FULL-TEXT INDEXES
#
# If you modify full-text variables that affect indexing (ft_min_word_len, ft_max_word_len or
# ft_stopword_file) or if you change the stopword file, you must rebuild your FULLTEXT indexes
# after making the changes and restarting the server.
#
# To rebuild the FULLTEXT indexes for a MyISAM table, it is sufficient to do a QUICK
# repair operation:
#
# 		REPAIR TABLE tbl_name QUICK;
#
# Alternatively, use ALTER_TABLE as just described.
#
# In some cases, this may be faster than a repair operation.
#
# Each table that contains any FULLTEXT index must be repaired as just shown.
#
# Otherwise, queries for the table may yield incorrect results, and modifications
# to the table will cause the server to see the table as corrupt and in need of repair.
#
# If you use myisamchk to perform an operation that modifies MyISAM table indexes (such as repair or analyze),
# the FULLTEXT indexes are rebuilt using the default full-text parameter values
# for minimum word length, maximum word length, and stopword file unless you specify otherwise.
#
# This can result in queries failing.
#
# The problem occurs because these parameters are known only by the server.
#
# THey are not stored in MyISAM index files.
#
# To avoid the problem if you have modified the minimum or maximum word length
# or stopword file values used by the server, specify the same ft_min_word_len,
# ft_max_word_len and ft_stopword_file values for myisamchk that you use
# for mysqld.
#
# For example, if you have set the minimum word length to 3, you can repair a table
# with myisamchk like this:
#
# 		myisamchk --recover --ft_min_word_len=3 tbl_name.MYI
#
# To ensure that myisamchk and the server uses the same values for full-text parameters,
# place each one in both the [mysqld] and [myisamchk] sections of an option file:
#
# 		[mysqld]
# 		ft_min_word_len=3
#
# 		[myisamchk]
# 		ft_min_word_len=3
#
# An alternative to using myisamchk for MyISAM table index modificaiton is to use
# the REPAIR_TABLE, ANALYZE_TABLE, OPTIMIZE_TABLE or ALTER_TABLE statements.
#
# These statements are performed by the server, which knows the proper full-text
# parameter value to use.
#
# 12.9.7 ADDING A COLLATION FOR FULL-TEXT INDEXING
#
# This section describes how to add a new collation for full-text searches using the 
# built-in full-text parser.
#
# The sample collation is like latin1_swedish_ci but treats the '-' character
# as a letter rather than as a punctuation character so that it can be indexed
# as a word character.
#
# General information about adding collations is given in SECTION 10.13, "ADDING A COLLATION TO A CHARACTER SET";
# It is assumed that you have read it and are familiar with the files involved.
#
# To add a collation for full-text indexing, use the following procedure.
#
# The instructions here add a collation for a simple character set, which as discussed in
# SECTION 10.13, "ADDING A COLLATION TO A CHARACTER SET",  can be created using a configuration
# file that describes the character set properties.
#
# For a complex character set such as Unicode, create collations using C source files that
# describe the character set properties.
#
# 		1. Add a collation to the Index.xml file. The collation ID must be unused, so choose a value
# 			different from 1000 if that ID is already taken on your system.
#
# 				<charset name="latin1">
# 				---
# 				<collation name="latin1_fulltext_ci" id="1000"/>
# 				</charset>
#
# 		2. Declare the sort order for the collation in the latin1.xml file
#
# 			In this case, the order can be copied from latin1_swedish_ci:
#
# 				<collation name="latin1_fulltext_ci">
# 				<map>
# 				00 01 02 -> etc
# 				10 11
# 				|
# 				V
# 				</map>
# 				</collation>
#
# 		3. Modify the ctype array in latin1.xml
#
# 			Change the value corresponding to 0x2D (which is the code for the '-' character)
# 			from 10 (punctuation) to 01 (small letter) in the following array.
#
# 			This is a map with values mapping each character etc, which i won't describe in full.
#
# 			Just the general gist:
#
# 				<ctype>
# 				<map>
# 				/* The map */
# 				</map>
# 				</ctype>
#
# 		4. Restart the server
#
# 		5. To employ the new collation, include it in the definition of columns that are to use it:
#
# 				DROP TABLE IF EXISTS t1;
# 				Query OK, 0 rows affected (0.13 sec)
#
# 				CREATE TABLE t1 (
# 					a TEXT CHARACTER SET latin1 COLLATE latin1_fulltext_ci,
# 					FULLTEXT INDEX(a)
# 				) ENGINE=InnoDB;
# 				Query OK, 0 rows affected (0.47 sec)
#
# 		6. Test the collation to verify that hyphen is considered as a word character:
#
# 			INSERT INTO t1 VALUES ('----'), ('....'),('abcd');
# 			Query OK, 3 rows affected (0.22 sec)
# 			Records: 3 Duplicates: 0 Warnings: 0
#
# 			SELECT * FROM t1 WHERE MATCH a AGAINST ('----' IN BOOLEAN MODE);
# 			+---------+
# 			| a 		 |
# 			+---------+
# 			| ----    |
# 			+---------+
# 			1 row in set (0.00 sec)
#
# 12.9.8 NGRAM FULl-TEXT PARSER
#
# The built-in MySQL full-text parser uses the white space between words as a delimiter
# to determine where words begin and end, which is a limitation when working with
# ideographic languages that do not use word delimiters.
#
# To adress this limitation, MySQL provides an ngram full-text parser that supports
# Chinese, Japanese, and Korean (CJK)
#
# The ngram full-text parser is supported for use with InnoDB and MyISAM
#
# NOTE:
#
# 		MySQL also provides a MeCab full-text parser plugin for Japanese, which
# 		tokenizes documents into meaningful words.
#
# 		FOr more information, see SECTION 12.9.9, "MECAB FULL-TEXT PARSER PLUGIN"
#
# An ngram is a contiguous sequence of n chars from a given sequence of text.
#
# The ngram parser tokenizes a sequence of text into a contiguous sequence of n characters.
#
# For example, you can tokenize "abcd" for different values of n using the ngram full-text parser:
#
# 		n=1: 'a', 'b', 'c', 'd'
# 		n=2: 'ab', 'bc', 'cd'
# 		n=3: 'abc', 'bcd'
# 		n=4: 'abcd'
#
# The ngram full-text parser is a built-in server plugin.
#
# AS with other built-in server plugins, it is automatically loaded when the server is started.
#
# The full-text search syntax described in SECTION 12.9 "FULL-TEXT SEARCH FUNCTIONS" applies to
# the ngram parser plugin.
#
# Differences in parsing behavior are described in this section.
#
# Full-text-related configuration options, except for minimum and maximum word length options
# (innodb_ft_min_token_size, innodb_ft_max_token_size, ft_min_word_len, ft_max_word_len)
# are also applicable.
#
# CONFIGURING NGRAM TOKEN SIZE
#
# The ngram parser has a default ngram token size of 2 (bigram)
#
# For example, with a token size of 2, the ngram parses the string "abc def" into four
# tokens:
#
# "ab", "bc", "de" and "ef"
#
# ngram token size is configurable using the ngram_token_size configuration option,
# which has a minimum value of 1 and maximum value of 10.
#
# Typically, ngram_token_size is set to the size of the largest token that you want to search for.
#
# If you only intend to search for single characters, set ngram_token_size to 1
#
# A smaller token size produces a smaller full-text search index, and faster searches.
#
# If you need to search for words comprised of more than one character, set ngram_token_size
# accordingly.
#
# For example, "Happy Birthday" is a connotation of 2 words in Simplified Chinese, where they are
# each "Birthday" and "happy".
#
# To search on two-character words such as these, set ngram_token_size to a value of 2 or higher.
#
# AS a read-only variable, ngram_token_size may only be set as part of a startup string or
# in a configuration file:
#
# 		) Startup string:
#
# 			mysqld --ngram_token_size=2
#
# 		) Configuration file:
#
# 			[mysqld]
# 			ngram_token_size=2
#
# NOTE:
#
# 		The following minimum and maximum word length configuration options are ignored
# 		for FULLTEXT indexes that use the ngram parser:
#
# 			innodb_ft_min_token_size
#
# 			innodb_ft_max_token_size
#
# 			ft_min_word_len
#
# 			ft_max_word_len
#
# CREATING A FULLTEXT INDEX THAT USES THE NGRAM PARSER
#
# To create a FULLTEXT index that uses the ngram parser, specify WITH PARSER ngram with
# CREATE_TABLE, ALTER_TABLE or CREATE_INDEX
#
# The following example demonstrates creating a table with an ngram FULLTEXT index,
# inserting sample data (Simplified Chinese text), and viewing tokenized data in
# the INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE table.
#
# 		USE test;
#
# 		CREATE TABLE articles (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			title VARCHAR(200),
# 			body TEXT,
# 			FULLTEXT (title,body) WITH PARSER ngram
# 		) ENGINE=InnoDB CHARACTER SET utf8mb4;
#
# 		SET NAMES utf8mb4;
#
# 		INSERT INTO articles (title,body) VALUES
# 			('<chinese letters>');
#
# 		SET GLOBAL innodb_ft_aux_table="test/articles";
#
# 		SELECT * FROM INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE ORDER BY doc_id, position;
#
# To add a FULLTEXT index to an existing table, you can use ALTER_TABLE or CREATE_INDEX
#
# For example:
#
# 		CREATE TABLE articles (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			title VARCHAR(200),
# 			body TEXT
# 		) ENGINE=InnoDB CHARACTER SET utf8;
#
# 		ALTER TABLE articles ADD FULLTEXT INDEX ft_index (title,body) WITH PARSER ngram;
#
# 		# OR
#
# 		CREATE FULLTEXT INDEX ft_index ON articles (title, body) WITH PARSER ngram;
#
# NGRAM PARSER SPACE HANDLING
#
# The ngram parser eliminates spaces when parsing.
#
# for example:
#
# 		) "ab cd" is parsed to "ab", "cd"
#
# 		) "a bc" is parsed to "bc"
#
# NGRAM PARSER STOPWORD HANDLING
#
# THe built-in MySQL full-text parser compares words to entries in the stopword list.
#
# If a word is equal to an entry in the stopword list, the word is excluded from the index.
#
# For the ngram parser, stopword handling is performed differently.
#
# Instead of excluding tokens that are equal to entries in the stopword list, the ngram parser
# excludes tokens that CONTAIN stopwords.
#
# For example, assuming ngram_token_size=2, a document that contains "a,b" is parsed to "a," and ",b".
#
# If a comma (",") is defined as a stopword, both "a," and ",b" are excluded from the index
# because they contain a comma.
#
# By default, the ngram parser uses the default stopword list, which contains a list of English stopwords.
#
# For a stopword list applicable to Chinese, Japanese or Korean, you must create your own.
#
# For information about creating a stopword list, see SECTION 12.9.4, "FULL-TEXT STOPWORDS"
#
# Stopwords greater in length than ngram_token_size are ignored.
#
# NGRAM PARSER TERM SEARCH
#
# For natural language mode search, the search term is converted to a union of ngram terms.
#
# For xample, the string "abc" (assuming ngram_token_size=2) is converted to "ab bc"
#
# Given two documents, one containing "ab" and the other containing "abc", the search term
# "ab bc" matches both documents
#
# For boolean mode search, the search term is converted to an ngram phrase search.
#
# FOr example, the string 'abc' (assuming ngram_token_size=2) is converted to "ab bc"
#
# Given two documents, one containing "ab" and the other containing "abc", the search
# phrase "ab bc" only matches the document containing 'abc'
#
# NGRAM PARSER WILDCARD SEARCH
#
# Because an ngram FULLTEXT index contains only ngrams, and does not contain information
# about the beginning of terms, wildcard searches may return unexpected results.
#
# The following behaviors apply to wildcard searches using ngram FULLTEXT search indexes:
#
# 		) If the prefix term of a wildcard search is shorter than ngram token size, the query
# 			returns all indexed rows that contain ngram tokens starting with the prefix term.
#
# 			For example, assuming ngram_token_size=2, a search on "a*" retrurns all rows starting with "a"
#
# 		) If the prefix term of a wildcard search is longer than ngram token size, the prefix term is converted
# 			to an ngram phrase and the wildcard operator is ignored.
#
# 			For example, assuming ngram_token_size=2, an "abc*" wildcard search is converted to "ab bc"
#
# NGRAM PARSER PHRASE SEARCH
#
# Phrase searches are converted to ngram phrase searches.
#
# For example, the search phrase "abc" is converted to "ab bc", which returns documents
# containing "abc" and "ab bc"
#
# The search phrase "abc def" is converted to "ab bc de ef", which returns documents
# containing "abc def" and "ab bc de ef"
#
# A document that contains "abcdef" is not returned.
#
# 12.9.9 MECAB FULl-TEXT PARSER PLUGIN
#
# THe built-in MySQL full-text parser uses the white space between words as a delimiter
# to determine where words begin and end, which is a limitation when working with ideographic
# languages that do not use word delimiters.
#
# To address this limitation for Japanese, MySQL provides a MeCab full-text parser plugin.
#
# The MeCab full-text parser plugin is supported for use with InnoDB and MyISAM
#
# NOTE:
#
# 		MySQL also provides an ngram full-text parser plugin that supports Japanese.
#
# 		For more information, see SECTION 12.9.8, "NGRAM FULL-TEXT PARSER"
#
# The MeCab full-text parser plugin is a full-text parser plugin for Japanese that
# tokenizes a sequence of text into meaningful words.
#
# For example, MeCab tokenizes <Japanese Collation> "Database management" into two
# parts, "Database" and "Management".
#
# By comparison, the ngram-full-text parser tokenizes text into a contiguous sequence
# of n characters, where n is a number between 1 and 10.
#
# In addition to tokenizing text into meaningful words, MeCab indexes are typically
# smaller than ngram indexes, and MeCab full-text searches are generally faster.
#
# One drawback is that it may take longer for the MeCab full-text parser to tokenize
# documents, compared to the ngram full-text parser.
#
# The full-text search syntax described in SECTION 12.9, "FULL-TEXT SEARCH FUNCTIONS"
# applies to the MeCab parser plugin.
#
# Differences in parsing behavior are described in this section.
#
# Full-text related configuration options are also applicable.
#
# For additional information about the MeCab parser, refer to it on Github.
#
# INSTALLING THE MECAB PARSER PLUGIN
#
# The MeCab parser plugin requires mecab and mecab-ipadic
#
# On supported Fedora, Debian and Ubuntu platforms (except Ubuntu 12.04 where the system
# mecab version is too old), MySQL dynamically links so the system mecab installation if it is
# installed to the default location.
#
# On other supported Unix-like platforms, libmecab.so is statically linked in libpluginmecab.se,
# which is located in the MySQL plugin directory.
#
# mecab-ipadic is included in MySQL binaries and is located in MYSQL_HOME\lib\mecab
#
# You can install mecab and mecab-ipadic using a native package management utility 
# (on Fedora, Debian and Ubuntu), or you can build mecab and mecab-ipadic from source.
#
# For information about installing mecab and mecab-ipadic using a native package management
# utility, see INSTALLING MECAB FROM A BINARY DISTRIBUTION.
#
# If you want to build mecab and mecab-ipadic from source, see BUILDING MECAB FROM SOURCE.
#
# On Windows, libmecab.dll is found in the MySQL bin directory
#
# mecab-ipadic is located in MYSQL_HOME/lib/mecab
#
# To install and configure the MeCab parser plugin, perform the following steps:
#
# 		1. In the MySQL configuration file, set the mecab_rc_file configuration option to the location
# 			of the mecabrc configuration file, which is the configuration file for MeCab.
#
# 			If you are using the MeCab package distributed with MySQL, the mecabrc file is located
# 			in MYSQL_HOME/lib/mecab/etc/.
#
# 				[mysqld]
# 				loose-mecab-rc-file=MYSQL_HOME/lib/mecab/etc/mecabrc
#
# 			The loose prefix is an option modifier.
#
# 			The mecab_rc_file option is not recognized by MySQL until the MeCab parser plugin is
# 			installed but it must be set before attempting to install the MeCab parser plugin.
#
# 			The loose prefix allows you to restart MySQL without encountering an error due to
# 			an unrecognized variable.
#
# 			If you use your own MeCab installation, or build MeCab from source, the location
# 			of the mecabrc configuration file may differ.
#
# 			For information about hte MySQL configuration file and its location, see SECTION 4.2.7, "USING OPTION FILES"
#
# 		2. Also in the MySQL configuration file, set the minimum token size to 1 or 2, which are the
# 			values recommended for use with the MeCab parser.
#
# 			For InnoDB tables, minimum token size is defined by the innodb_ft_min_token_size configuration
# 			option, which has a default value of 3.
#
# 			For MyISAM tables, minimum token size is defined by ft_min_word_len, which has a default
# 			value of 4.
#
# 				[mysqld]
# 				innodb_ft_min_token_size=1
#
# 		3. Modify the mecabrc configuration file to specify the dictionary you want to use.
#
# 			The mecab-ipadic package distributed with MySQL binaries includes three dictionaries
# 			(ipadic_euc-jp, ipadic_sjis and ipadic_utf-8)
#
# 			The mecabrc configuration file packaged with MySQL contains and entry similar to the following:
#
# 				dicdir = /path/to/mysql/lib/mecab/lib/mecab/dic/ipadic_euc-jp
#
# 			To use the ipadic_utf-8 dictionary, for example, modify the entry as follows:
#
# 				dicdir=MYSQL_HOME/lib/mecab/dic/ipadic_utf-8
#
# 			If you are using your own MeCab installation or have  built MeCab from source, 
# 			the default dicdir entry in the mecabrc file will differ, as will the dictionaries
# 			and their location.
#
# 			NOTE:
#
# 				After the MeCab parser plugin is installed, you can use the mecab_charset
# 				status variable to view the character set used with MeCab.
#
# 				The three MeCab dictionaries provided with the MySQL binary support the following
# 				character sets.
#
# 					) The ipadic_euc-jp dictionary supports the ujis and eucjpms char sets
#
# 					) The ipadic_sjis dictionary supports the sjis and cp932 character sets
#
# 					) The ipadic_utf-8 dictionary supports the utf8 and utf8mb4 character sets
#
# 				mecab_charset only reports the first supported character set.
#
# 				For example, the ipadic_utf-8 dictionary supports both utf8 and utf8mb4
#
# 				mecab_charset always reports utf8 when this dictionary is in use
#
# 		4. Restart MySQL
#
# 		5. Install the MeCab parser plugin:
#
# 				The MeCab parser plugin is installed using INSTTALL_PLUGIN syntax.
#
# 				The plugin name is mecab, and teh shared library name is libpluginmecab.so
#
# 				For additional information about installing plugins, see SECTION 5.6.1, "INSTALLING AND UNINSTALLING PLUGINS"
#
# 					INSTALL PLUGIN mecab SONAME 'libpluginmecab.so';
#
# 				Once installed, the MeCab parser plugin loads at every normal MySQL restart.
#
# 		6. Verify that the MeCab parser plugin is loaded using the SHOW_PLUGINS statement.
#
# 			SHOW PLUGINS;
#
# 		A mecab plugin should appear in the list of plugins.
#
# CREATING A FULLTEXT INDEX THAT USES THE MECAB PARSER
#
# To create a FULLTEXT index that uses the mecab parser, specify WITH PARSER ngram with
# CREATE_TABLE, ALTER_TABLE or CREATE_INDEX
#
# This example demonstrates creating a table with a mecab FULLTEXT index, inserting
# sample data, and viewing tokenized data in the INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE table:
#
# 		USE test;
#
# 		CREATE TABLE articles (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			title VARCHAR(200),
# 			body TEXT,
# 			FULLTEXT (title,body) WITH PARSER mecab
# 		) ENGINE=InnoDB CHARACTER SET utf8;
#
# 		SET NAMES utf8;
#
# 		INSERT INTO articles (title,body) VALUES
# 			('<Letters>');
#
# 		SET GLOBAL innodb_ft_aux_table="test/articles";
#
# 		SELECT * FROM INFORMATION_SCHEMA.INNODB_FT_INDEX_CACHE ORDER BY doc_id, position;
#
# To add a FULLTEXT index to an existing table, you can use ALTER_TABLE or CREATE_INDEX.
#
# For example:
#
# 		CREATE TABLE articles (
# 			id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 			title VARCHAR(200),
# 			body TEXT
# 		) ENGINE=InnoDB CHARACTER SET utf8;
#
# 		ALTER TABLE articles ADD FULLTEXT INDEX ft_index (title, body) WITH PARSER mecab;
#
# 		# OR:
#
# 		CREATE FULLTEXT INDEX ft_index ON articles (title, body) WITH PARSER mecab;
#
# MECAB PARSER SPACE HANDLING
#
# The MeCab parser uses spaces as separators in query strings.
#
# MECAB PARSER STOPWORD HANDLING
#
# By default, the MeCab parser uses the default stopword list, which contains a short list
# of English stopwords.
#
# For a stopword list applicable to Japanese, you must create your own.
#
# For information about creating stopword lists, see SECTION 12.9.4, "FULL-TEXT STOPWORDS"
#
# MECAB PARSER TERM SEARCH
#
# For natural language mode search, the search term is converted to a union of tokens.
#
# For Boolean mode search, the search term is converted to a search phrase.
#
# MECAB PARSER WILDCARD SEARCH
#
# Wildcard search terms are not tokenized.
#
# A search on <letters>* is performed on the prefix <letters>
#
# MECAB PARSER PHRASE SEARCH
#
# Phrases are tokenized.
#
# INSTALLING MECAB FROM A BINARY DISTRIB
#
# This section describes how ot isntall mecab and mecab-ipadic from a binary distirbution using
# a native package management utility.
#
# For example, on Fedora, you can use Yum to perform the installation:
#
# 		yum mecab-devel
#
# On Debian or Ubuntu, you can perform an APT installation:
#
# 		apt-get install mecab
# 		apt-get install mecab-ipadic
#
# INSTALLING MECAB FROM SOURCE
#
# If you want to build mecab and mecab-ipadic from source, basic
# installation steps are as follows.
#
# 1. Download the tar.gz packages for mecab and mecab-ipadic 
#
# 2. Install mecab:
#
# 		tar zxfv mecab-0.996.tar
# 		cd mecab-0.996
# 		./configure
# 		make
# 		make check
# 		su
# 		make install
#
# 3. Install mecab-ipadic:
#
# 		tar zxfv mecab-ipadic-2.7.0-20070801.tar
# 		cd mecab-ipadic-2.7.0-20070801
# 		./configure
# 		make
# 		su
# 		make install
#
# 4. Compile MySQL using the WITH_MECAB CMake option.
#
# Set the WITH_MECAB option to system if you have installed mecab and
# mecab-ipadic to the default location.
#
# 		-DWITH_MECAB=system
#
# If you defined a custom installation directory, set WITH_MECAB to the
# custom direcotry.
#
# For example:
#
# 		-DWITH_MECAB=/path/to/mecab
#
# 12.10 CAST FUNCTIONS AND OPERATORS
#
# Table 12.14 Cast Functions and Operators
#
# NAME 			DESC
#
# BINARY 		Cast a string to a binary string
#
# CAST() 		Cast a value as a certain type
#
# CONVERT() 	Cast a value as a certain type
#
# Cast functions and operators enable conversion of values from one data type to another.
#
# CONVERT() with a USING clause provides a way to convert data between different
# character sets:
#
# 		CONVERT(expr USING transcoding_name)
#
# In MySQL, transcoding names are the same as the corresponding character set names.
#
# Examples:
#
# 		SELECT CONVERT(_latin1'Mller' USING utf8);
# 		INSERT INTO utf8_table (utf8_column)
# 			SELECT CONVERT(latin1_column USING utf8) FROM latin1_table;
#
# You can also use CONVERT() without USING or CAST() to convert strings
# between different character sets:
#
# 		CONVERT(string, CHAR[(N)] CHARACTER SET charset_name)
# 		CAST(string AS CHAR[(N)] CHARACTER SET charset_name)
#
# Examples:
#
# 		SELECT CONVERT('test', CHAR CHARACTER SET utf8);
# 		SELECT CAST('test' AS CHAR CHARACTER SET utf8);
#
# If you specify CHARACTER SET charset_name as just shown, the resulting character set
# and collation are charset_name and the default collation of charset_name.
#
# If you omit CHARACTER SET charset_name, the resulting character set and collation
# are defined by the character_set_connection and collation_connection system variables
# that determine the default connection character set and collation (see SECTION 10.4, "CONNECTION CHARACTER SETS AND COLLATIONS")
#
# A COLLATE clause is not permitted within a CONVERT or CAST() call, but you can
# apply it to the function result.
#
# For example, this is legal:
#
# 		SELECT CAST('test' AS CHAR CHARACTER SET utf8) COLLATE utf8_bin;
#
# But this is illegal:
#
# 		SELECT CAST('test' AS CHAR CHARACTER SET utf8 COLLATE utf8_bin);
#
# Normally, you cannot compare a BLOB value or other binary string in case-insensitive fashion
# because binary strings use the binary character set, which has no collation with the concept of lettercase.
#
# To perform a case-insensitive comparison, use the CONVERT() or CAST() function to convert the
# value to a nonbinary string.
#
# Comparisons of the resulting string use its collation.
#
# For example, if the conversion result character set has a case-insensitive
# collation, a LIKE operation is not case-sensitive:
#
# 		SELECT 'A' LIKE CONVERT(blob_col USING latin1) FROM tbl_name;
#
# To use a different character set, substitute its name for latin1 in the preceding
# statement.
#
# TO specify a particular collation for the converted string, use a COLLATE clause
# following the CONVERT() call:
#
# 		SELECT 'A' LIKE CONVERT(blob_col USING latin1) COLLATE latin1_german1_ci FROM tbl_name;
#
# CONVERT() and CAST() can be used more generally for comparing strings that are represented
# in different character sets.
#
# For example, a comparison of these strings results in an error because they have different
# character sets:
#
# 		SET @s1 = _latin1 'abc', @s2 = _latin2 'abc';
# 		SELECT @s1 = @s2;
# 		ERROR 1267 (HY000): Illegal mix of collations (latin1_swedish_ci, IMPLICIT)
# 		and (latin2_general_ci, IMPLICIT) for operation '='
#
# Converting one of the strings to a character set compatible with the other enables
# the comparison to occur without error:
#
# 		SELECT @s1 = CONVERT(@s2 USING latin1);
# 		+--------------------------------------+
# 		| @s1 = CONVERT(@s2 USING latin1) 		|
# 		+--------------------------------------+
# 		| 						1 							|
# 		+--------------------------------------+
#
# For string literals, another way to specify the character set is to use a character set
# introducer (_latin1 and _latin2 in the preceding examples are instances of introducers)
#
# Unlike conversion functions such as CAST(), or CONVERT(), which convert a string from one
# character set to another, an introducer designates a string literal as having a particular
# character set, with no conversion involved.
#
# For more information, see SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# Character set conversion is also useful preceding lettercase conversion of binary strings.
#
# LOWER() and UPPER() are ineffective when applied directly to binary strings
# because the concept of lettercase does not apply.
#
# To perform lettercase conversion of a binary string, first convert it to a nonbinary
# string:
#
# 		SET @str = BINARY "New York";
# 		SELECT LOWER(@str), LOWER(CONVERT(@str USING utf8mb4));
# 		+-------------+---------------------------------------+
# 		| LOWER(@str) | LOWER(CONVERT(@str USING utf8mb4))    |
# 		+-------------+---------------------------------------+
# 		| New York 	  | new york 										|
# 		+-------------+---------------------------------------+
#
# If you convert an indexed column using BINARY, CAST() or CONVERT(), MySQL
# may not be able to use the index efficiently.
#
# The cast functions are useful for creating a column with a specific type
# in a CREATE_TABLE_---_SELECT statement:
#
#		CREATE TABLE new_table SELECT CAST('2000-01-01' AS DATE) AS c1;
# 		SHOW CREATE TABLE new_table\G
# 		***************************** 1. row **************************
# 				Table: new_table
# 	  Create Table: CREATE TABLE `new_table` (
# 		 `c1` date DEFAULT NULL
# 	  ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4
#
# The cast functions are useful for sorting ENUM columns in lexical order.
#
# Normally, sorting of ENUM columns occurs using the internal numeric values.
#
# Casting the values to CHAR results in a lexical sort:
#
# 		SELECT enum_col FROM tbl_name ORDER BY CAST(enum_col AS CHAR);
#
# CAST() also changes the result if you use it as part of a more complex expression such as
# CONCAT('Date: ',CAST(NOW() AS DATE))
#
# For temporal values, there is little need to use CAST() to extract data in different formats.
#
# Instead, use a function such as EXTRACT(), DATE_FORMAT(), or TIME_FORMAT()
#
# See SECTION 12.7, "DATE AND TIME FUNCTIONS"
#
# To cast a string to a number, you normally need do nothing other than use
# the string value in numeric context:
#
# 		SELECT 1+'1';
# 			-> 2
#
# That is also true for hexadecimal and bit literals, which are binary strings
# by default:
#
# 		SELECT X'41', X'41'+0;
# 			-> 'A', 65
#
# 		SELECT b'1100001', b'110000'+0;
# 			-> 'a', 97
#
# A string used in an arithmetic operation is converted to a floating-point number
# during expression evaluation.
#
# A number used in string context is converted to a string:
#
# 		SELECT CONCAT('hello you ',2);
# 			-> 'hello you 2'
#
# For information about implicit conversion of numbers to strings, see SECTION 12.2, "TYPE CONVERSION IN EXPRESSION EVALUATION"
#
# MySQL supports arithmetic with both signed and unsigned 64-bit values.
#
# For numeric operators (such as + or -) where one of the operands is an unsigned integer,
# the result is unsigned by default (see SECTION 12.6.1, "ARITHMETIC OPERATORS")
#
# To override this, use the SIGNED or UNSIGNED cast operator to cast a value
# to a signed or unsigned 64-bit integer, respectively.
#
# SELECT 1 - 2;
# 		-> -1
#
# SELECT CAST(1 - 2 AS UNSIGNED);
# 		-> <a lot>
#
# SELECT CAST(CAST(1 - 2 AS UNSIGNED) AS SIGNED);
# 		-> 1
#
# If either operand is a floating-point value, the result is a floating-point value and is
# not affected by the preceding rule 
#
# (in this context, DECIMAL column values are regarded as floating-point values)
#
# 		SELECT CAST(1 AS UNSIGNED) - 2.0;
# 			-> -1.0
#
# The SQL mode affects the result of conversion operations (see SECTION 5.1.11, "SERVER SQL MODES").
#
# Examples:
#
# 		) For conversion of a "zero" date string to a date, CONVERT() and CAST() return NULL
# 			and produce a warning when the NO_ZERO_DATE SQL mode is enabled.
#
# 		) For integer subtraction, if the NO_UNSIGNED_SUBTRACTION SQL mode is enabled,
# 			the subtraction result is signed even if any operand is unsigned.
#
# The following list describes the available cast functions and operators:
#
# 		) BINARY expr
#
# 			The BINARY operator converts the expression to a binary string.
#
# 			A common use for BINARY is to force a character string comparison to be done
# 			byte by byte rather than char by char, in effect becoming case-sensitive.
#
# 			The BINARY operator also causes trailing spaces in comparisons to be significant.
#
# 				SELECT 'a' = 'A';
# 					-> 1
#
# 				SELECT BINARY 'a' = 'A';
# 					-> 0
#
# 				SELECT 'a' = 'a ';
# 					-> 1
#
# 				SELECT BINARY 'a' = 'a ';
# 					-> 0
#
# 			In a comparison, BINARY affects the entire operation; it can be given before either operand with the same result.
#
# 			For purposes of converting a string expression to a bianry string, these constructs are equivalent:
#
# 				BINARY expr
# 				CAST(expr AS BINARY)
# 				CONVERT(expr USING BINARY)
#
# 			If a value is a string literal, it can be designated as a binary string
# 			without performing any conversion by using the _binary character set introducer:
#
# 				SELECT 'a' = 'A';
# 					-> 1
#
# 				SELECT _binary 'a' = 'A';
# 					-> 0
#
# 			For information about introducers, see SECTION 10.3.8, "CHARACTER SET INTRODUCERS"
#
# 			The BINARY operator in expressions differs in effect from the BINARY attribute in character
# 			column definitions.
#
# 			A character column defined with the BINARY attribute is assigned table default
# 			character set and the binary (_bin) collation of that character set.
#
# 			Every nonbinary character set has a _bin collation
#
# 			For example, the binary collation for the utf8_character set is utf8_bin,
# 			so if the table default char set is utf8, these two column defs are equivalent:
#
# 				CHAR(10) BINARY
# 				CHAR(10) CHARACTER SET utf8 COLLATE utf8_bin
#
# 			The use of CHARACTER SET binary in the definition of a CHAR, VARCHAR or TEXT column
# 			causes the column to be treated as the corresponding binary string data type.
#
# 			For example, the following pairs of definitions are equivalent:
#
# 				CHAR(10) CHARACTER SET binary
# 				BINARY(10)
#
# 				VARCHAR(10) CHARACTER SET binary
# 				VARBINARY(10)
#
# 				TEXT CHARACTER SET binary
# 				BLOB
#
#		) CAST(expr AS type)
#
# 			The CAST() function takes an expression of any type and produces a result value
# 			of the specified type, similar to CONVERT()
#
# 			For more information, see the description of CONVERT()
#
# 			CAST() is standard SQL syntax
#
# 		) CONVERT(expr, type), CONVERT(expr USING transcoding name)
#
# 			The CONVERT() function takes an expression of any type and produces a result
# 			value of the specified type.
#
# 			Discussion of CONVERT(expr, type) syntax here also applies to CAST(expr AS type),
# 			which is equivalent.
#
# 			CONVERT(---_USING_---) is standard SQL syntax.
#
# 			The non-USING form of CONVERT() is ODBC syntax.
#
# 			CONVERT() with USING converts data between different char sets.
#
# 			In MySQL, transcoding namesa re the same as the corresponding character
# 			set names.
#
# 			For example, this statement converts the string 'abc' in the default character
# 			set to the corresponding string in the utf8 character set:
#
# 				SELECT CONVERT('abc' USING utf8);
#
# 			CONVERT() without USING and CAST() take an expression and a type value specifying
# 			the result type.
#
# 			These type values are permitted:
#
# 				) BINARY[(N)]
#
# 					Produces a string with the BINARY data type.
#
# 					See SECTION 11.4.2, "THE BINARY AND VARBINARY TYPES" for a description
# 					of how this affects comparisons.
#
# 					If the optional length N is given, BINARY(N) causes the cast to use no more than N
# 					bytes of the argument.
#
# 					Values shorter than N bytes are padded with 0x00 bytes to a length of N.
#
# 				) CHAR[(N)] [charset_info]
#
# 					Produces a string with the CHAR data type.
#
# 					If the optional length N is given, CHAR(N) causes the cast to use no more than
# 					N characters of the argument.
#
# 					No padding occurs for values shorter than N characters.
#
# 					With no charset_info clause, CHAR produces a string with the default character set.
#
# 					To specify the character set explicitly, these charset_info values are permitted:
#
# 						) CHARACTER SET charset_name: Produces a string with the given character set
#
# 						) ASCII: Shorthand for CHARACTER SET latin1
#
# 						) UNICODE: Shorthand for CHARACTER SET ucs2
#
# 					In all cases, the string has the default collation for the character set
#
# 				) DATE
#
# 					Produces a DATE value
#
# 				) DATETIME
#
# 					Produces a DATETIME value
#
# 				) DECIMAL[(M[,D])]
#
# 					Produces a DECIMAL value.
#
# 					If the optional M and D values are given, they specify the maximum number of
# 					digits (the precision) and the number of digits following the decimal point (the scale)
#
# 				) JSON
#
# 					Produces a JSON value.
#
# 					For details on the rules for conversion of values between JSON and other types,
# 					see COMPARISON AND ORDERING OF JSON VALUES
#
# 				) NCHAR[(N)]
#
# 					Like CHAR, but produces a string with the national character set.
#
# 					see SECTION 10.3.7, "THE NATIONAL CHARACTER SET"
#
# 					Unlike CHAR, NCHAR does not permit trailing character set
# 					information to be specified.
#
# 				) SIGNED [INTEGER]
#
# 					Produces a signed integer value
#
# 				) TIME
#
# 					Produces a TIME value
#
# 				) UNSIGNED [INTEGER]
#
# 					Produces an unsigned integer value
#
# 12.11 XML FUNCTIONS
#
# Table 12.15 XML FUNCTIONS
#
# 		Name 					Description
#
# 	ExtractValue() 		Extracts a value from an XML string using XPath notation
#
# 	UpdateXML() 			Return replaced XML fragment
#
# 	This section discusses XML and related functionality in MySQL.
#
# 	NOTE:
#
# 		It is possible to obtain XML formatted output from MySQL in the mysql and
# 		mysqldump clients by invoking them with the --xml option.
#
# 		See SECTION 4.5.1, "MYSQL - THE MYSQL COMMAND-LINE CLIENT", and SECTION 4.5.4, "MYSQLDUMP - A DATABASE BACKUP PROGRAM"
#
# Two functions providing basic XPath 1.0 (XML Path Language, version 1.0) capabilities are available.
#
# Some basic information about XPath syntax and usage is provided later in this section;
# however, an in-depth discussion of these topics is beyond the scope of this manual, and you should
# refer to the XML PATH LANGUAGE (XPATH) 1.0 STANDARD for more info.
#
# A useful resource for those new to XPath or who desire a refresher in the basics, resources exist.
#
# NOTE:
#
# 		These functions remain under development.
#
# 		We continue to improve these and other aspects of XML and XPath functionality
# 		in MySQL 8.0 and onwards.
#
# XPath expressions used with these functions support user variables and local stored program
# variables.
#
# User variables are weakly checked; variables local to stored programs are strongly checked (see also BUG #26518):
#
# 		) USER VARIABLES (WEAK CHECKING)
#
# 			Variables using the syntax $@variable_name (that is, user variables) are not checked.
#
# 			No warnings or errors are issued by the server if a variable has the wrong type
# 			or has previously not been assigned a value.
#
# 			This also means the user is fully responsible for any typographical errors,
# 			since no warnings will be given if (for example) $@myvariable is used where
# 			$@myvariable was intended.
#
# 			Example:
#
# 				SET @xml = '<a><b>X</b><b>Y</b></a>';
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SET @i =1, @j = 2;
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SELECT @i, ExtractValue(@xml, '//b[$@i]');
# 				+---------+------------------------------------+
# 				| @i 		 | ExtractValue(@xml, '//b[$@i]') 	  |
# 				+---------+------------------------------------+
# 				| 1 		 | X 											  |
# 				+---------+------------------------------------+
# 				1 row in set (0.00 sec)
#
# 				SELECT @j, ExtractValue(@xml, '//b[$@j]');
# 				+---------+------------------------------------+
# 				| @j 		 | ExtractValue(@xml, '//b[$@j]') 	  |
# 				+---------+------------------------------------+
# 				| 2 		 | Y 											  |
# 				+---------+------------------------------------+
# 				1 row in set (0.00 sec) 
#
# 				SELECT @k, ExtractValue(@xml, '//b[$@k]'); 	
# 				+---------+------------------------------------+
# 				| @k 	    | ExtractValue(@xml, '//b[$@k]') 	  |
# 				+---------+------------------------------------+
# 				| NULL 	 | 											  |
# 				+---------+------------------------------------+
# 				1 row in set (0.00 sec)
#
# 		) VARIABLES IN STORED PROGRAMS (STRONG CHECKING)
#
# 			Variables using the syntax $variable_name can be declared
# 			and used with these functions when they are called inside stored programs.
#
# 			Such variables are local to the stored program in which they are defined,
# 			and are strongly checked for type and value.
#
# 			Example:
#
# 				DELIMITER |
#
# 				CREATE PROCEDURE myproc ()
# 				BEGIN
# 					DECLARE i INT DEFAULT 1;
# 					DECLARE xml VARCHAR(25) DEFAULT '<a>X</a><a>Y</a><a>Z</a>';
# 
# 					WHILE i < 4 DO
# 						SELECT xml, i, ExtractValue(xml, '//a[$i]');
# 						SET i = i+1;
# 					END WHILE;
# 				END |
# 			Query OK, 0 rows affected (0.01 sec)
#
# 			DELIMITER ;
#
# 			CALL myproc();
# 			+-----------------------------------+--------+-------------------------------+
# 			| xml 									   | i 	   | ExtractValue(xml, '//a[$i]')  |
# 			+-----------------------------------+--------+-------------------------------+
# 			| <a>X</a><a>Y</a><a>Z</a> 			| 1 		| X 									  |
# 			+-----------------------------------+--------+-------------------------------+
# 			1 row in set (0.00 sec)
#
# 			+-----------------------------------+--------+-------------------------------+
# 			| xml 										| i 	   | ExtractValue(xml, '//a[$i]')  |
# 			+-----------------------------------+--------+-------------------------------+
# 			| <a>X</a><a>Y</a><a>Z</a> 			| 2 		| Y 									  |
# 			+-----------------------------------+--------+-------------------------------+
# 			1 row in set (0.01 sec)
#
# 			+-----------------------------------+--------+-------------------------------+
# 			| xml 										| i 		| ExtractValue(xml, '//a[$i]')  |
# 			+-----------------------------------+--------+-------------------------------+
# 			| <a>X</a><a>Y</a><a>Z</a> 			| 3 		| Z 									  |
# 			+-----------------------------------+--------+-------------------------------+
# 			1 row in set (0.01 sec) 
#
# 		Parameters. Variables used in XPath expressions inside stored routines that are passed in
# 		as parameters are also subject to strong checking.
#
# Expressions containing user variables or variables local to stored programs must otherwise
# (except for notation) conform to the rules for XPath expressions containing variables as given
# in the XPath 1.0 specification.
#
# NOTE:
#
# 		A user variable used to stored an XPath expression is treated as an empty string.
#
# 		Because of this, it is not possible to store an XPath expression as a user variable.
# 		(Bug #32911)
#
# 	) ExtractValue(xml frag, xpath expr)
#
# 		ExtractValue() takes two string arguments,a fragment of XML markup xml_frag
# 		and an XPath expression xpath_expr (also known as a locator);
#
# 		It returns the text (CDATA) of the first text node which is a child of the element
# 		or elements matched by the XPath expression.
#
# 		Using this function is equivalent of performing a match using the xpath_expr
# 		after appending /text().
#
# 		In other words, 
#
# 			ExtractValue('<a><b>Sakila</b></a>', '/a/b')
#
# 			And
#
# 			ExtractValue('<a><b>Sakila</b></a>', '/a/b text()') 
#
# 		produce the same result.
#
# 		If multiple matches are found, the content of the first child text node of each matching
# 		element is returned (in the order matched) as a single, space-delimited string.
#
# 		If no matching text node is found for the expression (including the implicit /text()) -
# 		for whatever reason, as long as xpath_expr is valid and xml_frag consists of elements
# 		which are properly nested and closed - an empty string is returned.
#
# 		No distinction is made between a match on an empty element and no match at all.
#
# 		This is by design.
#
# 		If you need to determine whether no matching element was found in xml_frag or such
# 		an element was found but contained no child text nodes, you should test the result
# 		of an expression that uses the XPath count() function.
#
# 		For example, both of these statements return an empty string, as shown here:
#
# 			SELECT ExtractValue('<a><b/></a>', '/a/b');
# 			+-------------------------------------------+
# 			| ExtractValue('<a><b/></a>', '/a/b') 		  |
# 			+-------------------------------------------+
# 			| 														  |
# 			+-------------------------------------------+
# 			1 row in set (0.00 sec)
#
# 			SELECT ExtractValue('<a><c/></a>', '/a/b');
# 			+-------------------------------------------+
# 			| ExtractValue('<a><c/></a>', '/a/b') 		  |
# 			+-------------------------------------------+
# 			|  													  |
# 			+-------------------------------------------+
# 			1 row in set (0.00 sec)
#
# However, you can determine whether there was actually a matching element
# using the following:
#
# 			SELECT ExtractValue('<a><b/></a>', 'count(/a/b)');
# 			+-------------------------------------------------+
# 			| ExtractValue('<a><b/></a>', 'count(/a/b)') 	  |
# 			+-------------------------------------------------+
# 			| 1 															  |
# 			+-------------------------------------------------+
# 			1 row in set (0.00 sec)
#
# 			SELECT ExtractValue('<a><c/></a>', 'count(/a/b)');
# 			+-------------------------------------------------+
# 			| ExtractValue('<a><c/></a>', 'count(/a/b)') 	  |
# 			+-------------------------------------------------+
# 			| 0 															  |
# 			+-------------------------------------------------+
# 			1 row in set (0.01 sec)
#
# IMPORTANT:
#
# 		ExtractValue() returns only CDATA, and does not return any tags that might be contained
# 		within a matching tag, nor any of their content (see the result returned as val1 in the following example)
#
# 		SELECT
# 			ExtractValue('<a>ccc<b>ddd</b></a>', '/a') AS val1,
# 			ExtractValue('<a>ccc<b>ddd</b></a>', '/a/b') AS val2,
# 			ExtractValue('<a>ccc<b>ddd</b></a>', '//b') AS val3,
# 			ExtractValue('<a>ccc<b>ddd</b><b>eee</b></a>', '//b') AS val5;
#
# 		+-------+--------+---------+---------+-----------+
# 		| val1  | val2   | val3 	| val4 	 | val5 	    |
# 		+-------+--------+---------+---------+-----------+
# 		| ccc   | ddd    | ddd     |         | ddd eee   |
# 		+-------+--------+---------+---------+-----------+
#
# This function uses the current SQL collation for making comparisons with contains(), performing
# the same collation aggregation as other string functions (such as CONCAT()), in taking into account
# the collation coercibility of their arguments;
#
# See SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS", for an explanation of the rules
# governing this behavior.
#
# (Previously, binary - that is, case sensitive - comparing was always used)
#
# NULL is returned if xml_frag contains elements which are not properly nested or closed,
# and a warning is generated, as shown in this example:
#
# 		SELECT ExtractValue('<a>c</a><b', '//a');
# 		+------------------------------------------+
# 		| ExtractValue('<a>c</a><b', '//a') 		 |
# 		+------------------------------------------+
# 		| NULL 												 |
# 		+------------------------------------------+
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		*********************** 1. row ***********************
# 			Level: Warning
# 			 Code: 1525
# 		Message : Incorrect XML value: 'parse error at line 1 pos 11:
# 					 END-OF-INPUT unexpected ('>' wanted)'
# 		1 row in set (0.00 sec)
#
# 		SELECT ExtractValue('<a>c</a><b/>', '//a');
# 		+-------------------------------------------+
# 		| ExtractValue('<a>c</a><b/>', '//a') 		  |
# 		+-------------------------------------------+
# 		| c 													  |
# 		+-------------------------------------------+
# 		1 row in set (0.00 sec)
#
# ) UpdateXML(xml target, xpath expr, new xml)
#
# 		This function replaces a single portion of a given fragment of XML markup
# 		xml_target with a new XML fragment new_xml, and then returns the changed XML.
#
# 		The portion of xml_target that is replaced matches an XPath expression xpath_expr
# 		supplied by the user.
#
# 		If no expression matching xpath_expr is found, or if multiple matches are found,
# 		the function returns the original xml_target XML fragment.
#
# 		All three arguments should be strings.
#
# 			SELECT
# 				UpdateXML('<a><b>ccc</b><d></d></a>', '/a', '<e>fff</e>') AS val1,
#
# 				UpdateXML('<a><b>ccc</b><d></d></a>', '/b', '<e>fff</e>') AS val2,
#
# 				UpdateXML('<a><b>ccc</b><d></d></a>', '//b', '<e>fff</e>') AS val3,
#
# 				UpdateXML('<a><b>ccc</b><d></d></a>', '/a/d', '<e>fff</e>') AS val4,
#
# 				UpdateXML('<a><d></d><b>ccc</b><d></d></a>', '/a/d', '<e>fff</e>') AS val5
# 			\G
#
# 		**************************** 1. row ******************************
# 		val1: <e>fff</e>
#
# 		val2: <a><b>ccc</b><d></d></a>
#
# 		val3: <a><e>fff</e><d></d></a>
#
# 		val4: <a><b>ccc</b><e>fff</e></a>
#
# 		val5: <a><d></d><b>ccc</b><d></d></a>
#
# NOTE:
#
# 		A discussion in depth of XPath syntax and usage are beyond the scope of this manual.
#
# 		Please see the XML Path Language (XPath) 1.0 specification for definitive information.
#
# 		A useful resource for those new to XPath or who are wishing a refresher in the basics,
# 		see external resources.
#
# Descriptions and examples of some basic XPath expressions follow:
#
# 		) /tag
#
# 			Matches <tag/> if and only if <tag/> is the root element
#
# 			Example: /a has a match in <a><b/></a> because it matches the outermost (root) tag.
#
# 						It does not match the inner a element in <b><a/></b> because in this instance
# 						it is the child of another element.
#
# 		) /tag1/tag2
#
# 			Matches <tag2/> if and only if it is a child of <tag1/>, and <tag1/> is the root element.
#
# 			Example:
#
# 					/a/b matches the b element in the XML fragment <a><b/></a> because it is a child of the root element
# 					a.
#
# 					It does not have a match in <b><a/></b> because in this case, b is the root element
# 					(and hence the child of no other element)
#
# 					Not does the XPath expression have a match in <a><c><b/></c></a>;
#
# 					Here, b is a descendant of a, but not actually a child of a.
#
# 					This construct is extendable to three or more elements.
#
# 					For example, the XPath expression /a/b/c matches the c element
# 					in the fragment <a><b><c/></b></a>
#
# 		) //tag
#
# 			Matches any instance of <tag>
#
# 			Example: //a matches the a element in any of the following:
#
# 				<a><b><c/></b></a>; <c><a><b/></a></b>; <c><b><a/></b></c>
#
# 			// can be combined with /
#
# 			For example, //a/b matches the b element in either of the fragments:
#
# 				<a><b/></a>
#
# 				or
#
# 				<c><a><b/></a></c>
#
# 			NOTE:
#
# 				//tag is the equivalent of /descendant-or-self::*/tag
#
# 				A common error is to confuse this with /descendant-or-self::tag,,
# 				although the later expression can actually lead to very different results,
# 				as can be seen here:
#
# 					SET @xml = '<a><b><c>w</c><b>x</b><d>y</d>z</b></a>';
# 					Query OK, 0 rows affected (0.00 sec)
#
# 					SELECT @xml;
# 					+---------------------------------------------------+
# 					| @xml 															 |
# 					+---------------------------------------------------+
# 				   | <a><b><c>w</c><b>x</b><d>y</d>z</b></a> 			 |
# 					+---------------------------------------------------+
# 					1 row in set (0.00 sec)
#
# 					SELECT ExtractValue(@xml, '//b[1]');
# 					+---------------------------------------------------+
# 					| ExtractValue(@xml, '//b[1]') 							 |
# 					+---------------------------------------------------+
# 					| x z 															 |
# 					+---------------------------------------------------+
# 					1 row in set (0.00 sec)
#
# 					SELECT ExtractValue(@xml, '//b[2]'); 	
# 					+---------------------------------+
# 					| ExtractValue(@xml, '//b[2]') 	 |
# 					+---------------------------------+
# 					|											 |
# 					+---------------------------------+
# 					1 row in set (0.01 sec)
#
# 					SELECT ExtractValue(@xml, '/descendant-or-self::*/b[1]');
# 					+-------------------------------------------------------+
# 					| ExtractValue(@xml, '/descendant-or-self::*/b[1]') 	  |
# 					+-------------------------------------------------------+
# 					| x z 																  |
# 					+-------------------------------------------------------+
# 					1 row in set (0.06 sec)
#
# 					SELECT ExtractValue(@xml, '/descendant-or-self::*/b[2]');
# 					+-------------------------------------------------------+
# 					| ExtractValue(@xml, '/descendant-or-self::*/b[2]') 	  |
# 					+-------------------------------------------------------+
# 					| 																		  |
# 					+-------------------------------------------------------+
# 					1 row in set (0.00 sec)
#
# 					SELECT ExtractValue(@xml, '/descendant-or-self::b[1]');
# 					+-------------------------------------------------------+
# 					| ExtractValue(@xml, '/descendant-or-self::b[1]') 		  |
# 					+-------------------------------------------------------+
# 					| z 																	  |
# 					+-------------------------------------------------------+
# 					1 row in set (0.00 sec)
#
# 					SELECT ExtractValue(@xml, '/descendant-or-self::b[2]');
# 					+-------------------------------------------------------+
# 					| ExtractValue(@xml, '/descendant-or-self::b[2]') 		  |
# 					+-------------------------------------------------------+
# 					| x 																	  |
# 					+-------------------------------------------------------+
# 					1 row in set (0.00 sec)
#
# ) The * operator acts as a "wildcard" that matches any element.
#
# 		For example, the expression /*/b matches the b element in either of the
# 		XML fragments <a><b/></a> or <c><b/></c>
#
# 		However, the expression does not produce a match in the fragment <b><a/></b>
# 		because b must be a child of some other element.
#
# 		The wildcard may be used in any position:
#
# 			The expression /*/b/* will match any child of a b element that
# 			is itself not the root element.
#
# ) You can match any of several locators using the | (UNION) operator.
#
# 		For example, the expression //b|//c matches all b and c elements in the XML target.
#
# ) It is also possible to match an element based on the value of one or more of its attributes.
#
# 		This is done using the syntax tag[@attribute="value"]
#
# 		For example, the expression:
#
# 		//b[@id="idB"] 
#
# 			matches the second b element in the fragment
# 		
# 		<a><b id="idA"/><c/><b id="idB"/></a>
#
# 		To match against any element having:
#
# 		attribute="value" 
#
# 			use the XPath expression
# 		
# 		//*[attribute="value"]
#
# 		To filter multiple attribute values, simply use multiple attribute-comparison clauses
# 		in succession.
#
# 		For example, the expression:
#
# 			 //b[@c="x"][@d="y"] 
# 		
# 		matches the element
#
# 			<b c="x" d="y"/>
#
# 		occuring anywhere in a given XML fragment.
#
# 		To find elements for which the same attribute matches any of several values, you can use
# 		multiple locators joined by the | operator.
#
# 		For example, to match all b elements whose c attributes have either of the values 23 or 17,
# 		use the expression:
#
# 			//b[@c="23"]|//b[@c="17"]
#
# 		You can also use the logical or operator for this purpose:
#
# 			//b[@c="23" or @c="17"]
#
# 		NOTE:
#
# 			The difference between or and | is that or joins conditions,
# 			while | joins result sets.
#
# XPATH LIMITATIONS.
#
# The XPath syntax supported by these functions is currently subject to the
# following limitations:
#
# 		) Nodeset-to-nodeset comparison (such as '/a/b[@c=@d]') is not supported
#
# 		) All of the standard XPath comparison operators are supported. (Bug #22823)
#
# 		) Relative locator expressions are resolved in the context of the root node.
#
# 			For example, consider the following query and result:
#
# 				SELECT ExtractValue(
# 					'<a><b c="1">X</b><b c="2">Y</b></a>',
# 					'a/b'
# 				) AS result;
#
# 				+-------------------------+
# 				| result 					  |
# 				+-------------------------+
# 				| X Y 						  |
# 				+-------------------------+
# 				1 row in set (0.03 sec)
#
# 			In this case, the locator a/b resolves to /a/b
#
# 			Relative locators are also supported within predicates.
#
# 			In the following example, d[--/@c="1"] is resolved as /a/b[@c="1"]/d:
#
# 				SELECT ExtractValue(
# 					'<a>
# 					  <b c="1"><d>X</d></b>
# 					  <b c="2"><d>X</d></b>
# 					</a>'
# 					'a/b/d[--/@c="1"]')
# 				AS result;
#
# 				+------------------+
# 				| result 			 |
# 				+------------------+
# 				| X 					 |
# 				+------------------+
# 				1 row in set (0.00 sec)
#
# 		) Locators prefixed with expressions that evaluate as scalar values -
#
# 			including variable references, literals, numbers, and scalar function
# 			calls - are not permitted, and their use results in an error.
#
# 		) The :: operator is not supported in combination with node types such as the following:
#
# 			) axis::comment()
#
# 			) axis::text()
#
# 			) axis::processing-instructions()
#
# 			) axis:node()
#
# 			However, name tests (such as axis::name and axis::*) are supported,
# 			as shown in these examples:
#
# 				SELECT ExtractValue('<a><b>x</b><c>y</c></a>', '/a/child::b');
# 				+-----------------------------------------------------------+
# 				| ExtractValue('<a><b>x</b><c>y</c></a>', '/a/child::b')    |
# 				+-----------------------------------------------------------+
# 				| x 																			|
# 				+-----------------------------------------------------------+
# 				1 row in set (0.02 sec)
#
# 				SELECT ExtractValue('<a><b>x</b><c>y</c></a>', '/a/child::*');
# 				+-----------------------------------------------------------+
# 				| ExtractValue('<a><b>x</b><c>y</c></a>', '/a/child::*') 	|
# 				+-----------------------------------------------------------+
# 				| x y 																	   |
# 				+-----------------------------------------------------------+
# 				1 row in set (0.01 sec)
#
# 	) "Up-and-down" navigation is not supported in cases where the path would lead "above" the root element.
#
# 		That is, you cannot use expressions which match on descendants of ancestors of a given element,
# 		where one or more of the ancestors of the current element is also an ancestor of the root element
#
# 		(See BUG #16321)
#
# 	) The following XPath functions are not supported, or have known issues as indicated:
#
# 		) id()
#
# 		) lang()
#
# 		) local-name()
#
# 		) name()
#
# 		) namespace-uri()
#
# 		) normalize-space()
#
# 		) starts-with()
#
# 		) string()
#
# 		) substring-after()
#
# 		) substring-before()
#
# 		) translate()
#
# 	) The following axes are not supported:
#
# 		) following-sibling
#
# 		) following
#
# 		) preceding-sibling
#
# 		) preceding
#
# XPath expressions passed as arguments to ExtractValue() and UpdateXML() may contain the colon character
# (:) in element selectors, which enables their use with markup employing XML namespaces notation.
#
# For example:
#
# 		SET @xml = '<a>111<b:c>222<d>333</d><e:f>444</e:f></b:c></a>';
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT ExtractValue(@xml, '//e:f');
# 		+----------------------------------+
# 		| ExtractValue(@xml, '//e:f') 	  |
# 		+----------------------------------+
# 		| 444 									  |
# 		+----------------------------------+
# 		1 row in set (0.00 sec)
#
# 		SELECT UpdateXML(@xml, '//b:c', '<g:h>555</g:h>');
# 		+--------------------------------------------+
# 		| UpdateXML(@xml, '//b:c', '<g:h>555</g:h>') |
#		+--------------------------------------------+
# 		| <a>111<g:h>555</g:h></a> 						|
# 		+--------------------------------------------+
# 		1 row in set (0.00 sec)
#
# This is similar in some respects to what is permitted by Apache Xalan and some other parsers,
# and is much simpler than requiring namespace declarations or the use of namespace-uri() and
# local-name() functions.
#
# ERROR HANDLING
#
# For both ExtractValue() and UpdateXML(), the XPath locator used must be valid
# and the XML to be searched must consist of elements which are properly
# nested and closed.
#
# If the locator is invalid, an error is generated:
#
# 		SELECT ExtractValue('<a>c</a><b/>', '/&a');
# 		ERROR 1105 (HY000): XPath syntax error: '&a'
#
# If xml_frag does not consist of elements which are properly nested
# and closed, NULL is returned and a warning is generated, as shown in this example:
#
# 		SELECT ExtractValue('<a>c</a><b', '//a');
# 		+------------------------------------------+
# 		| ExtractValue('<a>c</a><b', '//a') 		 |
# 		+------------------------------------------+
# 		| NULL 												 |
# 		+------------------------------------------+
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		****************************** 1. row **************************
# 			Level: Warning
# 			 Code: 1525
# 		 Message: Incorrect XML value: 'parse error at line 1 pos 11:
# 					 END-OF-INPUT unexpected ('>' wanted)'
# 		 1 row in set (0.00 sec)
#
# 		SELECT ExtractValue('<a>c</a><b/>', '//a');
# 		+-------------------------------------------+
# 		| ExtractValue('<a>c</a><b/>', '//a') 		  |
# 		+-------------------------------------------+
# 		| c 													  |
# 		+-------------------------------------------+
# 		1 row in set (0.00 sec)
#
# IMPORTANT:
#
# 		The replacement XML used as the third argument to UpdateXML() is NOT checked
# 		to determine whether it consists solely of elements which are properly nested
# 		and closed.
#
# XPATH INJECTION
#
# Code injection occurs when malicious code is introduced into the system to gain unauthorized
# access to privileges and data.
#
# It is based on exploiting assumptions made by developers about the type and content of
# data input from users.
#
# XPath is no exception in this regard.
#
# A common scenario in which this can happen is the case of application which handles
# authorization by matching the combination of a login name and a PW with those found 
# in an XML file, using an XPath expression like this one:
#
# 		//user[login/text()='neapolitan' and password/text()='1c3cr34m']/attribute::id
#
# This is the XPath equivalent of an SQL statement like this one:
#
# 		SELECT id FROM users WHERE login='neapolitan' AND password'1c3cr34m';
#
# <?php
#
# 		$file = "users.xml";
#
# 		$login = $POST["login"];
# 		$password = $POST["password"];
#
# 		$xpath = "//user[login/text()=$login and password/text()=$password]/attribute::id";
#
# 		if( file_exists($file))
# 		{
# 			$xml = simplexml_load_file($file);
#
# 			if($result = $xml->xpath($xpath))
# 				echo "You are now logged in as $result[0].";
# 			else
# 				echo "Invalid login name or password.";
# 		}
# 		else
# 			exit("Failed to open $file.");
# ?>
#
# No checks are performed on the input.
#
# This means that a malevolent user can "short-circuit" the test by entering ' or 1=1
# for both the login name and password, resulting in $xpath being evaluated as shown here:
#
# 		//user[login/text()='' or 1=1 and password/text()='' or 1=1]/attribute::id
#
# Since the expression inside the square brackets always evaluate as true, it is effectively
# the same as this one, which matches the id attribute of every user element in the XML
# document:
#
# 		//user/attribute::id
#
# One way to circumvent this is simply by quoting the variable names to be interpolated
# in the definitoon of $xpath, forcing the values passed from a web form to be converted to strings:
#
# 		$xpath = "//user[login/text()='$login' and password/text()='$password']/attribute::id";
#
# This is the same strategy that is often recommended for preventing SQL injection attacks.
#
# In general, the practices you should follow for preventing XPath injection attacks are the
# same as for preventing SQL injections:
#
# 		) Never accept untested data from users in your app
#
# 		) Check all user-submitted data for type; reject or convert the data that is of the wrong type
#
# 		) Test numeric data for out of range values;
#
# 			Truncate, round, or reject values that are out of range.
#
# 			Test strings for illegal characters and either strip them out or reject
# 			input containing them.
#
# 		) Do not output explicit error messages that might provide an unauthorized user
# 			which clues that could be used to compromise the system;
#
# 			Log these to a file or database table instead
#
# Just as an SQL injection attack can be used to obtain information about DB schemas,
# so can XPath injection be used to traverse XML files to uncover their structure,
# as discussed in external sources.
#
# It is also important to check the output being sent back to the client.
#
# Consider what can happen when we use the MySQL ExtractValue() function:
#
# 		SELECT ExtractValue(
# 			LOAD_FILE('users.xml'),
# 			'//user[login/text()="" or 1=1 and password=text()="" or 1=1]/attribute::id'
# 		) AS id;
# 		+-------------------------------------+
# 		| id 											  |
# 		+-------------------------------------+
# 		| 00327 13579 02403 42354 28570 		  |
# 		+-------------------------------------+
# 		1 row in set (0.01 sec)
#
# Because ExtractValue() returns multiple matches as a single space-delimited string,
# this injection attack provides every valid ID contained within users.xml to the user
# as a single row of output.
#
# As an extra safeguard(), you should also test output before returning it
# to the user.
#
# Here is a simple example:
#
# 		SELECT @id = ExtractValue(
# 			LOAD_FILE('users.xml'),
# 			'//user[login/text()="" or 1=1 and password/text()="" or 1=1]/attribute::id'
# 		);
# 		Query OK, 0 rows affected (0.00 sec)
#
# 		SELECT IF(
# 				INSTR(@id, ' ') = 0,
# 				@id,
# 				'Unable to retrieve user ID')
# 		AS singleID;
# 	
# +-------------------------------------+
# | SingleID 									 |
# +-------------------------------------+
# | Unable to retrieve user ID 			 |
# +-------------------------------------+
# 1 row in set (0.00 sec)
#
# In general, the guidelines for returning data to users securely are the same as
# for accepting user input.
#
# These can be summed up as:
#
# 		) Always test outgoing data for type and permissible values.
#
# 		) Never permit unauthorized users to view error messages that might provide information
# 			about the application that could be used to exploit it.
#
# 12.12 BIT FUNCTIONS AND OPERATORS
#
# TABLE 12.16 BIT FUNCTIONS AND OPERATORS
#
# NAME 				DESC
#
# BIT_COUNT() 		Return the number of bits that are set
#
# & 					Bitwise AND
#
# ~ 					Bitwise inversion
#
# | 					Bitwise OR
#
# ^	 				Bitwise XOR
#
# << 					Left shift
#
# >> 					Right shift
#
# Bit functions and operators comprise:
#
# 		BIT_COUNT()
#
# 		BIT_AND()
#
# 		BIT_OR()
#
# 		BIT_XOR()
#
# 		&
#
# 		|
#
# 		^
#
# 		~
#
# 		<<
#
# 		>>
#
# (The BIT_AND(), BIT_OR() and BIT_XOR() aggregate functions are described in the
# SECTION 12.20.1, "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS")
#
# Prior to MySQL 8.0, bit functions and operators required BIGINT (64-bit integer)
# arguments and returned BIGINT values, so they had a maximum range of 64 bits.
#
# Non-BIGINT arguments were converted to BIGINT prior to performing the operation
# and truncation could occur.
#
# In MySQL 8.0, bit functions and operators permit binary string type arguments
# (BINARY, VARBINARY, and the BLOB types) and a value of like type, which enables them
# to take arguments and produce return values larger than 64 bits.
#
# Nonbinary string arguments are converted to BIGINT and processed as such, as before.
#
# AN implication of this change in behavior is that bit operations on binary string
# arguments might produce a different result in MySQL 8.0 than in 5.7
#
# For information about how to prepare MySQL 5.7 for potentional incompatibilities
# between 5.7 and 8.0, see BIT FUNCTIONS AND OPERATORS in the 5.7 version
#
# 		) BIT OPERATIONS PRIOR TO MYSQL 8.0
#
# 		) BIT OPERATIONS IN MYSQL 8.0
#
# 		) BINARY STRING BIT-OPERATION EXAMPLES
#
# 		) BITWISE AND, OR, AND XOR OPERATIONS
#
# 		) BITWISE COMPLEMENT AND SHIFT OPERATIONS
#
# 		) BIT_COUNT() OPERATIONS
#
# 		) BIT_AND(), BIT_OR() AND BIT_XOR() OPERATIONS
#
# 		) SPECIAL HANDLING OF HEXADECIMAL LITERALS, BIT LITERALS, AND NULL LITERALS
#
# 		) BIT-OPERATION INCOMPATIBILITIES WITH MYSQL 5.7
#
# BIT OPERATIONS PRIOR TO MYSQL 8.0
#
# Bit operations prior to MySQL 8.0 handle only unsigned 64-bit integer argument
# and result values (that is, unsigned BIGINT values)
#
# Conversion of arguments of other types to BIGINT occurs as necessary.
#
# Examples:
#
# 		) This statement operates on numeric literals, treated as unsigned 64-bit integers:
#
# 			SELECT 127 | 128, 128 << 2, BIT_COUNT(15);
# 			+------------+---------------+--------------------+
# 			| 127 | 128  | 128 << 2 	  | BIT_COUNT(15) 	  |
# 			+------------+---------------+--------------------+
# 			| 		255 	 | 512 			  |  	4 					  |
# 			+------------+---------------+--------------------+
#
# 		) This staetment performs to-number conversions on the string arguments ('127' to 127 and so forth)
# 			before performing the same operations as the first statement and producing the same results:
#
# 				SELECT '127' | '128', '128' << 2, BIT_COUNT('15');
# 				+--------------+-----------------+-------------------+
# 				| '127' | '128'| '128' << 2 		| BIT_COUNT('15')   |
# 				+--------------+-----------------+-------------------+
# 				| 			255 	| 		512 			| 		4 				  |
# 				+--------------+-----------------+-------------------+
#
# 		) This statement uses hexadecimal literals for the bit-operation arguments.
#
# 			MySQL by default treats hexadecimal literals as binary strings, but in numeric
# 			context evaluates them as numbers (see SECTION 9.1.4, "HEXADECIMAL LITERALS")
#
# 			Prior to 8.0, numeric context includes bit operations.
#
# 			Examples:
#
# 				SELECT X'7F' | X'80', X'80' << 2, BIT_COUNT(X'0F');
# 				+-----------------+---------------+---------------------+
# 				| X'7F' | X'80'   | X'80' << 2    | BIT_COUNT(X'0F') 	  |
# 				+-----------------+---------------+---------------------+
# 				| 			255 		| 		512 		 | 		4 				  |
# 				+-----------------+---------------+---------------------+
#
# 			Handling of bit-value literals in bit operations is similar to hexadecimal
# 			literals (that is, as numbers)
#
# BIT OPERATIONS IN MYSQL 8.0
#
# MySQL 8.0 extends bit operations to handle binary string arguments directly (without conversion)
# and produce binary string results.
#
# (Arguments that are not integers or binary strings are still converted to integers, as before)
#
# This extension enhances bit operations in the following ways:
#
# 		) Bit operations become possible on values longer than 64-bits
#
# 		) It is easier to perform bit operations on values that are more naturally represented
# 			as binary strings than as integers.
#
# For example, consider UUID values and IPv6 addresses, which have human-readable text formats like
# this:
#
# 		UUID: 6ccd780c-baba-1026-9564-5b8c656024db
# 		IPv6: fe80::219:d1ff:fe91:1a72
#
# It is cumbersome to operate on text strings in those formats.
#
# An alternative is to convert them to  fixed-length binary strings without delimiters.
# 
# UUID_TO_BIN() and INET6_ATON() each produce a value of data type BINARY(16), a binary string
# 16 bytes (128 bits) long.
#
# The following statements illustrate this (HEX() is used to produce displayable values):
#
# 		SELECT HEX(UUID_TO_BIN('6ccd780c-baba-1026-9564-5b8c656024db'));
# 		+----------------------------------------------------------------+
# 		| HEX(UUID_TO_BIN('6ccd780c-baba-1026-9564-5b8c656024db')) 		  |
# 		+----------------------------------------------------------------+
# 		| 6CCD780CBABA102695645B8C656024DB 										  |
# 		+----------------------------------------------------------------+
#
# 		SELECT HEX(INET6_ATON('fe80::219:d1ff:fe91:1a72')); 		
# 		+-------------------------------------------------+
# 		| HEX(INET6_ATON('fe80::219:d1ff:fe91:1a72')) 	  |
# 		+-------------------------------------------------+
# 		| FE800000000000000000000219D1FFFFE911A72 		  |
# 		+-------------------------------------------------+
#
# Those binary values are easily manipulable with bit operations to perform actions
# such as extracting the timestamp from UUID values, or extracting the network and host
# parts of IPv6 addresses. 
#
# (For examples, see later in this discussion)
#
# Arguments that count as binary strings include column values, routine parameters, local
# variables, and user-defined variables that have a binary string type:
#
# 		BINARY, VARBINARY or one of the BLOB types
#
# What about hexadecimal literals and bit literals?
#
# Recall that those are binary strings by default in MySQL, but numbers in numeric context.
#
# How are they handled for bit operations in MysQL 8.0?
#
# It has been common to specify arguments to bit operations using hexadecimal literals or bit literals
# with the intent that they represent numbers, so MySQL continues to evaluate bit operations in numeric
# context when all bit arguments are hexadecimal or bit literals, for backward compatbility.
#
# If you require evaluation as binary strings instead, that is easily accomplished:
#
# 	Use the _binary introducer for at least one literal
#
# 		) These bit operations evaluate the hexadecimal literals and bit literals as integers:
#
# 			SELECT X'40' | X'01', b'11110001' & b'01001111';
# 			+----------------+---------------------------------+
# 			| X'40' | X'01'  | b'11110001' & b'01001111' 		|
# 			+----------------+---------------------------------+
# 			| 			65 	  | 			65 							|
# 			+----------------+---------------------------------+
#
# 		) These bit operations evaluate the hexadecimal literals and bit literals as binary strings,
# 			due to the _binary introducer:
#
# 			SELECT _binary X'40' | X'01', b'11110001' & _binary b'010001111';
# 			+------------------------+----------------------------------------+
# 			| _binary X'40' | X'01'  | b'11110001' & _binary b'01001111' 		|
# 			+------------------------+----------------------------------------+
# 			| 	A 							 | A 													|
# 			+------------------------+----------------------------------------+
#
# Although the bit operations in both statements produce a result with a numeric value
# of 65, the second statement operates in binary-string context, for which 65 is ASCII A.
#
# In numeric evaluation context, permitted values of hexadecimal literal and bit literal
# arguments have a maximum of 64 bits, as do results.
#
# By contrast, in binary-string evaluation context, permitted arguments (and results)
# can exceed 64 bits:
#
# 		SELECT _binary X'4040404040404040' | X'0102030405060708';
# 		+--------------------------------------------------------+
# 		| _binary X'40404040404040' | X'0102030405060708' 			|
# 		+---------------------------+----------------------------+
# 		| ABCDEFGH 																|
# 		+--------------------------------------------------------+
#
# There are several ways to refer to a hexadecimal literal or bit literal in a bit operation
# to cause binary-string evaluation:
#
# 		_binary literal
# 		BINARY literal
# 		CAST(literal AS BINARY)
#
# Another way to produce binary-string evaluation of hexadecimal literals or bit literals to assign them
# to user-defined variables, which results in variables that have a binary string type:
#
# 		SET @v1 = X'40', @v2 = X'01', @v3 = b'11110001', @v4 = b'01001111'
# 		SELECT @v1 | @v2, @v3 & @v4;
# 		+------------+--------------+
# 		| @v1 | @v2  | @v3 & @v4 	 |
# 		+------------+--------------+
# 		| A 			 | A 				 |
# 		+------------+--------------+
#
# In binary-string context, bitwise operation argumnents must have the same length
# or an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs:
#
# 		SELECT _binary X'40' | X'0001';
# 		ERROR 3513 (HY000): Binary operands of bitwise
# 		operators must be of equal length
#
# To satisfy the equal-length requirement, pad the shorter value with leading zero digits or,
# if the longer value begins with leading zero digits and a shorter result value is acceptable,
# strip them:
#
# 		SELECT _binary X'0040' | X'0001';
# 		+---------------------------------+
# 		| _binary X'0040' | X'0001' 		 |
# 		+---------------------------------+
# 		| A 										 |
# 		+---------------------------------+
#
# 		SELECT _binary X'40' | X'01';
# 		+----------------------------+
# 		| _binary X'40' | X'01' 	  |
# 		+----------------------------+
# 		| A 								  |
# 		+----------------------------+
#
# Padding or stripping can also be accomplished using functions such as:
#
# 		LPAD()
#
# 		RPAD()
#
# 		SUBSTR()
#
# 		CAST()
#
# In such cases, the expression arguments are no longer all literals and
# _binary becomes unnecessary. Examples:
#
# 		SELECT LPAD(X'40', 2, X'00') | X'0001';
# 		+---------------------------------------+
# 		| LPAD(X'40', 2, X'00') | X'0001' 		 |
# 		+---------------------------------------+
# 		| A 												 |
# 		+---------------------------------------+
#
# 		SELECT X'40' | SUBSTR(X'0001', 2, 1);
# 		+---------------------------------------+
# 		| X'40' | SUBSTR(X'0001', 2, 1) 			 |
# 		+---------------------------------------+
# 		| A 												 |
# 		+---------------------------------------+
#
# BINARY STRING BIT-OPERATION EXAMPLES
#
# The following example illustrates use of bit operations to extract parts of a 
# UUID value, in this case, the timestamp and IEEE 802 node number.
#
# This technique requires bitmasks for each extracted part.
#
# Convert the text UUID to the corresponding 16-byte binary value so that it
# can be manipulated using bit operations in binary-string context:
#
# 		SET @uuid = UUID_TO_BIN('6ccd780c-baba-1026-9564-5b8c656024db');
# 		SELECT HEX(@uuid);
# 		+----------------------------------+
# 		| HEX(@uuid) 							  |
# 		+----------------------------------+
# 		| 6CCD780CBABA102695645B8C656024DB |
# 		+----------------------------------+
#
# Construct bitmasks for the timestamp and node number parts of the value.
#
# The timestamp comprises the first three parts (64 bits, bits 0 to 63)
# and the node number is the last part (48 bits, bits 80 to 127):
#
# 		SET @ts_mask = CAST(X'FFFFFFFFFFFFFFFF' AS BINARY(16));
# 		SET @node_mask = CAST(X'FFFFFFFFFFFF' AS BINARY(16)) >> 80;
# 		SELECT HEX(@ts_mask);
#
# 		+----------------------------------+
# 		| HEX(@ts_mask) 						  |
# 		+----------------------------------+
# 		| FFFFFFFFFFFFFFFF0000000000000000 |
# 		+----------------------------------+
#
# 		SELECT HEX(@node_mask);
# 		+----------------------------------+
# 		| HEX(@node_mask) 					  |
# 		+----------------------------------+
# 		| 0000000000000000FFFFFFFFFFFFFFFF |
# 		+----------------------------------+
#
# The CAST(--- AS BINARY(16)) function is used here because the masks
# must be the same length as the UUID value against which they are applied.
#
# The same result can be produced using other functions to pad the masks
# ot hte required length:
#
# 		SET @ts_mask= RPAD(X'FFFFFFFFFFFFFFFF' , 16, X'00');
# 		SET @node_mask = LPAD(X'FFFFFFFFFFFF', 16, X'00');
#
# Use hte masks to extract the timestamp and node number parts:
#
# 		SELECT HEX(@uuid & @ts_mask) AS 'timestamp part';
# 		+-----------------------------------------------+
# 		| timestamp part 											|
# 		+-----------------------------------------------+
# 		| 6CCD780CBABA102600000000000000000000 			|
# 		+-----------------------------------------------+
#
# 		SELECT HEX(@uuid & @node_mask) AS 'node part';
# 		+---------------------------------------------+
# 		| node part 											 |
# 		+---------------------------------------------+
# 		| 00000000000000000000000005B8C656024DB 		 |
# 		+---------------------------------------------+
#
# The preceding examples use these bit operations:
#
# 		Right shift (>>) and bitwise AND (&)
#
# 	NOTE:
#
# 		UUID_TO_BIN() takes a flag that causes some bit rearrangement in the
# 		resulting binary UUID value.
#
# 		If you use that flag, modify the extraction masks accordingly.
#
# The next example uses bit operations to extract the network and host parts of an
# IPv6 address.
#
# Suppose that hte network part has a length of 80 bits.
#
# Then the host part has a length of 128 - 80 = 48 bits.
#
# To extract the network and host parts of the address, convert it to a binary
# string, then use bit operations in binary-string context.
#
# Convert the text IPv6 address to the corresponding binary string:
#
# 		SET @ip = INET6_ATON('fe80::219:d1ff:fe91:1a72');
#
# Define the network length in bits:
#
# 		SET @net_len = 80;
#
# Construct network and host masks by shifting the all-ones address left or right
#
# To do this, begin with the address ::, which is shorthand for all zeros,
# as you can see by converting it to a binary string like this:
#
# 		SELECT HEX(INET6_ATON('::')) AS 'all zeros';
# 		+----------------------------------------------+
# 		| all zeros 											  |
# 		+----------------------------------------------+
# 		| 000000000000000000000000000000000 			  |
# 		+----------------------------------------------+
#
# To produce the complementary value (all ones), use the ~ operator
# to invert the bits:
#
# 		SELECT HEX(~INET6_ATON('::')) AS 'all ones';
# 		+------------------------------------------+
# 		| all ones 											 |
# 		+------------------------------------------+
# 		| FFFFFFFFFFFFFFFFFFFFFFFFFFFFF 				 |
# 		+------------------------------------------+
#
# Shift the all-ones value left or right to produce the network and host masks:
#
# 		SET @net_mask = ~INET6_ATON('::') << (128 - @net_len);
# 		SET @host_mask = ~INET6_ATON('::') >> @net_len;
#
# Display the masks to verify that they cover the correct parts of the address:
#
# 		SELECT INET6_NTOA(@net_mask) AS 'network mask';
# 		+-------------------------------------------+
# 		| network mask 									  |
# 		+-------------------------------------------+
# 		| ffff:ffff:ffff:ffff:ffff:: 					  |
# 		+-------------------------------------------+
#
# 		SELECT INET6_NTOA(@host_mask) AS 'host mask';
# 		+-------------------------------+
# 		| host mask 						  |
# 		+-------------------------------+
# 		| ::ffff:255.255.255.255 		  |
# 		+-------------------------------+
#
# Extracta nd dispaly the network and host parts of hte address:
#
# 		SET @net_part = @ip & @net_mask;
# 		SET @host_part = @ip & @host_mask;
# 		SELECT INET6_NTOA(@net_part) AS 'network part';
# 		+------------------+
# 		| network part 	 |
# 		+------------------+
# 		| fe80::219:0:0:0  |
# 		+------------------+
#
# 		SELECT INET6_NTOA(@host_part) AS 'host part';
# 		+------------------+
# 		| host part 		 |
# 		+------------------+
# 		| ::d1ff:fe91:1a72 |
# 		+------------------+
#
# The preceding example uses these bit operations:
#
# 		Complement (~)
#
# 		Left shift (<<)
#
# 		bitwise AND (&)
#
# The remaining discussion provides details on argument handling for each
# group of bit operations, more information about literal-value handling in
# bit operations, and potential incompatibilities between 8.0 and older versions.
#
# BITWISE AND, OR, AND XOR OPERATIONS
#
# For &, |, and ^ bit operations,, the result type dependso n whether the arguments are evaluated as binary strings or numbers:
#
# 		) Binary-string evaluation occurs when the arguments have a binary string type, and at least one of them is not
# 			a hexadecimal literal, bit literal or NULL literal.
#
# 			Numeric evaluation occurs otherwise, with argument conversion to unsigned 64-bit integers as necessary
#
# 		) Binary-string evaluation produces a binary string of the same length as the arguments.
#
# 			If the arguments have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 			Numeric evaluation produces an unsigned 64-bit integer.
#
# Examples of numeric evaluation:
#
# 		SELECT 64 | 1, X'40' | X'01';
# 		+---------+------------------+
# 		| 64 | 1  | X'40' | X'01' 	  |
# 		+---------+------------------+
# 		| 	65 	 | 65 				  |
# 		+---------+------------------+
#
# Examples of binary-string evaluation:
#
# 		SELECT _binary X'40' | X'01';
# 		+-----------------------------+
# 		| _binary X'40' | X'01' 		|
# 		+-----------------------------+
# 		| A 									|
# 		+-----------------------------+
#
# 		SET @var1 = X'40', @var2 = X'01';
# 		SELECT @var1 | @var2;
# 		+----------------------+
# 		| @var1 	| @var2 		  |
# 		+----------------------+
# 		| A 						  |
# 		+----------------------+
#
# BITWISE COMPLEMENT AND SHIFT OPERATIONS
#
# For ~, << and >> bit operations, the result type depends on whether the bit argument
# is evaluated as a binary string or number:
#
# 		) Binary-string evaluation occurs when the bit argument has a binary string type,
# 			and is not a hexadecimal literal, bit literal, or NULL literal.
#
# 			Numeric evaluation occurs otherwise, with argument conversion to an unsigned 64-bit
# 			integer as necessary
#
# 		) Binary-string evaluation produces a binary string of the same length as the bit argument.
#
# 			Numeric evaluation produces an unsigned 64-bit integer
#
# For shift operations, bits shifted off the end of the value are lost without warning, regardless
# of the argument type.
#
# In particular, if the shift count is greater or equal to the number of bits in the bit argument,
# all bits in the result are 0.
#
# Examples of numeric evaluation:
#
# 		SELECT ~0, 64 << 2, X'40' << 2;
# 		+--------------------------+------------+----------------------+
# 		| ~0 								| 64 << 2 	 | X'40' << 2 			   |
# 		+--------------------------+------------+----------------------+
# 		| 18446744073709551615 	   | 256 		 | 256 						|
# 		+--------------------------+------------+----------------------+
#
# Examples of binary-string evaluation:
#
# 		SELECT HEX(_binary X'1111000022220000' >> 16);
# 		+------------------------------------------+
# 		| HEX(_binary X'1111000022220000' >> 16 	 |
# 		+------------------------------------------+
# 		| 0000111100002222 								 |
# 		+------------------------------------------+
#
# 		SELECT HEX(_binary X'1111000022220000' << 16);
# 		+------------------------------------------+
# 		| HEX(_binary X'1111000022220000' << 16    |
# 		+------------------------------------------+
# 		| 0000222200000000 								 |
# 		+------------------------------------------+
#
# 		SET @var1 = X'F0F0F0F0';
# 		SELECT HEX(~@var1);
# 		+-----------------------+
# 		| HEX(~@var1) 				|
# 		+-----------------------+
# 		| 0F0F0F0F 					|
# 		+-----------------------+
#
# BIT_COUNT() OPERATIONS
#
# THe BIT_COUNT() function always returns an unsigned 64-bit integer,
# or NULL if the argument is NULL.
#
# 		SELECT BIT_COUNT(127);
# 		+-----------------+
# 		| BIT_COUNT(127)  |
# 		+-----------------+
# 		| 				7 		|
# 		+-----------------+
#
# 		SELECT BIT_COUNT(b'010101'), BIT_COUNT(_binary b'010101');
# 		+---------------------+-------------------------------------+
# 		| BIT_COUNT(b'010101')| BIT_COUNT(_binary b'010101') 			|
# 		+---------------------+-------------------------------------+
# 		| 				3 			 | 			3 									|
# 		+---------------------+-------------------------------------+
#
# BIT_AND(), BIT_OR(), AND BIT_XOR() OPERATIONS
#
# For the BIT_AND(), BIT_OR() and BIT_XOR() bit functions, the result type depends on whether
# the function argument values are evaluated as binary strings or numbers:
#
# 		) Binary-string evaluation occurs when the argument values have a binary string type,
# 			and the argument is not a hexadecimal literal, but literal, or NULL literal.
#
# 			Numeric evaluation occurs otherwise, with argument value conversion to unsigned
# 			64-bit integers as necessary.
#
# 		) Binary-string evaluation produces a binary string of the same length as the argument values.
#
# 			If argument values have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error
# 			occurs.
#
# 			If hte argument size exceeds 511 bytes, an ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE
# 			error occurs.
#
# 			Numeric evaluation produces an unsigned 64-bit integer.
#
# NULL values do not affect the result unless all values are NULL.
#
# In that case, the result is a neutral value having the same length as the length
# of the argument values (all bits 1 for BIT_AND(), all bits 0 for BIT_OR(), and BIT_XOR())
#
# Example:
#
# 		CREATE TABLE t (group_id INT, a VARBINARY(6));
# 		INSERT INTO t VALUES (1, NULL);
# 		INSERT INTO t VALUES (1, NULL);
#
# 		INSERT INTO t VALUES (2, NULL);
# 		INSERT INTO t VALUES (2, X'1234');
# 		INSERT INTO t VALUES (2, X'FF34');
#
# 		SELECT HEX(BIT_AND(a)), HEX(BIT_OR(a)), HEX(BIT_XOR(a))
# 		FROM t GROUP BY group_id;
#
# 		+---------------------+------------------+-------------------+
# 		| HEX(BIT_AND(a)) 	 | HEX(BIT_OR(a))   | HEX(BIT_XOR(a))   |
# 		+---------------------+------------------+-------------------+
# 		| FFFFFFFFFFFF 		 | 000000000000 	  | 000000000000 	    |
# 		| 1234 					 | FF34 				  | ED00 				 |
# 		+---------------------+------------------+-------------------+
#
# SPECIAL HANDLING OF HEXADECIMAL LITERALS, BIT LITERALS, AND NULL LITERALS
#
# For backwards compatibility, MySQL 8.0e valuates bit operations in numeric context
# when all bit arguments are hexadecimal literals, bit literals or NULL Literals.
#
# That is, bit operations on binary-string bit arguments do not use binary-string evaluation
# if all bit arguments are unadorned hexadecimal literals, bit literals, or NULL literals.
#
# (This does not apply to such literals if they are written with a _binary introducer, BINARY operator,
# or other way of specifying them explicitly as binary strings)
#
# The literal handling just described is the same as prior to MySQL 8.0
#
# Eexaxmples:
#
# 		) These bit operations evaluate the literals in numeric context and produce a BIGINT result:
#
# 			b'0001' | b'0010'
# 			X'0008' << 8
#
# 		) These bit operations evaluate NULL in numeric context and produce a BIGINT result that has a NULL value:
#
# 			NULL & NULL
# 			NULL >> 4
#
# In MySQL 8.0, you can cause those operations to evaluate the arguments in binary-string context
# by indicating explicitly that at least one argument is a binary string:
#
# 		_binary b'0001' | b'0010'
# 		_binary X'0008' << 8
# 		BINARY NULL & NULL
# 		BINARY NULL >> 4
#
# The result of hte last two expressions is NULL, just as without the BINARY operator, but the data
# type of the result is a binary string type rather than an integer type.
#
# BIT-OPERATION INCOMPATIBILITIES WITH 5.7
#
# Because bit operations can handle binary string arguments natively in MySQL 8.0,
# some expressions produce a different result in 8.0 than in 5.7
#
# The five problematic expression types to watch out for are:
#
# 		nonliteral_binary { & | ^ } binary
# 		binary { & | ^ } nonliteral_binary
# 		nonliteral_binary { << >> } anything
# 		~ nonliteral_binary
# 		AGGR_BIT_FUNC(nonliteral_binary)
#
# Those expressions return BIGINT in MySQL 5.7, binary string in 8.0
#
# Explanation of notation:
#
# 		) { op1 op2 --- }: List of operators that apply to the given expression type
#
# 		) binary. Any kind of binary string argument, including a hexadecimal literal, bit literal or NULL literal
#
# 		) nonliteral_binary. An argument that is a binary string value other than a hexadecimal literal, bit literal, or NULL literal
#
# 		) AGGR_BIT_FUNC: An aggregate function that takes bit-value arguments: BIT_AND(), BIT_OR(), BIT_XOR()
#
# For more info on incompatibilities - see BIT FUNCTIONS AND OPERATORS in MySQL 5.7
#
# THe following list describes available bit functions and operators:
#
# 		) |
#
# 			Bitwise OR
#
# 			The result type depends on whether the arguments are evaluated as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the arguments have a binary string type,
# 					and at least one of them is not a hexadecimal literal, bit literal, or NULL literal.
#
# 					NUmeric evaluation occurs otherwise, with argument conversion to unsigned 64-bit integers as called for.
#
# 				) Binary-string evaluation produces a binary string of hte same length as the arguments.
#
# 					If the arguments have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			For more information, see the introductory discussion in thsi section.
#
# 				SELECT 29 | 15;
# 					-> 31
#
# 				SELECT _binary X'40404040' | X'01020304';
# 					-> 'ABCD'
#
# 		) &
#
# 			Bitwise AND
#
# 			The result type depends on whether the arguments are evaluated as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the arguments have a binary string type,
# 					and at least one of them is not a hexadecimal literal, bit literal or NULL literal.
#
# 					NUmeric evaluation occurs otherwise, with argument conversion to unsigned 64-bit integers as called for.
#
# 				) Binary-string evaluation produces a binary string of hte same length as the arguments.
#
# 					If the arguments have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			For more info, see introductionary discsusion i nthsi section.
#
# 				SELECT 29 & 15;
# 					-> 13
#
# 				SELECT HEX(_binary X'FF' & b'11110000');
# 					-> 'F0'
#
# 		) ^
#
# 			Bitwise XOR
#
# 			The result type depends on whether the arguments are evaluated as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the arguments have a bianry string type, and at least one
# 					of them is not a hexadecimal literal, bit literal or NULL literal.
#
# 					nUmeric evaluation occurs otherwise, with argument conversion to unsigned 64-bit integers
# 					as called for.
#
# 				) Binary-string evaluation produces a binary string of the same length as the arguments.
#
# 					If the arguments have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 					NUmeric evaluation produces an unsigned 64-bit integer.
#
# 			For more information, see the introductory discussion in this section.
#
# 				SELECT 1 ^ 1;
# 					-> 0
#
# 				SELECT 1 ^ 0;
# 					-> 1
#
# 				SELECT 11 ^ 3;
#  				-> 8
#
#  			SELECT HEX(_binary X'FEDC' ^ X'1111');
# 					-> 'EFCD'
#
# 		) <<
#
# 			Shifts a longlong (BIGINT) number or binary string to the left.
#
# 			The result type depends on whether the bit argument is evaluated as binary strong or number:
#
# 				) Binary-string evaluation occurs when the big argument has a bianr ystring type, and is not a hexadecimal literal,
# 					bit literal or NULL literal.
#
# 					Numeric evaluation occurs otherwise, with argument conversion to an unsigned 64-bit int as called for.
#
# 				) Binary-string evaluation produces a binary string of the same length as the bit argument.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			Bits shifted off the end of the value are lost without warning, regardless of argument type.
#
# 			In particular, if the shift count is greater or equal to the number of bits in the big argument,
# 			all bits in the result are 0.
#
# 			For more info, see the introduction.
#
# 				SELECT 1 << 2;
# 					-> 4
#
# 				SELECT HEX(_binary X'00FF00FF00FF' << 8);
# 					-> 'FF00FF00FF00'
#
# 		) >>
#
# 			Shifts a longlong (BIGINT) number or binary string to the right
#
# 			The result depends on whether the bit argument is evaluated as a binary string or number:
#
# 				) Binary-string evaluation occurs when the bit argument has a binary string type,
# 					and is not a hexadecimal literal, bit literal or NULL literal.
#
# 					Numeric evaluation occurs otherwise, with argument conversion to an unsigned 64-bit integer 
# 					as called for
#
# 				) Binary-string evaluation produces a binary string of the same length as the bit argument.
#
# 					Numeric evaluation produces an unsigned 64-bit int
#
# 			Bits shifted off the end of the value are lost without warning, regardless of the argument type.
#
# 			IN particular, if the shift count is greater or equal to the number of bits in the bit argument,
# 			all bits in the result are 0.
#
# 			For more information, see the introductory disscusion:
#
# 				SELECT 4 >> 2;
# 					-> 1
# 
# 				SELECT HEX(_binary X'00FF00FF00FF' >> 8);
# 					-> '0000FF00FF00'
#
#
# 		) ~
#
# 			Invert all bits
#
# 			The result type depends on whether the bit argument is evaluated as a binary string or number:
#
# 				) Binary string evaluation occurs when the bit argument has a binary string type, and is not a 
# 					hexadecimal literal, bit literal, or NULL literal.
#
# 					NUmeric evaluation occurs otherwise, with argument conversion to an unsigned 64-bit
# 					integer as called for
#
# 				) Binary-string evaluation produces a bianry string of the same length as the bit argument.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			For more information, see the intro.
#
# 				SELECT 5 & ~1;
# 					-> 4
#
# 				SELECT HEX(~X'0000FFFF1111EEEE');
# 					-> 'FFFF0000EEEE1111'
#
# 		) BIT_COUNT(N)
#
# 			returns the number of bits that are set in the argument N as an unsigned 64-bit integer,
# 			or NULL if the argument is NULL
#
# 				SELECT BIT_COUNT(64); BIT_COUNT(BINARY 64);
# 					-> 1, 7
#
# 				SELECT BIT_COUNT('64'), BIT_COUNT(_binary '64');
# 					-> 1, 7
#
# 				SELECT BIT_COUNT(X'40'), BIT_COUNT(_binary X'40');
# 					-> 1, 1
#
# 12.13 ENCRYPTION AND COMPRESSION FUNCTIONS
#
# TABLE 12.17 ENCRYPTION FUNCTIONS
#
# NAME 													DESC
#
# AES_DECRYPT() 			Decrypt using AES
#
# AES_ENCRYPT() 			Encrypt using AES
#
# ASYMMETRIC_DECRYPT() 	Decrypt ciphertext using private or public key
#
# ASYMMETRIC_DERIVE() 	Derive symmetric key from asymmetric keys
#
# ASYMMETRIC_ENCRYPT() 	Encrypt cleartext using private orp ublic key
#
# ASYMMETRIC_SIGN() 		Generate signature from digest
#
# ASYMMETRIC_VERIFY() 	Verify that signature matches digest
#
# COMPRESS() 				Return result as a binary string
#
# CREATE_ASYMMETRIC_PRIV_KEY() 	Create private key
#
# CREATE_ASYMMETRIC_PUB_KEY() 	Create public key
#
# CREATE_DH_PARAMETERS() 			Generate shared DH secret
#
# CREATE_DIGEST() 					Generate digest from string
#
# DECODE() 								Decodes a string encrypted using ENCODE()
#
# DES_DECRYPT() 						Decrypt a string
#
# DES_ENCRYPT() 						Encrypt a string
#
# ENCODE() 								Encode a string
#
# ENCRYPT() 							Encrypt a string
#
# MD5() 									Calculate MD5 checksum
#
# PASSWORD() 							Calculate and return a password string
#
# RANDOM_BYTES() 						Return a random byte vector
#
# SHA1(), SHA() 						Calculate an SHA-1 160-bit checksum
#
# SHA2() 								Calculate an SHA-2 checksum
#
# STATEMENT_DIGEST() 				Compute statement digest hash value
#
# STATEMENT_DIGEST_TEXT() 			Compute normalized statement digest
#
# UNCOMPRESS() 						Uncompress a string compressed
#
# UNCOMPRESSED_LENGTH() 			Return the length of a string before compression
#
# VALIDATE_PASSWORD_STRENGTH() 	Determine strength of PW
#
# Many encryption and compression functions returns strings for which the result might contain 
# arbitrary byte values.
#
# if you want to store these results, use a column with a VARBINARY or BLOB binary string data type.
#
# This will avoid potential problems with trailing space removal or character set conversion that
# would change data values, such as may occur if you use a nonbinary string data type (CHAR, VARCHAR, TEXT)
#
# SOme encryption functions return strings of ASCII characters:
#
# 		MD5()
#
# 		SHA()
#
# 		SHA1()
#
# 		SHA2()
#
# 		STATEMENT_DIGEST()
#
# 		STATEMENT_DIGEST_TEXT()
#
# Their return value is a string that hs a character set and collation determined by the
# character_set_connection and collation_connection system variables.
#
# This is a nonbinary string unless the character set is binary
#
# If an application stores values from a function such as MD5 or SHA1 that returns as tring of
# hex digits, more efficient storage and comparisons can be obtained by converting the hex
# representation to binary using UNHEX() and storing hte result in a BINARY(N) column
#
# Each pair of hexadecimal digits requires one byte in binary form,
# so the value of N depends on the length of the hex string.
#
# N is 16 or an MD5(), and a 20 for a SHA1()
#
# For SHA2() N ranges from 28 to 32 depending on the argument specifying
# the desired bit length of the result
#
# The size penalty for storing hte hex string in a CHAR column is at least two times,
# up to eight times if the value is stored in a column that uses the utf8 char set
#
# (where ach character uses 4 bytes)
#
# Strong the string also results in slower comparisons because of the larger values
# and the need to take character set collation rules into account.
#
# Suppose that an application stores MD5() string values in a CHAR(32) column:
#
# 		CREATE TABLE md5_tbl (md5_val CHAR(32), ---);
# 		INSERT INTO md5_tbl (md5_val, ---) VALUES(MD5('abcdef'), ---);
#
# To convert hex strings to more compact format, modify the application
# to use UNHEX() and BINARY(16) instead:
#
# 		CREATE TABLE md5_tbl (md5_val BINARY(16), ---);
# 		INSERT INTO md5_tbl (md5_val, ---) VALUES(UNHEX(MD5('abcdef')), ---);
#
# Applications should be prepared to handle the very rare case that a hashing function
# produces the same value for two differnet input values
#
# One way to make collisions detectable is to make the hash column a primary key
#
# NOTE:
#
# 		Exploiits for the MD5 and SHA--1 algorithms have become known.
#
# 		You may wish to consider using another one-way encryption function
# 		described in this section instead, such as SHA2()
#
# CAUTION:
#
# 		PWs or other sensitive values supplied as args to encryption functions
# 		are sent in cleartext to the MySQL server unless an SSL connection
# 		is used.
#
# 		Also, such values will appear in any MySQL logs to which they are written.
#
# 		To avoid these types of exposures, applicaitons dcan encrypt sensitive
# 		values on the client side before sending them to the server.
#
# 		The same considerations apply to encryption keys.
#
# 		To avoid exposing these, applications can use stored procedures to encrypt
# 		and decrypt values on the server side
#
# ) AES_DECRYPT(crypt str, key str[, init vector])
#
# 		THis function decrypts data using the official AES (ADvanced Encryption Stnadard Algorithm)
#
# 		For more informaiton, see the description for AES_ENCRYPT()
#
# 		THe optional initialization vector argument, init_vector
#
# 		statements that use AES_DECRYPT() are unsafe for statement based replication
#
# ) AES_ENCRYPT(str,key str[, init vector])
#
# 		AES_ENCRYPT() and AES_DECRYPT() implement encryption and decryption of data using
# 		the official AES (Advanced Encryption Standard) algorithm, previously known
# 		as "Rijndael"
#
# 		The AES standard permits various key lengths
#
# 		By default these functions implement AES with a 128-bit key length.
#
# 		Key lengths of 196 or 256 bits can be used, as described later.
#
# 		the key length is a trade off between performance and security
#
# 		AES_ENCRYPT() encrypts the string str using the key string key_str and returns
# 		a binary string containing the encrypted output.
#
# 		AES_DECRYPT() decrypts the encrypted string crypt_str using the key string
# 		key_str and returns the original cleartext string
#
# 		If either function argument is NULL, the function returns NULL
#
# 		The str and crypt_str arguments can be any length, and padding is automatically
# 		added to str so it is a multiple of a block as required by block-based algos
# 		such as AES.
#
# 		THis padding is automatically removed by the AES_DECRYPT() function
#
# 		The length of crypt-str can be calculated using this formula:
#
# 			16 * (trunc(string_length / 16) + 1)
#
# 		For a key length of 128 bits, the most secure way to pass a key to the
# 		key_str argument is to create a truly random 128-bit value and pass
# 		it as a binary value.
#
# 		For example:
#
# 			INSERT INTO t
# 			VALUES (1, AES_ENCRYPT('text', UNHEX('<string>')));
#
# 		A passphrase can be used to generate an AES key by hashing hte passphrase.
#
# 		For example:
#
# 			INSERT iNTO t
# 			VALUES (1, AES_ENCRYPT('text', UNHEX(SHA2('My secret passphrase',512))));
#
# 		Do not pass a password or passphrase directly to crypt_str, hash it first.
#
# 		Previous versions of this documentation suggested the former approach, but it is
# 		no longer recommended as the examples shown here are more secure.
#
# 		If AES_DECRYPT() detects in valid data or incorrect padding, it returns NULL.
#
# 		However, it is possible for AES_DECRYPT() to return a non-NULL value
# 		(possibly garbage) if the input data or the key is invalid.
#
# 		AES_ENCRYPT() and AES_DECRYPT() permit control of the block encryption mode and take
# 		and optional init_vector initialization vector argument:
#
# 			) The block_encryption_mode system variable controls the mode for block-based encryption 
# 				algorithms.
#
# 				its default value is aes-128-ecb, which signifies encryption using a key length
# 				of 128 bits and ECB mode.
#
# 				For a description of hte permitted values of this variabe, see SECTION 5.1.8. "SERVER SYSTEM VARIABLES"
#
# 			) The optional init_vector argument provides an intiializaiton vector for block encryption
# 				modes that require it.
#
# 		For codes that require the optional init_vector argument, it must be 16 bytes or longer
# 		(bytes in excess of 16 are ignored)
#
# 		An error occurs if init_vector is missing
#
# 		For modes that do not require init_vector, it is ignored and a warning is generated
# 		if it is specified.
#
# 		A random string of bytes to use for the initialization vector
# 		can be produced by calling RANDOM_BYTES(16)
#
# 		For encryption modes that require an initialization vector, the same vector
# 		must be used for encryption and decryption.
#
# 			SET block_encryption_mode = 'aes-256-cbc';
# 			SET @key_str = SHA2('My secret passphrase',512);
# 			SET @init_vector = RANDOM_BYTES(16);
#
# 			SET @crypt_str = AES_ENCRYPT('text',@key_str,@init_vector);
# 			SELECT AES_DECRYPT(@crypt_str,@key_str,@init_vector);
# 			+---------------------------------------------------+
# 			| AES_DECRYPT(@crypt_str,@key_str,@init_vector) 	 |
# 			+---------------------------------------------------+
# 			| text 															 |
# 			+---------------------------------------------------+
#
# 		The following table lists each permitted block encryption mode, the SSL
# 		libraries that support it, and whether the initialization vector argument
# 		is required.
#
# 			BLOCK ENCRYPTION MODE 	SSL LIBRARIES THAT SUPPORT MODE 		INITIALIZATION VECTOR REQUIRED
# 			
# 			ECB 							OpenSSL, wolfSSL 							No
#
# 			CBC 							OpenSSL, wolfSSL 							Yes
#
# 			CFB1 							OpenSSL 										Yes
#
# 			CFB8 							OpenSSL 										Yes
#
# 			CFB128 						OpenSSL 										Yes
#
# 			OFB 							OpenSSL 										Yes
#
# 		Statements that use AES_ENCRYPT() or AES_DECRYPT() are unsafe for statement-based replication.
#
# 	) COMPRESS(string to compress)
#
# 		Compresses a string and returns the result as a binary string.
#
# 		This function requires MySQL to have been compiled with a compression library
# 		such as zlib.
#
# 		Otherwise, the return value is always NULL.
#
# 		The compressed string can be uncompressed with UNCOMPRESS()
#
# 			SELECT LENGTH(COMPRESS(REPEAT('a',1000)));
# 				-> 21
#
# 			SELECT LENGTH(COMPRESS(''));
# 				-> 0
#
# 			SELECT LENGTH(COMPRESS('a'));
# 				-> 13
#
# 			SELECT LENGTH(COMPRESS(REPEAT('a',16)));
# 				-> 15
#
# 		The compressed string contents are stored the following way:
#
# 			) Empty strings are stored as empty strings
#
# 			) Nonempty strings are stored as a 4-byte length of the uncompressed string 
# 				(low byte first), followed by the compressed string.
#
# 				If the string ends with space, an extra . character is added to avoid problems
# 				with endspace trimming should the result be stored in a CHAR or VARCHAR column.
#
# 				(However, use of nonbinary string data types such as CHAR or VARCHAR to store compressed
# 				strings is not recommended anyway because character set conversion may occur.
#
# 				Use a VARBINARY or BLOB binary string column instead.)
#
# 	) DECODE(crypt str, pass str)
#
# 		This function was removed in 8.0.3
#
# 		Consider using AES_ENCRYPT() and AES_DECRYPT() instead
#
# 	) DES_DECRYPT(crypt str[,key str])
#
# 		Removed in 8.0.3
#
# 		Consider using AES_ENCRYPT() and AES_DECRYPT() instead.
#
# 	) DES_ENCRYPT(str[, {key num|key str}])
#
# 		Removed in 8.0.3
#
# 		Consider using AES_ENCRYPT() and AES_DECRYPT() instead
#
# 	) ENCODE(str,pass str)
#
# 		Removed in 8.0.3
#
# 		Consider using AES_ENCRYPT() and AES_DECRYPT() instead
#
# 	) ENCRYPT(str[,salt])
# 		
# 		Removed in 8.0.3
#
# 		For one-way hashing, consider using SHA2() instead
#
# 	) MD5(str)
#
# 		Calculates an MD5 128-bit checksum for the string.
#
# 		The value is returned as a string of 32 hexadecimal digits, or NULL if the
# 		argument was NULL.
#
# 		The return value can, for example, be used as a hash key.
#
# 		See the notes at the beginning of this section about storing hash values efficiently.
#
# 		The return value is a string in the connection character set.
#
# 		If FIPS mode is enabled, MD5() returns NULL.
#
# 		See SECTION 6.6, "FIPS SUPPORT"
#
# 			SELECT MD5('testing');
# 				-> '<string>'
#
# 		This is the "RSA Data Security, Inc. MD5 Message-Digest Algorithm"
#
# 		See the note regarding the MD5 algorithm at the beginning of this section.
#
# 	) PASSWORD(str)
#
# 		This function was removed in MySQL 8.0.11
#
# 	) RANDOM_BYTES(len)
#
# 		This function returns a binary string of len random bytes generated using the random
# 		number generator of the SSL library.
#
# 		Permitted values of len range from 1 to 1024.
#
# 		For values outside that range, RANDOM_BYTES() generates a warning and returns NULL
#
# 		RANDOM_BYTES() can be used to provide the initialization vector for the AES_DECRYPT()
# 		and AES_ENCRYPT() functtions.
#
# 		For use in that context, len must be at least 16
#
# 		Larger values are permitted, but bytes in excess of 16 are ignored.
#
# 		RANDOM_BYTES() generates a random value, which makes its result nondeterministic.
#
# 		Consequently, statements that use this function are unsafe for statement-based replication.
#
# 	) SHA1(str), SHA(str)
#
# 		Calculates an SHA-1 160-bit checksum for the string, as described in RFC 3174 (Secure Hash Algorithm)
#
# 		The value is returned as a string of 40 hexadecimal digits, or NULL if the argument was NULL.
#
# 		One of the possible uses for this function is as a hash key.
#
# 		See the notes at the beginning of this section about storing hash values
# 		efficiently.
#
# 		SHA() is synonymous with SHA1()
#
# 		The return value is a string in the connection character set.
#
# 			SELECT SHA1('abc');
# 				-> '<string>'
#
# 		SHA1() can be considered a cryptographically more secure equivalent of MD5()
#
# 		However, see the note regarding the MD5 and SHA-1 algorithms at the beginning
# 		this section.
#
# 	) SHA2(str, hash length)
#
# 		Calculates the SHA-2 family of hash functions (SHA-224, SHA-256, SHA-384 and SHA-512)
#
# 		The first argument is the cleartext string to be hashed.
#
# 		The second argument indicates the desired bit length of the result, which must have a value
# 		of 224, 256, 384, 512 or 0 (which is equivalent to 256)
#
# 		If either argument is NULL or the hash length is not one of the permitted values, the return
# 		value is NULL.
#
# 		Otherwise, the function result is a hash value containing the desired number of bits.
#
# 		See the notes at the beginning of this section about storing hash values efficiently.
#
# 		The return value is a string in the connection character set.
#
# 			SELECT SHA2('abc', 224);
# 				-> '<string>'
#
# 		This function works only if MySQL has been configured with SSL support.
# 		See SECTION 6.4, "USING ENCRYPTED CONNECTIONS"
#
# 		SHA2() can be considered cryptographically more secure than MD5() or SHA1()
#
# 	) STATEMENT_DIGEST(statement)
#
# 		Given an SQL statement as a string, returns the statement digest hash value as
# 		a string in the connection character set or NULL if the argument is NULL.
#
# 		The related STATEMENT_DIGEST_TEXT() function returns the normalized statement digest.
#
# 		For informaiton about statement digesting, see SECTION 26.10, "PERFORMANCE SCHEMA STATEMENT DIGESTS AND SAMPLING"
#
# 		Both functions use the MySQL parser to parse the statement.
#
# 		If parsing fails, an error occurs.
#
# 		The error message includes the parse error only if the statement is provided as a literal string.
#
# 		The max_digest_length system variable determines the maximum number of bytes available to these
# 		functions for computing normalized statement digests.
#
# 			SET @stmt = 'SELECT * FROM mytable WHERE cola = 10 AND colb = 20';
# 			SELECT STATEMENT_DIGEST(@stmt);
# 			+-----------------------------------------------------------------+
# 			| STATEMENT_DIGEST(@stmt) 														|
# 			+-----------------------------------------------------------------+
# 			| <string> 																			|
# 			+-----------------------------------------------------------------+
#
# 			SELECT STATEMENT_DIGEST_TEXT(@stmt);
# 			+-----------------------------------------------------------------+
# 			| STATEMENT_DIGEST_TEXT(@stmt) 												|
# 			+-----------------------------------------------------------------+
# 			| SELECT * FROM `mytable` WHERE `cola` = ? AND `colb` = ? 			|
# 			+-----------------------------------------------------------------+
#
# 	) STATEMENT_DIGEST_TEXT(statement)
#
# 		Given an SQL statement as a string, returns the normalized statement digest as
# 		a string in the connection character set, or NULL if the argument is NULL.
#
# 		For additional discussion and examples, see the description of the related STATEMENT_DIGEST()
# 		function.
#
# 	) UNCOMPRESS(string to uncompress)
#
# 		Uncompresses a string compressed by the COMPRESS() function.
#
# 		If the argument is not a compressed value, the result is NULL.
#
# 		This function requires MySQL to have been compiled with a compression
# 		library such as zlib.
#
# 		Otherwise, the return value is always NULL
#
# 			SELECT UNCOMPRESS(COMPRESS('any string'));
# 				-> 'any string'
# 			SELECT UNCOMPRESS('any string');
# 				-> NULL
#
# 	) UNCOMPRESSED_LENGTH(compressed string)
#
# 		Returns the length that hte compressed string had before being compressed.
#
# 			SELECT UNCOMPRESSED_LENGTH(COMPRESS(REPEAT('a',30)));
# 				-> 30
#
# 	) VALIDATE_PASSWORD_STRENGTH(str)
#
# 		Given an argument representing a cleartext password, this function returns an integer
# 		to indicate how strong the password is.
#
# 		The return value ranges from 0 (weak) to 100 (strong)
#
# 		Password assessment by VALIDATE_PASSWORD_STRENGTH() is done by the validate_password
# 		component.
#
# 		If that component is not installed, the function always returns 0.
#
# 		For information about installing validate_password, see SECTION 6.5.3, "THE PASSWORD VALIDATION COMPONENT"
#
# 		To examine or configure the parameters that affect password testing, check or set the system
# 		variables implemented by validate_password
#
# 		See SECTION 6.5.3.2, "PASSWORD VALIDATION OPTIONS AND VARIABLES"
#
# 		The password is subjected to increasingly strict tests and the return value reflects which
# 		tests were satisfied, as shown in the following table.
#
# 		In addition, if the validate_password.check_user_name system variable is enabled and the
# 		password matches the user name, VALIDATE_PASSWORD_STRENGTH() returns 0 regardless of
# 		how other validate_password system variables are set.
#
# 			PASSWORD TEST 										RETURN VALUE
#
# 			Length < 4 											0
#
# 			Length > 4 and < validate_password.length 25
#
# 			Satisfies policy 1 (LOW) 						50
#
# 			Satisfies policy 2 (MEDIUM) 					75
#
# 			Satisfies policy 3 (STRONG) 					100
#
# 12.14 LOCKING FUNCTIONS
#
# This section describes functions used to manipulate user-level locks.
#
# TABLE 12.18 LOCKING FUNCTIONS
#
# 	NAME 							DESCRIPTION
#
# GET_LOCK() 					Get a named lock
#
# IS_FREE_LOCK() 				Whether the named lock is free
#
# IS_USED_LOCK() 				Whether the named lock is in use; return connection identifier if true
#
# RELEASE_ALL_LOCKS() 		Releases all current named locks
#
# RELEASE_LOCK() 				Releases the named lock
#
# 	) GET_LOCK(str, timeout)
#
# 		Tries to obtain a lock with a name given by the string str, using a timeout of  timeout seconds.
#
# 		A negative timeout values means infinite timeout.
#
# 		The lock is exclusive.
#
# 		While held by one session, other sessions cannot obtain a lock of the same name.
#
# 		Returns 1 if hte lock was obtained successfully, 0 if the attempt timed out
# 		(for example, because another client has previously locked the name), or NULL 
# 		if an error occurred (such as running out of memory or the thread was killed with mysqladmin kill)
#
# 		A lock obtained with GET_LOCK() is released explicitly by executing RELEASE_LOCK()
# 		or implicitly when your session terminates (either normally or abnormally)
#
# 		Locks obtained with GET_LOCK() are not released when transactions commit or roll back.
#
# 		GET_LOCK() is implemented using the metadata locking (MDL) subsystem.
#
# 		Multiple simultaneous locks can be acquired and GET_LOCK() does not release any existing
# 		locks.
#
# 		For example, suppose that you execute these statements:
#
# 			SELECT GET_LOCK('lock1', 10);
# 			SELECT GET_LOCK('lock2', 10);
#
# 			SELECT RELEASE_LOCK('lock2');
# 			SELECT RELEASE_LOCK('lock1');
#
# 		The second GET_LOCK() acquires a second lock and both RELEASE_LOCK() calls return 1 (success)
#
# 		It is even possible for a given session to acquire multiple locks for the same name.
#
# 		Other sessions cannot acquire a lock with that name until the acquiring session
# 		releases all its locks for the name.
#
# 		Uniquely named locks acquired with GET_LOCK() appear in the Performance Schema 
# 		metadata_locks table.
#
# 		The OBJECT_TYPE column says USER LEVEL LOCK and the OBJECT_NAME column indicates
# 		the lock name.
#
# 		In the case that multiple locks are acquired for the same name, only the first lock
# 		for the name registers a row in the metadata_locks table.
#
# 		Subsequent locks for the name increment a counter in the lock but do not acquire
# 		additional metadata locks.
#
# 		The metadata_locks row for the lock is deleted when the last lock instance on the name
# 		is released.
#
# 		The capability of acquiring multiple locks means there is the possibility of deadlock
# 		among clients.
#
# 		When this happens, the server chooses a caller and terminates its lock-acquisition
# 		request with an ER_USER_LOCK_DEADLOCK error.
#
# 		This error does not cause transactions to roll back.
#
# 		MySQL enforces a maximum length on lock names of 64 characters.
#
# 		GET_LOCK() can be used to implement application locks or to simulate record locks.
#
# 		Names are locked on a server-wide basis. If a name has been locked within one
# 		session, GET_LOCK() blocks any request by another session for a lock with the
# 		same name.
#
# 		This enables clients that agree on a given lock name to use the name to perform
# 		coooperative advisory locking.
#
# 		But be aware that it also enables a client that is not amongst the set of cooperating
# 		clients to lock a name, either inadvertedly or deliberately, and thus prevent any
# 		of the cooperating clients from locking that name.
#
# 		One way to reduce the likelihood of this is to use lock names that are database-specific
# 		or application-specific.
#
# 		For example, use lock names of the form db_name.str or app_name.str
#
# 		If multiple clients are waiting for a lock, the order in which they will acquire it is undefined.
#
# 		Applications should not assume that clients will acquire the lock in the same order
# 		that they issued the lock requests.
#
# 		GET_LOCK() is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format is set
# 		to STATEMENT.
#
# 			CAUTION:
#
# 				With the capability of acquiring multiple named locks, it is possible
# 				for a single statement to acquire a large number of locks.
#
# 				For example:
#
# 					INSERT INTO --- SELECT GET_LOCK(t1.col_name) FROM t1;
#
# 				These types of statements may have certain adverse effects.
#
# 				For example, if the statement fails part way through and rolls back,
# 				locks acquired up to the point of failure will still exist.
#
# 				If the intent is for there to be a correspondence between rows inserted
# 				and locks acquired, that intent will not be satisfied.
#
# 				Also, if it is important that locks are granted in a certain order,
# 				be aware that result set order may differ depending on which execution
# 				plan the optimizer chooses.
#
# 				For these reasons, it may be best to limit applications to a single
# 				lock-acquisition call per statement.
#
# 		A different locking interface is available as either a plugin service or a set
# 		of user-defined functions.
#
# 		This interface provides lock namespaces and distinct read and write locks,
# 		unlike the interface provided by GET_LOCK() and related functions.
#
# 		For details, see SECTION 29.3.1, "THE LOCKING SERVICE"
#
# 	) IS_FREE_LOCK(str)
#
# 		Checks whether the lock named str is free to use (that is, not locked).
#
# 		Returns 1 if the lock is free (no one is using the lock), 0 if the lock
# 		is in use, and NULL if an error occurs (such as an incorrect argument)
#
# 		This function is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format
# 		is set to STATEMENT.
#
# 	) IS_USED_LOCK(str)
#
# 		Checks whether the lock named str is in use (that is, locked).
#
# 		If so, it returns the connection identifier of the client session
# 		that holds the lock.
#
# 		Otherwise, it returns NULL
#
# 		This function is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format
# 		is set to STATEMENT.
#
# 	) RELEASE_ALL_LOCKS()
#
# 		Releases all named locks held by the current session and returns the number
# 		of locks released (0 if there were none)
#
# 		This function is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format
# 		is set to STATEMENT.
#
# 	) RELASE_LOCK(str)
#
# 		Releases the lock named by the string str that was obtained with GET_LOCK().
#
# 		Returns 1 if the lock was released, 0 if the lock was not established by
# 		this thread (in which case the lock is not released), and NULL if the named
# 		lock did not exist.
#
# 		The lock does not exist if it was never obtained by a call to GET_LOCK() or
# 		if it has previously been released.
#
# 		The DO statement is convenient to use with RELEASE_LOCK(). See SECTION 13.2.3, "DO SYNTAX"
#
# 		This function is unsafe for statement-based replication.
#
# 		A warning is logged if you use this function when binlog_format is set to STATEMENT.
#
# 12.15 INFORMATION FUNCTIONS
#
# TABLE 12.19 INFORMATION FUNCTIONS
#
# 		Name 								Desc
#
# BENCHMARK() 			Repeatedly execute an expression
#
# CHARSET() 			Return the character set of the argument
#
# COERCIBILITY() 		Return the collation coercibility value of the string argument
#
# COLLATION() 			Return the collation of the string argument
#
# CONNECTION_ID() 	Return the connection ID (thread ID) for the connection
#
# CURRENT_ROLE() 		Returns the current active roles
#
# CURRENT_USER(), 	The authenticated user name and host name
# CURRENT_USER
#
# DATABASE() 			Return the default (current) database name
#
# FOUND_ROWS() 		For a SELECT with a LIMIT clause, the number of rows that would be
# 							returned were there no LIMIT clause
#
# ICU_VERSION() 		ICU library version
#
# LAST_INSERT_ID() 	Value of the AUTOINCREMENT column for the last INSERT
#
# ROLES_GRAPHML() 	Returns a GraphML document representing memory role subgraphs
#
# ROW_COUNT() 			The number of rows updated
#
# SCHEMA() 				Synonym for DATABASE()
#
# SESSION_USER() 		Synonym for USER()
#
# SYSTEM_USER() 		Synonym for USER()
#
# USER() 				The user name and host name provided by the client
#
# VERSION() 			Return a string that indicates the MySQL server version
#
# 		) BENCHMARK(count,expr)
#
# 			The BENCHMARK() function executes the expression expr repeatedly count times.
#
# 			It may be used to time how quickly MySQL processes the expression.
# 			The result value is always 0.
#
# 			The intended use is from within the mysql client, which reports
# 			query execution times:
#
# 				SELECT BENCHMARK(1000000, AES_ENCRYPT('hello', 'goodbye'));
# 				+---------------------------------------------------------+
# 				| BENCHMARK(1000000, AES_ENCRYPT('hello', 'goodbye')) 	 |
# 				+---------------------------------------------------------+
# 				| 									0 										 |
# 				+---------------------------------------------------------+
# 				1 row in set (4.74 sec)
#
# 			The time reported is elapsed time on the client end, not CPU time on
# 			the server end.
#
# 			It is advisable to execute BENCHMARK() several times, and to interpret
# 			the result with regard to how heavily loaded the server machine is.
#
# 			BENCHMARK() is intended for measuring the runtime performance of scalar expresions,
# 			which has some significant implications for the way that you use it
# 			and interpret the results:
#
# 				) Only scalar expressions can be used.
#
# 					Although the expression can be a subquery, it must return
# 					a single column and at most a single row.
#
# 					For example, BENCHMARK(10, (SELECT * FROM t)) will fail if the
# 					table t has more than one column or more than one row.
#
# 				) Executing a SELECT expr statement N times differs from executing SELECT BENCHMARK(N, expr)
# 					in terms of the amount of overhead involved.
#
# 					The two have very different execution profiles and you should not expect them
# 					to take the same amount of time.
#
# 					The former involves the parser, optimizer, table locking, and runtime evaluation
# 					N times each.
#
# 					The latter involves only runtime evaluation N times, and all the other components
# 					just once.
#
# 					Memory structures already allocated are reused, and runtime optimizations such as 
# 					local caching of results already evaluated for aggregate functions can alter
# 					the results.
#
# 					Use of BENCHMARK() thus measures performance of the runtime component by giving more
# 					weight to that component and removing the "noise" introduced by the network, parser, optimizer,
# 					and so forth.
#
# 		) CHARSET(str)
#
# 			Returns the character set of the string argument
#
# 				SELECT CHARSET('abc');
# 					-> 'utf8'
#
# 				SELECT CHARSET(CONVERT('abc' USING latin1));
# 					-> 'latin1'
#
# 				SELECT CHARSET(USER());
# 					-> 'utf8'
#
# 		) COERCIBILITY(str)
#
# 			Returns the collation coercibility value of the string argument
#
# 				SELECT COERCIBILITY('abc' COLLATE utf8_swedish_ci);
# 					-> 0
#
# 				SELECT COERCIBILITY(USER());
# 					-> 3
#
# 				SELECT COERCIBILITY('abc');
# 					-> 4
#
# 				SELECT COERCIBILITY(1000);
# 					-> 5
#
# 			The return values have the meanings shown in the following table.
#
# 			Lower values have higher precedence.
#
# 				COERCIBILITY 	MEANING 					EXAMPLE
# 
# 					0 				Explicit collation 	Value with COLLATE clause
#
# 					1 				No collation 			Concatenation of strings with different collations
#
# 					2 				Implicit collation 	Column value, stored routine parameter or local variable
#
# 					3 				System constant 		USER() return value
#
# 					4 				Coercible 				Literal string
#
# 					5 				Numeric 					Numeric or temporal value
#
# 					5 				Ignorable 				NULL or an expression derived from NULL
#
# 			For more information, see SECTION 10.8.4, "COLLATION COERCIBILITY IN EXPRESSIONS"
#
# 		) COLLATION(str)
#
# 			Returns the collation of thte string argument
#
# 				SELECT COLLATION('abc');
# 					-> 'utf8_general_ci'
#
# 				SELECT COLLATION(_utf8mb4'abc');
# 					-> 'utf8mb4_0900_ai_ci'
#
# 				SELECT COLLATION(_latin1'abc');
# 					-> 'latin1_swedish_ci'
#
# 		) CONNECTION_ID()
#
# 			Returns the connection ID (thread ID) for the connection.
#
# 			Every connection has an ID that is unique among the set of currently
# 			connected clients.
#
# 			The value returned by CONNECTION_ID() is the same type of value as displayed
# 			in the ID column of the INFORMATION_SCHEMA.PROCESSLIST table, the Id column
# 			of SHOW_PROCESSLIST output, and the PROCESSLIST_ID column of the Performance
# 			Schema threads table.
#
# 				SELECT CONNECTION_ID();
# 					-> 23786
#
#
# 		) CURRENT_ROLE()
#
# 			Returns a utf8 string containing the current active roles for the current session,
# 			separated by commas, or NONE if there are none.
#
# 			The value reflects the setting of the sql_quote_show_create system variable.
#
# 			Suppose that an account is granted roles as follows:
#
# 				GRANT 'r1', 'r2' TO 'u1'@'localhost';
# 				SET DEFAULT ROLE ALL TO 'u1'@'localhost';
#
# 			In sessions for u1, the initial CURRENT_ROLE() value names the default account roles.
#
# 			Using SET_ROLE changes that:
#
# 				SELECT CURRENT_ROLE();
# 				+---------------------------------+
# 				| CURRENT_ROLE() 						 |
# 				+---------------------------------+
# 				| `r1`@`%`, `r2`@`%` 				 |
# 				+---------------------------------+
#
# 				SET ROLE 'r1'; SELECT CURRENT_ROLE();
# 				+--------------------+
# 				| CURRENT_ROLE() 		|
# 				+--------------------+
# 				| `r1`@`%` 				|
# 				+--------------------+
#
# 		) CURRENT_USER, CURRENT_USER()
#
# 			Returns the user name and host name combination for the MySQL account that hte server
# 			used to authenticate the current client.
#
# 			This account determines your access privileges.
#
# 			The return value is a string in the utf8 character set.
#
# 			The value of CURRENT_USER() can differ from the value of USER()
#
# 				SELECT USER();
# 					-> 'davida@localhost'
# 				SELECT * FROM mysql.user;
# 				ERROR 1044: Access denied for user ''@'localhost' to
# 				database 'mysql'
# 				SELECT CURRENT_USER();
# 					-> '@localhost'
#
# 			The example illustrates that although the client specified a user name
# 			of davida (as indicated by the value of the USER() function), the server
# 			authenticated the client using an anonymous user account (as seen by the empty user
# 			name part of the CURRENT_USER() value)
#
# 			One way this might occur is that there is no account listed in the grant tables
# 			for davida.
#
# 			Within a stored program or view, CURRENT_USER() returns the account for the user
# 			who defined the object (as given by its DEFINER value) unless defined with the
# 			SQL SECURITY INVOKER characteristic
#
# 			In the latter case, CURRENT_USER() returns the object's invoker
#
# 			Triggers and events have no option to define the SQL SECURITY characteristic,
# 			so for these objects, CURRENT_USER() returns the account for the user who
# 			defined the object.
#
# 			To return the invoker, use USER() or SESSION_USER()
#
# 			The following statements support use of the CURRENT_USER() function to take
# 			place of the name (and, possibly, a host for) an affected user or a definer;
#
# 			IN such cases, CURRENT_USER() is expanded where and as needed:
#
# 				) DROP_USER
#
# 				) RENAME_USER
#
# 				) GRANT
#
# 				) REVOKE
#
# 				) CREATE_FUNCTION
#
# 				) CREATE_PROCEDURE
#
# 				) CREATE_TRIGGER
#
# 				) CREATE_EVENT
#
# 				) CREATE_VIEW
#
# 				) ALTER_EVENT
#
# 				) ALTER_VIEW
#
# 				) SET_PASSWORD
#
# 			For information about the implications that this expansion of CURRENT_USER() 
# 			has for replication, see SECTION 17.4.1.8, "REPLICATION OF CURRENT_USER()"
#
# 		) DATABASE()
#
# 			Returns the default (current) database name as a string in the utf8 character set.
#
# 			If there is no default database, DATABASE() returns NULL.
#
# 			Within a stored routine, the default database is the database that the routine is associated with,
# 			which is not necessarily the same as the database that is the default in the calling context.
#
# 				SELECT DATABASE();
# 					-> 'test'
#
# 			If there is no default database, DATABASE() returns NULL
#
# 		) FOUND_ROWS()
#
# 			A SELECT statement may include a LIMIT clause to restrict the number of rows the
# 			server returns to the client.
#
# 			In some cases, it is desirable to know how many rows the statement would have returned
# 			without the LIMIT, but without running the statement again.
#
# 			To obtain this row count, include an SQL_CALC_FOUND_ROWS option in
# 			the SELECT statement, and then invoke FOUND_ROWS() afterward:
#
# 				SELECT SQL_CALC_FOUND_ROWS * FROM tbl_name
# 					WHERE id > 100 LIMIT 10;
# 				SELECT FOUND_ROWS();
#
# 			The second SELECT returns a number indicating how many rows the first SELECT
# 			would have returned had it been written without the LIMIT clause.
#
# 			In the absence of the SQL_CALC_FOUND_ROWS option in the most recent successful
# 			SELECT statement, FOUND_ROWS() returns the number of rows in the result set
# 			returned by that statement.
#
# 			If the statement includes a LIMIT clause, FOUND_ROWS() returns the number of
# 			rows up to the limit.
#
# 			For example, FOUND_ROWS() returns 10 or 60, respectivelly, if the statement
# 			includes LIMIT 10 or LIMIT 50, 10
#
# 			The row count available through FOUND_ROWS() is transient and not intended to be
# 			available past the statement following the SELECT SQL_CALC_FOUND_ROWS statement.
#
# 			If you need to refer to the value later, save it:
#
# 				SELECT SQL_CALC_FOUND_ROWS * FROM ---;
# 				SET @rows = FOUND_ROWS();
#
# 			if you are using SELECT SQL_CALC_FOUND_ROWS, MySQL must calculate how many rows
# 			are in the full result set.
#
# 			However, this is faster than running the query again without LIMIT, because the
# 			result set need not be sent to the client.
#
# 			SQL_CALC_FOUND_ROWS and FOUND_ROWS() can be useful in situations when you want to
# 			restrict the number of rows that a query returns, but also determine the
# 			number of rows in the full result set without running the query again.
#
# 			An example is a Web script that presents a paged display containing links
# 			to the pages that show other sections of a search result.
#
# 			Using FOUND_ROWS() enables you to determine how many other pages are needed
# 			for the rest of hte result.
#
# 			The use of SQL_CALC_FOUND_ROWS and FOUND_ROWS() is more complex for UNION statements
# 			than for simple SELECT statements, because LIMIT may occur at multiple places
# 			in a UNION.
#
# 			It may be applied to individual SELECT statements in the UNION, or global
# 			to the UNION result as a whole.
#
# 			The intent of SQL_CALC_FOUND_ROWS for UNION is that it should return the row count
# 			that would be returned without a global LIMIT.
#
# 			The conditions for use of SQL_CALC_FOUND_ROWS with UNION are:
#
# 				) The SQL_CALC_FOUND_ROWS keyword must appear in the first SELECT of the UNION.
#
# 				) The value of FOUND_ROWS() is exact only if UNION_ALL is used.
#
# 					If UNION without ALL is used, duplicate removal occurs and the
# 					value of FOUND_ROWS() is only approximate.
#
# 				) If no LIMIT is present in the UNION, SQL_CALC_FOUND_ROWS is ignored and
# 					returns the number of rows in the temporary table that is created
# 					to process the UNION.
#
# 			Beyond the cases described here, the behavior of FOUND_ROWS() is undefined (for example,
# 			its value following a SELECT statement that fails with an error)
#
# 			IMPORTANT:
#
# 				FOUND_ROWS() is not replicated reliably using statement-based replication.
#
# 				This function is automatically replicated using row-based replication.
#
# 		) ICU_VERSION()
#
# 			The version of the INternational Components for Unicode (ICU) library used to support
# 			regular expression operations
#
# 			(See SECTION 12.5.2, "REGULAR EXPRESSIONS")
#
# 			This function is primarily intended for use in test cases.
#
# 		) LAST_INSERT_ID(), LAST_INSERT_ID(expr)
#
# 			With no argument, LAST_INSERT_ID() returns a BIGINT UNSIGNED (64-bit) value
# 			representing the first automatically generated value successfully inserted
# 			for an AUTO_INCREMENT column as a result of the most recently executed 
# 			INSERT statement.
#
# 			The value of LAST_INSERT_ID() remains unchanged if no rows are successfully
# 			inserted.
#
# 			With an argument, LAST_INSERT_ID() returns an unsigned integer.
#
# 			For example, after inserting a row that generates an AUTO_INCREMENT value,
# 			you can get the value like this:
#
# 				SELECT LAST_INSERT_ID();
# 					-> 195
#
# 			The currently executing staetment does not affect the value of LAST_INSERT_ID()
#
# 			Suppose that you generate an AUTO_INCREMENT value with one statement, and then
# 			refer to LAST_INSERT_ID() in a multiple-row INSERT statement that inserts rows
# 			into a table with its own AUTO_INCREMENT column.
#
# 			The value of LAST_INSERT_ID() will remain stable in the second statement;
# 			Its value for the second and later rows is not affected by the earlier row
# 			insertions.
#
# 			(However, if you mix references to LAST_INSERT_ID() and LAST_INSERT_ID(expr),
# 				the effect is undefined)
#
# 			If the previous statement returned an error, the value of LAST_INSERT_ID() is
# 			undefined.
#
# 			For transactional tables, if the statement is rolled back due to an error, the
# 			value of LAST_INSERT_ID() is left undefined.
#
# 			For manual ROLLBACK, the value of LAST_INSERT_ID() is not restored to that
# 			before the transaction;
#
# 			it remains as it was at the point of the ROLLBACK.
#
# 			Within the body of a stored routine (procedure or function) or a trigger
# 			, the value of LAST_INSERT_ID() changes the same way as for statements
# 			executed outside the body of these kinds of objects.
#
# 			The effect of a stored routine or trigger upon the value of LAST_INSERT_ID()
# 			that is seen by following statements depends on the kind of routine:
#
# 				) If a stored procedure executes statements that change the value of
# 					LAST_INSERT_ID(), the changed value is seen by statements that follow
# 					the procedure call.
#
# 				) For stored functions and triggers that change the value, the value 
# 					is restored when the function or trigger ends, so following
# 					statements will not see a changed value.
#
# 			The ID that was generated is maintained in the server on a per-connection basis.
#
# 			This means that the value returned by the function to a given client is the first
# 			AUTO_INCREMENT value generated for the most recent statement affecting an
# 			AUTO_INCREMENT column by that client.
#
# 			This value cannot be affected by other clients, even if they generate
# 			AUTO_INCREMENT values of their own.
#
# 			This behavior ensures that each client can retrieve its own ID without 
# 			concern for the activity of other clients, and without the need for locks
# 			or transactions.
#
# 			The value of LAST_INSERT_ID() is not changed if you set the AUTO_INCREMENT
# 			column of a row to a non-"magic" value (that is, a value that is not NULL and
# 			not 0)
#
# 			IMPORTANT:
#
# 				If you insert multiple rows using a single INSERT statement, LAST_INSERT_ID()
# 				returns the value generated for the first inserted row only.
#
# 				The reason for this is to make it possible to reproduce easily the same
# 				INSERT statement against some other server.
#
# 			For example:
#
# 				USE test;
#
# 				CREATE TABLE t (
# 				id INT AUTO_INCREMENT NOT NULL PRIMARY KEY,
# 				name VARCHAR(10) NOT NULL
# 				);
#
# 				INSERT INTO t VALUES (NULL, 'Bob');
#
# 				SELECT * FROM t;
# 				+-------+--------------+
# 				| id 	  | name 		  |
# 				+-------+--------------+
# 				| 1 	  | Bob  		  |
# 				+-------+--------------+
#
# 				SELECT LAST_INSERT_ID();
# 				+----------------------+
# 				| LAST_INSERT_ID() 	  |
# 				+----------------------+
# 				| 						1 	  |
# 				+----------------------+
#
# 				INSERT INTO t VALUES
# 					(NULL, 'Mary'), (NULL, 'Jane'), (NULL, 'Lisa');
#
# 				SELECT * FROM t;
# 				+------+----------+
# 				| id   | name 		|
# 				+------+----------+
# 				| 1 	 | Bob 		|
# 				| 2 	 | Mary 	   |
# 				| 3 	 | Jane 		|
# 				| 4 	 | Lisa 		|
# 				+------+----------+
#
# 				SELECT LAST_INSERT_ID();
# 				+------------------------+
# 				| LAST_INSERT_ID() 		 |
# 				+------------------------+
# 				| 			2 					 |
# 				+------------------------+
#
# 			ALthough the second INSERT statement inserted three new rows into t, the ID
# 			generated for the first of these rows was 2, and it is this value that is returned
# 			by LAST_INSERT_ID() for the following SELECT statement.
#
# 			If you use INSERT_IGNORE and the row is ignored, the LAST_INSERT_ID() remains
# 			unchanged from the current value (or 0 is returned if the connection has not yet performed
# 			a successful INSERT) and, for non-transactional tables, the AUTO_INCREMENT counter is not incremented.
#
# 			For InnoDB tables, the AUTO_INCREMENT counter is incremented if innodb_autoinc_lock_mode is set
# 			to 1 or 2, as demonstrated in the following example:
#
# 				USE test;
#
# 				SELECT @@innodb_autoinc_lock_mode;
# 				+----------------------------------+
# 				| @@innodb_autoinc_lock_mode 		  |
# 				+----------------------------------+
# 				| 								1 			  |
# 				+----------------------------------+
#
# 				CREATE TABLE `t` (
# 					`id` INT(11) NOT NULL AUTO_INCREMENT,
# 					`val` INT(11) DEFAULT NULL,
# 				PRIMARY KEY (`id`),
# 				UNIQUE KEY `i1` (`val`)
# 				) ENGINE=InnoDB DEFAULT CHARSET=latin1;
#
# 				# INsert two rows
#
# 				INSERT INTO t (val) VALUES (1), (2);
#
# 				# With auto_increment_offset=1, the inserted rows
# 				# result in an AUTO_INCREMENT value of 3
#
# 				SHOW CREATE TABLE t\G
# 				************************* 1. row ************************
# 						Table: t
# 				Create Table: CREATE TABLE `t` (
# 					`id` int(11) NOT NULL AUTO_INCREMENT,
# 					`val` int(11) DEFAULT NULL,
# 				  PRIMARY KEY (`id`),
# 				  UNIQUE KEY `i1` (`val`)
# 				 ) ENGINE=InnoDB AUTO_INCREMENT=3 DEFAULT CHARSET=latin1
#
# 				# LAST_INSERT_ID() returns the first automatically generated value
# 				# that is successfully inserted for the AUTO_INCREMENT column
#
# 				SELECT LAST_INSERT_ID();
# 				+-------------------------+
# 				| LAST_INSERT_ID() 		  |
# 				+-------------------------+
# 				| 				1 				  |
# 				+-------------------------+
#
# 				# The attempted insertion of duplicate rows fail but errors are ignored
#
# 				INSERT IGNORE INTO t (val) VALUES (1), (2);
# 				Query OK, 0 rows affected (0.00 sec)
# 				Records: 2 Duplicates: 2 Warnings: 0
#
# 				# With innodb_autoinc_lock_mode=1, the AUTO_INCREMENT counter
# 				# is incremented for the ignored rows
#
# 				SHOW CREATE TABLE t\G
# 				************************** 1. row **********************
# 						Table: t
# 				Create Table: CREATE TABLE `t` (
# 					`id` int(11) NOT NULL AUTO_INCREMENT,
# 					`val` int(11) DEFAULT NULL,
# 					PRIMARY KEY (`id`),
# 					UNIQUE KEY `i1` (`val`)
# 				) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=latin1
#
# 				# The LAST_INSERT_ID is unchanged because the previous insert was unsuccessful
#
# 				SELECT LAST_INSERT_ID();
# 				+----------------------+
# 				| LAST_INSERT_ID() 	  |
# 				+----------------------+
# 				| 				1 			  |
# 				+----------------------+
#
# 			For more information, see SECTION 15.6.1.4, "AUTO_INCREMENT HANDLING IN INNODB"
#
# 			If expr is given as an argument to LAST_INSERT_ID(), the value of the argument is returned by
# 			the function and is remembered as the next value to be returned by LAST_INSERT_ID().
#
# 			This can be used to simulate sequences:
#
# 				a. Create a table to hold the sequence counter and initialize it:
#
# 					CREATE TABLE sequence (id INT NOT NULL);
# 					INSERT INTO sequence VALUES (0);
#
# 				b. Use the table to generate sequence numbers like this:
#
# 					UPDATE sequence SET id=LAST_INSERT_ID(id+1);
# 					SELECT LAST_INSERT_ID();
#
# 			The UPDATE statement increments the sequence counter and causes the
# 			next call to LAST_INSERT_ID() to return the updated value.
#
# 			The SELECT statement retrieves that value.
#
# 			The mysql_insert_id() C API function can also be used to get hte value.
#
# 			See SECTION 28.7.7.38, "MYSQL_INSERT_ID()"
#
# 		You can generate sequences without calling LAST_INSERT_ID(), but the utility of
# 		using the function this way is that the ID value is maintained in the server
# 		as the last automatically generated value.
#
# 		It is multi-user safe because multiple clients can issue the UPDATE statement
# 		and get their own sequence value with the SELECT statement (or mysql_insert_id()),
# 		without affecting or being affected by other clients that generate their own
# 		sequence values.
#
# 		Note that mysql_insert_id() is only updated afer INSERT and UPDATE statements,
# 		so you cannot use the C API function to retrieve the value for LAST_INSERT_ID(expr)
# 		after executing other SQL statements like SELECT or SET.
#
# 	) ROLES_GRAPHML()
#
# 		Returns a utf8 string containing a GraphML document representing memory role subgraphs.
#
# 		The ROLE_ADMIN or SUPER privilege is required to see content in the <graphml> element.
#
# 		Otherwise, the result shows only an empty element:
#
# 			SELECT ROLES_GRAPHML();
# 			+---------------------------------------------------+
# 			| ROLES_GRAPHML() 									       |
# 			+---------------------------------------------------+
# 			| <?xml version="1.0" encoding="UTF-8"?><graphml/>	 |
# 			+---------------------------------------------------+
#
# 	) ROW_COUNT()
#
# 		ROW_COUNT() returns a value as follows:
#
# 			) DDL statements: 0. This applies to statements such as CREATE_TABLE or DROP_TABLE
#
# 			) DML statements other than SELECT:
#
# 				The number of affected rows.
#
# 				This applies to statements such as UPDATE, INSERT, or DELETE (as before),
# 				but now also to statements such as ALTER_TABLE and LOAD_DATA_INFILE.
#
# 			) SELECT: -1 if hte statement returns a result set, or the number of rows "affected" if it does not.
#
# 				For example, for SELECT * FROM t1, ROW_COUNT() returns -1
#
# 				For SELECT * FROM t1 INTO OUTFILE 'file_name', ROW_COUNT() returns the
# 				number of rows written to the file.
#
# 			) SIGNAL statements: 0
#
# 		For UPDATE statements, the affected-rows value by default is the number of rows
# 		actually changed.
#
# 		If you specify the CLIENT_FOUND_ROWS flag to mysql_real_connect() when connecting to
# 		mysqld, the affected-rows value is the number of rows "found", that is, mathced by the WHERE clause.
#
# 		For REPLACE statements, the affected-rows value is 2 if the new row replaced an old row,
# 		because in this case, one row was inserted after the duplicate was deleted.
#
# 		For INSERT_---_ON_DUPLICATE_KEY_UPDATE statements, the affected-rows value per row is 1 if
# 		the row is inserted as a new row, 2 if an existing row is updated, and 0 if an existing row
# 		is set to its current values.
#
# 		If you specify the CLIENT_FOUND_ROWS flag, the affected-rows value is 1 (not 0) if an existing
# 		row is set to its current values.
#
# 		The ROW_COUNT() value is similar to the value from the mysql_affected_rows() C API function
# 		and the row count that the mysql client displays following statement execution.
#
# 			INSERT INTO t VALUES(1),(2),(3);
# 			Query OK, 3 rows affected (0.00 sec)
# 			Records: 3 DUplicates: 0 Warnings: 0
#
# 			SELECT ROW_COUNT();
# 			+-----------------+
# 			| ROW_COUNT() 	   |
# 			+-----------------+
# 			| 			3 			|
# 			+-----------------+
# 			1 row in set (0.00 sec)
#
# 			DELETE FROM t WHERE i IN(1,2);
# 			Query OK, 2 rows affected (0.00 sec)
#
# 			SELECT ROW_COUNT();
# 			+----------------+
# 			| ROW_COUNT() 	  |
# 			+----------------+
# 			| 			2 		  |
# 			+----------------+
# 			1 row in set (0.00 sec)
#
# 		
# 		IMPORTANT:
#
# 			ROW_COUNT() is not replicated reliably using statement-based replication.
#
# 			This function is automatically replicated using row-based replication.
#
# 	) SCHEMA()
#
# 		This function is a synonym for DATABASE()
#
# 	) SESSION_USER()
#
# 		SESSION_USER() is a synonym for USER()
#
# 	) SYSTEM_USER()
#
# 		SYSTEM_USER() is a synonym for USER()
#
# 	) USER()
#
# 		Returns the current MySQL user name and host name as a string in the utf8 character set.
#
# 			SELECT USER();
# 				-> 'davida@localhost'
#
# 		The value indicates the user name you specified when connecting to the server, and the client
# 		host from which you connected.
#
# 		The value can be different from that of CURRENT_USER()
#
# 	) VERSION()
#
# 		Returns a string that indicates the MySQL server version.
#
# 		The string uses the utf8 character set.
#
# 		The value might have a suffix in addition to the version number.
#
# 		See the description of the version system variable in SECTION 5.1.8, "SERVER SYSTEM VARIABLES"
#
# 		This function is unsafe for statement-based replication.
# 		A warning is logged if you use this function when binlog_format is set to STATEMENT.
#
# 			SELECT VERSION();
# 				-> '8.0.15-standard'
#
# 12.16 SPATIAL ANALYSIS FUNCTIONS
#
# MySQL provides functions to perform various operations on spatial data.
#
# These functions can be grouped into several major categories according to the type
# of operation they perform:
#
# 		) Functions that create geometries in various formats (WKT, WKB, internal)
#
# 		) Functions that convert geometries between formats
#
# 		) Functions that access qualitative or quantitative properties of a geometry
#
# 		) Functions that describe relations between two geometries
#
# 		) Functions that create new geometries from existing ones
#
# For general background about MySQL support for using spatial data, see SECTION 11.5, "SPATIAL DATA TYPES"
#
# 12.16.1 SPATIAL FUNCTION REFERENCE
#
# The following table lists each spatial function and provides a short description of each one.
#
# TABLE 12.20 SPATIAL FUNCTIONS
#
# 		NAME 											DESCRIPTION
#
# GeomCollection() 		Construct geometry collection from geometries
#
# GeometryCollection() 	Construct geometry collection from geometries
#
# LineString() 			Construct LineString from Point values
#
# MBRContains() 			Whether MBR of one geometry contains MBR of another
#
# MBRCoveredBy() 			Whether one MBR is covered by another
#
# MBRCovers() 				Whether one MBR covers another
#
# MBRDisjoint() 			Whether MBRs of two geometries are disjoint
#
# MBREquals() 				Whether MBRs of two geometries are equal
#
# MBRIntersects() 		Whether MBRs of two geometries intersect
#
# MBROverlaps() 			Whether MBRs of two geometries overlap
#
# MBRTouches() 			Whether MBRs of two geometries touch
#
# MBRWithin() 				Whether MBR of one geometry is within MBR of another
#
# MultiLineString() 		Construct MultiLineString from LineString values
#
# MultiPoint() 			Construct MultiPoint from Point values
#
# MultiPolygon() 			Construct MultiPolygon from Polygon values
#
# Point() 					Construct point from coordinates
#
# Polygon() 				Construct Polygon from LineString arguments
#
# ST_Area() 				Return Polygon or MultiPolygon area
#
# ST_AsBinary(), 			Convert from internal geometry format to WKB
# ST_AsWKB()	
#
# ST_AsGeoJSON() 			Generate GeoJSON object from geometry
#
# ST_AsText(), 			Convert from internal geometry format to WKT
# ST_ASWKT()
#
# ST_Buffer() 				Return geometry of points within given distance from geometry
#
# ST_Buffer_Strategy() 	Produce strategy option for ST_Buffer()
#
# ST_Centroid() 			Return centroid as a point
#
# ST_Contains() 			Whether one geometry contains another
#
# ST_ConvexHull() 		Return convex hull of geometry
#
# ST_Crosses() 			Whether one geometry crosses another
#
# ST_Difference() 		Return point set difference of two geometries
#
# ST_Dimension() 			Dimension of geometry
#
# ST_Disjoint() 			Whether one geometry is disjoint from another
#
# ST_Distance() 			The distance of one geometry from another
#
# ST_Distance_Sphere() 	Minimum distance on earth between two geometries
#
# ST_EndPoint() 			End Point of LineString
#
# ST_Envelope() 			Return MBR of geometry
#
# ST_Equals() 				Whether one geometry is equal to another
#
# ST_ExteriorRing() 		Return exterior ring of Polygon
#
# ST_GeoHash() 			Produce a geohash value
#
# ST_GeomCollFromText(), 				Return geometry collection from WKT
# ST_GeometryCollectionFromText(),
# ST_GeomCollFromTxt()
#
# ST_GeomCollFromWKB(), 				Return Geometry collection from WKB
# ST_GeometryCollectionFromWKB()
#
# ST_GeometryN() 							Return N-th geometry from geometry collection
#
# ST_GeometryType() 						Return name of geometry type
#
# ST_GeomFromGeoJSON() 					Generate geometry from GeoJSON object
#
# ST_GeomFromText(), 					Return Geometry from WKT
# ST_GeometryFromText()
#
# ST_GeomFromWKB(), 						Return geometry from WKB
# ST_GeometryFromWKB()
#
# ST_InteriorRingN() 					Return N-th interior ring of Polygon
#
# ST_Intersection() 						Return point set intersection of two geometries
#
# ST_Intersects() 						Whether one geometry intersects another
#
# ST_IsClosed() 							Whether a geometry is closed and simple
#
# ST_IsEmpty() 							Placeholder function
#
# ST_IsSimple() 							Whether a geometry is simple
#
# ST_IsValid() 							Whether a geometry is valid
#
# ST_LatFromGeoHash() 					Return latitude from geohash value
#
# ST_Latitude() 							Return latitude of Point
#
# ST_Length() 								Return length of LineString
#
# ST_LineFromText(), 					Construct LineString from WKT
# ST_LineStringFromText()
#
# ST_LineFromWKB(), 						Construct LineString from WKB
# ST_LineStringFromWKB()
#
# ST_LongFromGeoHash() 					Return longitude from geohash value
#
# ST_Longitude() 							Return longitude of Point
#
# ST_MakeEnvelope() 						Rectangle around two points
#
# ST_MLineFromText(), 					Construct MultiLineString from WKT
# ST_MultiLineStringFromText()
#
# ST_MLineFromWKB(), 					Construct MultiLineString from WKB
# ST_MultiLineStringFromWKB()
#
# ST_MPointFromText(), 					Construct MultiPoint from WKT
# ST_MultiPointFromText()
#
# ST_MPointFromWKB(), 					Construct multiPoint from WKB
# ST_MultiPointFromWKB()
#
# ST_MPolyFromText(), 					Construct MultiPolygon from WKT
# ST_MultiPolygonFromText()
#
# ST_MPolyFromWKB(), 					Construct MultiPolygon from WKB
# ST_MultiPolygonFromWKB()
#
# ST_NumGeometries() 					Return number of geometries in geometry collection
#
# ST_NumINteriorRing(), 				Return number of interior rings in Polygon
# ST_NumINteriorRings()
#
# ST_NumPoints() 							Return number of points in LineString
#
# ST_Overlaps() 							Whether one geometry overlaps another
#
# ST_PointFromGeoHash() 				Convert geohash value to POINT value
#
# ST_PointFromText() 					Construct Point from WKT
#
# ST_PointFromWKB() 						Construct Point from WKB
#
# ST_PointN() 								Return N-th point from LineString
#
# ST_PolyFromText(), 					Construct Polygon from WKT
# ST_PolygonFromText()
#
# ST_PolyFromWKB(), 						Construct Polygon from WKB
# ST_PolygonFromWKB()
#
# ST_Simplify() 							Returned simplified geometry
#
# ST_SRID() 								Return spatial reference system ID for geometry
#
# ST_StartPoint() 						Start Point of LineString
#
# ST_SwapXY() 								Return argument with X/Y coordinates swapped
#
# ST_SymDifference() 					return point set symmetric difference of two geometries
#
# ST_Touches() 							Whether one geometry touches another
#
# ST_Transform() 							Transform coordinates of geometry
#
# ST_Union() 								Return point set union of two geometries
#
# ST_Validate() 							Return validated geometry
#
# ST_Within() 								Whether one geometry is within another
#
# ST_X() 									Return X coordinate of Point
#
# ST_Y() 									Return Y coordinate of Point
#
# 12.16.2 ARGUMENT HANDLING BY SPATIAL FUNCTIONS
#
# Spatial values, or geometries, have the properties described at SECTION 11.5.2.2, "GEOMETRY CLASS"
#
# The following discussion list general spatial function argument-handling characteristics.
#
# Specific functions or groups of functions may have additional argument-handling characteristics,
# as discussed in the sections where those function descriptions occur.
#
# Spatial functions are defined only for valid geometry values.
#
# The spatial reference identifier (SRID) of a geometry identifies the coordinate space
# in which the geoemtry is defined.
#
# In MySQL, the SRID value is an integer associated with the geometry value.
#
# The maximum usable SRID value is 2^32-1
#
# If a larger value is given, only the lower 32 bits are used.
#
# SRID 0 represents an infinite flat Cartesian plane with no units assigned to its axes.
#
# To ensure SRID 0 behavior, create geometry values using SRID 0.
#
# SRID 0 is the default for new geometry values if no SRID is specified.
#
# Geometry values produced by any spatial function inherit the SRID of the geometry
# arguments.
#
# Spatial functions that take multiple geometry arguments require those arguments to have
# the same SRID values (that is, same value in the lower 32 bits)
#
# Assuming equal SRIDs, spatial functions do nothing with them after performing the equality
# check; geometry values are implicitly handled using Cartesian coordinates (SRID 0)
#
# If a spatial function returns ER_GIS_DIFFERENT_SRIDS, it means that the geometry arguments
# did not all have the same SRID.
#
# You must modify them to have the same SRID.
#
# The Open Geospatial Consortium guidelines require that input polygons already be closed,
# so unclosed polygons are rejected as invalid rather than being closed.
#
# Empty geometry-collection handling is as follows:
#
# 		An empty WKT input geometry collection may be specified as
# 		'GEOMETRYCOLLECTION()'
#
# This is also the output WKT resulting from a spatial operation that
# produces an empty geometry collection.
#
# During parsing of a nested geometry collection, teh collection is flattened
# and its basic components are used in various GIS operations to compute results.
#
# This provides additional flexibility to users because it is unnecessary to be concerned
# about the uniqueness of geometry data.
#
# Nested geometry collections may be produced from nested GIS function calls
# without having to be explicitly flattened first.
#
# 12.16.3 FUNCTIONS THAT CREATE GEOMETRY VALUES FROM WKT VALUES
#
# These functions take as arguments a Well-Known Text (WKT) representation and, optionally
# a spatial reference system identifier (SRID)
#
# They return the corresponding geometry.
#
# For a description of WKT format, see Well-Known Text (WKT) Format
#
# Functions in this section detect arguments in either Cartesian or geographical spatial
# reference systems (SRSs), and return results appropriate to the SRs.
#
# ST_GeomFromText() accepts a WKT value of any geometry type as its first argument.
#
# Other functions provide type-specific construction functions for construction
# of geometry values of each geometry type.
#
# Functions such as ST_MPointFromText() and ST_GeomFromText() that accept WKT-format
# representations of MultiPoint values permit individual points within values
# to be surrounded by parentheses.
#
# For example,, both of the following function calls are valid:
#
# 		ST_MPointFromText('MULTIPOINT (1 1, 2 2, 3 3)')
# 		ST_MPointFromText('MULTIPOINT ((1 1), (2 2), (3 3))')
#
# Functions such as ST_GeomFromText() that accept WKT geometry collection arguments
# understand both OpenGIS 'GEOMETRYCOLLECTION EMPTY' standard syntax and 
# MYSQL 'GEOMETRYCOLLECTION()' nonstandard syntax.
#
# Functions such as ST_AsWKT() that produce WKT values produce 'GEOMETRYCOLLECTION EMPTY'
# standard syntax:
#
# 		SET @s1 = ST_GeomFromText('GEOMETRYCOLLECTION()');
# 		SET @s2 = ST_GeomFromText('GEOMETRYCOLLECTION EMPTY');
# 		SELECT ST_AsWKT(@s1), ST_AsWKT(@s2);
#
# 		+----------------------------+----------------------------------+
# 		| ST_AsWKT(@s1) 				  | ST_AsWKT(@s2) 						 |
# 		+----------------------------+----------------------------------+
# 		| GEOMETRYCOLLECTION EMPTY   | GEOMETRYCOLLECTION EMPTY 			 |
# 		+----------------------------+----------------------------------+
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any geometry argument is NULL or is not a syntactically well-formed geometry,
# 			or if the SRID argument is NULL, the return value is NULL.
#
# 		) By default, geographic coordinates (latitude, longitude) are interpreted as in the order
# 			specified by the spatial reference system of geometry arguments.
#
# 			An optional options argument may be given to override the default axis order.
#
# 			options consists of a list of comma-separated key=value
#
# 			The only permitted key value is axis-order, with permitted values
# 			of lat-long, long-lat and srid-defined (the default)
#
# 			If the options argument is NULL, the return value is NULL.
#
# 			If the options argument is invalid, an error occurs to indicate why.
#
# 		) If an SRID argument refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs.
#
# 		) For geographic SRS geometry arguments, if any argument has a longitude or latitude that
# 			is out of range, an error occurs:
#
# 			) If a longitude value is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 			) If a latitude value is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 		Ranges shown are in degrees.
#
# 		If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 		The exact range limits deviate slightly due to floating-point arithmetic.
#
# These functions are available for creating geometries from WKT values:
#
# 		) ST_GeomCollFromText(wkt[, srid[, options]]),
# 			ST_GeometryCollectionFromText(wkt[, srid[, options]]),
# 			ST_GeomCollFromTxt(wkt[, srid[, options]])
#
# 			Constructs a GeometryCollection value using its WKT representation and SRID.
#
# 			These functions handle their arguments as described in the introduction to this section.
#
# 				SET @g = "MULTILINESTRING((10 10, 11 11), (9 9, 10 10))";
# 				SELECT ST_AsText(ST_GeomCollFromText(@g));
# 				+--------------------------------------------+
# 				| ST_AsText(ST_GeomCollFromText(@g)) 			|
# 				+--------------------------------------------+
# 				| MULTILINESTRING((10 10,11 11),(9 9,10 10)) |
# 				+--------------------------------------------+
#
# 		) ST_GeomFromText(wkt[, srid [, options]]),
# 			ST_GeometryFromText(wkt[, srid [, options]])
#
# 			Constructs a geometry value of any type using its WKT
# 			representation and SRID.
#
# 			These functions handle their arguments as described
# 			in the introduction to this section.
#
# 		) ST_LineFromText(wkt[, srid [, options]]),
# 			ST_LineStringFromText(wkt[, srid [, options]])
#
# 			Constructs a LineString value using its WKT representation
# 			and SRID.
#
# 			These functions handle their arguments as described in the
# 			introduction to this section.
#
# 		) ST_MLineFromText(wkt[, srid [, options]]),
# 			ST_MultiLineStringFromText(wkt[, srid [, options]])
#
# 			Constructs a MultiLineString value using its WKT representation
# 			and SRID.
#
# 			These functions handle their arguments as described in the intro
#
# 		) ST_MPointFromText(wkt[, srid[, options]]),
# 			ST_MultiPointFromText(wkt[, srid[, options]])
# 			
# 			Constructs a MultiPoint value using its WKT representation
# 				and SRID.
#
# 			These functions handle their arguments as described in the intro
#
# 		) ST_MPolyFromText(wkt[, srid[, options]]),
# 			ST_MultiPolygonFromText(wkt[, srid[, options]])
#
# 			Constructs a MultiPolygon value using its WKT representation
# 				and SRID.
#
# 			These functions handle their arguments as described in the intro
#
# 		) ST_PointFromText(wkt[, srid[, options]])
#
# 			Constructs a Point value using its WKT representation and SRID.
#
# 			ST_PointFromText() handles its arguments as described in the intro
#
# 		) ST_PolyFromText(wkt[, srid[, options]]),
# 			ST_PolygonFromText(wkt[, srid[, options]])
#
# 			Constructs a Polygon value using its WKT representation and SRID
#
# 			These functions handle their arguments as described in the intro.
#
# 12.16.4 FUNCTIONS THAT CREATE GEOMETRY VALUES FROM WKB VALUES
#
# These functions take as arguments a BLOB containing a Well-Known Binary (WKB) representation,
# and, optionally, a spatial reference system identifier (SRID)
#
# They return the corresponding geometry.
#
# For a description of WKB format, see Well-Known Binary (WKB) Format
#
# Functions in this section detect arguments in either Cartesian or geographical
# spatial reference systems (SRSs), and return results appropriate to the SRS.
#
# ST_GeomFromWKB() accepts a WKB value of any geometry type as its first argument.
#
# Other functions provide type-specific construction functions for construction of
# geometry values ofe ach geometry type.
#
# Prior to 8.0, these functions also accepted geometry objects as returned by the functions
# in SECTION 12.16.5, "MYSQL-SPECIFIC FUNCTIONS THAT CREATE GEOMETRY VALUES"
#
# Geometry arguments are no longer permitted and produce an error.
#
# to migrate calls from using geometry arguments to using WKB arguments,
# follow these guidelines:
#
# 		) Rewrite constructs such as ST_GeomFromWKB(Point(0, 0)) as Point(0, 0)
#
# 		) Rewrite constructs such as ST_GeomFromWKB(Point(0, 0), 4326) as ST_SRID(Point(0, 0), 4326)
# 			or ST_GeomFromWKB(ST_AsWKB(Point(0, 0)), 4326)
#
# UNless otherwise specified,, functions in this section handle their arguments as follows:
#
# 		) If the WKB or SRID argument is NULL, the return value is NULL
#
# 		) By default, geographic coordinates (latitude, longitude) are interpreted as in the
# 			order specified by the spatial reference system of geometry arguments.
#
# 			An optional options argument may be given to override the default axis order.
#
# 			Options consists of a list of comma-separated key=value.
#
# 			The only permitted key value is axis-order,, with permitted values of
# 			lat-long, long-lat and srid-defined (the default)
#
# 			If the options argument is NULL, the return value is NULL.
#
# 			If the options argument is invalid, an error occurs to indicate why.
#
# 		) If an SRID argument refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs.
#
# 		) For geogrpahic SRS geometry arguments, if any argument has a longitude or latitude
# 			that is out of range, an error occurs:
#
# 				) If a longitude value is not in the range (-180, 180], an ER_lONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If a latitude value is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 			Ranges shown are in degrees.
#
# 			If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 			The exact range limits deviate slightly due to floating-point arithemtic.
#
#  these functions are available for creating geometries from WKB values:
#
# 		) ST_GeomCollFromWKB(wkb[, srid[, optional]]),
# 			ST_GeometryCollectionFromWKB(wkb[, srid [, options]])
#
# 			Constructs a GeometryCollection value using its WKB representation and SRID.
#
# 			These functions handle their arguments as described in the intro.
#
# 		) ST_GeomFromWKB(wkb[, srid[, options]]),
# 			ST_GeometryFromWKB(wkb[, srid [, options]])
#
# 			Constructs a geometry value of any type using its WKB representation and SRID.
#
# 			These functions handle their arguments as descriebd in the intro.
#
# 		) ST_LineFromWKB(wkb[,, srid[, options]]),
# 			ST_LineStringFromWKB(wkb[, srid [, options]])
#
# 			Constructs a LineString value using its WKB representation and SRID.
#
# 			These functions handle their arguments as described in the intro.
#
# 		) ST_MLineFromWKB(wkb[, srid [, options]]),
# 			ST_MultiLineStringFromWKB(wkb[, srid[, options]])
#
# 			Consturcts a MultiLineString value using its WKB representation and SRID.
#
# 			These functions handle their arguments as described in the intro.
#
# 		) ST_MPointFromWKB(wkb[,, srid[, options]]),
# 			ST_MultiPointFromWKB(wkb[, srid[, options]])
#
# 			Constructs a MultiPoint value using its WKB representation and SRID.
#
# 			These functions handle their arguments as described in the intro.
#
# 		) ST_MPolyFromWKB(wkb[, srid[, options]]),
# 			ST_MultiPolygonFromWKB(wkb[, srid[, options]])
#
# 			Constructs a MultiPolygon value using its WKB representation and SRID.
#
# 			These functions handle their arguments as described in the intro.
#
# 		) ST_PointFromWKB(wkb[, srid[, options]])
# 	
# 			Constructs a Point value using its WKB representation and SRID.
#
# 			ST_PointFromWKB() handles its arguments as described in the intro.
#
# 		) ST_PolyFromWKB(wkb[, srid[, options]]),
# 			ST_PolygonFromWKB(wkb[, srid [, options]])
#
# 			Constructs a Polygon value using its WKB representation and SRID.
#
# 			These functions handle their args as described in the intro.
#
# 12.16.5 MYSQL-SPECIFIC FUNCTIONS THAT CREATE GEOMETRY VALUES
#
# MySQL provides a set of useful nonstandard functions for creating geometry values.
#
# The functions described in this section are MySQL extensions to the OpenGIS specificaiton.
#
# These functions produce geometry objects from either WKB values or geometry objects ass arguments.
#
# If any arugment is not a proper WKB or geometry representaiton of their proper
# object type, the return value is NULl.
#
# For example, you can insert the geometry return value from Point() directly into a POINT column:
#
# 		INSERT INTO t1 (pt_col) VALUES(Point(1,2));
#
# ) GeomCollection(g [, g] ---)
#
# 		COnstructs a GeomCollection value from the geometry arguments.
#
# 		GeomCollection() returns all the proper geometries contained in teh arguments even if
# 		a nonsupported geometry is present.
#
# 		GeomCollection() with no arguments is permitted as a way to create an empty geometry.
#
# 		Also, functions such as ST_GeomFromText() that accept WKT geometry collection arguments
# 		understand both OpenGIS 'GEOMETRYCOLLECTION EMPTY' standard syntax and MySQL
# 		'GEOMETRYCOLLECTION()' nonstandard syntax.
#
# 		GeomCollection() and GeometryCollection() are synonymous, with GeomCollection()
# 		the preferred function.
#
# ) GeometryCollection(g [, g] ---)
#
# 		Constructs a GeomCollection value from the geometry arguments:
#
# 		GeometryCollection() returns all the proper geometries contained in teh arguments
# 		even if a nonsupported geometry is present.
#
# 		GeometryCollection() with no arguments is permitted as a way to create an empty geoemtry.
#
# 		Also, functions such as ST_GeomFromText() that accept WKT geometry collection arguments
# 		understand both OpenGIS 'GEOMETRYCOLLECTION EMPTY' standard syntax and MySQL 
# 		'GEOMETRYCOLLECTION()' nonstandard syntax.
#
# 		GeomCollection() and GeometryCollection() are synonymous with GeomCollection() the preferred
# 		function.
#
# ) LineString(pt [, pt] ---)
#
# 		Constructs a LineString value from a number of Point or WKB Point arguments.
#
# 		if the number of arguments is less than two, the return value is NULL.
#
# ) MultiLineString(ls [,, ls] ---)
#
# 		Constructs a MultiLineString value using LineString or WKB LineSTring arguments
#
# ) MultiPoint(pt [, pt2] ---)
#
# 		Constructs a MultiPoint value using Point or WKB Point arguments.
#
# ) MultiPolygon(poly [, poly] ---)
#
# 		Constructs a MultiPolygon value from a set of Polygon or WKB Polygon arguments.
#
# ) Point(x, y)
#
# 		Constructs a Point using its coordinates
#
# ) Polygon(ls [, ls] ----)
#
# 		Constructs a Polygon value from a number of LineString or WKB LineString arguments.
#
# 		If any argument does not represent a LinearRing(that is, not a closed and simple LineString),
# 		the return value is NULL
#
# 12.16.6 GEOMETRY FORMAT CONVERSION FUNCTIONS
#
# MySQL supports the functions listed in this section for converting geometry values
# from internal geometry format to WKT or WKB format, or for swapping the order of X
# and Y coordinates.
#
# There are also functions to convert a string from WKT or WKB format to internal
# geometry format.
#
# See SECTION 12.16.3, "FUNCTIONS THAT CREATE GEOMETRY VALUES FROM WKT VALUES"
#
# and
#
# SECTION 12.16.4, "FUNCTIONS THAT CREATE GEOMETRY VALUES FROM WKB VALUES"
#
# Functions such as ST_GeomFromText() that accept WKT geometry collection arguments
# understand both OpenGIS 'GEOMETRYCOLLECTION EMPTY' standard syntax and MySQL
# 'GEOMETRYCOLLECTION()' nonstandard syntax.
#
# Another way to produce an empty geometry collection is by calling GeometryCollection()
# with no arguments.
#
# Functions usch as ST_AsWKT() that produce WKT values produce 'GEOMETRYCOLLECTION EMPTY'
# standard syntax:
#
# 		SET @s1 = ST_GeomFromText('GEOMETRYCOLLECTION()');
# 		SET @s2 = ST_GeomFromText('GEOMETRYCOLLECTION EMPTY');
# 		SELECT ST_AsWKT(@s1), ST_AsWKT(@s2);
#
# 		+---------------------------+--------------------------+
# 		| ST_AsWKT(@s1) 				 | ST_AsWKT(@s2) 			    |
# 		+---------------------------+--------------------------+
# 		| GEOMETRYCOLLECTION EMPTY  | GEOMETRYCOLLECTION EMPTY |
# 		+---------------------------+--------------------------+
#
# 		SELECT ST_AsWKT(GeomCollection());
# 		+--------------------------------+
# 		| ST_AsWKT(GeomCollection()) 		|
# 		+--------------------------------+
# 		| GEOMETRYCOLLECTION EMPTY 		|
# 		+--------------------------------+
#
# Unless otherwise specified, funcitons in this section handle their arguments as follows:
#
# 	) If any argument is NULL, the return value is NULL
#
# 	) If any geometry argument is not a syntactically well-formed geometry,
# 		an ER_GIS_INVALID_DATA error occurs.
#
# 	) If any geometry argument is an undefined spatial reference system, the axes
# 		are output in the order they appear in the geometry and an
# 		ER_WARN_SRS_NOT_FOUND_AXIS_ORDER warning occurs.
#
# 	) By default, geographic coordinates (latitude, longitude) are interpreted as in the order
# 		specified by the spatial reference system of geometry arguments.
#
# 		An optional options argument may be given to override the default axis order.
#
# 		options consist of a list of comma-separated key=value 
#
# 		The only permitted kkey value is axis-order, with permitted values of 
# 		lat-long, long-lat and srid-defined (the default)
#
# 		If the options argument is NULL, the return value is NULL.
#
# 		If the options argument is invalid, an error occurs to indicate why.
#
# 	) otherwise, the return value is non-NULL
#
# These functions are available for format conversions
# or coordinate swapping:
#
# 		) ST_AsBinary(g [, options]),
# 			ST_AsWKB(g [, options])
#
# 			Converts a value in internal geometry format to its WKB
# 			representation and returns the binary result.
#
# 			The function return value has geogrpahic coordinates (latitude, longitude)
# 			in the order specified by the spatial reference system that applies
# 			to the geometry argument.
#
# 			An optional options argument may be given to override the default axis order.
#
# 			ST_AsBinary() and ST_AsWKB() handle their arguments as described in the
# 			intro to this section.
#
# 				SET @g = ST_LineFromText('LINESTRING(0 5, 5 10, 10 15)', 4326);
# 				SELECT ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g)));
#
# 				+-------------------------------------------+
# 				| ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g)))   |
# 				+-------------------------------------------+
# 				| LINESTRING(5 0, 10 5, 15 10) 				  |
# 				+-------------------------------------------+
#
# 				SELECT ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g, 'axis-order=long-lat')));
# 				+----------------------------------------------------------------+
# 				| ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g, 'axis-order=long-lat'))) |
# 				+----------------------------------------------------------------+
# 				| LINESTRING(0 5, 5 10, 10 15) 											  |
# 				+----------------------------------------------------------------+
#
# 				SELECT ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g, 'axis-order=lat-long')));
# 				+----------------------------------------------------------------+
# 				| ST_AsText(ST_GeomFromWKB(ST_AsWKB(@g, 'axis-order=lat-long'))) |
# 				+----------------------------------------------------------------+
# 				| LINESTRING(5 0, 10 5, 15 10) 											  |
# 				+----------------------------------------------------------------+
#
# 	) ST_AsText(g [, options]),
# 		ST_AsWKT(g [, options])
#
# 		Converts a value in intenral geometry format to its wkt representation
# 		and returns the string result.
#
# 		The function return value has geographic coordinates (latitude, longitude) in the
# 		order specified by the spatial reference system that applies to the geometry argument.
#
# 		An optional options argument may be given to override the default axis order.
#
# 		ST_AsText() and ST_AsWKT() handle their arguments as described in the intro to this section.
#
# 			SET @g = 'LineString(1 1,2 2,3 3)';
# 			SELECT ST_AsText(ST_GeomFromText(@g));
# 			+--------------------------------------+
# 			| ST_AsText(ST_GeomFromText(@g)) 		|
# 			+--------------------------------------+
# 			| LINESTRING(1 1,2 2,3 3) 					|
# 			+--------------------------------------+
#
# 		Output for MultiPoint values includes parentheses around each point.
# 		For example:
#
# 			SELECT ST_AsText(ST_GeomFromText(@mp));
# 			+-------------------------------------+
# 			| ST_AsText(ST_GeomFromText(@mp)) 	  |
# 			+-------------------------------------+
# 			| MULTIPOINT((1 1),(2 2),(3 3)) 		  |
# 			+-------------------------------------+
#
# 	) ST_SwapXY(g)
#
# 		Accepts an argument in internal geometry format, swaps the X and Y values
# 		of each coordinate pair within the geometry, and returns the result.
#
# 		ST_SwapXY() handles its arguments as described in the introduction to this section.
#
# 			SET @g = ST_LineFromText('LINESTRING(0 5,5 10,10 15)');
# 			SELECT ST_AsText(@g);
# 			+----------------------------------+
# 			| ST_AsText(@g) 						  |
# 			+----------------------------------+
# 			| LINESTRING(0 5,5 10,10 15) 		  |
# 			+----------------------------------+
#
# 			SELECT ST_AsText(ST_SwapXY(@g));
# 			+-------------------------------+
# 			| ST_AsText(ST_SwapXY(@g)) 	  |
# 			+-------------------------------+
# 			| LINESTRING(5 0,10 5, 15 10)   |
# 			+-------------------------------+
#
# 12.16.7 GEOMETRY PROPERTY FUNCTIONS
#
# Each function that belongs to this group takes a geometry value as its argument
# and returns some quantitive or qualitative property of the geometry.
#
# Some functions restrict their argument type.
#
# Such functions return NULL if hte argument is of an incorrect geometry type.
#
# For example, the ST_Area() polygon function returns NULL if the object type
# is neither Polygon nor MultiPolygon
#
# 12.16.7.1 GENERAL GEOMETRY PROPERTY FUNCTIONS
#
# The functions listed in this section do not restrict their argument and accept
# a geometry value of any type.
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any argument is NULL, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs.
#
# 		) If any SRID argument is not within the range of a 32-bit unsigned integer, an ER_DATA_OUT_OF_RANGE error occurs.
#
# 		) If any SRID argument refers to an undefined SRS, an ER_SRS_NOT_FOUND error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These functions are available for obtaining geometry properties:
#
# 	) ST_Dimension(g)
#
# 		Returns the inherent dimension of the geometry value g.
#
# 		The dimension can be -1, 0, 1 or 2.
#
# 		The meaning of these values is given in 11.5.2.2, "GEOMETRY CLASS"
#
# 		ST_Dimension() handles its arguments as described in the introduction to this section.
#
# 			SELECT ST_Dimension(ST_GeomFromText('LineString(1 1,2 2)'));
# 			+-----------------------------------------------------------+
# 			| ST_Dimension(ST_GeomFromText('LineString(1 1,2 2)')) 		|
# 			+-----------------------------------------------------------+
# 			| 																	1 		   |
# 			+-----------------------------------------------------------+
#
# 	) ST_Envelope(g)
#
# 		Returns the minimum bounding rectangle (MBR) for the geometry value g.
#
# 		The result is returned as a Polygon value that is defined by the corner points
# 		of hte bounding box:
#
# 			POLYGON((MINX MINY, MAXX MINY, MAXX MAXY, MINX MAXY, MINX, MINY))
#
# 			SELECT ST_AsText(ST_Envelope(ST_GeomFromText('LineString(1 1,2 2)')));
# 			+--------------------------------------------------------------------+
# 			| ST_AsText(ST_Envelope(ST_GeomFromText('LineString(1 1,2 2)'))) 	   |
# 			+--------------------------------------------------------------------+
# 			| POLYGON((1 1,2 1,2 2,1 2,1 1)) 												|
# 			+--------------------------------------------------------------------+
#
# 		If the argument is a point or a vertical or horizontal line segment,, ST_Envelope()
# 		returns the point or the line segment as its MBR rather than returning an invalid
# 		polygon:
#
# 			SELECT ST_AsText(ST_Envelope(ST_GeomFromText('LineString(1 1,1 2)')));
# 			+---------------------------------------------------------------------+
# 			| ST_AsText(ST_Envelope(ST_GeomFromText('LineString(1 1,1 2)'))) 		 |
# 			+---------------------------------------------------------------------+
# 			| LINESTRING(1 1,1 2) 																 |
# 			+---------------------------------------------------------------------+
#
# 		ST_Envelope() handles its arguments as described in the intro to this section,
# 		with this exception:
#
# 			) If the geometry has an SRID value for a geographic spatial reference system (SRS),
# 				An ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 	) ST_GeometryType(g)
#
# 		Returns a binary string indicating the name of the geometry type of which the geometry instance
# 		g is a member.
#
# 		The name corresponds to one of the instanstiable Geometry subclasses:
#
# 		ST_GeometryType() handles its arguments as described in the introduction to this section.
#
# 			SELECT ST_GeometryType(ST_GeomFromText('POINT(1 1)'));
# 			+----------------------------------------------------+
# 			| ST_GeometryType(ST_GeomFromText('POINT(1 1)')) 	  |
# 			+----------------------------------------------------+
# 			| POINT 															  |
# 			+----------------------------------------------------+
#
# 	) ST_IsEmpty(g)
#
# 		This function is a placeholder that returns 1 for an empty geometry collection value or 0 otherwise.
#
# 		The only valid empty geometry is represented in the form of an empty geometry collection value.
# 		MySQL does not support GIS EMPTY values such as POINT EMPTY.
#
# 		ST_IsEmpty() handles its arguments as described in the introduction to this section.
#
# 	) ST_IsSimple(g)
#
# 		Returns 1 if the geometry value g is simple according to the ISO SQL/MM Part 3: Spatial standard.
#
# 		ST_IsSimple() returns 0 if the argument is not simple.
#
# 		The descriptions of the instantiable geometric classes given under SECTION 11.5.2, "THE OPENGIS GEOMETRY MODEL"
# 		include the specific conditions that cause class instances to be classified as not simple.
#
# 		ST_IsSimple() handles its arguments as described in the introduction to this section, with this exception:
#
# 			) If the geometry has a geographic SRS with a longitude or latitude that is out of range, an error occurs:
#
# 				) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If any latitude argument is not in the range (-90,90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 		Ranges shown are in degrees. The exact range limits deviate slightly due to floating-point arithmetic.
#
# 	) ST_SRID(g[, srid])
#
# 		With a single argument representing a valid geometry object g, ST_SRID() returns an integer
# 		indicating the ID of the spatial reference system (SRS) associated with g.
#
# 		With the optional second argument representing a valid SRID value, ST_SRID() returns an object
# 		with the same type as its first argument with an SRID value equal to the second argument.
#
# 		THis only sets the SRID value of the object; it does not perform any transformation of coordinate
# 		values.
#
# 		ST_SRID() handles its arguments as described in the introduction to this section, with this exception:
#
# 			) For the single-argument syntax, ST_SRID() returns the geometry SRID even if it refers to
# 				an undefined SRS.
#
# 				An ER_SRS_NOT_FOUND error does not occur.
#
# 		ST_SRID(g, target_srid) and ST_Transform(g, target_srid) differ as follows:
#
# 			) ST_SRID() changes the geometry SRID value without transforming its coordinates.
#
# 			) ST_Transform() transforms the geometry coordinates in addition to changing its SRID value.
#
# 				SET @g = ST_GeomFromText('LineString(1 1,2 2)', 0);
# 				SELECT ST_SRID(@g);
# 				+----------------------+
# 				| ST_SRID(@g) 			  |
# 				+----------------------+
# 				| 				0 			  |
# 				+----------------------+
#
# 				SET @g = ST_SRID(@g, 4326);
# 				SELECT ST_SRID(@g);
# 				+------------------+
# 				| ST_SRID(@g) 		 |
# 				+------------------+
# 				| 		4326 			 |
# 				+------------------+
#
# 			It is possible to create a geometry in a particular SRID by passing to ST_SRID() the result of one
# 			of the MySQL-specific functions for creating spatial values, along with an SRID value.
#
# 			For example:
#
# 				SET @g1 = ST_SRID(Point(1, 1), 4326);
#
# 			However, that method creates the geometry in SRID 0, then casts it to SRID 4326 (WGS 84)
#
# 			A preferable alternative is to create the geometry with the correct spatial reference system
# 			to begin with.
#
# 			For example:
#
# 				SET @g1 = ST_PointFromText('POINT(1 1)', 4326);
# 				SET @g1 = ST_GeomFromText('POINT(1 1)', 4326);
#
# 			The two-argument form of ST_SRID() is useful for tasks such as correcting or changing the
# 			SRS of geometries that have an incorrect SRID.
#
# 12.16.7.2 POINT PROPERTY FUNCTIONS
#
# A Point consists of X and Y coordinates, which may be obtained using the ST_X()
# and ST_Y() functions, respectively.
#
# These functions also permit an optional second argument that specifies an X or Y
# coordinate value, in which case the function result is the Point object from
# the first argument with the appropriate coordinate modified to be equal to the
# second argument
#
# For Point objects that have a geographic spatial reference system (SRS), the longitude
# and latitude may be obtained using the ST_Longitude() and ST_Latitude()
# functions, respectively.
#
# These functions also permit an optional second argument that specifies a longitude
# or latitude value, in which case the function result is the Point object from the
# first argument with the longitude or latitude modified to be equal to the second argument.
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any argument is NULL, the return value is NULL
#
# 		) If any geometry argument is a valid geometry but not a Point object, an ER_UNEXPECTED_GEOMETRY_TYPE
# 			error occurs.
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs.
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs.
#
# 		) If an X or Y coordinate argument is provided and the value is -inf, +inf, or NaN, an ER_DATA_OUT_OF_RANGE
# 			error occurs.
#
# 		) If a longitude or latitude argument is out of range, an error occurs:
#
# 			) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 			) If any latitude argument is not in the range [-90,90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 			Ranges shown are in degrees.
#
# 			The exact range limits deviate slightly due to floating-point arithmetic.
#
# 		) Othherwise, the return value is non-NULL
#
# These functions are available for obtaining point properties:
#
# 		) ST_Latitude(p [, new latitude val])
#
# 			With a single argument representing a valid Point object p that has a geographic
# 			spatial reference system (SRS), ST_Latitude() returns the latitude value of p as
# 			a double-precision number.
#
# 			With the optional second argument representing a valid latitude value, ST_Latitude()
# 			returns a Point object like the first argument with its latitude equal to the second argument.
#
# 			ST_Latitude() handles its arguments as described in the introduction to this section,
# 			with the addition that if the Point object is valid but does not have a geographic SRS,
# 			an ER_SRS_NOT_GEOGRAPHIC error occurs.
#
# 				SET @pt = ST_GeomFromText('POINT(45 90)', 4326);
# 				SELECT ST_Latitude(@pt);
# 				+-----------------------+
# 				| ST_Latitude(@pt) 		|
# 				+-----------------------+
# 				| 					45 		|
# 				+-----------------------+
#
# 				SELECT ST_AsText(ST_Latitude(@pt, 10));
# 				+---------------------------------+
# 				| ST_AsText(ST_Latitude(@pt, 10)) |	
# 				+---------------------------------+
# 				| POINT(10 90) 						 |
# 				+---------------------------------+
#
# 			This function was added in MySQL 8.0.12
#
# 		) ST_Longitude(p [, new longitude val])
#
# 			With a single argument representing a valid Point object p that has a geopgrahic
# 			spatial reference system (SRS), ST_Longitude() returns the longitude value of p
# 			as a double-precision number.
#
# 			With the optional second argument representing a valid longitude value,
# 			ST_Longitude() returns a Point object like the first argument with its longitude
# 			equal to the second argument.
#
# 			ST_Longitude() handles its arguments as described in the introduction to this section,
# 			with the addition that if the Point object is valid but does not have a geopgrahic
# 			SRS, an ER_SRS_NOT_GEOGRAPHIC error occurs.
#
# 				SET @pt = ST_GeomFromText('POINT(45 90)', 4326);
# 				SELECT ST_Longitude(@pt);
# 				+------------------------+
# 				| ST_Longitude(@pt) 		 |
# 				+------------------------+
# 				| 					90 		 |
# 				+------------------------+
#
# 				SELECT ST_AsText(ST_Longitude(@pt, 10));
# 				+----------------------------------+
# 				| ST_AsText(ST_Longitude(@pt, 10)) |
# 				+----------------------------------+
# 				| POINT(45 10) 						  |
# 				+----------------------------------+
#
# 			THis function was added in MySQL 8.0.12
#
# 		) ST_X(p[, new x val])
#
# 			With a single argument representing a valid Point object p,,
# 			ST_X() returns the X-coordinate value of p as a double-precision number.
#
# 			As of MySQL 8.0.12, the X coordinate is considered to refer to the axis
# 			that appear first in the Point spatial reference system (SRS) definition.
#
# 			With the optional second argument, ST_X() returns a Point object like the first argument
# 			with its X coordinate equal to the second argument.
#
# 			As of MySQL 8.0.12, if the Point object has a geographic SRS, the second argument
# 			must be in the proper range for longitude or latitude values.
#
# 			ST_X() handles its arguments as described in the introduction to this section.
#
# 				SELECT ST_X(Point(56.7, 53.34));
# 				+--------------------------------+
# 				| ST_X(Point(56.7, 53.34)) 		|
# 				+--------------------------------+
# 				| 							56.7 		   |
# 				+--------------------------------+
#
# 				SELECT ST_AsText(ST_X(Point(56.7, 53.34), 10.5));
# 				+--------------------------------------------+
# 				| ST_AsText(ST_X(Point(56.7, 53.34), 10.5))  |
# 				+--------------------------------------------+
# 				| POINT(10.5 53.34) 									|
# 				+--------------------------------------------+
#
# 		) ST_Y(p[, new y val])
#
# 			With a single argument representing a valid Point object p, ST_Y() returns the
# 			Y-coordinate value of p as a double-precision number.
#
# 			As of MySQL 8.0.12, the Y coordinate is considered to refer to the axis
# 			that appears second in the Point spatial reference system (SRS) definition.
#
# 			With the optional second argument, ST_Y() returns a Point object like the first
# 			argument with its Y coordinate equal to the second argument.
#
# 			AS of MySQL 8.0.12,, if the Point object has a geographic SRS, the second argument
# 			must be in the proper range for longitude or latitude values.
#
# 			ST_Y handles its arguments as described in the intro to this section.
#
# 				SELECT ST_Y(Point(56.7, 53.34));
# 				+------------------------------+
# 				| ST_Y(Point(56.7, 53.34)) 	 |
# 				+------------------------------+
# 				| 						53.34 		 |
# 				+------------------------------+
#
# 				SELECT ST_AsText(ST_Y(Point(56.7, 53.34), 10.5));
# 				+-------------------------------------------+
# 				| ST_AsText(ST_Y(Point(56.7, 53.34), 10.5)) |
# 				+-------------------------------------------+
# 				| POINT(56.7 10.5) 								  |
# 				+-------------------------------------------+
#
# 12.16.7.3 LINESTRING AND MULTILINESTRING PROPERTY FUNCTIONS
#
# A LineString consists of Point values.
#
# You can extract particular points of a LineString, count the number of points
# that it contains, or obtain its length.
#
# Some functions in this section also work for MultiLineString values.
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any argument is NULL or any geometry argument is an empty geometry, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs.
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system (SRS), an ER_SRS_NOT_FOUND error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These functions are available for obtaining linestring properties:
#
# 	) ST_EndPoint(ls)
#
# 		Returns the Point that is the endpoint of the LineString value ls.
#
# 		ST_EndPoint() handles its arguments as described in the intro to this section.
#
# 			SET @ls = 'LineString(1 1,2 2,3 3)';
# 			SELECT ST_AsText(ST_EndPoint(ST_GeomFromText(@ls)));
# 			+----------------------------------------------+
# 			| ST_AsText(ST_EndPoint(ST_GeomFromText(@ls))) |
# 			+----------------------------------------------+
# 			| POINT(3 3) 											  |
# 			+----------------------------------------------+
#
# 	) ST_IsClosed(ls)
#
# 		For a LineString value ls, ST_IsClosed() returns 1 if ls is closed
# 		(that is, its ST_StartPoint() and ST_EndPoint() values are the same)
#
# 		For a MultiLineString value ls, ST_IsClosed() returns 1 if ls is closed
# 		(that is, the ST_StartPoint() and ST_EndPoint() values are the same for 
# 		each LineString in ls)
#
# 		ST_IsClosed() returns 0 if ls is not closed, and NULL if ls is NULL.
#
# 		ST_IsClosed() handles its arguments as described in the intro to this section,
# 		with this exception:
#
# 			) If the geometry has an SRID value for a geographic spatial reference system (SRS),
# 				an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 				SET @ls1 = 'LineString(1 1,2 2,3 3,2 2)';
# 				SET @ls2 = 'LineString(1 1,2 2,3 3,1 1)';
#
# 				SELECT ST_IsClosed(ST_GeomFromText(@ls1));
# 				+----------------------------------------+
# 				| ST_IsClosed(ST_GeomFromText(@ls1)) 	  |
# 				+----------------------------------------+
# 				| 							0 						  |
# 				+----------------------------------------+
#
# 				SELECT ST_IsClosed(ST_GeomFromText(@ls2));
# 				+----------------------------------------+
# 				| ST_IsClosed(ST_GeomFromText(@ls2)) 	  |
# 				+----------------------------------------+
# 				| 							1 						  |
# 				+----------------------------------------+
#
# 				SET @ls3 = 'MultiLineString((1 1,2 2,3 3), (4 4,5 5))';
# 				
# 				SELECT ST_IsClosed(ST_GeomFromText(@ls3));
# 				+----------------------------------------+
# 				| ST_IsClosed(ST_GeomFromText(@ls3)) 	  |
# 				+----------------------------------------+
# 				| 							0 						  |
# 				+----------------------------------------+
#
# 	) ST_Length(ls)
#
# 		Returns a double-precision number indicating the length of the LineString or MultiLineString
# 		value ls in its associated spatial reference.
#
# 		The length of a MultiLineString value is equal to the sum of the lengths of its elements.
#
# 		ST_Length() computes a result as follows:
#
# 			) if the geometry is a valid LineString in a Cartesian SRS, the return value is the Cartesian length of the geometry.
#
# 			) If the geometry is a valid MultiLineString in a Cartesian SRS, the return value is the sum of the Cartesian lengths
# 				of its elements.
#
# 			) If the geometry is a valid LineString in a geographic SRS, the return value is the geodetic length of the geometry
# 				in that SRS, in meters.
#
# 			) If the geometry is a valid MultiLineString in a geographic SRS, the return value is the sum of the geodetic lengths
# 				of its elements in that SRS, in meters.
#
# 		ST_Length() handles its arguments as described in the introduction to this section, with these exceptions:
#
# 			) If the geometry is not a LineString or MultiLineString, the return value is NULL
#
# 			) If the geometry is geometrically invalid, either the result is an undefined length (that is,
# 				can be any number), or an error occurs.
#
# 			) If the length computation result is +inf, an ER_DATA_OUT_OF_RANGE error occurs.
#
# 			) If the geometry has a geographic SRS with a longitude or latitude that is out of range,
# 				an error occurs:
#
# 				) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If any latitude argument is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs
#
# 			Ranges shown are in degrees. The exact range limits deviate slightly due to floating-point arithmetic.
#
# 				SET @ls = 'LineString(1 1,2 2,3 3)';
# 				SELECT ST_Length(ST_GeomFromText(@ls));
# 				+---------------------------------+
# 				| ST_Length(ST_GeomFromText(@ls)) |
# 				+---------------------------------+
# 				| 				2.82842712 etc. 		 |
# 				+---------------------------------+
#
# 				SET @mls = 'MultiLineString((1 1,2 2,3 3), (4 4,5 5))';
# 				SELECT ST_Length(ST_GeomFromText(@mls));
# 				+---------------------------------+
# 				| ST_Length(ST_GeomFromText(@mls))|
# 				+---------------------------------+
# 				| 				4.24264068 etc. 		 |
# 				+---------------------------------+
#
# 	) ST_NumPoints(ls)
#
# 		Returns the number of Point objects in the LineString value ls.
#
# 		ST_NumPoints() handles its arguments as described in the intro to this section.
#
# 			SET @ls = 'LineString(1 1,2 2,3 3)';
# 			SELECT ST_NumPoints(ST_GeomFromText(@ls));
# 			+------------------------------------------+
# 			| ST_NumPoints(ST_GeomFromText(@ls)) 		 |
# 			+------------------------------------------+
# 			| 							3 							 |
# 			+------------------------------------------+
#
# 	) ST_PointN(ls, N)
#
# 		Returns the N-th Point in the LineString value ls.
#
# 		Points are numbered beginning with 1.
#
# 		ST_PointN() handles its arguments as described in the intro
# 		to this section.
#
# 			SET @ls = 'LineString(1 1,2 2,3 3)';
# 			SELECT ST_AsText(ST_PointN(ST_GeomFromText(@ls),2));
# 			+----------------------------------------------+
# 			| ST_AsText(ST_PointN(ST_GeomFromText(@ls),2)) |
# 			+----------------------------------------------+
# 			| POINT(2 2) 											  |
# 			+----------------------------------------------+
#
# 	) ST_StartPoint(ls)
#
# 		Returns the Point that is the start point of the LineString value ls.
#
# 		ST_StartPoint() handles its arguments as described in the introduction to this section.
#
# 			SET @ls = 'LineString(1 1,2 2,3 3)';
# 			SELECT ST_AsText(ST_StartPoint(ST_GeomFromText(@ls)));
# 			+-----------------------------------------------+
# 			| ST_AsText(ST_StartPoint(ST_GeomFromText(@ls)))|
# 			+-----------------------------------------------+
# 			| POINT(1 1) 												|
# 			+-----------------------------------------------+
#
# 12.16.7.4 POLYGON AND MULTIPOLYGON PROPERTY FUNCTIONS
#
# Functions in this section return properties of Polygon or MultiPolygon
# values.
#
# Unless otherwise specified, functions in this section handle their arguments
# as follows:
#
# 		) If any argument is NULL or any geometry argument is an empty geometry, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system
# 			(SRS), an ER_SRS_NOT_FOUND error occurs.
#
# 		) For functions that take multiple geometry arguments, if those arguments do not have the same SRID,
# 			an ER_GIS_DIFFERENT_SRIDS error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These functions are available for obtaining polygon properties:
#
# 		) ST_Area((poly|mpoly))
#
# 			Returns a double-precision number indicating the area of the Polygon or MultiPolygon
# 			argument, as measured in its spatial reference system.
#
# 			As of MySQL 8.0.13, ST_Area() handles its arguments as described in the introduction
# 			to this section, with these exceptions:
#
# 				) If the geometry is geometrically invalid, either the result is an undefined area (that is, it can be any number), or an error occurs.
#
# 				) If the geometry is valid but is not a Polygon or MultiPolygon object, an ER_UNEXPECTED_GEOMETRY_TYPE error occurs.
#
# 				) If the geometry is a valid Polygon in a Cartesian SRS, the result is the Cartesian area of the Polygon.
#
# 				) If the geometry is a valid MultiPolygon in a Cartesian SRS, the result is the sum of the Cartesian area of the polygons.
#
# 				) If the geometry is a valid Polygon in a geographic SRS, the result is the geodetic area of the polygon in that SRS, in square meters.
#
# 				) If the geometry is a valid MultiPolygon in a geographic SRS, the result is the sum of geodetic area of the polygons in that SRS,
# 					in square meters.
#
# 				) If an area computation results in +inf, an ER_DATA_OUT_OF_RANGE error occurs.
#
# 				) If the geometry has a geographic SRS with a longitude or latitude that is out of range,
# 					an error occurs:
#
# 					) If any longitude argument is not in the range(-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 					) If any latitude argument is not in the range [-90,90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 				Ranges shown are in degrees. The exact range limits deviate slightly due to floating-point arithmetic.
#
# 			Prior to MySQL 8.0.13, ST_Area() handles its arguments as described in the intro to this section,
# 			with these exceptions:
#
# 				) For arguments of dimension 0 or 1, the result is 0
#
# 				) If a geometry is empty, the return value is 0 rather than NULL
#
# 				) For a geometry collection, teh result is the sum of the area values of all components.
#
# 					If the geometry collection is empty, its area is returned as 0.
#
# 				) If the geometry has an SRID value for a geographic spatial reference system (SRS),
# 					an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 					SET @poly = 
# 						'Polygon((0 0,0 3,3 0,0 0),(1 1,1 2,2 1,1 1))';
# 					SELECT ST_Area(ST_GeomFromText(@poly));
# 					+---------------------------------------+
# 					| ST_Area(ST_GeomFromText(@poly)) 		 |
# 					+---------------------------------------+
# 					| 						4 							 |
# 					+---------------------------------------+
#
# 					SET @mpoly =
# 						'MultiPolygon((0 0,0 3,3 3,3 0,0 0), (1 1,1 2,2 2,2 1,1 1)))';
# 					SELECT ST_Area(ST_GeomFromText(@mpoly));
# 					+---------------------------------------+
# 					| ST_Area(ST_GeomFromText(@mpoly)) 		 |
# 					+---------------------------------------+
# 					| 					8 								 |
# 					+---------------------------------------+
#
# 		) ST_Centroid({poly|mpoly})
#
# 			Returns the mathematical centroid for the Polygon or MultiPolygon argument as a Pointt.
#
# 			The result is not guaranteed to be on the MultiPolygon.
#
# 			THis function processes geometry collections by computing the centroid point for components
# 			of highest dimension in the collection.
#
# 			Such components are extracted and made into a single MultiPolygon, MultiLineString or MultiPoint
# 			for centroid computation.
#
# 			ST_Centroid() handles its arguments as described in the intro, with these exceptions:
#
# 				) The return value is NULL for the additional condition that the argument is an empty geometry collection.
#
# 				) If the geometry has an SRID value for a geographic spatial reference system (SRS),
# 					an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 					SET @poly =
# 						ST_GeomFromText('POLYGON((0 0,10 0,10 10,0 10,0 0), (5 5,7 5,7 7,5 7,5 5))');
# 					SELECT ST_GeometryType(@poly), ST_AsText(ST_Centroid(@poly));
# 					+------------------------------+-------------------------------------+
# 					| ST_GeometryType(@poly) 		 | ST_AsText(ST_Centroid(@poly)) 		|
# 					+------------------------------+-------------------------------------+
# 					| POLYGON 							 | POINT(4.9583333 etc. 4.95833333 etc.|
# 					+------------------------------+-------------------------------------+
#
# 		) ST_ExteriorRing(poly)
#
# 			Returns the exterior ring of the Polygon value poly as a LineString
#
# 			ST_ExteriorRing() handles its arguments as described in the intro to this section.
#
# 				SET @poly =
# 					'Polygon((0 0,0 3,3 3,3 0,0 0),(1 1,1 2,2 2,2 1,1 1))';
# 				SELECT ST_AsText(ST_ExteriorRing(ST_GeomFromText(@poly)));
# 				+--------------------------------------------------------+
# 				| ST_AsText(ST_ExteriorRing(ST_GeomFromText(@poly))) 	   |
# 				+--------------------------------------------------------+
# 				| LINESTRING(0 0,0 3,3 3,3 0,0 0) 								|
# 				+--------------------------------------------------------+
#
# 		) ST_InteriorRingN(poly, N)
#
# 			Returns the N-th interior ring for the Polygon value poly as a LineString.
#
# 			Rings are numbered beginning with 1.
#
# 			ST_InteriorRingN() handles its arguments as described in the intro.
#
# 				SET @poly = 
# 					'Polygon((0 0,0 3,3 3,3 0,0 0),(1 1,1 2,2 2,2 1,1 1))';
# 				SELECT ST_AsText(ST_InteriorRingN(ST_GeomFromText(@poly),1));
# 				+-------------------------------------------------------+
# 				| ST_AsText(ST_InteriorRingN(ST_GeomFromText(@poly),1)) |
# 				+-------------------------------------------------------+
# 				| LINESTRING(1 1,1 2,2 2,2 1,1 1) 							  |
# 				+-------------------------------------------------------+
#
# 		) ST_NumInteriorRing(poly), ST_NumInteriorRings(poly)
#
# 			Returns the number of interior rings in the Polygon value poly.
#
# 			ST_NumInteriorRing() and ST_NuminteriorRings() handle their arguments
# 			as described in the intro.
#
# 				SET @poly =
# 					'Polygon((0 0,0 3,3 3,3 0,0 0), (1 1,1 2,2 2,2 1,1 1))';
# 				SELECT ST_NumInteriorRings(ST_GeomFromText(@poly));
# 				+---------------------------------------------------------+
# 				| ST_NumInteriorRings(ST_GeomFromText(@poly)) 				 |
# 				+---------------------------------------------------------+
# 				| 						1 													 |
# 				+---------------------------------------------------------+
#
# 12.16.7.5 GEOMETRYCOLLECTION PROPERTY FUNCTIONS
#
# These functions return properties of GeometryCollection values.
#
# Unless otherwise specified, functions in this section handle their arguments
# as follows:
#
# 		) If any argument is NULL or any geometry argument is an empty geometry, the return value is NULL
#
# 		) if any geometry is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system
# 			(SRS), an ER_SRS_NOT_FOUND error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These functions are available for obtaining geometry collection properties:
#
# 		) ST_GeometryN(gc, N)
#
# 			Returns the N-th geometry in the GeometryCollection value gc.
#
# 			Geometries are numbered beginning with 1.
#
# 			ST_GeometryN() handle its arguments as described in the intro.
#
# 				SET @gc = 'GeometryCollection(Point(1 1),LineString(2 2, 3 3))';
# 				SELECT ST_AsText(ST_GeometryN(ST_GeomFromText(@gc),1));
# 				+------------------------------------------------+
# 				| ST_AsText(ST_GeometryN(ST_GeomFromText(@gc),1))|
# 				+------------------------------------------------+
# 				| POINT(1 1) 												 |
# 				+------------------------------------------------+
#
# 		) ST_NumGeometries(gc)
#
# 			Returns the number of geometries in the GeometryCollection value gc.
#
# 			ST_NumGeometries() handles its arguments as descriebd in the intro.
#
# 				SET @gc = 'GeometryCollection(Point(1 1), LineString(2 2, 3 3))';
# 				SELECT ST_NumGeometries(ST_GeomFromText(@gc));
# 				+----------------------------------------+
# 				| ST_NumGeometries(ST_GeomFromText(@gc)) |
# 				+----------------------------------------+
# 				| 						2 							  |
# 				+----------------------------------------+
#
# 12.16.8 SPATIAL OPERATOR FUNCTIONS
#
# OpenGIS proposes a number of functions that can produce geometries.
#
# They are designed to implement spatial operators.
#
# These functions support all argument type combinations except those
# that are inapplicable according to the Open Geospatial Consortium spec.
#
# Unless otherwise specified, functions in this section handle their arguments
# as follows:
#
# 		) If any argument is NULL, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs.
#
# 		) If any geometry argument has an SRID value that refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs.
#
# 		) For functions that take multiple geometry arguments, if those arguments do not have the same SRID,
# 			an ER_GIS_DIFFERENT_SRIDS error occurs.
#
# 		) If any geometry argument has an SRID value for a geographic SRS; an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS
# 			error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# THese spatial operator functions are available:
#
# 		) ST_Buffer(g, d[, strategy1[, strategy2[, strategy3]]])
#
# 			Returns a geometry that represents all points whose distance from the geometry value
# 			g is less than or equal to a distance of d.
#
# 			If the geometry argument is empty, ST_Buffer() returns an empty geometry.
#
# 			If the distance is 0, ST_Buffer() returns the geometry argument unchanged:
#
# 				SET @pt = ST_GeomFromText('POINT(0 0)');
# 				SELECT ST_AsText(ST_Buffer(@pt, 0));
# 				+-----------------------------------+
# 				| ST_AsText(ST_Buffer(@pt, 0)) 		|
# 				+-----------------------------------+
# 				| POINT(0 0) 								|
# 				+-----------------------------------+
#
# 			ST_Buffer() supports negative distances for Polygon and MultiPolygon values,
# 			and for geometry collections containing Polygon or MultiPolygon values.
#
# 			The result may be an empty geometry.
#
# 			ST_Buffer() permits up to three optional strategy arguments following the distance
# 			argument.
#
# 			Strategies influence buffer computation.
#
# 			These arguments are byte string values produced by the ST_Buffer_Strategy()
# 			function, to be used for point, join and end strategies:
#
# 				) Point strategies apply to Point and MultiPoint geometries.
#
# 					If no point strategy is specified, the default is ST_Buffer_Strategy('point circle', 32)
#
# 				) Join strategies apply to LineString, MultiLineString, Polygon and MultiPolygon geometries.
#
# 					If no join strategy is specified, the default is ST_Buffer_Strategy('join round', 32)
#
# 				) End strategies apply to LineString and MultiLineString geometries.
#
# 					If no end strategy is specified, the default is ST_Buffer_Strategy('end round', 32)
#
# 			Up to one strategy of each type may be specified, and they may be given in any order.
#
# 			ST_Buffer() handles its arguments as described in the introduction to this section,
# 			with these exceptions:
#
# 				) For a negative distance for Point, MultiPoint, LineString, and MultiLineString values,
# 					and for geometry collations not containing any Polygon or MultiPolygon
# 					values, an ER_WRONG_ARGUMENTS error occurs.
#
# 				) If multiple strategies of a given type are specified, an ER_WRONG_ARGUMENTS error occurs.
#
# 					SET @pt = ST_GeomFromText('POINT(0 0)');
# 					SET @pt_strategy = ST_Buffer_Strategy('point_square');
# 					SELECT ST_AsText(ST_Buffer(@pt, 2, @pt_strategy));
# 					+--------------------------------------------+
# 					| ST_AsText(ST_Buffer(@pt, 2, @pt_strategy)) |
# 					+--------------------------------------------+
# 					| POLYGON((-2 -2,2 -2,2 2,-2 2,-2 -2)) 		|
# 					+--------------------------------------------+
#
# 					SET @ls = ST_GeomFromText('LINESTRING(0 0,0 5,5 5)');
# 					SET @end_strategy = ST_Buffer_Strategy('end_flat');
# 					SET @join_strategy = ST_Buffer_Strategy('join_round', 10);
# 					SELECT ST_AsText(ST_Buffer(@ls, 5, @end_strategy, @join_strategy))
# 					+-------------------------------------------------------------+
# 					| ST_AsText(ST_Buffer(@ls, 5, @end_strategy, @join_strategy)) |
# 					+-------------------------------------------------------------+
# 					| POLYGON((5 5,5 10,0 10, -3.5355 etc. 8.5355 etc.,  			  |
# 					| -5 5, -5 0,0 0,5 0,5 5)) 											  |
# 					+-------------------------------------------------------------+
#
# 	) ST_Buffer_Strategy(strategy[, points per circle])
#
# 		This function returns a strategy byte strings for use with ST_Buffer()
# 		to influence buffer computation.
#
# 		INformation about strats can be found in external parts.
#
# 		THe first argument must be a string indicating a strategy option:
#
# 			) For point strategies, permitted values are 'point_circle' and 'point_square'
#
# 			) For join strategies, permitted values are 'join_round' and 'join_miter'
#
# 			) For end strategies, permitted values are 'end_round' and 'end_flat'
#
# 		If the first argument is 'point_circle', 'join_round', 'join_miter' or
# 		'end_round', the points_per_circle argument must be given as a positive numeric value.
#
# 		The maximum points_per_circle value is the value of the max_points_in_geometry system variable.
#
# 		For examples, see the Description of ST_Buffer()
#
# 		ST_Buffer_Strategy() handles its arguments as described in the intro to this section,
# 		with these exceptions:
#
# 			) If any argument is invalid, an ER_WRONG_ARGUMENTS error occurs
#
# 			) If the first argument is 'point_square' or 'end_flat', the points_per_circle argument
# 				must not be given or an ER_WRONG_ARGUMENTS error occurs.
#
# 	) ST_ConvexHull(g)
#
# 		Returns a geometry that represents the convex hull of the geometry value g.
#
# 		This function computes a geometry's convex hull by first checking whether its vertex
# 		points are colinear.
#
# 		This function returns a linear hull if so, a polygon hull otherwise.
#
# 		THis function processes geometry collections by extracting all vertex points
# 		of all components of the collection, creating a MultiPoint value from them,
# 		and computing its convex hull.
#
# 		ST_ConvexHull() handles its arguments as described in the introduction, with this exception:
#
# 			) The return value is NULL ofr hte additional condition that hte argument is an empty geometry collection.
#
# 				SET @g = 'MULTIPOINT(5 0,25 0, 15 10,15 25)';
# 				SELECT ST_AsText(ST_ConvexHull(ST_GeomFromText(@g)));
# 				+-----------------------------------------------+
# 				| ST_AsText(ST_ConvexHull(ST_GeomFromText(@g))) |
# 				+-----------------------------------------------+
# 				| POLYGON((5 0,25 0, 15 25,5 0)) 					|
# 				+-----------------------------------------------+
#
# 	) ST_Difference(g1, g2)
#
# 		Returns a geometry that represents the point set difference of the geometry values
# 		g1 and g2
#
# 		ST_Difference() handles its arguments as described in the intro of this section.
#
# 			SET @g1 = Point(1,1), @g2 = Point(2,2);
# 			SELECT ST_AsText(ST_Difference(@g1, @g2));
# 			+----------------------------------------+
# 			| ST_AsText(ST_Difference(@g1, @g2)) 	  |
# 			+----------------------------------------+
# 			| POINT(1 1) 									  |
# 			+----------------------------------------+
#
# 	) ST_Intersection(g1, g2)
#
# 		Returns a geometry that represents the point set intersection
# 		of the geometry values g1 and g2
#
# 		ST_Intersection() handles its arguments as described in the intro to this section.
#
# 			SET @g1 = ST_GeomFromText('LineString(1 1, 3 3)');
# 			SET @g2 = ST_GeomFromText('LineString(1 3, 3 1)');
# 			SELECT ST_AsText(ST_Intersection(@g1, @g2));
# 			+------------------------------------------+
# 			| ST_AsText(ST_Intersection(@g1, @g2)) 	 |
# 			+------------------------------------------+
# 			| POINT(2 2)
#
# 	) ST_SymDifference(g1, g2)
#
# 		Returns a geometry that represents the point set symmetric difference
# 		of the geometry values g1 and g2, which is defined as:
#
# 			g1 symdifference g2 := (g1 union g2) difference (g1 intersection g2)
#
# 		Or, in function call notation:
#
# 			ST_SymDifference(g1, g2) = ST_Difference(ST_Union(g1, g2), ST_Intersection(g1, g2))
#
# 		ST_SymDifference() handles its arguments as described in the intro to this section.
#
# 			SET @g1 = Point(1,1), @g2 = Point(2,2);
# 			SELECT ST_AsText(ST_SymDifference(@g1, @g2));
# 			+--------------------------------------+
# 			| ST_AsText(ST_SymDifference(@g1, @g2))|
# 			+--------------------------------------+
# 			| MULTIPOINT((1 1),(2 2)) 				   |
# 			+--------------------------------------+
#
# 	) ST_Transform(g, target srid)
#
# 		Transforms a geometry from one spatial system (SRS) to another.
#
# 		The return value is a geometry of the same type as the input geometry with all coordinates
# 		transformed to the target SRID, target_srid.
#
# 		Transformation support is limited to geographic SRSs, unless the SRID of the geometry
# 		argument is the same as the target SRID value, in which case the return value
# 		is the input geometry for any valid SRS.
#
# 		ST_Transform() handles its arguments as described in the intro to this section,
# 		with these exceptions:
#
# 			) Geometry arguments that have an SRID value for a geographic SRS do not produce an error
#
# 			) If the geometry or target SRID argument has an SRID value that refers to an undefined
# 				spatial reference system (SRS), an ER_SRS_NOT_FOUND error occcurs.
#
# 			) If the geometry is in an SRS that ST_Transform() cannot transform from, an 
# 				ER_TRANSFORM_SOURCE_SRS_NOT_SUPPORTED error occurs.
#
# 			) If hte target SRID is in an SRS that ST_Transform() cannot transform to,
# 				an ER_TRANSFORM_TARGET_SRS_NOT_SUPPORTED error occurs.
#
# 			) If the geometry is in an SRS that is not WGS 84 and has no TOWGS84 clause,
# 			an ER_TRANSFORM_SOURCE_SRS_MISSING_TOWGS84 error occurs.
#
# 			) If the target SRID is in an SRS that is not WGS 84 and has no TOWGS84 clause,
# 				an ER_TRANSFORM_TARGET_SRS_MISSING_TOWGS84 error occurs.
#
# 		ST_SRID(g, target srid) and ST_Transform(g, target_srid) differ as follows:
#
# 			) ST_SRID() changes the geometry SRID value without transforming its coordinates.
#
# 			) ST_Transform() transforms the geometry coordinates in addition to changing its SRID value.
#
# 				SET @p = ST_GeomFromText('POINT(52.381389 13.064444)', 4326);
# 				SELECT ST_AsText(@p);
# 				+--------------------------------+
# 				| ST_AsText(@p) 					   |
# 				+--------------------------------+
# 				| POINT(52.381389 13.064444) 		|
# 				+--------------------------------+
#
# 				SET @p = ST_Transform(@p, 4230);
# 				SELECT ST_AsText(@p);
# 				+--------------------------------+
# 				| ST_AsText(@p) 					   |
# 				+--------------------------------+
# 				| POINT(52.387 etc. 13.065 etc.  |
# 				+--------------------------------+
#
# 	) ST_Union(g1, g2)
#
# 		Returns a geometry that represents the point set union of the geometry
# 		values g1 and g2
#
# 		ST_Union() handles its arguments as described in the intro to this section:
#
# 			SET @g1 = ST_GeomFromText('LineString(1 1, 3 3)');
# 			SET @g2 = ST_GeomFromText('LineString(1 3, 3 1)');
# 			SELECT ST_AsText(ST_Union(@g1, @g2));
# 			+--------------------------------------+
# 			| ST_AsText(ST_Union(@g1, @g2)) 	      |
# 			+--------------------------------------+
# 			| MULTILINESTRING((1 1,3 3),(1 3,3 1)) |
# 			+--------------------------------------+
#
# In addition, SECTION 12.16.7, "GEOMETRY PROPERTY FUNCTIONS",
# discusses several functions that construct new geometries form existing ones.
#
# See that section for descriptions of these functions:
#
# 		) ST_Envelope(g)
#
# 		) ST_StartPoint(ls)
#
# 		) ST_EndPoint(ls)
#
# 		) ST_PointN(ls, N)
#
# 		) ST_ExteriorRing(poly)
#
# 		) ST_INteriorRingN(poly, N)
#
# 		) ST_GeometryN(gc, N)
#
# 12.16.9 FUNCTIONS THAT TEST SPATIAL RELATIONS BETWEEN GEOMETRY OBJECTS
#
# The functions described in this section take two geometries as arguments and
# return a qualitative or quantitative relation between them.
#
# MySQL implements two sets of functions using function names defined by the
# OpenGIS specification.
#
# One set tests the relationship between two geometry values using
# precise object shapes, the other set uses minimum bounding rectangles (MBRs)
#
# 12.16.9.1 SPATIAL RELATION FUNCTIONS THAT USE OBJECT SHAPES
#
# The OpenGIS specification defines the following functions to test the relationship
# between two geometry values g1 and g2, using precise object shapes.
#
# The return values 1 and 0 indicate true/false, respectivelly.
#
# Except for ST_Distance(), which returns distance values.
#
# Functions in this section detect arguments in either Cartesian or geographical
# spatial reference systems (SRSs), and return results appropriate to the SRS.
#
# Unless otherwise specified, functions in this section handle their arguments
# as follows:
#
# 	) If any argument is NULL or any geometry argument is an empty geometry,
# 		the return value is NULL
#
# 	) If any geometry argument is not a syntactically well-formed geometry,
# 		an ER_GIS_INVALID_DATA error occurs
#
# 	) If any geometry argument refers to an undefined spatial reference system (SRS),
# 		an ER_SRS_NOT_FOUND error occurs.
#
# 	) For functions that take multiple geometry arguments, if those arguments do not
# 		have the same SRID, an ER_GIS_DIFFERENT_SRIDS error occurs.
#
# 	) If any geometry arugment is geometrically invalid, either hte result is true
# 		or false (it is undefined which) or an error occurs.
#
# 	) For geographic SRS geometry arguments, if any arguments has a longitude or
# 		latitude that is out of range, an error occurs:
#
# 		) If a longitude value is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs
#
# 		) If a latitude value is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 		Ranges shown are in degrees.
#
# 		If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 		The exact range limits deviate slightly due to floating-point arithmetic.
#
# 		) Otherwise, the return value is non-NULL
#
# These object-shape functions are available for testing geometry relationships:
#
# 	) ST_Contains(g1, g2)
#
# 		Returns 1 or 0 to indicate whether g1 completely contains g2.
#
# 		THis tests the opposite relationship as ST_Within()
#
# 		ST_Contains() handles its arguments as described in the intro
#
# 	) ST_Crosses(g1, g2)
#
# 		Two geometries spatially cross if their spatial relation has the following properties:
#
# 			) Unless g1 and g2 are both of dimension 1: g1 crosses g2 if the interior of g2 has points in common with the interior of g1,
# 				but g2 does not cover the entire interior of g1.
#
# 			) If both g1 and g2 are of dimension 1: IF the lines cross each other in a finite number of points
# 				(that is, no common line segments, only single points in common)
#
# 		THis function returns 1 or 0 to indicate whether g1 spatially crosses g2.
#
# 		ST_Crosses() handles its arguments as described in the introduction to this section except that
# 		the return value is NULL for these additional conditions:
#
# 			) g1 is of dimension 2 (Polygon or MultiPolygon)
#
# 			) g2 is of dimension 1 (Point or MultiPoint)
#
# 	) ST_Disjoint(g1, g2)
#
# 		Returns 1 or 0 to indicate whether g1 is spatially disjoint from (does not intersect) g2
#
# 		ST_Disjoint() handles its arguments as described in the intro
#
# 	) ST_Distance(g1, g2 [, unit])
#
# 		Returns the distance betwee g1 and g2, measured in the length unit of the spatial reference
# 		system (SRS) of the geometry arguments, or in the unit of the optional unit argument if that
# 		is specified.
#
# 		This function processes geometry collections by returning the shortest distance among all
# 		combinations of the components of the two geometry arguments.
#
# 		ST_Distance() handles its geometry arguments as described in the intro, with these exceptions:
#
# 			) ST_Distance() detects arguments in a geographic (ellipsodial) spatial reference system
# 				and returns the geodetic distance on the ellipsiod.
#
# 				The only permitted geographic argument types are Point and Point, or Point and MultiPoint
# 				(in any argument order)
#
# 				If called with other type argument combinations in a geographic SRS, an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS
# 				error occurs.
#
# 			) If any argument is geometrically invalid, either the result is an undefined distance (that is, it can be any number) or
# 				an error occurs.
#
# 			) If an intermediate or final result produces NaN or a ngetaive number, an ER_GIS_INVALID_DATA error occurs.
#
# 		AS of MySQL 8.0.14, ST_Distance() permits an optional unit argument that specifies
# 		the linear unit for the returned distance value.
#
# 		These rules apply:
#
# 			) If a unit is specified but not supported by MySQL, an ER_UNIT_NOT_FOUND error occurs.
#
# 			) If a supported linear unit is specified and the SRID is 0, an ER_GEOMETRY_IN_UNKNOWN_LENGTH_UNIT error occurs.
#
# 			) If a supported linear unit is specified and the SRID is not 0, the result is in that unit
#
# 			) If a unit is not specified, the result is in the unit of the SRS of the geometries, whether Cartesian or
# 				geographic.
#
# 				Currently, all MySQL SRSs are expressed in meters.
#
# 		A unit is supported if it is found in the INFORMATION_SCHEMA ST_UNITS_OF_MEASURE table
#
# 		See SECTION 25.28, "THE INFORMATION_SCHEMA ST_UNITS_OF_MEASURE TABLE"
#
# 			SET @g1 = Point(1,1);
# 			SET @g2 = Point(2,2);
# 			SELECT ST_Distance(@g1, @g2);
# 			+---------------------------+
# 			| ST_Distance(@g1, @g2) 	 |
# 			+---------------------------+
# 			| 		1.414 etc. 				 |
# 			+---------------------------+
#
# 			SET @g1 = ST_GeomFromText('POINT(1 1)', 4326);
# 			SET @g2 = ST_GeomFromText('POINT(2 2)', 4326);
# 			SELECT ST_Distance(@g1, @g2);
# 			+------------------------+
# 			| ST_Distnace(@g1, @g2)  |
# 			+------------------------+
# 			| 			156874.385 etc. |
# 			+------------------------+
#
# 			SELECT ST_Distance(@g1, @g2, 'metre');
# 			+--------------------------------+
# 			| ST_Distance(@g1, @g2, 'metre') |
# 			+--------------------------------+
# 			| 				156874.385 etc. 	   |
# 			+--------------------------------+
#
# 			SELECT ST_Distance(@g1, @g2, 'foot');
# 			+--------------------------------+
# 			| ST_Distance(@g1, @g2, 'foot')  |
# 			+--------------------------------+
# 			| 					514679.743 etc.   |
# 			+--------------------------------+
#
# 		For the special case of distance calculations on a sphere, see the ST_Distance_Sphere() function
#
# 	) ST_Equals(g1, g2)
#
# 		Returns 1 or 0 to indicate whether g1 is spatially equal to g2
#
# 		ST_Equals() handles its arguments as described in the intro, except that
# 		it does not return NULL for empty geometry arguments.
#
# 			SET @g1 = Point(1,1), @g2 = Point(2,2);
# 			SELECT ST_Equals(@g1, @g1), ST_Equals(@g1, @g2);
# 			+----------------------+--------------------------+
# 			| ST_Equals(@g1, @g1)  | ST_Equals(@g1, @g2) 	  |
# 			+----------------------+--------------------------+
# 			| 					1 		  | 			0 					  |
# 			+----------------------+--------------------------+
#
# 	) ST_Intersects(g1, g2)
#
# 		Returns 1 or 0 to indicate whether g1 spatially intersects g2
#
# 		ST_Intersects() handles its arguments as described in the intro
#
# 	) ST_Overlaps(g1, g2)
#
# 		Two geometries spatially overlap if they intersect and their intersection result
# 		in a geometry of the same dimension but not equal to either of the given geometries.
#
# 		This function returns 1 or 0 to indicate whether g1 spatially overlaps g2.
#
# 		ST_Overlaps() handles its arguments as described in the intro, except that
# 		the return value is NULL for the additional condition that the dimensions
# 		of the two geometries are not equal.
#
# 	) ST_Touches(g1, g2)
#
# 		Two geometries spatially touch if their interiors do not intersect,
# 		but the boundary of one of the geometries intersects either the boundary
# 		or the interior of hte other.
#
# 		This function returns 1 or 0 to indicate whether g1 spatially touches g2.
#
# 		ST_Touches() handles its arguments as described in the intro, except that ther eturn
# 		value is NULL for the additional condition that both geometries are of dimension
# 		0 (Point or MultiPoint)
#
# 	) ST_Within(g1, g2)
#
# 		Returns 1 or 0 to indicate whether g1 is spatially within g2.
#
# 		This tests the opposite relationship as ST_Contains()
#  
# 		ST_Within() handles its arguments as described in the intro.
#
# 12.16.9.2 SPATIAL RELATION FUNCTIONS THAT USE MINIMUM BOUNDING RECTANGLES
#
# MySQL provides several MySQL-specific functions that test the relationship between
# minimum bounding rectangles (MBRs) of two geometries g1 and g2.
#
# The return values 1 and 0 indicate true and false, respectively.
#
# The bounding box of a point is interpreted as a point that is both boundary and interior.
#
# The bounding box of a straight horizontal or vertical line is interpreted as a line where the
# interior of hte line is also boundary.
#
# The endpoints are boundary points.
#
# If any of the parameters are geometry collections, the interior, boundary and exterior
# of those parameters are those of the union of all elements in the collection.
#
# Functions in this section detect arguments in either Cartesian or geographical spatial reference
# systems (SRSs), and return result appropriate to the SRS.
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any argument is NULL or an empty geometry, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry, an ER_GIS_INVALID_DATA error occurs.
#
# 		) If any geometry argument refers to an undefined spatial reference system (SRS), an ER_SRS_NOT_FOUND error occurs
#
# 		) For functions that take multiple geometry arguments, if those arguments do not have the same SRID,
# 			an ER_GIS_DIFFERENT_SRIDS error occurs.
#
# 		) If any argument is geometrically invalid, either the result is true or false (it is undefined which), or an error occurs.
#
# 		) For geographic SRS geometry arguments, if any argument has a longitude or latitude that is out of range,,
# 			an error occurs:
#
# 			) If a longitude value is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs
#
# 			) If a latitude value is not in the range (-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs
#
# 			Ranges shown are in degrees.
#
# 			If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 			The exact range limits deviate slightly due to floating-point arithemtic.
#
# 		) Otherwise, the return value is non-NULL
#
# These MBR functions are available for testing geometry relationships:
#
# 		) MBRContains(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangle of g1 contains
# 			the minimum bounding rectangle of g2.
#
# 			This tests the opposite relationship as MBRWithin()
#
# 			MBRContains() handles its arguments as described in the intro
#
# 				SET @g1 = ST_GeomFromText('Polygon((0 0,0 3,3 3,3 0,0 0))');
# 				SET @g2 = ST_GeomFromText('Point(1 1)');
# 				SELECT MBRContains(@g1,@g2), MBRWithin(@g2,@g1);
# 			
# 			+---------------------+------------------------+
# 			| MBRContains(@g1,@g2)| MBRWithin(@g2,@g1) 	  |
# 			+---------------------+------------------------+
# 			| 					1 		 | 				1 			  |
# 			+---------------------+------------------------+
#
# 		) MBRCoveredBy(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangle of g1 is covered by
# 			the minimum bounding rectangle of g2.
#
# 			This tests the opposite relationship as MBRCovers()
#
# 			MBRCoveredBy() handles its arguments as described in the intro
#
# 				SET @g1 = ST_GeomFromText('Polygon((0 0,0 3,3 3,3 0,0 0))');
# 				SET @g2 = ST_GeomFromText('Point(1 1)');
# 				SELECT MBRCovers(@g1,@g2), MBRCoveredby(@g1,@g2);
# 				+---------------------+--------------------------+
# 				| MBRCovers(@g1,@g2)  | MBRCoveredby(@g1,@g2)    |
# 				+---------------------+--------------------------+
# 				| 			1 				 | 				0 				 |
# 				+---------------------+--------------------------+
#
# 				SELECT MBRCovers(@g2,@g1), MBRCoveredby(@g2, @g1);
# 				+---------------------+--------------------------+
# 				| MBRCovers(@g2, @g1) | MBRCoveredBy(@g2, @g1)   |
# 				+---------------------+--------------------------+
# 				| 				0 			 |  			1 					 |
# 				+---------------------+--------------------------+
#
# 		) MBRCovers(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangle of g1
# 			covers the minimum bounding rectangle of g2.
#
# 			THis tests the opposite relationship as MBRCoveredBy()
#
# 			See the description of MBRCoveredBy() for example
#
# 			MBRCovers() handles its argument as described in the intro
#
# 		) MBRDisjoint(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangles
# 			of the two geometries g1 and g2 are disjoint (do not intersect)
#
# 			MBRDisjoint() handles its arguments as described in the intro
#
# 		) MBREquals(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangles
# 			of the two geometries g1 and g2 are teh same.
#
# 			MBREquals() handles its arguments as described in the intro, except that
# 			it does not return NULL for empty geometry arguments.
#
# 		) MBRIntersects(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangles
# 			of the two geometries g1 and g2 intersect.
#
# 			MBRIntersects() handles its arguments as described in the intro.
#
# 		) MBROverlaps(g1, g2)
#
# 			Two geometries spatially overlap if they intersect and their intersection
# 			results in a geometry of the same dimension but not equal to either of
# 			the given geometries.
#
# 			This function returns 1 or 0 to indicate whether the minimum bounding
# 			rectangles of the two geometries g1 and g2 overlap.
#
# 			MBROverlaps() handles its arguments as described in the intro.
#
# 		) MBRTouches(g1, g2)
#
# 			Two geometries spatially touch if their intersiors do not intersect,
# 			but the boundary of one of the geometries intersects either the boundary
# 			or the interior of the other.
#
# 			This function returns 1 or 0 to indicate whether the minimum bounding rectangles
# 			of the two geometries g1 and g2 touch
#
# 			MBRTouches() handles its arguments as described in the intro
#
# 		) MBRWithin(g1, g2)
#
# 			Returns 1 or 0 to indicate whether the minimum bounding rectangle
# 			of g1 is within the minimum bounding rectangle of g2.
#
# 			THis tests the opposite relationship as MBRContains()
#
# 			MBRWIthin() handles its arguments as described in the intro.
#
# 				SET @g1 = ST_GeomFromText('Polygon((0 0,0 3,3 3,3 0,0 0))');
# 				SET @g2 = ST_GeomFromText('Polygon((0 0,0 5,5 5,5 0,0 0))');
# 				SELECT MBRWithin(@g1,@g2), MBRWithin(@g2,@g1);
# 				+----------------------+----------------------+
# 				| MBRWithin(@g1,@g2)   | MBRWithin(@g2,@g1)   |
# 				+----------------------+----------------------+
# 				| 			1 				  | 			0 				 |
# 				+----------------------+----------------------+
#
# 12.16.10 SPATIAL GEOHASH FUNCTIONS
#
# Geohash is a system for encoding latitude and longitude coordinates of arbitrary precision
# into a text string.
#
# Geohash values are strings that contain only characters chosen from "0-9a-z"
#
# The functions in this section enable manipulation of geohash values, which provides
# applications the capabilities of importing and exporting geohash data, and of indexing
# and searching geohash values.
#
# Unless otherwise specified, functions in this section handle their arguments as follows:
#
# 		) If any argument is NULL, the return value is NULL
#
# 		) If any argument is invalid, an error occurs
#
# 		) If any argument has a longitude or latitude that is out of range, an error occurs:
#
# 			) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs
#
# 			) If any latitude argument is not in the range [-90,90], an ER_LATITUDE_OUT_OF_RANGE error occurs
#
# 			Ranges shown are in degrees.
#
# 			The exact range limits deviate slightly due to floating-point arithmetic.
#
# 		) If any point argument does not have SRID 0 or 4326, an ER_SRS_NOT_FOUND error occurs.
#
# 			point argument SRID validity is not checked.
#
# 		) If any SRID argument refers to an undefined spatial reference system (SRS),
# 			an ER_SRS_NOT_FOUND error occurs
#
# 		) If any SRID argument is not within the range of a 32-bit unsigned integer,
# 			an ER_DATA_OUT_OF_RANGE error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These geohash funcitons are available:
#
# 	) ST_GeoHash(longitude, latitude, max_length),
# 		ST_GeoHash(point, max_lengtH)
#
# 		Returns a geohash string in the connection char set and collation
#
# 		For the first syntax, the longitude must be a number in the range [-180, 180],
# 		and the latittude must be a number in the range [-90,90]
#
# 		For the second syntax, a POINT value is required, where the X and Y coordinates
# 		are in the valid ranges for longitude and latitude, respectively.
#
# 		THe resulting stringi s no longer than max_length characters, which has
# 		an upper limit of 100.
#
# 		The string might be shorter than max_length chars because the algorithm that
# 		creates the geohash value continues until it has created a string that is either
# 		an exact representation of the location or max_length chars, whichever comes first.
#
# 		ST_GeoHash() handles its arguments as described in the intro.
#
# 			SELECT ST_GeoHash(180,0,10), ST_GeoHash(-180,-90,15);
# 			+-------------------------+----------------------------+
# 			| ST_GeoHash(180,0,10)    | ST_GeoHash(-180, -90, 15)  |
# 			+-------------------------+----------------------------+
# 			| xbpbpbpbpb 				  | 000000000000000 				 |
# 			+-------------------------+----------------------------+
#
# 	) ST_LatFromGeoHash(geohash str)
#
# 		Returns the latitude from a geohash string value, as a doule-precision
# 		number in the range [-90, 90]
#
# 		The ST_LatFromGeoHash() decoding function reads no more than 433 characters from the
# 		geohash_str argument.
#
# 		That represents the upper limit on information in teh internal representation
# 		of coordinate values.
#
# 		Characters past the 433rd are ignored, even if they are otherwise illegal
# 		and produce an error.
#
# 		ST_LatFromGeoHash() handles its arguments as described in the intro.
#
# 			SELECT ST_LatFromGeoHash(ST_GeoHash(45, -20,10));
# 			+--------------------------------------------+
# 			| ST_LatFromGeoHash(ST_GeoHash(45, -20, 10)) |
# 			+--------------------------------------------+
# 			| 									-20 				   |
# 			+--------------------------------------------+
#
# 	) ST_LongFromGeoHash(geohash str)
#
# 		Returns the longitude from a geohash string value, as a double precision number in the range
# 		[-180, 180]
#
# 		The remarks in the descriptionof ST_LatFromGeoHash() regarding the maximum number of characters
# 		processed from the geohash_str argument also apply to ST_LongFromGeoHash()
#
# 		ST_LongFromGeoHash() handles its arguments as described in the intro.
#
# 			SELECT ST_LongFromGeoHash(ST_GeoHash(45, -20,10));
# 			+-------------------------------------------------+
# 			| ST_LongFromGeoHash(ST_GeoHash(45, -20, 10)) 	  |
# 			+-------------------------------------------------+
# 			| 								45 							  |
# 			+-------------------------------------------------+
#
# 	) ST_PointFromGeoHash(geohash str, srid)
#
# 		Returns a POINT value containing the decoded geohash value,
# 		given a geohash string value.
#
# 		The X and Y coordinates of the point are the longitude in the range
# 		[-180, 180] and the latitude in the range [-90, 90], respectively.
#
# 		The srid argument is an 32-bit unsigned integer.
#
# 		The remarks in the description of ST_LatFromGeoHash() regarding the maximum
# 		number of characters processed from the geohash_str argument also apply to
# 		ST_PointFromGeoHash()
#
# 		ST_PointFromGeoHash() handles its arguments as described in the intro.
#
# 			SET @gh = ST_GeoHash(45, -20, 10);
# 			SELECT ST_AsText(ST_PointFromGeoHash(@gh,0));
# 			+---------------------------------------+
# 			| ST_AsText(ST_PointFromGeoHash(@gh,0)) |
# 			+---------------------------------------+
# 			| POINT(45 -20) 								 |
# 			+---------------------------------------+
#
# 12.16.11 SPATIAL GEOJSON FUNCTIONS
#
# This section describes functions for converting between GeoJSON documents
# and spatial values.
#
# GeoJSON is an open standard for encoding geometric/geographical features.
#
# For more info, see <link>
#
# The functions discussed here follow GeoJSON specifications revision 1.0
#
# GeoJSON supports the same geometric/geographic data types that MySQL supports.
#
# Feature and FeatureCollection objects are not supported, except that geometry
# objects are extracted from them.
#
# CRS support is limited to values that identify an SRID.
#
# MySQL also supports a native JSON data type and a set of SQL  functions
# to enable operations on JSON values.
#
# For more information, see SECTION 11.6, "THE JSON DATA TYPE"
# and SECTION 12.17, "JSON FUNCTIONS"
#
# 	) ST_AsGeoJSON(g [, max_dec_digits [, options]])
#
# 		Generates a GeoJSON object from the geometry g.
#
# 		The object string has the connection character set and collation.
#
# 		If any argument is NULL, the return value is NULL. If any non-NULL argument is invalid,
# 		an error occurs.
#
# 		max_dec_digits, if specified, limits the number of decimal digits for coordinates and
# 		causes rounding of output.
#
# 		If not specified, this argument defaults to its maximum value of 2^32 - 1, the min is 0
#
# 		options, if specified, is a bitmask.
#
# 		The following table shows the permitted flag values.
#
# 		If the geometry argument has an SRID of 0, no CRS object is produced
# 		even for those flag values that request one.
#
# 		FLAG VALUE 		MEANING
#
# 		0 					No options. This is the default if options is not specified
#
# 		1 					Add a bounding box to the output
#
# 		2 					Add a short-format CRS URN to the output. The default format is a short format (EPSG:srid)
#
# 		4 					Add a long-format CRS URN (urn:ogc:def:crs:EPSG::srid)
#
# 							This flag overrides flag 2. For example, option values of 5 and 7 mean
# 							the same (add a bounding box and a long-format CRS URN)
#
# 		
# 			SELECT ST_AsGeoJSON(ST_GeomFromText('POINT(11.111111 12.222222)'),2);
# 			+---------------------------------------------------------------+
# 			| ST_AsGeoJSON(ST_GeomFromText('POINT(11.111111 12.222222)'),2) |
# 			+---------------------------------------------------------------+
# 			| {"type": "Point", "coordinates": [11.11, 12.22]} 				 |
# 			+---------------------------------------------------------------+
#
# 	) ST_GeomFromGeoJSON(str [, options [, srid]])
#
# 		Parse a string str representing a GeoJSON object and returns a geometry.
#
# 		If any argument is NULL, the return value is NULL
#
# 		If any non-NULL argument is invalid, an error occurs.
#
# 		options, if given, describes how to handle GeoJSON documents that
# 		contain geometries with coordinate dimensions higher than 2.
#
# 		The following table shows the permitted options values
#
# 			OPTION VALUE 		MEANING
#
# 			1 						Reject the document and produce an error. This is the default if options is not specified
#
# 			2,3,4 				Accept the document and strip off the coordinates for higher coordinate dimensions
#
# 		options values of 2,3, and 4 currently produce the same effect.
#
# 		If geometries with coordinate dimensions higher than 2 are supported in the future, these values
# 		will produce different effects.
#
# 		The srid argument, if given, must be a 32-bit unsigned integer.
#
# 		If not given, the geometry return value has an SRID of 4326.
#
# 		If srid refers to an undefined spatial reference system (SRS), an ER_SRS_NOT_FOUND error occurs.
#
# 		For geographic SRS geometry arguments, if any argument has a longitude or latitude
# 		that is out of range, an error occurs:
#
# 			) If a longitude value is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs
#
# 			) If a latitude value is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs
#
# 		Ranges shown are in degrees.
#
# 		If an SRS uses another unit, the range uses the correpsonding values in its unit.
#
# 		The exact range limits deviate slightly due to floating-point arithmetic.
#
# 		GeoJSON geometry, feature, and feature collection objects may have a crs property.
#
# 		The parsing function parses named CRS URNs in the urn:ogc:def:crs:EPSG::srid and
# 		EPSG:srid namespaces, but not CRSs given as link objects.
#
# 		Also, urn:ogc:def:crs:OGC:1.3:CRS84 is recognized as SRID 4326.
#
# 		If an object has a CRS that is not understood, an error occurs, with the exception
# 		that if hte optional srid argument is given, any CRS is ignored even if it is invalid.
#
# 		If a crs member that specifies an SRID different from the top-level object SRID is found
# 		at a lower level of the GeoJSON document, an ER_INVALID_GEOJSON_CRS_NOT_TOP_LEVEL
# 		error occurs.
#
# 		As specified in the GeoJSON specification, parsing is case sensitive for the type
# 		member of the GeoJSON input (Point, LineString, and so forth)
#
# 		The specification is silent regarding case sensitivity for other parsing,
# 		which in MySQL is not case-sensitive.
#
# 		This example shows the parsing result for a simple GeoJSON object:
#
# 			SET @json = '{ "type": "Point", "coordinates": [102.0, 0.0]}';
# 			SELECT ST_AsText(ST_GeomFromGeoJSON(@json));
# 			+----------------------------------------+
# 			| ST_AsText(ST_GeomFromGeoJSON(@json))   |
# 			+----------------------------------------+
# 			| POINT(102 0) 								  |
# 			+----------------------------------------+
#
# 12.16.12 SPATIAL CONVENIENCE FUNCTIONS
#
# The functions in this section provide convenience operations
# on geometry values.
#
# Unless otherwise specified, functions in this section handle their
# arguments as follows:
#
# 		) If any argument is NULL, the return value is NULL
#
# 		) If any geometry argument is not a syntactically well-formed geometry,
# 			an ER_GIS_INVALID_DATA error occurs.
#
# 		) If any geometry argument has an SRID value that refers to an undefined
# 			spatial reference system (SRS), an ER_SRS_NOT_FOUND error occurs.
#
# 		) For functions that take multiple geometry arguments, if those arguments
# 			do not have the same SRID, an ER_GIS_DIFFERENT_SRIDS error occurs.
#
# 		) Otherwise, the return value is non-NULL
#
# These convenience functions are available:
#
# 	) ST_Distance_Sphere(g1, g2 [, radius])
#
# 		Returns the minimum spherical distance between Point or MultiPoint arguments
# 		on a sphere, in meters.
#
# 		(For general-purpose distance calculations, see the ST_Distance() function)
#
# 		The optional radius argument should be given in meters.
#
# 		If both geometry parameters are valid Cartesian Point or MultiPoint values
# 		in SRID 0, the return value is shortest distance between the two geometries
# 		on a sphere with the provided radius.
#
# 		If omitted, the default radius is 6,370,986 meters, Point X and Y coordinates
# 		are interpreted as longitude and latitude, respectively, in degrees.
#
# 		If both geometry parameters are valid Point or MultiPoint values in a geographic
# 		spatial reference system (SRS), the return value is the shortest distance
# 		between the two geometries on a sphere with the provided radius.
#
# 		If omitted, the default rais is equal to the mean radius, defined as
# 		(2a+b)/3, where a is the semi-major axis and b is the semi-minor axis
# 		of the SRS.
#
# 		ST_Distance_Sphere() handles its arguments as described in the intro.
#
# 			) Supported geometry argument combinations are Point and Point, or Point
# 				and MultiPoint (in any argument order)
#
# 			If at least one of the geometries is neither Point nor MultiPoint,
# 			and its SRID is 0, an ER_NOT_IMPLEMENTED_FOR_CARTESIAN_SRS error occurs
#
# 			If at least one of the geometries is neither Point nor MultiPoint, and
# 			its SRID refers to a geographic SRS, an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS
# 			error occurs.
#
# 			If any geometry refers to a projected SRS, an ER_NOT_IMPLEMENTED_FOR_PROJECTED_SRS
# 			error occurs.
#
# 			) If any argument has a longitude or latitude that is out of range, an error occurs:
#
# 				) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If any latitude argument is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 				Ranges shown are degrees.
#
# 				If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 				The exact range limits deviate slightly due to floating-point arithmetic.
#
# 			) If hte radius argument is present but not positive, an ER_NONPOSITIVE_RADIUS error occurs
#
# 			) If the distance exceeds the range of a double-precision number, an ER_STD_OVERFLOW_ERROR error occurs.
#
# 				SET @pt1 = ST_GeomFromText('POINT(0 0)');
# 				SET @pt2 = ST_GeomFromText('POINT(180 0)');
# 				ST_Distance_Sphere(@pt1, @pt2);
#
# 				+--------------------------------+
# 				| ST_Distance_Sphere(@pt1, @pt2) |
# 				+--------------------------------+
# 				| 			20015042.813 etc. 		|
# 				+--------------------------------+
#
#  ) ST_IsValid(g)
#
# 		Returns 1 if the argument is geometrically valid, 0 if the argument is not geometrically
# 		valid.
#
# 		Geometry validity is defined by the OGC specification.
#
# 		The only valid empty geometry is represented in the form of an empty geometry
# 		collection value.
#
# 		ST_IsValid() returns 1 in this case.
#
# 		MySQL does not support GIS EMPTY values such as POINT EMPTY.
#
# 		ST_IsValid() handles its arguments as described in the intro, with this exception:
#
# 			) If the geometry has a geographic SRS with a longitude or latitude that is out of range,
# 				an error occurs:
#
# 				) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If any latitude argument is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 				Ranges shown are in degrees.
#
# 				If an SRS uses another unit, the range uses the corresponding values in its unit.
#
# 				The exact range limits deviate slightly due to floating-point arithemtic.
#
# 					SET @ls1 = ST_GeomFromText('LINESTRING(0 0, -0.00 0, 0.0 0)');
# 					SET @ls2 = ST_GeomFromText('LINESTRING(0 0, 1 1)');
# 					SELECT ST_IsValid(@ls1);
# 					+----------------------+
# 					| ST_IsValid(@ls1) 	  |
# 					+----------------------+
# 					| 				0 			  |
# 					+----------------------+
#
# 					SELECT ST_IsValid(@ls2);
# 					+----------------------+
# 					| ST_IsValid(@ls2) 	  |
# 					+----------------------+
# 					| 				1 			  |
# 					+----------------------+
#
# 	) ST_MakeEnvelope(pt1, pt2)
#
# 		Returns the rectangle that forms the envelope around two points,
# 		as a Point, LineString, or Polygon.
#
# 		Calculations are done using the Cartesian coordinate system rather
# 		than on a sphere, spheroid or on earth.
#
# 		Given two points pt1 and pt2, ST_MakeEnvelope() creates the result
# 		geometry on an abstract plane like this:
#
# 			) If pt1 and pt2 are equal, the result is point pt1
#
# 			) Otherwise, if (pt1, pt2) is a vertical or horizontal line segment,
# 				the result is the line segment (pt1, pt2)
#
# 			) Otherwise, the result is a polygon using pt1 and pt2 as diagonal points.
#
# 		THe result geometry has an SRID of 0.
#
# 		ST_MakeEnvelope() handles its arguments as described in the intro, with the exceptions:
#
# 			) If the arguments are not Point values, an ER_WRONG_ARGUMENTS error occurs.
#
# 			) An ER_GIS_INVALID_DATA error occurs for the additional condition that any coordinate value of
# 				the two points is infinite or NaN.
#
# 			) If any geometry has an SRID value for a geographic spatial reference system (SRS),
# 				an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 				SET @pt1 = ST_GeomFromText('POINT(0 0)');
# 				SET @pt2 = ST_GeomFromText('POINT(1 1)');
# 				SELECT ST_AsText(ST_MakeEnvelope(@pt1, @pt2));
# 				+--------------------------------------+
# 				| ST_AsText(ST_MakeEnvelope(@pt1, @pt2)|
# 				+--------------------------------------+
# 				| POLYGON((0 0,1 0,1 1,0 1,0 0)) 	   |
# 				+--------------------------------------+
#
# 	) ST_Simplify(g, max_distance)
#
# 		Simplifies a geometry using the Douglas-Peucker algorithm and 
# 		returns a simplified value of the same type.
#
# 		The geometry may be any geometry type, although the Douglas-Peucker
# 		algorithm may not actually process every type.
#
# 		A geometry collection is processed by giving its components one
# 		by one to the simplification algorithm, and the returned geometries
# 		are put into a geometry collection as a result.
#
# 		The max_distance argument is the distance (in units of the input coordinates)
# 		of a vertex to other segments to be removed.
#
# 		Vertices within this distance of the simplified linestring are removed.
#
# 		According to BoostGeometry, geometries might become invalid as a result
# 		of the simplification process, and the process might create self-intersections.
#
# 		To check the validity of the result, pass it to ST_IsValid()
#
# 		ST_Simplify() handles its arguments as described in the intro, with this exception:
#
# 			) If the max_distance argument is not positive, or is NaN, an ER_WRONG_ARGUMENTS
# 				error occurs.
#
# 				SET @g = ST_GeomFromText('LINESTRING(0 0,0 1,1 1,1 2,2 2,2 3,3 3)');
# 				SELECT ST_AsText(ST_Simplify(@g, 0.5));
# 				+---------------------------------------+
# 				| ST_AsText(ST_Simplify(@g, 0.5)) 		 |
# 				+---------------------------------------+
# 				| LINESTRING(0 0,0 1,1 1,2 3,3 3) 		 |
# 				+---------------------------------------+
#
# 				SELECT ST_AsText(ST_Simplify(@g, 1.0));
# 				+---------------------------------------+
# 				| ST_AsText(ST_Simplify(@g, 1.0)) 		 |
# 				+---------------------------------------+
# 				| LINESTRING(0 0,3 3) 						 |
# 				+---------------------------------------+
#
# 	) ST_Validate(g)
#
# 		Validates a geometry according to the OGC specification.
#
# 		A geometry can be syntactically well-formed (WKB value plus SRID)
# 		but geometrically invalid.
#
# 		For example, this polygon is geometrically invalid: POLYGON((0 0,0 0, 0 0,0 0,0 0))
#
# 		ST_Validate() returns the geometry if it is syntactically well-formed and is geometrically
# 		valid, NULL if the argument is not syntactically well-formed or is not geometrically valid or IS NULL.
#
# 		ST_Validate() can be used to filter out invalid geometry data, although at a cost.
#
# 		For applications that require more precise results not tained by invalid data, this penalty
# 		may be worthwhile.
#
# 		If the geometry argument is valid, it is returned as is, except that if an input
# 		Polygon or MultiPolygon has clockwise rings, those rings are reversed before checking
# 		for validity.
#
# 		If the geometry is valid, the value with the reversed rings is returned.
#
# 		The only valid empty geometry is represented in the form of an empty geometry
# 		collection value.
#
# 		ST_Validate() returns it directly without further checks in this case.
#
# 		AS of MySQL 8.0.13, ST_Validate() handles its arguments as described in the intro,
# 		with these exceptions:
#
# 			) if the geometry has a geographic SRS with a longitude or latitude that is out of range,
# 				an error occurs:
#
# 				) If any longitude argument is not in the range (-180, 180], an ER_LONGITUDE_OUT_OF_RANGE error occurs.
#
# 				) If any latitude argument is not in the range [-90, 90], an ER_LATITUDE_OUT_OF_RANGE error occurs.
#
# 				Ranges shown are in degrees.
#
# 				The exact range limits deviate slightly due to floating-point arithmetic.
#
# 		Prior to MySQL 8.0.13, ST_Validate() handles its arguments as described in the intro, except:
#
# 			) If the geometry is not syntatically well-formed, the return value is NULL.
#
# 				An ER_GIS_INVALID_DATA error does not occur.
#
# 			) If the geometry has an SRID value for a geographical spatial reference system (SRS),
# 				an ER_NOT_IMPLEMENTED_FOR_GEOGRAPHIC_SRS error occurs.
#
# 				SET @ls1 = ST_GeomFromText('LINESTRING(0 0)');
# 				SET @ls2 = ST_GeomFromText('LINESTRING(0 0, 1 1)');
# 				SELECT ST_AsText(ST_Validate(@ls1));
# 				+------------------------------------+
# 				| ST_AsText(ST_Validate(@ls1)) 		 |
# 				+------------------------------------+
# 				| NULL 										 |
# 				+------------------------------------+
#
# 				SELECT ST_AsText(ST_Validate(@ls2));
# 				+------------------------------------+
# 				| ST_AsText(ST_Validate(@ls2)) 		 |
# 				+------------------------------------+
# 				| LINESTRING(0 0,1 1) 					 |
# 				+------------------------------------+
#
# 12.17 JSON FUNCTIONS
#
# 12.17.1 JSON FUNCTION REFERENCE
# 12.17.2 FUNCTIONS THAT CREATE JSON VALUES
# 12.17.3 FUNCTIONS THAT SEARCH JSON VALUES
# 12.17.4 FUNCTIONS THAT MODIFY JSON VALUES
# 12.17.5 FUNCTIONS THAT RETURN JSON VALUE ATTRIBUTES
# 12.17.6 JSON TABLE FUNCTIONS
# 12.17.7 JSON UTILITY FUNCTIONS
#
# The functions described in this section perform operations on JSON values.
#
# For discussion of the JSON data type and additional examples showing how to use
# these functions, see SECTION 11.6, "THE JSON DATA TYPE"
#
# For functions that take a JSON argument, an error occurs if the argument is not a valid
# JSON value.
#
# Arguments parsed as JSON are indicated by json_doc; arguments indicated by val
# are not parsed.
#
# A set of spatial functions for operating on GeoJSON values is also available.
# See SECTION 12.16.11, "SPATIAL GEOJSON FUNCTIONS"
#
# 12.17.1 JSON FUNCTION REFERENCE
#
# TABLE 12.21 JSON FUNCTIONS
#
# Name 									Description
#
# JSON_ARRAY() 						Create JSON array
#
# JSON_ARRAY_APPEND() 				Append data to JSON document
#
# JSON_ARRAY_INSERT() 				Insert into JSON array
#
# -> 										Return value from JSON column after evaluating path; equivalent
# 											to JSON_EXTRACT()
#
# JSON_CONTAINS() 					Whether JSON document contains specific object at path
#
# JSON_CONTAINS_PATH() 				Whether JSON document contains any data at path
#
# JSON_DEPTH() 						Maximum depth of JSON document
#
# JSON_EXTRACT() 						Return data from JSON document
#
# ->> 									Return value from JSON column after evaluating path and unquoting the result;
# 											equivalent to JSON_UNQUOTE(JSON_EXTRACT())
#
# JSON_INSERT() 						Insert data into JSON document
#
# JSON_KEYS() 							Array of keys from JSON document
#
# JSON_LENGTH() 						Number of elements in JSON document
#
# JSON_MERGE() (deprecated 8.0.3) Merge JSON documents, preserving duplicate keys.
# 											Deprecated synonym for JSON_MERGE_PRESERVE()
#
# JSON_MERGE_PATCH() 				Merge JSON documents, replacing values of duplicate keys
#
# JSON_MERGE_PRESERVE() 			Merge JSON documents, preserving duplicate keys
#
# JSON_OBJECT() 						Create JSON object
#
# JSON_PRETTY() 						Prints a JSON document in human-readable format, with each array
# 											element or object member printed on a new line, indented two spaces
# 											with respect to its parent.
#
# JSON_QUOTE() 						Quote JSON document
#
# JSON_REMOVE() 						Remove data from JSON document
#
# JSON_REPLACE() 						Replace values in JSON document
#
# JSON_SEARCH() 						Path to value within JSON document
#
# JSON_SET() 							Insert data into JSON document
#
# JSON_STORAGE_FREE() 				Freed space within binary representation of a JSON column value following a partial update
#
# JSON_STORAGE_SIZE() 				Space used for storage of binary representation of a JSON document;
# 											for a JSON column, the space used when the document was inserted,
# 											prior to any partial updates.
#
# JSON_TABLE() 						Returns data from a JSON expression as a relational table
#
# JSON_TYPE() 							Type of JSON value
#
# JSON_UNQUOTE() 						Unquote JSON value
#
# JSON_VALID() 						Whether JSON value is valid
#
# MySQL supports two aggregate JSON functions JSON_ARRAYAGG() and JSON_OBJECTAGG()
#
# See SECTION 12.20, "AGGREGATE (GROUP BY) FUNCTIONS", for description of these.
#
# MySQL also supports "pretty-printing" of JSON values in an easy-to-read format, using
# the JSON_PRETTY() function.
#
# You can see how much storage space a given JSON value takes up, and how much space remains
# for additional storage, using JSON_STORAGE_SIZE() and JSON_STORAGE_FREE(), respectively.
#
# For complete descriptions of these functions, see SECTION 12.17.7, "JSON UTILITY FUNCTIONS"
#
# 12.17.2 FUNCTIONS THAT CREATE JSON VALUES
#
# The functions listed in this section compose JSON values from component elements.
#
# 		) JSON_ARRAY([val[, val] ---])
#
# 			Evaluates a (possibly empty) list of values and returns a JSON array containing those values.
#
# 				SELECT JSON_ARRAY(1, "abc", NULL, TRUE, CURTIME());
# 				+--------------------------------------------+
# 				| JSON_ARRAY(1, "abc", NULL, TRUE, CURTIME())|
# 				+--------------------------------------------+
# 				| [1, "abc", null, true, "11:30:24.000000"]  |
# 				+--------------------------------------------+
#
# 		) JSON_OBJECT([key, val[, key, val] ---])
#
# 			Evaluates a (possibly empty) list of key-value pairs and returns a JSON object
# 			containing those pairs.
#
# 			An error occurs if any key name is NULL or the number of argument is odd.
#
# 				SELECT JSON_OBJECT('id', 87, 'name', 'carrot');
# 				+----------------------------------------------+
# 				| JSON_OBJECT('id', 87, 'name', 'carrot') 	  |
# 				+----------------------------------------------+
# 				| {"id": 87, "name": "carrot"} 					  |
# 				+----------------------------------------------+
#
# 		) JSON_QUOTE(string)
#
# 			Quotes a string as a JSON value by wrapping it with double quote characters
# 			and escaping interior quote and other characters, then returning the result as
# 			a utf8mb4 string.
#
# 			Returns NULL if the argument is NULL
#
# 			This function is typically used to produce a valid JSON string literal for
# 			inclusion within a JSON document.
#
# 			Certain special characters are escaped with backslashes per the escape sequence
# 			shown in TABLE 12.22, "JSON_UNQUOTE() SPECIAL CHARACTER ESCAPE SEQUENCES"
#
# 				SELECT JSON_QUOTE('null'), JSON_QUOTE('"null"');
# 				+---------------------+--------------------------+
# 				| JSON_QUOTE('null')  | JSON_QUOTE('"null"') 	 |
# 				+---------------------+--------------------------+
# 				| "null" 				 | "\"null\"" 					 |
# 				+---------------------+--------------------------+
#
# 				SELECT JSON_QUOTE('[1, 2, 3]');
# 				+-------------------------------+
# 				| JSON_QUOTE('[1, 2, 3]') 		  |
# 				+-------------------------------+
# 				| "[1, 2, 3]" 						  |
# 				+-------------------------------+
#
# 			You can also obtain JSON values by casting values of other types to the JSON type
# 			using CAST(value AS JSON), see CONVERTING BETWEEN JSON AND NON-JSON VALUES, for more information.
#
# 			Two aggregate functions generating JSON values are available 
#
# 			JSON_ARRAYAGG() returns a result set as a single JSON array, and JSON_OBJECTTAG()
# 			returns a result set as a single JSON object.
#
# 			For more information, see SECTION 12.20, "AGGREGATE (GROUP BY) FUNCTIONS"
#
# 12.17.3 FUNCTIONS THAT SEARCH JSON VALUES
#
# The functions in this section perform search operations on JSON values to extract
# data from them, report whether data exists at a location within them, or report the
# path to data within them.
#
# 		) JSON_CONTAINS(target, candidate[, path])
#
# 			Indicates by returning 1 or 0 whether a given candidate JSON document is contained
# 			within a target JSON document, or - if a path argument was supplied - whether 
# 			the candidate is found at a specific path within the target.
#
# 			Returns NULL if any argument is NULL, or if the path argument does not identify
# 			a section of the target document.
#
# 			An error occurs if target or candidate is not a valid JSON document, or if the
# 			path argument is not a valid path expression or contains a * or ** wildcard.
#
# 			To check only whether any data exists at the path, use JSON_CONTAINS_PATH() instead.
#
# 			The following rules define containment:
#
# 				) A candidate scalar is contained in a target scalar if and only if they are comparable
# 					and are equal.
#
# 					Two scalar values are comparable if they have the same JSON_TYPE() types, with the
# 					exception that values of types INTEGER and DECIMAL are also comparable to each other.
#
# 				) A candidate array is contained in a target array if and only if every element in the
# 					candidate is contained in some element of the target.
#
# 				) A candidate nonarray is contained in a target array if and only if the candidate
# 					is contained in some elements of the target.
#
# 				) A candidate object is contained in a target object if and only if for each key in the 
# 					candidate there is a key with the same name in the target and the value associated
# 					with the candidate key is contained in the value associated with the target key.
#
# 			Otherwise, the candidate value is not contained in the target document.
#
# 				SET @j = '{"a": 1, "b": 2, "c": {"d": 4}}';
# 				SET @j2 = '1';
# 				SELECT JSON_CONTAINS(@j, @j2, '$.a');
# 				+-----------------------------------+
# 				| JSON_CONTAINS(@j, @j2, '$.a') 	   |
# 				+-----------------------------------+
# 				| 								1 				|
# 				+-----------------------------------+
#
# 				SELECT JSON_CONTAINS(@j, @j2, '$.b');
# 				+-----------------------------------+
# 				| JSON_CONTAINS(@j, @j2, '$.b') 		|
# 				+-----------------------------------+
# 				| 								0 				|
# 				+-----------------------------------+
#
# 				SET @j2 = '{"d": 4}';
# 				SELECT JSON_CONTAINS(@j, @j2, '$.a');
# 				+-----------------------------------+
# 				| JSON_CONTAINS(@j, @j2, '$.a') 	   |
# 				+-----------------------------------+
# 				| 								0 				|
# 				+-----------------------------------+
#
# 				SELECT JSON_CONTAINS(@j, @j2, '$.c');
# 				+-----------------------------------+
# 				| JSON_CONTAINS(@j, @j2, '$.c') 		|
# 				+-----------------------------------+
# 				| 								1 				|
# 				+-----------------------------------+
#
# 		) JSON_CONTAINS_PATH(json_doc, one_or_all, path[, path] ---)
#
# 			Returns 0 or 1, to indicate whether a JSON document contains data at a given
# 			path or paths.
#
# 			Returns NULL if any argument is NULL.
#
# 			An error occurs if the json_doc argument is not a valid JSON document,
# 			any path argument is not a valid path expression, or one_or_all is not 'one' or 'all'
#
# 			To check for a specific value at a path, use JSON_CONTAINS() instead
#
# 			The return value is 0 if no specified path exists within the document.
# 			Otherwise, the return value depends on the one_or_all argument:
#
# 				) 'one': 1 if at least one path exists within the document, 0 otherwise
#
# 				) 'all': 1 if all paths exist within the document, 0 otherwise
#
# 					SET @j = '{"a": 1, "b": 2, "c": {"d": 4}}';
# 					SELECT JSON_CONTAINS_PATH(@j, 'one', '$.a', '$.e');
# 					+--------------------------------------------------+
# 					| JSON_CONTAINS_PATH(@j, 'one', '$.a', '$.e') 		|
# 					+--------------------------------------------------+
# 					| 												1 					|
# 					+--------------------------------------------------+
#
# 					SELECT JSON_CONTAINS_PATH(@j, 'all', '$.a', '$.e');
# 					+--------------------------------------------------+
# 					| JSON_CONTAINS_PATH(@j, 'all', '$.a', '$.e') 		|
# 					+--------------------------------------------------+
# 					| 													0 			   |
# 					+--------------------------------------------------+
#
# 					SELECT JSON_CONTAINS_PATH(@j, 'one', '$.c.d'); 	
# 					+------------------------------------------+
# 					| JSON_CONTAINS_PATH(@j, 'one', '$.c.d')   |
# 					+------------------------------------------+
# 					| 										1 				 |
# 					+------------------------------------------+
#
# 					SELECT JSON_CONTAINS_PATH(@j, 'one', '$.a.d');
# 					+------------------------------------------+
# 					| JSON_CONTAINS_PATH(@j, 'one', '$.a.d') 	 |
# 					+------------------------------------------+
# 					| 										0 				 |
# 					+------------------------------------------+
#
# 		) JSON_EXTRACT(json_doc, path[, path] ---)
#
# 			Returns data from a JSON document, selected from the parts of the document
# 			matched by the path arguments.
#
# 			Returns NULL if any argument is NULL or no paths locate a value in the document.
#
# 			An error occurs if the json_doc argument is not a valid JSON document or any path
# 			argument is not a valid path expression.
#
# 			The return value consists of all values matched by the path arguments.
#
# 			If it is possible that those arguments could return multiple values, the matched
# 			values are autowrapped as an array, in the order corresponding to the paths that
# 			produced them.
#
# 			Otherwise, the return value is the single matched value.
#
# 				SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]');
# 				+------------------------------------------------+
# 				| JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]') 	 |
# 				+------------------------------------------------+
# 				| 20 															 |
# 				+------------------------------------------------+
#
# 				SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]', '$[0]');
# 				+----------------------------------------------------+
# 				| JSON_EXTRACT('[10, 20, [30, 40]]', '$[1]', '$[0]') |
# 				+----------------------------------------------------+
# 				| [20, 10] 														  |
# 				+----------------------------------------------------+
#
# 				SELECT JSON_EXTRACT('[10, 20, [30, 40]]', '$[2][*]');
# 				+---------------------------------------------------+
# 				| JSON_EXTRACT('[10, 20, [30, 40]]', '$[2][*]') 	 |
# 				+---------------------------------------------------+
# 				| [30, 40] 														 |
# 				+---------------------------------------------------+
#
# 			MySQL supports the -> operator as shorthand for this function as used with 2 arguments
# 			where the left hand side is a JSON column identifier (not an expression) and the right hand
# 			side is the JSON path to be matched within the column.
#
# 	) column->path
#
# 		The -> operator serves as an alias for the JSON_EXTRACT() function when used with two
# 		arguments, a column identifier on the left and a JSON path on the right that is evaluated
# 		against the JSON document (the column value)
#
# 		You can use such expressions in place of column identifiers wherever they occur in SQL
# 		statements.
#
# 		The two SELECT statements shown here produce the same output:
#
# 			SELECT c, JSON_EXTRACT(c, "$.id"), g
# 			FROM jemp
# 			WHERE JSON_EXTRACT(c, "$.id") > 1
# 			ORDER BY JSON_EXTRACT(c, "$.name");
# 			+-------------------------------------+-----------------+----------+
# 			| c 											  | c->"$.id" 		  | g 		 |
# 			+-------------------------------------+-----------------+----------+
# 			| {"id": "3", "name": "Barney"} 		  | "3" 				  | 3 		 |
# 			| {"id": "4", "name": "Betty"} 		  | "4" 				  | 4 		 |
# 			| {"id": "2", "name": "Wilma"} 		  | "2" 				  | 2 		 |
# 			+-------------------------------------+-----------------+----------+
# 			3 rows in set (0.00 sec)
#
# 			SELECT c, c->"$.id", g
# 			FROM jemp
# 			WHERE c->"$.id" > 1
# 			ORDER BY c->"$.name";
# 			+-------------------------------------+-----------------+----------+
# 			| c 									 		  | c->"$.id" 		  | g 		 |
# 			+-------------------------------------+-----------------+----------+
# 			| {"id": "3", "name": "Barney"} 		  | "3" 				  | 3 		 |
# 			| {"id": "4", "name": "Betty"} 		  | "4" 				  | 4 		 |
# 			| {"id": "2", "name": "Wilma"} 		  | "2" 				  | 2 		 |
# 			+-------------------------------------+-----------------+----------+
# 			3 rows in set (0.00 sec)
#
# 		This functionality is not limited to SELECT, as shown here:
#
# 			ALTER TABLE jemp ADD COLUMN n INT;
# 			Query OK, 0 rows affected (0.68 sec)
# 			Records: 0 Duplicates: 0 Warnings: 0
#
# 			UPDATE jemp SET n=1 WHERE c->"$.id" = "4";
# 			Query OK, 1 row affected (0.04 sec)
# 			Rows matched: 1 Changed: 1 Warnings: 0
#
# 			SELECT c, c->"$.id", g, n
# 			FROM jemp
# 			WHERE JSON_EXTRACT(c, "$.id") > 1
# 			ORDER BY c->"$.name";
# 			+------------------------------------+--------------+--------+---------+
# 			| c 											 | c->"$.id" 	 | g 		 | n 		  |
# 			+------------------------------------+--------------+--------+---------+
# 			| {"id": "3", "name": "Barney"} 		 | "3" 			 | 3 		 | NULL    |
# 			| {"id": "4", "name": "Betty"} 		 | "4" 			 | 4 		 | 1 		  |
# 			| {"id": "2", "name": "Wilma"} 		 | "2" 			 | 2 		 | NULL 	  |
# 			+------------------------------------+--------------+--------+---------+
# 			3 rows in set (0.00 sec)
#
# 			DELETE FROM jemp WHERE c->"$.id" = "4";
# 			Query OK, 1 row affected (0.04 sec)
#
# 			SELECT c, c->"$.id", g, n
# 			FROM jemp
# 			WHERE JSON_EXTRACT(c, "$.id") > 1
# 			ORDER BY c->"$.name";
# 			+------------------------------------+-------------+---------+----------+
# 			| c 											 | c->"$.id"   | g 		 | n 			|
# 			+------------------------------------+-------------+---------+----------+
# 			| {"id": "3", "name": "Barney"} 		 | "3" 			| 3 		 | NULL 	   |
# 			| {"id": "2", "name": "Wilma"} 		 | "2" 			| 2 		 | NULL 		|
# 			+------------------------------------+-------------+---------+----------+
# 			2 rows in set (0.00 sec)
#
# 		(See INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX, for the statements used to
# 			create and populate the table just shown)
#
# 		This also works with JSON array values, as shown here:
#
# 			CREATE TABLE tj10 (a JSON, b INT);
# 			Query OK, 0 rows affected (0.26 sec)
#
# 			INSERT INTO tj10
# 			VALUES ("[3,10,5,17,44]", 33), ("[3,10,5,17,[22,44,66]]", 0);
# 			Query OK, 1 row affected (0.04 sec)
#
# 			SELECT a->"$[4]" FROM tj10;
# 			+-------------------+
# 			| a->"$[4]" 		  |
# 			+-------------------+
# 			| 44 					  |
# 			| [22, 44, 66] 	  |
# 			+-------------------+
# 			2 rows in set (0.00 sec)

# 			SELECT * FROM tj10 WHERE a->"$[0]" = 3;
# 			+----------------------------------+------------+
# 			| a 										  | b 			|
# 			+----------------------------------+------------+
# 			| [3, 10, 5, 17, 44] 				  | 33 			|
# 			| [3, 10, 5, 17, [22, 44, 66]]     | 0 			|
# 			+----------------------------------+------------+
# 			2 rows in set (0.00 sec)
#
# 		Nested arrays are supported.
#
# 		An expression using -> evaluates as NULL if no matching key is found in the target
# 		JSON document, as shown here:
#
# 			SELECT * FROM tj10 WHERE a->"$[4][1]" IS NOT NULL;
# 			+----------------------------------+------------+
# 			| a 										  | b 		   |
# 			+----------------------------------+------------+
# 			| [3, 10, 5, 17, [22, 44, 66]] 	  | 0 			|
# 			+----------------------------------+------------+
#
# 			SELECT a->"$[4][1]" FROM tj10;
# 			+--------------------+
# 			| a->"$[4][1]" 		|
# 			+--------------------+
# 			| NULL 					|
# 			| 44 						|
# 			+--------------------+
# 			2 rows in set (0.00 sec)
#
# 		This is the same behavior as seen in such cases when using JSON_EXTRACT():
#
# 			SELECT JSON_EXTRACT(a, "$[4][1]") FROM tj10;
# 			+---------------------------------+
# 			| JSON_EXTRACT(a, "$[4][1]") 		 |
# 			+---------------------------------+
# 			| NULL 									 |
# 			| 44 										 |
# 			+---------------------------------+
# 			2 rows in set (0.00 sec)
#
# 	) column->>path
#
# 		This is an improved, unquoting extraction operator.
#
# 		Whereas the -> operator simply extracts avalue, the ->> operator in addition
# 		unquotes the extracted result.
#
# 		In other words, given a JSON column value column and a path expression path,
# 		the following three expressions return the same value:
#
# 			) JSON_UNQUOTE(JSON_EXTRACT(column, path))
# 	
# 			) JSON_UNQUOTE(column->path)
#
# 			) column->>path
#
# 		The ->> operator can be used wherever JSON_UNQUOTE(JSON_EXTRACT)) would be allowed.
#
# 		This includes (but is not limited to) SELECT lists, WHERE and HAVING clauses,
# 		and ORDER BY and GROUP BY clauses.
#
# 		The next few statements demonstrate some ->> operator equivalences with other expressions
# 		in the mysql client:
#
# 			SELECT * FROM jemp WHERE g > 2;
# 			+-------------------------------+----------+
# 			| c 								     | g 		 |
# 			+-------------------------------+----------+
# 			| {"id": "3", "name": "Barney"} | 3 		 |
# 			| {"id": "4", "name": "Betty"}  | 4 		 |
# 			+-------------------------------+----------+
# 			2 rows in set (0.01 sec)
#
# 			SELECT c->'$.name' AS name
# 				FROM jemp WHERE g > 2;
# 			+----------------+
# 			| name 			  |
# 			+----------------+
# 			| "Barney" 		  |
# 			| "Betty" 		  |
# 			+----------------+
# 			2 rows in set (0.00 sec)
#
# 			SELECT JSON_UNQUOTE(c->'$.name') AS name
# 				FROM jemp WHERE g > 2;
# 			+---------------+
# 			| name 			 |
# 			+---------------+
# 			| Barney 		 |
# 			| Betty 			 |
# 			+---------------+
# 			2 rows in set (0.00 sec)
#
# 			SELECT c->>'$.name' AS name
# 				FROM jemp WHERE g > 2;
# 			+--------------+
# 			| name 			|
# 			+--------------+
# 			| Barney 	   |
# 			| Betty 			|
# 			+--------------+
# 			2 rows in set (0.00 sec)
#
# 	See INDEXING A GENERATED COLUMN TO PROVIDE A JSON COLUMN INDEX, for the SQL
# 	statements used to create and populate the jemp table in the set of examples
# 	just shown.
#
# 	This operator can also be used with JSON arrays, as shown here:
#
# 		CREATE TABLE tj10 (a JSON, b INT);
# 		Query OK, 0 rows affected (0.26 sec)
#
# 		INSERT INTO tj10 VALUES
# 			('[3,10,5, "x",44]', 33),
# 			('[3,10,5,17,[22,"y",66]]', 0);
# 		Query OK, 2 rows affected (0.04 sec)
# 		Records: 2 Duplicates: 0 Warnings: 0
#
# 		SELECT a->"$[3]", a->"$[4][1]" FROM tj10;
# 		+-----------------+------------------------+
# 		| a->"$[3]" 		| a->"$[4][1]" 			 |
# 		+-----------------+------------------------+
# 		| "x" 				| NULL 						 |
# 		| 17 					| "y" 						 |
# 		+-----------------+------------------------+
# 		2 rows in set (0.00 sec)
#
# 		SELECT a->>"$[3]", a->>"$[4][1]" FROM tj10;
# 		+-----------------+------------------------+
# 		| a->>"$[3]" 		| a->>"$[4][1]" 			 |
# 		+-----------------+------------------------+
# 		| x 					| NULL 						 |
# 		| 17 					| y 							 |
# 		+-----------------+------------------------+
# 		2 rows in set (0.00 sec)
#
# As with ->, the ->> operator is always expanded in the output
# of EXPLAIN, as the following example demonstrates:
#
# 		EXPLAIN SELECT c->>'$.name' AS name
# 			FROM jemp WHERE g > 2\G
# 		****************************** 1. row ************************
# 						id: 1
# 			select_type: SIMPLE
# 					table: jemp
# 			partitions : NULL
# 					type : range
# 		possible_keys : i
# 					 key : i
# 				key_len : 5
# 					 ref : NULL
# 					rows : 2
# 				filtered: 100.00
# 				   Extra: Using where
# 		1 row in set, 1 warning (0.00 sec)
#
# 		SHOW WARNINGS\G
# 		******************************** 1. row *******************************
# 			Level: Note
# 			 Code: 1003
# 		 Message: /* select#1 */ select
# 		 json_unquote(json_extract(`jtest`.`jemp`.`c`,'$.name')) AS 
# 		 `name` from `jtest`.`jemp` where (`jtest`.`jemp`.`g` > 2)
# 		1 row in set(0.00 sec)
#
# This is similar to how MySQL expands the -> operator in the same circumstances.
#
# 		) JSON_KEYS(json_doc[, path])
#
# 			Returns the keys from the top-level value of a JSON object as a JSON array,
# 			or, if a path argument is given, the top-level keys from the selected path.
#
# 			Returns NULL if any argument is NULL, the json_doc argument is not an object,
# 			or path, if given, does not locate an object.
#
# 			An error occurs if the json_doc argument is not a valid JSON document
# 			or the path argument is not a valid path expression or contains a * or ** wildcard.
#
# 			The result array is empty if the selected object is empty.
#
# 			If the top-level value has nested subobjects, the return value does not include
# 			keys from those subobjects:
#
# 				SELECT JSON_KEYS('{"a": 1, "b": {"c": 30}}');
# 				+--------------------------------------------+
# 				| JSON_KEYS('{"a": 1, "b": {"c": 30}}') 		|
# 				+--------------------------------------------+
# 				| ["a", "b"] 											|
# 				+--------------------------------------------+
#
# 				SELECT JSON_KEYS('{"a": 1, "b": {"c": 30}}', '$.b');
# 				+----------------------------------------------+
# 				| JSON_KEYS('{"a": 1, "b": {"c": 30}}', '$.b') |
# 				+----------------------------------------------+
# 				| ["c"] 													  |
# 				+----------------------------------------------+
#
# 		) JSON_SEARCH(json doc, one or all, search str [, escape char[, path] ---])
#
# 			Returns the path to the given string within a JSON document.
#
# 			Returns NULL if any of the json_doc, search_str, or path arguments are
# 			NULL, no path exists within the document, or search_str is not found.
#
# 			An error occurs if the json_doc argument is not a valid JSON document,
# 			any path argument is not a valid path expression, one_or_all is not
# 			'one' or 'all', or escape_char is not a constant expression:
#
# 			The one_or_all argument affects the search as follows:
#
# 				) 'one': The search terminates after the first match and returns one path string.
#
# 							It is undefined which match is considered first.
#
# 				) 'all': The search returns all matching path strings such that no duplicate paths are included.
#
# 							If there are multiple strings, they are autowrapped as an array.
#
# 							The order of the array elements is undefined.
#
# 			Within the search_str search string argument, the % and _ characters work as for the LIKE operator:
#
# 				% matches any number of characters (including zero characters),
# 				and _ matches exactly one character.
#
# 			To sppecify a literal % or _ character in the search string, precede it by the escape character.
#
# 			The default is \ if the escape_char argument is missing or NULL.
#
# 			Otherwise, escape_char must be a constant that is empty or one character.
#
# 			For more information, about matching and escape character behavior, see the description
# 			of LIKE in SECTION 12.5.1, "STRING COMPARISON FUNCTIONS"
#
# 			For escape character handling, a difference from the LIKE behavior is that the escape
# 			character for JSON_SEARCH() must evaluate to a constant at compile time, not just at
# 			execution time.
#
# 			For example, if JSON_SEARCH() is used in a prepared statement and the escape_char argument
# 			is supplied using a ? parameter,, the parameter value might be constant at execution time,
# 			but is not at compile time.
#
# 				SET @j = '["abc", [{"k": "10"}, "def"], {"x":"abc"}, {"y":"bcd"}]';
#
# 				SELECT JSON_SEARCH(@j, 'one', 'abc');
# 				+------------------------------------------+
# 				| JSON_SEARCH(@j, 'one', 'abc') 				 |
# 				+------------------------------------------+
# 				| "$[0]" 											 |
# 				+------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', 'abc');
# 				+-------------------------------------+
# 				| JSON_SEARCH(@j, 'all', 'abc') 		  |
# 				+-------------------------------------+
# 				| ["$[0]", "$[2].x"] 					  |
# 				+-------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', 'ghi');
# 				+-----------------------------------+
# 				| JSON_SEARCH(@j, 'all', 'ghi') 	   |
# 				+-----------------------------------+
# 				| NULL 										|
# 				+-----------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10');
# 				+------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10') 		 |
# 				+------------------------------------+
# 				| "$[1][0].k" 								 |
# 				+------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$');
# 				+-----------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$') |
# 				+-----------------------------------------+
# 				| "$[1][0].k" 										|
# 				+-----------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$[*]');
# 				+--------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$[*]') |
# 				+--------------------------------------------+
# 				| "$[1][0].k" 											|
# 				+--------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$**.k');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$**.k') |
# 				+---------------------------------------------+
# 				| "$[1][0].k" 											 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$[*][0].k');
# 				+------------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$[*][0].k')|
# 				+------------------------------------------------+
# 				| "$[1][0].k" 												 |
# 				+------------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$[1]');
# 				+------------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$[1]') 	 |
# 				+------------------------------------------------+
# 				| "$[1][0].k" 												 |
# 				+------------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '10', NULL, '$[1][0]');
# 				+------------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '10', NULL, '$[1][0]')  |
# 				+------------------------------------------------+
# 				| "$[1][0].k"  											 |
# 				+------------------------------------------------+
#
# 				SELECT JSON_SEWARCH(@j, 'all', 'abc', NULL, '$[2]');
#  			+-------------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', 'abc', NULL, '$[2]') 	  |
# 				+-------------------------------------------------+
# 				| "$[2].x" 													  |
# 				+-------------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%a%);
# 				+------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%a%') 		 |
# 				+------------------------------------+
# 				| ["$[0]", "$[2].x"] 					 |
# 				+------------------------------------+
#  
# 				SELECT JSON_SEARCH(@j, 'all', '%b%');
# 				+------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%') 		 |
# 				+------------------------------------+
# 				| ["$[0]", "$[2].x", "$[3].y"] 		 |
# 				+------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%b%', NULL, '$[0]');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%', NULL, '$[0]') |
# 				+---------------------------------------------+
# 				| "$[0]" 												 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%b%', NULL, '$[2]');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%', NULL, '$[2]') |
# 				+---------------------------------------------+
# 				| "$[2].x" 												 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%b%', NULL, '$[1]');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%', NULL, '$[1]') |
# 				+---------------------------------------------+
# 				| NULL 													 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%b%', '', '$[1]');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%', '', '$[1]')   |
# 				+---------------------------------------------+
# 				| NULL 													 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_SEARCH(@j, 'all', '%b%', '', '$[3]');
# 				+---------------------------------------------+
# 				| JSON_SEARCH(@j, 'all', '%b%', '', '$[3]') 	 |
# 				+---------------------------------------------+
# 				| "$[3].y" 												 |
# 				+---------------------------------------------+
#
# For more information about the JSON path syntax supported by MySQL,
# including rules governing the wildcard operators * and **, see JSON PATH SYNTAX.
#
# 12.17.4 FUNCTIONS THAT MODIFY JSON VALUES
#
# The functions in this section modify JSON values and return the result.
#
# 		) JSON_ARRAY_APPEND(json doc, path, val[, path, val] ---)
#
# 			Appends values to the end of the indicated arrays within a JSON document
# 			and returns the result.
#
# 			Returns NULL if any argument is NULL.
#
# 			An error occurs if the json_doc argument is not a valid JSON document
# 			or any path argument is not a valid path expression or contains a * or ** wilcard.
#
# 			The path-value pairs are evaluated left to right.
#
# 			The document produced by evaluating one pair becomes the new value against
# 			which the next pair is evaluated.
#
# 			If a path selects a scalar or object value, that value is autowrapped within an array
# 			and the new value is added to that array.
#
# 			Pairs for which the path does not identify any value in the JSON document are ignored.
#
# 				SET @j = '["a", ["b", "c"], "d"]';
# 				SELECT JSON_ARRAY_APPEND(@j, '$[1]', 1);
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$[1]', 1) 	   |
# 				+--------------------------------------+
# 				| ["a", ["b", "c", 1], "d"] 				|
# 				+--------------------------------------+
#
# 				SELECT JSON_ARRAY_APPEND(@j, '$[0]', 2);
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$[0]', 2) 		|
# 				+--------------------------------------+
# 				| [["a", 2], ["b", "c"], "d"] 			|
# 				+--------------------------------------+
#
# 				SELECT JSON_ARRAY_APPEND(@j, '$[1][0]', 3);
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$[1][0]', 3)  |
# 				+--------------------------------------+
# 				| ["a", [["b", 3], "c"], "d"]				|
# 				+--------------------------------------+
#
# 				SET @j = '{"a": 1, "b": [2, 3], "c": 4}';
# 				SELECT JSON_ARRAY_APPEND(@j, '$.b', 'x');
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$.b', 'x') 	|
# 				+--------------------------------------+
# 				| {"a": 1, "b": [2, 3, "x"], "c": 4}   |
# 				+--------------------------------------+
#
# 				SELECT JSON_ARRAY_APPEND(@j, '$.c', 'y');
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$.c', 'y') 	|
# 				+--------------------------------------+
# 				| {"a": 1, "b": [2, 3], "c": [4, "y"]} |
# 				+--------------------------------------+
#
# 				SET @j = '{"a": 1}';
# 				SELECT JSON_ARRAY_APPEND(@j, '$', 'z');
# 				+--------------------------------------+
# 				| JSON_ARRAY_APPEND(@j, '$', 'z' 		|
# 				+--------------------------------------+
# 				| [{"a": 1}, "z"] 						   |
# 				+--------------------------------------+
#
# 			In MySQL 5.7, this function was named JSON_APPEND(). That name is no longer supported in 8.0
#
# 	) JSON_ARRAY_INSERT(json_doc, path, val[, path, val] ---)
#
# 		Updates a JSON document, inserting into an array within the document and returning
# 		the modified document.
#
# 		Returns NULL if any argument is NULL.
#
# 		An error occurs if the json_doc argument is not a valid JSON document
# 		or any path argument is not a valid path expression or contains a * or
# 		** wildcard or does not end with an array element identifier.
#
# 		The path-value pairs are evaluated left to right.
#
# 		The document produced by evaluating one pair becomes the new value against
# 		which the next pair is evaluated.
#
# 		Pairs for which the path does not identify any array in the JSON document are ignored.
#
# 		If a path identifies an array element, the corresponding value is inserted at that
# 		element position, shifting any following values to the right.
#
# 		If a path identifies an array position past the end of an array, the value is inserted
# 		at the end of the array.
#
# 			SET @j = '["a", {"b": [1, 2]}, [3, 4]]';
# 			SELECT JSON_ARRAY_INSERT(@j, '$[1]', 'x');
# 			+--------------------------------------------+
# 			| JSON_ARRAY_INSERT(@j, '$[1]', 'x') 			|
# 			+--------------------------------------------+
# 			| ["a", "x", {"b": [1, 2]}, [3, 4]] 		   |
# 			+--------------------------------------------+
#
# 			SELECT JSON_ARRAY_INSERT(@j, '$[100]', 'x');
# 			+--------------------------------------------+
# 			| JSON_ARRAY_INSERT(@j, '$[100]', 'x') 		|
# 			+--------------------------------------------+
# 			| ["a", {"b": [1, 2]}, [3, 4], "x"] 			|
# 			+--------------------------------------------+
#
# 			SELECT JSON_ARRAY_INSERT(@j, '$[1].b[0]', 'x');
# 			+------------------------------------------+
# 			| JSON_ARRAY_INSERT(@j, '$[1].b[0]', 'x')  |
# 			+------------------------------------------+
# 			| ["a", {"b": ["x", 1, 2]}, [3, 4]] 		 |
# 			+------------------------------------------+
#
# 			SELECT JSON_ARRAY_INSERT(@j, '$[2][1]', 'y');
# 			+------------------------------------------+
# 			| JSON_ARRAY_INSERT(@j, '$[2][1]', 'y') 	 |
# 			+------------------------------------------+
# 			| ["a", {"b": [1, 2]}, [3, "y", 4]] 		 |
# 			+------------------------------------------+
#
# 			SELECT JSON_ARRAY_INSERT(@j, '$[0]', 'x', '$[2][1]', 'y');
# 			+----------------------------------------------------+
# 			| JSON_ARRAY_INSERT(@j, '$[0]', 'x', '$[2][1]', 'y') |
#  		+----------------------------------------------------+
# 			| ["x", "a", {"b": [1, 2]}, [3, 4]] 					  |
# 			+----------------------------------------------------+
#
# 		earlier modifications affect the positions of the following elements in the array,
# 		so subsequent paths in the same JSON_ARRAY_INSERT() call should take this into
# 		account.
#
# 		In the final example, the second path inserts nothing because the path no longer
# 		matches anything after the first insert.
#
# 	) JSON_INSERT(json_doc, path, val[, path, val] ---)
#
# 		Inserts data into a JSON document and returns the result.
#
# 		Returns NULL if any argument is NULL. 
# 
# 		An error occurs if the json_doc argument is not a valid JSON
# 		document or any path argument is not a valid path expression
# 		or contains a * or ** wildcard.
#
# 		The path-value pairs are evaluated left to right.
#
# 		The document produced by evaluating one pair becomes the new value against
# 		which the next pair is evaluated.
#
# 		A path-value pair for an existing path in the document is ignored and does not
# 		overwrite the existing document value.
#
# 		A path-value pair for a nonexisting path in the document adds the value
# 		to the document if the path identifies one of these types of values:
#
# 			) A member not present in an exsting object.
#
# 				The member is added to the object and associated with the new value.
#
# 			) A position past the end of an existing array.
#
# 				THe array is extended with the new value.
#
# 				If the existing value is not an array, it is autowrapped as an array,
# 				then extended with the new value.
#
# 		Otherwise, a path-value pair for a nonexisting path in the document is ignored
# 		and has no effect.
#
# 		For a comparison of JSON_INSERT(), JSON_REPLACE(), and JSON_SET(), see the discussion
# 		of JSON_SET()
#
# 			SET @j = '{ "a": 1, "b": [2, 3]}';
# 			SELECT JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]');
# 			+--------------------------------------------------------+
# 			| JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]') 	   |
# 			+--------------------------------------------------------+
# 			| {"a": 1, "b": [2, 3], "c": "[true, false]"} 			   |
# 			+--------------------------------------------------------+
#
# 		The third and final value listed in the result is a quoted string and
# 		not an array like the second one (which is not quoted in the output);
#
# 		No casting of values to the JSON type is performed.
#
# 		To insert the array as an array, you must perform such casts explicitly
# 		as shown here:
#
# 			SELECT JSON_INSERT(@j, '$.a', 10, '$.c', CAST('[true, false]' AS JSON));
# 			+------------------------------------------------------------------+
# 			| JSON_INSERT(@j, '$.a', 10, '$.c', CAST('[true, false]' AS JSON)) |
# 			+------------------------------------------------------------------+
# 			| {"a": 1, "b". [2, 3], "c": [true, false]} 								 |
# 			+------------------------------------------------------------------+
# 			1 row in set (0.00 sec)
#
# 	) JSON_MERGE(json_doc, json_doc[, json_doc] ---)
#
# 		Merges two or more JSON documents. Synonym for JSON_MERGE_PRESERVE(); deprecated
# 		in MySQL 8.0.3 and subject to removal in a future release.
#
# 			SELECT JSON_MERGE('[1, 2]', '[true, false]');
# 			+-------------------------------------------+
# 			| JSON_MERGE('[1, 2]', '[true, false]') 	  |
# 			+-------------------------------------------+
# 			| [1, 2, true, false]							  |
# 			+-------------------------------------------+
# 			1 row in set, 1 warning (0.00 sec)
#
# 			SHOW WARNINGS\G
# 			******************************* 1. row ***********************************
# 				Level: Warning
# 				 Code: 1287
# 			  Message: 'JSON_MERGE' is deprecated and will be removed in a future release. \
# 				Please use JSON_MERGE_PRESERVE/JSON_MERGE_PATCH instead
# 			1 row in set (0.00 sec)
#
# 		For additional examples, see the entry for JSON_MERGE_PRESERVE()
#
# 	) JSON_MERGE_PATCH(json doc, json_doc[, json_doc] ---)
#
# 		Performs an RFC 7396 compliant merge of two or more JSON documents and returns the merged result,
# 		without preserving members having duplicate keys.
#
# 		Raises an error if at least one of the documents passed as arguments to this function is not valid.
#
# 			) NOTE
#
# 				For an exaplnation and example of the differences between this function and JSON_MERGE_PRESERVE(),
# 				See JSON_MERGE_PATCH() COMPARED WITH JSON_MERGE_PRESERVE()
#
# 		JSON_MERGE_PATCH() performs a merge as follows:
#
# 			a. If the first argument is not an object, the result of the merge is the same as if an empty
# 				object had been merged with the second argument.
#
# 			b. If the second argument is not an object, the result of the merge is the second argument
#
# 			c. If both arguments are objects, the result of the merge is an object with the following members:
#
# 				) All members of the first object which do not have a corresponding member with the same key in the second object.
#
# 				) All members of the second object which do not have a corresponding key in the first object, and whose value is not the JSON null literal.
#
# 				) All members with a key that exists in both the first and the second object, and whose value in the second object is
# 					not the JSON null literal.
#
# 					The values of these members are the results of recursively merging the value in teh first object with the value
# 					in the second object.
#
# 		For additional information, see NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES.
#
# 			SELECT JSON_MERGE_PATCH('[1, 2]', '[true, false]');
# 			+-------------------------------------------------+
# 			| JSON_MERGE_PATCH('[1, 2]', '[true, false]') 	  |
# 			+-------------------------------------------------+
# 			| [true, false] 											  |
# 			+-------------------------------------------------+
#
# 			SELECT JSON_MERGE_PATCH('{"name": "x"}', '{"id": 47}');
# 			+-------------------------------------------------+
# 			| JSON_MERGE_PATCH('{"name": "x"}', '{"id": 47}') |
# 			+-------------------------------------------------+
# 			| {"id": 47, "name": "x"} 								  |
# 			+-------------------------------------------------+
#
# 			SELECT JSON_MERGE_PATCH('1', 'true');
# 			+----------------------------------+
# 			| JSON_MERGE_PATCH('1', 'true') 	  |
# 			+----------------------------------+
# 			| true 									  |
# 			+----------------------------------+
#
# 			SELECT JSON_MERGE_PATCH('[1, 2]', '{"id": 47}');
# 			+----------------------------------------------+
# 			| JSON_MERGE_PATCH('[1, 2]', '{"id": 47}')     |
# 			+----------------------------------------------+
# 			| {"id": 47} 											  |
# 			+----------------------------------------------+
#
# 			SELECT JSON_MERGE_PATCH('{ "a": 1, "b":2 }',
# 				'{ "a": 3, "c":4 }');
# 			+------------------------------------------------------------+
# 			| JSON_MERGE_PATCH('{ "a": 1, "b":2 }', '{ "a": 3, "c":4 }') |
# 			+------------------------------------------------------------+
# 			| {"a": 3, "b": 2, "c": 4} 											 |
# 			+------------------------------------------------------------+
#
# 			SELECT JSON_MERGE_PATCH('{ "a": 1, "b":2 }', '{ "a": 3, "c": 4 }',
# 				'{ "a": 5, "d":6 }');
# 			+-----------------------------------------------------------------------------------+
# 			| JSON_MERGE_PATCH('{ "a": 1, "b":2 }', '{ "a": 3, "c":4 }', '{ "a": 5, "d": 6 }')  |
# 			+-----------------------------------------------------------------------------------+
# 			| {"a": 5, "b": 2, "c": 4, "d": 6} 																	|
# 			+-----------------------------------------------------------------------------------+
#
# 	You can use this function to remove a member by specifying null as the value of the same member in the 
#  second argument, as shown here:
#
# 		SELECT JSON_MERGE_PATCH('{"a":1, "b":2}', '{"b":null}');
# 		+------------------------------------------------------------+
# 		| JSON_MERGE_PATCH('{"a":1, "b":2}', '{"b":null}') 			 |
# 		+------------------------------------------------------------+
# 		| {"a": 1} 																	 |
# 		+------------------------------------------------------------+
#
# 	This example shows that the function operates in a recursive function; that is, values
# 	of members are not limited to scalars, but rather can themselves be JSON documents:
#
# 		SELECT JSON_MERGE_PATCH('{"a":{"x":1}}', '{"a":{"y":2}}');
# 		+-----------------------------------------------------------+
# 		| JSON_MERGE_PATCH('{"a":{"x":1}}', '{"a":{"y":2}}') 			|
# 		+-----------------------------------------------------------+
# 		| {"a": {"x": 1, "y": 2}} 												|
# 		+-----------------------------------------------------------+
#
# 	JSON_MERGE_PATCH() is supported in MySQL 8.0.3 and later
#
# JSON_MERGE_PATCH() compared with JSON_MERGE_PRESERVE()
#
# The behavior of JSON_MERGE_PATCH() is the same as that of JSON_MERGE_PRESERVE(),
# with the following two exceptions:
#
# 		) JSON_MERGE_PATCH() removes any member in the first object with a matching key
# 			in the second object, provided that the value associated with the key in the
# 			second object is not JSON null
#
# 		) If the second object has a member with a key matching a member in teh first object,
# 			JSON_MERGE_PATCH() replaces the value in the firsto bject with the value in
# 			the second object, whereas JSON_MERGE_PRESERVE() appends the second value to the first.
#
# This example compares the results of merging the same 3 JSON objects, each having a matching
# key "a", with each of these two functions:
#
# 		SET @x = '{ "a": 1, "b": 2 }',
# 			 @y = '{ "a": 3, "c": 4 }',
# 			 @z = '{ "a": 5, "d": 6 }';
#
# 		SELECT JSON_MERGE_PATCH(@x, @y, @z) AS Patch,
# 				 JSON_MERGE_PRESERVE(@x, @y, @z) AS Preserve\G
# 		********************** 1. row **********************
# 			Patch: {"a": 5, "b": 2, "c": 4, "d": 6}
# 		Preserve: {"a": [1, 3, 5], "b": 2, "c": 4, "d": 6}
#
# ) JSON_MERGE_PRESERVE(json doc, json doc[, json doc] ---)
#
# 		Merges two or more JSON documents and returns the merged result.
#
# 		Returns NULLL if any argument is NULL.
#
# 		An error occurs if any argument is not a valid JSON document.
#
# 		Merging takes place according to the following rules.
#
# 		For additional information, see NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES
#
# 			) Adjacent arrays are merged to a single array
#
# 			) Adjacent objects are merged to a single object
#
# 			) A scalar value is autowrapped as an array and merged as an array
#
# 			) An adjacent array and object are merged by autowrapping the object as an array and
# 				merging the two arrays.
#
# 				SELECT JSON_MERGE_PRESERVE('[1, 2]', '[true, false]');
# 				+------------------------------------------------------+
# 				| JSON_MERGE_PRESERVE('[1, 2]', '[true, false]') 		 |
# 				+------------------------------------------------------+
# 				| [1, 2, true, false] 											 |
# 				+------------------------------------------------------+
#
# 				SELECT JSON_MERGE_PRESERVE('{"name": "x"}', '{"id": 47}');
# 				+-------------------------------------------------------+
# 				| JSON_MERGE_PRESERVE('{"name": "x"}', '{"id": 47}') 	  |
# 				+-------------------------------------------------------+
# 				| {"id": 47, "name": "x"} 										  |
# 				+-------------------------------------------------------+
#
# 				SELECT JSON_MERGE_PRESERVE('1', 'true');
# 				+--------------------------------------+
# 				| JSON_MERGE_PRESERVE('1', 'true') 	   |
# 				+--------------------------------------+
# 				| [1, true] 									|
# 				+--------------------------------------+
#
# 				SELECT JSON_MERGE_PRESERVE('[1, 2]', '{"id": 47}');
# 				+----------------------------------------------------+
# 				| JSON_MERGE_PRESERVE('[1, 2]', '{"id": 47}') 		  |
# 				+----------------------------------------------------+
# 				| [1, 2, {"id": 47}] 										  |
# 				+----------------------------------------------------+
#
# 				SELECT JSON_MERGE_PRESERVE('{ "a": 1, "b": 2 }',
# 						'{ "a": 3, "c": 4 }');
# 				+--------------------------------------------------------------+
# 				| JSON_MERGE_PRESERVE('{ "a": 1, "b": 2 }','{ "a": 3, "c":4 }')|
# 				+--------------------------------------------------------------+
# 				| {"a": [1, 3], "b": 2, "c": 4} 											|
# 				+--------------------------------------------------------------+
#
# 				SELECT JSON_MERGE_PRESERVE('{ "a": 1, "b": 2 }', '{ "a": 3, "c": 4}',
# 						'{ "a": 5, "d": 6 }');
# 				+---------------------------------------------------------------------------------------+
# 				| JSON_MERGE_PRESERVE('{ "a": 1, "b": 2 }', '{ "a": 3, "c": 4 }', '{ "a": 5, "d": 6 }') |
# 				+---------------------------------------------------------------------------------------+
# 				| {"a": [1, 3, 5], "b": 2, "c": 4, "d": 6} 															 |
# 				+---------------------------------------------------------------------------------------+
#
# 		This function was added in MySQL 8.0.3 as a synonym for JSON_MERGE()
#
# 		The JSON_MERGE() function is now deprecated, and is subject to removal.
#
# 		This function is similar but differs from JSON_MERGE_PATCH() in significant respects;
# 		see JSON_MERGE_PATCH() COMPARED WITH JSON_MERGE_PRESERVE() for more info
#
# 	) JSON_REMOVE(json doc, path[, path] ---)
#
# 		Removes data from a JSON document and returns teh result.
#
# 		Returns NULL if any argument is NULL.
#
# 		An error occurs if the json_doc argument is not a valid JSON document
# 		or any path argument is not a valid path expression or is $ or contains
# 		a * or ** wildcard.
#
# 		The path arguments are evaluated left to right.
#
# 		THe document produced by evaluating one path becomes the new value
# 		against which the next path is evaluated.
#
# 		It is not an error if the element to be removed does not exist
# 		in the document; in that case, the path does not affect the document.
#
# 			SET @j = '["a", ["b", "c"], "d"]';
# 			SELECT JSON_REMOVE(@j, '$[1]');
# 			+------------------------------------+
# 			| JSON_REMOVE(@j, '$[1]') 				 |
# 			+------------------------------------+
# 			| ["a", "d"] 								 |
# 			+------------------------------------+
#
# 	) JSON_REPLACE(json_doc, path, val [, path, val] ---)
#
# 		Replaces existing values in a JSON document and returns the result.
#
# 		Returns NULL if any argument is NULL.
#
# 		An error occurs if the json_doc argument is not a valid JSON document
# 		or any path argument is not a valid path expression or contains a * or ** wildcard.
#
# 		The path-value pairs are evaluated left to right.
#
# 		The document produced by evaluating one pair becomes the new value against which
# 		the next pair is evaluated.
#
# 		A path-value pair for an existing path in the document overwrites the existing document
# 		value with the new value.
#
# 		A path-value pair for a nonexisting path in the document is ignored and has no effect.
#
# 		In MySQL 8.0.4, the optimizer can perform a partial, in-place update of a JSON column instead
# 		of removing the old document and writing the new document in its entirety to the column.
#
# 		This optimization can be performed for an update statement that uses the JSON_REPLACE()
# 		function and meets the conditions outlined in PARTIAL UPDATES OF JSON VALUES.
#
# 		For a comparison of JSON_INSERT(), JSON_REPLACE(), and JSON_SET(), see the discussion of
# 		JSON_SET()
#
# 			SET @j = '{ "a": 1, "b": [2, 3]}';
# 			SELECT JSON_REPLACE(@j, '$.a', 10, '$.c', '[true, false]');
# 			+--------------------------------------------------------+
# 			| JSON_REPLACE(@j, '$.a', 10, '$.c', '[true, false]') 	|
# 			+--------------------------------------------------------+
# 			| {"a": 10, "b": [2, 3]} 											|
# 			+--------------------------------------------------------+
#
# 	) JSON_SET(json_doc, path, val[, path, val] ---)
#
# 		Inserts or updates data in a JSON document and returns the result.
#
# 		Returns NULL if any argument is NULL or path, if given, does not locate
# 		an object.
#
# 		An error occurs if the json_doc argument is not a valid JSON document or
# 		any path argument is not a valid path expression or contains a * or ** wildcard.
#
# 		The path-value pairs are evaluated left to right. THe document provided by evaluating one
# 		pair becomes teh new value against which the next pair is evaluated.
#
# 		A path-value pair for an existing path in the document overwrites the existing document
# 		value with the new value.
#
# 		A path-value pair for a nonexisting path in the document adds the value to the document
# 		if the path identifies one of these types of values:
#
# 			) A member not present in an existing object.
#
# 				The member is added to the object and associated with the new value.
#
# 			) A position past the end of an existing array.
#
# 				The array is extended with the new value.
#
# 				IF the existing value is not an array, it is autowrapped as an array,
# 				then extended with the new value.
#
# 		Otherwise, a path-value pair for a nonexisting path in the document is ignored and has no effect.
#
# 		In MySQL 8.0.4, the optimizer can perform a partial, in-place update of a JSON column instead of
# 		removing the old document and writing the new document in its entirety to the column.
#
# 		This optimization can be performed for an update statement that uses the JSON_SET() function
# 		and meets the conditions outlined in PARTIAL UPDATES OF JSON VALUES
#
# 		The JSON_SET(), JSON_iNSERT() and JSON_REPLACE() functions are related:
#
# 			) JSON_SET() replaces existing values and adds nonexisting values
#
# 			) JSON_INSERT() inserts values without replacing existing values
#
# 			) JSON_REPLACE() replaces only existing values
#
# 		The following examples illustrate these differences, using one path that does exist in the
# 		document ($.a) and another that does not exist ($.c):
#
# 			SET @j = '{ "a": 1, "b": [2, 3]}';
# 			SELECT JSON_SET(@j, '$.a', 10, '$.c', '[true, false]');
# 			+------------------------------------------------------+
# 			| JSON_SET(@j, '$.a', 10, '$.c', '[true, false]') 		 |
# 			+------------------------------------------------------+
# 			| {"a": 10, "b": [2, 3], "c": "[true, false]"} 		    |
# 			+------------------------------------------------------+
#
# 			SELECT JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]');
# 			+------------------------------------------------------+
# 			| JSON_INSERT(@j, '$.a', 10, '$.c', '[true, false]') 	 |
# 			+------------------------------------------------------+
# 			| {"a": 1, "b": [2, 3], "c": "[true, false]"} 			 |
# 			+------------------------------------------------------+
#
# 			SELECT JSON_REPLACE(@j, '$.a', 10, '$.c', '[true, false]');
# 			+------------------------------------------------------+
# 			| JSON_REPLACE(@j, '$.a', 10, '$.c', '[true, false]')  |
# 			+------------------------------------------------------+
# 			| {"a": 10, "b": [2, 3]} 										 |
# 			+------------------------------------------------------+
#
# 	) JSON_UNQUOTE(json val)
#
# 		Unquotes JSON value and returns the result as a utf8mb4 string.
#
# 		Returns NULL if the argument is NULL. An error occurs if the value starts and ends
# 		with doule quotes but is not a valid JSON string literal.
#
# 		Within a string, certain sequences have special meaning unless the NO_BACKSLASH_ESCAPES
# 		SQL mode is enabled.
#
# 		Each of these sequences begin with a backslash (\), known as the escape character.
#
# 		MySQL recognizes the escape sequences shown in TABLE 12.22, "JSON_UNQUOTE() SPECIAL CHARACTER ESCAPE SEQUENCES"
#
# 		For all other escape sequences, backslash is ignored. 
# 		That is, the escaped character is interpreted as if it was not escaped.
#
# 		For example, \x is just x.
#
# 		These sequences are case-sensitive.
#
# 		For example, \b is interpreted as a backspace, but \B is interpreted as B
#
# 		TABLE 12.22 JSON_UNQUOTE() SPECIAL CHARACTER ESCAPE SEQUENCES
#
# 		ESCAPE SEQUENCES 			CHARACTER REPRESENTED BY SEQUENCE
#
# 		\" 							A double quote (") character
#
# 		\b 							A backspace character
#
# 		\f 							A formfeed character
#
# 		\n 							A newline (linefeed) character
#
# 		\r 							A carriage return character
#
# 		\t 							A tab character
#
# 		\\ 							A backslash (\) character
#
# 		\uXXXX 						UTF-8 bytes for Unicode value XXXX
#
# 		Two simple examples of the use of this function are shown here:
#
# 			SET @j = '"abc"';
# 			SELECT @j, JSON_UNQUOTE(@j);
# 			+-----------+------------------------+
# 			| @j 			| JSON_UNQUOTE(@j) 		 |
# 			+-----------+------------------------+
# 			| "abc" 		| abc 						 |
# 			+-----------+------------------------+
#
# 			SET @j = '[1, 2, 3]';
# 			SELECT @j, JSON_UNQUOTE(@j);
# 			+------------------+--------------------------+
# 			| @j 					 | JSON_UNQUOTE(@j) 			 |
# 			+------------------+--------------------------+
# 			| [1,2,3]			 | [1, 2, 3] 					 |
# 			+------------------+--------------------------+
#
# 		The following set of examples shows how JSON_UNQUOTE handles escapes with NO_BACKSLASH_ESCAPES disabled and enabled:
#
# 			SELECT @@sql_mode;
# 			+----------------------+
# 			| @@sql_mode 			  |
# 			+----------------------+
# 			| 							  |
# 			+----------------------+
#
# 			SELECT JSON_UNQUOTE('"\\t\\u0032"');
# 			+----------------------------------+
# 			| JSON_UNQUOTE('"\\t\\u0032"') 	  |
# 			+----------------------------------+
# 			| 			2 								  |
# 			+----------------------------------+
#
# 			SET @@sql_mode = 'NO_BACKSLASH_ESCAPES';
# 			SELECT JSON_UNQUOTE('"\\t\\u0032"');
# 			+--------------------------------+
# 			| JSON_UNQUOTE('"\\t\\u0032"')   |
# 			+--------------------------------+
# 			| \t\u0032 								|
# 			+--------------------------------+
#
# 			SELECT JSON_UNQUOTE('"\t\u0032"');
# 			+-----------------------------------+
# 			| JSON_UNQUOTE('"\t\u0032"') 			|
# 			+-----------------------------------+
# 			| 				2 							   |
# 			+-----------------------------------+
#
# 12.17.5 FUNCTIONS THAT RETURN JSON VALUE ATTRIBUTES
#
# the functions in this section return attributes of JSON values
#
# 		) JSON_DEPTH(json_doc)
#
# 			Returns the maximum depth of a JSON document.
#
# 			Returns NULL if the argument is NULL. An error occurs if the argument is not a valid
# 			JSON document.
#
# 			An empty array, empty object, or scalar value has depth 1.
#
# 			A nonempty array containing only elements of depth 1 or nonempty object
# 			containing only member values of depth 1 has depth 2.
#
# 			Otherwise, a JSON document has a depth greater than 2.
#
# 			SELECT JSON_DEPTH('{}'), JSON_DEPTH('[]'), JSON_DEPTH('true');
# 			+---------------------+-----------------------+------------------------+
# 			| JSON_DEPTH('{}') 	 | JSON_DEPTH('[]') 		 | JSON_DEPTH('true') 	  |
# 			+---------------------+-----------------------+------------------------+
# 			|  			1 			 |  				1 			 | 			1 				  |
# 			+---------------------+-----------------------+------------------------+
#
# 			SELECT JSON_DEPTH('[10, 20]'), JSON_DEPTH('[[], {}]');
# 			+---------------------------+-----------------------------------+
# 			| JSON_DEPTH('[10, 20]') 	 | JSON_DEPTH('[[], {}]') 				 |
# 			+---------------------------+-----------------------------------+
# 			| 				2 					 | 					2 						 |
# 			+---------------------------+-----------------------------------+
#
# 			SELECT JSON_DEPPTH('[10, {"a": 20}]');
# 			+-----------------------------------+
# 			| JSON_DEPTH('[10, {"a": 20}]') 		|
# 			+-----------------------------------+
# 			| 					3 							|
# 			+-----------------------------------+
#
# 	) JSON_LENGTH(json doc[, path])
#
# 		Returns the length of a JSON document, or, if a path argument is given, the length of the value
# 		within the document identified by the path.
#
# 		Returns NULL if any argument is NULL or the path argument does not identify a value in the document.
#
# 		An error occurs if the json_doc argument is not a valid JSON document or the path argument is
# 		not a valid path expression or contains a * or ** wildcard.
#
# 		The length of a document is determined as follows:
#
# 			) THe length of a scalar is 1
#
# 			) THe length of an array is the number of array elements
#
# 			) The length of an object is the number of object members
#
# 			) THe length does not count the length of nested arrays or objects.
#
# 				SELECT JSON_LENGTH('[1, 2, {"a": 3}]');
# 				+---------------------------------------------+
# 				| JSON_LENGTH('[1, 2, {"a": 3}]') 				 |
# 				+---------------------------------------------+
# 				| 							3 								 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_LENGTH('{"a": 1, "b": {"c": 30}}');
# 				+---------------------------------------------+
# 				| JSON_LENGTH('{"a": 1, "b": {"c": 30}}') 	 |
# 				+---------------------------------------------+
# 				| 							2 								 |
# 				+---------------------------------------------+
#
# 				SELECT JSON_LENGTH('{"a": 1, "b": {"c": 30}}', '$.b');
# 				+------------------------------------------------+
# 				| JSON_lENGTH('{"a": 1, "b": {"c": 30}}', '$.b') |
#				+------------------------------------------------+
# 				| 							1 									 |
# 				+------------------------------------------------+
#
# 	) JSON_TYPE(json val)
#
# 		Returns a utf8mb4 string indicating the type of a JSON value.
#
# 		This can be an object, an array, or a scalar type, as shown here:
#
# 			SET @j = '{"a": [10, true]}';
# 			SELECT JSON_TYPE(@j);
# 			+---------------------+
# 			| JSON_TYPE(@j) 		 |
# 			+---------------------+
# 			| OBJECT 				 |
# 			+---------------------+
#
# 			SELECT JSON_TYPE(JSON_EXTRACT(@j, '$.a'));
# 			+------------------------------------------+
# 			| JSON_TYPE(JSON_EXTRACT(@j, '$.a')) 		 |
# 			+------------------------------------------+
# 			| ARRAY 												 |
# 			+------------------------------------------+
#
# 			SELECT JSON_TYPE(JSON_EXTRACT(@j, '$.a[0]'));
# 			+------------------------------------------+
# 			| JSON_TYPE(JSON_EXTRACT(@j, '$.a[0]')) 	 |
# 			+------------------------------------------+
# 			| INTEGER 											 |
# 			+------------------------------------------+
#
# 			SELECT JSON_TYPE(JSON_EXTRACT(@j, '$.a[1]'));
# 			+------------------------------------------+
# 			| JSON_TYPE(JSON_EXTRACT(@j, '$.a[1]')) 	 |
# 			+------------------------------------------+
# 			| BOOLEAN 											 |
# 			+------------------------------------------+
#
# 		JSON_TYPE() returns NULL if the argument is NULL:
#
# 			SELECT JSON_TYPE(NULL);
# 			+----------------------+
# 			| JSON_TYPE(NULL) 	  |
# 			+----------------------+
# 			| NULL 					  |
# 			+----------------------+
#
# 		An error occurs if the argument is not a valid JSON value:
#
# 			SELECT JSON_TYPE(1);
# 			ERROR 3146 (22032): Invalid data type for JSON data in argument 1
# 			to function json_type; a JSON string or JSON type is required
#
# 		For a non-NULL, non-error result, the following list describes the possible JSON_TYPE() return values:
#
# 			) Purely JSON types:
#
# 				) OBJECT: JSON Objects
#
# 				) ARRAY: JSON arrays
#
# 				) BOOLEAN: The JSON true and false literals
#
# 				) NULL: The JSON null literal
#
# 			) Numeric types:
#
# 				) Integer: MySQL TINYINT, SMALLINT, MEDIUMINT and INT and BIGINT scalars
#
# 				) Double: MySQL DOUBLE FLOAT scalars
#
# 				) DECIMAL: MySQL DECIMAL and Numeric scalars
#
# 			) Temporal types:
#
# 				) DATETIME: MySQL DATETIME and TIMESTAMP scalars
#
# 				) DATE: MySQL DATE scalars
#
# 				) TIME: MySQL TIME scalars
#
# 			) String types:
#
# 				) STRING: MySQL utf8 character type scalars: CHAR, VARCHAR, TEXT, ENUM and SET
#
# 			) Binary types:
#
# 				) BLOB: MySQL binary type scalars including BINARY, VARBINARY, BLOB and BIT
#
# 			) All other types:
#
#  			) OPAQUE (raw bits)
#
# 		) JSON_VALID(val):
#
# 			Returns 0 or 1 to indicate whether a value is a valid JSON.
#
# 			Returns NULL if the argument is NULL
#
# 				SELECT JSON_VALID('{"a": 1}');
# 				+-------------------------------+
# 				| JSON_VALID('{"a": 1}') 		  |
# 				+-------------------------------+
# 				| 1 									  |
# 				+-------------------------------+
#
# 				SELECT JSON_VALID('hello'), JSON_VALID('"hello"');
# 				+-------------------------+-------------------------+
# 				| JSON_VALID('hello') 	  | JSON_VALID('"hello"') 	 |
# 				+-------------------------+-------------------------+
# 				| 				0 				  | 					1 			 |
# 				+-------------------------+-------------------------+
#
# 12.17.6 JSON TABLE FUNCTIONS
#
# This section contains information about JSON functions that convert JSON data to tabular data.
#
# In MySQL 8.0.4, and later, one such function - JSON_TABLE() is supported.
#
# 		) JSON_TABLE(expr, path COLUMNS (column list) [AS] alias)
#
# 			Extracts data from a JSON document and returns it as a relational table having the
# 			specified columns.
#
# 			The complete syntax for this function is shown here:
#
# 				JSON_TABLE(
# 					expr,
# 					path COLUMNS (column_list)
# 					[AS] alias
# 				)
#
# 				column_list:
# 					column[, column][, ---]
#
# 				column:
# 					name FOR ORDINALITY
# 					| name type PATH string path [on_error] [on_empty]
# 					| name type EXISTS PATH string path
# 					| NESTED [PATH] path COLUMNS (column_list)
# 	
# 				on_error:
# 					(NULL | ERROR | DEFAULT json_string) ON ERROR
#
# 				on_empty:
# 					(NULL | ERROR | DEFAULT json_string) ON EMPTY
#
# expr: This is an expression that returns JSON data.
#
# This can be a constant('{"a":1}'), a column (t1.json_data, given table t1 specified
# prior to JSON_TABLE() in the FROM clause), or a function call (JSON_EXTRACT(t1, jsn_data, '$.post.comments'))
#
# path: A JSON path expression, which is applied to the data source.
#
# 		We refer to the JSON value matching the path as the row source;
# 		this is used to generate a row of relational data.
#
# 		The COLUMNS clause evaluates the row source, finds specific JSON values within the row source,
# 		and returns those JSON values as SQL values in individual columns of a row of relational data.
#
# 		The alias is required.
#
# 		The usual rules for table aliases apply (see SECTION 9.2, "SCHEMA OBJECT NAMES")
#
# 		JSON_TABLE() supports four types of columns, described in the following list:
#
# 			) a. name FOR ORDINALITY
#
# 				This type enumerates rows in the COLUMNS clause; the column named name
# 				is a counter whose type is UNSIGNED int, and whose initial value is 1.
#
# 				This is equivalent to specifying a column as AUTO_INCREMENT in a CREATE_TABLE
# 				statement, and can be used to distinguish parent rows with the same
# 				value for multiple rows generated by a NESTED [PATH] clause
#
# 			) name type PATH string_path [on_error] [on_empty]:
#
# 				Columns of this type are used to extract values specified by string_path
#
# 				type is a MySQL data type.
#
# 				JSON_TABLE() extracts data as JSON then coerces it to the column type,
# 				using the regular automatic type conversion applying to JSON data in MySQL.
#
# 				The exact behavior depends on the column type:
#
# 					If the column type is an SQL type, then only a scalar value can be saved
# 					in the column.
#
# 				Saving an object or array triggers the on error clause, this also occurs
# 				when an error takes place during coercion from the values saved as JSON
# 				to the table column, such as trying to save the string 'asd' to an itneger column.
#
# 				A missing value triggers the on_empty clause.
#
# 				The optional on_error clause determines what JSON_TABLE() does when saving an object or array:
#
# 					) NULL ON ERROR: The column is set to NULL; this is the default behavior.
#
# 						If an error occurs during type coercion, a warning is thrown.
#
# 					) ERROR ON ERROR: An error is thrown
#
# 					) DEFAULT json string ON ERROR: The json_string is parsed as JSON (provided that it is valid)
# 						and stored instead of the object or array.
#
# 					A warning is thrown if the error is caused by type coercion.
#
# 					Column type rules also apply to the default value.
#
# 				When a value saved to a column is truncated, such as saving 3.14159 in a DECIMAL(10,1) column,
# 				a warning is issued independently of any ON ERROR option.
#
# 				When multiple values are truncated in a single statement, the warning is issued only once.
#
# 				The optional on empty clause determines what JSON_TABLE() does in the event that data
# 				is missing (depending on type)
#
# 				This clause is also triggered on a column in a NESTED PATH clause when the letter
# 				has no match and a NULL complemented row is produced for it.
#
# 				on empty takes one of the following values:
#
# 					) NULL ON EMPTY: The column is set to NULL; this is the default behavior.
#
# 					) ERROR ON EMPTY: An error is thrown
#
# 					) DEFAULT json_string ON EMPTY: The provided json_string is parsed as JSON, as long as it
# 						is valid, and stored instead of the missing value.
#
# 						Column type rules also apply to the default value.
#
# 				This query demonstrates the use of the ON ERROR and ON EMPTY options.
#
# 				The row corresponding to {"b":1} is empty for the path "$.a", and attempting
# 				to save [1,2] as a scalar produces an error; these rows are highlighted in the output shown.
#
# 					SELECT
# 						FROM
# 							JSON_TABLE(
# 								'[{"a":"3"},{"a":2},{"b":1},{"a":0},{"a":[1,2]}]',
# 								"$[*]"
# 								COLUMNS(
# 									rowid FOR ORDINALITY,
# 									ac VARCHAR(100) PATH "$.a" DEFAULT '999' ON ERROR DEFAULT '111' ON EMPTY,
# 									aj JSON PATTH "$.a" DEFAULT '{"x": 333}' ON EMPTY,
# 									bx INT EXISTS PATH "$.b"
# 								)
# 							) AS tt;
#
# 					+-------+--------+------------+--------+
# 					| rowid | ac 	  | aj 			| bx 		|
# 					+-------+--------+------------+--------+
# 					| 	 1   | 3 	  | "3" 		   | 0 		|
# 					|   2   | 2 	  | 2 			| 0 		|
# 					|   3   | 111    | {"x": 333} | 1 		|
# 					| 	 4   | 0 	  | 0 			| 0 		|
# 					| 	 5   | 999 	  | [1, 2] 	   | 0 		|
# 					+-------+--------+------------+--------+
#
# 			) c. name type EXISTS PATH path: This column returns 1 if any data is present at the location
# 				specified by path, and 0 otherwise.
#
# 				Type can be any valid MySQL data type, but should normally be specified as some variety of INT
#
# 			) d. NESTED [PATH] path COLUMNS (column_list): 
#
# 					This flattens nested objects or arrays in JSON data into a single row along with
# 					the JSON values from the parent object or array.
#
# 					Using multiple PATH options allows projection of JSON values from mutliple levels of
# 					nesting into a single row.
#
# 					The path is relative to the parent path row path of JSON_TABLE(), or the path of the parent
# 					NESTED [PATH] clause in the event of nested paths.
#
# 		Column names are subject to the usual rules and limitations governing table column names.
#
# 		See SECTION 9.2, "SCHEMA OBJECT NAMES"
#
# 		All JSON and JSON path expressions are checked for valditiy; an invalid expression
# 		of either type causes an error.
#
# 		Each match for the path preceding the COLUMNS keyword maps to an individual row in
# 		the result table.
#
# 		For example, the following query gives the result shown here:
#
# 			SELECT *
# 				FROM
# 					JSON_TABLE(
# 						'[{"x":2,"y":"8"},{"x":"3","y":"7"},{"x":"4","y":6}]',
# 						"$[*]" COLUMNS(
# 							xval VARCHAR(100) PATH "$.x",
# 							yval VARCHAR(100) PATH "$.y"
# 						)
# 					) AS jt1;
#
# 			+---------+------------+
# 			| xval 	 | yval 		  |
# 			+---------+------------+
# 			| 2 		 | 8			  |
# 			| 3 		 | 7 			  |
# 			| 4 		 | 6 			  |
# 			+---------+------------+
#
# 		The expression "$[*]" matches each element of the array.
#
# 		You can filter the rows in the result by modifying the path;
#
# 		for example, using "$[1]" limits extraction to the second element of the
# 		JSON array used as the source, as shown here:
#
# 			SELECT *
# 				FROM
# 					JSON_TABLE(
# 						'[{"x":2,"y":"8"},{"x":"3","y":"7"},{"x":"4","y":6}]'
# 						"$[1]" COLUMNS(
# 							xval VARCHAR(100) PATH "$.x",
# 							yval VARCHAR(100) PATH "$.y"
# 						)
# 					) AS jt1;
#
# 			+-------+---------+
# 			| xval  | yval 	|
# 			+-------+---------+
# 			| 3 	  | 7 		|
# 			+-------+---------+
#
# 		Within a column definition, "$" passes the entire match to the column;
#
# 		"$.x" and "$.y" pass only the values corresponding to the keys x and y,
# 		respectively, within that match.
#
# 		For more information, see JSON PATH SYNTAX
#
# 		NESTED PATH (or simply NESTED; PATH is optional) produces a set of records
# 		for each match in the COLUMNS clause to which it belongs.
#
# 		If there is no match, all columns of the nested path are set to NULL.
#
# 		This implements an outer join between the topmost clause and NESTED [PATH]
#
# 		An inner join can be emulated by applying a suitable condition in the
# 		WHERE clause, as shown here:
#
# 			SELECT *
# 			FROM
# 				JSON_TABLE(
# 					'[ {"a": 1, "b": [11,111]}, {"a": 2, "b": [22,222]},
# 						{"a":3}]',
# 					'$[*]' COLUMNS(
# 								a INT PATH '$.a',
# 								NESTED PATH '$.b[*]' COLUMNS (b INT PATH '$')
# 								)
# 					) AS jt
# 			WHERE b IS NOT NULL;
#
# 		+------+---------+
# 		| a 	 | b 		  |
# 		+------+---------+
# 		| 	1 	 | 11 	  |
# 		|  1 	 | 111 	  |
# 		|  2 	 | 22 	  |
# 		|  2 	 | 222 	  |
# 		+------+---------+
#
# 	Sibling nested paths - that is, two or more instances of NESTED [PATH] in the same
# columns clause - are processed one after another, one at a time.
#
# While one nested path is producing records, columns of any sibling nested path expressions
# are set to NULL.
#
# This means that the total number of records for a single match within a single containing
# COLUMNS clause is the sum and not the product of all records produced by NESTED [PATH]
# modifiers, as shown here:
#
# 		SELECT *
# 		FROM
# 			JSON_TABLE(
# 				'[{"a": 1, "b": [11,111]}, {"a": 2, "b": [22,222]}]',
# 				'$[*]' COLUMNS(
# 					a INT PATH '$.a',
# 					NESTED PATH '$.b[*]' COLUMNS (b1 INT PATH '$'),
# 					NESTED PATH '$.b[*]' COLUMNS (b2 INT PATH '$')
# 			)
# 		) AS jt;
#
# +---------+----------+------------+
# | a 		| b1 		  | 	b2 		|
# +---------+----------+------------+
# | 	1 		| 	11 	  | 	NULL 	   |
# | 	1 		|  111 	  | 	NULL 		|
# | 	1 		| 	NULL 	  | 	11 		|
# | 	1 		|  NULL 	  | 	111 	   |
# | 	2 		| 	22 	  | 	NULL 		|
# | 	2 		|  222 	  | 	NULL 		|
# | 	2 		| 	NULL 	  | 	22 		|
# | 	2 		| 	NULL 	  | 	222 		|
# +---------+----------+------------+
#
# A FOR ORDINALITY column enumerates records produced by the COLUMNS clause, and can be used
# to distinguish parent records of a nested path, especially if values in parent records
# are the same, as can be seen here:
#
# 		SELECT *
# 		FROM
# 			JSON_TABLE(
# 				'[{"a": "a_val",'
# 					"b": [{"c": "c_val", "l": [1,2]}]},
# 				'{"a": "a_val",
# 					"b": [{"c": "c_val","l": [11]}, {"c": "c_val", "l": [22]}]}]',
# 				'$[*]' COLUMNS(
# 					top_ord FOR ORDINALITY,
# 					apath VARCHAR(10) PATH '$.a',
# 					NESTED PATH '$.b[*]' COLUMNS (
# 						bpath VARCHAR(10) PATH '$.c',
# 						ord FOR ORDINALITY,
# 						NESTED PATH '$.l[*]' COLUMNS (lpath varchar(10) PATH '$')
# 						)
# 				)
# 		) as jt;
#
# +--------------+--------------+-----------------+---------------+-------------+
# | top_ord 	  | apath 		  | bpath 			  | ord 				| lpath 		  |
# +--------------+--------------+-----------------+---------------+-------------+
# | 		1 		  | a_val 		  | c_val 			  | 	1 				| 1 			  |
# | 		1 		  | a_val 		  | c_val 			  |   1 				| 2 			  |
# | 		2 		  | a_val 		  | c_val 			  | 	1 				| 11 			  |
# | 		2 		  | a_val 		  | c_val 			  | 	2 				| 22 			  |
# +--------------+--------------+-----------------+---------------+-------------+
#
# The source document contains an array of two elements; each of these elements produce two rows.
#
# The values of apath and bpath are the same over the entire result set;
#
# This means that they cannot be used to determine whether lpath values came from the same
# or different parents.
#
# The value of the ord column remains the same as the set of records having top_ord equal
# to 1, so these two values are from a single object.
#
# The remaining two values are from different objects, since they have different
# values in the ord column.
#
# 12.17.7 JSON UTILITY FUNCTIONS
#
# This section documents utility functions that act on JSON values, or strings that can
# be parsed as JSON values.
#
# JSON_PRETTY() prints out a JSON value in a format that is easy to read.
#
# JSON_STORAGE_SIZE() and JSON_STORAGE_FREE() show, respectively, the amount of storage space used
# by a given JSON value and the amount of space remaining in a JSON column following a partial update.
#
# 		) JSON_PRETTY(json val)
#
# 			Provides pretty-printing of JSON values similar to that implemented in PHP and by other
# 			languages and database systems.
#
# 			The value supplied must be a JSON value or a valid string representation of a JSON value.
#
# 			Extraneous whitespace and newlines present in this value have no effect on the output.
#
# 			For a NULL value, the function returns NULL.
#
# 			If the value is not a JSON document, or if it cannot be parsed as one, the function
# 			fails with an error.
#
# 			Formatting of the output from this function adheres to the following rules:
#
# 				) Each array element or object member appears on a separate line, indented by one additional level as compared to its parent
#
# 				) Each level of indentation adds two leading spaces
#
# 				) A comma separating individual array elements or object members is printed before the newline that separates
# 					the two elements or members.
#
# 				) The key and the value of an object member are separated by a colon followed by a space (': ')
#
# 				) An empty object or array is printed on a single line. No space is printed between the opening and closing brace.
#
# 				) Special characters in string scalars and key names are escaped employing the same rules used by the JSON_QUOTE() function.
#
# 					SELECT JSON_PRETTY('123'); # scalar
# 					+-----------------------------+
# 					| JSON_PRETTY('123') 			|
# 					+-----------------------------+
# 					| 123 								|
# 					+-----------------------------+
#
# 					SELECT JSON_PRETTY("[1,3,5]"); #array
# 					+-----------------------------+
# 					| JSON_PRETTY("[1,3,5]") 		|
# 					+-----------------------------+
# 					| [ 									|
# 					| 1, 									|
# 					| 3, 									|
# 					| 5  									|
# 					| ] 									|
# 					+-----------------------------+
#
# 					SELECT JSON_PRETTY('{"a":"10", "b":"15","x":"25"}'); # object
# 					+-----------------------------------------------+
# 					| JSON_PRETTY('{"a":"10", "b":"15", "x":"25"}') |
# 					+-----------------------------------------------+
# 					| { 															|
# 					|	"a": "10", 												|
# 					|  "b": "15", 												|
# 					|  "x": "25" 												|
# 					| } 															|
# 					+-----------------------------------------------+
#
# 					SELECT JSON_PRETTY('["a",1,{"key1":"value1"},
# 						"5", "77", {"key2":["value3","valueX",
# 						"valueY"]}, "j", "2" ]')\G #nested arrays and objects
# 					*************************************** 1.row ***********************************
# 					JSON_PRETTY('["a",1,{"key1":"value1"}, 
# 								  ("5", "77", {"key2":["value3", "valuex", "valuey"]}, "j", "2" ]'):
# 									[ "a",
# 										1,
# 										{
# 											"key1": "value1"
# 										},
# 										"5",
# 										"77",
# 										{
# 											"key2": [
# 												"value3",
# 												"valuex",
# 												"valuey"
# 											]
# 										},
# 										"j",
# 										"2"
# 									]
#
# 		) JSON_STORAGE_FREE(json_val)
#
# 			For a JSON column value, this funciton shows how much storage spaces was freed
# 			in its binary representation after it was updated in place using JSON_SET(),
# 			JSON_REPLACE(), or JSON_REMOVE().
#
# 			The argument can also be a valid JSON document or a string which can be parsed as one -
# 			either as a literal value or as the value of a user variable - in which case the function
# 			returns 0.
#
# 			It returns a positive, nonzero value if the argument is a JSON column value which has been
# 			updated as described previously, such that its binary representation takes up less space
# 			than it did prior to the update.
#
# 			For a JSON column which has been updated such that its binary representation is the same
# 			as or larger than before, or if the update was not able to take advantage of a partial update,
# 			it returns 0; it returns NULL if the argument is NULL.
#
# 			If json_val is not NULL, and neither is a valid JSON document nor can be successfully parsed as one,
# 			an error results.
#
# 			In this example, we create a table containing a JSON column, then insert a row containing a JSON
# 			object:
#
# 				CREATE TABLE jtable (jcol JSON);
# 				Query OK, 0 rows affected (0.38 sec)
#
# 				INSERT INTO jtable VALUES
# 					('{"a": 10, "b": "wxyz", "c": "[true, false]"}');
# 				Query OK, 1 row affected (0.04 sec)
#
# 				SELECT * FROM jtable;
# 				+--------------------------------------------------+
# 				| jcol 															|
# 				+--------------------------------------------------+
# 				| {"a": 10, "b": "wxyz", "c": "[true, false]"} 		|
# 				+--------------------------------------------------+
# 				1 row in set (0.00 sec)
#
# 			Now we update the column value using JSON_SET() such that a partial update
# 			can be performed; in this case, we replace the value pointed to by the
# 			c key (the array [true, false]) with one that takes up less space (the integer 1):
#
# 				UPDATE jtable
# 					SET jcol = JSON_SET(jcol, "$.a", 10, "$.b","wxyz", "$.c", 1);
# 				Query OK, 1 row affected (0.03 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT * FROM jtable;
# 				+-------------------------------------+
# 				| jcol 										  |
# 				+-------------------------------------+
# 				| {"a": 10, "b": "wxyz", "c": 1} 	  |
# 				+-------------------------------------+
# 				1 row in set (0.00 sec)
#
# 				SELECT JSON_STORAGE_FREE(jcol) FROM jtable;
# 				+----------------------------------+
# 				| JSON_STORAGE_FREE(jcol) 			  |
# 				+----------------------------------+
# 				| 							14 			  |
# 				+----------------------------------+
# 				1 row in set (0.00 sec)
#
# 			The effects of successive partial updates on this free space are cumulative,
# 			as shown in this example using JSON_SET() to reduce the space taken up
# 			by the value having key b (and making no other changes):
#
# 				UPDATE jtable
# 					SET jcol = JSON_SET(jcol, "$.a", 10, "$.b", "wx", "$.c", 1);
# 				Query OK, 1 row affected (0.03 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT JSON_STORAGE_FREE(jcol) FROM jtable;
# 				+---------------------------------+
# 				| JSON_STORAGE_FREE(jcol) 			 |
# 				+---------------------------------+
# 				| 							16 			 |
# 				+---------------------------------+
# 				1 row in set (0.00 sec)
#
# 			Updating the column without using JSON_SET(), JSON_REPLACE(), or
# 			JSON_REMOVE() means that the optimizer cannot perform the update
# 			in place; in this case, JSON_STORAGE_FREE() returns 0, as shown here:
#
# 				UPDATE jtable SET jcol = '{"a": 10, "b": 1}';
# 				Query OK, 1 row affected (0.05 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT JSON_STORAGE_FREE(jcol) FROM jtable;
# 				+-------------------------------+
# 				| JSON_STORAGE_FREE(jcol) 		  |
# 				+-------------------------------+
# 				| 					0 					  |
# 				+-------------------------------+
# 				1 row in set (0.00 sec)
#
# 			Partial updates of JSON documents can be performed only on column values.
#
# 			For a user variable that stores a JSON value, the value is always
# 			completely replaced, even when the update is performed using JSON_SET():
#
# 				SET @j = '{"a": 10, "b": "wxyz", "c": "[true, false]"}';
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SET @j = JSON_SET(@j, '$.a', 10, '$.b', 'wxyz', '$.c', '1');
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SELECT @j, JSON_STORAGE_FREE(@j) AS Free;
# 				+----------------------------------+----------+
# 				| @j 										  | Free 	 |
# 				+----------------------------------+----------+
# 				| {"a": 10, "b": "wxyz", "c": "1"} | 0 		 |
# 				+----------------------------------+----------+
#
# 			For a JSON literal, this function always returns 0:
#
# 				SELECT JSON_STORAGE_FREE('{"a": 10, "b": "wxyz", "c": "1"}') AS Free;
# 				+---------------+
# 				| Free 			 |
# 				+---------------+
# 				| 		0 			 |
# 				+---------------+
# 				1 row in set (0.00 sec)
#
# 		) JSON_STORAGE_SIZE(json_val)
#
# 			This function returns the number of bytes used to store the binary representation of a JSON
# 			document.
#
# 			When the argument is a JSON column, this is the space used to store the JSON document
# 			as it was inserted into the column, prior to any partial updates that may have been 
# 			performed on it afterwards.
#
# 			json_val must be a valid JSON document or a string which can be parsed as one.
#
# 			In the case where it is string, the function returns the amount of storage space in
# 			the JSON binary representation that is created by parsing the string as JSON and
# 			converting it to binary.
#
# 			It returns NULL if the argument is NULL
#
# 			An error results when json_val is not NULL, and is not - or cannot be successfully
# 			parsed as - a JSON document.
#
# 			To illustrate this function's behavior when used with a JSON column as its argument,
# 			we create a table named jtable containing a JSON column jcol, insert a JSON value
# 			into the table, then obtain the storage space used by this column with JSON_STORAGE_SIZE(),
# 			as shown here:
#
# 				CREATE TABLE jtable (jcol JSON);
# 				Query OK, 0 rows affected (0.42 sec)
#
# 				INSERT INTO jtable VALUES
# 					('{"a": 1000, "b": "wxyz", "c": "[1, 3, 5, 7]"}');
# 				Query OK, 1 row affected (0.04 sec)
#
# 				SELECT
# 					jcol,
# 					JSON_STORAGE_SIZE(jcol) AS Size,
# 					JSON_STORAGE_FREE(jcol) AS Free
# 				FROM jtable;
# 				+------------------------------------------------+---------+------------+
# 				| jcol 														 | Size 	  | Free 		|
# 				+------------------------------------------------+---------+------------+
# 				| {"a": 1000, "b": "wxyz", "c": "[1, 3, 5, 7]"}  | 	47   | 0 			|
# 				+------------------------------------------------+---------+------------+
# 				1 row in set (0.00 sec)
#
# 			According to the output of JSON_STORAGE_SIZE(), the JSON document inserted into
# 			the column takes up 47 bytes.
#
# 			We also checked the amount of space freed by any previous partial updates
# 			of the column using JSON_STORAGE_FREE(); since no updates have yet been performed,
# 			this is 0, as expected.
#
# 			Next we perform an UPDATE on the table that should result in a partial update of the
# 			document stored in jcol, and then test the result as shown here:
#
# 				UPDATE jtable SET jcol =
# 						JSON_SET(jcol, "$.b", "a");
# 				Query OK, 1 row affected (0.04 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT
# 					jcol,
# 					JSON_STORAGE_SIZE(jcol) AS Size,
# 					JSON_STORAGE_FREE(jcol) AS Free
# 				FROM jtable;
# 				+-------------------------------------------+---------+-------------+
# 				| jcol 												  | Size 	| Free 		  |
# 				+-------------------------------------------+---------+-------------+
# 				| {"a": 1000, "b": "a", "c": "[1, 3, 5, 7]"}| 47 	   | 3 			  |
# 				+-------------------------------------------+---------+-------------+
# 				1 row in set (0.00 sec)
#
# 			The value returned by JSON_STORAGE_FREE() in the previous query indicates that
# 			a partial update of the JSON document was performed, and that this freed 3 bytes
# 			of space used to store it.
#
# 			the result returned by JSON_STORAGE_SIZE() is unchanged by the partial update
#
# 			Partial updates are supported for updates using JSON_SET(), JSON_REPLACE(), or
# 			JSON_REMOVE()
#
# 			The direct assignment of a value to a JSON column cannot be partially updated;
# 			following such an update, JSON_STORAGE_SIZE() always shows the storage used for
# 			the newly-set value:
#
# 				UPDATE jtable
# 					SET jcol = '{"a": 4.55, "b": "wxyz", "c": "[true, false]"}';
# 				Query OK, 1 row affected (0.04 sec)
# 				Rows matched: 1 Changed: 1 Warnings: 0
#
# 				SELECT
# 					jcol,
# 					JSON_STORAGE_SIZE(jcol) AS Size,
# 					JSON_STORAGE_FREE(jcol) AS Free
# 				FROM jtable;
# 				+------------------------------------------------+------------+---------+
# 				| jcol 												 		 | Size 		  | Free 	|
# 				+------------------------------------------------+------------+---------+
# 				| {"a": 4.55, "b": "wxyz", "c": "[true, false]"} | 56 		  | 0 		|
# 				+------------------------------------------------+------------+---------+
# 				1 row in set (0.00 sec)
#
# 			A JSON user variable cannot be partially updated.
#
# 			This means that this function always shows the space currently used to store
# 			a JSON document in a user variable:
#
# 				SET @j = '[100, "sakila", [1, 3, 5], 425.05]';
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SELECT @j, JSON_STORAGE_SIZE(@j) AS Size;
# 				+----------------------------------------+------+
# 				| @j 												  | Size |
# 				+----------------------------------------+------+
# 				| [100, "sakila", [1, 3, 5], 425.05] 	  | 45 	|
# 				+----------------------------------------+------+
# 				1 row in set (0.00 sec)
#
# 				SET @j = JSON_SET(@j, '$[1]', "json");
# 				Query OK, 0 rows affected (0.00 sec)
#
# 				SELECT @j, JSON_STORAGE_SIZE(@j) AS Size;
# 				+--------------------------------------------+--------+
# 				| @j 												      | Size   |
# 				+--------------------------------------------+--------+
# 				| [100, "json", [[10, 20, 30], 3, 5], 425.05 | 56 		|
# 				+--------------------------------------------+--------+
# 				1 row in set (0.00 sec)
#
# 			For a JSON literal, this function always returns the current storage space used:
#
# 				SELECT
# 					JSON_STORAGE_SIZE('[100, "sakila", [1, 3, 5], 425.05]') AS A,
# 					JSON_STORAGE_SIZE('{"a": 1000, "b": "a", "c": "[1, 3, 5, 7]"}') AS B,
# 					JSON_STORAGE_SIZE('{"a": 1000, "b": "wxyz", "c": "[1, 3, 5, 7]"}') AS C,
# 					JSON_STORAGE_SIZE('[100, "json", [[10, 20, 30], 3, 5], 425.05]') AS D;
# 				+-----+-----+-----+----+
# 				| A 	| B 	| C 	| D  |
# 				+-----+-----+-----+----+
# 				| 45  | 44  | 47  | 56 |
# 				+-----+-----+-----+----+
# 				1 row in set (0.00 sec)
#
# 12.18 FUNCTIONS USED WITH GLOBAL TRANSACTION IDENTIFIERS (GTIDs)
#
# The functions described in this section are used with GTID-based replication.
#
# It is important to keep in mind that all of these functions take string representation
# of GTID sets as arguments.
#
# As such, the GTID sets must always be quoted when used with them. See GTID SETS for more information.
#
# The union of two GTID sets is simply their representations as strings, joined together
# with an interposed comma.
#
# In other words, you can define a very simple function for obtaining the union
# of two GTID sets, similar to that created here:
#
# 		CREATE FUNCTION GTID_UNION(g1 TEXT, g2 TEXT)
# 			RETURNS TEXT DETERMINISTIC
# 			RETURN CONCAT(g1, ',', g2);
#
# For more information about GTIDs and how these GTID functions are used in practice,
# see SECTION 17.1.3, "REPLICATION WITH GLOBAL TRANSACTION IDENTIFIERS"
#
# TABLE 12.23 GTID FUNCTIONS
#
# NAME 									Description
#
# GTID_SUBSET() 					Return true if all GTIDs in subset are also in set; otherwise, false.
#
# GTID_SUBTRACT() 				Return all GTIDs in set that are not in subset
#
# WAIT_FOR_EXECUTED_GTID_SET  Wait until the given GTIDs have executed on slave
#
# WAIT_UNTIL_SQL_ 				Wait until the given GTIDs have executed on slave
# THREAD_AFTER_GTIDS()
#
# 		) GTID_SUBSET(set1, set2)
#
# 			Given two sets of global transaction identifiers set1 and set2, returns true
# 			if all GTIDs in set1 are also in set2.
#
# 			Returns false otherwise.
#
# 			The GTID sets used with this function are represented as strings, as shown
# 			in the following examples:
#
# 				SELECT GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:23',
# 						'3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57')\G
# 				**************************** 1. row ***************************
# 				GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:23',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57'): 1
# 				1 row in set (0.00 sec)
#
# 				SELECT GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:23-25',
# 						'3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57')\G
# 				***************************** 1. row **************************
# 				GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:23-25',
# 					'3E11FA47-71CA-11E1-9E33-C80AA949562:21-57'): 1
# 				1 row in set (0.00 sec)
#
# 				SELECT GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:20-25',
# 						'3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57')\G
# 				***************************** 1. row ***************************
# 				GTID_SUBSET('3E11FA47-71CA-11E1-9E33-C80AA9429562:20-25',
# 					'3E11FA47-71CA-11E1-9E33-C80AA94295962:21-57'): 0
# 				1 row in set (0.00 sec)
#
# 		) GTID_SUBTRACT(set1, set2)
#
# 			Given two sets of global transaction identifiers set1 and set2, returns only
# 			those GTIDs from set1 that are not in set2.
#
# 			All GTID sets used with this function are represented as strings and must be quoted,
# 			as shown in these examples:
#
# 				SELECT GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:21')\G
# 				******************************* 1. row *****************************
# 				GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:21'): 3e11fa47-71ca-11e1-9e33-c80aa9429562:22-57
# 				1 row in set (0.00 sec)
#
# 				SELECT GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:20-25')\G
# 				****************************** 1. row *******************************
# 				GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:20-25'): 3e11fa47-71ca-11e1-9e33-c80aa9429562:26-57
# 				1 row in set (0.00 sec)
#
# 				SELECT GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:23-24')\G
# 				***************************** 1. row ********************************
# 				GTID_SUBTRACT('3E11FA47-71CA-11E1-9E33-C80AA9429562:21-57',
# 					'3E11FA47-71CA-11E1-9E33-C80AA9429562:23-24'): 3e11fa47-71ca-11e1-9e33-c80aa9429562:21-22:25-57
# 				1 row in set (0.01 sec)
#
# 		) WAIT_FOR_EXECUTED_GTID_SET(gtid_set[, timeout])
#
# 			Wait until the server has applied all of the transactions whose global transaction identifier
# 			are contained in gtid_set; that is, until the condition GTID_SUBSET(gtid_subset, @@GLOBAL.gtid_executed) holds.
#
# 			See SECTION 17.1.3.1, "GTID FORMAT AND STORAGE" for a definition of GTID sets.
#
# 			If a timeout is specified, and timeout seconds elapse before all of the transactions in the
# 			GTID set have been applied, the function stops waiting.
#
# 			timeout is optional, and the default timeout is 0 seconds, in which case the funciton always
# 			waits until all of the transactions in the GTID set have been applied.
#
# 			WAIT_FOR_EXECUTED_GTID_SET() monitors all the GTIDs that are applied on the server,
# 			including transactions that arrive from all replication channels and user clients.
#
# 			it does not take into account whether replication channels have been started or stopped.
#
# 			For more information, SEE SECTION 17.1.3, "REPLICATION WITH GLOBAL TRANSACTION IDENTIFIERS"
#
# 			GTID sets used with this function are represented as strings and so must be quoted as shown
# 			in the following example:
#
# 				SELECT WAIT_FOR_EXECUTED_GTID_SET('3E11FA47-71CA-9E33-C80AA9429562:1-5');
# 					-> 0
#
# 			For a syntax description for GTID sets, see SECTION 17.1.3.1, "GTID FORMAT AND STORAGE"
#
# 			For WAIT_FOR_EXECUTED_GTID_SET(), the return value is the state of the query, where 0
# 			represents success and 1 represents timeout.
#
# 			Any other failures generate an error.
#
# 			gtid_mode cannot be changed to OFF while any client is using this function to wait for
# 			GTIDs to be applied.
#
# 		) WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS(gtid set[, timeout][, channel])
#
# 			WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() is similar to WAIT_FOR_EXECUTED_GTID_SET() in that it
# 			waits until all of the transactions whose global transaction identifiers are contained
# 			in gtid_set have been applied, or until timeout seconds have elapsed, whichever comes
# 			first.
#
# 			However, WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() applies to a specific replication channel,
# 			and stops only after the transactions have been applied on the specified channel,
# 			for which the applier must be running.
#
# 			In contrast, WAIT_FOR_EXECUTED_GTID_SET() stops after the transactions have been applied,
# 			regardless of where they were applied (on any replication channel or any user client),
# 			and whether or not any replication channels are running.
#
# 			The channel option names which replication channel the function applies to.
#
# 			If no channel is named and no channels other than the default replication channel
# 			exist, the function applies to the default replication channel.
#
# 			If multiple replication channels exist, you must specify a channel as otherwise
# 			it is not known which replication channel the function applies to.
#
# 			See SECTION 17.2.3, "REPLICATION CHANNELS" for more information on replication channels.
#
# 				NOTE:
#
# 					Because WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() applies to a specific replication channel,
# 					if an expected transaction arrives on a different replication channel or from a 
# 					user client, for example in a failover or manual recovery situation, the function
# 					can hang indefinetly if no timeout is set.
#
# 					Use WAIT_FOR_EXECUTED_GTID_SET() instead to ensure correct handling of transactions
# 					in these situations.
#
# 			GTID sets used with WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() are represented as strings and must be
# 			quoted in the same way as for WAIT_FOR_EXECUTED_GTID_SET()
#
# 			For WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS(), the return value for the function is an arbitrary
# 			positive number.
#
# 			If GTID-based replication is not active (that is, if the value of the gtid_mode variable
# 			is OFF), then this value is undefined and WAIT_UNTIL_SQL_THREAD_AFTER_GTIDS() returns NULL.
#
# 			If the slave is not running then the function also returns NULL.
#
# 			gtid_mode cannot be changed to OFF while any client is using this function to wait for
# 			GTIDs to be applied.
#
# 12.19 MYSQL ENTERPRISE ENCRYPTION FUNCTIONS
#
# 12.19.1 MySQL ENTERPRISE ENCRYPTION INSTALLATION
# 12.19.2 MySQL ENTERPRISE ENCRYPTION USAGE AND EXAMPLES
# 12.19.3 MYSQL ENTERPRISE ENCRYPTION FUNCTION REFERENCE
# 12.19.4 MYSQL ENTERPRISE ENCRYPTION FUNCTION DESCRIPTIONS
#
# NOTE:
# 		MySQL Enterprise Encryption is an extension included in MySQL Enterprise Edition,
# 		a commercial product.
#
# MySQL Enterprise Edition includes a set of encryption functions based on the OpenSSL
# library that exposes OpenSSL capabilities at the SQL level.
#
# These functions enable Enterprise applications to perform the following operations:
#
# 		) Implement added data protection using public-key asymmetric cryptography
#
# 		) Create public and private keys and digital signatures
#
# 		) Perform asymmetric encryption and decryption
#
# 		) Use cryptographic hashing for digital signing and data verification and validation
#
# MySQL Enterprise Encryption supports the RSA, DSA and DH cryptographic algorithms.
#
# MySQL Enterprise Encryption is supplied as a user-defined function (UDF) library, from which
# individual functions can be installed individually.
#
# 12.19.1 MYSQL ENTERPPRISE ENCRYPTION INSTALLATION
#
# MySQL Enterprise Encryption functions are located in a user-defined function
# (UDF) library file installed in the plugin directory (the directory named by the
# plugin_dir system variable)
#
# The UDF library base name is openssl_udf and the suffix is platform dependent.
#
# For example, the file name on Linux or Windows is openssl_udf.so or openssl_udf.dll,
# respectively.
#
# To install functions from the library file, use the CREATE_FUNCTION statement.
#
# To load all functions from the library, use this set of statements (adjust the file
# name suffix as necessary):
#
# 		CREATE FUNCTION asymmetric_decrypt RETURNS STRING
# 			SONAME 'openssl_udf.so';
# 		CREATE FUNCTION asymmetric_derive RETURNS STRING
# 			SONAME 'openssl_udf.so';
#
# 		CREATE FUNCTION asymmetric_encrypt RETURNS STRING
# 			SONAME 'openssl_udf.so';
# 		CREATE FUNCTION asymmetric_sign RETURNS STRING
# 			SONAME 'openssl_udf.so';
#
# 		CREATE FUNCTION asymmetric_verify RETURNS INTEGER
# 			SONAME 'openssl_udf.so';
# 		CREATE FUNCTION create_asymmetric_priv_key RETURNS STRING
# 			SONAME 'openssl_udf.so';
#
# 		CREATE FUNCTION create_asymmetric_pub_key RETURNS STRING
# 			SONAME 'openssl_udf.so';
# 		CREATE FUNCTION create_dh_parameters RETURNS STRING
# 			SONAME 'openssl_udf.so';
# 
# 		CREATE FUNCTION create_digest RETURNS STRING
# 			SONAME 'openssl_udf.so';
#
# Once installed, UDFs remain installed across server restarts.
#
# To unload UDFs, use the DROP_FUNCTION statement.
#
# For example, to unload the key-generation functions, do
# this:
#
# 		DROP FUNCTION create_asymmetric_priv_key;
# 		DROP FUNCTION create_asymmetric_pub_key;
#
# In the CREATE_FUNCTION and DROP_FUNCTION statements, the function names must be
# specified in lowercase.
#
# This differs from their use at function invocation time, for which you
# can use any lettercase.
#
# The CREATE_FUNCTION and DROP_FUNCTION statements require the INSERT and
# DROP privilege, respectively, for the mysql database.
#
# 12.19.2 MySQL ENTERPRISE ENCRYPTION USAGE AND EXAMPLES
#
# To use MySQL Enterprise Encryption in applications, invoke the functions that
# are appropriate for the operations you wish to perform.
#
# This section demonstrates how to carry out some representative tasks:
#
# 		) Create a private/public key pair using RSA encryption
#
# 		) Use the private key to encrypt data and the public key to decrypt it
#
# 		) Generate a digest from a string
#
# 		) Use the digest with a key pair
#
# 		) Create a symmetric key
#
# 		) Limit CPU usage by key-generation operations
#
# CREATE A PRIVATE/PUBLIC KEY PAIR USING RSA ENCRYPTION
#
# 		-- Encryption algorithm; can be 'DSA' or 'DH' instead
# 		SET @algo = 'RSA';
# 		-- Key length in bits; make larger for strong keys
# 		SET @key_len = 1024;
#
# 		-- Create private key
# 		SET @priv = CREATE_ASYMMETRIC_PRIV_KEY(@algo, @key_len);
# 		-- Derive corresponding public key from private key, using same algorithm
# 		SET @pub = CREATE_ASYMMETRIC_PUB_KEY(@algo, @priv);
#
# Now you can use the key pair to encrypt and decrypt data, sign and verify data,
# or generate symmetric keys.
#
# USE THE PRIVATE KEY TO ENCRYPT DATA AND THE PUBLIC KEY TO DECRYPT IT
#
# This requires that the members of the key pair be RSA keys.
#
# 		SET @ciphertext = ASYMMETRIC_ENCRYPT(@algo, 'My secret text', @priv);
# 		SET @cleartext = ASYMMETRIC_DECRYPT(@algo, @ciphertext, @pub);
#
# Conversely, you can encrypt using the public key and decrypt using the private key.
#
# 		SET @ciphertext = ASYMMETRIC_ENCRYPT(@algo, 'My secret text', @pub);
# 		SET @cleartext = ASYMMETRIC_DECRYPT(@algo, @ciphertext, @priv);
#
# In either case, the algorithm specified for the encryption and decryption
# functions must match that used to generate the keys.
#
# GENERATE A DIGEST FROM A STRING
#
# 		-- Digest type; can be 'SHA256', 'SHA384', or 'SHA512' instead
# 		SET @dig_type = 'SHA224';
#
# 		-- Generate digest string
# 		SET @dig = CREATE_DIGEST(@dig_type, 'My text to digest');
#
# USE THE DIGEST WITH A KEY PAIR
#
# The key pair can be used to sign data, then verify that the signature
# matches the digest.
#
# 		-- Encryption algorithm; could be 'DSA' instead; keys must
# 		-- have been created using same algorithm
# 		SET @algo = 'RSA';
#
# 		-- Generate signature for digest and verify signature against digest
# 		SET @sig = ASYMMETRIC_SIGN(@algo, @dig, @priv, @dig_type);
# 		-- verify signature against digest
# 		SET @verf = ASYMMETRIC_VERIFY(@algo, @dig, @sig, @pub, @dig_type);
#
# CREATE A SYMMETRIC KEY
#
# This requires DH private/public keys as inputs, created using a shared symmetric secret.
#
# Create the secret by passing the key length to CREATE_DH_PARAMETERS(), then pass
# the secret as the "key length" to CREATE_ASYMMETRIC_PRIV_KEY()
#
# 		-- Generate DH shared symmetric secret
# 		SET @dhp = CREATE_DH_PARAMETERS(1024);
#
# 		-- Generate DH key pairs
# 		SET @algo = 'DH';
# 		SET @priv1 = CREATE_ASYMMETRIC_PRIV_KEY(@algo, @dhp);
# 		SET @pub1 = CREATE_ASYMMETRIC_PUB_KEY(@algo, @priv1);
#
# 		SET @priv2 = CREATE_ASYMMETRIC_PRIV_KEY(@algo, @dhp);
# 		SET @pub2 = CREATE_ASYMMETRIC_PUB_KEY(@algo, @priv2);
#
# 		-- Generate symmetric key using public key of first party,
# 		-- private key of second party
# 		SET @sym1 = ASYMMETRIC_DERIVE(@pub1, @priv2);
#
# 		-- Or use public key of second party, private key of first party
# 		SET @sym2 = ASYMMETRIC_DERIVE(@pub2, @priv1);
#
# Key string values can be created at runtime and stored into a variable
# or table using SET, SELECT, or INSERT:
#
# 		SET @priv1 = CREATE_ASYMMETRIC_PRIV_KEY('RSA', 1024);
# 		SELECT CREATE_ASYMMETRIC_PRIV_KEY('RSA', 1024) INTO @priv2;
# 		INSERT INTO t (key_col) VALUES(CREATE_ASYMMETRIC_PRIV_KEY('RSA', 1024));
#
# Key string values stored in files can be read using the LOAD_FILE() function by users
# who have the FILE privilege.
#
# Digest and signature strings can be handled similarly
#
# LIMIT CPU USAGE BY KEY-GENERATION OPERATIONS
#
# The CREATE_ASYMMETRIC_PRIV_KEY() and CREATE_DH_PARAMETERS() encryption functions
# take a key-length parameter, and the amount of CPU resources required by these functions
# increases as the key length increases.
#
# For some installations, this might result in unacceptable CPU usage if applications
# frequently generate excessively long keys.
#
# OpenSSL imposes a minimum key length of 1,024 bits for all keys.
#
# OpenSSL also imposes a maximum key length of 10,000 bits and 16,384 bits
# for DSA and RSA keys, respetively, for CREATE_ASYMMETRIC_PRIV_KEY(), and
# a maximum key length of 10,000 bits for CREATE_DH_PARAMETERS()
#
# If those maximum values are too high, three environment variables are available
# to enable MySQL server administrators to set lower maximum lengths for key generation,
# and thereby to limit CPU usage:
#
# 		) MySQL_OPENSSL_UDF_DSA_BITS_THRESHOLD: Maximum DSA key length in bits for 
# 			CREATE_ASYMMETRIC_PRIV_KEY() 
#
# 			The minimum and maximum values for this variable are 1,024 and 10,000
#
# 		) MySQL_OPENSSL_UDF_RSA_BITS_THRESHOLD: Maximum RSA key length in bits for
# 			CREATE_ASYMMETRIC_PRIV_KEY()
#
# 			The minimum and maximum values for this variable are 1,024 and 16,384
#
# 		) MySQL_OPENSSL_UDF_DH_BITS_THRESHOLD: Maximum key length in bits for 
# 			CREATE_DH_PARAMETERS()
#
# 			The minimum and maximum values for this variable are 1,024 and 10,100
#
# To use any of these environment variables, set them in the environment of the process
# that starts the server.
#
# If set, their values take precedence over the maximum key lengths imposed by OpenSSL.
#
# For example, to set a maximum key length of 4,096 bits for DSA and RSA keys for
# CREATE_ASYMMETRIC_PRIV_KEY(), set these variables:
#
# 		export MySQL_OPENSSL_UDF_DSA_BITS_THRESHOLD=4096
# 		export MySQL_OPENSSL_UDF_RSA_BITS_THRESHOLD=4096
#
# The example uses Bourne shell syntax. The syntax for other shells may difer.
#
# 12.19.3 MySQL ENTERPRISE ENCRYPTION FUNCTION REFERENCE
#
# TABLE 12.24 MySQL ENTERPRISE ENCRYPTION FUNCTIONS
#
# 		NAME 							Description
#
# ASYMMETRIC_DECRYPT() 			Decrypt ciphertext using private or public key
#
# ASYMMETRIC_DERIVE() 			Derive symmetric key from asymmetric keys
#
# ASYMMETRIC_ENCRYPT() 			Encrypt cleartext using private or public key
#
# ASYMMETRIC_SIGN() 				Generate signature from digest
#
# ASYMMETRIC_VERIFY() 			Verify that signature matches digest
#
# CREATE_ASYMMETRIC_PRIV_KEY() Create private key
#
# CREATE_ASYMMETRIC_PUB_KEY() Create public key
#
# CREATE_DH_PARAMETERS() 		Generate shared DH secret
#
# CREATE_DIGEST() 				Generate digest from string
#
# 12.19.4 MYSQL ENTERPRISE ENCRYPTION FUNCTION DESCRIPTIONS
#
# MySQL Enterprise Encryption functions have these general characteristics:
#
# 		) For arguments of the wrong type or an incorrect number of arguments, each function returns an error
#
# 		) If the arguments are not suitable to permit a function to perform the requested operation, it returns
# 			NULL or 0 as appropriate.
#
# 			This occurs, for example, if a function does not support a specific algorithm, a key length
# 			is too short or too long, or a string expected to be a key string in PEM format is not a valid
# 			key.
#
# 			(OpenSSL imposes its own key-length limits, and server administrators can impose additional limits
# 			on maximum key length by setting environment variables.
#
# 			See SECTION 12.19.2, "MYSQL ENTERPRISE ENCRYPTION USAGE AND EXAMPLES"
#
# 		) The underlying SSL library takes care of randomness initialization
#
# Several of the functions take an encryption algorithm argument.
#
# The following table summarizes the supported algorithms by function.
#
# TABLE 12.25 SUPPORTED ALGORITHMS BY FUNCTION
#
# 		FUNCTION 					SUPPORTED ALGORITHMS
#
# ASYMMETRIC_DECRYPT() 				RSA
#
# ASYMMETRIC_DERIVE() 				DH
#
# ASYMMETRIC_ENCRYPT() 				RSA
#
# ASYMMETRIC_SIGN() 					RSA, DSA
#
# ASYMMETRIC_VERIFY() 				RSA, DSA
#
# CREATE_ASYMMETRIC_PRIV_KEY() 	RSA, DSA, DH
#
# CREATE_ASYMMETRIC_PUB_KEY() 	RSA, DSA, DH
#
# CREATE_DH_PARAMETERS() 			DH
#
# NOTE:
#
# 		Although you can create keys using any of the RSA, DSA or DH encryption
# 		algorithms, other functions that take key arguments might accept only
# 		certain types of keys.
#
# 		For example, ASYMMETRIC_ENCRYPT() and ASYMMETRIC_DECRYPT() accept only RSA keys
#
# The following descriptions describe the calling sequences for MySQL Enterprise Encryption
# functions.
#
# For additional examples and discussion, see SECTION 12.19.2, "MySQL ENTERPRISE ENCRYPTION USAGE AND EXAMPLES"
#
# 		) ASYMMETRIC_DECRYPT(algorithm, crypt_str, key_str)
#
# 			Decrypts an encrypted string using the given algorithm and key string, and returns the resulting
# 			cleartext as a binary string. If decryption fails, the result is NULL.
#
# 			key_str must be a valid key string in PEM format.
#
# 			For successful decryption, it must be the public or private key string
# 			corresponding to the private or public key string used with the
# 			ASYMMETRIC_ENCRYPT() to produce the encrypted string.
#
# 			algorithm indicates the encryption algorithm used to create the key.
#
# 			Supported algorithm values: 'RSA'
#
# 			For a usage example, see the description of ASYMMETRIC_ENCRYPT()
#
# 		) ASYMMETRIC_DERIVE(pub key str, priv key str)
#
# 			Derives a symmetric key using the private key of one party and the public
# 			key of another, and returns the resulting key as a binary string.
#
# 			If key derivation fails, the result is NULL
#
# 			pub_key_str and priv_key_str must be valid key strings in PEM format.
#
# 			They must be created using the DH algorithm.
#
# 			Suppose that you have  two pairs of public and private keys:
#
# 				SET @dhp = CREATE_DH_PARAMETERS(1024);
# 				SET @priv1 = CREATE_ASYMMETRIC_PRIV_KEY('DH', @dhp);
#
# 				SET @pub1 = CREATE_ASYMMETRIC_PUB_KEY('DH', @priv1);
# 				SET @priv2 = CREATE_ASYMMETRIC_PRIV_KEY('DH', @dhp);
#
# 				SET @pub2 = CREATE_ASYMMETRIC_PUB_KEY('DH', @priv2);
#
# 			Suppose further that you use the private key from one pair and the public key
# 			from the other pair to create a symmetric key string.
#
# 			Then this symmetric key identity relationship holds:
#
# 				ASYMMETRIC_DERIVE(@pub1, @priv2) = ASYMMETRIC_DERIVE(@pub2, @priv1)
#
# 		) ASYMMETRIC_ENCRYPT(algorithm, str, key_str)
#
# 			Encrypts a string using the given algorithm and key string, and returns
# 			the resulting ciphertext as a binary string.
#
# 			If encryption fails, the result is NULL
#
# 			The str length cannot be greater than the key_str length - 11, in bytes
#
# 			key_str must be a valid key string in PEM format. algorithm indicates
# 			the encryption algorithm used to create the key.
#
# 			Supported algorithm values: 'RSA'
#
# 			To encrypt a string, pass a private or public key string to ASYMMETRIC_ENCRYPT()
#
# 			To recover the original unencrypted string, pass the encrypted string to
# 			ASYMMETRIC_DECRYPT(), along with the public or private key string corresponding
# 			to the private or public key string used for encryption.
#
# 				-- Generate private/public key pair
# 				SET @priv = CREATE_ASYMMETRIC_PRIV_KEY('RSA', 1024);
# 				SET @pub = CREATE_ASYMMETRIC_PUB_KEY('RSA', @priv);
#
# 				-- Encrypt using private key, decrypt using public key
# 				SET @ciphertext = ASYMMETRIC_ENCRYPT('RSA', 'The quick brown fox', @priv);
# 				SET @cleartext = ASYMMETRIC_DECRYPT('RSA', @ciphertext, @pub);
#
# 				-- Encrypt using public key, decrypt using private key
# 				SET @ciphertext = ASYMMETRIC_ENCRYPT('RSA', 'The quick brown fox', @pub);
# 				SET @cleartext = ASYMMETRIC_DECRYPT('RSA', @ciphertext, @priv);
#
# 			Suppose that:
#
# 				SET @s = a string to be encrypted
# 				SET @priv = a valid private RSA key string in PEM format
# 				SET @pub = the corresponding public RSA key string in PEM format
#
# 			Then these identity relationships hold:
#
# 				ASYMMETRIC_DECRYPT('RSA', ASYMMETRIC_ENCRYPT('RSA', @s, @priv), @pub) = @s
# 				ASYMMETRIC_DECRYPT('RSA', ASYMMETRIC_ENCRYPT('RSA', @s, @pub), @priv) = @s
#
# 		) ASYMMETRIC_SIGN(algorithm, digest str, priv key str, digest type)
#
# 			Signs a digest string using a private key string, and returns the signature
# 			as a binary string.
#
# 			If signing fails, the result is NULL
#
# 			digest_str is the digest string. It can be generated by calling CREATE_DIGEST().
#
# 			digest_type indicates the digest algorithm used to generate the digest string
#
# 			priv_key_str is the private key string to use for signing the digest string.
# 			It must be a valid key string in PEM format.
#
# 			algorithm indicates the encryption algorithm used to create the key.
#
# 			Supported algorithm values: 'RSA', 'DSA'
#
# 			Supported digest_type values: 'SHA224', 'SHA384', 'SHA512'
#
# 			For a usage example, see the description of ASYMMETRIC_VERIFY()
#
# 		) ASYMMETRIC_VERIFY(algorithm, digest_str, sig_str, pub_key_str, digest_type)
#
# 			Verifies whether the signature string matches the digest string, and returns
# 			1 or 0 to indicate whether verification succeeded or failed.
#
# 			digest_str is the digest string. It can be generated by calling CREATE_DIGEST()
#
# 			digest_type indicates the digest algorithm used to generate the digest string.
#
# 			sig_str is the signature string. It can be generated by calling ASYMMETRIC_SIGN()
#
# 			pub_key_str is the public key string of the signer.
#
# 			It corresponds to the private key passed to ASYMMETRIC_SIGN() to generate the signature
# 			string and must be a valid key string in PEM format
#
# 			algorithm indicates the encryption algorithm used to create the key
#
# 			Supported algorithm values: 'RSA', 'DSA'
#
# 			Supported digest_type values: 'SHA224', 'SHA256', 'SHA384', 'SHA512'
#
# 				-- Set the encryption algorithm and digest type
# 				SET @algo = 'RSA';
# 				SET @dig_type = 'SHA224';
#
# 				-- Create private/public key pair
# 				SET @priv = CREATE_ASYMMETRIC_PRIV_KEY(@algo, 1024);
# 				SET @pub = CREATE_ASYMMETRIC_PUB_KEY(@algo, @priv);
#
# 				--- Generate digest from string
# 				SET @dig = CREATE_DIGEST(@dig_type, 'The quick bornw fox');
#
# 				-- generate signature for digest and verify signature against digest
# 				SET @sig = ASYMMETRIC_SIGN(@algo, @dig, @priv, @dig_type);
# 				SET @verf = ASYMMETRIC_VERIFY(@algo, @dig, @sig, @pub, @dig_type);
#
# 		) CREATE_ASYMMETRIC_PRIV_KEY(algorithm, {key len|dh secret})
#
# 			Creates a private key using the given algorithm and key length or DH secret,
# 			and returns the key as a binary string in PEM format.
#
# 			If key generation fails, the result is NULL
#
# 			Supported algorithm values: 'RSA', 'DSA', 'DH'
#
# 			Supported key_len values: The minimum key length in bits is 1,024
#
# 			THe maximum key length depends on the algorithm: 16,384 for RSA and
# 			10,000 for DSA.
#
# 			These key-length limits are constraints imposed by OpenSSL.
#
# 			Server administrators can impose additional limits on maximum key length
# 			by setting environment variables.
#
# 			see SECTION 12.19.2, "MYSQL ENTERPRISE USAGE AND EXAMPLES"
#
# 			For DH keys, pass a shared DH secret instead of a key length.
#
# 			To create the secret, pass the key length to CREATE_DH_PARAMETERS()
#
# 			This example creates a 2,048-bit DSA private key, then derives a public key
# 			from the private key:
#
# 				SET @priv = CREATE_ASYMMETRIC_PRIV_KEY('DSA', 2048);
# 				SET @pub = CREATE_ASYMMETRIC_PUB_KEY('DSA', @priv);
#
# 			For an example showing DH key generation, see the description of ASYMMETRIC_DERIVE()
#
# 			Some general considerations in choosing key lengths and encryption algorithms:
#
# 				) The strength of encryption for private and public keys increases with the key size,
# 					but the time for key generation increases as well
#
# 				) Generation of DH keys takes much longer than RSA or RSA keys
#
# 				) Asymmetric encryption functions are slower than symmetric functions.
#
# 					If performance is an important factor and the functions are to be used
# 					very frequently, you are better off using symmetric encryption.
#
# 					For example, consider using AES_ENCRYPT() and AES_DECRYPT()
#
# 		) CREATE_ASYMMETRIC_PUB_KEY(algorithm, priv_key_str)
#
# 			Derives a public key from the given private key using the given algorithm,
# 			and returns the key as a binary string in PEM format.
#
# 			If key derivation fails, teh result is NULL
#
# 			priv_key_str must be a valid key string in PEM format.
# 			algorithm indicates the encryption algorithm used to create the key.
#
# 			Supported algorithm values: 'RSA', 'DSA', 'DH'
#
# 			For a usage example, see the description of CREATE_ASYMMETRIC_PRIV_KEY()
#
# 		) CREATE_DH_PARAMETERS(key_len)
#
# 			Creates a shared secret for generating a DH private/public key pair and returns
# 			a binary string that can be passed to CREATE_ASYMMETRIC_PRIV_KEY()
#
# 			If secret generation fails, the result is null
#
# 			Supported key_len values: The minimum and maximum key lengths in bits are
# 			1,024 and 10,000
#
# 			These key-length limits are constraints imposed by OpenSSL.
#
# 			Server administrators can impose additional limits on maximum key length
# 			by setting environment variables.
#
# 			See SECTION 12.19.2, "MySQL ENTERPRISE ENCRYPTION USAGE AND EXAMPLES"
#
# 			For an example showing how to use the return value for generating symmetric keys,
# 			see the description of ASYMMETRIC_DERIVE()
#
# 				SET @dhp = CREATE_DH_PARAMETERS(1024);
#
# 		) CREATE_DIGEST(digest type, str)
#
# 			Creates a digest from the given string using the given digest type, and returns the
# 			digest as a binary string.
#
# 			If digest generation fails, the result is NULL 
#
# 			Supported digest_type values: 'SHA224', 'SHA256', 'SHA384', 'SHA512'
#
# 				SET @dig = CREATE_DIGEST('SHA512', The quick brown fox');
# 	
# 			The resulting digest string is suitable for use with ASYMMETRIC_SIGN()
# 			and ASYMMETRIC_VERIFY()
#
# 12.20 AGGREGATE (GROUP BY) FUNCTIONS
#
# 12.20.1 AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS
# 12.20.2 GROUP BY MODIFIERS
# 12.20.3 MySQL HANDLING OF GROUP BY
# 12.20.4 DETECTION OF FUNCTIONAL DEPENDENCE
#
# 12.20.1 AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS
#
# This section describes group (aggregate) functions that operate on sets of values.
#
# TABLE 12.26 AGGREGATE (GROUP BY) FUNCTIONS
#
# Name 				Desc
#
# AVG() 				Return the average value of the argument
#
# BIT_AND() 		Return bitwise AND
#
# BIT_OR() 			Return bitwise OR
#
# BIT_XOR() 		Return bitwise XOR
#
# COUNT() 			Return a count of the number of rows returned
#
# COUNT(DISTINCT) Return the count of a number of different values
#
# GROUP_CONCAT() 	Return a concatenated string
#
# JSON_ARRAYAGG() Return result set as a single JSON array
#
# JSON_OBJECTAGG() Return result set as a single JSON object
#
# MAX() 				Return the maximum value
#
# MIN() 				Return the minimum value
#
# STD() 				Return the pop standard deviation
#
# STDDEV() 			Return the pop standard deviation
#
# STDDEV_POP() 	Return the pop standard deviation
#
# STDDEV_SAMP() 	Return the sample standard deviation
#
# SUM() 				Return the sum
#
# VAR_POP() 		Return the population standard variance
#
# VAR_SAMP() 		Return the sample variance
#
# VARIANCE() 		Return the population standard variance
#
# Unless otherwise stated, group functions ignore NULL values.
#
# If you use a group function in a statement containing no GROUP BY clause,
# it is equivalent to grouping on all rows.
#
# For more information, see SECTION 12.20.3, "MYSQL HANDLING OF GROUP BY"
#
# Most aggregate functions can be used as window functions.
#
# Those that can be used this way are signified in their syntax description
# by [over_clause], representing an optional OVER clause.
#
# over_clause is described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX",
# which also includes other information about window function usage.
#
# For numeric arguments, the variance and standard deviation functions return a 
# DOUBLE value.
#
# The SUM() and AVG() functions return a DECIMAL value for exact-value arguments
# (integer or DECIMAL), and a DOUBLE value for approximate-value arguments
# (FLOAT or DOUBLE)
#
# The SUM() and AVG() aggregate functions do not work with temporal values.
#
# (They convert the values to numbers, losing everything after the first nonnumeric
# character)
#
# To work around this, convert to numeric units, perform the aggregate operation,
# and convert back to a temporal value.
#
# Examples:
#
# 		SELECT SEC_TO_TIME(SUM(TIME_TO_SEC(time_col))) FROM tbl_name;
# 		SELECT FROM_DAYS(SUM(TO_DAYS(date_col))) FROM tbl_name;
#
# Functions such as SUM() or AVG() that expect a numeric argument cast the argument
# to a number if necessary.
#
# For SET or ENUM values, the cast operation causes the underlying numeric value
# to be used.
#
# The BIT_AND(), BIT_OR() and BIT_XOR() aggregate functions perform bit operations.
#
# Prior to MySQL 8.0, bit functions and operators required BIGINT(64-bit integer)
# arguments and returned BIGINT values, so they had a maximum range of 64 bits.
#
# Non-BIGINT arguments were converted to BIGINT prior to performing the operation
# and truncation could occur.
#
# In MySQL 8.0, bit functions and operators permit binary string type arguments
# (BINARY, VARBINARY, and the BLOB types) and return a value of like type, which
# enables them to take arguments and produce return values larger than 64 bits.
#
# For discussion about argument evaluation and result types for bit operations,
# see the introductory discussion in SECTION 12.12, "BIT FUNCTIONS AND OPERATORS"
#
# 		) AVG([DISTINCT] expr) [over clause]
#
# 			Returns the average value of expr. The DISTINCT option can be used to return
# 			the average of the distinct values of expr.
#
# 			If there are no matching rows, AVG() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX";
# 			it cannot be used with DISTINCT.
#
# 				SELECT student_name, AVG(test_score)
# 				FROM student
# 				GROUP BY student_name;
#
# 		) BIT_AND(expr) [over_clause]
#
# 			Returns the bitwise AND of all bits in expr
#
# 			The result type depends on whether the function argument values are evaluated
# 			as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the argument values have a binary string type,
# 					and the argument is not a hexadecimal literal, bit literal, or NULL literal.
#
# 					Numeric evaluation occurs otherwise, with argument value conversion to unsigned
# 					64-bit integers as necessary
#
# 				) Binary-string evaluation produces a binary string of the same length as the argument values.
#
# 					If argument values have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 					If the argument size exceeds 511 bytes, an ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE error occurs.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			If there are no matching rows, BIT_AND() returns a neutral value (all bits set to 1) having the same length
# 			as the argument values.
#
# 			NULL values do not affect the result unless all values are NULL.
#
# 			In that case, the result is a neutral value having the same length as the argument values.
#
# 			For more information discussion about argument evaluation and result types, see the intro
# 			discussion in SECTION 12.12, "BIT FUNCTIONS AND OPERATORS"
#
# 			As of MySQL 8.0.12, this function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) BIT_OR(expr) [over clause]
#
# 			Returns the bitwise OR of all bits in expr.
#
# 			The result type depends on whether the function argument values are evaluated
# 			as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the argument values have a binary string type,
# 					and the argument is not a hexadecimal literal, bit literal or NULL literal.
#
# 					Numeric evaluation occurs otherwise, with argument value conversion to unsigned
# 					64-bit integers as necessary
#
# 				) Binary-string evaluation produces a binary string of the same length as the argument values.
#
# 					If argument values have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE error occurs.
#
# 					If the argument size exceeds 511 bytes, an ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE
# 					error occurs.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			If there are no matching rows, BIT_OR() returns a neutral value (all bits set to 0) having
# 			the same length as the argument values.
#
# 			NULL values do not affect the result unless all values are NULL.
#
# 			In that case, the result is a neutral value having the same length as the argument values.
#
# 			For more information discussions about argument evaluation and result types, see the intro
# 			discussion in SECTION 12.12, "BIT FUNCTIONS AND OPERATORS"
#
# 			As of MySQL 8.0.12, this function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) BIT_XOR(expr)_[over_clause]
#
# 			Returns the bitwise XOR of all bits in expr
#
# 			The result type depends on whether the function argument values are evaluated
# 			as binary strings or numbers:
#
# 				) Binary-string evaluation occurs when the argument values have a binary string type,
# 					and the argument is not a hexadecimal literal, bit literal or NULL literal
#
# 					Numeric evaluation occurs otherwise, with argument value conversion to unsigned
# 					64-bit integers as necessary.
#
# 				) Binary-string evaluation produces a binary string of the same length as the
# 					argument values.
#
# 					If argument values have unequal lengths, an ER_INVALID_BITWISE_OPERANDS_SIZE
# 					error occurs.
#
# 					If the argument size exceeds 511 bytes, an ER_INVALID_BITWISE_AGGREGATE_OPERANDS_SIZE
# 					error occurs.
#
# 					Numeric evaluation produces an unsigned 64-bit integer
#
# 			If there are no matching rows, BIT_XOR() returns a neutral value (all bits set to 0) having the same
# 			length as the argument values.
#
# 			NULL values do not affect the result unless all values are NULL.
#
# 			In that case, the result is a neutral value having the same length as the argument values.
#
# 			For more information discussion about argument evaluation and result types, see the intro discussion
# 			in SECTION 12.12, "BIT FUNCTIONS AND OPERATORS"
#
# 			As of MySQL 8.0.12, this function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) COUNT(expr)_[over_clause]
#
# 			Returns a count of the number of non-NULL values of expr in the rows retrieved by a
# 			SELECT statement.
#
# 			The result is a BIGINT value.
#
# 			If there are no matching rows, COUNT() returns 0
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 				SELECT student.student_name,COUNT(*)
# 				FROM student, course
# 				WHERE student.student_id=course.student_id
# 				GROUP BY student_name;
#
# 			COUNT(*) is somewhat different in that it returns a count of the number of rows
# 			retrieved, whether or not they contain NULL values.
#
# 			For transactional storage engines suchh as InnoDB, storing an exact row count
# 			is problematic.
#
# 			Multiple transactions may be occurring at the same time, each of which
# 			may affect the count.
#
# 			InnoDB does not keep an internal count of rows in a table because concurrent
# 			transactions might "see" differnet number of rows at the same time.
#
# 			Consequently, SELECT  COUNT(*) statements only count rows visible to the current transaction.
#
# 			As of MySQL 8.0.13, SELECT COUNT(*) FROM tbl_name query performance for InnoDB
# 			tables is optimized for single-threaded workloads if there are no extra
# 			clauses such as WHERE or GROUP BY
#
# 			InnoDB processes SELECT COUNT(*) statements by traversing the smallest available
# 			secondary index unless an index or optimizer hint directs the optimizer to use a
# 			different index.
#
# 			If a secondary index is not present, InnoDB processes SELECT COUNT(*) statements
# 			by scanning the clustered index.
#
# 			As of MySQL 8.0.14, InnoDB supports parallel index reads, which improves performance
# 			of non-locking SELECT COUNT(*) FROM tbl_name queries.
#
# 			The innodb_parallel_read_threads session variable must be set to a value greater than
# 			1 for parallel index reads to occur.
#
# 			The default value is 4.
#
# 			The actual number of threads used to perform a parallel index read is determined by the
# 			innodb_parallel_read_threads setting or the number of index subtrees to scan,
# 			whichever is smaller.
#
# 			The pages read into the buffer pool during the scan are kept at the tail of the buffer
# 			pool LRU list so that they can be discarded quickly when free buffer pool pages
# 			are required.
#
# 			Processing SELECT COUNT(*) statements takes some time if index records are not entirely
# 			in the buffer pool.
#
# 			For a faster count, create a counter table and let your application update it according
# 			to the inserts and deletes it does.
#
# 			However, this method may not scale well in situations where thousands of concurrent transactions
# 			are initiating updates to the same counter table.
#
# 			If an approximate row count is sufficient, use SHOW_TABLE_STATUS.
#
# 			InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way.
#
# 			There is no performance difference.
#
# 			For MyISAM tables, COUNT(*) is optimized to return very quickly if the SELECT retrieves
# 			from one table, no other columns are retrieved - and there is no WHERE clause.
#
# 			For example:
#
# 				SELECT COUNT(*) FROM student;
#
# 			This optimization only applies to MyISAM tables, because an exact row count is stored
# 			for this storage engine and can be accessed very quickly.
#
# 			COUNT(1) is only subject to the same optimization if hte first column is defined
# 			as NOT NULL.
#
# 		) COUNT(DISTINCT expr, [expr ---])
#
# 			Returns a count of the number of rows with different non-NULL expr values.
#
# 			If there are no matching rows, COUNT(DISTINCT) returns 0
#
# 				SELECT COUNT(DISTINCT results) FROM student;
#
# 			In MySQL, you can obtain the number of distinct expression combinations that do not contain
# 			NULL by giving a list of expressions.
#
# 			In standard SQL, you would have to do a concatenation of all expressions
# 			inside COUNT(DISTINCT ---)
#
# 		) GROUP_CONCAT(expr)
#
# 			This function returns a string result with the concatenated non-NULL values from a group.
#
# 			It returns NULL if there are no non-NULL values. The full syntax is as follows:
#
# 				GROUP_CONCAT([DISTINCT] expr [, expr ---]
# 								[ORDER BY {unsigned_integer | col_name | expr}
# 									[ASC |DESC] [,col_name ---]]
# 								[SEPARATOR str_val])
#
# 				SELECT student_name,
# 					GROUP_CONCAT(test_score),
# 				FROM student
# 				GROUP BY student_name;
#
# 				OR
#
# 				SELECT student_name,
# 					GROUP_CONCAT(DISTINCT test_score,
# 									ORDER BY test_score DESC SEPARATOR ' ')
# 				FROM student
# 				GROUP BY student_name;
#
# 			In MySQL, you can get the concatenated values of expression combinations.
#
# 			To eliminate duplicate values, use the DISTINCT clause.
#
# 			To sort values in the result, use the ORDER BY clause. To sort in reversed order,
# 			add the DESC (descending) keyword to the name of the column you are sorting by in
# 			the ORDER BY clause.
#
# 			The default is ascending order; this may be specified explicitly using the ASC keyword.
#
# 			The default separator between values in a group is comma (,)
#
# 			To specify a separator explicitly, use SEPARATOR followed by the string literal value
# 			that should be inserted between group values.
#
# 			TO eliminate the separator altogether, specify SEPARATOR ''
#
# 			The result is truncated to the maximum length that is given by the
# 			group_concat_max_len system variable, which has a default value of 1024.
#
# 			THe value can be set higher, although the effective maximum length
# 			is constraned by the value of max_allowed_packet.
#
# 			The syntax to change the value of group_concat_max_len at runtime is as
# 			follows, where val is an unsigned integer:
#
# 				SET [GLOBAL | SESSION] group_concat_max_len = val;
#
# 			The return value is a nonbinary or binary string, depending on whether the
# 			arguments are nonbinary or binary strings.
#
# 			The result type is TEXT or BLOB unless group_concat_max_len is less
# 			than or equal to 512, in which case the result type is VARCHAR or
# 			VARBINARY.
#
# 			See also CONCAT() and CONCAT_WS(): SECTION 12.5, "STRING FUNCTIONS"
#
# 		) JSON_ARRAYAGG(col or expr) [over clause]
#
# 			Aggregates a result set as a single JSON array whose elements consists of the rows.
#
# 			The order of elements in this array is undefuned.
#
# 			The function acts on a column or an expression that evaluates
# 			to a single value. Returns NULL if the result contains no rows,
# 			or in the event of an error.
#
# 			As of MySQL 8.0.14, this function executes as a window function if over_clause
# 			is present
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTIONS CONCEPTS AND SYNTAX"
#
# 				SELECT o_id, attribute, value FROM t3;
# 				+-------+---------------+---------+
# 				| o_id  | attribute 	   | value   |
# 				+-------+---------------+---------+
# 				| 2 	  | color 			| red 	 |
# 				| 2 	  | fabric 			| silk 	 |
# 				| 3 	  | color 			| green 	 |
# 				| 3 	  | shape 			| square  |
# 				+-------+---------------+---------+
# 				4 rows in set (0.00 sec)
#
# 				SELECT o_id, JSON_ARRAYAGG(attribute) AS attributes
# 				FROM t3 GROUP BY o_id;
# 				+---------+-----------------------+
# 				| o_id 	 | attributes 				 |
# 				+---------+-----------------------+
# 				| 2 		 | ["color", "fabric"] 	 |
# 				| 3 		 | ["color", "shape"] 	 |
# 				+---------+-----------------------+
# 				2 rows in set (0.00 sec)
#
# 		) JSON_OBJECTAGG(key, value) [over_clause]
#
# 			Takes two column names or expressions as arguments, the first of these being used
# 			as a key and the second as a value, and returns a JSON object containing key-value
# 			pairs.
#
# 			Returns NULL if the result contains no rows, or in the event of an error.
#
# 			An error occurs if any key name is NULL or the number of arguments is not equal to
# 			2.
#
# 			As of MySQL 8.0.14, this function executes as a window function if over_clause is
# 			present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			When used as a window function, if there are duplicate keys within a frame, only the 
# 			last value for the key is present in the result.
#
# 			This is in keeping with the MySQL JSON data type specificaiton that does not permit
# 			duplicate keys.
#
# 			When parsing text values as JSON, the value for the last occurring key is retained,
# 			and any earlier values are discarded.
#
# 			The value for the key from last row in the frame is deterministic if the ORDER BY
# 			specification guarantees that the values have a specific order.
#
# 			If not, the resulting value of the key is nondeterministic:
#
# 				SELECT o_id, attribute, value FROM t3;
# 				+--------+--------------+----------+
# 				| o_id 	| attribute 	| value 	  |
# 				+--------+--------------+----------+
# 				| 2 		| color 			| red 	  |
# 				| 2 		| fabric 		| silk 	  |
# 				| 3 		| color 			| green 	  |
# 				| 3 		| shape 			| square   |
# 				+--------+--------------+----------+
# 				4 rows in set (0.00 sec)
#
# 				SELECT o_id, JSON_OBJECTAGG(attribute, value) FROM t3 GROUP BY o_id;
# 				+--------+-----------------------------------------+
# 				| o_id 	| JSON_OBJECTAGG(attribute, name) 			|
# 				+--------+-----------------------------------------+
# 				| 2 		| {"color": "red", "fabric": "silk"} 	   |
# 				| 3 		| {"color": "green", "shape": "square"}   |
# 				+--------+-----------------------------------------+
# 				1 row in set (0.00 sec)
#
# 			DUPLICATE KEY HANDLING:
#
# 				When the result of this function is normalized, values having duplicate keys
# 				are discarded, and only the last value encountered is used with that key
# 				in the returned object ("last duplicate key wins")
#
# 				This means that the result of using this function on columns from a SELECT
# 				can depend on the order in which in the rows are returned, which is not guaranteed.
#
# 				Consider the following:
#
# 			CREATE TABLE t(c VARCHAR(10), i INT);
# 			Query OK, 0 rows affected (0.33 sec)
#
# 			INSERT INTO t VALUES ('key', 3), ('key', 4), ('key', 5);
# 			Query OK, 3 rows affected (0.10 sec)
# 			Records: 3 Duplicates: 0 Warnings: 0
#
# 			SELECT c, i FROM t;
# 			+--------+------------+
# 			| c 		| i 			 |
# 			+--------+------------+
# 			| key 	| 3 			 |
# 			| key 	| 4 			 |
# 			| key 	| 5 			 |
# 			+--------+------------+
# 			3 rows in set (0.00 sec)
#
# 			SELECT JSON_OBJECTAGG(c, i) FROM t;
# 			+-----------------------------------+
# 			| JSON_OBJECTAGG(c, i) 					|
# 			+-----------------------------------+
# 			| {"key": 5}  								|
# 			+-----------------------------------+
# 			1 row in set (0.00 sec)
#
# 			DELETE FROM t;
# 			Query OK, 3 rows affected (0.08 sec)
#
# 			INSERT INTO t VALUES ('key', 3), ('key', 5), ('key', 4);
# 			Query OK, 3 rows affected (0.06 sec)
# 			Records: 3 Duplicates: 0 Warnings: 0
#
# 			SELECT c, i FROM t;
# 			+---------+---------+
# 			| c 		 | i 		  |
# 			+---------+---------+
# 			| key 	 | 3 		  |
# 			| key 	 | 5 		  |
# 			| key 	 | 4 		  |
# 			+---------+---------+
# 			3 rows in set (0.00 sec)
#
# 			SELECT JSON_OBJECTAGG(c, i) FROM t;
# 			+----------------------+
# 			| JSON_OBJECTAGG(c, i) |
# 			+----------------------+
# 			| {"key": 4}			  |
# 			+----------------------+
# 			1 row in set (0.00 sec)
#
# 			See NORMALIZATION, MERGING, AND AUTOWRAPPING OF JSON VALUES for additional information
# 			and examples.
#
# 		) MAX([DISTINCT] expr) [over_clause]
# 
# 			Returns the maximum value of expr
#
# 			MAX() may take a string argument; in such cases, it returns the maximum string value.
# 			See SECTION 8.3.1, "HOW MYSQL USES INDEXES"
#
# 			The DISTINCT keyword can be used to find the maximum of the distinct values of expr,
# 			however, this produces the same result as omitting DISTINCT.
#
# 			If there are no matching rows, MAX() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX",
# 			it cannot be used with DISTINCT.
#
# 				SELECT student_name, MIN(test_score), MAX(test_score)
# 				FROM student
# 				GROUP BY student_name;
#
# 			For MAX(), MySQL currently compares ENUM and SET columns by their string values rather
# 			than by the string's relative position in the set.
#
# 			This differs from how ORDER BY compares them.
#
# 		) MIN([DISTINCT] expr) [over_clause]
#
# 			Returns the minimum value of expr
#
# 			MIN() may take a string argument; in such cases, it returns the minimum
# 			string value.
#
# 			See SECTION 8.3.1, "HOW MYSQL USES INDEXES"
#
# 			The DISTINCT keyword can be used to find the minimum of the distinct values of
# 			expr, however, this produces the same result as omitting DISTINCT.
#
# 			If there are no matching rows, MIN() returns NULL
#
# 			This function executes as a window function if over_clause is present
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX";
# 			it cannot be used with DISTINCT
#
# 				SELECT student_name, MIN(test_score), MAX(test_score)
# 				FROM student
# 				GROUP BY student_name;
#
# 			For MIN(), MySQL currently compares ENUM and SET columns by their string value rather than
# 			by the string's relative position in the set.
#
# 			This differs from how ORDER BY compares them.
#
# 		) STD(expr) [over clause]
#
# 			Returns the population standard deviation of expr.
#
# 			STD() is a synonym for the standard SQL function STDDEV_POP(),
# 			provided as a MySQL extension.
#
# 			If there are no matching rows, STD() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) STDDEV(expr) [over clause]
#
# 			Returns the population standard deviation of expr.
#
# 			STDDEV() is a synonym for the standard SQL function STDDEV_POP(),
# 			provided for compatibility with Oracle.
#
# 			If there are no matching rows, STDDEV() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) STDDEV_POP(expr) [over clause]
#
# 			Returns the population standard deviation of expr (the square root of VAR_POP))
#
# 			You can also use STD() or STDDEV(), which are equivalent but not standard SQL
# 			
# 			If there are no matching rows, STDDEV_POP() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) STDDEV_SAMP(expr) [over clause]
#
# 			Returns the sample standard deviation of expr (the square root of VAR_SAMP())
#
# 			If there are no matching rows, STDDEV_SAMP() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) SUM([DISTINCT] expr) [over clause]
#
# 			Returns the sum of expr. If the return set has no rows, SUM() returns NULL.
#
# 			The DISTINCT keyword can be used to sum only the distinct values of expr.
#
# 			If there are no matching rows, SUM() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX",
# 			it cannot be used with DISTINCT.
#
# 		) VAR_POP(expr) [over_clause]
#
# 			Returns the population standard variance of expr.
#
# 			It considers rows as the whole population,, not as as maple, so it has the
# 			number of rows as the denominator.
#
# 			You can also use VARIANCE(), which is equivalent but is not standard SQL.
#
# 			if there are no matching rows, VAR_POP() returns NULL
#
# 			This function executes as a window function if over_clause is present.
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) VAR_SAMP(expr) [over clause]
#
# 			Returns the sample variance of expr. That is, the denominator is the number of rows
# 			minus one.
#
# 			If there are no matching rows, VAR_SAMP() returns NULL
#
# 			This function executes as a window function if over_clause is present.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) VARIANCE(expr) [over_clause]
#
# 			Returns the population standard variance of expr.
#
# 			VARIANCE() is a synonym for the standard SQL function VAR_POP(), provided as
# 			a MySQL extension.
#
# 			If there are no matching rows, VARIANCE() returns NULL
#
# 			This function executes as a window function if over_clause is present
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 12.20.2 GROUP BY MODIFIERS
#
# The GROUP BY clause permits a WITH ROLLUP modifier that causes summary output to include
# extra rows that represent higher-level (That is, super-aggregate) summary operations.
#
# ROLLUP thus enables you to answer questions at multiple levels of analysis with a single query.
#
# For example, ROLLUP can be used to provide support for OLAP (Online Analytical Processing) operations.
#
# Suppose that a sales table has year, country, product and profit columns for recording
# sales profitability:
#
# 		CREATE TABLE sales
# 		(
# 			year INT,
# 			country VARCHAR(20),
# 			product VARCHAR(32),
# 			profit INT
# 		);
#
# TO summarize table contents per year, use a simple GROUP BY like this:
#
# 		SELECT year, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year;
# +-------+-----------+
# | year  | profit 	 |
# +-------+-----------+
# | 2000  | 4525 		 |
# | 2001  | 3010 		 |
# +-------+-----------+
#
# The output shows the total (aggregate) profit fore ach year.
#
# To also determine the total profit summed over all years, you must add up the individual
# values yourself or run an additional query.
#
# Or, you can use ROLLUP - which provides both levels of analysis with a single query.
#
# Adding a WITH ROLLUP modifier to the GROUP BY clause causes the query to produce
# another (super-aggregate) row that shows the grant total over all year values:
#
# 		SELECT year, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+--------+---------------+
# 		| year 	| profit 		 |
# 		+--------+---------------+
# 		| 2000 	| 4525 			 |
# 		| 2001 	| 3010 			 |
# 		| NULL 	| 7535 			 |
# 		+--------+---------------+
#
# The NULL value in the year column identifies the grant total super-aggregate line.
#
# ROLLUP has a more complex effect when there are multiple GROUP by columns.
#
# In this case, each time there is a change in value in any but the last grouping
# column, the query produces an extra super-aggregate summary row.
#
# For example, without ROLLUP, a summary of the sales table based on year, country,
# and product might look like this, where the output indicates summary values only
# at the year/country/product level of analysis:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product;
# 		+------+-----------------+-----------------+-------------+
# 		| year | country 			 | product 			 | profit 		|
# 		+------+-----------------+-----------------+-------------+
# 		| 2000 | Finland 			 | Computer 		 | 1500 			|
# 		| 2000 | Finland 			 | Phone 			 | 100 			|
# 		| 2000 | India 			 | Calculator 		 | 150 		   |
# 		| 2000 | India 			 | Computer 		 | 1200 			|
# 		| 2000 | USA 				 | Calculator 		 | 75 			|
# 		| 2000 | USA 				 | Computer 		 | 1500 			|
# 		| 2001 | Finland 			 | Phone 			 | 10 			|
# 		| 2001 | USA 				 | Calculator 		 | 50 			|
# 		| 2001 | USA 				 | Computer 		 | 2700 			|
# 		| 2001 | USA 				 | TV 				 | 250 			|
# 		+------+-----------------+-----------------+-------------+
#
# With ROLLUP added, the query produces several extra rows:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# 		+------+-----------------+------------+-------------+
# 		| year | country 			 | product 	  | profit 		 |
# 		+------+-----------------+------------+-------------+
# 		| 2000 | Finland 			 | Computer   | 1500 		 |
# 		| 2000 | Finland 			 | Phone 	  | 100 			 |
# 		| 2000 | Finland 			 | NULL 		  | 1600 		 |
# 		| 2000 | India 			 | Calculator | 150 			 |
# 		| 2000 | India 			 | Computer   | 1200 		 |
# 		| 2000 | India 			 | NULL 		  | 1350 		 |
# 		| 2000 | USA 				 | Calculator | 75 			 |
# 		| 2000 | USA 				 | Computer   | 1500 		 |
# 		| 2000 | USA 				 | NULL 		  | 1575 		 |
# 		| 2000 | NULL 				 | NULL 		  | 4525 		 |
# 		| 2001 | Finland 			 | Phone 	  | 10 			 |
# 		| 2001 | Finland 			 | NULL 		  | 10 			 |
# 		| 2001 | USA 				 | Calculator | 50 			 |
# 		| 2001 | USA 				 | Computer   | 2700 		 |
# 		| 2001 | USA 				 | TV 		  | 250 			 |
# 		| 2001 | USA 				 | NULL 		  | 3000 		 |
# 		| 2001 | NULL 				 | NULL 		  | 3010 		 |
# 		| NULL | NULL 				 | NULL 		  | 7535 		 |
# 		+------+-----------------+------------+-------------+
#
# Now the output includes summary information at four levels of analysis, not just one:
#
# 		) Following each set of product rows for a given year and country, an extra super-aggregate summary row
# 			appears showing the total for all products.
#
# 			These rows have the product column set to NULL
#
# 		) Following each set of rows for a given year, an extra super-aggregate summary row appears showing
# 			the total for all countries and products.
#
# 			These rows have the country and products columns set to NULL
#
# 		) Finally, following all other rows, an extra super-aggregate summary row appears showing the grand total
# 			for all years, countries, and products.
#
# 			This row has the year, country and products set to NULL
#
# Previously, MySQL did not allow the use of DISTINCT or ORDER BY in a query having a WITH ROLLUP option.
#
# This restriction is lifted in MySQL 8.0.12, and later.
#
# (Bug #87450, Bug #86311, Bug#26640100, Bug#26073513)
#
# For GROUP BY --- WITH ROLLUP queries, to test whether NULL values in the result represent
# super-aggregate values, the GROUPING() function is available for use in theh select list,
# HAVING clause and (as of MySQL 8.0.12) ORDER BY clause.
#
# For example, GROUPING(year) returns 1 when NULL in the year column occurs in a super-aggregate
# row, and 0 otherwise.
#
# SImilarly, GROUPING(country) and GROUPING(product) return 1 for super-aggregate NULL values
# in the country and product columns, respectively:
#
# 		SELECT
# 			year, country, product, SUM(profit) AS profit,
# 			GROUPING(year) AS grp_year,
# 			GROUPING(country) AS grp_country,
# 			GROUPING(product) AS grp_product
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
# 		| year | country 			  | product 		 | profit 	     | grp_year   	  | grp_country 		| grp_product 	  |
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
# 		| 2000 | Finland 			  | Computer 		 | 1500 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | Finland 			  | Phone 			 | 100 			  | 0 				  | 0 		 			| 0 				  |
# 		| 2000 | Finland 			  | NULL 			 | 1600 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | India 			  | Calculator 	 | 150 			  | 0 				  | 0 				   | 0				  |
# 		| 2000 | India 			  | Computer 		 | 1200 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | India 			  | NULL 			 | 1350 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | USA 				  | Calculator 	 | 75 			  | 0 				  | 0 				   | 0 				  |
# 		| 2000 | USA 				  | Computer 		 | 1500 			  | 0 				  | 0 					| 0 				  |
# 		| 2000 | USA 				  | NULL 			 | 1575 			  | 0 				  | 0 					| 1 				  |
# 		| 2000 | NULL 				  | NULL 			 | 4525 			  | 0 				  | 1 					| 1 				  |
# 		| 2001 | Finland 			  | Phone 			 | 10 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | Finland 			  | NULL 			 | 10 			  | 0 				  | 0 					| 1 				  |
# 		| 2001 | USA 				  | Calculator 	 | 50 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | Computer 		 | 2700 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | TV 				 | 250 			  | 0 				  | 0 					| 0 				  |
# 		| 2001 | USA 				  | NULL 			 | 3000 			  | 0 				  | 0 					| 1 				  |
# 		| 2001 | NULL 				  | NULL 			 | 3010 			  | 0 				  | 1 					| 1 				  |
# 		| NULL | NULL 				  | NULL 			 | 7535 			  | 1 				  | 1 					| 1 				  |
# 		+------+------------------+----------------+---------------+-----------------+------------------+----------------+
#
# Instead of displaying the GROUPING()  result directly, you can use GROUPING() to substitute labels for super-aggregate
# NULL values:
#
# 		SELECT
# 			IF(GROUPING(year), 'All years', year) AS year,
# 			IF(GROUPING(country), 'All countries', country) AS country,
# 			IF(GROUPING(product), 'ALl products', product) AS product,
# 			SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP;
# +------------+---------------------+-------------------+--------------+
# | year 		| country 				 | product 				| profit 		|
# +------------+---------------------+-------------------+--------------+
# | 2000 		| Finland 				 | Computer 			| 1500 			|
# | 2000 		| Finland 				 | Phone 				| 100 			|
# | 2000 		| Finland 				 | All products 		| 1600 			|
# | 2000 		| India 					 | Calculator 			| 150 			|
# | 2000 		| India 					 | Computer 			| 1200 			|
# | 2000 		| India 					 | All products 		| 1350 		   |
# | 2000 		| USA 					 | Calculator 			| 75 				|
# | 2000 		| USA 					 | Computer 			| 1500 		   |
# | 2000 		| USA 					 | All products 		| 1575 			|
# | 2000 		| All countries 		 | All products 		| 4525 			|
# | 2001 		| Finland 				 | Phone 				| 10 				|
# | 2001 		| Finland 				 | All products 		| 10 				|
# | 2001 		| USA 					 | Calculator 			| 50 				|
# | 2001 		| USA 					 | Computer 			| 2700 			|
# | 2001 		| USA 					 | TV 					| 250 			|
# | 2001 		| USA 					 | All Products 		| 3000 			|
# | 2001 		| All countries 		 | ALl products 		| 3010 			|
# | All years  | All countries 		 | All products 		| 7535 			|
# +------------+---------------------+-------------------+--------------+
#
# With multiple expression arguments, GROUPING() returns a result representing a bitmask
# that combines the results for each expression, with the lowest-order bit corresponding
# ot the result for the rightmost expression.
#
# For example, GROUPING(year, country, product) is evaluated like this:
#
# 		result FOR GROUPING(product)
# 	 + result FOR GROUPING(country) << 1
#   + result FOR GROUPING(year) << 2
#
# The result of such a GROUPING() is nonzero if any of the expressions represents a super-aggregate NULL,
# so you can return only the super-aggregate rows and filter out the regular grouped rows like this:
#
# 	SELECT year, country, product, SUM(profit) AS profit
# 	FROM sales
# 	GROUP BY year, country, product WITH ROLLUP
# 	HAVING GROUPING(year, country, product) <> 0;
# +--------+------------+--------+------------+
# | year   | country 	| product| profit 	 |
# +--------+------------+--------+------------+
# | 2000   | Finland 	| NULL 	| 1600 		 |
# | 2000   | India 		| NULL 	| 1350 		 |
# | 2000   | USA 			| NULL   | 1575 		 |
# | 2000   | NULL 		| NULL 	| 4525 		 |
# | 2001   | Finland 	| NULL   | 10 			 |
# | 2001   | USA 			| NULL   | 3000 		 |
# | 2001   | NULL 		| NULL 	| 3010 		 |
# | NULL   | NULL 		| NULL 	| 7535 		 |
# +--------+------------+--------+------------+
#
# The sales table contains no NULL values, so all NULL values in a ROLLUP result represent
# super-aggregate values.
#
# When the data set contains NULL values, ROLLUP summaries may contain NULL values not only
# in super-aggregate rows, but also in regular grouped rows.
#
# GROUPING() enables these to be distinguished.
#
# Suppose that table t1 contains a simple data set with two grouping factors for a
# set of quantity values, where NULL indicates something like "other" or "unknown"
#
# 		SELECT * FROM t1;
# 		+-------+----------+-----------+
# 		| name  | size 	 | quantity  | 
# 		+-------+----------+-----------+
# 		| ball  | small 	 | 10 		 |
# 		| ball  | large 	 | 20 		 |
# 		| ball  | NULL 	 | 5 			 |
# 		| hoop  | small 	 | 15 		 |
# 		| hoop  | large 	 | 5 			 |
# 		| hoop  | NULL 	 | 3 			 |
# 		+-------+----------+-----------+
#
# A simple ROLLUP operation produces these results, in which it is not so easy to distinguish
# NULL values in super-aggregate rows from NULL values in regular grouped rows:
#
# 		SELECT name, size, SUM(quantity) AS quantity
# 		FROM t1
# 		GROUP BY name, size WITH ROLLUP;
# 		+--------+-----------+----------------+
# 		| ball 	| size 		| quantity 		  |
# 		+--------+-----------+----------------+
# 		| ball 	| NULL 		| 	5 				  |
# 		| ball   | large 		|  20 			  |
# 		| ball 	| small 		|  10  			  |
# 		| ball   | NULL 		|  35 			  |
# 		| hoop   | NULL 		|  3 				  |
# 		| hoop   | large 		|  5 				  |
# 		| hoop   | small 		|  15 			  |
# 		| hoop   | NULL 		| 	23 			  |
# 		| NULL 	| NULL 		|  58 			  |
# 		+--------+-----------+----------------+
#
# Using GROUPING() to substitute labels for the super-aggregate NULL values makes the result easier
# to interpret:
#
# 		SELECT
# 			IF(GROUPING(name) = 1, 'All items', name) AS name,
# 			IF(GROUPING(size) = 1, 'All sizes', size) AS size,
# 			SUM(quantity) AS quantity
# 		FROM t1
# 		GROUP BY name, size WITH ROLLUP;
# 	+----------------+----------------+---------------+
# 	| name 			  | size 			 | quantity 	  |
# 	+----------------+----------------+---------------+
# 	| ball 			  | NULL 			 | 	5 			  |
#  | ball 			  | large 			 | 	20 		  |
# 	| ball 			  | small 			 | 	10 		  |
# 	| ball 			  | All sizes 		 | 	35 		  |
# 	| hoop 			  | NULL 			 | 	3 			  |
# 	| hoop 			  | large 			 | 	5 			  |
# 	| hoop 			  | small 			 | 	15 		  |
# 	| hoop 			  | All sizes 		 | 	23 		  |
# 	| All items 	  | All sizes 		 | 	58 		  |
# 	+----------------+----------------+---------------+
#
# OTHER CONSIDERATIONS WHEN USING ROLLUP
#
# The following discussion lists some behaviors specific to the MySQL implementation of ROLLUP.
#
# Prior to 8.0.12, when you use ROLLUP, you cannot also use an ORDER BY clause to sort the results.
# In other words, ROLLUP and ORDER BY were mutually exclusive in MySQL.
#
# However, you still have some control over sort order. To work around the restriction that prevents
# using ROLLUP with ORDER BY and achieve a specific sort order of grouped results, generate the 
# grouped result set as a derived table and apply ORDER BY to it.
#
# For example:
#
# 		SELECT * FROM
# 			(SELECT year, SUM(profit) AS profit
# 			FROM sales GROUP BY year WITH ROLLUP) AS dt
# 		ORDER BY year DESC;
# 		+-------+-----------+
# 		| year  | profit 	  |
# 		+-------+-----------+
# 		| 2001  | 3010 	  |
# 		| 2000  | 4525 	  |
# 		| NULL  | 7535 	  |
# 		+-------+-----------+
#
# As of MySQL 8.0.12, ORDER BY and ROLLUP can be used together, which enables the use
# of ORDER BY and GROUPING() to achieve a specific sort order of grouped results.
#
# For example:
#
# 		SELECT year, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP
# 		ORDER BY GROUPING(year) DESC;
# 		+--------+----------+
# 		| year 	| profit   |
# 		+--------+----------+
# 		| NULL 	| 7535 	  |
# 		| 2000   | 4525 	  |
# 		| 2001 	| 3010 	  |
# 		+--------+----------+
#
# In both cases, the super-aggregate summary rows sort with the rows from which
# they are calculated, and their placement depends on sort order (at the end for
# ascending sort, at the beginning for descending sort)
#
# LIMIT can be used to restrict the number of rows returned to the client.
#
# LIMIT is applied after ROLLUP, so the limit applies against the extra rows
# added by ROLLUP.
#
# For example:
#
# 		SELECT year, country, product, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year, country, product WITH ROLLUP
# 		LIMIT 5;
# 		+---------+--------------+----------------+-------------+
# 		| year 	 | country 		 | product 			| profit 	  |
# 		+---------+--------------+----------------+-------------+
# 		| 2000    | Finland 		 | Computer 		| 1500 		  |
# 		| 2000 	 | Finland 		 | Phone 			| 100 		  |
# 		| 2000 	 | Finland 		 | NULL 				| 1600 		  |
# 		| 2000 	 | India 		 | Calculator 		| 150 		  |
# 		| 2000    | India 		 | Computer 		| 1200 		  |
# 		+---------+--------------+----------------+-------------+
#
# Using LIMIT with ROLLUP may produce results taht are more difficult to interpret,
# because there is less context for understanding the super-aggregate rows.
#
# The NULL indicators in each super-aggregate row are produced when the row is
# sent to the client.
#
# The server looks at the columns named in the GROUP BY clause following
# the leftmost one that has changed value.
#
# For any column in the result set with a name that matches any of those
# names, its value is set to NULL.
#
# (If you specify grouping columns by column position, the server identifies
# which columns to set to NULL by position)
#
# Because the NULL values in the super-aggregate rows are placed into the result
# set at such a late stage in query processing, you can test them as NULL values
# only in the select list or HAVING clause.
#
# You cannot test them as NULL values in join conditions or the WHERE clause
# to determine which rows to select.
#
# For example, you cannot add WHERE product IS NULL to the query to eliminate
# from the output all but the super-aggregate rows.
#
# The NULL values do appear as NULL on the client side and can be tested as such
# using any MySQL client programming interface.
#
# However, at this point, you cannot distinguish whether a NULL represents
# a regular grouped value or a super-aggregate value.
#
# A MySQL extension permits a column that does not appear in the GROUP BY list 
# to be named in teh select list.
#
# (For information about nonaggregated columns and GROUP BY, see SECTION 12.20.3,
# "MySQL HANDLING OF GROUP BY")
#
# In this case, the server is free to choose any value from this nonaggregated
# column in summary rows, and this includes the extra rows added by WITH ROLLUP.
#
# For example, in the following query, country is a nonaggregated column that does
# not appear in the GROUP BY list and values chosen for this column are nondeterministic:
#
# 		SELECT year, country, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+----------+-------------+-----------+
# 		| year 	  | country 	 | profit 	 |
# 		+----------+-------------+-----------+
# 		| 2000 	  | India 		 | 4525 		 |
# 		| 2001 	  | USA 			 | 3010 		 |
# 		| NULL 	  | USA 			 | 7535 		 |
# 		+----------+-------------+-----------+
#
# This behavior is permitted when the ONLY_FULL_GROUP_BY SQL mode is not enabled.
#
# If that mode is enabled, the server rejects the query as illegal because
# country is not listed in the GROUP BY clause.
#
# With ONLY_FULL_GROUP_BY enabled, you can still execute the query by using the
# ANY_VALUE() function for nondeterministic-value columns:
#
# 		SELECT year, ANY_VALUE(country) AS country, SUM(profit) AS profit
# 		FROM sales
# 		GROUP BY year WITH ROLLUP;
# 		+-------+--------------+-----------+
# 		| year  | country 	  | profit 	  |
# 		+-------+--------------+-----------+
# 		| 2000  | India 		  | 4525 	  |
# 		| 2001  | USA 			  | 3010 	  |
# 		| NULL  | USA 			  | 7535		  |
# 		+-------+--------------+-----------+
#
# 12.20.3 MYSQL HANDLING OF GROUP BY
#
# SQL92 and earlier does not permit queries for which the select list, HAVING condition,
# or ORDER BY list refer to nonaggregated columns that are not named in the GROUP BY
# clause.
#
# For example, this query is illegal in standard SQL 92 because the nonaggregated name column
# in the select list does not appear in the GROUP BY:
#
# 		SELECT o.custid, c.name, MAX(o.payment)
# 			FROM orders AS o, customers AS c
# 			WHERE o.custid = c.custid
# 			GROUP BY o.custid;
#
# For the query to be legal in SQL92, the name column must be omitted from the select list
# or named in the GROUP BY clause.
#
# SQL99 and later permits such nonaggregates per optional feature T301 if they are functionalily
# dependent on GROUP BY columns:
#
# 		if such a relationship exists between name and custid, th query is legal.
#
# This would be the case, for example, were custid a primary key of customers.
#
# MySQL implements detection of functional dependence.
#
# If the ONLY_FULL_GROUP_BY SQL mode is enabled (which it is by default), MySQL
# rejects queries for which the select list, HAVING CONDITION or ORDER BY list
# refer to nonaggregated columns that are neither named in teh GROUP BY clause
# nor are functionally dependent on them.
#
# If ONLY_FULL_GROUP_BY is disabled, a MySQL extension to the standard SQL use of
# GROUP BY permits the select list, HAVING condition, or ORDER BY list to refer to
# nonaggregated columns even if the columns are not functionally dependent on
# GROUP BY columns.
#
# This causes MySQL to accept the preceding query. In this case, the server is free
# to choose any value from each group, so unless they are the same, the values
# chosen are nondeterministic - which is probably not what you want.
#
# Furthermore, the selection of values from each group cannot be influenced by
# adding an ORDER BY clause.
#
# Result set sorting occurs after values have been chosen, and ORDER BY does not
# affect which value within each group the server chooses.
#
# Disabling ONLY_FULL_GROUP_BY is useful primarily when you know that, due to
# some property of the data, all values in each nonaggregated column not
# named in the GROUP BY are the same for each group.
#
# You can achieve the same effect without disabling ONLY_FULL_GROUP_BY by using
# ANY_VALUE() to refer to the nonaggregated column.
#
# The following discussion demonstrates functional dependence, the error message
# MySQL produces when functional dependence is absent, and ways of causing
# MySQL to accept a query in the absence of functional dependence.
#
# This query might be invalid with ONLY_FULL_GROUP_BY enabled because the nonaggregated
# address column in the select list is not named in the GROUP BY clause:
#
# 		SELECT name, address, MAX(age) FROM t GROUP BY name;
#
# The query is valid if name is a primary key of t or is a unique NOT NULL column.
#
# In such cases, MySQL recognizes that the selected column is functionally
# dependent on a grouping column.
#
# For example, if name is a primary key, its value determines the value of
# address because each group has only one value of the primary key and thus
# only one row.
#
# As a result, there is no randomness in the choice of address value in a group
# and no need to reject the query.
#
# The query is invalid if name is not a primary key of t or a unique NOT NULL column.
# In this case, no functional dependency can be inferred and an error occurs:
#
# 		SELECT name, address, MAX(age) FROM t GROUP BY name;
# 		ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP
# 		BY clause and contains nonaggregated column 'mydb.t.address' which
# 		is not functionally dependent on columns in GROUP BY clause;
# 		this is incompatible with sql_mode=only_full_group_by
#
# If you know that, for a given data set, each name value in fact uniquely
# determines the address value, address is effectively functionally dependent
# on name.
#
# To tell MySQL to accept the query, you can use the ANY_VALUE() function:
#
# 		SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name;
#
# Alternatively, disable ONLY_FULL_GROUP_BY
#
# The preceding example is quite simple, however. In particular, it is unlikely you would
# group on a single primary key because every group would contain only one row.
#
# For additional examples demonstrating functional dependence in more complex queries,
# see SECTION 12.20.4, "DETECTION OF FUNCTIONAL DEPENDENCE"
#
# if a query has aggregate functions and no GROUP BY clause, it cannot have nonaggregated
# columns in the select list, HAVING condition, or ORDER BY list with ONLY_FULL_GROUP_BY enabled:
#
# 		SELECT name, MAX(age) FROM t;
# 		ERROR 1140 (42000): In aggregated query without GROUP BY, expression
# 		#1 of SELECT list contains nonaggregated column 'mydb.t.name'; this
# 		is incompatible with sql_mode=only_full_group_by
#
# Without GROUP BY, there is a single group and it is nondeterministic which name values to choose
# for the group.
#
# Here, too, ANY_VALUE() can be used, if it is immaterial which name value MySQL chooses:
#
# 		SELECT ANY_VALUE(name), MAX(age) FROM t;
#
# ONLY_FULL_GROUP_BY also affects handling of queries that use DISTINCT and ORDER BY.
#
# Consider the case of a table t with three columns c1, c2, and c3 that contains these
# rows:
#
# 		c1 c2 c3
# 		1  2  A
# 		3  4 	B
# 		1  2  C
#
# Suppose that we execute the following query, expecting the results to be ordered
# by c3:
#
# 		SELECT DISTINCT c1, c2 FROM t ORDER BY c3;
#
# To order the result, duplicates must be eliminated first.
#
# But to do so, should we keep the first row or the third?
#
# This arbitrary choice influences the retained value of c3, which in turn
# influences ordering and makes it arbitrary as well.
#
# To prevent this problem, a query that has DISTINCT and ORDER BY is rejected
# as invalid if any ORDER BY expression does not satisfy at least one of these
# conditions:
#
# 		) The expression is equal to one in the select list
#
# 		) All columns referenced by the expression and belonging to the query's selected tables
# 			are elements of the select list.
#
# Another MySQL extension to standard SQL permits references in the HAVING clause to aliased
# expressions in the select list.
#
# For example, the following query returns name values that occur only once in table orders:
#
# 		SELECT name, COUNT(name) FROM orders
# 			GROUP BY name
# 			HAVING COUNT(name) = 1;
#
# The MySQL extension permits the use of an alias in the HAVING clause for the
# aggregated column:
#
# 		SELECT name, COUNT(name) AS c FROM orders
# 			GROUP BY name
# 			HAVING c = 1;
#
# Standard SQL permits only column expressions in GROUP BY clauses, so a statement
# such as this is invalid because FLOOR(value/100) is a noncolumn expression:
#
# 		SELECT id, FLOOR(value/100)
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100);
#
# MySQL extends standard SQL to permit noncolumn expressions in GROUP BY clauses
# and considers the preceding statement valid.
#
# Standard SQL also does not permit alaises in GROUP BY clauses.
#
# MySQL extends standard SQL to permit aliases, so another way to write
# the query is as follows:
#
# 		SELECT id, FLOOR(value/100) AS val
# 			FROM tbl_name
# 			GROUP BY id, val;
#
# The alias val is considered a column expression in the GROUP BY clause.
#
# In the presence of a noncolumn expression in the GROUP BY clause, MySQL recognizes
# equality between that expression and expressions in the select list.
#
# This means that with ONLY_FULL_GROUP_BY SQL mode enabled, tthe query containing 
# GROUP BY id, FLOOR(value/100) is valid because that same FLOOR() expression occurs
# in the select list.
#
# However, MySQL does not try to recognize functional dependence on GROUP BY noncolumn
# expressions, so the following query is invalid with ONLY_FULL_GROUP_BY enabled,
# even though the third selected expression is a simple formula of the id column
# and the FLOOR() expression in the GROUP BY clause:
#
# 		SELECT id, FLOOR(value/100), id+FLOOR(value/100)
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100);
#
# A workaround is to use a derived table:
#
# 		SELECT id, F, id+F
# 		FROM
# 			(SELECT id, FLOOR(value/100) AS F
# 			FROM tbl_name
# 			GROUP BY id, FLOOR(value/100)) AS dt;
#
# 12.20.4 DETECTION OF FUNCTIONAL DEPENDENCE
#
# The following discussion provides several examples of the ways in which MySQL detects
# functional dependencies.
#
# The examples use this notation:
#
# 		{X} -> {Y}
#
# Understand this as "X uniquely determines Y"; which also means that Y is functionally dependent on X.
#
# The examples use the world database, which can be downloaded at <link>.
#
# You can find details on how to install the database on the same page.
#
# 		) FUNCTIONAL DEPENDENCIES DERIVED FROM KEYS
#
# 		) FUNCTIONAL DEPENDENCIES DERIVED FROM MULTIPLE-COLUMN KEYS AND FROM EQUALITIES
#
# 		) FUNCTIONAL DEPENDENCY SPECIAL CASES
#
# 		) FUNCTIONAL DEPENDENCIES AND VIEWS
#
# 		) COMBINATIONS OF FUNCTIONAL DEPENDENCIES
#
# FUNCTIONAL DEPENDENCIES DERIVED FROM KEYS
#
# The following query selects, for each country, a count of spoken languages:
#
# 		SELECT co.Name, COUNT(*)
# 		FROM countrylanguage cl, country co
# 		WHERE cl.CountryCode = co.Code
# 		GROUP BY co.Code;
#
# co.Code is a primary key of co, so all columns of co are functionally dependent on it,
# as expressed using this notation:
#
# 		{co.Code} -> {co.*}
#
# Thus, co.name is functionally dependent on GROUP BY columns and the query is valid.
#
# A UNIQUE index over a NOT NULL column could be used instead of a primary key and the
# same functional dependence would apply.
#
# (This is not true for a UNIQUE index that permits NULL values because it permits multiple
# NULL values and in that case uniqueness is lost)
#
# FUNCTIONAL DEPENDENCIES DERIVED FROM MULTIPLE-COLUMN KEYS AND FROM EQUALITIES
#
# This query selects, for each country, a list of all spoken languages and how many
# people speak them:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population / 100.0 AS SpokenBy
# 		FROM countrylanguage cl, country co
# 		WHERE cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# The pair (cl.CountryCode, cl.Language) is a two-column composite primary key
# of cl, so that column pair uniquely determines all columns of cl:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*)
#
# Moreover, because of the equality in the WHERE clause:
#
# 		{cl.CountryCode} -> {co.Code}
#
# And, because co.Code is primary key of co:
#
# 		{co.Code} -> {co.*}
#
# "Uniquely determines" relationships are transitive, therefore:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# As a result, the query is valid.
#
# AS with the previous example, a UNIQUE key over NOT NULL columns could be used
# instead of a primary key.
#
# An INNER JOIN condition can be used instead of WHERE.
#
# The same functional dependencies apply:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM countrylanguage cl INNER JOIN country co
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# FUNCTIONAL DEPENDENCY SPECIAL CASES
#
# Whereas an equality test in a WHERE condition or INNER JOIN condition is symmetric,
# an equality test in an outer join condition is not, because tables play different roles.
#
# Assume that referential integrity has been accidentally broken and there exists a row
# of countrylanguage without a coresponding row in country.
#
# Consider the same query as in the previous example, but with a LEFT JOIN:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM countrylanguage cl LEFT JOIN country co
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# For a given value of cl.CountryCode, the value of co.Code in the join
# result is either found in a matching row (determined by cl.CountryCode) or is
# NULL-complemented if there is no match (also determined by cl.CountryCode).
#
# In each case, this relationship applies:
#
# 		{cl.CountryCode} -> {co.Code}
#
# cl.CountryCode is itself functionally dependent on {cl.CountryCode, cl.Language} which
# is a primary key.
#
# If in the join result co.Code is NULL-complemented, co.Name is as well.
#
# If co.Code is not NULL-complemented, then because co.Code is a primary key,
# it determines co.Name. Therefore, in all cases:
#
# 		{co.Code} -> {co.Name}
#
# Which yields:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# As a result, the query is valid.
#
# However, suppose that the tables are swapped, as in this query:
#
# 		SELECT co.Name, cl.Language,
# 		cl.Percentage * co.Population/100.0 AS SpokenBy
# 		FROM country co LEFT JOIN countrylanguage cl
# 		ON cl.CountryCode = co.Code
# 		GROUP BY cl.CountryCode, cl.Language;
#
# Now this relationship does NOT apply:
#
# 		{cl.CountryCode, cl.Language} -> {cl.*,co.*}
#
# Indeed, all NULL-complemented rows made for cl will be put into
# a single group (they have both GROUP BY columns equal to NULL), and
# inside this group the value of co.Name can vary.
#
# It is invalid, and MySQL rejects it.
#
# Functional dependence in outer joins is thus linked to whether determinant
# columns belong to the left or right side of the LEFT JOIN.
#
# Determination of functional dependence becomes more complex if htere are
# nested outer joins or the join condition does not consist entirely
# of equality comparisons.
#
# FUNCTIONAL DEPENDENCIES AND VIEWS
#
# Suppose that a view on countries produces their code, their name in uppercase,
# and how many different official languages they have:
#
# 		CREATE VIEW Country2 AS
# 		SELECT co.Code, UPPER(co.Name) AS UpperName,
# 		COUNT(cl.Language) AS OfficialLanguages
# 		FROM country AS co JOIN countrylanguage AS cl
# 		ON cl.CountryCode = co.Code
# 		WHERE cl.isOfficial = 'T'
# 		GROUP BY co.Code;
#
# This definition is valid because:
#
# 		{co.Code} -> {co.*}
#
# In the view result, the first selected column is co.Code, which is also
# the group column and thus determines all other selected expressions:
#
# 		{Country2.Code} -> {Country2.*}
#
# MySQL understands this and uses this information, as described following.
#
# This query displays countries, how many different official languages they have,
# and how many cities they have, by joining the view with the city table:
#
# 		SELECT co2.Code, co2.UpperName, co2.OfficialLanguages,
# 		COUNT(*) AS Cities
# 		FROM country2 AS co2 JOIN city ci
# 		ON ci.CountryCode = co2.Code
# 		GROUP BY co2.Code;
#
# This query is valid because, as seen previously:
#
# 		{co2.Code} -> {co2.*}
#
# MySQL is able to discover a functional dependency in the result of a view and use
# that to validate a query which uses the view.
#
# The same would be true if country2 were a derived table (or common table expression),
# as in:
#
# 		SELECT co2.Code, co2.UpperName, co2.OfficialLanguages,
# 		COUNT(*) AS Cities
# 		FROM
# 		( 
# 			SELECT co.Code, UPPER(co.Name) AS UpperName,
# 			COUNT(cl.Language) AS OfficialLanguages
# 			FROM country AS co JOIN countrylanguage AS cl
# 			ON cl.CountryCode=co.Code
# 			WHERE cl.isOfficial='T'
# 			GROUP BY co.Code
#  	) AS co2
# 		JOIN city ci ON ci.CountryCode = co2.Code
# 		GROUP BY co2.Code;
#
# COMBINATIONS OF FUNCTIONAL DEPENDENCIES:
#
# MySQL is able to combine all of hte preceding types
# of functional dependencies (key based, equality based, view based)
# to validate more complex queries.
#
# 12.21 WINDOW FUNCTIONS
#
# 12.21.1 WINDOW FUNCTION DESCRIPTIONS
# 12.21.2 WINDOW FUNCTION CONCEPTS AND SYNTAX
# 12.21.3 WINDOW FUNCTION FRAME SPECIFICATION
# 12.21.4 NAMED WINDOWS
# 12.21.5 WINDOW FUNCTION RESTRICTIONS
#
# MySQL supports window functions that, for each row from a query, perform a calculation
# using rows related to that row.
#
# The following sections discuss how to use window functions, including descriptions
# of the OVER and WINDOW clauses.
#
# The first section provides descriptions of the nonaggregate window functions.
# For descriptions of the aggregate window functions, see 12.20.1, "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# For information about optimization and window functions, see SECTION 8.2.1.19, "WINDOW FUNCTION OPTIMIZATION"
#
# 12.21.1 WINDOW FUNCTION DESCRIPTIONS
#
# This section describes nonaggregate window functions that, for each row from a query,
# perform a calculation using rows related to that row.
#
# Most aggregate functions also can be used as window functions; see SECTION 12.20.1,
# "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# For window function usage information and examples, and definitions of terms such as
# the OVER clause, window, partition, frame and peer, see SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# TABLE 12.27 WINDOW FUNCTIONS
#
# 		Name 							Description
#
# CUME_DIST() 						Cumulative distribution value
#
# DENSE_RANK() 					Rank of current row within its partition, without gaps
#
# FIRST_VALUE() 					Value of argument from first row of window frame
#
# LAG() 								Value of argument from row lagging current row within partition
#
# LAST_VALUE() 					Value of argument from last row of window frame
#
# LEAD() 							Value of argument from row leading current row within partition
#
# NTH_VALUE() 						Value of argument from N-th row of window frame
#
# NTILE() 							Bucket number of current row within its partition
#
# PERCENT_RANK() 					Percentage rank value 
#
# RANK() 							Rank of current row within its partition, with gaps
#
# ROW_NUMBER() 					Number of current row within its partition
#
# In the following function descriptions, over_clause represents the OVER clause, described
# in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# Some window functions permit a null_treatment clause that specifies how to handle
# NULL values when calculating results.
#
# This clause is optional.
#
# It is part of the SQL standard, but the MySQL implementation permits only RESPECT
# NULLS (which is also the default)
#
# This means that NULL values are considered when calculating results.
#
# IGNORE NULLS is parsed, but produces an error.
#
# 		) CUME_DIST() over_clause
#
# 			Returns the cumulative distribution of a value within a group of values,
# 			that is, the percentage of partition values less than or equal to the value in the current row.
#
# 			This represents the number of rows preceding or peer with the current row in the
# 			window ordering of the window partition divided by the total number of rows
# 			in the window partition.
#
# 			Return values range from 0 to 1
#
# 			This function should be used with ORDER BY to sort partition rows into the desired order.
#
# 			Without ORDER BY, all rows are peers and have value N/N = 1, where N is the partition size.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows, for the set of values in the val column, the CUME_DIST()
# 			value for each row, as well as the percentage rank value returned by the similar
# 			PERCENT_RANK() function.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() OVER w AS 'row_number',
# 					CUME_DIST() OVER w AS 'cume_dist',
# 					PERCENT_RANK() OVER w AS 'percent_rank'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+---------+--------------------+----------------------------+-------------------+
# 				| val 	 | row_number 			 | cume_dist 						| percent_rank 	  |
# 				+---------+--------------------+----------------------------+-------------------+
# 				| 1 		 | 1 						 | 0.22 etc. 						| 0 					  |
# 				| 1 		 | 2 						 | 0.22 etc. 						| 0 					  |
# 				| 2 		 | 3 						 | 0.33 etc 						| 0.25 				  |
# 				| 3 		 | 4 						 | 0.66 etc. 						| 0.375 				  |
# 				| 3 		 | 5 						 | 0.66 etc. 						| 0.375 				  |
# 				| 3 		 | 6 						 | 0.66 etc. 						| 0.375 				  |
# 				| 4 		 | 7 						 | 0.88 etc. 						| 0.75 				  |
# 				| 4 		 | 8 						 | 0.88 etc. 						| 0.75 				  |
# 				| 5 		 | 9 						 | 1 									| 1 					  |
# 				+---------+--------------------+----------------------------+-------------------+
#
# 		) DENSE_RANK() over_clause
#
# 			Returns the rank of the current row within its partition, without gaps.
#
# 			Peers are considered ties and receive the same rank. This function assigns
# 			conesecutive ranks to peer groups; the result is that groups of size greater
# 			than one do not produce noncontiguous rank numbers.
#
# 			For an example, see the RANK() function description.
#
# 			This function should be used with ORDER BY to sort partition rows into
# 			the desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		) FIRST_VALUE(expr) [null_treatment] over_clause
#
# 			Returns the value of expr from the first row of the window frame.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section introduction.
#
# 			The following query demonstrates FIRST_VALUE(), LAST_VALUE() and two instances
# 			of NTH_VALUE():
#
# 				SELECT
# 					time, subject, val,
# 					FIRST_VALUE(val) OVER w AS 'first',
# 					LAST_VALUE(val) OVER w AS 'last',
# 					NTH_VALUE(val, 2) OVER w AS 'second',
# 					NTH_VALUE(val, 4) OVER w AS 'fourth'
# 				FROM observations
# 				WINDOW w AS (PARTITION BY subject ORDER BY time
# 								ROWS UNBOUNDED PRECEDING);
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
# 			| time 				| subject 		 | val 	 | first  | last 		 | second  | fourth 	 |
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
# 			| 07:00:00 		   | st113 			 | 10 	 | 10 	 | 10 		 | NULL 	  | NULL 	 |
# 			| 07:15:00 		   | st113 			 | 9 		 | 10 	 | 9 			 | 9 		  | NULL 	 |
# 			| 07:30:00 			| st113 			 | 25 	 | 10 	 | 25 		 | 9 		  | NULL 	 |
# 			| 07:45:00 			| st113 			 | 20 	 | 10 	 | 20 		 | 9 		  | 20 		 |
# 			| 07:00:00 			| xh458 			 | 0 		 | 0 		 | 0 			 | NULL 	  | NULL 	 |
# 			| 07:15:00 			| xh458 			 | 10 	 | 0 		 | 10 		 | 10 	  | NULL 	 |
# 			| 07:30:00 			| xh458 			 | 5 		 | 0 		 | 5 			 | 10 	  | NULL 	 |
# 			| 07:45:00 			| xh458 			 | 30 	 | 0 		 | 30 		 | 10 	  | 30 		 |
# 			| 08:00:00 			| xh458 			 | 25 	 | 0 		 | 25 		 | 10 	  | 30 		 |
# 			+-----------------+---------------+--------+--------+-----------+---------+----------+
#
# 			Each function uses the rows in the current frame, which, per the window definition shown,
# 			extends from the first partition row to the current row.
#
# 			For the NTH_VALUE() calls, the current frame does not always include the requested row,
# 			in such cases, the return value is NULL
#
# 		) LAG(expr [, N[, default]]) [null_treatment] over_clause
#
# 			Returns the value of expr from the row that lags (precedes) the current row by N rows
# 			within its partition.
#
# 			If there is no such row, the return value is default.
#
# 			For example, if N is 3, the return value is default for the first two rows.
#
# 			If N or default are missing, the defaults are 1 and NULL, respectively.
#
# 			N must be a literal nonnegative integer. If N is 0, expr is evaluated for the current row.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			LAG() (and the similar LEAD() function) are often used to compute differences between rows.
#
# 			The following query shows a set of time-ordered observations and, for each one,
# 			the LAG() and LEAD() values from the adjoining rows, as well as the differences
# 			between the current and adjoining rows:
#
# 				SELECT
# 					t, val,
# 					LAG(val) 			OVER w AS 'lag',
# 					LEAD(val) 			OVER w AS 'lead',
# 					val - LAG(val) 	OVER w AS 'lag diff',
# 					val - LEAD(val) 	OVER w AS 'lead diff'
# 				FROM series
# 				WINDOW w AS (ORDER BY t);
# 				+--------------------+---------+----------+----------+------------------+--------------------+
# 				| t 						| val 	 | lag 		| lead 	  | lag diff 			| lead diff 			|
# 				+--------------------+---------+----------+----------+------------------+--------------------+
# 				| 12:00:00 				| 100 	 | NULL 		| 125 	  | NULL 				| 	-25 					|
# 				| 13:00:00 				| 125 	 | 100 		| 132 	  | 25 					|  -7 					|
# 				| 14:00:00 				| 132 	 | 125 		| 145 	  | 7 					|  -13 					|
# 				| 15:00:00 				| 145 	 | 132 		| 140 	  | 13 					|  5 						|
# 				| 16:00:00 				| 140 	 | 145 		| 150 	  | -5 					|  -10 					|
# 				| 17:00:00 				| 150 	 | 140 		| 200 	  | 10 					|  -50 					|
# 				| 18:00:00 				| 200 	 | 150 		| NULL 	  | 50 					| 	NULL 					|
# 				+--------------------+---------+----------+----------+------------------+--------------------+
#
# 			In the example, the LAG() and LEAD() calls use the default N and default values of 1 and NULL, respectively.
#
# 			The first row shows what happens when there is no previous row for LAG(): The function returns the
# 			default value (in this case, NULL) 
#
# 			The last row shows the same thing when there is no next row for LEAD()
#
# 			LAG() and LEAD() also serve to compute sums rather than differences.
#
# 			Consider this data set, which contains the first few numbers of the Fibonacci series:
#
# 				SELECT n FROM fib ORDER BY n;
# 				+--------+-
# 				| n 	   |
# 				+--------+
# 				| 1 		|
# 				| 1 		|
# 				| 2 		|
# 				| 3 		|
# 				| 5 		|
# 				| 8 		|
# 				+--------+
#
# 			THe following query shows the LAG() and LEAD() values for the rows adjacent
# 			to the current row.
#
# 			It also uses those functions to add to the current row value the values
# 			from the preceding and following rows.
#
# 			The effect is to generate the next number in the Fibonacci series, and the
# 			next number after that:
#
# 				SELECT
# 					n,
# 					LAG(n, 1, 0) 		OVER w AS 'lag',
# 					LEAD(n, 1, 0) 		OVER w AS 'lead',
# 					n + LAG(n, 1, 0) 	OVER w AS 'next_n',
# 					n + LEAD(n, 1, 0) OVER w AS 'next_next_n'
# 				FROM fib
# 				WINDOW w AS (ORDER BY n);
# 				+--------+----------+---------+-----------+-------------------+
# 				| n 		| lag 	  | lead 	| next_n 	| next_next_n 		  |
# 				+--------+----------+---------+-----------+-------------------+
# 				| 1 		| 0 		  | 1 		| 	1 			| 2 					  |
# 				| 1 		| 1 		  | 2 		|  2 			| 3 					  |
# 				| 2 		| 1 		  | 3 		|  3 		   | 5 					  |
# 				| 3 		| 2 		  | 5 		|  5 			| 8 					  |
# 				| 5 		| 3 		  | 8  		|  8 			| 13 					  |
# 				| 8 		| 5 		  | 0 		|  13 		| 8 					  |
# 				+--------+----------+---------+-----------+-------------------+
#
# 			One way to generate the initial set of Fibonacci numbers is to use a recursive
# 			common table expression.
#
# 			For an example, see FIBONACCI SERIES GENERATION
#
# 		) LAST_VALUE(expr) [null_treatment] over_clause
#
# 			Returns the value of expr from the last row of the window frame
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			For an example, see the FIRST_VALUE() function description
#
# 		) LEAD(expr [, N[, default]]) [null_treatment] over_clause
#
# 			Returns the value of expr from the row that leads (follows) the current row
# 			by N rows within its partition.
#
# 			If there is no such row, the return value is default.
#
# 			For example, if N is 3, the return value is default for the last two rows.
#
# 			If N or default are missing, the defaults are 1 and NULL, respectively.
#
# 			N must be a literal nonnegative integer. If N is 0, expr is evaluated for the
# 			current row.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in this section intro
#
# 			For an example, see the LAG() function description
#
# 		) NTH_VALUE(expr, N) [from_first_last] [null_treatment] over_clause
#
# 			Returns the value of expr from the N-th row of the window frame.
# 			If there is no such row, the return value is NULL.
#
# 			N must be a literal positive integer.
#
# 			from_first_last is part of the SQL standard, but the MySQL implementation
# 			permits only FROM FIRST(which is also the default)
#
# 			This means that calculations begin at the first row of the window.
#
# 			FROM LAST is parsed, but produces an error. To obtain the same effect as
# 			FROM LAST (begin calculations at the last row of the window), use 
# 			ORDER BY to sort in reverse order.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			null_treatment is as described in the section intro.
#
# 			For an example, see the FIRST_VALUE() function description
#
# 		) NTILE(N) over_clause
#
# 			Divides a partition into N groups (buckets), assigns each row in the partition
# 			its bucket number, and returns the bucket number of the current row within its partition.
#
# 			For example, if N is 4, NTILE() divides rows into four buckets.
#
# 			If N is 100, NTILE() divides rows into 100 buckets.
#
# 			N must be a literal positive integer. Bucket number return values range from 1 to N.
#
# 			This function should be used with ORDER BY to sort partition rows into the
# 			desired order.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows, for the set of values in the val column,, the percentile values
# 			resulting from dividing the rows into two or four groups.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() 	OVER w AS 'row_number',
# 					NTILE(2) 		OVER w AS 'ntile2',
# 					NTILE(4) 		OVER w AS 'ntile4'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+---------+---------------+----------------+------------+
# 				| val 	 | row_number 	  | ntile2 			 | ntile4 	  |
# 				+---------+---------------+----------------+------------+
# 				| 1 		 | 1 				  | 1 				 | 1 			  |
# 				| 1 		 | 2 				  | 1 				 | 1 			  |
# 				| 2 		 | 3 				  | 1 				 | 1 			  |
# 				| 3 		 | 4 				  | 1 				 | 2 			  |
# 				| 3 		 | 5 				  | 1 				 | 2 			  |
# 				| 3 		 | 6 				  | 2 				 | 3 			  |
# 				| 4 		 | 7 				  | 2 				 | 3 			  |
# 				| 4 		 | 8 				  | 2 				 | 4 			  |
# 				| 5 		 | 9 				  | 2 				 | 4 			  |
# 				+---------+---------------+-----------------+-----------+
#
# 		) PERCENT_RANK() over_clause
#
# 			Returns the percentage of partition values less than the value in the current row,
# 			excluding the highest value.
#
# 			Return values range from 0 to 1 and represent the row relative rank, calculated
# 			as the result of this formula, where rank is the row rank and rows is the number
# 			of partition rows:
#
# 				(rank - 1) / (rows - 1)
#
# 			This function should be used with ORDER BY to sort partition rows into the desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			For an example, see the CUME_DIST() function description.
#
# 		) RANK() over_clause
#
# 			Returns the rank of the current row within its partition, with gaps.
#
# 			Peers are considered ties and receive the same rank.
#
# 			This function does not assign consecutive ranks to peer groups if groups
# 			of size greater than one exist; the result is noncontiguous rank numbers.
#
# 			This function should be used with ORDER BY to sort partition rows into the
# 			desired order.
#
# 			Without ORDER BY, all rows are peers.
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 			The following query shows the difference between RANK(), which produces ranks with gaps,
# 			and DENSE_RANK(), which produces ranks without gaps.
#
# 			The query shows rank values for each member of a set of values in the val column,
# 			which contains some duplicates.
#
# 			RANK() assigns peers (the duplicates) the same rank value, and the next greater value
# 			has a rank higher by the number of peers minus one.
#
# 			DENSE_RANK() also assigns peers the same rank value, but the next higher value
# 			has a rank one greater.
#
# 			For reference, the query also displays row numbers using ROW_NUMBER():
#
# 				SELECT
# 					val,
# 					ROW_NUMBER() OVER w AS 'row_number',
# 					RANK() 		 OVER w AS 'rank',
# 					DENSE_RANK() OVER w AS 'dense_rank'
# 				FROM numbers
# 				WINDOW w AS (ORDER BY val);
# 				+--------+--------------------+----------+---------------+
# 				| val 	| row_number 			| rank 	  | dense_rank 	|
# 				+--------+--------------------+----------+---------------+
# 				| 1 		| 1 						| 1 		  | 1 				|
# 				| 1 		| 2 						| 1 		  | 1 				|
# 				| 2 		| 3 						| 3 		  | 2 				|
# 				| 3 	   | 4 						| 4 		  | 3 				|
# 				| 3 		| 5 						| 4 		  | 3 				|
# 				| 3 		| 6 						| 4 		  | 3 				|
# 				| 4 		| 7 						| 7 		  | 4 				|
# 				| 4 		| 8 					   | 7 		  | 4 				|
# 				| 5 		| 9 						| 9 		  | 5 				|
# 				+--------+--------------------+----------+---------------+
#
# 		) ROW_NUMBER() over_clause
#
# 			Returns the number of the current row within its partition.
#
# 			Rows numbers range from 1 to the number of partition rows.
#
# 			ORDER BY affects the order in which rows are numbered.
#
# 			Without ORDER BY, row numbering is nondeterministic.
#
# 			ROW_NUMBER() assigns peers different row numbers. 
#
# 			To assign peers the same value, use RANK() or DENSE_RANK()
#
# 			For an example, see the RANK() function description
#
# 			over_clause is as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 12.21.2 WINDOW FUNCTION CONCEPTS AND SYNTAX
#
# This section describes how to use window functions.
#
# Examples use the same sales information data set as found in the discussion
# of the GROUPING() function in SECTION 12.20.2, "GROUP BY MODIFIERS"
#
# 		SELECT * FROM sales ORDER BY country, year, product;
# 		+----------+-------------+-------------------+-----------+
# 		| year 	  | country 	 | product 			   | profit 	|
# 		+----------+-------------+-------------------+-----------+
# 		| 2000 	  | Finland 	 | Computer 			| 1500 		|
# 		| 2000 	  | Finland 	 | Phone 				| 100 		|
# 		| 2001 	  | Finland 	 | Phone 				| 10 			|
# 		| 2000 	  | India 		 | Calculator 			| 75 			|
# 		| 2000 	  | India 		 | Calculator 			| 75 		   |
# 		| 2000 	  | India 		 | Computer 			| 1200 		|
# 		| 2000 	  | USA 			 | Calculator 			| 75 		   |
# 		| 2000 	  | USA 			 | Computer 			| 1500 		|
# 		| 2001 	  | USA 			 | Calculator 			| 50 			|
# 		| 2001 	  | USA 			 | Computer 			| 1500 		|
# 		| 2001 	  | USA 			 | Computer 			| 1200 		|
# 		| 2001 	  | USA 			 | TV 					| 150 		|
# 		| 2001 	  | USA 			 | TV 					| 100 		|
# 		+----------+-------------+-------------------+-----------+
#
# A window function performs an aggregate-like operation on a set of query rows.
#
# However, whereas an aggregate operation groups query rows into a single
# result row, a window function produces a result for each query row:
#
# 		) The row for which function evaluation occurs is called the current row
#
# 		) The query rows related to the current row over which function evaluation occurs
# 			comprise the window for the current row.
#
# For example, using the sales information table, these two queries perform aggregate
# operations that produce a single global sum for all rows taken as a group, and sums
# grouped per country:
#
# 		SELECT SUM(profit) AS total_profit
# 		FROM sales;
# 		+---------------------------+
# 		| total_profit 				 |
# 		+---------------------------+
# 		| 	7535 							 |
# 		+---------------------------+
#
# 		SELECT country, SUM(profit) AS country_profit
# 		FROM sales
# 		GROUP BY country
# 		ORDER BY country;
# 		+------------+----------------+
# 		| country 	 | country_profit |
# 		+------------+----------------+
# 		| Finland 	 | 		1610 	   |
# 		| India 		 | 		1350 	   |
# 		| USA 		 | 		4575 		|
# 		+------------+----------------+
#
# By contrast, window operations do not collapse groups of query rows to a single
# output row.
#
# Instead, they produce a result for each row.
#
# Like the preceding queries, the following query uses SUM(), but this time
# as a window function:
#
# 		SELECT
# 			year, country, product, profit,
# 			SUM(profit) OVER() AS total_profit,
# 			SUM(profit) OVER(PARTITION BY country) AS country_profit
# 		FROM sales
# 		ORDER BY country, year, product, profit;
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
# 		| year 	  | country 		| product 			 | profit 	 | total_profit 		  | country_profit 	 |
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
# 		| 2000 	  | Finland 		| Computer 			 | 1500 		 | 7535 					  | 	1610 				 |
# 		| 2000 	  | Finland 		| Phone 				 | 100 		 | 7535 					  | 	1610 				 |
# 		| 2001 	  | Finland 		| Phone 				 | 10 		 | 7535 					  | 	1610 				 |
# 		| 2000 	  | India 			| Calculator 		 | 75 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | India 			| Calculator 		 | 75 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | India 			| Computer 			 | 1200 		 | 7535 					  | 	1350 				 |
# 		| 2000 	  | USA 				| Calculator 		 | 75 		 | 7535 					  | 	4575 				 |
# 		| 2000 	  | USA 				| Computer 			 | 1500 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| Calculator 		 | 50 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 			   | Computer 			 | 1200 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| Computer 			 | 1500 		 | 7535 					  | 	4575 				 |
# 		| 2001 	  | USA 				| TV 					 | 100 		 | 7535 					  | 	4575 				 |
#		| 2001 	  | USA 				| TV 					 | 150 		 | 7535 					  | 	4575 				 |
# 		+----------+---------------+------------------+-----------+---------------------+-------------------+
#
# Each window operation in the query is signified by inclusion of an OVER clause that specifies
# how to partition query rows into groups for processing by the window function:
#
# 		) The first OVER clause is empty, which treats the entire set of query rows as a single partition.
#
# 			The window function thus produces a global sum, but does so for each row
#
# 		) The second OVER clause partitions rows by country, producing a sum per partition (per country)
#
# 			The function produces this sum for each partition row.
#
# Window functions are permitted only in the select list and ORDER BY clause.
#
# Query result rows are determined from the FROM clause, after WHERE, GROUP BY, and 
# HAVING processing, and windowing execution occurs before ORDER BY, LIMIT and SELECT DISTINCT.
#
# The OVER clause is permitted for many aggregate functions, which therefore can be used
# as window or nonwindow functions, depending on whether the OVER clause is present or absent:
#
# 		AVG()
# 		BIT_AND()
# 		BIT_OR()
#
# 		BIT_XOR()
# 		COUNT()
# 		JSON_ARRAYAGG()
# 			
#		JSON_OBJECTAGG()
# 		MAX()
# 		MIN()
#
# 		STDDEV_POP(), STDDEV(), STD()
# 		STDDEV_SAMP()
# 		SUM()
#
# 		VAR_POP(), VARIANCE()
# 		VAR_SAMP()
#
# For details about each aggregate function, see SECTION 12.20.1, "AGGREGATE (GROUP BY) FUNCTION DESCRIPTIONS"
#
# MySQL also supports nonaggregate functions that are used only as window functions.
#
# For these, the OVER clause is mandatory:
#
# 		CUME_DIST()
#
# 		DENSE_RANK()
#
# 		FIRST_VALUE()
#
# 		LAG()
#
# 		LAST_VALUE()
#
# 		LEAD()
#
# 		NTH_VALUE()
#
# 		NTILE()
#
# 		PERCENT_RANK()
#
# 		RANK()
#
# 		ROW_NUMBER()
#
# For details about each nonaggregate function, see SECTION 12.21.1, "WINDOW FUNCTION DESCRIPTIONS"
#
# As an example of one of those nonaggregate window functions, this query uses ROW_NUMBER(),
# which produces the row number of each row within its partition.
#
# In this case, rows are numbered per country.
#
# By default, partition rows are unordered and row numbering is nondeterministic.
#
# To sort partition rows, include an ORDER BY clause within the window definition.
#
# The query uses unordered and ordered partitions (the row_num1 and row_num2 columns)
# to illustrate the difference between omitting and including ORDER BY:
#
# 		SELECT
# 			year, country, product, profit,
# 			ROW_NUMBER() OVER(PARTITION BY country) AS row_num1,
# 			ROW_NUMBER() OVER(PARTITION BY country ORDER BY year, product) AS row_num2
# 		FROM sales;
#
# +--------+------------------+------------------+---------------+----------------+--------------+
# | year   | country 			| product 			 | profit 		  | row_num1 		 | row_num2 	 |
# +--------+------------------+------------------+---------------+----------------+--------------+
# | 2000   | Finland 			| Computer 			 | 1500 			  | 2 				 | 	1 			 |
# | 2000   | Finland 			| Phone 				 | 100 			  | 1 				 | 	2 			 |
# | 2001   | Finland 			| Phone 				 | 10 			  | 3 				 | 	3 			 |
# | 2000   | India 				| Calculator 		 | 75 			  | 2 				 | 	1 			 |
# | 2000   | India 				| Calculator 		 | 75 			  | 3 				 | 	2 			 |
# | 2000   | India 				| Computer 			 | 1200 			  | 1 				 | 	3 			 |
# | 2000   | USA 					| Calculator 		 | 75 			  | 5 				 | 	1 		    |
# | 2000   | USA 					| Computer 			 | 1500 			  | 4 				 | 	2 			 |
# | 2001   | USA 					| Calculator 		 | 50 			  | 2 				 | 	3 			 |
# | 2001   | USA 					| Computer 			 | 1500 			  | 3 				 | 	4 			 |
# | 2001   | USA 					| Computer 			 | 1200 			  | 7 				 | 	5 			 |
# | 2001   | USA 					| TV 					 | 150 			  | 1 				 | 	6 			 |
# | 2001   | USA 					| TV 					 | 100 			  | 6 				 | 	7 			 |
# +--------+------------------+------------------+---------------+----------------+--------------+
#
# As mentioned previously, to use a window function (or treat an aggregate function as a window function),
# include an OVER clause following the function call.
#
# The OVER clause has two forms:
#
# 		over_clause:
# 			{OVER (window_spec) | OVER window_name}
#
# Both forms define how the window functions should process query rows.
#
# They differ in whether the window is defined directly in the OVER clause, or
# supplied by a reference to a named window defined elsewhere in the query:
#
# 		) In the first case, the window specification appears directly in the OVER clause, between the parentheses
#
# 		) In the second case, window_name is the name for a window specification defined by a WINDOW clause elsewhere
# 			in the query.
#
# 			For details, see SECTION 12.21.4, "NAMED WINDOWS"
#
# For OVER (window_spec) syntax, the window specification has several parts, all optional:
#
# 		window_spec:
# 			[window_name] [partition_clause] [order_clause] [frame_clause]
#
# If OVER() is empty, the window consists of all query rows and the window function computes
# a result using all rows.
#
# Otherwise, the clauses present within the parentheses determine which query rows are used
# to compute the function result and how they are partitioned and ordered:
#
# 		) window_name: The name of a window defined by a WINDOW clause elsewhere in the query.
#
# 			If window_name appears by itself within the OVER clause, it completely defines
# 			the window.
#
# 			If partitioning, ordering, or framing clauses are also given, they modify interpretation
# 			of the named window.
#
# 			For details, SEE SECTION 12.21.4, "NAMED WINDOWS"
#
# 		) partition_clause: A PARTITION BY clause indicates how to divide the query rows into groups.
#
# 			The window function result for a given row is based on the rows of the partition
# 			that contains the row.
#
# 			If PARTITION BY is omitted, there is a single partition consisting of all query rows.
#
# 			NOTE:
#
# 				Partitioning for window functions differs from table partitioning. For more information about
# 				table partitioning, see CHAPTER 23, PARTITIONING
#
# 			partition_clause has this syntax:
#
# 				partition_clause:
# 					PARTITION BY expr [, expr] ---
#
# 			Standard SQL requires PARTITION BY to be followed by column names only.
#
# 			A MySQL extension is to permit expressions, not just column names.
#
# 			For example, if a table contains a TIMESTAMP column named ts, standard SQL
# 			permits PARTITION BY ts but not PARTITION BY HOUR(ts), whereas MySQL permits both.
#
# 		) order_clause: An ORDER BY clause indicates how to sort rows in each partition.
#
# 			Partition rows that are equal according to the ORDER BY clause are considered peers.
#
# 			If ORDER BY is omitted, partition rows are unordered, with no procesing order implied,
# 			and all partition rows are peers.
#
# 			order_clause has this syntax:
#
# 				order_clause:
# 					ORDER BY expr [ASC|DESC] [, expr [ASC|DESC]] ---
#
# 			Each ORDER BY expression optionally can be followed by ASC or DESC to indicate sort direction.
#
# 			The default is ASC if no direction is specified, NULL values sort first for
# 			ascending sorts, last for descending sorts.
#
# 			An ORDER BY in a window definition applies within individual partitions.
#
# 			To sort the result set as a whole, include an ORDER BY at the query top level.
#
# 		) frame_clause: A frame is a subset of the current partition and the frame clause specifies
# 			how to define the subset.
#
# 			The frame clause has many subclasses of its own.
#
# 			For details, see SECTION 12.21.3, "WINDOW FUNCTION FRAME SPECIFICATION"
#
# 12.21.3 WINDOW FUNCTION FRAME SPECIFICATION
#
# The definition of a window used with a window function can include a frame clause.
#
# A frame is a subset of the current partition and the frame clause specifies
# how to define the subset.
#
# Frames are determined with respect to the current row, which enables a frame to
# move within a partition depending on the location of the current row within its
# partition.
#
# Examples:
#
# 		) By defining a frame to be all rows from the partition start to the current row,
# 			you can compute running totals for each row
#
# 		) By defining a frame as extending N rows on either side of the current row,
# 			you can compute rolling averages.
#
# The following query demonstrates the use of moving frames to compute running totals
# within each group of time-ordered level values, as well as rolling averages computed
# from the current row and the rows that immediately precede and follow it:
#
# 		SELECT
# 			time, subject, val,
# 			SUM(val) OVER (PARTITION BY subject ORDER BY time
# 								ROWS UNBOUNDED PRECEDING)
# 			AS running_total,
# 			AVG(val) OVER (PARTITION BY subject ORDER BY time
# 								ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING)
# 				AS running_average
# 			FROM observations;
# 		+------------------+---------------+-------------+-------------------+-------------------+
# 		| time 				 | subject 		  | val 			 | running_total 		| running_average   |
# 		+------------------+---------------+-------------+-------------------+-------------------+
# 		| 07:00:00 			 | st113 		  | 10 			 | 		10 			| 9.5000 			  |
# 		| 07:15:00 			 | st113 		  | 9 			 | 		19 			| 14.6667 			  |
# 		| 07:30:00 			 | st113 		  | 25 			 | 		44 		   | 18.0000 			  |
# 		| 07:45:00 			 | st113 		  | 20 			 | 		64 			| 22.5000 			  |
# 		| 07:00:00 			 | xh458 		  | 0 			 | 		0 				| 5.0000 			  |
# 		| 07:15:00 			 | xh458 		  | 10 			 | 		10 			| 5.0000 			  |
# 		| 07:30:00 			 | xh458 		  | 5 			 | 		15 			| 15.0000 			  |
# 		| 07:45:00 			 | xh458 		  | 30 			 | 		45 			| 20.0000 			  |
# 		| 08:00:00 			 | xh458 		  | 25 			 | 		70 			| 27.5000 			  |
# 		+------------------+---------------+-------------+-------------------+-------------------+
#
# For the running_average column, there is no frame row preceding the first one or following the last.
#
# In these cases, AVG() computes the average of the rows that are available.
#
# Aggregate functions used as window functions operate on rows in the current row frame,
# as do these nonaggregate window functions:
#
# 		FIRST_VALUE()
# 		LAST_VALUE()
# 		NTH_VALUE()
#
# Standard SQL specifies that window functions that operate on the entire partition should
# have no frame clause.
#
# MySQL permits a frame clause for such functions but ignores it.
#
# These functions use the entire partition even if a frame is specified:
#
# 		CUME_DIST()
# 
# 		DENSE_RANK()
#
# 		LAG()
#
# 		LEAD()
#
# 		NTILE()
#
# 		PERCENT_RANK()
#
# 		RANK()
#
# 		ROW_NUMBER()
#
# The frame clause,, if given, has this syntax:
#
# 		frame_clause:
# 			frame_units frame_extent
#
# 		frame_units:
# 			{ROWS | RANGE}
#
# In the absence of a frame clause, the default frame depends on whether
# an ORDER BY clause is present, as described later in this section.
#
# The frame_units value indicates the type of relationship between the
# current row and frame rows:
#
# 		) ROWS: The frame is defined by beginning and ending row positions.
#
# 			Offsets are differences in row numbers from the current row number.
#
# 		) RANGE: The frame is defined by rows within a value range.
#
# 			Offsets are differences in row values from the current row value.
#
# The frame_extent value indicates the start and end points of the frame.
#
# You can specify just the start of hte frame (in which case the current row is implicitly the end)
# or use BETWEEN to specify both frame endpoints:
#
# 		frame_extent:
# 			{frame_start | frame_between}
#
# 		frame_between:
# 			BETWEEN frame_start AND frame_end
#
# 		frame_start, frame_end: {
# 			CURRENT ROW
# 		 | UNBOUNDED PRECEDING
# 		 | UNBOUNDED FOLLOWING
# 		 | expr PRECEDING
# 		 | expr FOLLOWING
# 		}
#
# With BETWEEN syntax, frame_start must not occur later than frame_end
#
# The permitted frame_start and frame_end values have these meanings:
#
# 		) CURRENT ROW: For ROWS, the bound is the current row. For RANGE, the bounds is the peers of the current row.
#
# 		) UNBOUNDED PRECEDING: The bound is the first partition row
#
# 		) UNBOUNDED FOLLOWING: The bound is the last partition row
#
# 		) expr PRECEDING: For ROWS, the bound is expr rows before the current row.
#
# 			For RANGE, the bound is the rows with values equal to the current row value
# 			minus expr; if the current row value is NULL, the bound is the peers of the row.
#
# 			For expr PRECEDING (and expr FOLLOWING) expr can be a ? parameter marker
# 			(for use in a prepared statement), a nonnegative numeric literal, or a temporal
# 			interval of the form INTERVAL val unit.
#
# 			For INTERVAL expressions, val specifies nonnegative interval value,
# 			and unit is a keyword indicating the units in which the value should be interpreted.
#
# 			(For details about the permitted units specifiers, see the description of the DATE_ADD()
# 			function in SECTION 12.7, "DATE AND TIME FUNCTIONS")
#
# 			RANGE on a numeric or temporal expr requires ORDER BY on a numeric or temporal expression,
# 			respectively.
#
# 			Examples of valid expr PRECEDING and expr FOLLOWING indicators:
#
# 				10 PRECEDING
# 				INTERVAL 5 DAY PRECEDING
# 				5 FOLLOWING
# 				INTERVAL '2:30' MINUTE_SECOND FOLLOWING
#
# 		) expr FOLLOWING: For ROWS, the bound is expr rows after the current row.
#
# 			For RANGE, the bound is the rows with values equal to the current row
# 			value plus expr; if the current row value is NULL, the bound is the
# 			peers of hte row.
#
# 			For permitted values of expr, see the description of expr PRECEDING
#
# The following query demonstrates FIRST_VALUE(), LAST_VALUE() and two instaces of NTH_VALUE():
#
# 		SELECT
# 			time, subject, val,
# 			FIRST_VALUE(val) 		OVER w AS 'first',
# 			LAST_VALUE(val) 		OVER w AS 'last',
# 			NTH_VALUE(val, 2) 	OVER w AS 'second',
# 			NTH_VALUE(val, 4) 	OVER w AS 'fourth'
# 		FROM observations
# 		WINDOW w AS (PARTITION BY subject ORDER BY time
# 						ROWS UNBOUNDED PRECEDING);
#
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
# 		| time 			| subject 	 | val 	  | first 	 | last 	    | second 		| fourth |
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
# 		| 07:00:00 		| st113 		 | 10 	  | 10 		 | 10 		 | NULL 		   | NULL 	|
# 		| 07:15:00     | st113 		 | 9 		  | 10 		 | 9 			 | 9 				| NULL   |
# 		| 07:30:00     | st113 		 | 25 	  | 10 		 | 25 		 | 9 				| NULL   |
# 		| 07:45:00 		| st113 		 | 20 	  | 10 		 | 20 		 | 9 				| 20 		|
# 		| 07:00:00  	| xh458 		 | 0 		  | 0 		 | 0 			 | NULL 		   | NULL 	|
# 		| 07:15:00     | xh458 		 | 10 	  | 0 		 | 10 		 | 10 			| NULL 	|
# 		| 07:30:00 		| xh458 		 | 5 		  | 0 		 | 5 			 | 10 			| NULL 	|
# 		| 07:45:00 	   | xh458 		 | 30 	  | 0 		 | 30 		 | 10 			| 30 		|
# 		| 08:00:00 		| xh458 		 | 25 	  | 0 		 | 25 		 | 10 			| 30 	   |
# 		+--------------+------------+---------+----------+-----------+-------------+--------+
#
# Each function uses the rows in the current frame, which, per the window definition shown,
# extends from the first partition row to the current row.
#
# For the NTH_VALUE() calls, the current frame does not always include the requested row;
# in such cases, the return value is NULL
#
# In the absence of a frame clause, the default frame depends on whether an ORDER BY clause
# is present:
#
# 		) With ORDER BY: 
#
# 			The default frame includes rows from the partition start through
# 			the current row, including all peers of the current row (rows equal to the current
# 			row according to the ORDER BY clause)
#			
# 			The default is equivalent to this frame specification:
#
# 				RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
#
# 		) Without ORDER BY:
#
# 			The default frame includes all partition rows (because, without ORDER BY, all partition
# 			rows are peers)
#
# 			The default is equivalent to this frame specification:
#
# 				RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING
#
# Because the default frame differs depending on presence or absence of ORDER BY,
# adding ORDER BY to a query to get deterministic results may change the results.
#
# (For example, the values produced by SUM() might change)
#
# TO obtain the same results but ordered per ORDER BY, provide an explicit
# frame specification to be used regardless of whether ORDER BY is present.
#
# The meaning of a frame specification can be nonobvious when the current
# row value is NULL.
#
# Assuming that to be the case, these examples illustrate how various frame
# specifications apply:
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 FOLLOWING AND 15 FOLLOWING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 FOLLOWING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at the end of the partition.
#
# 			Because an ASC sort puts NULL values first, the frame is the entire partition.
#
# 		) ORDER BY X DESC RANGE BETWEEN 10 FOLLOWING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at the end of the partition.
#
# 			Because a DESC sort puts NULL values last, the frame is only the NULL values.
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND UNBOUNDED FOLLOWING
#
# 			The frame starts at NULL and stops at teh end of the partition.
#
# 			Because an ASC sort puts NULL values first, the frame is the entire partition.
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND 10 FOLLOWING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN 10 PRECEDING AND 1 PRECEDING
#
# 			The frame starts at NULL and stops at NULL, thus includes only rows with value NULL
#
# 		) ORDER BY X ASC RANGE BETWEEN UNBOUNDED PRECEDING AND 10 FOLLOWING
#
# 			The frame starts at the beginning of the partition and stops at rows with value NULL.
#
# 			Because n ASC sort puts NULL values first, the frame is only the NULL values
#
# 12.21.4 NAMED WINDOWS
#
# Windows can be defined and given names by which to refer to them in OVER clauses.
#
# To do this, use a WINDOW clause.
#
# If present in a query, the WINDOW clause falls between the positions of the
# HAVING and ORDER BY clauses, and has this syntax:
#
# 		WINDOW window_name AS (window_spec)
# 			[, window_name AS (window_spec)] ---
#
# For each window definition, window_name is the window name, and window_spec is the
# same type of window specification as given between the parentheses of an OVER
# clause, as described in SECTION 12.21.2, "WINDOW FUNCTION CONCEPTS AND SYNTAX"
#
# 		window_spec:
# 			[window_name] [partition_clause] [order_clause] [frame_clause]
#
# A WINDOW clause is useful for queries in which multiple OVER clauses would otherwise
# define the same window.
#
# Instead, you can define the window once, give it a name, and refer to the name
# in teh OVER clauses.
#
# Consider this query, which defines the same window multiple times:
#
# 		SELECT
# 			val,
# 			ROW_NUMBER() OVER (ORDER BY val) AS 'row_number',
# 			RANK() 		 OVER (ORDER BY val) AS 'rank',
# 			DENSE_RANK() OVER (ORDER BY val) AS 'dense_rank'
# 		FROM numbers;
#
# The query can be written more simply by using WINDOW to define the window once and referring
# to the window by name in the OVER clauses:
#
# 		SELECT
# 			val,
# 			ROW_NUMBER() OVER w AS 'row_number',
# 			RANK() 		 OVER w AS 'rank',
# 			DENSE_RANK() OVER w AS 'dense_rank'
# 		FROM numbers
# 		WINDOW w AS (ORDER BY val);
#
# A named window also makes it easier to experiment with the window definition
# to see the effect on query results.
#
# YOu need only modify the window definition in the WINDOW clause, rather than
# multiple OVER clause definitions.
#
# If an OVER clause uses OVER (window_name ---) rather than OVER window_name,
# the named window can be modified by the addition of other clauses.
#
# For example, this query defines a window that includes partitioning, and uses
# ORDER BY in the OVER clauses to modify the window in different ways:
#
# 		SELECT
# 			DISTINCT year, country,
# 			FIRST_VALUE(year) OVER (w ORDER BY year ASC) AS first,
# 			FIRST_VALUE(year) OVER (w ORDER BY year DESC) AS last
# 		FROM sales
# 		WINDOW w AS (PARTITION BY country);
#
# An OVER clause cna only add properties to a named window, not modify them.
#
# If the named window definition includes a partitioning, ordering or framing
# property, the OVER clause that refers to the window name cannot also include
# the same kind of property or an error occurs:
#
# 		) This construct is permitted because the window definition and the referring
# 			OVER clause do not contain the same kind of properties:
#
# 			OVER (w ORDER BY country)
# 			--- WINDOW w AS (PARTITION BY country)
#
# 		) This construct is not permitted because the OVER clause specifies PARTITION BY 
# 			for a named window that already has PARTITION BY:
#
# 			OVER (w PARTITION BY year)
# 			--- WINDOW w AS (PARTITION BY country)
#
# The definition of a named window can itself begin with a window_name.
#
# In such cases, forward and backward references are permitted, but not cycles:
#
# 		) This is permitted; it contains forward and backward references but no cycles:
#
# 			WINDOW w1 AS (w2), w2 AS (), w3 AS (w1)
#
# 		) This is not permitted because it contains a cycle:
#
# 			WINDOW w1 AS (w2), w2 AS (w3), w3 AS (w1)
#
# 12.21.5 WINDOW FUNCTION RESTRICTIONS
#
# The SQL standard imposes a constraint on window functions that they cannot
# be used in UPDATE or DELETE statements to update rows.
#
# Using such functions in a subquery of these statements (to select rows)
# is permitted.
#
# MySQL does not support these window function features:
#
# 		) DISTINCT syntax for aggregate window functions
#
# 		) Nested window functions
#
# 		) Dynamic frame endpoints that depend on the value of the current row
#
# THe parser recognizes these window constructs which nevertheless are not
# supported:
#
# 		) The GROUPS frame units specifier is parsed, but produces an error.
#
# 			Only ROWS and RANGE are supported.
#
# 		) The EXCLUDE clause for frame specification is parsed, but produces an error.
#
# 		) IGNORE NULLS is parsed, but produces an error. Only RESPECT NULLS
# 			is supported.
#
# 		) FROM LAST is parsed, but produces an error. Only FROM FIRST is supported.
#
# 12.22 INTERNAL FUNCTIONS
#
# TABLE 12.28 INTERNAL FUNCTIONS
#
# NAME 								Desc
#
# CAN_ACCESS_COLUMN() 			Internal use only
#
# CAN_ACCESS_DATABASE() 		Internal
#
# CAN_ACCESS_TABLE() 			Internal
#
# CAN_ACCESS_VIEW() 				Internal
#
# GET_DD_COLUMN_PRIVILEGES() 	Internal
#
# GET_DD_CREATE_OPTIONS() 		Internal
#
# GET_DD_INDEX_SUB_PART_LENGTH() Internal
#
# INTERNAL_AUTO_INCREMENT() 	Internal
#
# INTERNAL_AVG_ROW_LENGTH() 	Internal
#
# INTERNAL_CHECK_TIME() 		Internal
#
# INTERNAL_CHECKSUM() 			Internal
#
# INTERNAL_DATA_FREE() 			Internal
#
# INTERNAL_DATA_LENGTH() 		Internal
#
# INTERNAL_DD_CHAR_LENGTH() 	Internal
#
# INTERNAL_GET_COMMENT_OR_ERROR() Internal
#
# INTERNAL_GET_VIEW_WARNING_OR_ERROR() Internal
#
# INTERNAL_INDEX_COLUMN_CARDINALITY() Internal
#
# INTERNAL_INDEX_LENGTH() 		Internal
#
# INTERNAL_KEYS_DISABLED() 	INternal
#
# INTERNAL_MAX_DATA_LENGTH() 	Internal
#
# INTERNAL_TABLE_ROWS() 		internal
#
# INTERNAL_UPDATE_TIME() 		internal
#
# The functions listed in this section are intended only for internal use by teh server.
#
# Attempts by users to invoke them, results in an error.
#
# 		) CAN_ACCESS_COLUMN(ARGS)
#
# 		) CAN_ACCESS_DATABASE(ARGS)
#
# 		) CAN_ACCESS_TABLE(ARGS)
#
# 		) CAN_ACCESS_VIEW(ARGS)
#
# 		) GET_DD_COLUMN_PRIVILEGES(ARGS)
#
# 		) GET_DD_CREATE_OPTIONS(ARGS)
#
# 		) GET_DD_INDEX_SUB_PART_LENGTH(ARGS)
#
# 		) INTERNAL_AUTO_INCREMENT(ARGS)
#
# 		) INTERNAL_AVG_ROW_LENGTH(ARGS)
#
# 		) INTERNAL_CHECK_TIME(ARGS)
#
# 		) INTERNAL_CHECKSUM(ARGS)
#
# 		) INTERNAL_DATA_FREE(ARGS)
#
# 		) INTERNAL_DATA_LENGTH(ARGS)
#
# 		) INTERNAL_DD_CHAR_LENGTH(ARGS)
#
# 		) INTERNAL_GET_COMMENT_OR_ERROR(ARGS)
#
# 		) INTERNAL_GET_VIEW_WARNING_OR_ERROR(ARGS)
#
# 		) INTERNAL_INDEX_COLUMN_CARDINALITY(ARGS)
#
# 		) INTERNAL_INDEX_LENGTH(ARGS)
#
# 		) INTERNAL_KEYS_DISABLED(ARGS)
#
# 		) INTERNAL_MAX_DATA_LENGTH(ARGS)
#
# 		) INTERNAL_TABLE_ROWS(ARGS)
#
# 		) INTERNAL_UPDATE_TIME(ARGS)
#
# 		) IS_VISIBLE_DD_OBJECT(ARGS)
#
# 12.23 MISCELLANEOUS FUNCTIONS
#
# TABLE 12.29 MISCELLANEOUS FUNCTIONS
#
# 		NAME 									DESCRIPTION
# ANY_VALUE() 			Suppress ONLY_FULL_GROUP_BY value rejection
#
# BIN_TO_UUID() 		Convert binary UUID to string
#
# DEFAULT() 			Return the default value for a table column
#
# GROUPING() 			Distinguish super-aggregate ROLLUP rows from regular rows
#
# INET_ATON() 			Return the numeric value of an IP address
#
# INET_NTOA() 			Return the IP address from a numeric value
#
# INET6_ATON() 		Return the numeric value of an IPv6 address
#
# INET6_NTOA() 		Return the IPv6 address from a numeric value
#
# IS_IPV4() 			Whether argument is an IPv4 address
#
# IS_IPV4_COMPAT() 	Whether argument is an IPv4-compatible address
#
# IS_IPV4_MAPPED() 	Whether argument is an IPV4-mapped address
#
# IS_IPV6() 			Whether argument is an IPv6 address
#
# IS_UUID() 			Whether argument is a valid UUID
#
# MASTER_POS_WAIT() 	Block until the slave has read and applied all updates up to teh specific position
#
# NAME_CONST() 		Cause the column to have the given name
#
# RAND() 				Return a random floating-point value
#
# SLEEP() 				Sleep for a number of seconds
#
# UUID() 				Returns a Universal Unique Identifier (UUID)
#
# UUID_SHORT() 		Return an integer-valued universal identifier
#
# UUID_TO_BIN() 		Convert string UUID to binary
#
# VALUES() 				Defines the values to be used during an INSERT
#
# 		) ANY_VALUE(arg)
#
# 			THis function is useful for GROUP BY queries when the ONLY_FULL_GROUP_BY SQL mode is enabled,
# 			for cases when MySQL rejects a query that you know is valid for reasons that MySQL
# 			cannot determine.
#
# 			The function return value  and type are the same as the return value and type of its argument,
# 			but the function result is not checked for the ONLY_FULL_GROUP_BY SQL mode.
#
# 			For example, if name is a nonindexed column, the following query fails with
# 			ONLY_FULL_GROUP_BY enabled:
#
# 				SELECT name, address, MAX(age) FROM t GROUP BY name;
# 				ERROR 1055 (42000): Expression #2 of SELECT list is not
# 				in GROUP BY clause and contains nonaggregated column
# 				'mydb.t.address' which is not functionally dependent
# 				on columns in GROUP BY clause; this is incompatible
# 				with sql_mode=only_full_group_by
#
# 			THe failure occurs because address is a nonaggregated column that is
# 			neither named among GROUP BY columns nor functionally dependent on them.
#
# 			As a result, the address value for rows within each name group is nondeterminsitic.
#
# 			There are multiple ways to cause MySQL to accept the query:
#
# 				) Alter the table to make name a primary key or a unique NOT NULL column.
#
# 					This enables MySQL to determine that address is functionally dependent
# 					on name;
#
# 					That is, address is uniquely determined by name. (This technique is inapplicable if NULL
# 					must be permitted as a valid name value)
#
# 				) Use ANY_VALUE() to refer to address:
#
# 					SELECT name, ANY_VALUE(address), MAX(age) FROM t GROUP BY name;
#
# 					In this case, MySQL ignores teh nondeterminism of address values within
# 					each name group and accepts the query.
#
# 					This may be useful if you simply do not care which value of a nonaggregated
# 					column is chosen for each group.
#
# 					ANY_VALUE() is not an aggregate function, unlike functions such as SUM()
# 					or COUNT()
#
# 					It simply acts to suppress the test for nondeterminism
#
# 				) Disable ONLY_FULL_GROUP_BY.
#
# 					This is equivalent to using ANY_VALUE() with ONLY_FULL_GROUP_BY enabled,
# 					as described in previous time.
#
# 			ANY_VALUE() is also useful if funcitonal dependence exists between columns but
# 			MySQL cannot determine it.
#
# 			The following query is valid because age is functionally dependent
# 			on the grouping column age-1, but MySQL cannot tell that and rejects
# 			the query with ONLY_FULL_GROUP_BY enabled:
#
# 				SELECT age FROM t GROUP BY age-1;
#
# 			To cause MySQL to accept the query, use ANY_VALUE():
#
# 				SELECT ANY_VALUE(age) FROM t GROUP BY age-1;
#
# 			ANY_VALUE() can be used for queries that refer to aggregate functions
# 			in the absence of a GROUP BY clause:
#
# 				SELECT name, MAX(age) FROM t;
# 				ERROR 1140 (42000): In aggregated query without GROUP BY, expression
# 				#1 of SELECT list contains nonaggregated column 'mydb.t.name'; this
# 				is incompatible with sql_mode=only_full_group_by
#
# 			Without GROUP BY, there is a single group and it is nondeterminsitic which name value
# 			to choose for the group.
#
# 			ANY_VALUE() tells MySQL to accept the query:
#
# 				SELECT ANY_VALUE(name), MAX(age) FROM t;
#
# 			It may be that, due to some property of a given data set, you know that a selected
# 			nonaggregated column is effectively functionally dependent on a GROUP BY column.
#
# 			For example, an application may enforce uniqueness of one column with respect
# 			to another.
#
# 			In this case, using ANY_VALUE() for hte effectively functioanlly dependent
# 			column may make sense.
#
# 			For additional discussion, see SECTION 12.20.3, "MySQL HANDLING OF GROUP BY"
#
# 		) BIN_TO_UUID(binary uuid), BIN_TO_UUID(binary uuid, swap flag)
#
# 			https://dev.mysql.com/doc/refman/8.0/en/miscellaneous-functions.html
# 				